from typing import List , Dict [EOL] import typing [EOL] [docstring] [EOL] import setuptools [EOL] import os [EOL] import pymfe [EOL] [EOL] [EOL] with open ( [string] , [string] ) as fh : [EOL] LONG_DESCRIPTION = fh . read ( ) [EOL] [EOL] [EOL] NAME = [string] [EOL] [EOL] [EOL] VERSION = pymfe . __version__ [EOL] [EOL] [EOL] DESCRIPTION = [string] [EOL] [EOL] [EOL] LICENSE = [string] [EOL] [EOL] [EOL] URL = [string] [EOL] [EOL] MAINTAINER = [string] [EOL] [EOL] [EOL] MAINTAINER_EMAIL = [string] [EOL] [EOL] [EOL] DOWNLOAD_URL = [string] [EOL] [EOL] [EOL] CLASSIFIERS = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] [EOL] [EOL] INSTALL_REQUIRES = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] [EOL] [EOL] EXTRAS_REQUIRE = { [string] : [ [string] , [string] , [string] , [string] , [string] ] , [string] : [ [string] , [string] , [string] ] , [string] : [ [string] , [string] , [string] , [string] , [string] ] } [EOL] [EOL] [EOL] setuptools . setup ( name = NAME , version = VERSION , long_description = LONG_DESCRIPTION , long_description_content_type = [string] , license = LICENSE , url = URL , maintainer = MAINTAINER , maintainer_email = MAINTAINER_EMAIL , description = DESCRIPTION , download_url = DOWNLOAD_URL , packages = setuptools . find_packages ( ) , classifiers = CLASSIFIERS , install_requires = INSTALL_REQUIRES , extras_require = EXTRAS_REQUIRE , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.List[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 $typing.Dict[builtins.str,typing.List[builtins.str]]$ 0 0 0
from typing import Any , Tuple , Sequence [EOL] import pymfe [EOL] import typing [EOL] [docstring] [EOL] [EOL] from sklearn . datasets import load_iris [EOL] from pymfe . mfe import MFE [EOL] [EOL] [comment] [EOL] data = load_iris ( ) [EOL] y = data . target [EOL] X = data . data [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] mfe = MFE ( ) [EOL] mfe . fit ( X , y ) [EOL] ft = mfe . extract ( ) [EOL] print ( len ( ft [ [number] ] ) ) [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] mfe = MFE ( groups = [string] , summary = [string] ) [EOL] mfe . fit ( X , y ) [EOL] ft = mfe . extract ( ) [EOL] print ( len ( ft [ [number] ] ) ) [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $pymfe.mfe.MFE$ 0 0 0 0 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 0 0 0 0 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Tuple , Sequence [EOL] import pymfe [EOL] import typing [EOL] [docstring] [EOL] [EOL] [comment] [EOL] from sklearn . datasets import load_iris [EOL] import numpy as np [EOL] import pymfe . mfe [EOL] import matplotlib . pyplot as plt [EOL] [EOL] iris = load_iris ( ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] np . random . seed ( [number] ) [EOL] [EOL] arrsize = np . zeros ( [number] ) [EOL] time = np . zeros ( [number] ) [EOL] [EOL] X = np . empty ( ( iris . target . size , [number] ) ) [EOL] [EOL] for i in np . arange ( [number] ) : [EOL] X = np . hstack ( ( X , iris . data ) ) [EOL] print ( f"{ i } [string] { X . shape [ [number] ] } [string] " ) [EOL] model = pymfe . mfe . MFE ( features = [string] , summary = [string] , measure_time = [string] ) . fit ( X ) [EOL] res = model . extract ( suppress_warnings = True ) [EOL] [EOL] arrsize [ i ] = model . _custom_args_ft [ [string] ] . shape [ [number] ] [EOL] time [ i ] = res [ [number] ] [ [number] ] [EOL] [EOL] plt . plot ( arrsize , time , label = [string] ) [EOL] plt . hlines ( y = np . arange ( [number] , [number] + int ( np . ceil ( np . max ( time ) ) ) ) , xmin = [number] , xmax = arrsize [ - [number] ] , linestyle = [string] , color = [string] ) [EOL] plt . legend ( ) [EOL] plt . show ( ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[docstring] [EOL] [EOL] from pymfe . mfe import MFE [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] MFE . metafeature_description ( ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] MFE . metafeature_description ( groups = [ [string] , [string] ] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] MFE . metafeature_description ( sort_by_group = True , sort_by_mtf = True ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] MFE . metafeature_description ( sort_by_group = True , sort_by_mtf = True , include_references = True ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] MFE . metafeature_description ( print_table = False ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import List , Any , Tuple , Sequence [EOL] import pymfe [EOL] import typing [EOL] [docstring] [EOL] [EOL] from sklearn . datasets import load_iris [EOL] from pymfe . mfe import MFE [EOL] [EOL] data = load_iris ( ) [EOL] y = data . target [EOL] X = data . data [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] model = MFE ( groups = [ [string] , [string] , [string] ] , measure_time = [string] ) [EOL] model . fit ( X , y ) [EOL] ft = model . extract ( ) [EOL] print ( [string] . join ( [string] . format ( x , y ) for x , y in zip ( ft [ [number] ] , ft [ [number] ] ) ) ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] ft_general = model . parse_by_group ( [string] , ft ) [EOL] print ( [string] . join ( [string] . format ( x , y ) for x , y in zip ( ft_general [ [number] ] , ft_general [ [number] ] ) ) ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] ft_subset = model . parse_by_group ( [ [string] , [string] ] , ft ) [EOL] print ( [string] . join ( [string] . format ( x , y ) for x , y in zip ( ft_subset [ [number] ] , ft_subset [ [number] ] ) ) ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] ft_subset = MFE . parse_by_group ( [ [string] , [string] ] , ft ) [EOL] print ( [string] . join ( [string] . format ( x , y ) for x , y in zip ( ft_subset [ [number] ] , ft_subset [ [number] ] ) ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing.List[typing.Any],...]$ 0 $pymfe.mfe.MFE$ 0 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing.List[typing.Any],...]$ 0 0 0 0 $typing.Tuple[typing.List[typing.Any],...]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing.List[typing.Any],...]$ 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing.List[typing.Any],...]$ 0 0 0 0 $typing.Tuple[typing.List[typing.Any],...]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing.List[typing.Any],...]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing.List[typing.Any],...]$ 0 0 0 0 $typing.Tuple[typing.List[typing.Any],...]$ 0 0 0 0 0 0 0
from typing import Tuple [EOL] import pymfe [EOL] import typing [EOL] [docstring] [EOL] [EOL] from sklearn . datasets import load_iris [EOL] from pymfe . mfe import MFE [EOL] [EOL] [comment] [EOL] [comment] [EOL] model = MFE ( ) [EOL] model_groups = model . valid_groups ( ) [EOL] print ( model_groups ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] model_groups = MFE . valid_groups ( ) [EOL] print ( model_groups ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] model = MFE ( ) [EOL] mtfs_all = model . valid_metafeatures ( ) [EOL] print ( mtfs_all ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] mtfs_all = MFE . valid_metafeatures ( ) [EOL] print ( mtfs_all ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] mtfs_landmarking = MFE . valid_metafeatures ( groups = [string] ) [EOL] print ( mtfs_landmarking ) [EOL] [EOL] mtfs_subset = MFE . valid_metafeatures ( groups = [ [string] , [string] ] ) [EOL] print ( mtfs_subset ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] model = MFE ( ) [EOL] summaries = model . valid_summary ( ) [EOL] print ( summaries ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] summaries = MFE . valid_summary ( ) [EOL] print ( summaries ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pymfe.mfe.MFE$ 0 0 0 0 0 $typing.Tuple[builtins.str,...]$ 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 $typing.Tuple[builtins.str,...]$ 0 0 0 0 0 0 0 $typing.Tuple[builtins.str,...]$ 0 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.str,...]$ 0 0 0 0 0 0 0 0 0 0 0 $pymfe.mfe.MFE$ 0 0 0 0 0 $typing.Tuple[builtins.str,...]$ 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 $typing.Tuple[builtins.str,...]$ 0 0 0 0 0 0 0 $typing.Tuple[builtins.str,...]$ 0 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.str,...]$ 0 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.str,...]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.str,...]$ 0 0 0 $typing.Tuple[builtins.str,...]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.str,...]$ 0 0 0 0 0 0 0 $pymfe.mfe.MFE$ 0 0 0 0 0 $typing.Tuple[builtins.str,...]$ 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 $typing.Tuple[builtins.str,...]$ 0 0 0 0 0 0 0 $typing.Tuple[builtins.str,...]$ 0 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.str,...]$ 0 0
from typing import List , Any , Tuple [EOL] import pymfe [EOL] import typing [EOL] [docstring] [EOL] [EOL] [comment] [EOL] import sklearn . tree [EOL] from sklearn . datasets import load_iris [EOL] from pymfe . mfe import MFE [EOL] [EOL] data = load_iris ( ) [EOL] y = data . target [EOL] X = data . data [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] mfe = MFE ( features = [ [string] , [string] , [string] , [string] ] ) [EOL] mfe . fit ( X , y ) [EOL] [EOL] ft = mfe . extract_with_confidence ( sample_num = [number] , confidence = [number] , verbose = [number] , ) [EOL] [EOL] print ( [string] . join ( [string] . format ( x , y [ [number] ] , y [ [number] ] ) for x , y in zip ( ft [ [number] ] , ft [ [number] ] ) ) ) [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pymfe.mfe.MFE$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing.List[typing.Any],...]$ 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing.List[typing.Any],...]$ 0 0 0 0 $typing.Tuple[typing.List[typing.Any],...]$ 0 0 0 0 0 0 0 0
from typing import Any , Tuple , Sequence [EOL] import pymfe [EOL] import typing [EOL] [docstring] [EOL] [EOL] [EOL] [comment] [EOL] from sklearn . datasets import load_iris [EOL] from pymfe . mfe import MFE [EOL] [EOL] data = load_iris ( ) [EOL] y = data . target [EOL] X = data . data [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] mfe = MFE ( features = [ [string] , [string] , [string] , [string] , [string] ] ) [EOL] mfe . fit ( X , y ) [EOL] ft = mfe . extract ( sd = { [string] : [number] } , nr_norm = { [string] : [string] , [string] : [string] , [string] : [number] } , nr_cor_attr = { [string] : [number] } , ) [EOL] print ( [string] . join ( [string] . format ( x , y ) for x , y in zip ( ft [ [number] ] , ft [ [number] ] ) ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pymfe.mfe.MFE$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 0 0 0 0 0 0
from typing import Any , Tuple , Sequence [EOL] import pymfe [EOL] import typing [EOL] [docstring] [EOL] [EOL] [EOL] [comment] [EOL] from sklearn . datasets import load_iris [EOL] from pymfe . mfe import MFE [EOL] [EOL] data = load_iris ( ) [EOL] y = data . target [EOL] X = data . data [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] mfe = MFE ( features = [ [string] , [string] ] , summary = [ [string] , [string] , [string] ] ) [EOL] mfe . fit ( X , y ) [EOL] ft = mfe . extract ( ) [EOL] print ( [string] . join ( [string] . format ( x , y ) for x , y in zip ( ft [ [number] ] , ft [ [number] ] ) ) ) [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] mfe = MFE ( features = [ [string] , [string] , [string] ] , summary = [ [string] , [string] , [string] ] ) [EOL] mfe . fit ( X , y ) [EOL] ft = mfe . extract ( ) [EOL] print ( [string] . join ( [string] . format ( x , y ) for x , y in zip ( ft [ [number] ] , ft [ [number] ] ) ) ) [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] mfe = MFE ( features = [ [string] , [string] , [string] , [string] , [string] ] , summary = [ [string] , [string] , [string] ] ) [EOL] mfe . fit ( X , y ) [EOL] ft = mfe . extract ( ) [EOL] print ( [string] . join ( [string] . format ( x , y ) for x , y in zip ( ft [ [number] ] , ft [ [number] ] ) ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pymfe.mfe.MFE$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 0 0 0 0 0 0
from typing import Any , Tuple , Sequence [EOL] import pymfe [EOL] import typing [EOL] [docstring] [EOL] [EOL] [comment] [EOL] import sklearn . tree [EOL] from sklearn . datasets import load_iris [EOL] from pymfe . mfe import MFE [EOL] [EOL] iris = load_iris ( ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [EOL] model = sklearn . tree . DecisionTreeClassifier ( ) . fit ( iris . data , iris . target ) [EOL] extractor = MFE ( ) [EOL] ft = extractor . extract_from_model ( model ) [EOL] print ( [string] . join ( [string] . format ( x , y ) for x , y in zip ( ft [ [number] ] , ft [ [number] ] ) ) ) [EOL] [EOL] [comment] [EOL] extractor = MFE ( features = [ [string] , [string] ] , summary = [string] ) [EOL] [EOL] ft = extractor . extract_from_model ( model , arguments_fit = { [string] : [number] } , arguments_extract = { [string] : [number] , [string] : { [string] : [number] } } ) [EOL] [EOL] print ( [string] . join ( [string] . format ( x , y ) for x , y in zip ( ft [ [number] ] , ft [ [number] ] ) ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 $pymfe.mfe.MFE$ 0 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 $pymfe.mfe.MFE$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 0 0 0 0 0 0 0 0 0 $pymfe.mfe.MFE$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 $pymfe.mfe.MFE$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 0 0 0 $typing.Tuple[typing.Sequence[typing.Any],...]$ 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [EOL] from typing import Tuple , Union , List , Dict , Any [EOL] import typing [EOL] import os [EOL] import sys [EOL] import sphinx_rtd_theme [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] sys . path . insert ( [number] , os . path . abspath ( [string] ) ) [EOL] from github_link import make_linkcode_resolve [EOL] import sphinx_gallery [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] project = [string] [EOL] copyright = [string] [EOL] author = [string] [EOL] [EOL] [comment] [EOL] from pymfe import __version__ [EOL] version = release = __version__ [EOL] [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] master_doc = [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] extensions = [ [string] , [string] , [string] , [string] , [string] , [string] , ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] numpydoc_show_class_members = False [EOL] [EOL] [EOL] [comment] [EOL] templates_path = [ [string] ] [EOL] [EOL] [comment] [EOL] add_function_parentheses = False [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] exclude_patterns = [ [string] , [string] ] [EOL] [comment] [EOL] [EOL] autodoc_default_options = { [string] : True , [string] : True } [EOL] [comment] [EOL] [EOL] [comment] [EOL] autosummary_generate = True [EOL] [EOL] [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] pygments_style = [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] html_theme = [string] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [EOL] [EOL] [comment] [EOL] htmlhelp_basename = [string] [EOL] [EOL] [EOL] [comment] [EOL] intersphinx_mapping = { [string] : ( [string] . format ( sys . version_info ) , None ) , [string] : ( [string] , None ) , [string] : ( [string] , None ) , [string] : ( [string] , None ) , [string] : ( [string] , None ) , [string] : ( [string] , None ) , [string] : ( [string] , None ) } [EOL] [EOL] [comment] [EOL] [EOL] sphinx_gallery_conf = { [string] : [string] , [string] : os . path . join ( [string] ) , [string] : [string] , [string] : [string] , [string] : { [string] : None , } , } [EOL] [EOL] [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] linkcode_resolve = make_linkcode_resolve ( [string] , [string] [string] [string] ) [EOL] [comment] [EOL] [EOL] [EOL] [comment] [EOL] import os [EOL] os . system ( [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.bool]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Tuple[builtins.str,None]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Union[typing.Dict[builtins.str,None],builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import io [EOL] import typing [EOL] [docstring] [EOL] import os [EOL] import pandas as pd [EOL] from pymfe . mfe import MFE [EOL] [EOL] [EOL] AUTO_PAGES_PATH = [string] [EOL] TABLE_CONF = [string] [EOL] [EOL] NOTE_REL_SUB = [string] [EOL] [EOL] NOTE_OTHER_INFO = [string] [EOL] [EOL] TITLE = [string] [EOL] [EOL] [EOL] def meta_features_description ( ) : [EOL] [docstring] [EOL] data , _ = MFE . metafeature_description ( sort_by_group = True , sort_by_mtf = True , print_table = False , include_references = True ) [EOL] [EOL] if not os . path . exists ( AUTO_PAGES_PATH ) : [EOL] os . makedirs ( AUTO_PAGES_PATH ) [EOL] [EOL] col = data [ [number] ] [EOL] del data [ [number] ] [EOL] df = pd . DataFrame ( data , columns = col ) [EOL] [EOL] df . to_csv ( AUTO_PAGES_PATH + [string] , index = False ) [EOL] [EOL] notes = NOTE_REL_SUB + [string] + NOTE_OTHER_INFO [EOL] [EOL] table_str = TABLE_CONF [EOL] f = open ( AUTO_PAGES_PATH + [string] , [string] ) [EOL] f . write ( TITLE + [string] + table_str + [string] + notes ) [EOL] f . close ( ) [EOL] [EOL] [EOL] def main ( ) : [EOL] [docstring] [EOL] meta_features_description ( ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] from typing import Any [EOL] import typing [EOL] from operator import attrgetter [EOL] import inspect [EOL] import subprocess [EOL] import os [EOL] import sys [EOL] from functools import partial [EOL] [EOL] REVISION_CMD = [string] [EOL] [EOL] [EOL] def _get_git_revision ( ) : [EOL] try : [EOL] revision = subprocess . check_output ( REVISION_CMD . split ( ) ) . strip ( ) [EOL] except ( subprocess . CalledProcessError , OSError ) : [EOL] print ( [string] ) [EOL] return None [EOL] return revision . decode ( [string] ) [EOL] [EOL] [EOL] def _linkcode_resolve ( domain , info , package , url_fmt , revision ) : [EOL] [docstring] [EOL] [EOL] if revision is None : [EOL] return [EOL] if domain not in ( [string] , [string] ) : [EOL] return [EOL] if not info . get ( [string] ) or not info . get ( [string] ) : [EOL] return [EOL] [EOL] class_name = info [ [string] ] . split ( [string] ) [ [number] ] [EOL] if type ( class_name ) != str : [EOL] [comment] [EOL] class_name = class_name . encode ( [string] ) [EOL] module = __import__ ( info [ [string] ] , fromlist = [ class_name ] ) [EOL] obj = attrgetter ( info [ [string] ] ) ( module ) [EOL] [EOL] try : [EOL] fn = inspect . getsourcefile ( obj ) [EOL] except Exception : [EOL] fn = None [EOL] if not fn : [EOL] try : [EOL] fn = inspect . getsourcefile ( sys . modules [ obj . __module__ ] ) [EOL] except Exception : [EOL] fn = None [EOL] if not fn : [EOL] return [EOL] [EOL] fn = os . path . relpath ( fn , start = os . path . dirname ( __import__ ( package ) . __file__ ) ) [EOL] try : [EOL] lineno = inspect . getsourcelines ( obj ) [ [number] ] [EOL] except Exception : [EOL] lineno = [string] [EOL] return url_fmt . format ( revision = revision , package = package , path = fn , lineno = lineno ) [EOL] [EOL] [EOL] def make_linkcode_resolve ( package , url_fmt ) : [EOL] [docstring] [EOL] revision = _get_git_revision ( ) [EOL] return partial ( _linkcode_resolve , revision = revision , package = package , url_fmt = url_fmt ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Any [EOL] import typing [EOL] [docstring] [EOL] [EOL] import pytest [EOL] import numpy as np [EOL] [EOL] from pymfe . scoring import accuracy [EOL] from pymfe . scoring import balanced_accuracy [EOL] from pymfe . scoring import f1 [EOL] [EOL] [EOL] def test_accuracy ( ) : [EOL] y_true = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] y_pred = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] assert accuracy ( y_true , y_pred ) == [number] [EOL] [EOL] y_true = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] y_pred = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] assert accuracy ( y_true , y_pred ) == [number] [EOL] [EOL] y_true = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] y_pred = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] assert accuracy ( y_true , y_pred ) == [number] [EOL] [EOL] y_true = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] y_pred = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] assert accuracy ( y_true , y_pred ) == [number] [EOL] [EOL] [EOL] def test_balanced_accuracy ( ) : [EOL] y_true = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] y_pred = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] assert np . isclose ( balanced_accuracy ( y_true , y_pred ) , [number] ) [EOL] [EOL] y_true = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] y_pred = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] assert np . isclose ( balanced_accuracy ( y_true , y_pred ) , [number] ) [EOL] [EOL] y_true = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] y_pred = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] assert np . isclose ( balanced_accuracy ( y_true , y_pred ) , [number] / [number] ) [EOL] [EOL] [EOL] def test_f1 ( ) : [EOL] y_true = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] y_pred = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] assert np . isclose ( f1 ( y_true , y_pred ) , [number] ) [EOL] [EOL] y_true = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] y_pred = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] assert np . isclose ( f1 ( y_true , y_pred ) , [number] ) [EOL] [EOL] y_true = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] y_pred = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] assert np . isclose ( f1 ( y_true , y_pred ) , [number] / [number] ) [EOL] [EOL] y_true = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] y_pred = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] assert np . isclose ( f1 ( y_true , y_pred ) , [number] ) [EOL] [EOL] y_true = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] y_pred = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] assert np . isclose ( f1 ( y_true , y_pred ) , [number] / [number] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import List , Any , Union [EOL] import numpy [EOL] import builtins [EOL] import typing [EOL] [docstring] [EOL] import typing as t [EOL] [EOL] import arff [EOL] import pandas as pd [EOL] import numpy as np [EOL] [EOL] DATA_ID = [ [string] , [string] , [string] , ] [EOL] [EOL] DATA_ = [ None , None , None , ] [EOL] [EOL] [EOL] def load_xy ( dt_id ) : [EOL] [docstring] [EOL] if DATA_ [ dt_id ] is None : [EOL] with open ( DATA_ID [ dt_id ] , [string] ) as data_file : [EOL] data = arff . load ( data_file ) [EOL] df = pd . DataFrame ( data [ [string] ] ) [EOL] y = df . iloc [ : , - [number] ] [EOL] X = df . iloc [ : , : - [number] ] [EOL] DATA_ [ dt_id ] = ( X , y ) [EOL] [EOL] return DATA_ [ dt_id ] [EOL] [EOL] [EOL] def raise_memory_error ( size = [number] ) : [EOL] [docstring] [EOL] return np . zeros ( int ( size ) , dtype = np . float64 ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Optional , Any [EOL] import numpy [EOL] import typing [EOL] [docstring] [EOL] import typing as t [EOL] [EOL] import numpy as np [EOL] [EOL] [EOL] def calc_cls_inds ( y , classes = None ) : [EOL] [docstring] [EOL] if classes is None : [EOL] classes = np . unique ( y ) [EOL] [EOL] cls_inds = np . array ( [ np . equal ( y , cur_cls ) for cur_cls in classes ] , dtype = bool ) [EOL] [EOL] return cls_inds [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
import numpy [EOL] import builtins [EOL] [docstring] [EOL] import numpy as np [EOL] import sklearn . metrics [EOL] [EOL] [EOL] def accuracy ( y_true , y_pred ) : [EOL] [docstring] [EOL] return sklearn . metrics . accuracy_score ( y_true , y_pred ) [EOL] [EOL] [EOL] def balanced_accuracy ( y_true , y_pred ) : [EOL] [docstring] [EOL] return sklearn . metrics . balanced_accuracy_score ( y_true , y_pred ) [EOL] [EOL] [EOL] def f1 ( y_true , y_pred ) : [EOL] [docstring] [EOL] return sklearn . metrics . f1_score ( y_true , y_pred , average = [string] ) [EOL] [EOL] [EOL] def kappa ( y_true , y_pred ) : [EOL] [docstring] [EOL] raise NotImplementedError ( [string] ) [EOL] [EOL] [EOL] def auc ( y_true , y_pred ) : [EOL] [docstring] [EOL] raise NotImplementedError ( [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[docstring] [EOL] [EOL] from . _version import __version__ [comment] [EOL]	0 0 0 0 0 0 0 0 0 0
[docstring] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] __version__ = [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0
from typing import Optional , Tuple , Union , List , Literal , Dict , Any [EOL] import numpy [EOL] import builtins [EOL] import typing_extensions [EOL] import typing [EOL] [docstring] [EOL] import typing as t [EOL] import warnings [EOL] [EOL] import numpy as np [EOL] import scipy [EOL] import sklearn . preprocessing [EOL] import sklearn . cross_decomposition [EOL] [EOL] import pymfe . _summary as _summary [EOL] [EOL] [EOL] class MFEStatistical : [EOL] [docstring] [EOL] [EOL] @ classmethod def precompute_statistical_class ( cls , y = None , ** kwargs ) : [EOL] [docstring] [EOL] precomp_vals = { } [EOL] [EOL] if y is not None and not { [string] , [string] } . issubset ( kwargs ) : [EOL] classes , class_freqs = np . unique ( y , return_counts = True ) [EOL] [EOL] precomp_vals [ [string] ] = classes [EOL] precomp_vals [ [string] ] = class_freqs [EOL] [EOL] return precomp_vals [EOL] [EOL] @ classmethod def precompute_can_cors ( cls , N = None , y = None , ** kwargs ) : [EOL] [docstring] [EOL] precomp_vals = { } [EOL] [EOL] if ( y is not None [EOL] and N is not None [EOL] and N . size [EOL] and not { [string] , [string] } . issubset ( kwargs ) ) : [EOL] can_cors = cls . _calc_can_cors ( N = N , y = y ) [EOL] [EOL] precomp_vals [ [string] ] = can_cors [EOL] precomp_vals [ [string] ] = cls . _can_cor_to_eigval ( can_cors ) [EOL] [EOL] return precomp_vals [EOL] [EOL] @ classmethod def precompute_statistical_cor_cov ( cls , N = None , ddof = [number] , ** kwargs ) : [EOL] [docstring] [EOL] precomp_vals = { } [EOL] [EOL] if N is not None and N . size : [EOL] if [string] not in kwargs : [EOL] precomp_vals [ [string] ] = np . cov ( N , rowvar = False , ddof = ddof ) [EOL] [EOL] if [string] not in kwargs : [EOL] abs_corr_mat = np . abs ( np . corrcoef ( N , rowvar = False ) ) [EOL] [EOL] if not isinstance ( abs_corr_mat , np . ndarray ) and np . isnan ( abs_corr_mat ) : [EOL] abs_corr_mat = np . array ( [ np . nan ] ) [EOL] [EOL] precomp_vals [ [string] ] = abs_corr_mat [EOL] [EOL] return precomp_vals [EOL] [EOL] @ staticmethod def _can_cor_to_eigval ( can_cors ) : [EOL] [docstring] [EOL] sqr_can_cors = np . square ( can_cors ) [EOL] can_cor_eig_vals = sqr_can_cors / ( [number] - sqr_can_cors ) [EOL] return can_cor_eig_vals [EOL] [EOL] @ classmethod def _calc_can_cors ( cls , N , y , ) : [EOL] [docstring] [EOL] y_bin = sklearn . preprocessing . OneHotEncoder ( sparse = False ) . fit_transform ( y . reshape ( - [number] , [number] ) ) [EOL] [EOL] num_classes , num_attr = y_bin . shape [ [number] ] , N . shape [ [number] ] [EOL] [comment] [EOL] [comment] [EOL] n_components = min ( num_classes , num_attr ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] warnings . filterwarnings ( [string] , category = UserWarning ) [EOL] [EOL] N_tf , y_tf = sklearn . cross_decomposition . CCA ( n_components = n_components ) . fit_transform ( N , y_bin ) [EOL] [EOL] warnings . filterwarnings ( [string] , category = UserWarning ) [EOL] [EOL] ind = [number] [EOL] can_cors = np . zeros ( n_components , dtype = float ) [EOL] [EOL] while ind < n_components and np . any ( np . flatnonzero ( N_tf [ : , ind ] ) ) : [EOL] can_cors [ ind ] = np . corrcoef ( N_tf [ : , ind ] , y_tf [ : , ind ] ) [ [number] , [number] ] [EOL] ind += [number] [EOL] [EOL] can_cors = can_cors [ : ind ] [EOL] [EOL] return can_cors [EOL] [EOL] @ classmethod def ft_can_cor ( cls , N , y , can_cors = None , ) : [EOL] [docstring] [EOL] if can_cors is None : [EOL] can_cors = cls . _calc_can_cors ( N = N , y = y ) [EOL] [EOL] return can_cors [EOL] [EOL] @ classmethod def ft_gravity ( cls , N , y , norm_ord = [number] , classes = None , class_freqs = None , cls_inds = None , ) : [EOL] [docstring] [EOL] if classes is None or class_freqs is None : [EOL] classes , class_freqs = np . unique ( y , return_counts = True ) [EOL] [EOL] ind_cls_maj = np . argmax ( class_freqs ) [EOL] class_maj = classes [ ind_cls_maj ] [EOL] [EOL] classes = np . delete ( classes , ind_cls_maj ) [EOL] class_freqs = np . delete ( class_freqs , ind_cls_maj ) [EOL] [EOL] ind_cls_min = np . argmin ( class_freqs ) [EOL] [EOL] if cls_inds is not None : [EOL] insts_cls_maj = N [ cls_inds [ ind_cls_maj , : ] , : ] [EOL] [comment] [EOL] ind_cls_min += ind_cls_min >= ind_cls_maj [EOL] insts_cls_min = N [ cls_inds [ ind_cls_min , : ] , : ] [EOL] [EOL] else : [EOL] class_min = classes [ ind_cls_min ] [EOL] insts_cls_maj = N [ y == class_maj , : ] [EOL] insts_cls_min = N [ y == class_min , : ] [EOL] [EOL] gravity = np . linalg . norm ( insts_cls_maj . mean ( axis = [number] ) - insts_cls_min . mean ( axis = [number] ) , ord = norm_ord , ) [EOL] [EOL] return gravity [EOL] [EOL] @ classmethod def ft_cor ( cls , N , abs_corr_mat = None ) : [EOL] [docstring] [EOL] if abs_corr_mat is None : [EOL] abs_corr_mat = np . abs ( np . corrcoef ( N , rowvar = False ) ) [EOL] [EOL] res_num_rows , _ = abs_corr_mat . shape [EOL] [EOL] inf_triang_vals = abs_corr_mat [ np . tril_indices ( res_num_rows , k = - [number] ) ] [EOL] [EOL] return np . abs ( inf_triang_vals ) [EOL] [EOL] @ classmethod def ft_cov ( cls , N , ddof = [number] , cov_mat = None , ) : [EOL] [docstring] [EOL] if cov_mat is None : [EOL] cov_mat = np . cov ( N , rowvar = False , ddof = ddof ) [EOL] [EOL] res_num_rows , _ = cov_mat . shape [EOL] [EOL] inf_triang_vals = cov_mat [ np . tril_indices ( res_num_rows , k = - [number] ) ] [EOL] [EOL] return np . abs ( inf_triang_vals ) [EOL] [EOL] @ classmethod def ft_nr_disc ( cls , N , y , can_cors = None , ) : [EOL] [docstring] [EOL] if can_cors is None : [EOL] can_cors = cls . ft_can_cor ( N = N , y = y ) [EOL] [EOL] return can_cors . size [EOL] [EOL] @ classmethod def ft_eigenvalues ( cls , N , ddof = [number] , cov_mat = None , ) : [EOL] [docstring] [EOL] if cov_mat is None : [EOL] cov_mat = np . cov ( N , rowvar = False , ddof = ddof ) [EOL] [EOL] return np . linalg . eigvalsh ( cov_mat ) [EOL] [EOL] @ classmethod def ft_g_mean ( cls , N , allow_zeros = True , epsilon = [number] ) : [EOL] [docstring] [EOL] min_values = N . min ( axis = [number] ) [EOL] [EOL] if allow_zeros : [EOL] cols_invalid = min_values < [number] [EOL] cols_zero = np . logical_and ( min_values >= [number] , min_values < epsilon ) [EOL] cols_valid = np . logical_not ( np . logical_or ( cols_invalid , cols_zero ) ) [EOL] [EOL] else : [EOL] cols_invalid = min_values <= epsilon [EOL] cols_valid = np . logical_not ( cols_invalid ) [EOL] [EOL] _ , num_col = N . shape [EOL] g_mean = np . zeros ( num_col , dtype = float ) [EOL] [EOL] g_mean [ cols_valid ] = scipy . stats . gmean ( N [ : , cols_valid ] , axis = [number] ) [EOL] [EOL] g_mean [ cols_invalid ] = np . nan [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] return g_mean [EOL] [EOL] @ classmethod def ft_h_mean ( cls , N ) : [EOL] [docstring] [EOL] return scipy . stats . hmean ( N , axis = [number] ) [EOL] [EOL] @ classmethod def ft_iq_range ( cls , N ) : [EOL] [docstring] [EOL] return scipy . stats . iqr ( N , axis = [number] ) [EOL] [EOL] @ classmethod def ft_kurtosis ( cls , N , method = [number] , bias = True ) : [EOL] [docstring] [EOL] kurt_arr = np . apply_along_axis ( func1d = _summary . sum_kurtosis , axis = [number] , arr = N , method = method , bias = bias , ) [EOL] [EOL] return kurt_arr [EOL] [EOL] @ classmethod def ft_mad ( cls , N , factor = [number] ) : [EOL] [docstring] [EOL] return scipy . stats . median_absolute_deviation ( x = N , axis = [number] , scale = factor ) [EOL] [EOL] @ classmethod def ft_max ( cls , N ) : [EOL] [docstring] [EOL] return N . max ( axis = [number] ) [EOL] [EOL] @ classmethod def ft_mean ( cls , N ) : [EOL] [docstring] [EOL] return N . mean ( axis = [number] ) [EOL] [EOL] @ classmethod def ft_median ( cls , N ) : [EOL] [docstring] [EOL] return np . median ( N , axis = [number] ) [EOL] [EOL] @ classmethod def ft_min ( cls , N ) : [EOL] [docstring] [EOL] return N . min ( axis = [number] ) [EOL] [EOL] @ classmethod def ft_nr_cor_attr ( cls , N , threshold = [number] , normalize = True , abs_corr_mat = None , ) : [EOL] [docstring] [EOL] abs_corr_vals = cls . ft_cor ( N , abs_corr_mat = abs_corr_mat ) [EOL] [EOL] _ , num_attr = N . shape [EOL] [EOL] norm_factor = [number] [EOL] [EOL] if normalize : [EOL] norm_factor = [number] / ( num_attr * ( num_attr - [number] ) ) [EOL] [EOL] return np . sum ( abs_corr_vals >= threshold ) * norm_factor [EOL] [EOL] @ classmethod def ft_nr_norm ( cls , N , method = [string] , threshold = [number] , failure = [string] , max_samples = [number] , ) : [EOL] [docstring] [EOL] accepted_tests = ( [string] , [string] , [string] , [string] , ) [EOL] [EOL] if method not in accepted_tests : [EOL] raise ValueError ( [string] . format ( method , accepted_tests ) ) [EOL] [EOL] if failure not in ( [string] , [string] ) : [EOL] raise ValueError ( [string] [string] . format ( failure ) ) [EOL] [EOL] if max_samples <= [number] : [EOL] return np . nan [EOL] [EOL] num_inst , num_attr = N . shape [EOL] [EOL] max_row_index = min ( max_samples , num_inst ) [EOL] [EOL] test_results = [ ] [EOL] [EOL] if method in ( [string] , [string] ) : [EOL] _ , p_values_shapiro = np . apply_along_axis ( func1d = scipy . stats . shapiro , axis = [number] , arr = N [ : max_row_index , : ] ) [EOL] [EOL] test_results . append ( p_values_shapiro > threshold ) [EOL] [EOL] if method in ( [string] , [string] ) : [EOL] _ , p_values_dagostino = scipy . stats . normaltest ( N [ : max_row_index , : ] , axis = [number] ) [EOL] [EOL] test_results . append ( p_values_dagostino > threshold ) [EOL] [EOL] if method in ( [string] , [string] ) : [EOL] anderson_stats = np . repeat ( False , num_attr ) [EOL] [EOL] for attr_ind , attr_vals in enumerate ( N [ : max_row_index , : ] . T ) : [EOL] stat_value , crit_values , signif_levels = scipy . stats . anderson ( attr_vals , dist = [string] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] stat_index = np . argmin ( abs ( signif_levels - threshold ) ) [EOL] crit_val = crit_values [ stat_index ] [EOL] [EOL] anderson_stats [ attr_ind ] = stat_value <= crit_val [EOL] [EOL] test_results . append ( anderson_stats ) [EOL] [EOL] if failure == [string] : [EOL] attr_is_normal = np . any ( test_results , axis = [number] ) [EOL] [EOL] else : [EOL] attr_is_normal = np . all ( test_results , axis = [number] ) [EOL] [EOL] return np . sum ( attr_is_normal ) [EOL] [EOL] @ classmethod def ft_nr_outliers ( cls , N , whis = [number] ) : [EOL] [docstring] [EOL] v_min , q_1 , q_3 , v_max = np . percentile ( N , ( [number] , [number] , [number] , [number] ) , axis = [number] ) [EOL] [EOL] whis_iqr = whis * ( q_3 - q_1 ) [EOL] [EOL] cut_low = q_1 - whis_iqr [EOL] cut_high = q_3 + whis_iqr [EOL] [EOL] return np . sum ( np . logical_or ( cut_low > v_min , cut_high < v_max ) ) [EOL] [EOL] @ classmethod def ft_range ( cls , N ) : [EOL] [docstring] [EOL] return np . ptp ( N , axis = [number] ) [EOL] [EOL] @ classmethod def ft_sd ( cls , N , ddof = [number] ) : [EOL] [docstring] [EOL] return N . std ( axis = [number] , ddof = ddof ) [EOL] [EOL] @ classmethod def ft_sd_ratio ( cls , N , y , ddof = [number] , classes = None , class_freqs = None , ) : [EOL] [docstring] [EOL] [EOL] def calc_sample_cov_mat ( N , y , ddof ) : [EOL] [docstring] [EOL] sample_cov_matrices = np . array ( [ np . cov ( N [ y == cl , : ] , rowvar = False , ddof = ddof ) for cl in classes ] ) [EOL] [EOL] return np . flip ( m = sample_cov_matrices , axis = ( [number] , [number] ) ) [EOL] [EOL] def calc_pooled_cov_mat ( sample_cov_matrices , vec_weight , num_inst , num_classes , ) : [EOL] [docstring] [EOL] pooled_cov_mat = np . array ( [ weight * S_i for weight , S_i in zip ( vec_weight , sample_cov_matrices ) ] ) . sum ( axis = [number] ) / ( num_inst - num_classes ) [EOL] [EOL] return pooled_cov_mat [EOL] [EOL] def calc_gamma_factor ( num_col , num_classes , num_inst ) : [EOL] [docstring] [EOL] gamma = [number] - ( ( [number] * num_col ** [number] + [number] * num_col - [number] ) / ( [number] * ( num_col + [number] ) * ( num_classes - [number] ) ) ) * ( np . sum ( [number] / vec_weight ) - [number] / ( num_inst - num_classes ) ) [EOL] return gamma [EOL] [EOL] def calc_m_factor ( sample_cov_matrices , pooled_cov_mat , num_inst , num_classes , gamma , vec_weight , ) : [EOL] [docstring] [EOL] vec_logdet = [ np . math . log ( np . linalg . det ( S_i ) ) for S_i in sample_cov_matrices ] [EOL] [EOL] m_factor = gamma * ( ( num_inst - num_classes ) * np . math . log ( np . linalg . det ( pooled_cov_mat ) ) - np . dot ( vec_weight , vec_logdet ) ) [EOL] [EOL] return m_factor [EOL] [EOL] num_inst , num_col = N . shape [EOL] [EOL] if classes is None or class_freqs is None : [EOL] classes , class_freqs = np . unique ( y , return_counts = True ) [EOL] [EOL] num_classes = classes . size [EOL] [EOL] sample_cov_matrices = calc_sample_cov_mat ( N , y , ddof ) [EOL] [EOL] vec_weight = class_freqs - [number] [EOL] [EOL] pooled_cov_mat = calc_pooled_cov_mat ( sample_cov_matrices , vec_weight , num_inst , num_classes ) [EOL] [EOL] gamma = calc_gamma_factor ( num_col , num_classes , num_inst ) [EOL] [EOL] m_factor = calc_m_factor ( sample_cov_matrices , pooled_cov_mat , num_inst , num_classes , gamma , vec_weight , ) [EOL] [EOL] return np . exp ( m_factor / ( num_col * ( num_inst - num_classes ) ) ) [EOL] [EOL] @ classmethod def ft_skewness ( cls , N , method = [number] , bias = True ) : [EOL] [docstring] [EOL] skew_arr = np . apply_along_axis ( func1d = _summary . sum_skewness , axis = [number] , arr = N , bias = bias , method = method , ) [EOL] [EOL] return skew_arr [EOL] [EOL] @ classmethod def ft_sparsity ( cls , X , normalize = True ) : [EOL] [docstring] [EOL] ans = np . array ( [ attr . size / np . unique ( attr ) . size for attr in X . T ] ) [EOL] [EOL] num_inst , _ = X . shape [EOL] [EOL] norm_factor = [number] [EOL] if normalize : [EOL] norm_factor = [number] / ( num_inst - [number] ) [EOL] [EOL] return ( ans - [number] ) * norm_factor [EOL] [EOL] @ classmethod def ft_t_mean ( cls , N , pcut = [number] ) : [EOL] [docstring] [EOL] return scipy . stats . trim_mean ( N , proportiontocut = pcut ) [EOL] [EOL] @ classmethod def ft_var ( cls , N , ddof = [number] ) : [EOL] [docstring] [EOL] return N . var ( axis = [number] , ddof = ddof ) [EOL] [EOL] @ classmethod def ft_w_lambda ( cls , N , y , can_cor_eigvals = None , can_cors = None , ) : [EOL] [docstring] [EOL] if can_cor_eigvals is None : [EOL] if can_cors is None : [EOL] can_cors = cls . _calc_can_cors ( N = N , y = y ) [EOL] [EOL] can_cor_eigvals = cls . _can_cor_to_eigval ( can_cors ) [EOL] [EOL] if can_cor_eigvals . size == [number] : [EOL] return np . nan [EOL] [EOL] return np . prod ( [number] / ( [number] + can_cor_eigvals ) ) [EOL] [EOL] @ classmethod def ft_p_trace ( cls , N , y , can_cors = None , ) : [EOL] [docstring] [EOL] if can_cors is None : [EOL] can_cors = cls . _calc_can_cors ( N = N , y = y ) [EOL] [EOL] if can_cors . size == [number] : [comment] [EOL] return np . nan [EOL] [EOL] return np . sum ( np . square ( can_cors ) ) [EOL] [EOL] @ classmethod def ft_lh_trace ( cls , N , y , can_cor_eigvals = None , can_cors = None , ) : [EOL] [docstring] [EOL] if can_cor_eigvals is None : [EOL] if can_cors is None : [EOL] can_cors = cls . _calc_can_cors ( N = N , y = y ) [EOL] [EOL] can_cor_eigvals = cls . _can_cor_to_eigval ( can_cors ) [EOL] [EOL] if can_cor_eigvals . size == [number] : [comment] [EOL] return np . nan [EOL] [EOL] return np . sum ( can_cor_eigvals ) [EOL] [EOL] @ classmethod def ft_roy_root ( cls , N , y , criterion = [string] , can_cors = None , can_cor_eigvals = None , ) : [EOL] [docstring] [EOL] VALID_CRITERIA = ( [string] , [string] ) [EOL] [EOL] if criterion not in VALID_CRITERIA : [EOL] raise ValueError ( [string] . format ( VALID_CRITERIA ) ) [EOL] [EOL] if criterion == [string] : [EOL] if can_cor_eigvals is None : [EOL] if can_cors is None : [EOL] can_cors = cls . _calc_can_cors ( N = N , y = y ) [EOL] [EOL] can_cor_eigvals = cls . _can_cor_to_eigval ( can_cors ) [EOL] [EOL] values = can_cor_eigvals [EOL] [EOL] else : [EOL] if can_cors is None : [EOL] can_cors = cls . _calc_can_cors ( N = N , y = y ) [EOL] [EOL] values = np . square ( can_cors ) [EOL] [EOL] if values . size == [number] : [comment] [EOL] return np . nan [EOL] [EOL] return np . max ( values ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0
from typing import Optional , Union , Dict , Any , Sequence [EOL] import numpy [EOL] import builtins [EOL] import typing [EOL] [docstring] [EOL] import typing as t [EOL] import numpy as np [EOL] [EOL] [EOL] class MFEGeneral : [EOL] [docstring] [EOL] [EOL] @ classmethod def precompute_general_class ( cls , y = None , ** kwargs ) : [EOL] [docstring] [EOL] precomp_vals = { } [EOL] [EOL] if y is not None and not { [string] , [string] } . issubset ( kwargs ) : [EOL] classes , class_freqs = np . unique ( y , return_counts = True ) [EOL] [EOL] precomp_vals [ [string] ] = classes [EOL] precomp_vals [ [string] ] = class_freqs [EOL] [EOL] return precomp_vals [EOL] [EOL] @ classmethod def ft_attr_to_inst ( cls , X ) : [EOL] [docstring] [EOL] return X . shape [ [number] ] / X . shape [ [number] ] [EOL] [EOL] @ classmethod def ft_cat_to_num ( cls , X , cat_cols ) : [EOL] [docstring] [EOL] num_cat = len ( cat_cols ) [EOL] [EOL] if X . shape [ [number] ] == num_cat : [EOL] return np . nan [EOL] [EOL] return num_cat / ( X . shape [ [number] ] - num_cat ) [EOL] [EOL] @ classmethod def ft_freq_class ( cls , y , class_freqs = None , ) : [EOL] [docstring] [EOL] if class_freqs is None : [EOL] _ , class_freqs = np . unique ( y , return_counts = True ) [EOL] [EOL] return class_freqs / y . size [EOL] [EOL] @ classmethod def ft_inst_to_attr ( cls , X ) : [EOL] [docstring] [EOL] return X . shape [ [number] ] / X . shape [ [number] ] [EOL] [EOL] @ classmethod def ft_nr_attr ( cls , X ) : [EOL] [docstring] [EOL] return X . shape [ [number] ] [EOL] [EOL] @ classmethod def ft_nr_bin ( cls , X ) : [EOL] [docstring] [EOL] bin_cols = np . apply_along_axis ( func1d = lambda col : np . unique ( col ) . size == [number] , axis = [number] , arr = X ) [EOL] [EOL] return np . sum ( bin_cols ) [EOL] [EOL] @ classmethod def ft_nr_cat ( cls , cat_cols ) : [EOL] [docstring] [EOL] return len ( cat_cols ) [EOL] [EOL] @ classmethod def ft_nr_class ( cls , y , classes = None ) : [EOL] [docstring] [EOL] if classes is not None : [EOL] return classes . size [EOL] [EOL] return np . unique ( y ) . size [EOL] [EOL] @ classmethod def ft_nr_inst ( cls , X ) : [EOL] [docstring] [EOL] return X . shape [ [number] ] [EOL] [EOL] @ classmethod def ft_nr_num ( cls , X , cat_cols ) : [EOL] [docstring] [EOL] return X . shape [ [number] ] - len ( cat_cols ) [EOL] [EOL] @ classmethod def ft_num_to_cat ( cls , X , cat_cols ) : [EOL] [docstring] [EOL] if not cat_cols : [EOL] return np . nan [EOL] [EOL] num_cat = len ( cat_cols ) [EOL] [EOL] return ( X . shape [ [number] ] - num_cat ) / num_cat [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Tuple , Union , Literal , Type , Callable , Iterable , Any , Sequence [EOL] import numpy [EOL] import typing [EOL] import typing_extensions [EOL] import builtins [EOL] [docstring] [EOL] import typing as t [EOL] import collections [EOL] [EOL] import scipy . stats [EOL] import numpy as np [EOL] [EOL] TypeNumeric = t . Union [ int , float , np . number ] [EOL] [docstring] [EOL] [EOL] TypeValList = t . Sequence [ TypeNumeric ] [EOL] [docstring] [EOL] [EOL] [EOL] def _remove_nan ( values ) : [EOL] [docstring] [EOL] if not isinstance ( values , np . ndarray ) : [EOL] values = np . asarray ( values , dtype = float ) [EOL] [EOL] return values [ ~ np . isnan ( values ) ] [EOL] [EOL] [EOL] def sum_histogram ( values , bins = [number] , normalize = True ) : [EOL] [docstring] [EOL] if len ( values ) == [number] : [EOL] return np . full ( bins , fill_value = np . nan ) [EOL] [EOL] try : [EOL] freqs , _ = np . histogram ( values , bins = bins ) [EOL] [EOL] except ValueError : [EOL] return np . full ( bins , fill_value = np . nan ) [EOL] [EOL] if normalize : [EOL] freqs = freqs / sum ( freqs ) [EOL] [EOL] return freqs [EOL] [EOL] [EOL] def sum_quantiles ( values , package = [string] , numpy_interpolation = [string] , scipy_alphap = [number] , scipy_betap = [number] , ) : [EOL] [docstring] [EOL] if len ( values ) == [number] : [EOL] return np . full ( [number] , fill_value = np . nan ) [EOL] [EOL] valid_packages = ( [string] , [string] ) [EOL] [EOL] if package not in valid_packages : [EOL] raise ValueError ( [string] . format ( valid_packages , package ) ) [EOL] [EOL] if package == [string] : [EOL] return np . quantile ( values , ( [number] , [number] , [number] , [number] , [number] ) , interpolation = numpy_interpolation , ) [EOL] [EOL] return scipy . stats . mstats . mquantiles ( values , ( [number] , [number] , [number] , [number] , [number] ) , alphap = scipy_alphap , betap = scipy_betap , ) [EOL] [EOL] [EOL] def sum_nanquantiles ( values , numpy_interpolation = [string] ) : [EOL] [docstring] [EOL] if len ( values ) == [number] : [EOL] return np . full ( [number] , fill_value = np . nan ) [EOL] [EOL] return np . nanquantile ( values , ( [number] , [number] , [number] , [number] , [number] ) , interpolation = numpy_interpolation , ) [EOL] [EOL] [EOL] def sum_skewness ( values , method = [number] , bias = True ) : [EOL] [docstring] [EOL] if method not in ( [number] , [number] , [number] ) : [EOL] raise ValueError ( [string] . format ( method ) ) [EOL] [EOL] num_vals = len ( values ) [EOL] [EOL] if num_vals == [number] : [EOL] return np . nan [EOL] [EOL] skew_val = scipy . stats . skew ( values , bias = bias ) [EOL] [EOL] if method == [number] and num_vals != [number] : [EOL] skew_val *= ( num_vals * ( num_vals - [number] ) ) ** [number] / ( num_vals - [number] ) [EOL] [EOL] elif method == [number] : [EOL] skew_val *= ( ( num_vals - [number] ) / num_vals ) ** [number] [EOL] [EOL] return skew_val [EOL] [EOL] [EOL] def sum_kurtosis ( values , method = [number] , bias = True ) : [EOL] [docstring] [EOL] if method not in ( [number] , [number] , [number] ) : [EOL] raise ValueError ( [string] . format ( method ) ) [EOL] [EOL] num_vals = len ( values ) [EOL] [EOL] if num_vals == [number] : [EOL] return np . nan [EOL] [EOL] kurt_val = scipy . stats . kurtosis ( values , bias = bias ) [EOL] [EOL] if method == [number] and num_vals > [number] : [EOL] kurt_val = ( num_vals + [number] ) * kurt_val + [number] [EOL] kurt_val *= ( num_vals - [number] ) / ( ( num_vals - [number] ) * ( num_vals - [number] ) ) [EOL] [EOL] elif method == [number] : [EOL] kurt_val = ( kurt_val + [number] ) * ( [number] - [number] / num_vals ) ** [number] - [number] [EOL] [EOL] return kurt_val [EOL] [EOL] [EOL] def sum_nanstd ( values , ddof = [number] ) : [EOL] [docstring] [EOL] if len ( values ) <= ddof : [EOL] return np . nan [EOL] [EOL] return np . nanstd ( values , ddof = ddof ) [EOL] [EOL] [EOL] def sum_std ( values , ddof = [number] ) : [EOL] [docstring] [EOL] if len ( values ) <= ddof : [EOL] return np . nan [EOL] [EOL] return np . std ( values , ddof = ddof ) [EOL] [EOL] [EOL] def sum_nanvar ( values , ddof = [number] ) : [EOL] [docstring] [EOL] if len ( values ) <= ddof : [EOL] return np . nan [EOL] [EOL] return np . nanvar ( values , ddof = ddof ) [EOL] [EOL] [EOL] def sum_var ( values , ddof = [number] ) : [EOL] [docstring] [EOL] if len ( values ) <= ddof : [EOL] return np . nan [EOL] [EOL] return np . var ( values , ddof = ddof ) [EOL] [EOL] [EOL] def sum_nancount ( values ) : [EOL] [docstring] [EOL] return len ( values ) - np . count_nonzero ( np . isnan ( values ) ) [EOL] [EOL] [EOL] def sum_naniq_range ( values ) : [EOL] [docstring] [EOL] return scipy . stats . iqr ( values , nan_policy = [string] ) [EOL] [EOL] [EOL] def sum_nanptp ( values ) : [EOL] [docstring] [EOL] return np . nanmax ( values ) - np . nanmin ( values ) [EOL] [EOL] [EOL] def sum_nanhistogram ( values , bins = [number] , normalize = True ) : [EOL] [docstring] [EOL] if not isinstance ( values , np . ndarray ) : [EOL] values = np . asarray ( values , dtype = float ) [EOL] [EOL] return sum_histogram ( values = _remove_nan ( values = values ) , bins = bins , normalize = normalize ) [EOL] [EOL] [EOL] def sum_nankurtosis ( values , method = [number] , bias = True ) : [EOL] [docstring] [EOL] if not isinstance ( values , np . ndarray ) : [EOL] values = np . asarray ( values , dtype = float ) [EOL] [EOL] return sum_kurtosis ( values = _remove_nan ( values = values ) , method = method , bias = bias ) [EOL] [EOL] [EOL] def sum_nanskewness ( values , method = [number] , bias = True ) : [EOL] [docstring] [EOL] if not isinstance ( values , np . ndarray ) : [EOL] values = np . asarray ( values , dtype = float ) [EOL] [EOL] return sum_skewness ( values = _remove_nan ( values = values ) , method = method , bias = bias ) [EOL] [EOL] [EOL] def _apply_power_func ( values , p_func , p , ) : [EOL] [docstring] [EOL] if len ( values ) == [number] : [EOL] if np . isscalar ( p ) : [EOL] return np . nan [EOL] [EOL] return np . full ( len ( p ) , fill_value = np . nan ) [comment] [EOL] [EOL] if not isinstance ( values , np . ndarray ) or values . dtype != float : [EOL] values = np . asarray ( values , dtype = float ) [EOL] [EOL] if np . isscalar ( p ) : [EOL] return p_func ( values , p ) [comment] [EOL] [EOL] res = np . array ( [ p_func ( values , cur_p ) for cur_p in p ] ) [comment] [EOL] [EOL] return res [EOL] [EOL] [EOL] def sum_powersum ( values , p = [number] , ) : [EOL] [docstring] [EOL] [EOL] def ps_func ( arr , p ) : [EOL] if np . any ( np . isnan ( arr ) ) : [EOL] return np . nan [EOL] [EOL] return np . sum ( np . power ( arr , p ) ) [EOL] [EOL] return _apply_power_func ( values = values , p_func = ps_func , p = p ) [EOL] [EOL] [EOL] def sum_nanpowersum ( values , p = [number] , ) : [EOL] [docstring] [EOL] return sum_powersum ( _remove_nan ( values = values ) , p = p ) [EOL] [EOL] [EOL] def sum_pnorm ( values , p = [number] , ) : [EOL] [docstring] [EOL] [EOL] def pn_func ( arr , p ) : [EOL] if np . any ( np . isnan ( arr ) ) : [EOL] return np . nan [EOL] [EOL] return np . linalg . norm ( x = arr , ord = p ) if p >= [number] else np . nan [EOL] [EOL] return _apply_power_func ( values = values , p_func = pn_func , p = p ) [EOL] [EOL] [EOL] def sum_nanpnorm ( values , p = [number] , ) : [EOL] [docstring] [EOL] return sum_pnorm ( _remove_nan ( values = values ) , p = p ) [EOL] [EOL] [EOL] def sum_sum ( values ) : [EOL] [docstring] [EOL] if len ( values ) == [number] : [EOL] return np . nan [EOL] [EOL] return sum ( values ) [EOL] [EOL] [EOL] def sum_nansum ( values ) : [EOL] [docstring] [EOL] if len ( values ) == [number] or np . all ( np . isnan ( values ) ) : [EOL] return np . nan [EOL] [EOL] return np . nansum ( values ) [EOL] [EOL] [EOL] SUMMARY_METHODS = collections . OrderedDict ( ( ( [string] , np . mean ) , ( [string] , np . nanmean ) , ( [string] , sum_std ) , ( [string] , sum_nanstd ) , ( [string] , sum_var ) , ( [string] , sum_nanvar ) , ( [string] , len ) , ( [string] , sum_nancount ) , ( [string] , sum_histogram ) , ( [string] , sum_nanhistogram ) , ( [string] , scipy . stats . iqr ) , ( [string] , sum_naniq_range ) , ( [string] , sum_kurtosis ) , ( [string] , sum_nankurtosis ) , ( [string] , np . max ) , ( [string] , np . nanmax ) , ( [string] , np . median ) , ( [string] , np . nanmedian ) , ( [string] , np . min ) , ( [string] , np . nanmin ) , ( [string] , sum_quantiles ) , ( [string] , sum_nanquantiles ) , ( [string] , np . ptp ) , ( [string] , sum_nanptp ) , ( [string] , sum_skewness ) , ( [string] , sum_nanskewness ) , ( [string] , sum_sum ) , ( [string] , sum_nansum ) , ( [string] , sum_powersum ) , ( [string] , sum_pnorm ) , ( [string] , sum_nanpowersum ) , ( [string] , sum_nanpnorm ) , ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Optional , Any , Dict [EOL] import numpy [EOL] import typing [EOL] import builtins [EOL] [docstring] [EOL] [EOL] import typing as t [EOL] [EOL] import numpy as np [EOL] import scipy . spatial [EOL] import sklearn [EOL] [EOL] [EOL] class MFEConcept : [EOL] [docstring] [EOL] [EOL] @ classmethod def precompute_concept_dist ( cls , N , concept_dist_metric = [string] , ** kwargs ) : [EOL] [docstring] [EOL] precomp_vals = { } [EOL] [EOL] if N is not None and [string] not in kwargs : [EOL] [comment] [EOL] N = sklearn . preprocessing . MinMaxScaler ( feature_range = ( [number] , [number] ) ) . fit_transform ( N ) [EOL] [EOL] [comment] [EOL] concept_distances = scipy . spatial . distance . cdist ( N , N , metric = concept_dist_metric ) [EOL] [EOL] precomp_vals [ [string] ] = concept_distances [EOL] [EOL] return precomp_vals [EOL] [EOL] @ classmethod def ft_conceptvar ( cls , N , y , conceptvar_alpha = [number] , concept_dist_metric = [string] , concept_minimum = [number] , concept_distances = None , ) : [EOL] [docstring] [EOL] if concept_distances is None : [EOL] sub_dic = cls . precompute_concept_dist ( N , concept_dist_metric ) [EOL] concept_distances = sub_dic [ [string] ] [EOL] [EOL] n_col = N . shape [ [number] ] [EOL] [EOL] div = np . sqrt ( n_col ) - concept_distances [EOL] div [ div <= [number] ] = concept_minimum [comment] [EOL] weights = np . power ( [number] , - conceptvar_alpha * ( concept_distances / div ) ) [EOL] np . fill_diagonal ( weights , [number] ) [EOL] [EOL] rep_class_matrix = np . repeat ( [ y ] , y . shape [ [number] ] , axis = [number] ) [EOL] [comment] [EOL] class_diff = np . not_equal ( rep_class_matrix . T , rep_class_matrix ) . astype ( int ) [EOL] [EOL] conceptvar_by_example = np . sum ( weights * class_diff , axis = [number] ) / np . sum ( weights , axis = [number] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] return conceptvar_by_example [EOL] [EOL] @ classmethod def ft_wg_dist ( cls , N , wg_dist_alpha = [number] , concept_dist_metric = [string] , concept_minimum = [number] , concept_distances = None , ) : [EOL] [docstring] [EOL] if concept_distances is None : [EOL] sub_dic = cls . precompute_concept_dist ( N , concept_dist_metric ) [EOL] concept_distances = sub_dic [ [string] ] [EOL] [EOL] n_col = N . shape [ [number] ] [EOL] [EOL] div = np . sqrt ( n_col ) - concept_distances [EOL] div [ div <= [number] ] = concept_minimum [comment] [EOL] weights = np . power ( [number] , - wg_dist_alpha * ( concept_distances / div ) ) [EOL] np . fill_diagonal ( weights , [number] ) [EOL] [EOL] wg_dist_example = np . sum ( weights * concept_distances , axis = [number] ) / np . sum ( weights , axis = [number] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] return wg_dist_example [EOL] [EOL] @ classmethod def ft_impconceptvar ( cls , N , y , impconceptvar_alpha = [number] , concept_dist_metric = [string] , concept_distances = None , ) : [EOL] [docstring] [EOL] if concept_distances is None : [EOL] sub_dic = cls . precompute_concept_dist ( N , concept_dist_metric ) [EOL] concept_distances = sub_dic [ [string] ] [EOL] [EOL] radius = np . ceil ( concept_distances ) . astype ( int ) [EOL] radius [ radius == [number] ] = [number] [EOL] [EOL] weights = np . power ( [number] , - impconceptvar_alpha * radius ) [EOL] np . fill_diagonal ( weights , [number] ) [EOL] [EOL] rep_class_matrix = np . repeat ( [ y ] , y . shape [ [number] ] , axis = [number] ) [EOL] [comment] [EOL] class_diff = np . not_equal ( rep_class_matrix . T , rep_class_matrix ) . astype ( int ) [EOL] [EOL] impconceptvar_by_example = np . sum ( weights * class_diff , axis = [number] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] return impconceptvar_by_example [EOL] [EOL] @ classmethod def ft_cohesiveness ( cls , N , cohesiveness_alpha = [number] , concept_dist_metric = [string] , concept_distances = None , ) : [EOL] [docstring] [EOL] if concept_distances is None : [EOL] sub_dic = cls . precompute_concept_dist ( N , concept_dist_metric ) [EOL] concept_distances = sub_dic [ [string] ] [EOL] [EOL] radius = np . ceil ( concept_distances ) . astype ( int ) [EOL] radius [ radius == [number] ] = [number] [EOL] [EOL] weights = np . power ( [number] , - cohesiveness_alpha * radius ) [EOL] np . fill_diagonal ( weights , [number] ) [EOL] [EOL] cohesiveness_by_example = np . sum ( weights , axis = [number] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] return cohesiveness_by_example [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0