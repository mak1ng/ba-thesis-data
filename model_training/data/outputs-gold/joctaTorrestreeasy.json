from typing import List [EOL] import typing [EOL] from unittest . mock import call , patch [EOL] [EOL] from treeasy . entropy import ( attribute_information_gain , collection_entropy , entropy , target_collection_information_gain , ) [EOL] [EOL] [EOL] def test_entropy ( snapshot ) : [EOL] snapshot . assert_match ( entropy ( [ ( [number] / [number] ) , ( [number] / [number] ) ] ) ) [EOL] snapshot . assert_match ( entropy ( [ [number] , [number] , [number] , [number] , [number] ] ) ) [EOL] [EOL] [EOL] def test_collection_entropy ( snapshot ) : [EOL] collection_entropy_one = collection_entropy ( [ [number] , [number] ] ) [EOL] collection_entropy_two = collection_entropy ( [ [number] , [number] , [number] ] ) [EOL] [EOL] entropy_one = entropy ( [ ( [number] / [number] ) , ( [number] / [number] ) ] ) [EOL] entropy_two = entropy ( [ ( [number] / [number] ) , ( [number] / [number] ) , ( [number] / [number] ) ] ) [EOL] [EOL] assert collection_entropy_one == entropy_one [EOL] assert collection_entropy_two == entropy_two [EOL] [EOL] snapshot . assert_match ( collection_entropy_one ) [EOL] snapshot . assert_match ( collection_entropy_two ) [EOL] [EOL] [EOL] @ patch ( [string] ) def test_collection_entropy_call ( entropy , snapshot ) : [EOL] collection_entropy ( [ [number] , [number] ] ) [EOL] collection_entropy ( [ [number] , [number] , [number] ] ) [EOL] [EOL] entropy . assert_has_calls ( [ call ( [ ( [number] / [number] ) , ( [number] / [number] ) ] ) , call ( [ ( [number] / [number] ) , ( [number] / [number] ) , ( [number] / [number] ) ] ) ] ) [EOL] [EOL] [EOL] def test_attribute_information_gain ( snapshot ) : [EOL] snapshot . assert_match ( attribute_information_gain ( [number] , [number] , [ [ [number] , [number] ] , [ [number] , [number] ] ] ) ) [EOL] snapshot . assert_match ( attribute_information_gain ( [number] , [number] , [ [ [number] , [number] ] , [ [number] , [number] ] ] ) ) [EOL] [EOL] [EOL] @ patch ( [string] ) def test_target_collection_information_gain_call ( attribute_information_gain ) : [EOL] attribute_subsets = [ [ [number] , [number] ] , [ [number] , [number] ] ] [EOL] [EOL] target_collection_information_gain ( [ [number] , [number] ] , attribute_subsets ) [EOL] [EOL] attribute_information_gain . assert_called_once_with ( [number] , [number] , attribute_subsets ) [EOL] [EOL] [EOL] def test_target_collection_information_gain ( snapshot ) : [EOL] attribute_subsets = [ [ [number] , [number] ] , [ [number] , [number] ] ] [EOL] [EOL] collection_result = target_collection_information_gain ( [ [number] , [number] ] , attribute_subsets ) [EOL] [EOL] direct_result = attribute_information_gain ( [number] , [number] , attribute_subsets ) [EOL] [EOL] assert collection_result == direct_result [EOL] snapshot . assert_match ( collection_result ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import List , Any [EOL] import typing [EOL] import pandas as pd [EOL] [EOL] from treeasy . trees import tree_id3 [EOL] [EOL] [EOL] def test_tree_id3 ( snapshot ) : [EOL] training_data = pd . read_csv ( [string] ) [EOL] training_data . drop ( [ [string] ] , axis = [number] , inplace = True ) [EOL] [EOL] attributes = list ( training_data . columns ) [EOL] target = [string] [EOL] [EOL] expected_tree = tree_id3 ( training_data , target , attributes ) [EOL] snapshot . assert_match ( str ( expected_tree ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , List , Any [EOL] import typing [EOL] import pandas as pd [EOL] [EOL] from treeasy . classify import classify [EOL] from treeasy . trees import tree_id3 [EOL] [EOL] [EOL] def test_classify_tree_id3 ( ) : [EOL] training_data = pd . read_csv ( [string] ) [EOL] training_data . drop ( [ [string] ] , axis = [number] , inplace = True ) [EOL] [EOL] attributes = list ( training_data . columns ) [EOL] target = [string] [EOL] [EOL] tree = tree_id3 ( training_data , target , attributes ) [EOL] [EOL] instance_no = { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , } [EOL] [EOL] instance_yes = { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , } [EOL] [EOL] result_no = classify ( tree , instance_no ) [EOL] result_yes = classify ( tree , instance_yes ) [EOL] [EOL] assert result_no == [string] [EOL] assert result_yes == [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
[comment] [EOL] [comment] [EOL] from typing import Any [EOL] import typing [EOL] from __future__ import unicode_literals [EOL] [EOL] from snapshottest import Snapshot [EOL] [EOL] [EOL] snapshots = Snapshot ( ) [EOL] [EOL] snapshots [ [string] ] = [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0
	0
[comment] [EOL] [comment] [EOL] from typing import Any [EOL] import typing [EOL] from __future__ import unicode_literals [EOL] [EOL] from snapshottest import Snapshot [EOL] [EOL] [EOL] snapshots = Snapshot ( ) [EOL] [EOL] snapshots [ [string] ] = [number] [EOL] [EOL] snapshots [ [string] ] = [number] [EOL] [EOL] snapshots [ [string] ] = [number] [EOL] [EOL] snapshots [ [string] ] = [number] [EOL] [EOL] snapshots [ [string] ] = [number] [EOL] [EOL] snapshots [ [string] ] = [number] [EOL] [EOL] snapshots [ [string] ] = [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0
from typing import List [EOL] import builtins [EOL] import typing [EOL] from math import log2 [EOL] from typing import List [EOL] [EOL] [EOL] def collection_entropy ( collection ) : [EOL] [docstring] [EOL] [EOL] collection_size = sum ( collection ) [EOL] return entropy ( [ ( target / collection_size ) for target in collection ] ) [EOL] [EOL] [EOL] def entropy ( probabilities , log = log2 ) : [EOL] [docstring] [EOL] [EOL] if not probabilities : [EOL] return [number] [EOL] [EOL] entropy = [number] [EOL] [EOL] for p in probabilities : [EOL] term = p * log ( p ) [EOL] entropy -= term [EOL] [EOL] return entropy [EOL] [EOL] [EOL] def target_collection_information_gain ( target_collection , attribute_subsets ) : [EOL] target_instance_size = sum ( target_collection ) [EOL] target_entropy = collection_entropy ( target_collection ) [EOL] [EOL] return attribute_information_gain ( target_entropy , target_instance_size , attribute_subsets ) [EOL] [EOL] [EOL] def attribute_information_gain ( target_entropy , target_instance_size , attribute_subsets ) : [EOL] attribute_entropy = [number] [EOL] [EOL] for subset in attribute_subsets : [EOL] subset_weigth = sum ( subset ) / target_instance_size [EOL] attribute_entropy += subset_weigth * collection_entropy ( subset ) [EOL] [EOL] gain = target_entropy - attribute_entropy [EOL] return gain [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , List , Any [EOL] import treeasy [EOL] import typing [EOL] import pandas as pd [EOL] [EOL] from treeasy . entropy import attribute_information_gain , collection_entropy [EOL] from treeasy . types import Tree [EOL] [EOL] [EOL] def tree_id3 ( examples , target_attribute , attributes ) : [EOL] [docstring] [EOL] [comment] [EOL] if len ( attributes ) == [number] : [EOL] target_attribute_mode = get_column_values_count ( examples [ target_attribute ] ) . idxmax ( ) [EOL] return Tree ( target_attribute_mode ) [EOL] [EOL] [comment] [EOL] target_attribute_values = list ( get_column_values_count ( examples [ target_attribute ] ) ) [EOL] [EOL] [comment] [EOL] target_attribute_entropy = collection_entropy ( target_attribute_values ) [EOL] [EOL] if target_attribute in attributes : [EOL] attributes . remove ( target_attribute ) [EOL] [EOL] [comment] [EOL] if len ( target_attribute_values ) == [number] : [EOL] return Tree ( get_column_values_count ( examples [ target_attribute ] ) . idxmax ( ) ) [EOL] [EOL] [comment] [EOL] target_instance_size = sum ( target_attribute_values ) [EOL] [EOL] [comment] [EOL] max_information_gain_attribute = get_max_information_gain_attribute ( examples , attributes , target_attribute , target_attribute_entropy , target_instance_size , ) [EOL] [EOL] [comment] [EOL] root = Tree ( max_information_gain_attribute ) [EOL] [EOL] [comment] [EOL] children_branches = [ ] [EOL] for value in examples [ max_information_gain_attribute ] . unique ( ) : [EOL] examples_subset = get_attribute_value_dataframe ( examples , max_information_gain_attribute , value ) [EOL] [EOL] if max_information_gain_attribute in attributes : [EOL] attributes . remove ( max_information_gain_attribute ) [EOL] children_branches . append ( ( value , tree_id3 ( examples_subset , target_attribute , attributes ) ) ) [EOL] [EOL] root . set_children ( children_branches ) [EOL] return root [EOL] [EOL] [EOL] def get_max_information_gain_attribute ( examples , attributes , target_attribute , target_attribute_entropy , target_instance_size , ) : [EOL] attribute_gains = get_attribute_gains ( examples , attributes , target_attribute , target_attribute_entropy , target_instance_size , ) [EOL] return max ( attribute_gains , key = attribute_gains . get ) [EOL] [EOL] [EOL] def get_attribute_gains ( examples , attributes , target_attribute , target_attribute_entropy , target_instance_size , ) : [EOL] attribute_gains = { } [EOL] for attribute in attributes : [EOL] attribute_subset_values = get_attribute_subset_values ( examples , attribute , target_attribute ) [EOL] information_gain = attribute_information_gain ( target_attribute_entropy , target_instance_size , attribute_subset_values ) [EOL] [EOL] attribute_gains . update ( { attribute : information_gain } ) [EOL] [EOL] return attribute_gains [EOL] [EOL] [EOL] def get_attribute_subset_values ( examples , attribute , target_attribute ) : [EOL] attribute_values_subset = [ ] [EOL] for value in examples [ attribute ] . unique ( ) : [EOL] value_subset_df = get_attribute_value_dataframe ( examples , attribute , value ) [EOL] attribute_values_subset . append ( get_column_values_count ( value_subset_df [ target_attribute ] ) ) [EOL] [EOL] return attribute_values_subset [EOL] [EOL] [EOL] def get_attribute_value_dataframe ( original_df , column , value ) : [EOL] return original_df . loc [ original_df [ column ] == value ] [EOL] [EOL] [EOL] def get_column_values_count ( column ) : [EOL] return column . value_counts ( ) [EOL] [EOL] [EOL] def test_tree_id3_tennis ( ) : [EOL] training_data = pd . read_csv ( [string] ) [EOL] training_data . drop ( [ [string] ] , axis = [number] , inplace = True ) [EOL] [EOL] attributes = list ( training_data . columns ) [EOL] target = [string] [EOL] [EOL] t = tree_id3 ( training_data , target , attributes ) [EOL] with open ( [string] , [string] ) as result : [EOL] result . write ( str ( t ) ) [EOL] [EOL] [EOL] def test_tree_id3_cars ( ) : [EOL] training_data = pd . read_csv ( [string] ) [EOL] training_data . drop ( [ [string] ] , axis = [number] , inplace = True ) [EOL] [EOL] attributes = list ( training_data . columns ) [EOL] target = [string] [EOL] [EOL] t = tree_id3 ( training_data , target , attributes ) [EOL] with open ( [string] , [string] ) as result : [EOL] result . write ( str ( t ) ) [EOL] [EOL] [EOL] def test_tree_id3_iris ( ) : [EOL] training_data = pd . read_csv ( [string] ) [EOL] [EOL] attributes = list ( training_data . columns ) [EOL] target = [string] [EOL] [EOL] t = tree_id3 ( training_data , target , attributes ) [EOL] with open ( [string] , [string] ) as result : [EOL] result . write ( str ( t ) ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] test_tree_id3_tennis ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict [EOL] import typing [EOL] import json [EOL] [EOL] [EOL] class Tree : [EOL] def __init__ ( self , root_name ) : [EOL] self . root = root_name [EOL] self . children = [ ] [EOL] [EOL] def set_children ( self , children ) : [EOL] self . children = children [EOL] [EOL] def get_tree_dict ( self ) : [EOL] tree_dict = { [string] : self . root } [EOL] [EOL] if len ( self . children ) > [number] : [EOL] tree_dict . update ( { [string] : { v : cd . get_tree_dict ( ) for v , cd in self . children } } ) [EOL] [EOL] return tree_dict [EOL] [EOL] def __repr__ ( self ) : [EOL] [EOL] return json . dumps ( self . get_tree_dict ( ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,unknown]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,unknown]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,unknown]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , Any [EOL] import treeasy [EOL] import typing [EOL] from typing import Dict [EOL] [EOL] from treeasy . types import Tree [EOL] [EOL] [EOL] def classify ( tree , instance ) : [EOL] model = tree . get_tree_dict ( ) [EOL] [EOL] while True : [EOL] tree_node = model [ [string] ] [EOL] [EOL] if [string] in model . keys ( ) : [EOL] instance_value = instance [ tree_node ] [EOL] model = model [ [string] ] [ instance_value ] [EOL] else : [EOL] return tree_node [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0