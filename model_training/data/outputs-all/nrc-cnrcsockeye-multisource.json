[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from sockeye_contrib . sacrebleu . sacrebleu import raw_corpus_bleu , compute_bleu , corpus_chrf , CHRF_ORDER , CHRF_BETA , sentence_bleu , sentence_chrf	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
[comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import List [EOL] import typing [EOL] import builtins [EOL] import glob [EOL] import os [EOL] import shutil [EOL] import subprocess [EOL] import sys [EOL] import tempfile [EOL] from typing import List [EOL] [EOL] [comment] [EOL] try : [EOL] import sockeye_contrib . autopilot . autopilot as autopilot [EOL] except ImportError : [EOL] SOCKEYE_ROOT = os . path . dirname ( os . path . dirname ( os . path . dirname ( os . path . abspath ( __file__ ) ) ) ) [EOL] PYTHONPATH = [string] [EOL] if os . environ . get ( PYTHONPATH , None ) : [EOL] os . environ [ PYTHONPATH ] += os . pathsep + SOCKEYE_ROOT [EOL] else : [EOL] os . environ [ PYTHONPATH ] = SOCKEYE_ROOT [EOL] sys . path . append ( SOCKEYE_ROOT ) [EOL] import sockeye_contrib . autopilot . autopilot as autopilot [EOL] [EOL] [EOL] [comment] [EOL] WNMT_TASK = [string] [EOL] DATA_ONLY_TASK = [string] [EOL] WMT_TASK = [string] [EOL] WMT_SRC = [string] [EOL] WMT_TRG = [string] [EOL] WMT_BPE = [number] [EOL] PREFIX_ZERO = [string] [EOL] [EOL] [EOL] def run_test ( command , workspace ) : [EOL] [docstring] [EOL] success = False [EOL] try : [EOL] subprocess . check_call ( command + [ [string] . format ( workspace ) ] ) [EOL] success = True [EOL] except subprocess . CalledProcessError : [EOL] pass [EOL] if not success : [EOL] print ( [string] , file = sys . stderr ) [EOL] print ( [string] , file = sys . stderr ) [EOL] log_dir = os . path . join ( workspace , autopilot . DIR_LOGS ) [EOL] last_log = sorted ( os . listdir ( log_dir ) , key = lambda fname : os . stat ( os . path . join ( log_dir , fname ) ) . st_mtime ) [ - [number] ] [EOL] with open ( os . path . join ( log_dir , last_log ) , [string] ) as log : [EOL] for line in log : [EOL] print ( line , file = sys . stderr , end = [string] ) [EOL] print ( [string] , file = sys . stderr ) [EOL] raise RuntimeError ( [string] % [string] . join ( command ) ) [EOL] [comment] [EOL] [comment] [EOL] model_dirs = glob . glob ( os . path . join ( workspace , autopilot . DIR_SYSTEMS , [string] , [string] ) ) [EOL] for model_dir in model_dirs : [EOL] shutil . rmtree ( model_dir ) [EOL] [EOL] [EOL] def main ( ) : [EOL] [docstring] [EOL] with tempfile . TemporaryDirectory ( prefix = [string] ) as tmp_dir : [EOL] work_dir = os . path . join ( tmp_dir , [string] ) [EOL] [EOL] [comment] [EOL] command = [ sys . executable , [string] , [string] , [string] . format ( WMT_TASK ) , [string] , [string] , [string] ] [EOL] run_test ( command , workspace = work_dir ) [EOL] [EOL] [comment] [EOL] command = [ sys . executable , [string] , [string] , [string] . format ( WMT_TASK ) , [string] , [string] , [string] , [string] ] [EOL] run_test ( command , workspace = work_dir ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] command = [ sys . executable , [string] , [string] , [string] . format ( DATA_ONLY_TASK ) , [string] , [string] , [string] ] [EOL] run_test ( command , workspace = work_dir ) [EOL] [EOL] [comment] [EOL] command = [ sys . executable , [string] , [string] , [string] , [string] , os . path . join ( work_dir , autopilot . DIR_SYSTEMS , WMT_TASK + autopilot . SUFFIX_TEST , autopilot . DIR_DATA , autopilot . DIR_RAW , autopilot . PREFIX_TRAIN + autopilot . SUFFIX_SRC_GZ ) , os . path . join ( work_dir , autopilot . DIR_SYSTEMS , WMT_TASK + autopilot . SUFFIX_TEST , autopilot . DIR_DATA , autopilot . DIR_RAW , autopilot . PREFIX_TRAIN + autopilot . SUFFIX_TRG_GZ ) , [string] , os . path . join ( work_dir , autopilot . DIR_SYSTEMS , WMT_TASK + autopilot . SUFFIX_TEST , autopilot . DIR_DATA , autopilot . DIR_RAW , autopilot . PREFIX_DEV + autopilot . SUFFIX_SRC_GZ ) , os . path . join ( work_dir , autopilot . DIR_SYSTEMS , WMT_TASK + autopilot . SUFFIX_TEST , autopilot . DIR_DATA , autopilot . DIR_RAW , autopilot . PREFIX_DEV + autopilot . SUFFIX_TRG_GZ ) , [string] , os . path . join ( work_dir , autopilot . DIR_SYSTEMS , WMT_TASK + autopilot . SUFFIX_TEST , autopilot . DIR_DATA , autopilot . DIR_RAW , autopilot . PREFIX_TEST + PREFIX_ZERO + autopilot . SUFFIX_SRC_GZ ) , os . path . join ( work_dir , autopilot . DIR_SYSTEMS , WMT_TASK + autopilot . SUFFIX_TEST , autopilot . DIR_DATA , autopilot . DIR_RAW , autopilot . PREFIX_TEST + PREFIX_ZERO + autopilot . SUFFIX_TRG_GZ ) , [string] , WMT_SRC , WMT_TRG , [string] . format ( WMT_BPE ) , [string] , [string] , [string] ] [EOL] run_test ( command , workspace = work_dir ) [EOL] [EOL] [comment] [EOL] command = [ sys . executable , [string] , [string] , [string] , [string] , os . path . join ( work_dir , autopilot . DIR_SYSTEMS , WMT_TASK + autopilot . SUFFIX_TEST , autopilot . DIR_DATA , autopilot . DIR_TOK , autopilot . PREFIX_TRAIN + autopilot . SUFFIX_SRC_GZ ) , os . path . join ( work_dir , autopilot . DIR_SYSTEMS , WMT_TASK + autopilot . SUFFIX_TEST , autopilot . DIR_DATA , autopilot . DIR_TOK , autopilot . PREFIX_TRAIN + autopilot . SUFFIX_TRG_GZ ) , [string] , os . path . join ( work_dir , autopilot . DIR_SYSTEMS , WMT_TASK + autopilot . SUFFIX_TEST , autopilot . DIR_DATA , autopilot . DIR_TOK , autopilot . PREFIX_DEV + autopilot . SUFFIX_SRC_GZ ) , os . path . join ( work_dir , autopilot . DIR_SYSTEMS , WMT_TASK + autopilot . SUFFIX_TEST , autopilot . DIR_DATA , autopilot . DIR_TOK , autopilot . PREFIX_DEV + autopilot . SUFFIX_TRG_GZ ) , [string] , os . path . join ( work_dir , autopilot . DIR_SYSTEMS , WMT_TASK + autopilot . SUFFIX_TEST , autopilot . DIR_DATA , autopilot . DIR_TOK , autopilot . PREFIX_TEST + PREFIX_ZERO + autopilot . SUFFIX_SRC_GZ ) , os . path . join ( work_dir , autopilot . DIR_SYSTEMS , WMT_TASK + autopilot . SUFFIX_TEST , autopilot . DIR_DATA , autopilot . DIR_TOK , autopilot . PREFIX_TEST + PREFIX_ZERO + autopilot . SUFFIX_TRG_GZ ) , [string] , [string] . format ( WMT_BPE ) , [string] , [string] , [string] ] [EOL] run_test ( command , workspace = work_dir ) [EOL] [EOL] [comment] [EOL] command = [ sys . executable , [string] , [string] , [string] , [string] , os . path . join ( work_dir , autopilot . DIR_SYSTEMS , WMT_TASK + autopilot . SUFFIX_TEST , autopilot . DIR_DATA , autopilot . DIR_BPE , autopilot . PREFIX_TRAIN + autopilot . SUFFIX_SRC_GZ ) , os . path . join ( work_dir , autopilot . DIR_SYSTEMS , WMT_TASK + autopilot . SUFFIX_TEST , autopilot . DIR_DATA , autopilot . DIR_BPE , autopilot . PREFIX_TRAIN + autopilot . SUFFIX_TRG_GZ ) , [string] , os . path . join ( work_dir , autopilot . DIR_SYSTEMS , WMT_TASK + autopilot . SUFFIX_TEST , autopilot . DIR_DATA , autopilot . DIR_BPE , autopilot . PREFIX_DEV + autopilot . SUFFIX_SRC_GZ ) , os . path . join ( work_dir , autopilot . DIR_SYSTEMS , WMT_TASK + autopilot . SUFFIX_TEST , autopilot . DIR_DATA , autopilot . DIR_BPE , autopilot . PREFIX_DEV + autopilot . SUFFIX_TRG_GZ ) , [string] , os . path . join ( work_dir , autopilot . DIR_SYSTEMS , WMT_TASK + autopilot . SUFFIX_TEST , autopilot . DIR_DATA , autopilot . DIR_BPE , autopilot . PREFIX_TEST + PREFIX_ZERO + autopilot . SUFFIX_SRC_GZ ) , os . path . join ( work_dir , autopilot . DIR_SYSTEMS , WMT_TASK + autopilot . SUFFIX_TEST , autopilot . DIR_DATA , autopilot . DIR_BPE , autopilot . PREFIX_TEST + PREFIX_ZERO + autopilot . SUFFIX_TRG_GZ ) , [string] , [string] , [string] , [string] ] [EOL] run_test ( command , workspace = work_dir ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.int$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , KeysView [EOL] import multiprocessing [EOL] import logging [EOL] import typing [EOL] [docstring] [EOL] [EOL] [EOL] import multiprocessing as mp [EOL] import logging [EOL] import os [EOL] import sys [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def __dummy_function_to_start_semaphore_tracker ( ) : [EOL] logger . info ( [string] ) [EOL] [EOL] [EOL] __context = None [EOL] [EOL] [EOL] def initialize ( ) : [EOL] global __context [EOL] [EOL] if __context is not None : [EOL] [comment] [EOL] return [EOL] [EOL] if not __context : [EOL] if os . name == [string] : [EOL] [comment] [EOL] __context = mp . get_context ( ) [EOL] else : [EOL] try : [EOL] __context = mp . get_context ( [string] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] all_imported_modules = sys . modules . keys ( ) [EOL] [EOL] assert [string] not in all_imported_modules , ( [string] [string] ) [EOL] [EOL] p = mp . Process ( target = __dummy_function_to_start_semaphore_tracker ) [EOL] p . start ( ) [EOL] p . join ( ) [EOL] except ValueError : [EOL] logger . warning ( [string] ) [EOL] __context = mp . get_context ( ) [EOL] [EOL] [EOL] def get_context ( ) : [EOL] assert __context is not None , ( [string] [string] ) [EOL] return __context [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 $None$ 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] __version__ = [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import sockeye . multiprocessing_utils as mp [EOL] mp . initialize ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List [EOL] import typing [EOL] import pytest [EOL] import mxnet as mx [EOL] [EOL] import sockeye . checkpoint_decoder [EOL] [EOL] [EOL] source_0_0 = [ [string] % i for i in range ( [number] ) ] [EOL] source_0_1 = [ [string] % i for i in range ( [number] ) ] [EOL] source_0_2 = [ [string] % i for i in range ( [number] ) ] [EOL] [EOL] source_1_0 = [ [string] % i for i in range ( [number] ) ] [EOL] source_1_1 = [ [string] % i for i in range ( [number] ) ] [EOL] source_1_2 = [ [string] % i for i in range ( [number] ) ] [EOL] [EOL] target = [ [string] % i for i in range ( [number] ) ] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( ( ( source_0_0 , ) , ) , target , [number] , [number] , ( [ [ [ [string] , [string] , [string] ] , ] , ] , [ [string] , [string] , [string] ] ) ) , ( ( ( source_0_0 , source_0_1 , source_0_2 ) , ) , target , [number] , [number] , ( [ [ [ [string] , [string] , [string] ] , [ [string] , [string] , [string] ] , [ [string] , [string] , [string] ] , ] , ] , [ [string] , [string] , [string] ] ) ) , ( ( ( source_0_0 , ) , ( source_1_0 , ) ) , target , [number] , [number] , ( [ [ [ [string] , [string] , [string] ] , ] , [ [ [string] , [string] , [string] ] , ] , ] , [ [string] , [string] , [string] ] ) ) , ( ( ( source_0_0 , source_0_1 , source_0_2 ) , ( source_1_0 , source_1_1 , source_1_2 ) ) , target , [number] , [number] , ( [ [ [ [string] , [string] , [string] ] , [ [string] , [string] , [string] ] , [ [string] , [string] , [string] ] , ] , [ [ [string] , [string] , [string] ] , [ [string] , [string] , [string] ] , [ [string] , [string] , [string] ] , ] , ] , [ [string] , [string] , [string] ] ) ) , ] ) def test_convolutional_embedding_encoder ( multisource , target , sample_size , seed , expected ) : [EOL] [docstring] [EOL] sampled = sockeye . checkpoint_decoder . parallel_subsample ( multisource , target , sample_size , seed ) [EOL] assert sampled == expected [EOL] [EOL] [EOL] [EOL] @ pytest . fixture ( scope = [string] ) def multisource_with_factors ( tmp_path_factory ) : [EOL] [docstring] [EOL] data_dir = tmp_path_factory . mktemp ( [string] ) [EOL] target = data_dir / [string] [EOL] with target . open ( mode = [string] ) as f : [EOL] for s in [ [string] % i for i in range ( [number] ) ] : [EOL] print ( s , file = f ) [EOL] multisource = [ ] [EOL] for s in range ( [number] ) : [EOL] factors = [ ] [EOL] for f in range ( [number] ) : [EOL] name = [string] % ( s , f ) [EOL] factor = data_dir / name [EOL] factors . append ( str ( factor ) ) [EOL] with factor . open ( mode = [string] ) as f : [EOL] for i in range ( [number] ) : [EOL] print ( name + [string] % i , file = f ) [EOL] multisource . append ( factors ) [EOL] model = tmp_path_factory . mktemp ( [string] ) [EOL] return model , multisource , str ( target ) [EOL] [EOL] [EOL] [EOL] def test_simple_CheckpointDecoder ( multisource_with_factors ) : [EOL] [docstring] [EOL] model , multisource , target = multisource_with_factors [EOL] cd = sockeye . checkpoint_decoder . CheckpointDecoder ( context = mx . context , multisource = multisource , references = target , model = [string] ) [EOL] [comment] [EOL] assert len ( cd . target_sentences ) == [number] [EOL] assert len ( cd . inputs_sentences ) == [number] [EOL] [comment] [EOL] assert len ( cd . inputs_sentences [ [number] ] ) == [number] [EOL] [comment] [EOL] assert len ( cd . inputs_sentences [ [number] ] [ [number] ] ) == [number] [EOL] assert len ( cd . inputs_sentences [ [number] ] [ [number] ] ) == [number] [EOL] [comment] [EOL] assert cd . inputs_sentences [ [number] ] [ [number] ] [ [number] ] . strip ( ) == [string] [EOL] assert cd . inputs_sentences [ [number] ] [ [number] ] [ [number] ] . strip ( ) == [string] [EOL] assert cd . inputs_sentences [ [number] ] [ [number] ] [ [number] ] . strip ( ) == [string] [EOL] [comment] [EOL] assert cd . inputs_sentences [ [number] ] [ [number] ] [ [number] ] . strip ( ) == [string] [EOL] assert cd . inputs_sentences [ [number] ] [ [number] ] [ [number] ] . strip ( ) == [string] [EOL] assert cd . inputs_sentences [ [number] ] [ [number] ] [ [number] ] . strip ( ) == [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 $typing.List[builtins.str]$ 0 $typing.List[builtins.str]$ 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 $typing.List[builtins.str]$ 0 $typing.List[builtins.str]$ 0 0 0 $typing.List[builtins.str]$ 0 $typing.List[builtins.str]$ 0 $typing.List[builtins.str]$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import typing [EOL] import mxnet as mx [EOL] import numpy as np [EOL] [EOL] import sockeye . constants as C [EOL] import sockeye . transformer [EOL] [EOL] [EOL] def test_auto_regressive_bias_op ( ) : [EOL] bias = mx . nd . Custom ( op_type = [string] , length = [number] ) [EOL] [EOL] assert bias . dtype == np . float32 [EOL] [EOL] expected = np . array ( [ [ [number] , - [number] ] , [ [number] , [number] ] ] ) . reshape ( ( [number] , [number] , [number] ) ) [EOL] np . testing . assert_array_equal ( bias . asnumpy ( ) , expected ) [EOL] [EOL] [EOL] def test_auto_regressive_bias_op_float16 ( ) : [EOL] bias = mx . nd . Custom ( op_type = [string] , length = [number] , dtype = C . DTYPE_FP16 ) [EOL] [EOL] assert bias . dtype == np . float16 [EOL] [EOL] expected = np . array ( [ [ [number] , - [number] ] , [ [number] , [number] ] ] ) . reshape ( ( [number] , [number] , [number] ) ) [EOL] np . testing . assert_array_equal ( bias . asnumpy ( ) , expected ) [EOL] [EOL] [EOL] def test_auto_regressive_bias_sym ( ) : [EOL] bias = mx . sym . Custom ( op_type = [string] , length = [number] ) [EOL] [EOL] arg_types , out_types , aux_types = bias . infer_type ( ) [EOL] assert out_types [ [number] ] == np . float32 [EOL] [EOL] out = bias . eval ( ) [ [number] ] [EOL] [EOL] assert out . dtype == np . float32 [EOL] [EOL] expected = np . array ( [ [ [number] , - [number] ] , [ [number] , [number] ] ] ) . reshape ( ( [number] , [number] , [number] ) ) [EOL] np . testing . assert_array_equal ( out . asnumpy ( ) , expected ) [EOL] [EOL] [EOL] def test_auto_regressive_bias_sym_float16 ( ) : [EOL] bias = mx . sym . Custom ( op_type = [string] , length = [number] , dtype = C . DTYPE_FP16 ) [EOL] [EOL] arg_types , out_types , aux_types = bias . infer_type ( ) [EOL] assert out_types [ [number] ] == np . float16 [EOL] [EOL] out = bias . eval ( ) [ [number] ] [EOL] [EOL] assert out . dtype == np . float16 [EOL] [EOL] expected = np . array ( [ [ [number] , - [number] ] , [ [number] , [number] ] ] ) . reshape ( ( [number] , [number] , [number] ) ) [EOL] np . testing . assert_array_equal ( out . asnumpy ( ) , expected ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , Dict , List [EOL] import typing [EOL] import os [EOL] from tempfile import TemporaryDirectory [EOL] [EOL] import numpy as np [EOL] [EOL] import sockeye . constants as C [EOL] import sockeye . lexicon [EOL] [EOL] [EOL] def test_topk_lexicon ( ) : [EOL] lexicon = [ [string] , [string] , [string] , [string] ] [EOL] vocab_list = [ [string] , [string] , [string] ] [EOL] vocab = dict ( ( y , x ) for ( x , y ) in enumerate ( C . VOCAB_SYMBOLS + vocab_list ) ) [EOL] k = [number] [EOL] lex = sockeye . lexicon . TopKLexicon ( vocab , vocab ) [EOL] [EOL] [comment] [EOL] with TemporaryDirectory ( prefix = [string] ) as work_dir : [EOL] [comment] [EOL] input_lex_path = os . path . join ( work_dir , [string] ) [EOL] with open ( input_lex_path , [string] ) as out : [EOL] for line in lexicon : [EOL] print ( line , file = out ) [EOL] [comment] [EOL] lex . create ( input_lex_path , k ) [EOL] [EOL] [comment] [EOL] expected = np . zeros ( ( len ( C . VOCAB_SYMBOLS ) + len ( vocab_list ) , k ) , dtype = np . int ) [EOL] [comment] [EOL] expected [ len ( C . VOCAB_SYMBOLS ) , : [number] ] = [ len ( C . VOCAB_SYMBOLS ) , len ( C . VOCAB_SYMBOLS ) + [number] ] [EOL] [comment] [EOL] expected [ len ( C . VOCAB_SYMBOLS ) + [number] , : [number] ] = [ len ( C . VOCAB_SYMBOLS ) + [number] ] [EOL] assert np . all ( lex . lex == expected ) [EOL] [EOL] [comment] [EOL] expected_sorted = np . sort ( expected , axis = [number] ) [EOL] json_lex_path = os . path . join ( work_dir , [string] ) [EOL] lex . save ( json_lex_path ) [EOL] lex . load ( json_lex_path ) [EOL] assert np . all ( lex . lex == expected_sorted ) [EOL] [EOL] [comment] [EOL] trg_ids = lex . get_trg_ids ( np . array ( [ [ vocab [ [string] ] , vocab [ [string] ] ] ] , dtype = np . int ) ) [EOL] expected = np . array ( [ vocab [ symbol ] for symbol in C . VOCAB_SYMBOLS + [ [string] , [string] ] ] , dtype = np . int ) [EOL] assert np . all ( trg_ids == expected ) [EOL] [EOL] trg_ids = lex . get_trg_ids ( np . array ( [ [ vocab [ [string] ] ] ] , dtype = np . int ) ) [EOL] expected = np . array ( [ vocab [ symbol ] for symbol in C . VOCAB_SYMBOLS + [ [string] ] ] , dtype = np . int ) [EOL] assert np . all ( trg_ids == expected ) [EOL] [EOL] trg_ids = lex . get_trg_ids ( np . array ( [ [ vocab [ [string] ] ] ] , dtype = np . int ) ) [EOL] expected = np . array ( [ vocab [ symbol ] for symbol in C . VOCAB_SYMBOLS ] , dtype = np . int ) [EOL] assert np . all ( trg_ids == expected ) [EOL] [EOL] [comment] [EOL] small_k = k - [number] [EOL] lex . load ( json_lex_path , k = small_k ) [EOL] assert lex . lex . shape [ [number] ] == small_k [EOL] trg_ids = lex . get_trg_ids ( np . array ( [ [ vocab [ [string] ] ] ] , dtype = np . int ) ) [EOL] expected = np . array ( [ vocab [ symbol ] for symbol in C . VOCAB_SYMBOLS + [ [string] ] ] , dtype = np . int ) [EOL] assert np . all ( trg_ids == expected ) [EOL] [EOL] [comment] [EOL] large_k = k + [number] [EOL] lex . load ( json_lex_path , k = large_k ) [EOL] assert lex . lex . shape [ [number] ] == k [EOL] trg_ids = lex . get_trg_ids ( np . array ( [ [ vocab [ [string] ] , vocab [ [string] ] ] ] , dtype = np . int ) ) [EOL] expected = np . array ( [ vocab [ symbol ] for symbol in C . VOCAB_SYMBOLS + [ [string] , [string] ] ] , dtype = np . int ) [EOL] assert np . all ( trg_ids == expected ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import argparse [EOL] import argparse [EOL] import pytest [EOL] [EOL] import sockeye . image_captioning . arguments as arguments [EOL] import sockeye . constants as C [EOL] [EOL] from test . unit . test_arguments import _test_args [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [string] , dict ( source_image_size = [ [number] , [number] , [number] ] , image_root = [string] , input = [string] , output_root = [string] , output = [string] , batch_size = [number] , image_positional_embedding_type = C . NO_POSITIONAL_EMBEDDING , image_encoder_model_path = [string] , image_encoder_model_epoch = [number] , image_encoder_layer = [string] , image_encoder_conv_map_size = [number] , image_encoder_num_hidden = [number] , no_image_encoder_global_descriptor = True , load_all_features_to_memory = False , device_ids = [ - [number] ] , disable_device_locking = False , lock_dir = [string] , use_cpu = False , extract_image_features = False ) ) ] ) def test_image_extract_features_cli_args ( test_params , expected_params ) : [EOL] _test_args ( test_params , expected_params , arguments . add_image_extract_features_cli_args ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [string] , dict ( source_root = [string] ) ) ] ) def test_image_source_root_args ( test_params , expected_params ) : [EOL] _test_args ( test_params , expected_params , arguments . add_image_source_root_args ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [string] , dict ( validation_source_root = [string] , validation_source = [string] , validation_target = [string] , validation_source_factors = [ ] ) ) ] ) def test_image_validation_data_params ( test_params , expected_params ) : [EOL] _test_args ( test_params , expected_params , arguments . add_image_validation_data_params ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [string] , dict ( load_all_features_to_memory = True , extract_image_features = False ) ) ] ) def test_preextracted_features_args ( test_params , expected_params ) : [EOL] _test_args ( test_params , expected_params , arguments . add_preextracted_features_args ) [EOL] [EOL] [EOL] def test_add_image_train_cli_args ( ) : [EOL] [comment] [EOL] [comment] [EOL] params = argparse . ArgumentParser ( ) [EOL] arguments . add_image_train_cli_args ( params ) [EOL] [EOL] [EOL] def test_add_image_caption_cli_args ( ) : [EOL] [comment] [EOL] [comment] [EOL] params = argparse . ArgumentParser ( ) [EOL] arguments . add_image_caption_cli_args ( params ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , List [EOL] import typing [EOL] import os [EOL] from tempfile import TemporaryDirectory [EOL] [EOL] import mxnet as mx [EOL] import numpy as np [EOL] import pytest [EOL] [EOL] import sockeye . constants as C [EOL] import sockeye . data_io [EOL] import sockeye . image_captioning . data_io as data_io [EOL] from sockeye import vocab [EOL] from sockeye . utils import seed_rngs [EOL] from test . common_image_captioning import generate_img_or_feat , tmp_img_captioning_dataset , _FEATURE_SHAPE , _CNN_INPUT_IMAGE_SHAPE [EOL] [EOL] seed_rngs ( [number] ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [ [string] , [string] , [string] , [string] , [string] ] , [ [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] , [number] , [number] ] , [ [number] , [number] ] ] , [ [number] , [number] , [number] ] , [ [string] , [string] ] , [ [ [number] , [number] ] , [ [number] , [number] ] ] , [ [ [number] , [number] ] , [ [number] , [number] ] ] ) ] ) def test_raw_list_text_dset_loader ( source_list , target_sentences , num_samples_per_bucket , expected_source_0 , expected_target_0 , expected_label_0 ) : [EOL] [comment] [EOL] buckets = sockeye . data_io . define_parallel_buckets ( [number] , [number] , [number] , [number] ) [EOL] dset_loader = data_io . RawListTextDatasetLoader ( buckets = buckets , eos_id = [number] , pad_id = C . PAD_ID ) [EOL] [EOL] assert isinstance ( dset_loader , data_io . RawListTextDatasetLoader ) [EOL] assert len ( dset_loader . buckets ) == [number] [EOL] [EOL] [comment] [EOL] pop_dset_loader = dset_loader . load ( source_list , target_sentences , num_samples_per_bucket ) [EOL] [EOL] assert isinstance ( pop_dset_loader , sockeye . data_io . ParallelDataSet ) [EOL] assert len ( pop_dset_loader . source ) == [number] [EOL] assert len ( pop_dset_loader . target ) == [number] [EOL] assert len ( pop_dset_loader . label ) == [number] [EOL] np . testing . assert_equal ( pop_dset_loader . source [ [number] ] , expected_source_0 ) [EOL] np . testing . assert_almost_equal ( pop_dset_loader . target [ [number] ] . asnumpy ( ) , expected_target_0 ) [EOL] np . testing . assert_almost_equal ( pop_dset_loader . label [ [number] ] . asnumpy ( ) , expected_label_0 ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [ [string] , [string] , [string] , [string] , [string] ] , [ [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] , [number] , [number] ] , [ [number] , [number] ] ] , [ [number] , [number] , [number] ] ) ] ) def test_image_text_sample_iter ( source_list , target_sentences , num_samples_per_bucket ) : [EOL] batch_size = [number] [EOL] image_size = _CNN_INPUT_IMAGE_SHAPE [EOL] buckets = sockeye . data_io . define_parallel_buckets ( [number] , [number] , [number] , [number] ) [EOL] bucket_batch_sizes = sockeye . data_io . define_bucket_batch_sizes ( buckets , batch_size , batch_by_words = False , batch_num_devices = [number] , data_target_average_len = [ None ] * len ( buckets ) ) [EOL] dset_loader = data_io . RawListTextDatasetLoader ( buckets = buckets , eos_id = - [number] , pad_id = C . PAD_ID ) [EOL] with TemporaryDirectory ( ) as work_dir : [EOL] source_list_img = [ ] [EOL] source_list_npy = [ ] [EOL] for s in source_list : [EOL] source_list_img . append ( os . path . join ( work_dir , s + [string] ) ) [EOL] source_list_npy . append ( os . path . join ( work_dir , s + [string] ) ) [EOL] [comment] [EOL] for s in source_list_img : [EOL] filename = os . path . join ( work_dir , s ) [EOL] generate_img_or_feat ( filename , use_features = False ) [EOL] for s in source_list_npy : [EOL] filename = os . path . join ( work_dir , s ) [EOL] generate_img_or_feat ( filename , use_features = True ) [EOL] [EOL] [comment] [EOL] pop_dset_loader = dset_loader . load ( source_list_img , target_sentences , num_samples_per_bucket ) [EOL] data_iter = data_io . ImageTextSampleIter ( pop_dset_loader , buckets , batch_size , bucket_batch_sizes , image_size , use_feature_loader = False , preload_features = False ) [EOL] data = data_iter . next ( ) [EOL] assert isinstance ( data , mx . io . DataBatch ) [EOL] np . testing . assert_equal ( data . data [ [number] ] . asnumpy ( ) . shape [ [number] : ] , image_size ) [EOL] [EOL] [comment] [EOL] pop_dset_loader = dset_loader . load ( source_list_npy , target_sentences , num_samples_per_bucket ) [EOL] data_iter = data_io . ImageTextSampleIter ( pop_dset_loader , buckets , batch_size , bucket_batch_sizes , _FEATURE_SHAPE , use_feature_loader = True , preload_features = True ) [EOL] data = data_iter . next ( ) [EOL] assert isinstance ( data , mx . io . DataBatch ) [EOL] np . testing . assert_equal ( data . data [ [number] ] . asnumpy ( ) . shape [ [number] : ] , _FEATURE_SHAPE ) [EOL] [EOL] [EOL] def test_get_training_feature_text_data_iters ( ) : [EOL] [comment] [EOL] source_list = [ [string] , [string] , [string] , [string] , [string] ] [EOL] prefix = [string] [EOL] use_feature_loader = True [EOL] preload_features = True [EOL] train_max_length = [number] [EOL] dev_max_length = [number] [EOL] expected_mean = [number] [EOL] expected_std = [number] [EOL] test_max_length = [number] [EOL] batch_size = [number] [EOL] if use_feature_loader : [EOL] source_image_size = _FEATURE_SHAPE [EOL] else : [EOL] source_image_size = _CNN_INPUT_IMAGE_SHAPE [EOL] with tmp_img_captioning_dataset ( source_list , prefix , train_max_length , dev_max_length , test_max_length , use_feature_loader ) as data : [EOL] [comment] [EOL] vcb = vocab . build_from_paths ( [ data [ [string] ] , data [ [string] ] ] ) [EOL] [EOL] train_iter , val_iter , config_data , data_info = data_io . get_training_image_text_data_iters ( source_root = data [ [string] ] , source = data [ [string] ] , target = data [ [string] ] , validation_source_root = data [ [string] ] , validation_source = data [ [string] ] , validation_target = data [ [string] ] , vocab_target = vcb , vocab_target_path = None , batch_size = batch_size , batch_by_words = False , batch_num_devices = [number] , source_image_size = source_image_size , fill_up = [string] , max_seq_len_target = train_max_length , bucketing = True , bucket_width = [number] , use_feature_loader = use_feature_loader , preload_features = preload_features ) [EOL] assert isinstance ( train_iter , data_io . ParallelSampleIter ) [EOL] assert isinstance ( val_iter , data_io . ParallelSampleIter ) [EOL] assert isinstance ( config_data , data_io . DataConfig ) [EOL] assert isinstance ( data_info . sources [ [number] ] , data_io . FileListReader ) [EOL] assert data_info . target == data [ [string] ] [EOL] assert data_info . source_vocabs is None [EOL] assert data_info . target_vocab is None [EOL] assert config_data . data_statistics . max_observed_len_source == [number] [EOL] assert config_data . data_statistics . max_observed_len_target == train_max_length - [number] [EOL] assert np . isclose ( config_data . data_statistics . length_ratio_mean , expected_mean ) [EOL] assert np . isclose ( config_data . data_statistics . length_ratio_std , expected_std ) [EOL] [EOL] assert train_iter . batch_size == batch_size [EOL] assert val_iter . batch_size == batch_size [EOL] assert train_iter . default_bucket_key == ( [number] , train_max_length ) [EOL] assert val_iter . default_bucket_key == ( [number] , dev_max_length ) [EOL] assert train_iter . dtype == [string] [EOL] [EOL] [comment] [EOL] bos_id = vcb [ C . BOS_SYMBOL ] [EOL] expected_first_target_symbols = np . full ( ( batch_size , ) , bos_id , dtype = [string] ) [EOL] for epoch in range ( [number] ) : [EOL] while train_iter . iter_next ( ) : [EOL] batch = train_iter . next ( ) [EOL] assert len ( batch . data ) == [number] [EOL] assert len ( batch . label ) == [number] [EOL] assert batch . bucket_key in train_iter . buckets [EOL] source = batch . data [ [number] ] . asnumpy ( ) [EOL] target = batch . data [ [number] ] . asnumpy ( ) [EOL] label = batch . label [ [number] ] . asnumpy ( ) [EOL] assert source . shape [ [number] ] == target . shape [ [number] ] == label . shape [ [number] ] == batch_size [EOL] [comment] [EOL] assert np . array_equal ( target [ : , [number] ] , expected_first_target_symbols ) [EOL] [comment] [EOL] assert np . array_equal ( label [ : , [number] ] , target [ : , [number] ] ) [EOL] [comment] [EOL] assert np . sum ( label == vcb [ C . EOS_SYMBOL ] ) == batch_size [EOL] train_iter . reset ( ) [EOL] [EOL] [EOL] def test_get_training_image_text_data_iters ( ) : [EOL] [comment] [EOL] source_list = [ [string] , [string] , [string] , [string] , [string] ] [EOL] prefix = [string] [EOL] use_feature_loader = False [EOL] preload_features = False [EOL] train_max_length = [number] [EOL] dev_max_length = [number] [EOL] expected_mean = [number] [EOL] expected_std = [number] [EOL] test_max_length = [number] [EOL] batch_size = [number] [EOL] if use_feature_loader : [EOL] source_image_size = _FEATURE_SHAPE [EOL] else : [EOL] source_image_size = _CNN_INPUT_IMAGE_SHAPE [EOL] with tmp_img_captioning_dataset ( source_list , prefix , train_max_length , dev_max_length , test_max_length , use_feature_loader ) as data : [EOL] [comment] [EOL] vcb = vocab . build_from_paths ( [ data [ [string] ] , data [ [string] ] ] ) [EOL] [EOL] train_iter , val_iter , config_data , data_info = data_io . get_training_image_text_data_iters ( source_root = data [ [string] ] , source = data [ [string] ] , target = data [ [string] ] , validation_source_root = data [ [string] ] , validation_source = data [ [string] ] , validation_target = data [ [string] ] , vocab_target = vcb , vocab_target_path = None , batch_size = batch_size , batch_by_words = False , batch_num_devices = [number] , source_image_size = source_image_size , fill_up = [string] , max_seq_len_target = train_max_length , bucketing = False , bucket_width = [number] , use_feature_loader = use_feature_loader , preload_features = preload_features ) [EOL] assert isinstance ( train_iter , data_io . ParallelSampleIter ) [EOL] assert isinstance ( val_iter , data_io . ParallelSampleIter ) [EOL] assert isinstance ( config_data , data_io . DataConfig ) [EOL] assert isinstance ( data_info . sources [ [number] ] , data_io . FileListReader ) [EOL] assert data_info . target == data [ [string] ] [EOL] assert data_info . source_vocabs is None [EOL] assert data_info . target_vocab is None [EOL] assert config_data . data_statistics . max_observed_len_source == [number] [EOL] assert config_data . data_statistics . max_observed_len_target == train_max_length - [number] [EOL] assert np . isclose ( config_data . data_statistics . length_ratio_mean , expected_mean ) [EOL] assert np . isclose ( config_data . data_statistics . length_ratio_std , expected_std ) [EOL] [EOL] assert train_iter . batch_size == batch_size [EOL] assert val_iter . batch_size == batch_size [EOL] assert train_iter . default_bucket_key == ( [number] , train_max_length ) [EOL] assert val_iter . default_bucket_key == ( [number] , dev_max_length ) [EOL] assert train_iter . dtype == [string] [EOL] [EOL] [comment] [EOL] bos_id = vcb [ C . BOS_SYMBOL ] [EOL] expected_first_target_symbols = np . full ( ( batch_size , ) , bos_id , dtype = [string] ) [EOL] for epoch in range ( [number] ) : [EOL] while train_iter . iter_next ( ) : [EOL] batch = train_iter . next ( ) [EOL] assert len ( batch . data ) == [number] [EOL] assert len ( batch . label ) == [number] [EOL] assert batch . bucket_key in train_iter . buckets [EOL] source = batch . data [ [number] ] . asnumpy ( ) [EOL] target = batch . data [ [number] ] . asnumpy ( ) [EOL] label = batch . label [ [number] ] . asnumpy ( ) [EOL] assert source . shape [ [number] ] == target . shape [ [number] ] == label . shape [ [number] ] == batch_size [EOL] [comment] [EOL] assert np . array_equal ( target [ : , [number] ] , expected_first_target_symbols ) [EOL] [comment] [EOL] assert np . array_equal ( label [ : , [number] ] , target [ : , [number] ] ) [EOL] [comment] [EOL] assert np . sum ( label == vcb [ C . EOS_SYMBOL ] ) == batch_size [EOL] train_iter . reset ( )	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import List , Tuple [EOL] import typing [EOL] import builtins [EOL] import random [EOL] import string [EOL] [EOL] import pytest [EOL] [EOL] from test . common_image_captioning import run_train_captioning , tmp_img_captioning_dataset [EOL] [EOL] _LINE_MAX_LENGTH = [number] [EOL] _TEST_MAX_LENGTH = [number] [EOL] [EOL] ENCODER_DECODER_SETTINGS = [ ( [string] [string] [string] [string] [string] , [string] ) , ( [string] [string] [string] [string] [string] , [string] ) , ( [string] [string] [string] [string] , [string] ) , ( [string] [string] [string] [string] , [string] ) ] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , ENCODER_DECODER_SETTINGS ) def test_caption_random_features ( train_params , translate_params ) : [EOL] [comment] [EOL] source_list = [ [string] . join ( random . choice ( string . ascii_uppercase ) for _ in range ( [number] ) ) for i in range ( [number] ) ] [EOL] prefix = [string] [EOL] use_features = True [EOL] with tmp_img_captioning_dataset ( source_list , prefix , train_max_length = _LINE_MAX_LENGTH , dev_max_length = _LINE_MAX_LENGTH , test_max_length = _TEST_MAX_LENGTH , use_features = use_features ) as data : [EOL] [comment] [EOL] translate_params_batch = translate_params + [string] [EOL] [EOL] [comment] [EOL] run_train_captioning ( train_params = train_params , translate_params = translate_params , translate_params_equiv = translate_params_batch , train_source_path = data [ [string] ] , train_target_path = data [ [string] ] , dev_source_path = data [ [string] ] , dev_target_path = data [ [string] ] , test_source_path = data [ [string] ] , test_target_path = data [ [string] ] , max_seq_len = _LINE_MAX_LENGTH + [number] , work_dir = data [ [string] ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0