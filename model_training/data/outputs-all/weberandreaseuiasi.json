[comment] [EOL] from typing import Any [EOL] import analysis [EOL] import typing [EOL] [docstring] [EOL] [EOL] import matplotlib . pyplot as plt [EOL] import numpy as np [EOL] import pandas as pd [EOL] from hdbscan import HDBSCAN [EOL] from sklearn . cluster import DBSCAN [EOL] from sklearn . pipeline import Pipeline [EOL] [EOL] from analysis . data import GeographicArea , features [EOL] from analysis . scaler import SpatialWaterVapourScaler [EOL] [EOL] file_pattern = [string] [EOL] area = GeographicArea ( lat = ( - [number] , [number] ) , lon = ( - [number] , [number] ) ) [EOL] df = area . import_dataset ( file_pattern ) [EOL] X = df [ features ] . values [EOL] [EOL] [comment] [EOL] scaler = SpatialWaterVapourScaler ( km = [number] , H2O = [number] , delD = [number] ) [EOL] [comment] [EOL] cluster = HDBSCAN ( min_cluster_size = [number] , gen_min_span_tree = True ) [EOL] [EOL] [comment] [EOL] pipeline = Pipeline ( [ ( [string] , scaler ) , ( [string] , cluster ) ] ) [EOL] [EOL] y = pipeline . fit_predict ( X ) [EOL] [EOL] subarea = GeographicArea ( lat = ( - [number] , [number] ) , lon = ( [number] , [number] ) ) [EOL] area . subarea_plot ( X , y , subarea = subarea , include_noise = True ) [EOL] [EOL] [comment]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $analysis.scaler.SpatialWaterVapourScaler$ 0 0 0 0 $builtins.str$ 0 0 0 $analysis.data.GeographicArea$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $analysis.data.GeographicArea$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $analysis.scaler.SpatialWaterVapourScaler$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $analysis.scaler.SpatialWaterVapourScaler$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 $analysis.data.GeographicArea$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $analysis.data.GeographicArea$ 0 0 0 0 0 $typing.Any$ 0 $analysis.data.GeographicArea$ 0 $analysis.data.GeographicArea$ 0 0 0 0 0 0 0 0
from typing import Any [EOL] import logging [EOL] import numpy [EOL] import iasi [EOL] import netCDF4 [EOL] import typing [EOL] import logging [EOL] [EOL] import numpy as np [EOL] from luigi . util import requires [EOL] from netCDF4 import Dataset , Group , Variable [EOL] [EOL] from iasi . file import CopyNetcdfFile , MoveVariables [EOL] from iasi . quadrant import Quadrant [EOL] from iasi . util import root_group_of [EOL] [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class CompositionException ( Exception ) : [EOL] pass [EOL] [EOL] [EOL] class Composition : [EOL] @ staticmethod def factory ( group ) : [EOL] if [string] in group . variables . keys ( ) : [EOL] return SingularValueComposition ( group ) [EOL] if [string] in group . variables . keys ( ) : [EOL] return EigenComposition ( group ) [EOL] raise CompositionException ( [string] . format ( group . name ) ) [EOL] [EOL] def __init__ ( self , group ) : [EOL] self . group = group [EOL] [EOL] def reconstruct ( self , nol , target = None ) : [EOL] raise NotImplementedError [EOL] [EOL] def _export_reconstruction ( self , target , array , quadrant ) : [EOL] root = root_group_of ( self . group ) [EOL] existing_dimensions = target . dimensions . keys ( ) [EOL] for name , dim in root . dimensions . items ( ) : [EOL] if name in existing_dimensions : [EOL] continue [EOL] target . createDimension ( name , len ( dim ) if not dim . isunlimited ( ) else None ) [EOL] var = quadrant . create_variable ( target , self . group . path ) [EOL] var [ : ] = array [ : ] [EOL] [EOL] [EOL] class SingularValueComposition ( Composition ) : [EOL] [EOL] def __init__ ( self , group ) : [EOL] super ( ) . __init__ ( group ) [EOL] vars = group . variables . keys ( ) [EOL] assert [string] in vars and [string] in vars and [string] in vars and [string] in vars [EOL] self . U = group [ [string] ] [EOL] self . s = group [ [string] ] [EOL] self . Vh = group [ [string] ] [EOL] self . k = group [ [string] ] [EOL] self . quadrant = Quadrant . for_disassembly ( group . parent . name , group . name , self . U ) [EOL] [EOL] def reconstruct ( self , nol , target = None ) : [EOL] result = np . ma . masked_all ( self . quadrant . transformed_shape ( ) , dtype = np . float32 ) [EOL] k_all = self . k [ ... ] [EOL] U_all = self . U [ ... ] [EOL] s_all = self . s [ ... ] [EOL] Vh_all = self . Vh [ ... ] [EOL] for event in range ( self . Vh . shape [ [number] ] ) : [EOL] if np . ma . is_masked ( nol [ event ] ) or nol . data [ event ] > [number] : [EOL] continue [EOL] if np . ma . is_masked ( k_all [ event ] ) or k_all . data [ event ] <= [number] : [EOL] continue [EOL] level = int ( nol . data [ event ] ) [EOL] k = k_all . data [ event ] [EOL] U = U_all . data [ event , : , : k ] [EOL] s = s_all . data [ event , : k ] [EOL] Vh = Vh_all . data [ event , : k , : ] [EOL] reconstruction = ( U * s ) . dot ( Vh ) [EOL] self . quadrant . assign_disassembly ( reconstruction , result [ event ] , level ) [EOL] [comment] [EOL] if target : [EOL] self . _export_reconstruction ( target , result , self . quadrant ) [EOL] return result [EOL] [EOL] [EOL] class EigenComposition ( Composition ) : [EOL] [EOL] def __init__ ( self , group ) : [EOL] super ( ) . __init__ ( group ) [EOL] vars = group . variables . keys ( ) [EOL] assert [string] in vars and [string] in vars and [string] in vars [EOL] self . Q = group [ [string] ] [EOL] self . s = group [ [string] ] [EOL] self . k = group [ [string] ] [EOL] self . quadrant = Quadrant . for_disassembly ( group . parent . name , group . name , self . Q ) [EOL] [EOL] def reconstruct ( self , nol , target = None ) : [EOL] result = np . ma . masked_all ( self . quadrant . transformed_shape ( ) , dtype = np . float32 ) [EOL] Q_all = self . Q [ ... ] [EOL] s_all = self . s [ ... ] [EOL] k_all = self . k [ ... ] [EOL] for event in range ( self . Q . shape [ [number] ] ) : [EOL] if np . ma . is_masked ( nol [ event ] ) or nol . data [ event ] > [number] : [EOL] continue [EOL] if np . ma . is_masked ( k_all [ event ] ) or k_all . data [ event ] <= [number] : [EOL] continue [EOL] level = int ( nol . data [ event ] ) [EOL] k = k_all . data [ event ] [EOL] Q = Q_all . data [ event , : , : k ] [EOL] s = s_all . data [ event , : k ] [EOL] reconstruction = ( Q * s ) . dot ( Q . T ) [EOL] self . quadrant . assign_disassembly ( reconstruction , result [ event ] , level ) [EOL] if target : [EOL] self . _export_reconstruction ( target , result , self . quadrant ) [EOL] return result [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $netCDF4.Group$ 0 0 0 0 0 0 $netCDF4.Group$ 0 0 0 0 0 0 0 0 0 0 0 $netCDF4.Group$ 0 0 0 0 0 $netCDF4.Group$ 0 0 0 0 0 0 0 0 0 0 0 $netCDF4.Group$ 0 0 0 0 0 0 0 0 0 $netCDF4.Group$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ma.MaskedArray$ 0 $netCDF4.Dataset$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $netCDF4.Dataset$ 0 $numpy.ma.MaskedArray$ 0 $iasi.quadrant.Quadrant$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $netCDF4.Dataset$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $netCDF4.Dataset$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.quadrant.Quadrant$ 0 0 0 $netCDF4.Dataset$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ma.MaskedArray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $netCDF4.Group$ 0 0 0 0 0 0 0 0 0 $netCDF4.Group$ 0 0 $typing.Any$ 0 $netCDF4.Group$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 $netCDF4.Group$ 0 0 0 0 0 0 0 0 $netCDF4.Group$ 0 0 0 0 0 0 0 0 $netCDF4.Group$ 0 0 0 0 0 0 0 0 $netCDF4.Group$ 0 0 0 0 0 0 0 0 0 0 0 0 $netCDF4.Group$ 0 0 0 0 0 $netCDF4.Group$ 0 0 0 0 0 0 0 0 0 0 $numpy.ma.MaskedArray$ 0 0 0 $numpy.ma.MaskedArray$ 0 $netCDF4.Dataset$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ma.MaskedArray$ 0 0 0 0 0 $numpy.ma.MaskedArray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $numpy.ma.MaskedArray$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 $builtins.int$ 0 0 0 0 0 $netCDF4.Dataset$ 0 0 0 0 0 0 $netCDF4.Dataset$ 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $netCDF4.Group$ 0 0 0 0 0 0 0 0 0 $netCDF4.Group$ 0 0 $typing.Any$ 0 $netCDF4.Group$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 $netCDF4.Group$ 0 0 0 0 0 0 0 0 $netCDF4.Group$ 0 0 0 0 0 0 0 0 $netCDF4.Group$ 0 0 0 0 0 0 0 0 0 0 0 0 $netCDF4.Group$ 0 0 0 0 0 $netCDF4.Group$ 0 0 0 0 0 0 0 0 0 0 $numpy.ma.MaskedArray$ 0 0 0 $numpy.ma.MaskedArray$ 0 $netCDF4.Dataset$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ma.MaskedArray$ 0 0 0 0 0 $numpy.ma.MaskedArray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $numpy.ma.MaskedArray$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 $builtins.int$ 0 0 0 $netCDF4.Dataset$ 0 0 0 0 0 0 $netCDF4.Dataset$ 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0
from typing import Dict , Type , List , Any [EOL] import logging [EOL] import netCDF4 [EOL] import typing [EOL] import iasi [EOL] import logging [EOL] import os [EOL] from typing import Dict , List , Tuple [EOL] [EOL] import luigi [EOL] import numpy as np [EOL] from luigi . util import inherits , requires [EOL] from netCDF4 import Dataset , Group , Variable [EOL] [EOL] import iasi [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def dimensions_of ( variable ) : [EOL] return { name : dim for name , dim in zip ( variable . dimensions , variable . shape ) } [EOL] [EOL] [EOL] def child_groups_of ( group ) : [EOL] yield group [EOL] if group . groups : [EOL] for subgroup in group . groups . values ( ) : [EOL] yield from child_groups_of ( subgroup ) [EOL] [EOL] [EOL] def child_variables_of ( group ) : [EOL] for subgroup in child_groups_of ( group ) : [EOL] for variable in subgroup . variables . values ( ) : [EOL] yield ( subgroup , variable ) [EOL] [EOL] [EOL] def root_group_of ( group ) : [EOL] if group . parent : [EOL] return root_group_of ( group . parent ) [EOL] else : [EOL] return group [EOL] [EOL] [EOL] class custom ( luigi . Config ) : [EOL] tracking_url = luigi . Parameter ( default = [string] ) [EOL] [EOL] [EOL] class CustomTask ( luigi . Task ) : [EOL] [docstring] [EOL] force = luigi . BoolParameter ( significant = False , default = False ) [EOL] force_upstream = luigi . BoolParameter ( significant = False , default = False ) [EOL] [EOL] def __init__ ( self , * args , ** kwargs ) : [EOL] [comment] [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] if self . force_upstream is True : [EOL] self . force = True [EOL] if self . force is True : [EOL] done = False [EOL] tasks = [ self ] [EOL] while not done : [EOL] if not issubclass ( tasks [ [number] ] . __class__ , luigi . ExternalTask ) : [EOL] [comment] [EOL] outputs = luigi . task . flatten ( tasks [ [number] ] . output ( ) ) [EOL] [ os . remove ( out . path ) for out in outputs if out . exists ( ) ] [EOL] if self . force_upstream is True : [EOL] tasks += luigi . task . flatten ( tasks [ [number] ] . requires ( ) ) [EOL] tasks . pop ( [number] ) [EOL] if len ( tasks ) == [number] : [EOL] done = True [EOL] [EOL] [EOL] @ luigi . Task . event_handler ( luigi . Event . START ) def callback_start ( self ) : [EOL] if hasattr ( self , [string] ) and callable ( self . set_tracking_url ) : [EOL] self . set_tracking_url ( custom ( ) . tracking_url ) [EOL] logger . info ( [string] , type ( self ) . __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $netCDF4.Group$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[iasi.util.custom]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[iasi.util.CustomTask]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[iasi.util.CustomTask]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.List[iasi.util.CustomTask]$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $typing.List[iasi.util.CustomTask]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.List[iasi.util.CustomTask]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[iasi.util.CustomTask]$ 0 0 0 0 0 0 0 $typing.List[iasi.util.CustomTask]$ 0 0 0 0 0 0 0 0 0 $typing.List[iasi.util.CustomTask]$ 0 0 0 0 0 0 0 0 0 $typing.List[iasi.util.CustomTask]$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List , Type [EOL] import numpy [EOL] import iasi [EOL] import netCDF4 [EOL] import pandas [EOL] import builtins [EOL] import typing [EOL] import glob [EOL] import logging [EOL] import os [EOL] import time [EOL] from datetime import datetime [EOL] from typing import Dict [EOL] [EOL] import luigi [EOL] import numpy as np [EOL] import pandas as pd [EOL] from luigi . util import requires [EOL] from netCDF4 import Dataset [EOL] [EOL] from iasi . file import CopyNetcdfFile , ReadFile , FileTask [EOL] [EOL] [EOL] class AposterioriProcessing ( FileTask ) : [EOL] [comment] [EOL] level_of_interest = luigi . IntParameter ( default = - [number] ) [EOL] svd = luigi . BoolParameter ( ) [EOL] dim = luigi . IntParameter ( default = [number] ) [EOL] file = luigi . Parameter ( ) [EOL] [EOL] output_variables = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] [EOL] calculated = [ [string] , [string] , [string] , [string] , [string] ] [EOL] [EOL] def requires ( self ) : [EOL] raise NotImplementedError [EOL] [EOL] def run ( self ) : [EOL] with Dataset ( self . input ( ) . path , [string] ) as nc : [EOL] events = nc . dimensions [ [string] ] . size [EOL] self . avk = self . reconstruct ( nc ) [EOL] self . wv = nc [ [string] ] [ ... ] [EOL] self . atm_alt = nc [ [string] ] [ ... ] [EOL] self . wv_a = nc [ [string] ] [ ... ] [EOL] self . nol = nc [ [string] ] [ ... ] [EOL] self . result = { var : [ ] for var in self . calculated } [EOL] for event in range ( events ) : [EOL] self . process_event ( event ) [EOL] df = pd . DataFrame ( self . result ) [EOL] with self . output ( ) . temporary_path ( ) as target : [EOL] df . to_csv ( target , index = None ) [EOL] [EOL] def process_event ( self , event ) : [EOL] [comment] [EOL] if isinstance ( self . avk , np . ma . MaskedArray ) and self . avk [ event ] . mask . all ( ) : [EOL] return [EOL] levels = self . nol [ event ] [EOL] if np . ma . is_masked ( levels ) : [EOL] return [EOL] n = int ( levels ) [EOL] P = np . block ( [ [ np . identity ( n ) * [number] , np . identity ( n ) * [number] ] , [ - np . identity ( n ) , np . identity ( n ) ] ] ) [EOL] P_inv = np . linalg . inv ( P ) [EOL] A = np . block ( [ [ self . avk [ event , [number] , [number] , : n , : n ] , self . avk [ event , [number] , [number] , : n , : n ] ] , [ self . avk [ event , [number] , [number] , : n , : n ] , self . avk [ event , [number] , [number] , : n , : n ] ] ] ) . T [EOL] A_ = P @ A @ P_inv [EOL] C = np . block ( [ [ A_ [ n : , n : ] , np . zeros ( ( n , n ) ) ] , [ - A_ [ n : , : n ] , np . identity ( n ) ] ] ) [EOL] A__ = C @ A_ [EOL] x = C @ P @ ( self . wv [ event ] [ : n , : n ] . reshape ( - [number] ) - self . wv_a [ event ] [ : n , : n ] . reshape ( - [number] ) ) + P @ self . wv_a [ event ] [ : n , : n ] . reshape ( - [number] ) [EOL] corrlength = [number] [EOL] S = np . exp ( - ( ( self . atm_alt [ event , : n , np . newaxis ] - self . atm_alt [ event , np . newaxis , : n ] ) ** [number] / ( [number] * corrlength ** [number] ) ) ) [EOL] corrlengthbl = [number] [EOL] Sbl = np . exp ( - ( ( self . atm_alt [ event , : n , np . newaxis ] - self . atm_alt [ event , np . newaxis , : n ] ) ** [number] / ( [number] * corrlengthbl ** [number] ) ) ) [EOL] S_ = np . block ( [ [ S [ : [number] , : [number] ] , Sbl [ [number] : , : [number] ] . T ] , [ Sbl [ [number] : , : [number] ] , S [ [number] : , [number] : ] ] ] ) [EOL] [comment] [EOL] [comment] [EOL] S__ = ( A__ [ : n , : n ] - np . identity ( n ) ) @ S_ @ ( A__ [ : n , : n ] - np . identity ( n ) ) . T [EOL] self . result [ [string] ] . append ( np . exp ( x [ self . level_of_interest - n ] - x [ self . level_of_interest ] / [number] ) ) [EOL] self . result [ [string] ] . append ( [number] * ( np . exp ( x [ self . level_of_interest ] ) - [number] ) ) [EOL] self . result [ [string] ] . append ( np . trace ( A__ [ : n , : n ] ) ) [EOL] self . result [ [string] ] . append ( np . sqrt ( S__ [ self . level_of_interest , self . level_of_interest ] ) ) [EOL] self . result [ [string] ] . append ( self . atm_alt [ event , self . level_of_interest + n ] ) [EOL] [EOL] def reconstruct ( self , dataset ) : [EOL] raise NotImplementedError [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] [comment] [EOL] class SvdAposteriori ( AposterioriProcessing ) : [EOL] def output_directory ( self ) : [EOL] return os . path . join ( [string] , [string] , str ( self . dim ) ) [EOL] [EOL] def output_extention ( self ) : [EOL] return [string] [EOL] [EOL] def reconstruct ( self , dataset ) : [EOL] avk_U = dataset [ [string] ] [ ... ] [EOL] avk_s = dataset [ [string] ] [ ... ] [EOL] avk_Vh = dataset [ [string] ] [ ... ] [EOL] events = dataset . dimensions [ [string] ] . size [EOL] grid_levels = dataset . dimensions [ [string] ] . size [EOL] species = dataset . dimensions [ [string] ] . size [EOL] result = np . ndarray ( shape = ( events , species , species , grid_levels , grid_levels ) , dtype = np . float64 ) [EOL] for event in range ( events ) : [EOL] for row in range ( species ) : [EOL] for column in range ( species ) : [EOL] U = avk_U [ event , row , column , : ] [EOL] s = avk_s [ event , row , column , : ] [EOL] Vh = avk_Vh [ event , row , column , : ] [EOL] sigma = np . diag ( s ) [EOL] result [ event , row , column ] = np . dot ( U , np . dot ( sigma , Vh ) ) [EOL] return result [EOL] [EOL] [comment] [EOL] [EOL] [EOL] class EigenAposteriori ( AposterioriProcessing ) : [EOL] def output_directory ( self ) : [EOL] return os . path . join ( [string] , [string] , str ( self . dim ) ) [EOL] [EOL] def output_extention ( self ) : [EOL] return [string] [EOL] [EOL] def reconstruct ( self , dataset ) : [EOL] avk_Q = dataset [ [string] ] [ ... ] [EOL] avk_s = dataset [ [string] ] [ ... ] [EOL] events = dataset . dimensions [ [string] ] . size [EOL] grid_levels = dataset . dimensions [ [string] ] . size [EOL] species = dataset . dimensions [ [string] ] . size [EOL] result = np . ndarray ( shape = ( events , species , species , grid_levels , grid_levels ) , dtype = np . float64 ) [EOL] for event in range ( events ) : [EOL] for row in range ( species ) : [EOL] for column in range ( species ) : [EOL] Q = avk_Q [ event , row , column , : ] [EOL] s = avk_s [ event , row , column , : ] [EOL] Q_inv = np . linalg . pinv ( Q ) [EOL] sigma = np . diag ( s ) [EOL] result [ event , row , column ] = Q . dot ( sigma ) . dot ( Q_inv ) [EOL] return result [EOL] [EOL] [EOL] @ requires ( ReadFile ) class DirectAposteriori ( AposterioriProcessing ) : [EOL] def output_directory ( self ) : [EOL] return os . path . join ( [string] , [string] ) [EOL] [EOL] def output_extention ( self ) : [EOL] return [string] [EOL] [EOL] def reconstruct ( self , dataset ) : [EOL] return dataset [ [string] ] [ ... ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[iasi.aposteriori.AposterioriProcessing]$ 0 0 0 0 0 0 0 $typing.Type[iasi.aposteriori.AposterioriProcessing]$ 0 0 0 0 0 0 0 0 0 0 $typing.Type[iasi.aposteriori.AposterioriProcessing]$ 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $builtins.int$ 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 0 $builtins.int$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $builtins.int$ 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 $typing.Any$ 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 $builtins.float$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 $builtins.int$ 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 $builtins.int$ 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $builtins.int$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $builtins.int$ 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $numpy.ndarray$ 0 0 0 $netCDF4.Dataset$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $netCDF4.Dataset$ 0 0 0 $typing.Any$ 0 $netCDF4.Dataset$ 0 0 0 0 0 0 0 $typing.Any$ 0 $netCDF4.Dataset$ 0 0 0 0 0 0 0 $typing.Any$ 0 $netCDF4.Dataset$ 0 0 0 0 0 0 0 0 0 $netCDF4.Dataset$ 0 0 0 0 0 0 0 0 0 0 $netCDF4.Dataset$ 0 0 0 0 0 0 0 0 0 0 $netCDF4.Dataset$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $netCDF4.Dataset$ 0 0 0 $typing.Any$ 0 $netCDF4.Dataset$ 0 0 0 0 0 0 0 $typing.Any$ 0 $netCDF4.Dataset$ 0 0 0 0 0 0 0 0 0 $netCDF4.Dataset$ 0 0 0 0 0 0 0 0 0 0 $netCDF4.Dataset$ 0 0 0 0 0 0 0 0 0 0 $netCDF4.Dataset$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $netCDF4.Dataset$ 0 0 0 0 $netCDF4.Dataset$ 0 0 0 0 0 0 0
from typing import Dict , List , Type , Any [EOL] import logging [EOL] import iasi [EOL] import netCDF4 [EOL] import builtins [EOL] import typing [EOL] import logging [EOL] import os [EOL] import re [EOL] [EOL] import luigi [EOL] from luigi import Config [EOL] from luigi . util import common_params , inherits , requires [EOL] from netCDF4 import Dataset , Group , Variable [EOL] [EOL] import iasi [EOL] from iasi . util import CustomTask , child_groups_of , child_variables_of [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def filename_by ( path ) : [EOL] _ , file = os . path . split ( path ) [EOL] filename , _ = os . path . splitext ( file ) [EOL] return filename [EOL] [EOL] [EOL] class ReadFile ( luigi . ExternalTask ) : [EOL] [docstring] [EOL] file = luigi . Parameter ( ) [EOL] [EOL] def output ( self ) : [EOL] return luigi . LocalTarget ( self . file ) [EOL] [EOL] [EOL] @ requires ( ReadFile ) class FileTask ( CustomTask ) : [EOL] [docstring] [EOL] dst = luigi . Parameter ( ) [EOL] log_file = luigi . BoolParameter ( significant = False , default = False ) [EOL] [EOL] def output ( self ) : [EOL] filename , extension = os . path . splitext ( self . file ) [EOL] _ , filename = os . path . split ( filename ) [EOL] file = filename + ( self . output_extension ( ) [EOL] if self . output_extension ( ) else extension ) [EOL] path = os . path . join ( self . dst , self . output_directory ( ) , file ) [EOL] return luigi . LocalTarget ( path = path ) [EOL] [EOL] def output_directory ( self ) : [EOL] [docstring] [EOL] raise NotImplementedError [EOL] [EOL] def output_extension ( self ) : [EOL] [docstring] [EOL] return None [EOL] [EOL] @ luigi . Task . event_handler ( luigi . Event . START ) def callback_start ( self ) : [EOL] if hasattr ( self , [string] ) and self . log_file : [EOL] [comment] [EOL] filename = filename_by ( self . file ) [EOL] file = os . path . join ( self . dst , self . output_directory ( ) , filename + [string] ) [EOL] [comment] [EOL] os . makedirs ( os . path . join ( self . dst , self . output_directory ( ) ) , exist_ok = True ) [EOL] self . log_handler = logging . FileHandler ( file , mode = [string] ) [EOL] self . log_handler . setFormatter ( iasi . log_formatter ) [EOL] logging . getLogger ( ) . addHandler ( self . log_handler ) [EOL] [EOL] @ luigi . Task . event_handler ( luigi . Event . PROCESSING_TIME ) def callback_execution_time ( self , execution_time ) : [EOL] logger . info ( [string] , type ( self ) . __name__ , str ( execution_time ) ) [EOL] [EOL] @ luigi . Task . event_handler ( luigi . Event . SUCCESS ) def callback_success ( self ) : [EOL] logger . info ( [string] , type ( self ) . __name__ ) [EOL] if hasattr ( self , [string] ) : [EOL] self . _remove_log_hander ( ) [EOL] [EOL] @ luigi . Task . event_handler ( luigi . Event . FAILURE ) def callback_failure ( self , error ) : [EOL] logger . error ( [string] , type ( self ) . __name__ ) [EOL] logger . error ( [string] , error ) [EOL] if hasattr ( self , [string] ) : [EOL] self . _remove_log_hander ( ) [EOL] [EOL] def _remove_log_hander ( self ) : [EOL] if hasattr ( self , [string] ) : [EOL] self . log_handler . close ( ) [EOL] logging . getLogger ( ) . removeHandler ( self . log_handler ) [EOL] [EOL] [EOL] @ requires ( ReadFile ) class CopyNetcdfFile ( FileTask ) : [EOL] [docstring] [EOL] format = luigi . Parameter ( default = [string] ) [EOL] [EOL] mapping = { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] } [EOL] [EOL] def run ( self ) : [EOL] input = Dataset ( self . input ( ) . path , [string] ) [EOL] with self . output ( ) . temporary_path ( ) as target : [EOL] output = Dataset ( target , [string] , format = self . format ) [EOL] self . copy_dimensions ( input , output ) [EOL] self . copy_variables ( input , output ) [EOL] input . close ( ) [EOL] output . close ( ) [EOL] [EOL] def copy_dimensions ( self , input , output , recursive = True ) : [EOL] [comment] [EOL] if recursive : [EOL] for group in child_groups_of ( input ) : [EOL] target_group = output . createGroup ( group . path ) [EOL] for name , dim in group . dimensions . items ( ) : [EOL] target_group . createDimension ( name , len ( dim ) if not dim . isunlimited ( ) else None ) [EOL] [comment] [EOL] else : [EOL] for name , dim in input . dimensions . items ( ) : [EOL] output . createDimension ( name , len ( dim ) if not dim . isunlimited ( ) else None ) [EOL] [EOL] def copy_variable ( self , target , var , path = None , compressed = False ) : [EOL] if path : [EOL] out_var = target . createVariable ( path , var . datatype , var . dimensions , zlib = compressed ) [EOL] else : [EOL] out_var = target . createVariable ( var . name , var . datatype , var . dimensions , zlib = compressed ) [EOL] out_var . setncatts ( { k : var . getncattr ( k ) for k in var . ncattrs ( ) } ) [EOL] out_var [ : ] = var [ : ] [EOL] [EOL] def copy_variables ( self , input , output , exclusion_pattern = None ) : [EOL] input_variables = list ( child_variables_of ( input ) ) [EOL] counter = [number] [EOL] for group , var in input_variables : [EOL] counter += [number] [EOL] if group . path == [string] : [EOL] path = var . name [EOL] else : [EOL] path = f'{ group . path } [string] { var . name }' [EOL] if exclusion_pattern and re . match ( exclusion_pattern , path ) : [EOL] continue [EOL] message = f' [string] { counter } [string] { len ( input_variables ) } [string] { path }' [EOL] self . set_status_message ( message ) [EOL] logger . info ( message ) [EOL] self . copy_variable ( output , var , self . mapping . get ( var . name , path ) ) [EOL] [EOL] [EOL] class MoveVariables ( CopyNetcdfFile ) : [EOL] [docstring] [EOL] [EOL] def output_directory ( self ) : [EOL] return [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[iasi.file.CopyNetcdfFile]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $None$ 0 0 0 $netCDF4.Dataset$ 0 $netCDF4.Dataset$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $netCDF4.Dataset$ 0 0 0 $typing.Any$ 0 $netCDF4.Dataset$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $netCDF4.Dataset$ 0 0 0 0 0 0 0 0 $netCDF4.Dataset$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $netCDF4.Variable$ 0 0 0 $netCDF4.Dataset$ 0 $netCDF4.Variable$ 0 $builtins.str$ 0 0 0 $builtins.bool$ 0 0 0 0 0 0 $builtins.str$ 0 0 $typing.Any$ 0 $netCDF4.Dataset$ 0 0 0 $builtins.str$ 0 $netCDF4.Variable$ 0 0 0 $netCDF4.Variable$ 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 $typing.Any$ 0 $netCDF4.Dataset$ 0 0 0 $netCDF4.Variable$ 0 0 0 $netCDF4.Variable$ 0 0 0 $netCDF4.Variable$ 0 0 0 0 0 $builtins.bool$ 0 0 $typing.Any$ 0 0 0 0 0 0 $netCDF4.Variable$ 0 0 0 0 0 0 0 0 $netCDF4.Variable$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $netCDF4.Variable$ 0 0 0 0 0 0 $None$ 0 0 0 $netCDF4.Dataset$ 0 $netCDF4.Dataset$ 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 $netCDF4.Dataset$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.int$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $netCDF4.Dataset$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Dict [EOL] import numpy [EOL] import netCDF4 [EOL] import builtins [EOL] import typing [EOL] import os [EOL] [EOL] import numpy as np [EOL] from netCDF4 import Dataset , Group , Variable [EOL] from iasi . util import dimensions_of [EOL] [EOL] [EOL] class QuadrantException ( Exception ) : [EOL] pass [EOL] [EOL] [EOL] class Quadrant : [EOL] [docstring] [EOL] @ classmethod def for_assembly ( cls , gas , var_name , var ) : [EOL] assert var_name in [ [string] , [string] , [string] ] [EOL] dimensions = dimensions_of ( var ) [EOL] events = dimensions [ [string] ] [EOL] levels = dimensions [ [string] ] [EOL] [comment] [EOL] if gas == [string] or gas == [string] : [EOL] return cls ( events , levels ) [EOL] if gas == [string] or gas == [string] : [EOL] [comment] [EOL] if var_name == [string] : [EOL] return AssembleTwoQuadrants ( events , levels ) [EOL] [comment] [EOL] else : [EOL] return AssembleFourQuadrants ( events , levels ) [EOL] raise QuadrantException ( f' [string] { gas }' ) [EOL] [EOL] @ classmethod def for_disassembly ( cls , gas , var_name , var ) : [EOL] [comment] [EOL] assert var_name in [ [string] , [string] , [string] ] [EOL] dimensions = dimensions_of ( var ) [EOL] events = dimensions [ [string] ] [EOL] if [string] in dimensions . keys ( ) : [EOL] levels = dimensions [ [string] ] [EOL] else : [EOL] levels = int ( dimensions [ [string] ] / [number] ) [EOL] if gas == [string] or gas == [string] : [EOL] return cls ( events , levels ) [EOL] if gas == [string] or gas == [string] : [EOL] [comment] [EOL] if var_name == [string] : [EOL] return DisassembleTwoQuadrants ( events , levels ) [EOL] [comment] [EOL] else : [EOL] return DisassembleFourQuadrants ( events , levels ) [EOL] raise QuadrantException ( f' [string] { gas }' ) [EOL] [EOL] def __init__ ( self , events , grid_levels = [number] ) : [EOL] self . events = events [EOL] self . grid_levels = grid_levels [EOL] [EOL] def transform ( self , array , levels ) : [EOL] return array [ : levels , : levels ] [EOL] [EOL] def transformed_shape ( self ) : [EOL] return ( self . events , self . grid_levels , self . grid_levels ) [EOL] [EOL] def assign_disassembly ( self , of , to , l ) : [EOL] to [ : l , : l ] = of [ : l , : l ] [EOL] [EOL] def upper_and_lower_dimension ( self ) : [EOL] return ( [string] , [string] ) [EOL] [EOL] def create_variable ( self , dataset , path ) : [EOL] return dataset . createVariable ( path , [string] , ( [string] , [string] , [string] ) ) [EOL] [EOL] [EOL] class AssembleTwoQuadrants ( Quadrant ) : [EOL] [EOL] def transform ( self , array , levels ) : [EOL] return np . block ( [ [ array [ [number] , : levels , : levels ] ] , [ array [ [number] , : levels , : levels ] ] ] ) [EOL] [EOL] def transformed_shape ( self ) : [EOL] return ( self . events , self . grid_levels * [number] , self . grid_levels ) [EOL] [EOL] def upper_and_lower_dimension ( self ) : [EOL] return ( [string] , [string] ) [EOL] [EOL] [EOL] class DisassembleTwoQuadrants ( Quadrant ) : [EOL] [EOL] def transform ( self , array , l ) : [EOL] return np . array ( [ array [ : l , : l ] , array [ self . grid_levels : self . grid_levels + l , : l ] ] ) [EOL] [EOL] def transformed_shape ( self ) : [EOL] return ( self . events , [number] , self . grid_levels , self . grid_levels ) [EOL] [EOL] def assign_disassembly ( self , of , to , l ) : [EOL] to [ [number] , : l , : l ] = of [ : l , : l ] [EOL] to [ [number] , : l , : l ] = of [ l : [number] * l , : l ] [EOL] [EOL] def create_variable ( self , dataset , path ) : [EOL] return dataset . createVariable ( path , [string] , ( [string] , [string] , [string] , [string] ) ) [EOL] [EOL] [EOL] class AssembleFourQuadrants ( Quadrant ) : [EOL] [EOL] def transform ( self , array , levels ) : [EOL] return np . block ( [ [ array [ [number] , [number] , : levels , : levels ] , array [ [number] , [number] , : levels , : levels ] ] , [ array [ [number] , [number] , : levels , : levels ] , array [ [number] , [number] , : levels , : levels ] ] ] ) [EOL] [EOL] def transformed_shape ( self ) : [EOL] return ( self . events , self . grid_levels * [number] , self . grid_levels * [number] ) [EOL] [EOL] def upper_and_lower_dimension ( self ) : [EOL] return ( [string] , [string] ) [EOL] [EOL] [EOL] class DisassembleFourQuadrants ( Quadrant ) : [EOL] [EOL] def transform ( self , a , l ) : [EOL] d = self . grid_levels [EOL] return np . array ( [ [ a [ [number] : l + [number] , [number] : l + [number] ] , a [ d : d + l , [number] : l + [number] ] ] , [ a [ [number] : l + [number] , d : d + l ] , a [ d : d + l , d : d + l ] ] ] ) [EOL] [EOL] def transformed_shape ( self ) : [EOL] return ( self . events , [number] , [number] , self . grid_levels , self . grid_levels ) [EOL] [EOL] def assign_disassembly ( self , reconstructed , result , l ) : [EOL] result [ [number] , [number] , : l , : l ] = reconstructed [ : l , : l ] [EOL] result [ [number] , [number] , : l , : l ] = reconstructed [ : l , l : [number] * l ] [EOL] result [ [number] , [number] , : l , : l ] = reconstructed [ l : [number] * l , : l ] [EOL] result [ [number] , [number] , : l , : l ] = reconstructed [ l : [number] * l , l : [number] * l ] [EOL] [EOL] def create_variable ( self , dataset , path ) : [EOL] return dataset . createVariable ( path , [string] , ( [string] , [string] , [string] , [string] , [string] ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $netCDF4.Variable$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 $netCDF4.Variable$ 0 0 $typing.Any$ 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 $typing.Any$ 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $netCDF4.Variable$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 $netCDF4.Variable$ 0 0 $typing.Any$ 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 $builtins.int$ 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $typing.Any$ 0 $builtins.int$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $typing.Any$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ma.MaskedArray$ 0 $builtins.int$ 0 0 0 0 $numpy.ma.MaskedArray$ 0 0 $builtins.int$ 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $netCDF4.Variable$ 0 0 0 $netCDF4.Dataset$ 0 $builtins.str$ 0 0 0 0 $netCDF4.Dataset$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ma.MaskedArray$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $numpy.ma.MaskedArray$ 0 0 0 0 $builtins.int$ 0 0 $builtins.int$ 0 0 0 0 $numpy.ma.MaskedArray$ 0 0 0 0 $builtins.int$ 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ma.MaskedArray$ 0 $builtins.int$ 0 0 0 0 0 0 $numpy.ma.MaskedArray$ 0 0 $numpy.ma.MaskedArray$ 0 0 $builtins.int$ 0 0 $builtins.int$ 0 0 $numpy.ma.MaskedArray$ 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $netCDF4.Variable$ 0 0 0 $netCDF4.Dataset$ 0 $builtins.str$ 0 0 0 0 $netCDF4.Dataset$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ma.MaskedArray$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $numpy.ma.MaskedArray$ 0 0 0 0 0 0 $builtins.int$ 0 0 $builtins.int$ 0 0 $numpy.ma.MaskedArray$ 0 0 0 0 0 0 $builtins.int$ 0 0 $builtins.int$ 0 0 0 0 $numpy.ma.MaskedArray$ 0 0 0 0 0 0 $builtins.int$ 0 0 $builtins.int$ 0 0 $numpy.ma.MaskedArray$ 0 0 0 0 0 0 $builtins.int$ 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ma.MaskedArray$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ma.MaskedArray$ 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 $numpy.ma.MaskedArray$ 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 $numpy.ma.MaskedArray$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 $numpy.ma.MaskedArray$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $netCDF4.Variable$ 0 0 0 $netCDF4.Dataset$ 0 $builtins.str$ 0 0 0 0 $netCDF4.Dataset$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] import logging [EOL] import logging as _logging [EOL] [EOL] from iasi . composition import Composition [EOL] from iasi . compression import CompressDataset , DecompressDataset [EOL] [EOL] _log_format = [string] [EOL] _date_format = [string] [EOL] log_formatter = _logging . Formatter ( _log_format , _date_format ) [EOL] _logging . basicConfig ( level = _logging . INFO , format = _log_format , datefmt = _date_format ) [EOL] _logging . getLogger ( [string] ) . setLevel ( _logging . WARNING ) [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $logging.Formatter$ 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] import numpy [EOL] import builtins [EOL] from functools import partial [EOL] [EOL] import numpy as np [EOL] [EOL] [EOL] class Covariance : [EOL] def __init__ ( self , nol , alt ) : [EOL] [docstring] [EOL] [EOL] self . nol = nol [EOL] self . alt = alt [EOL] [EOL] def gaussian ( self , x , mu , sig ) : [EOL] [docstring] [EOL] return np . exp ( - ( ( x - mu ) * ( x - mu ) ) / ( [number] * sig * sig ) ) [EOL] [EOL] def traf ( self ) : [EOL] [docstring] [EOL] return np . block ( [ [ np . identity ( self . nol ) * [number] , np . identity ( self . nol ) * [number] ] , [ - np . identity ( self . nol ) , np . identity ( self . nol ) ] ] ) [EOL] [EOL] def assumed_covariance ( self , species = [number] , w1 = [number] , w2 = [number] , correlation_length = [number] ) : [EOL] [docstring] [EOL] [comment] [EOL] assert ( species >= [number] ) and ( species <= [number] ) [EOL] result = np . zeros ( ( species * self . nol , species * self . nol ) ) [EOL] for i in range ( self . nol ) : [EOL] for j in range ( self . nol ) : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] result [ i , j ] = w1 * self . gaussian ( self . alt [ i ] , self . alt [ j ] , correlation_length ) [EOL] if species == [number] : [EOL] [comment] [EOL] [comment] [EOL] result [ i + self . nol , j + self . nol ] = w2 * self . gaussian ( self . alt [ i ] , self . alt [ j ] , correlation_length ) [EOL] return result [EOL] [EOL] def apriori_covariance ( self ) : [EOL] [docstring] [EOL] P = self . traf ( ) [EOL] return np . linalg . inv ( P ) @ self . apriori_covariance_traf ( ) @ np . linalg . inv ( P . T ) [EOL] [EOL] def type1_of ( self , matrix ) : [EOL] [docstring] [EOL] P = self . traf ( ) [EOL] return P @ matrix @ np . linalg . inv ( P ) [EOL] [EOL] def c_by_type1 ( self , A_ ) : [EOL] return np . block ( [ [ A_ [ self . nol : , self . nol : ] , np . zeros ( ( self . nol , self . nol ) ) ] , [ - A_ [ self . nol : , : self . nol ] , np . identity ( self . nol ) ] ] ) [EOL] [EOL] def c_by_avk ( self , avk ) : [EOL] A_ = self . type1_of ( avk ) [EOL] return self . c_by_type1 ( A_ ) [EOL] [EOL] def type2_of ( self , matrix ) : [EOL] [docstring] [EOL] A_ = self . type1_of ( matrix ) [EOL] C = self . c_by_type1 ( A_ ) [EOL] return C @ A_ [EOL] [EOL] def smoothing_error ( self , actual_matrix , to_compare , ** kwargs ) : [EOL] [docstring] [EOL] return ( actual_matrix - to_compare ) @ self . assumed_covariance ( ** kwargs ) @ ( actual_matrix - to_compare ) . T [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List , Type [EOL] import logging [EOL] import typing [EOL] import iasi [EOL] import glob [EOL] import logging [EOL] import os [EOL] from math import ceil [EOL] from typing import Dict , List , Tuple [EOL] [EOL] import luigi [EOL] import numpy as np [EOL] from luigi . util import common_params , inherits , requires [EOL] from netCDF4 import Dataset , Group , Variable [EOL] from scipy import linalg [EOL] [EOL] from iasi . composition import Composition , CompositionException [EOL] from iasi . decomposition import Decomposition , DecompositionException [EOL] from iasi . file import CopyNetcdfFile , MoveVariables , ReadFile [EOL] from iasi . quadrant import Quadrant [EOL] from iasi . util import child_groups_of , child_variables_of [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class CompressionParams ( luigi . Config ) : [EOL] threshold = luigi . FloatParameter ( default = None ) [EOL] [EOL] [EOL] class CompressDataset ( CompressionParams , CopyNetcdfFile ) : [EOL] [EOL] def requires ( self ) : [EOL] return MoveVariables ( file = self . file , dst = self . dst , log_file = self . log_file ) [EOL] [EOL] def output_directory ( self ) : [EOL] if self . threshold : [EOL] return os . path . join ( [string] , str ( self . threshold ) ) [EOL] return [string] [EOL] [EOL] def run ( self ) : [EOL] input = Dataset ( self . input ( ) . path ) [EOL] with self . output ( ) . temporary_path ( ) as target : [EOL] output = Dataset ( target , [string] , format = self . format ) [EOL] self . copy_dimensions ( input , output , recursive = False ) [EOL] [comment] [EOL] self . copy_variables ( input , output , exclusion_pattern = [string] ) [EOL] [comment] [EOL] levels = input [ [string] ] [ ... ] [EOL] dim_levels = input . dimensions [ [string] ] . size [EOL] dim_species = input . dimensions [ [string] ] . size [EOL] output . createGroup ( [string] ) [EOL] output . createDimension ( [string] , dim_levels * dim_species ) [EOL] variables = list ( child_variables_of ( input [ [string] ] ) ) [EOL] counter = [number] [EOL] for group , var in variables : [EOL] message = f' [string] { counter } [string] { len ( variables ) } [string] { group . path } [string] { var . name }' [EOL] self . set_status_message ( message ) [EOL] progress = int ( ( counter / len ( variables ) ) * [number] ) [EOL] self . set_progress_percentage ( progress ) [EOL] try : [EOL] dec = Decomposition . factory ( group , var , self . threshold ) [EOL] logger . info ( f' [string] { group . path } [string] { var . name }' ) [EOL] dec . decompose ( output , levels ) [EOL] except DecompositionException : [EOL] logger . debug ( f'{ group . path } [string] { var . name } [string] ' ) [EOL] self . copy_variable ( output , var , f'{ group . path } [string] { var . name }' ) [EOL] counter += [number] [EOL] input . close ( ) [EOL] output . close ( ) [EOL] [EOL] [EOL] class DecompressDataset ( CompressionParams , CopyNetcdfFile ) : [EOL] [EOL] compress_upstream = luigi . BoolParameter ( default = False ) [EOL] [EOL] def requires ( self ) : [EOL] if self . compress_upstream : [EOL] return CompressDataset ( file = self . file , dst = self . dst , threshold = self . threshold , log_file = self . log_file ) [EOL] return ReadFile ( file = self . file ) [EOL] [EOL] def output_directory ( self ) : [EOL] if self . threshold : [EOL] return os . path . join ( [string] , str ( self . threshold ) ) [EOL] return [string] [EOL] [EOL] def run ( self ) : [EOL] input = Dataset ( self . input ( ) . path ) [EOL] with self . output ( ) . temporary_path ( ) as target : [EOL] output = Dataset ( target , [string] , format = self . format ) [EOL] self . copy_dimensions ( input , output , recursive = False ) [EOL] [comment] [EOL] self . copy_variables ( input , output , exclusion_pattern = [string] ) [EOL] levels = input [ [string] ] [ ... ] [EOL] groups = list ( child_groups_of ( input [ [string] ] ) ) [EOL] counter = [number] [EOL] for group in groups : [EOL] counter += [number] [EOL] message = f' [string] { counter } [string] { len ( groups ) } [string] { group . path }' [EOL] self . set_status_message ( message ) [EOL] self . set_progress_percentage ( int ( counter / len ( groups ) * [number] ) ) [EOL] logger . info ( message ) [EOL] try : [EOL] comp = Composition . factory ( group ) [EOL] comp . reconstruct ( levels , output ) [EOL] except CompositionException : [EOL] for var in group . variables . values ( ) : [EOL] self . copy_variable ( output , var , path = f'{ group . path } [string] { var . name }' ) [EOL] input . close ( ) [EOL] output . close ( ) [EOL] [EOL] [EOL] class SelectSingleVariable ( CompressionParams , CopyNetcdfFile ) : [EOL] gas = luigi . Parameter ( default = [string] ) [EOL] variable = luigi . Parameter ( ) [EOL] ancestor = luigi . Parameter ( default = [string] ) [EOL] [EOL] def requires ( self ) : [EOL] if self . ancestor == [string] : [EOL] return MoveVariables ( dst = self . dst , file = self . file ) [EOL] if self . ancestor == [string] : [EOL] return CompressDataset ( dst = self . dst , file = self . file , threshold = self . threshold , log_file = self . log_file ) [EOL] if self . ancestor == [string] : [EOL] return DecompressDataset ( dst = self . dst , file = self . file , threshold = self . threshold , log_file = self . log_file , compress_upstream = True ) [EOL] raise ValueError ( f' [string] { self . ancestor } [string] ' ) [EOL] [EOL] def output_directory ( self ) : [EOL] var = f'{ self . gas } [string] { self . variable }' if self . gas else self . variable [EOL] if self . ancestor == [string] : [EOL] return os . path . join ( [string] , [string] , var , str ( self . threshold ) ) [EOL] if self . ancestor == [string] : [EOL] return os . path . join ( [string] , [string] , var , str ( self . threshold ) ) [EOL] if self . ancestor == [string] : [EOL] return os . path . join ( [string] , [string] , var , str ( self . threshold ) ) [EOL] raise ValueError ( f' [string] { self . ancestor }' ) [EOL] [EOL] def run ( self ) : [EOL] input = Dataset ( self . input ( ) . path , [string] ) [EOL] with self . output ( ) . temporary_path ( ) as target : [EOL] output = Dataset ( target , [string] , format = self . format ) [EOL] self . copy_dimensions ( input , output ) [EOL] [comment] [EOL] if self . gas : [EOL] var_path = os . path . join ( [string] , self . gas , self . variable ) [EOL] else : [EOL] var_path = self . variable [EOL] attribute = input [ var_path ] [EOL] if isinstance ( attribute , Group ) : [EOL] for var in attribute . variables . values ( ) : [EOL] self . copy_variable ( output , var , f'{ attribute . path } [string] { var . name }' , compressed = True ) [EOL] else : [EOL] assert isinstance ( attribute , Variable ) [EOL] self . copy_variable ( output , attribute , var_path , compressed = True ) [EOL] [EOL] [EOL] class CompressDateRange ( luigi . WrapperTask ) : [EOL] [EOL] date_interval = luigi . DateIntervalParameter ( ) [EOL] src = luigi . Parameter ( ) [EOL] dst = luigi . Parameter ( ) [EOL] [EOL] def requires ( self ) : [EOL] files = [ ] [EOL] for date in self . date_interval : [EOL] pattern = f" [string] { date . strftime ( [string] ) } [string] " [EOL] path = os . path . join ( self . src , pattern ) [EOL] files += glob . glob ( path ) [EOL] for file in files : [EOL] yield CompressDataset ( file = file , dst = self . dst , log_file = True )	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[iasi.compression.CompressionParams]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 $builtins.str$ 0 0 0 0 $builtins.int$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 $builtins.int$ 0 0 0 0 $builtins.int$ 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[iasi.compression.DecompressDataset]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 $builtins.int$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.int$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 $logging.Logger$ 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[iasi.compression.SelectSingleVariable]$ 0 0 0 0 0 0 0 0 0 0 $typing.Type[iasi.compression.SelectSingleVariable]$ 0 0 0 0 0 0 0 $typing.Type[iasi.compression.SelectSingleVariable]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[iasi.compression.CompressDateRange]$ 0 0 0 0 0 0 0 $typing.Type[iasi.compression.CompressDateRange]$ 0 0 0 0 0 0 0 $typing.Type[iasi.compression.CompressDateRange]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , Any , List , Union , Set [EOL] import analysis [EOL] import typing [EOL] import unittest [EOL] [EOL] import pandas as pd [EOL] [EOL] from analysis . data import GeographicArea , features [EOL] from analysis . scaler import SpatialWaterVapourScaler [EOL] from analysis . search import GridSearchHDBSCAN , GridSearchDBSCAN [EOL] from analysis . aggregation import AggregateClusterStatistics [EOL] from sklearn . model_selection import ParameterGrid [EOL] import luigi [EOL] [EOL] file = [string] [EOL] [EOL] [EOL] class TestData ( unittest . TestCase ) : [EOL] [EOL] def test_import ( self ) : [EOL] area = GeographicArea ( lat = ( - [number] , [number] ) , lon = ( - [number] , [number] ) ) [EOL] df = area . import_dataset ( file ) [EOL] self . assertEqual ( df . shape , ( [number] , [number] ) ) [EOL] [comment] [EOL] self . assertGreaterEqual ( df . lat . min ( ) , - [number] ) [EOL] self . assertLessEqual ( df . lat . max ( ) , [number] ) [EOL] self . assertGreaterEqual ( df . lon . min ( ) , - [number] ) [EOL] self . assertLessEqual ( df . lon . max ( ) , [number] ) [EOL] [EOL] [EOL] class TestScaler ( unittest . TestCase ) : [EOL] [EOL] def test_latitude_scaling ( self ) : [EOL] df = pd . DataFrame ( { [string] : [ [number] , [number] ] , [string] : [ [number] , - [number] ] , [string] : [ [number] , [number] ] , [string] : [ [number] , [number] ] } ) [EOL] self . assertListEqual ( list ( df . columns ) , features ) [EOL] scaler = SpatialWaterVapourScaler ( delD = [number] , H2O = [number] , km = [number] ) [EOL] X_ = scaler . fit_transform ( df [ features ] . values ) [EOL] [EOL] [comment] [EOL] self . assertAlmostEqual ( X_ [ [number] , [number] ] * scaler . km , [number] , places = [number] ) [EOL] self . assertAlmostEqual ( X_ [ [number] , [number] ] * scaler . km , - [number] , places = [number] ) [EOL] [comment] [EOL] self . assertAlmostEqual ( X_ [ [number] , [number] ] * scaler . km , [number] * [number] ) [EOL] [EOL] [EOL] class TestGridSearch ( unittest . TestCase ) : [EOL] [EOL] def test_hdbscan ( self ) : [EOL] task = GridSearchHDBSCAN ( file = file , dst = [string] , force_upstream = True ) [EOL] assert luigi . build ( [ task ] , local_scheduler = True ) [EOL] df = pd . read_csv ( task . output ( ) . path ) [EOL] columns = set ( df . columns ) [EOL] expected = { [string] , [string] , [string] , [string] , [string] } [EOL] self . assertTrue ( expected <= columns ) [EOL] self . assertEqual ( df . shape [ [number] ] , [number] ) [EOL] [EOL] def test_dbscan ( self ) : [EOL] task = GridSearchDBSCAN ( file = file , dst = [string] , force_upstream = True ) [EOL] assert luigi . build ( [ task ] , local_scheduler = True ) [EOL] df = pd . read_csv ( task . output ( ) . path ) [EOL] columns = set ( df . columns ) [EOL] expected = { [string] , [string] , [string] , [string] , [string] } [EOL] self . assertTrue ( expected <= columns ) [EOL] self . assertEqual ( df . shape , ( [number] , [number] ) ) [EOL] [EOL] def test_aggregation ( self ) : [EOL] grid_params = { [string] : [ [number] ] , [string] : [ [number] ] , [string] : [ [number] ] , [string] : [ [number] ] , [string] : [ [number] , [number] ] } [EOL] task = AggregateClusterStatistics ( grid_params , file_pattern = [string] , dst = [string] , clustering_algorithm = [string] , force_upstream = True ) [EOL] assert luigi . build ( [ task ] , local_scheduler = True ) [EOL] with task . output ( ) . open ( ) as out : [EOL] df = pd . read_csv ( out ) [EOL] self . assertEqual ( df . shape , ( [number] , [number] ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $analysis.data.GeographicArea$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $analysis.data.GeographicArea$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $analysis.scaler.SpatialWaterVapourScaler$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $analysis.scaler.SpatialWaterVapourScaler$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $analysis.scaler.SpatialWaterVapourScaler$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $analysis.scaler.SpatialWaterVapourScaler$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $analysis.scaler.SpatialWaterVapourScaler$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $analysis.search.GridSearchHDBSCAN$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $analysis.search.GridSearchHDBSCAN$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $analysis.search.GridSearchHDBSCAN$ 0 0 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 $typing.Any$ 0 $typing.Set[typing.Any]$ 0 0 $typing.Set[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Set[builtins.str]$ 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $analysis.search.GridSearchDBSCAN$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $analysis.search.GridSearchDBSCAN$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $analysis.search.GridSearchDBSCAN$ 0 0 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 $typing.Any$ 0 $typing.Set[typing.Any]$ 0 0 $typing.Set[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Set[builtins.str]$ 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Union[typing.List[builtins.float],typing.List[builtins.int]]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $analysis.aggregation.AggregateClusterStatistics$ 0 0 0 $typing.Dict[builtins.str,typing.Union[typing.List[builtins.float],typing.List[builtins.int]]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $analysis.aggregation.AggregateClusterStatistics$ 0 0 0 0 0 0 0 0 $analysis.aggregation.AggregateClusterStatistics$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] import builtins [EOL] import iasi [EOL] import pandas [EOL] import unittest [EOL] [EOL] import luigi [EOL] import numpy as np [EOL] import pandas as pd [EOL] from netCDF4 import Dataset [EOL] [EOL] import iasi . evaluation as eval [EOL] from iasi . evaluation import ( EvaluationCompressionSize , EvaluationErrorEstimation ) [EOL] [EOL] [EOL] class TestEvaluation ( unittest . TestCase ) : [EOL] [EOL] def test_compression_size ( self ) : [EOL] task = EvaluationCompressionSize ( file = [string] , dst = [string] , force = True , gases = [ [string] , [string] , [string] , [string] ] , variables = [ [string] , [string] , [string] ] , log_file = True ) [EOL] assert luigi . build ( [ task ] , local_scheduler = True ) [EOL] [EOL] @ classmethod def filter_by ( cls , df , var , level_of_interest , type = [number] , rc_error = True , threshold = None ) : [EOL] filtered = df [ ( df [ [string] ] == var ) & ( df [ [string] ] == level_of_interest ) & ( df [ [string] ] == type ) & ( df [ [string] ] == rc_error ) ] [EOL] if threshold : [EOL] filtered = filtered [ filtered [ [string] ] == threshold ] [EOL] assert len ( filtered ) > [number] [EOL] return filtered [EOL] [EOL] @ classmethod def setUpClass ( cls ) : [EOL] task = EvaluationErrorEstimation ( file = [string] , dst = [string] , force_upstream = True , gases = [ [string] , [string] , [string] , [string] ] , variables = [ [string] , [string] , [string] ] , log_file = True ) [EOL] assert luigi . build ( [ task ] , local_scheduler = True ) [EOL] with task . output ( ) . open ( ) as file : [EOL] df = pd . read_csv ( file ) [EOL] cls . wv = df [ df [ [string] ] == [string] ] [EOL] cls . ghg = df [ df [ [string] ] == [string] ] [EOL] cls . hno3 = df [ df [ [string] ] == [string] ] [EOL] cls . atm = df [ df [ [string] ] == [string] ] [EOL] [EOL] def test_water_vapour ( self ) : [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] err_wv_avk_type1 = self . filter_by ( self . wv , [string] , - [number] , rc_error = False ) [EOL] self . assertEqual ( len ( err_wv_avk_type1 ) , [number] , [string] ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] rc_err_wv_avk_type1 = self . filter_by ( self . wv , [string] , - [number] , rc_error = True , threshold = [number] ) [EOL] self . assertEqual ( len ( rc_err_wv_avk_type1 ) , [number] , [string] ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] err_wv_avk_type2 = self . filter_by ( self . wv , [string] , - [number] , rc_error = False , type = [number] ) [EOL] self . assertEqual ( len ( err_wv_avk_type2 ) , [number] , [string] ) [EOL] rc_err_wv_avk_type2 = self . filter_by ( self . wv , [string] , - [number] , rc_error = True , type = [number] , threshold = [number] ) [EOL] self . assertEqual ( len ( rc_err_wv_avk_type2 ) , [number] , [string] ) [EOL] self . assertLess ( rc_err_wv_avk_type1 . err . values [ [number] ] , rc_err_wv_avk_type2 . err . values [ [number] ] , [string] ) [EOL] self . assertLess ( err_wv_avk_type1 . err . values [ [number] ] , err_wv_avk_type2 . err . values [ [number] ] , [string] ) [EOL] [EOL] def test_greenhouse_gases_report_exists ( self ) : [EOL] self . assertGreater ( len ( self . ghg ) , [number] ) [EOL] [EOL] def test_nitrid_acid_report_exists ( self ) : [EOL] self . assertGreater ( len ( self . hno3 ) , [number] ) [EOL] [EOL] def test_atmospheric_temperature_report_exists ( self ) : [EOL] self . assertGreater ( len ( self . hno3 ) , [number] ) [EOL] [EOL] [EOL] class TestErrorEstimation ( unittest . TestCase ) : [EOL] [EOL] def test_correlation_lenght_is_consistent ( self ) : [EOL] [docstring] [EOL] [EOL] nc = Dataset ( [string] ) [EOL] alt = nc [ [string] ] [ ... ] [EOL] nol = nc [ [string] ] [ ... ] [EOL] alt_trop = nc [ [string] ] [ ... ] [EOL] [EOL] wv = eval . WaterVapour ( [string] , nol , alt , None , alt_trop = alt_trop ) [EOL] ghg = eval . GreenhouseGas ( [string] , nol , alt , alt_trop = alt_trop ) [EOL] hno3 = eval . NitridAcid ( [string] , nol , alt , alt_trop = alt_trop ) [EOL] tatm = eval . NitridAcid ( [string] , nol , alt , alt_trop = alt_trop ) [EOL] [EOL] self . assertTrue ( np . array_equal ( wv . sigma ( [number] ) , ghg . sigma ( [number] ) ) ) [EOL] self . assertTrue ( np . array_equal ( wv . sigma ( [number] ) , hno3 . sigma ( [number] ) ) ) [EOL] self . assertTrue ( np . array_equal ( wv . sigma ( [number] ) , tatm . sigma ( [number] ) ) ) [EOL] [EOL] def test_invalid_altitude ( self ) : [EOL] [comment] [EOL] [comment] [EOL] task = EvaluationErrorEstimation ( file = [string] , dst = [string] , force_upstream = True , gases = [ [string] , [string] , [string] , [string] ] , variables = [ [string] , [string] , [string] ] ) [EOL] assert luigi . build ( [ task ] , local_scheduler = True ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.evaluation.EvaluationCompressionSize$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.evaluation.EvaluationCompressionSize$ 0 0 0 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 $builtins.str$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0 $builtins.bool$ 0 0 0 $builtins.float$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 $builtins.float$ 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 $builtins.float$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $iasi.evaluation.EvaluationErrorEstimation$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.evaluation.EvaluationErrorEstimation$ 0 0 0 0 0 0 0 0 $iasi.evaluation.EvaluationErrorEstimation$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 $iasi.evaluation.WaterVapour$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 $iasi.evaluation.GreenhouseGas$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 $iasi.evaluation.NitridAcid$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 $iasi.evaluation.NitridAcid$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $iasi.evaluation.WaterVapour$ 0 0 0 0 0 0 $iasi.evaluation.GreenhouseGas$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.evaluation.WaterVapour$ 0 0 0 0 0 0 $iasi.evaluation.NitridAcid$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.evaluation.WaterVapour$ 0 0 0 0 0 0 $iasi.evaluation.NitridAcid$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.evaluation.EvaluationErrorEstimation$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.evaluation.EvaluationErrorEstimation$ 0 0 0 0 0 0 0
import iasi [EOL] import luigi [EOL] import unittest [EOL] from iasi import CompressDataset [EOL] [EOL] [EOL] class TestErrors ( unittest . TestCase ) : [EOL] [docstring] [EOL] [EOL] def test_svd_converges ( self ) : [EOL] task = CompressDataset ( file = [string] , force_upstream = True , dst = [string] ) [EOL] assert luigi . build ( [ task ] , local_scheduler = True ) [EOL] [EOL] def test_complex_eigenvectors ( self ) : [EOL] [docstring] [EOL] [EOL] task = CompressDataset ( file = [string] , force_upstream = True , dst = [string] ) [EOL] assert luigi . build ( [ task ] , local_scheduler = True ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.compression.CompressDataset$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.compression.CompressDataset$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.compression.CompressDataset$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.compression.CompressDataset$ 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] import iasi [EOL] import datetime [EOL] import unittest [EOL] [EOL] import luigi [EOL] import numpy as np [EOL] from netCDF4 import Dataset [EOL] [EOL] from iasi . compression import ( CompressDataset , CompressDateRange , DecompressDataset ) [EOL] [EOL] [EOL] class TestCompression ( unittest . TestCase ) : [EOL] [EOL] def test_dataset_compression ( self ) : [EOL] task = CompressDataset ( file = [string] , dst = [string] , force = True , threshold = [number] , log_file = False ) [EOL] assert luigi . build ( [ task ] , local_scheduler = True ) [EOL] with Dataset ( task . output ( ) . path ) as nc : [EOL] state = nc [ [string] ] [EOL] subgroups = state . groups . keys ( ) [EOL] self . assertListEqual ( list ( subgroups ) , [ [string] , [string] , [string] , [string] , [string] ] ) [EOL] [EOL] def test_dataset_decompression ( self ) : [EOL] task = DecompressDataset ( file = [string] , dst = [string] , force = True , log_file = False , compress_upstream = True ) [EOL] success = luigi . build ( [ task ] , local_scheduler = True ) [EOL] self . assertTrue ( success ) [EOL] [EOL] [EOL] class TestDateInterval ( unittest . TestCase ) : [EOL] [EOL] def test_date_range ( self ) : [EOL] [comment] [EOL] interval = luigi . date_interval . Custom . parse ( [string] ) [EOL] task = CompressDateRange ( date_interval = interval , dst = [string] , src = [string] ) [EOL] luigi . build ( [ task ] , local_scheduler = True ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.compression.CompressDataset$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.compression.CompressDataset$ 0 0 0 0 0 0 0 0 0 0 $iasi.compression.CompressDataset$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.compression.DecompressDataset$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $iasi.compression.DecompressDataset$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.compression.CompressDateRange$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.compression.CompressDateRange$ 0 0 0 0 0 0 0
from typing import Any , List [EOL] import typing [EOL] import iasi [EOL] import pandas [EOL] import unittest [EOL] [EOL] import luigi [EOL] import pandas as pd [EOL] [EOL] from iasi . aposteriori import DirectAposteriori , SvdAposteriori , EigenAposteriori [EOL] [EOL] [EOL] class TestAposterioriProcessing ( unittest . TestCase ) : [EOL] def test_uncompressed_retrieval ( self ) : [EOL] task = DirectAposteriori ( file = [string] , dst = [string] , force = True , log_file = False ) [EOL] success = luigi . build ( [ task ] , local_scheduler = True ) [EOL] self . assertTrue ( success ) [EOL] with task . output ( ) . open ( [string] ) as file : [EOL] df = pd . read_csv ( file ) [EOL] self . verify_results ( df ) [EOL] [EOL] [EOL] def verify_results ( self , df ) : [EOL] [comment] [EOL] [comment] [EOL] self . assertEqual ( df . shape , ( [number] , [number] ) ) [EOL] [comment] [EOL] column_names = list ( df ) [EOL] self . assertListEqual ( column_names , DirectAposteriori . calculated ) [EOL] [comment] [EOL] event = df . iloc [ [number] ] [EOL] self . assertAlmostEqual ( event [ [string] ] , [number] , delta = [number] ) [EOL] self . assertAlmostEqual ( event [ [string] ] , - [number] , delta = [number] ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] self . assertAlmostEqual ( event [ [string] ] , [number] , delta = [number] ) [EOL] self . assertAlmostEqual ( event [ [string] ] , [number] , delta = [number] ) [EOL] self . assertAlmostEqual ( event [ [string] ] , [number] , delta = [number] ) [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.aposteriori.DirectAposteriori$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $iasi.aposteriori.DirectAposteriori$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $iasi.aposteriori.DirectAposteriori$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $None$ 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] import iasi [EOL] import unittest [EOL] [EOL] import luigi [EOL] import numpy as np [EOL] from netCDF4 import Dataset , Group , Variable [EOL] [EOL] from iasi . compression import CompressDataset [EOL] from iasi . file import MoveVariables [EOL] from iasi . quadrant import ( AssembleFourQuadrants , AssembleTwoQuadrants , DisassembleFourQuadrants , DisassembleTwoQuadrants , Quadrant ) [EOL] from iasi . util import child_groups_of , child_variables_of [EOL] [EOL] [EOL] class TestQuadrants ( unittest . TestCase ) : [EOL] @ classmethod def setUpClass ( cls ) : [EOL] file = [string] [EOL] [comment] [EOL] compression = CompressDataset ( file = file , dst = [string] , force = True , log_file = False ) [EOL] uncompressed = MoveVariables ( file = file , dst = [string] , force = True , log_file = False ) [EOL] assert luigi . build ( [ compression , uncompressed ] , local_scheduler = True ) [EOL] cls . compressed = Dataset ( compression . output ( ) . path ) [EOL] cls . uncompressed = Dataset ( uncompressed . output ( ) . path ) [EOL] [EOL] @ classmethod def tearDownClass ( cls ) : [EOL] cls . compressed . close ( ) [EOL] cls . uncompressed . close ( ) [EOL] [EOL] def test_child_groups ( self ) : [EOL] state = self . uncompressed [ [string] ] [EOL] children = child_groups_of ( state ) [EOL] names = [ g . name for g in children ] [EOL] self . assertListEqual ( names , [ [string] , [string] , [string] , [string] , [string] , [string] ] ) [EOL] [EOL] def test_variables_of_group ( self ) : [EOL] wv = self . uncompressed [ [string] ] [EOL] self . assertIsInstance ( wv , Group ) [EOL] children = [ var . name for g , var in child_variables_of ( wv ) ] [EOL] self . assertListEqual ( children , [ [string] , [string] , [string] , [string] , [string] , [string] ] ) [EOL] [EOL] def test_single_quadrant_assembly ( self ) : [EOL] avk = self . uncompressed [ [string] ] [EOL] q = Quadrant . for_assembly ( [string] , [string] , avk ) [EOL] self . assertIsInstance ( q , Quadrant ) [EOL] self . assertTupleEqual ( q . transformed_shape ( ) , ( [number] , [number] , [number] ) ) [EOL] array = np . random . uniform ( size = ( [number] , [number] ) ) [EOL] assembly = q . transform ( array , [number] ) [EOL] self . assertTupleEqual ( assembly . shape , ( [number] , [number] ) ) [EOL] self . assertTrue ( np . allclose ( array [ : [number] , : [number] ] , assembly ) ) [EOL] [EOL] def test_two_quadrants_assembly ( self ) : [EOL] xavk = self . uncompressed [ [string] ] [EOL] q = Quadrant . for_assembly ( [string] , xavk . name , xavk ) [EOL] self . assertIsInstance ( q , AssembleTwoQuadrants ) [EOL] self . assertTupleEqual ( q . transformed_shape ( ) , ( [number] , [number] , [number] ) ) [EOL] array = np . random . uniform ( size = ( [number] , [number] , [number] ) ) [EOL] assembly = q . transform ( array , [number] ) [EOL] self . assertTupleEqual ( assembly . shape , ( [number] , [number] ) ) [EOL] [EOL] def test_four_quadrants_assembly ( self ) : [EOL] avk = self . uncompressed [ [string] ] [EOL] q = Quadrant . for_assembly ( [string] , [string] , avk ) [EOL] self . assertIsInstance ( q , AssembleFourQuadrants ) [EOL] self . assertTupleEqual ( q . transformed_shape ( ) , ( [number] , [number] , [number] ) ) [EOL] array = np . random . uniform ( size = ( [number] , [number] , [number] , [number] ) ) [EOL] assembly = q . transform ( array , [number] ) [EOL] self . assertTupleEqual ( assembly . shape , ( [number] , [number] ) ) [EOL] close = np . allclose ( assembly [ [number] : [number] * [number] , : [number] ] , array [ [number] , [number] , : [number] , : [number] ] ) [EOL] self . assertTrue ( close , [string] ) [EOL] [EOL] def test_single_quadrant_disassembly ( self ) : [EOL] atm_n = self . compressed [ [string] ] [EOL] q = Quadrant . for_disassembly ( [string] , [string] , atm_n ) [EOL] self . assertIsInstance ( q , Quadrant ) [EOL] self . assertTupleEqual ( q . transformed_shape ( ) , ( [number] , [number] , [number] ) ) [EOL] array = np . random . uniform ( size = ( [number] , [number] ) ) [EOL] disassembly = q . transform ( array , [number] ) [EOL] self . assertTupleEqual ( disassembly . shape , ( [number] , [number] ) ) [EOL] [EOL] def test_two_quadrant_disassembly ( self ) : [EOL] xavk = self . compressed [ [string] ] [EOL] q = Quadrant . for_disassembly ( [string] , [string] , xavk ) [EOL] self . assertIsInstance ( q , DisassembleTwoQuadrants ) [EOL] self . assertTupleEqual ( q . transformed_shape ( ) , ( [number] , [number] , [number] , [number] ) ) [EOL] array = np . arange ( [number] * [number] ) . reshape ( [number] , [number] ) [EOL] disassembly = q . transform ( array , [number] ) [EOL] self . assertTupleEqual ( disassembly . shape , ( [number] , [number] , [number] ) ) [EOL] close = np . allclose ( array [ : [number] , : [number] ] , disassembly [ [number] , : [number] , : [number] ] ) [EOL] self . assertTrue ( close ) [EOL] close = np . allclose ( array [ [number] : [number] , : [number] ] , disassembly [ [number] , : [number] , : [number] ] ) [EOL] self . assertTrue ( close ) [EOL] [EOL] def test_four_quadrant_disassembly ( self ) : [EOL] avk_rc = self . compressed [ [string] ] [EOL] q = Quadrant . for_disassembly ( [string] , [string] , avk_rc ) [EOL] [EOL] self . assertIsInstance ( q , DisassembleFourQuadrants ) [EOL] self . assertTupleEqual ( q . transformed_shape ( ) , ( [number] , [number] , [number] , [number] , [number] ) ) [EOL] avk = self . uncompressed [ [string] ] [EOL] q_assembly = Quadrant . for_assembly ( [string] , [string] , avk ) [EOL] array = np . arange ( [number] * [number] ) . reshape ( [number] , [number] ) [EOL] disassembly = q . transform ( array , [number] ) [EOL] array_rc = q_assembly . transform ( disassembly , [number] ) [EOL] self . assertTupleEqual ( disassembly . shape , ( [number] , [number] , [number] , [number] ) ) [EOL] close = np . allclose ( array [ [number] : [number] , [number] : [number] ] , disassembly [ [number] , [number] , : [number] , : [number] ] ) [EOL] self . assertTrue ( close ) [EOL] for i in range ( [number] ) : [EOL] for j in range ( [number] ) : [EOL] close = np . allclose ( array [ i * [number] : [number] + i * [number] , j * [number] : [number] + j * [number] ] , array_rc [ i * [number] : ( i + [number] ) * [number] , j * [number] : ( j + [number] ) * [number] ] ) [EOL] self . assertTrue ( close ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $iasi.compression.CompressDataset$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.compression.CompressDataset$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.compression.CompressDataset$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 $typing.list$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.list$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.list$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.list$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $iasi.quadrant.Quadrant$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $iasi.quadrant.Quadrant$ 0 0 0 0 0 0 0 0 $iasi.quadrant.Quadrant$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $iasi.quadrant.Quadrant$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $iasi.quadrant.Quadrant$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 $iasi.quadrant.Quadrant$ 0 0 0 0 0 0 0 0 $iasi.quadrant.Quadrant$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $iasi.quadrant.Quadrant$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $iasi.quadrant.Quadrant$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $iasi.quadrant.Quadrant$ 0 0 0 0 0 0 0 0 $iasi.quadrant.Quadrant$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $iasi.quadrant.Quadrant$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $iasi.quadrant.Quadrant$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $iasi.quadrant.Quadrant$ 0 0 0 0 0 0 0 0 $iasi.quadrant.Quadrant$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $iasi.quadrant.Quadrant$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $iasi.quadrant.Quadrant$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $iasi.quadrant.Quadrant$ 0 0 0 0 0 0 0 0 $iasi.quadrant.Quadrant$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $iasi.quadrant.Quadrant$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $iasi.quadrant.Quadrant$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $iasi.quadrant.Quadrant$ 0 0 0 0 0 0 0 0 $iasi.quadrant.Quadrant$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $iasi.quadrant.Quadrant$ 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0
from typing import Any , Set [EOL] import logging [EOL] import typing [EOL] import iasi [EOL] import logging [EOL] import math [EOL] import os [EOL] import unittest [EOL] from typing import Set [EOL] [EOL] import luigi [EOL] import numpy as np [EOL] from netCDF4 import Dataset , Group , Variable [EOL] [EOL] from iasi . compression import CompressDataset , DecompressDataset [EOL] from iasi . file import MoveVariables [EOL] from iasi . util import child_groups_of , child_variables_of [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] logger . setLevel ( logging . DEBUG ) [EOL] [EOL] [EOL] class TestCompareDecompressionResult ( unittest . TestCase ) : [EOL] @ classmethod def setUpClass ( cls ) : [EOL] file = [string] [EOL] [comment] [EOL] compression = DecompressDataset ( file = file , dst = [string] , force_upstream = True , log_file = False , compress_upstream = True ) [EOL] uncompressed = MoveVariables ( file = file , dst = [string] , force_upstream = True , log_file = False ) [EOL] assert luigi . build ( [ compression , uncompressed ] , local_scheduler = True ) [EOL] cls . compressed = Dataset ( compression . output ( ) . path ) [EOL] cls . uncompressed = Dataset ( uncompressed . output ( ) . path ) [EOL] [EOL] @ classmethod def tearDownClass ( cls ) : [EOL] cls . compressed . close ( ) [EOL] cls . uncompressed . close ( ) [EOL] [EOL] def variable_names ( self , variables ) : [EOL] return set ( map ( lambda v : v . name , variables ) ) [EOL] [EOL] def group_paths ( self , groups ) : [EOL] return set ( map ( lambda g : g . path , groups ) ) [EOL] [EOL] def test_all_variables_exist ( self ) : [EOL] for group in child_groups_of ( self . uncompressed ) : [EOL] if group . path == [string] : [EOL] other_vars = set ( self . compressed . variables . keys ( ) ) [EOL] else : [EOL] other_vars = set ( self . compressed [ group . path ] . variables . keys ( ) ) [EOL] self . assertSetEqual ( set ( group . variables . keys ( ) ) , other_vars ) [EOL] [EOL] def test_all_variable_values_are_close ( self ) : [EOL] for group , var in child_variables_of ( self . uncompressed [ [string] ] ) : [EOL] path = os . path . join ( group . path , var . name ) [EOL] [comment] [EOL] if var . name not in [ [string] , [string] , [string] ] or group . name in [ [string] ] : [EOL] continue [EOL] original = var [ ... ] [EOL] reconstructed = self . compressed [ path ] [ ... ] [EOL] [comment] [EOL] for event in range ( original . shape [ [number] ] ) : [EOL] if reconstructed [ event ] . mask . all ( ) : [EOL] continue [EOL] same_mask = np . equal ( original [ event ] . mask , reconstructed [ event ] . mask ) . all ( ) [EOL] self . assertTrue ( same_mask , f' [string] { path } [string] { event }' ) [EOL] a = original [ event ] . compressed ( ) [EOL] b = reconstructed [ event ] . compressed ( ) [EOL] close = np . ma . allclose ( a , b , atol = [number] , rtol = [number] ) [EOL] if not close : [EOL] logger . error ( [string] , np . abs ( a - b ) . max ( ) ) [EOL] self . assertTrue ( close , f' [string] { path } [string] { event }' ) [EOL] logger . debug ( [string] , path ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $iasi.compression.DecompressDataset$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.compression.DecompressDataset$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.compression.DecompressDataset$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Set$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Set$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 $builtins.str$ 0 0
from typing import Any , Tuple [EOL] import numpy [EOL] import builtins [EOL] import typing [EOL] import iasi [EOL] import logging [EOL] import os [EOL] import sys [EOL] import unittest [EOL] import warnings [EOL] from typing import Tuple [EOL] [EOL] import luigi [EOL] import numpy as np [EOL] from netCDF4 import Dataset , Group , Variable [EOL] [EOL] from iasi . composition import ( Composition , EigenComposition , SingularValueComposition ) [EOL] from iasi . compression import CompressDataset [EOL] from iasi . file import MoveVariables [EOL] [EOL] [EOL] class TestComposition ( unittest . TestCase ) : [EOL] @ classmethod def setUpClass ( cls ) : [EOL] file = [string] [EOL] [comment] [EOL] compression = CompressDataset ( file = file , dst = [string] , force = True , log_file = False ) [EOL] uncompressed = MoveVariables ( file = file , dst = [string] , force = True , log_file = False ) [EOL] assert luigi . build ( [ compression , uncompressed ] , local_scheduler = True ) [EOL] cls . compressed = Dataset ( compression . output ( ) . path ) [EOL] cls . uncompressed = Dataset ( uncompressed . output ( ) . path ) [EOL] [EOL] @ classmethod def tearDownClass ( cls ) : [EOL] cls . compressed . close ( ) [EOL] cls . uncompressed . close ( ) [EOL] [EOL] def masks_equal ( self , a , b ) : [EOL] return np . equal ( a . mask , b . mask ) . all ( ) [EOL] [EOL] def test_eigen_composition_combined ( self ) : [EOL] self . verify_eigen_composition ( [string] , ( [number] , [number] , [number] , [number] , [number] ) ) [EOL] [EOL] def test_eigen_composition_single ( self ) : [EOL] self . verify_eigen_composition ( [string] , ( [number] , [number] , [number] ) ) [EOL] [EOL] def verify_eigen_composition ( self , attribute , shape ) : [EOL] array = self . compressed [ attribute ] [EOL] nol = self . compressed [ [string] ] [ ... ] [EOL] self . assertIsInstance ( array , Group ) [EOL] eig = EigenComposition ( array ) [EOL] reconstruction = eig . reconstruct ( nol ) [EOL] self . assertTupleEqual ( reconstruction . shape , shape ) [EOL] original = self . uncompressed [ attribute ] [ ... ] [EOL] [comment] [EOL] self . assertFalse ( reconstruction . mask . all ( ) ) [EOL] self . assertFalse ( np . isnan ( reconstruction [ : , : [number] , : [number] ] ) . any ( ) , [string] ) [EOL] self . assertFalse ( np . isinf ( reconstruction [ : , : [number] , : [number] ] ) . any ( ) , [string] ) [EOL] close = np . allclose ( reconstruction . compressed ( ) , original . compressed ( ) , atol = [number] ) [EOL] self . assertTrue ( close , [string] ) [EOL] self . assertTrue ( self . masks_equal ( reconstruction , original ) ) [EOL] [EOL] def test_svd_one_quadrant ( self ) : [EOL] self . verify_singular_value_composition ( [string] , ( [number] , [number] , [number] ) ) [EOL] [EOL] def test_svd_two_quadrants ( self ) : [EOL] self . verify_singular_value_composition ( [string] , ( [number] , [number] , [number] , [number] ) ) [EOL] [EOL] def test_svd_four_quadrants ( self ) : [EOL] self . verify_singular_value_composition ( [string] , ( [number] , [number] , [number] , [number] , [number] ) ) [EOL] [EOL] def verify_singular_value_composition ( self , attribute , shape ) : [EOL] avk = self . compressed [ attribute ] [EOL] self . assertIsInstance ( avk , Group ) [EOL] svc = SingularValueComposition ( avk ) [EOL] nol = self . compressed [ [string] ] [ ... ] [EOL] reconstruction = svc . reconstruct ( nol ) [EOL] self . assertTupleEqual ( reconstruction . shape , shape ) [EOL] original = self . uncompressed [ attribute ] [ ... ] [EOL] [comment] [EOL] self . assertFalse ( reconstruction . mask . all ( ) ) [EOL] self . assertFalse ( np . isnan ( reconstruction [ : , : [number] , : [number] ] ) . any ( ) , [string] ) [EOL] self . assertFalse ( np . isinf ( reconstruction [ : , : [number] , : [number] ] ) . any ( ) , [string] ) [EOL] close = np . allclose ( reconstruction . compressed ( ) , original . compressed ( ) , atol = [number] ) [EOL] self . assertTrue ( close , [string] ) [EOL] self . assertTrue ( self . masks_equal ( reconstruction , original ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $iasi.composition.SingularValueComposition$ 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.composition.SingularValueComposition$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0
from typing import Any , List [EOL] import typing [EOL] import iasi [EOL] import unittest [EOL] [EOL] import luigi [EOL] from netCDF4 import Dataset [EOL] [EOL] from iasi . compression import SelectSingleVariable [EOL] from iasi . file import CopyNetcdfFile , MoveVariables [EOL] from iasi . util import child_variables_of [EOL] [EOL] [EOL] class TestCopyNetcdf ( unittest . TestCase ) : [EOL] [EOL] file = [string] [EOL] [EOL] def test_select_single_variable ( self ) : [EOL] tasks = [ SelectSingleVariable ( file = [string] , dst = [string] , force_upstream = True , variable = [string] , ancestor = ancestor , log_file = False ) for ancestor in [ [string] , [string] , [string] ] ] [EOL] assert luigi . build ( tasks , local_scheduler = True ) [EOL] [comment] [EOL] with Dataset ( tasks [ [number] ] . output ( ) . path , [string] ) as nc : [EOL] child_items = list ( child_variables_of ( nc ) ) [EOL] self . assertEqual ( len ( child_items ) , [number] ) [EOL] group , var = child_items [ [number] ] [EOL] self . assertEqual ( group . path , [string] ) [EOL] self . assertEqual ( var . name , [string] ) [EOL] [comment] [EOL] with Dataset ( tasks [ [number] ] . output ( ) . path , [string] ) as nc : [EOL] child_items = list ( child_variables_of ( nc ) ) [EOL] self . assertEqual ( len ( child_items ) , [number] ) [EOL] vars = [ var . name for _ , var in child_items ] [EOL] self . assertListEqual ( vars , [ [string] , [string] , [string] , [string] ] ) [EOL] groups = [ group . path for group , _ in child_items ] [EOL] self . assertListEqual ( groups , [ [string] ] * [number] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[iasi.compression.SelectSingleVariable]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[iasi.compression.SelectSingleVariable]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[iasi.compression.SelectSingleVariable]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[iasi.compression.SelectSingleVariable]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 $typing.list$ 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 $typing.list$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.list$ 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 $typing.list$ 0 0 0 0 0 0 0 0
import iasi [EOL] import unittest [EOL] [EOL] import luigi [EOL] from netCDF4 import Dataset [EOL] [EOL] from iasi import DecompressDataset [EOL] from iasi . file import MoveVariables [EOL] from test_precision import TestCompareDecompressionResult [EOL] [EOL] [EOL] class IntegrationTest ( TestCompareDecompressionResult ) : [EOL] @ classmethod def setUpClass ( cls ) : [EOL] file = [string] [EOL] compression = DecompressDataset ( file = file , dst = [string] , force_upstream = True , compress_upstream = True ) [EOL] uncompressed = MoveVariables ( file = file , dst = [string] , force_upstream = True ) [EOL] assert luigi . build ( [ compression , uncompressed ] , local_scheduler = True ) [EOL] cls . compressed = Dataset ( compression . output ( ) . path ) [EOL] cls . uncompressed = Dataset ( uncompressed . output ( ) . path ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $iasi.compression.DecompressDataset$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.compression.DecompressDataset$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.compression.DecompressDataset$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] import iasi [EOL] import unittest [EOL] from iasi . decomposition import Decomposition [EOL] from netCDF4 import Dataset [EOL] [EOL] [EOL] class TestThreshold ( unittest . TestCase ) : [EOL] [EOL] def test_default_values ( self ) : [EOL] dummy = Dataset ( [string] , [string] , diskless = True , persist = False ) [EOL] group = dummy . createGroup ( [string] ) [EOL] group . createDimension ( [string] , [number] ) [EOL] variable = group . createVariable ( [string] , [string] , ( [string] ) ) [EOL] [EOL] [comment] [EOL] dec = Decomposition ( group , variable , threshold = [number] ) [EOL] self . assertEqual ( dec . threshold , [number] ) [EOL] [EOL] [comment] [EOL] dec = Decomposition ( group , variable ) [EOL] self . assertEqual ( dec . threshold , [number] ) [EOL] [EOL] [comment] [EOL] self . assertEqual ( dec . default_threshold ( [string] , [string] ) , [number] ) [EOL] self . assertEqual ( dec . default_threshold ( [string] , [string] ) , [number] ) [EOL] self . assertEqual ( dec . default_threshold ( [string] , [string] ) , [number] ) [EOL] [comment] [EOL] self . assertEqual ( dec . default_threshold ( [string] , [string] ) , [number] ) [EOL] self . assertEqual ( dec . default_threshold ( [string] , [string] ) , [number] ) [EOL] self . assertEqual ( dec . default_threshold ( [string] , [string] ) , [number] ) [EOL] [comment] [EOL] self . assertEqual ( dec . default_threshold ( [string] , [string] ) , [number] ) [EOL] self . assertEqual ( dec . default_threshold ( [string] , [string] ) , [number] ) [EOL] self . assertEqual ( dec . default_threshold ( [string] , [string] ) , [number] ) [EOL] [comment] [EOL] self . assertEqual ( dec . default_threshold ( [string] , [string] ) , [number] ) [EOL] self . assertEqual ( dec . default_threshold ( [string] , [string] ) , [number] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.decomposition.Decomposition$ 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $iasi.decomposition.Decomposition$ 0 0 0 0 0 0 0 0 0 $iasi.decomposition.Decomposition$ 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $iasi.decomposition.Decomposition$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.decomposition.Decomposition$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.decomposition.Decomposition$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.decomposition.Decomposition$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.decomposition.Decomposition$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.decomposition.Decomposition$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.decomposition.Decomposition$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.decomposition.Decomposition$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.decomposition.Decomposition$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.decomposition.Decomposition$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.decomposition.Decomposition$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.decomposition.Decomposition$ 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] from typing import Any [EOL] import builtins [EOL] import typing [EOL] import iasi [EOL] import matplotlib [EOL] import luigi [EOL] import matplotlib . pyplot as plt [EOL] import numpy as np [EOL] import pandas as pd [EOL] [EOL] from iasi . evaluation import EvaluationCompressionSize [EOL] [EOL] task = EvaluationCompressionSize ( dst = [string] , file = [string] , gases = [ [string] , [string] , [string] , [string] ] , variables = [ [string] , [string] , [string] ] ) [EOL] [EOL] assert luigi . build ( [ task ] , local_scheduler = True ) [EOL] [EOL] df = pd . read_csv ( task . output ( ) . open ( [string] ) ) [EOL] original = df [ df [ [string] ] == [string] ] [EOL] compressed = df [ df [ [string] ] == [string] ] [EOL] [EOL] [EOL] def filter_by ( df , gas , variable , threshold = None ) : [EOL] return df [ ( df [ [string] ] == gas ) & ( df [ [string] ] == variable ) ] [EOL] [EOL] [EOL] def plot_size_for ( gas , variable ) : [EOL] gas_compressed = filter_by ( compressed , gas , variable ) [EOL] ax = gas_compressed . plot . bar ( x = [string] , y = [string] , rot = [number] , legend = False ) [EOL] gas_original = filter_by ( original , gas , variable ) [EOL] assert len ( gas_original ) == [number] [EOL] original_size = gas_original [ [string] ] . values [ [number] ] [EOL] ax . axhline ( original_size , color = [string] ) [EOL] ax . text ( [number] , original_size * [number] , [string] , horizontalalignment = [string] ) [EOL] [comment] [EOL] ax . set_ylabel ( [string] ) [EOL] ax . set_xlabel ( [string] ) [EOL] plt . title ( f' [string] { gas } [string] { variable }' ) [EOL] plt . show ( ) [EOL] [EOL] [EOL] def plot_total_size_for ( gas ) : [EOL] gas_compressed = compressed [ compressed [ [string] ] == gas ] [EOL] ax = gas_compressed . groupby ( [string] ) . sum ( ) [ [string] ] . plot . bar ( rot = [number] ) [EOL] ax . set_ylabel ( [string] ) [EOL] ax . set_xlabel ( [string] ) [EOL] gas_original_sum = original [ original [ [string] ] == gas ] [ [string] ] . sum ( ) [EOL] ax . axhline ( gas_original_sum , color = [string] ) [EOL] ax . text ( [number] , gas_original_sum * [number] , [string] , horizontalalignment = [string] ) [EOL] plt . title ( f' [string] { gas }' ) [EOL] plt . show ( ) [EOL] [EOL] [EOL] [comment] [EOL] plot_size_for ( [string] , [string] ) [EOL] [EOL] [comment] [EOL] plot_size_for ( [string] , [string] ) [EOL] [EOL] [comment] [EOL] plot_size_for ( [string] , [string] ) [EOL] [comment] [EOL] plot_size_for ( [string] , [string] ) [EOL] [comment] [EOL] plot_size_for ( [string] , [string] ) [EOL] [comment] [EOL] plot_size_for ( [string] , [string] ) [EOL] [comment] [EOL] plot_size_for ( [string] , [string] ) [EOL] [comment] [EOL] plot_size_for ( [string] , [string] ) [EOL] [comment] [EOL] plot_size_for ( [string] , [string] ) [EOL] [comment] [EOL] plot_size_for ( [string] , [string] ) [EOL] [comment] [EOL] plot_size_for ( [string] , [string] ) [EOL] [comment] [EOL] plot_total_size_for ( [string] ) [EOL] [comment] [EOL] plot_total_size_for ( [string] ) [EOL] [comment] [EOL] plot_total_size_for ( [string] ) [EOL] [comment] [EOL] plot_total_size_for ( [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.evaluation.EvaluationCompressionSize$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $iasi.evaluation.EvaluationCompressionSize$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $iasi.evaluation.EvaluationCompressionSize$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] from typing import Any [EOL] import typing [EOL] import matplotlib . pyplot as plt [EOL] import numpy as np [EOL] from mpl_toolkits . axes_grid1 import ImageGrid [EOL] from netCDF4 import Dataset [EOL] [EOL] import matplotlib [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] nc = Dataset ( [string] ) [EOL] avk = nc [ [string] ] [ [number] ] [EOL] xavk = nc [ [string] ] [ [number] ] [EOL] atm_n = nc [ [string] ] [ [number] ] [EOL] [EOL] level = [number] [EOL] interpolation = None [EOL] [EOL] fig = plt . figure ( figsize = ( [number] , [number] ) ) [EOL] [comment] [EOL] [EOL] gs = fig . add_gridspec ( nrows = [number] , ncols = [number] ) [EOL] [EOL] [EOL] def create_image_grid ( grid_spec , nrows_ncols = ( [number] , [number] ) ) : [EOL] return ImageGrid ( fig , grid_spec , nrows_ncols = nrows_ncols , axes_pad = [number] , cbar_mode = [string] , cbar_location = [string] , cbar_size = [string] , cbar_pad = [number] , ) [EOL] [EOL] [EOL] def plot_image_grid ( matrix , title , position ) : [EOL] grid = create_image_grid ( position ) [EOL] for i in range ( [number] ) : [EOL] for j in range ( [number] ) : [EOL] idx = i * [number] + j [EOL] im = grid [ idx ] . imshow ( matrix [ j , i , : level , : level ] , interpolation = interpolation ) [EOL] grid [ idx ] . cax . colorbar ( im ) [EOL] grid [ [number] ] . set_ylabel ( [string] ) [EOL] grid [ [number] ] . set_ylabel ( [string] ) [EOL] grid [ [number] ] . set_xlabel ( [string] ) [EOL] grid [ [number] ] . set_xlabel ( [string] ) [EOL] grid [ [number] ] . set_title ( title , x = [number] ) [EOL] [EOL] [EOL] [comment] [EOL] plot_image_grid ( avk , [string] , gs [ : [number] , : [number] ] ) [EOL] [comment] [EOL] plot_image_grid ( atm_n , [string] , gs [ : [number] , [number] : [number] ] ) [EOL] [comment] [EOL] grid = create_image_grid ( gs [ : , [number] : [number] ] , ( [number] , [number] ) ) [EOL] for i in range ( [number] ) : [EOL] im = grid [ i ] . imshow ( xavk [ i , : level , : level ] , interpolation = interpolation ) [EOL] grid [ i ] . cax . colorbar ( im ) [EOL] [EOL] grid [ [number] ] . set_title ( [string] ) [EOL] grid [ [number] ] . set_ylabel ( [string] ) [EOL] grid [ [number] ] . set_ylabel ( [string] ) [EOL] grid [ [number] ] . set_xlabel ( [string] ) [EOL] [EOL] [comment] [EOL] plt . show ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $None$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 $builtins.int$ 0 0 $None$ 0 $None$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $builtins.int$ 0 0 $builtins.int$ 0 0 $None$ 0 $None$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] from typing import Any , Tuple , List , Type [EOL] import netCDF4 [EOL] import pandas [EOL] import builtins [EOL] import typing [EOL] import notebooks [EOL] import glob [EOL] from typing import List , Tuple [EOL] [EOL] import cartopy . crs as ccrs [EOL] import matplotlib . pyplot as plt [EOL] import numpy as np [EOL] import pandas as pd [EOL] import seaborn as sns [EOL] from netCDF4 import Dataset [EOL] from sklearn . base import BaseEstimator , TransformerMixin [EOL] from sklearn . cluster import DBSCAN [EOL] from sklearn . metrics import davies_bouldin_score [EOL] from sklearn . pipeline import Pipeline [EOL] from sklearn . preprocessing import StandardScaler [EOL] [EOL] Coordinate = Tuple [ float , float ] [EOL] CoordinateRange = Tuple [ float , float ] [EOL] [EOL] features = [ [string] , [string] , [string] , [string] ] [EOL] [EOL] [EOL] class GeographicArea : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , lat , lon ) : [EOL] [docstring] [EOL] self . lat = lat [EOL] self . lon = lon [EOL] [EOL] def import_dataset ( self , file_pattern ) : [EOL] frames = [ ] [EOL] for file in glob . glob ( file_pattern ) : [EOL] frame = pd . DataFrame ( ) [EOL] with Dataset ( file ) as nc : [EOL] for feature in features : [EOL] var = nc [ feature ] [ ... ] [EOL] assert not var . mask . any ( ) [EOL] frame [ feature ] = var . data [EOL] frame = self . filter ( frame ) [EOL] frames . append ( frame ) [EOL] return pd . concat ( frames , ignore_index = True ) [EOL] [EOL] def get_extend ( self ) : [EOL] return [ * self . lon , * self . lat ] [EOL] [EOL] def filter ( self , df ) : [EOL] return df [ ( df . lon . between ( * self . lon ) ) & ( df . lat . between ( self . lat [ [number] ] , self . lat [ [number] ] ) ) ] [EOL] [EOL] def scatter ( self , * args , ** kwargs ) : [EOL] ax = plt . axes ( projection = ccrs . PlateCarree ( ) ) [EOL] ax . set_extent ( [ * self . lon , * self . lat ] , crs = ccrs . PlateCarree ( ) ) [EOL] ax . coastlines ( ) [EOL] ax . scatter ( * args , ** kwargs ) [EOL] [EOL] [EOL] class SpatialWaterVapourScaler ( BaseEstimator , TransformerMixin ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , delD = [number] , H2O = [number] , km = [number] ) : [EOL] self . delD = delD [EOL] self . H2O = H2O [EOL] self . km = km [EOL] [EOL] def fit ( self , X , y = None ) : [EOL] return self [EOL] [EOL] def transform ( self , X , y = None ) : [EOL] [docstring] [EOL] assert X . shape [ [number] ] == [number] [EOL] [comment] [EOL] X [ : , [number] ] = ( X [ : , [number] ] * [number] ) / self . km [EOL] [comment] [EOL] X [ : , [number] ] = ( X [ : , [number] ] * [number] ) / self . km [EOL] [comment] [EOL] X [ : , [number] ] = np . log ( X [ : , [number] ] ) / self . H2O [EOL] [comment] [EOL] X [ : , [number] ] = X [ : , [number] ] / self . delD [EOL] return X [EOL] [EOL] [EOL] [comment] [EOL] area = GeographicArea ( lat = ( [number] , - [number] ) , lon = ( - [number] , [number] ) ) [EOL] df = area . import_dataset ( [string] ) [EOL] scaler = SpatialWaterVapourScaler ( km = [number] , H2O = [number] , delD = [number] ) [EOL] scaled = pd . DataFrame ( scaler . transform ( df . values ) , columns = features ) [EOL] clustering = DBSCAN ( eps = [number] , min_samples = [number] ) [EOL] pipeline = Pipeline ( [ ( [string] , scaler ) , ( [string] , clustering ) ] ) [EOL] samples = df [EOL] pipeline . fit ( samples [ features ] . values ) [EOL] clustering = pipeline . named_steps [ [string] ] [EOL] samples [ [string] ] = clustering . labels_ [EOL] scaled [ [string] ] = clustering . labels_ [EOL] [comment] [EOL] samples = samples [ samples . label != - [number] ] [EOL] scaled = scaled [ scaled . label != - [number] ] [EOL] [EOL] [comment] [EOL] [EOL] [EOL] class SaveClusterGroups : [EOL] [EOL] def __init__ ( self , H2O_bins = [number] , delD_bins = [number] ) : [EOL] self . H2O_bins = H2O_bins [EOL] self . delD_bins = delD_bins [EOL] [EOL] def create_dataset ( self , filename ) : [EOL] nc = Dataset ( filename , [string] , format = [string] ) [EOL] nc . createDimension ( [string] , self . H2O_bins ) [EOL] nc . createDimension ( [string] , self . delD_bins ) [EOL] [comment] [EOL] nc . createDimension ( [string] , None ) [EOL] nc . createVariable ( [string] , [string] , ( [string] , [string] , [string] ) ) [EOL] return nc [EOL] [EOL] def save ( self , df , filename = [string] ) : [EOL] assert - [number] not in df . label [EOL] with self . create_dataset ( filename ) as nc : [EOL] cluster = nc [ [string] ] [EOL] for group , data in df . groupby ( [ [string] ] ) : [EOL] hist , xedges , yedges = np . histogram2d ( data [ [string] ] . values , data [ [string] ] . values , bins = ( self . H2O_bins , self . delD_bins ) ) [EOL] cluster [ group ] = hist . T [EOL] [EOL] [EOL] cluster_groups = SaveClusterGroups ( ) [EOL] cluster_groups . save ( samples ) [EOL] [EOL] [EOL] [comment] [EOL] nc = Dataset ( [string] ) [EOL] cluster_hist = nc [ [string] ] [ ... ] [EOL] plt . imshow ( cluster_hist [ [number] ] , interpolation = [string] , origin = [string] ) [EOL] plt . colorbar ( ) [EOL] plt . show ( ) [EOL] [EOL] [comment] [EOL] y = samples [ [string] ] [EOL] x = np . log ( samples [ [string] ] ) [EOL] plt . scatter ( x , y , alpha = [number] , marker = [string] , s = [number] , c = samples [ [string] ] ) [EOL] plt . ylabel ( [string] ) [EOL] plt . xlabel ( [string] ) [EOL] plt . show ( ) [EOL] [EOL] [EOL] [comment] [EOL] area . scatter ( samples . lon , samples . lat , alpha = [number] , marker = [string] , s = [number] , c = samples [ [string] ] , cmap = [string] ) [EOL] [comment] [EOL] plt . show ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.float,builtins.float]$ 0 $typing.Tuple[builtins.float,builtins.float]$ 0 0 0 0 0 0 0 $typing.Tuple[builtins.float,builtins.float]$ 0 $typing.Tuple[builtins.float,builtins.float]$ 0 0 0 $typing.Tuple[builtins.float,builtins.float]$ 0 $typing.Tuple[builtins.float,builtins.float]$ 0 0 0 $pandas.DataFrame$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 $pandas.DataFrame$ 0 0 0 0 $pandas.DataFrame$ 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $notebooks.cluster.GeographicArea$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $notebooks.cluster.GeographicArea$ 0 0 0 0 0 0 $notebooks.cluster.SpatialWaterVapourScaler$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $notebooks.cluster.SpatialWaterVapourScaler$ 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $notebooks.cluster.SpatialWaterVapourScaler$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 $typing.List[builtins.str]$ 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $netCDF4.Dataset$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $notebooks.cluster.SaveClusterGroups$ 0 0 0 0 0 $notebooks.cluster.SaveClusterGroups$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $notebooks.cluster.GeographicArea$ 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] from math import cos , pi [EOL] [EOL] import numpy as np [EOL] from sklearn . base import BaseEstimator , TransformerMixin [EOL] [EOL] [comment] [EOL] latitude_km = [number] [EOL] [EOL] class SpatialWaterVapourScaler ( BaseEstimator , TransformerMixin ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , delD = [number] , H2O = [number] , km = [number] ) : [EOL] self . delD = delD [EOL] self . H2O = H2O [EOL] self . km = km [EOL] [EOL] def fit ( self , X , y = None ) : [EOL] return self [EOL] [EOL] def transform ( self , X , y = None ) : [EOL] [docstring] [EOL] assert X . shape [ [number] ] == [number] [EOL] X_ = np . ndarray ( X . shape ) [EOL] [comment] [EOL] X_ [ : , [number] ] = ( X [ : , [number] ] * latitude_km ) / self . km [EOL] [comment] [EOL] [comment] [EOL] X_ [ : , [number] ] = ( X [ : , [number] ] * latitude_km * np . cos ( X [ : , [number] ] * ( pi / [number] ) ) ) / self . km [EOL] [comment] [EOL] X_ [ : , [number] ] = np . log ( X [ : , [number] ] ) / self . H2O [EOL] [comment] [EOL] X_ [ : , [number] ] = X [ : , [number] ] / self . delD [EOL] return X_ [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0
[EOL] import builtins [EOL] from typing import Any , List , Dict [EOL] import logging [EOL] import sklearn [EOL] import numpy [EOL] import analysis [EOL] import typing [EOL] import logging [EOL] [EOL] import luigi [EOL] import numpy as np [EOL] import pandas as pd [EOL] from hdbscan import HDBSCAN [EOL] from sklearn . cluster import DBSCAN [EOL] from sklearn . metrics import ( calinski_harabasz_score , davies_bouldin_score , silhouette_score ) [EOL] from sklearn . model_selection import ParameterGrid [EOL] from sklearn . pipeline import Pipeline [EOL] [EOL] from typing import List [EOL] [EOL] from analysis . data import GeographicArea , features [EOL] from analysis . scaler import SpatialWaterVapourScaler [EOL] from iasi . file import FileTask [EOL] [EOL] metrics = { [string] : davies_bouldin_score , [string] : silhouette_score , [string] : calinski_harabasz_score } [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class GridSearch ( FileTask ) : [EOL] [EOL] def __init__ ( self , grid_params = None , * args , ** kwargs ) : [EOL] self . _grid_params = grid_params [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] [EOL] area = GeographicArea ( lat = ( - [number] , [number] ) , lon = ( - [number] , [number] ) ) [EOL] [EOL] @ property def grid_params ( self ) : [EOL] if self . _grid_params : [EOL] return self . _grid_params [EOL] self . _grid_params = self . default_parameters ( ) [EOL] return self . _grid_params [EOL] [EOL] @ grid_params . setter def grid_params ( self , value ) : [EOL] self . _grid_params = value [EOL] [EOL] @ classmethod def default_parameters ( cls ) : [EOL] raise NotImplementedError [EOL] [EOL] def create_pipeline ( self ) : [EOL] raise NotImplementedError [EOL] [EOL] def output_extension ( self ) : [EOL] return [string] [EOL] [EOL] def statistics ( self , y ) : [EOL] [docstring] [EOL] total = len ( y ) [EOL] cluster , counts = np . unique ( y [ y > - [number] ] , return_counts = True ) [EOL] noise = len ( y [ y == - [number] ] ) [EOL] return total , len ( cluster ) , counts . mean ( ) , counts . std ( ) , noise [EOL] [EOL] def load_data ( self ) : [EOL] df = self . area . import_dataset ( self . input ( ) . path ) [EOL] return df . values [EOL] [EOL] def run ( self ) : [EOL] param_grid = list ( ParameterGrid ( self . grid_params ) ) [EOL] results = pd . DataFrame ( data = param_grid ) [EOL] scores = [ ] [EOL] X = self . load_data ( ) [EOL] for params in param_grid : [EOL] pipeline = self . create_pipeline ( ) [EOL] pipeline . set_params ( ** params ) [EOL] scaler = pipeline . named_steps [ [string] ] [EOL] X_ = scaler . fit_transform ( X ) [EOL] y = pipeline . fit_predict ( X ) [EOL] noise_mask = y > - [number] [EOL] param_score = [ ] [EOL] for name , scorer in metrics . items ( ) : [EOL] logger . info ( f' [string] { name } [string] ' ) [EOL] try : [EOL] score = scorer ( X_ [ noise_mask ] , y [ noise_mask ] ) [EOL] except Exception as err : [EOL] logger . warn ( f' [string] { name } [string] { err }' ) [EOL] score = np . nan [EOL] param_score . append ( score ) [EOL] if isinstance ( self , GridSearchHDBSCAN ) : [EOL] [comment] [EOL] cluster = pipeline . named_steps [ [string] ] [EOL] dbcv_score = cluster . relative_validity_ [EOL] logger . info ( f' [string] { dbcv_score }' ) [EOL] param_score . append ( dbcv_score ) [EOL] scores . append ( param_score + list ( self . statistics ( y ) ) ) [EOL] [EOL] if isinstance ( self , GridSearchHDBSCAN ) : [EOL] column_names = list ( metrics . keys ( ) ) + [ [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] else : [EOL] column_names = list ( metrics . keys ( ) ) + [ [string] , [string] , [string] , [string] , [string] ] [EOL] scores = pd . DataFrame ( data = scores , columns = column_names ) [EOL] results = pd . concat ( [ results , scores ] , axis = [number] ) [EOL] with self . output ( ) . temporary_path ( ) as file : [EOL] results . to_csv ( file ) [EOL] [EOL] [EOL] class GridSearchDBSCAN ( GridSearch ) : [EOL] [EOL] @ classmethod def default_parameters ( cls ) : [EOL] return { [string] : [ [number] ] , [string] : [ [number] ] , [string] : [ [number] ] , [string] : [ [number] ] , [string] : [ [number] , [number] ] } [EOL] [EOL] def output_directory ( self ) : [EOL] return [string] [EOL] [EOL] def create_pipeline ( self ) : [EOL] return Pipeline ( [ ( [string] , SpatialWaterVapourScaler ( ) ) , ( [string] , DBSCAN ( ) ) ] ) [EOL] [EOL] [EOL] class GridSearchHDBSCAN ( GridSearch ) : [EOL] [EOL] @ classmethod def default_parameters ( cls ) : [EOL] return { [string] : [ [number] ] , [string] : [ [number] ] , [string] : [ [number] ] , [string] : [ [number] , [number] ] } [EOL] [EOL] def output_directory ( self ) : [EOL] return [string] [EOL] [EOL] def create_pipeline ( self ) : [EOL] return Pipeline ( [ ( [string] , SpatialWaterVapourScaler ( ) ) , ( [string] , HDBSCAN ( gen_min_span_tree = True ) ) ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $analysis.data.GeographicArea$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $numpy.ndarray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $sklearn.pipeline.Pipeline$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $sklearn.pipeline.Pipeline$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Tuple , List , Type [EOL] import builtins [EOL] import typing [EOL] import matplotlib [EOL] import pandas [EOL] [docstring] [EOL] [EOL] import glob [EOL] from random import choice , sample [EOL] from typing import List , Tuple [EOL] [EOL] from cartopy . mpl . ticker import LongitudeFormatter , LatitudeFormatter [EOL] [EOL] import cartopy . crs as ccrs [EOL] import matplotlib . patches as patches [EOL] import matplotlib . pyplot as plt [EOL] from matplotlib import colors [EOL] import numpy as np [EOL] import pandas as pd [EOL] from netCDF4 import Dataset [EOL] from matplotlib . gridspec import GridSpec [EOL] [EOL] [EOL] Coordinate = Tuple [ float , float ] [EOL] CoordinateRange = Tuple [ float , float ] [EOL] [EOL] features = [ [string] , [string] , [string] , [string] ] [EOL] flags = [ [string] , [string] , [string] ] [EOL] [EOL] [comment] [EOL] np . random . seed ( [number] ) [EOL] random_colors = colors . ListedColormap ( np . random . rand ( [number] , [number] ) ) [EOL] [EOL] [EOL] class GeographicArea : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , lat = ( [number] , - [number] ) , lon = ( [number] , - [number] ) , level = [number] ) : [EOL] [docstring] [EOL] self . lat = lat [EOL] self . lon = lon [EOL] self . level = level [EOL] [EOL] def import_dataset ( self , file_pattern ) : [EOL] [docstring] [EOL] frames = [ ] [EOL] for file in glob . glob ( file_pattern ) : [EOL] frame = pd . DataFrame ( ) [EOL] with Dataset ( file ) as nc : [EOL] [comment] [EOL] for feature in features [ : [number] ] : [EOL] var = nc [ feature ] [ ... ] [EOL] assert not var . mask . any ( ) [EOL] frame [ feature ] = var . data [EOL] [comment] [EOL] for feature in features [ [number] : ] : [EOL] var = nc [ feature ] [ : , self . level ] [EOL] assert not var . mask . any ( ) [EOL] frame [ feature ] = var . data [EOL] for flag in flags : [EOL] flag_data = nc [ [string] + flag ] [ ... ] [EOL] frame [ flag ] = flag_data . data [EOL] for flag in [ [string] , [string] ] : [EOL] flag_data = nc [ [string] + flag ] [ : , self . level ] [EOL] frame [ flag ] = flag_data . data [EOL] frame = self . filter_location ( frame ) [EOL] frame = self . filter_flags ( frame ) [EOL] frames . append ( frame ) [EOL] return pd . concat ( frames , ignore_index = True ) [ features ] [EOL] [EOL] def filter_location ( self , df ) : [EOL] return df [ ( df . lon . between ( * self . lon ) ) & ( df . lat . between ( * self . lat ) ) ] [EOL] [EOL] def filter_flags ( self , df ) : [EOL] return df [ ( df [ [string] ] . isin ( [ [number] , [number] , [number] ] ) ) & ( df [ [string] ] . isin ( [ [number] , [number] ] ) ) & ( df [ [string] ] == [number] ) & ( df [ [string] ] == [number] ) & ( df [ [string] ] == [number] ) ] [EOL] [EOL] def scatter ( self , * args , ** kwargs ) : [EOL] ax = plt . axes ( projection = ccrs . PlateCarree ( ) ) [EOL] ax . set_extent ( self . _get_extend ( ) , crs = ccrs . PlateCarree ( ) ) [EOL] ax . coastlines ( ) [EOL] ax . scatter ( * args , ** kwargs ) [EOL] return ax [EOL] [EOL] def _get_extend ( self ) : [EOL] return [ * self . lon , self . lat [ [number] ] , self . lat [ [number] ] ] [EOL] [EOL] def cluster_subsample ( self , df , n_samples ) : [EOL] sample_frames = [ ] [EOL] cluster = df . groupby ( [ [string] ] ) . groups [EOL] for cluster_indices in sample ( list ( cluster . values ( ) ) , n_samples ) : [EOL] sample_frames . append ( df . iloc [ cluster_indices ] ) [EOL] subsamples = pd . concat ( sample_frames ) [EOL] return df [ df . index . isin ( subsamples . index ) ] [EOL] [EOL] def filter_cluster_centroid ( self , df ) : [EOL] [comment] [EOL] groups = df . groupby ( [ [string] ] ) [ [string] , [string] ] . mean ( ) [EOL] [comment] [EOL] groups = self . filter_location ( groups ) [EOL] groups [ [string] ] = True [EOL] df = df . merge ( groups [ [string] ] , left_on = [string] , right_index = True , how = [string] ) [EOL] df [ [string] ] . fillna ( False , inplace = True ) [EOL] return df [ df [ [string] ] == True ] [EOL] [EOL] def _rectangle ( self , ** kwargs ) : [EOL] origin = ( self . lon [ [number] ] , self . lat [ [number] ] ) [EOL] width = self . lon [ [number] ] - self . lon [ [number] ] [EOL] height = self . lat [ [number] ] - self . lat [ [number] ] [EOL] return patches . Rectangle ( origin , width , height , ** kwargs ) [EOL] [EOL] def _set_ticks ( self , ax , steps = [number] ) : [EOL] [comment] [EOL] start = int ( self . lon [ [number] ] / [number] ) * [number] [EOL] xticks = np . arange ( start , self . lon [ [number] ] + steps , steps ) [EOL] ax . set_xticks ( xticks , crs = ccrs . PlateCarree ( ) ) [EOL] [comment] [EOL] start = int ( self . lat [ [number] ] / [number] ) * [number] [EOL] yticks = np . arange ( start , self . lat [ [number] ] + steps , steps ) [EOL] ax . set_yticks ( yticks , crs = ccrs . PlateCarree ( ) ) [EOL] [EOL] [comment] [EOL] lon_formatter = LongitudeFormatter ( zero_direction_label = True ) [EOL] ax . xaxis . set_major_formatter ( lon_formatter ) [EOL] lat_formatter = LatitudeFormatter ( ) [EOL] ax . yaxis . set_major_formatter ( lat_formatter ) [EOL] [EOL] [comment] [EOL] ax . set_xlim ( self . lon [ [number] ] , self . lon [ [number] ] ) [EOL] ax . set_ylim ( self . lat [ [number] ] , self . lat [ [number] ] ) [EOL] [EOL] def compare_plot ( self , X , y , include_noise = True , n_samples = None , subarea = None , filename = None ) : [EOL] [comment] [EOL] df = pd . DataFrame ( X , columns = features ) [EOL] df [ [string] ] = y [EOL] noise = df [ df [ [string] ] == - [number] ] [EOL] no_noise = df [ df [ [string] ] > - [number] ] [EOL] [EOL] [comment] [EOL] fig = plt . figure ( figsize = ( [number] , [number] ) ) [EOL] ax1 = plt . subplot ( [number] ) [comment] [EOL] ax1 . set_xlabel ( [string] ) [EOL] ax1 . set_ylabel ( [string] ) [EOL] ax2 = plt . subplot ( [number] , projection = ccrs . PlateCarree ( ) ) [comment] [EOL] ax2 . set_extent ( self . _get_extend ( ) , crs = ccrs . PlateCarree ( ) ) [EOL] self . _set_ticks ( ax2 ) [EOL] ax2 . coastlines ( ) [EOL] [EOL] [comment] [EOL] if include_noise and len ( noise ) > [number] : [EOL] self . geo_scatter ( ax2 , noise , c = [string] , alpha = [number] ) [EOL] [EOL] [comment] [EOL] if n_samples : [EOL] samples = self . cluster_subsample ( df , n_samples ) [EOL] self . water_scatter ( ax1 , samples ) [EOL] self . geo_scatter ( ax2 , samples ) [EOL] [EOL] [comment] [EOL] if subarea : [EOL] ax2 . add_patch ( subarea . _rectangle ( linewidth = [number] , edgecolor = [string] , facecolor = [string] ) ) [EOL] cluster_area = subarea . filter_cluster_centroid ( no_noise ) [EOL] outside_area = no_noise [ ~ no_noise . index . isin ( cluster_area . index ) ] [EOL] self . water_scatter ( ax1 , cluster_area ) [EOL] self . geo_scatter ( ax2 , cluster_area ) [EOL] self . geo_scatter ( ax2 , outside_area ) [EOL] [comment] [EOL] noise_area = subarea . filter_location ( noise ) [EOL] if include_noise and len ( noise_area ) > [number] : [EOL] self . water_scatter ( ax1 , noise_area , c = [string] , alpha = [number] ) [EOL] elif not n_samples : [EOL] if include_noise and len ( noise ) > [number] : [EOL] self . water_scatter ( ax1 , noise , c = [string] , alpha = [number] ) [EOL] self . water_scatter ( ax1 , no_noise , alpha = [number] ) [EOL] self . geo_scatter ( ax2 , no_noise , alpha = [number] ) [EOL] [EOL] if filename : [EOL] plt . savefig ( filename , bbox_inches = [string] ) [EOL] plt . show ( ) [EOL] [EOL] def geo_scatter ( self , ax , df , alpha = [number] , s = [number] , ** kwargs ) : [EOL] [comment] [EOL] cmap = kwargs . pop ( [string] , random_colors ) [EOL] c = kwargs . pop ( [string] , df [ [string] ] ) [EOL] ax . scatter ( df [ [string] ] , df [ [string] ] , c = c , cmap = cmap , alpha = alpha , s = s , ** kwargs ) [EOL] [EOL] def water_scatter ( self , ax , df , alpha = [number] , s = [number] , ** kwargs ) : [EOL] cmap = kwargs . pop ( [string] , random_colors ) [EOL] c = kwargs . pop ( [string] , df [ [string] ] ) [EOL] ax . scatter ( np . log ( df [ [string] ] ) , df [ [string] ] , c = c , cmap = cmap , alpha = alpha , s = s , ** kwargs ) [EOL] [EOL] def subarea_plot ( self , X , y , subarea , include_noise = True , filename = None ) : [EOL] [comment] [EOL] df = pd . DataFrame ( X , columns = features ) [EOL] df [ [string] ] = y [EOL] noise = df [ df [ [string] ] == - [number] ] [EOL] no_noise = df [ df [ [string] ] > - [number] ] [EOL] [EOL] [comment] [EOL] fig = plt . figure ( figsize = ( [number] , [number] ) ) [EOL] gs = GridSpec ( [number] , [number] , figure = fig ) [EOL] ax1 = plt . subplot ( gs [ [number] , : ] ) [comment] [EOL] ax1 . set_xlabel ( [string] ) [EOL] ax1 . set_ylabel ( [string] ) [EOL] ax2 = plt . subplot ( gs [ : [number] , [number] ] , projection = ccrs . PlateCarree ( ) ) [comment] [EOL] ax2 . set_extent ( self . _get_extend ( ) , crs = ccrs . PlateCarree ( ) ) [EOL] ax3 = plt . subplot ( gs [ : [number] , [number] ] , projection = ccrs . PlateCarree ( ) ) [comment] [EOL] ax3 . set_extent ( subarea . _get_extend ( ) , crs = ccrs . PlateCarree ( ) ) [EOL] self . _set_ticks ( ax2 ) [EOL] subarea . _set_ticks ( ax3 , [number] ) [EOL] ax2 . coastlines ( ) [EOL] ax3 . coastlines ( ) [EOL] [EOL] [comment] [EOL] if include_noise and len ( noise ) > [number] : [EOL] self . geo_scatter ( ax2 , noise , c = [string] , alpha = [number] ) [EOL] noise_area = subarea . filter_location ( noise ) [EOL] subarea . geo_scatter ( ax3 , noise_area , c = [string] , alpha = [number] ) [EOL] self . water_scatter ( ax1 , noise_area , c = [string] , alpha = [number] ) [EOL] [EOL] ax2 . add_patch ( subarea . _rectangle ( linewidth = [number] , edgecolor = [string] , facecolor = [string] ) ) [EOL] cluster_area = subarea . filter_cluster_centroid ( no_noise ) [EOL] outside_area = no_noise [ ~ no_noise . index . isin ( cluster_area . index ) ] [EOL] self . water_scatter ( ax1 , cluster_area ) [EOL] self . geo_scatter ( ax2 , cluster_area ) [EOL] self . geo_scatter ( ax2 , outside_area ) [EOL] self . geo_scatter ( ax3 , cluster_area ) [EOL] [EOL] if filename : [EOL] plt . savefig ( filename , bbox_inches = [string] ) [EOL] plt . show ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.float,builtins.float]$ 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.float,builtins.float]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.float,builtins.float]$ 0 $typing.Tuple[builtins.float,builtins.float]$ 0 0 0 $typing.Tuple[builtins.float,builtins.float]$ 0 $typing.Tuple[builtins.float,builtins.float]$ 0 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 $pandas.DataFrame$ 0 0 0 $pandas.DataFrame$ 0 0 0 0 $pandas.DataFrame$ 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 $pandas.DataFrame$ 0 0 0 0 $pandas.DataFrame$ 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 $pandas.DataFrame$ 0 $builtins.int$ 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $typing.List[typing.Any]$ 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $pandas.DataFrame$ 0 $pandas.DataFrame$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $matplotlib.patches.Rectangle$ 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.float,builtins.float]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.float,builtins.float]$ 0 $builtins.float$ 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
import warnings [EOL] warnings . filterwarnings ( [string] , category = DeprecationWarning )	0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] from typing import Any [EOL] import netCDF4 [EOL] import typing [EOL] from netCDF4 import Dataset [EOL] import sys [EOL] [EOL] assert len ( sys . argv ) == [number] [EOL] [EOL] slice = int ( sys . argv [ [number] ] ) [EOL] input = sys . argv [ [number] ] [EOL] output = sys . argv [ [number] ] [EOL] [EOL] [EOL] def copy_dimensions ( input , output ) : [EOL] for name , dim in input . dimensions . items ( ) : [EOL] output . createDimension ( name , len ( dim ) if not dim . isunlimited ( ) else None ) [EOL] [EOL] [EOL] def copy_variables ( input , output , slice ) : [EOL] [comment] [EOL] for name , var in input . variables . items ( ) : [EOL] out_var = output . createVariable ( name , var . datatype , var . dimensions ) [EOL] out_var . setncatts ( { k : var . getncattr ( k ) for k in var . ncattrs ( ) } ) [EOL] if var . dimensions [ [number] ] == [string] : [EOL] out_var [ : slice ] = var [ : slice ] [EOL] else : [EOL] out_var [ : ] = var [ : ] [EOL] [EOL] [EOL] with Dataset ( input ) as input , Dataset ( output , [string] ) as output : [EOL] copy_dimensions ( input , output ) [EOL] copy_variables ( input , output , slice ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.int$ 0 0