[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] [comment] [EOL] [EOL] from typing import List , Dict [EOL] import typing [EOL] project = [string] [EOL] copyright = [string] [EOL] author = [string] [EOL] [EOL] [comment] [EOL] release = [string] [EOL] [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] extensions = [ [string] , [string] , [string] ] [EOL] [EOL] [comment] [EOL] templates_path = [ [string] ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] exclude_patterns = [ [string] , [string] , [string] ] [EOL] [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] html_theme = [string] [EOL] html_logo = [string] [EOL] html_favicon = [string] [EOL] html_theme_options = { [string] : True , [string] : True , } [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] html_static_path = [ [string] ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $typing.Dict[builtins.str,builtins.bool]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , List , Dict [EOL] import typing [EOL] from __future__ import ( absolute_import , division , print_function ) [EOL] [EOL] __metaclass__ = type [EOL] [EOL] [EOL] def organize_images ( images ) : [EOL] image_names = list ( images . keys ( ) ) [EOL] image_reqs = { } [EOL] for image in image_names : [EOL] if [string] not in images [ image ] : [EOL] image_reqs [ image ] = [ ] [EOL] else : [EOL] image_reqs [ image ] = [ value for key , value in images [ image ] [ [string] ] . items ( ) ] [EOL] layers = [ ] [EOL] [EOL] while len ( image_names ) > [number] : [EOL] layer = [ ] [EOL] for image in image_names : [EOL] if len ( image_reqs [ image ] ) == [number] : [EOL] layer . append ( image ) [EOL] if len ( layer ) == [number] : [EOL] raise Exception ( [string] . format ( image_names ) ) [EOL] layers . append ( layer ) [EOL] for image in layer : [EOL] image_names . remove ( image ) [EOL] for obs_image in image_names : [EOL] if image in image_reqs [ obs_image ] : [EOL] image_reqs [ obs_image ] . remove ( image ) [EOL] return layers [EOL] [EOL] [EOL] class FilterModule ( object ) : [EOL] [docstring] [EOL] [EOL] def filters ( self ) : [EOL] return { [string] : organize_images } [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , Dict [EOL] import flask [EOL] import requests [EOL] import typing [EOL] from flask import Flask [EOL] from flask import Response [EOL] from flask import request [EOL] [EOL] import requests [EOL] [EOL] import base64 [EOL] from subprocess import check_output [EOL] [EOL] [EOL] app = Flask ( __name__ ) [EOL] [EOL] ELASTICSEARCH_PORT = [number] [EOL] ip = check_output ( [ [string] , [string] ] ) . decode ( [string] ) . split ( [string] ) [ [number] ] . strip ( ) [EOL] REDIRECT_TO = f' [string] { ip } [string] { ELASTICSEARCH_PORT } [string] ' [EOL] ADMIN_KEY = base64 . b64encode ( open ( [string] ) . read ( ) . encode ( [string] ) ) . decode ( [string] ) [EOL] [EOL] [EOL] def create_flask_response ( original_response ) : [EOL] flask_response = Response ( response = original_response . content , content_type = original_response . headers [ [string] ] ) [EOL] [EOL] flask_response . status_code = original_response . status_code [EOL] [EOL] for cookie_key , cookie_value in original_response . cookies . items ( ) : [EOL] flask_response . set_cookie ( cookie_key , value = cookie_value ) [EOL] [EOL] return flask_response [EOL] [EOL] [EOL] def is_gui_search_scroll_request ( url , request ) : [EOL] return request . method == [string] \ [EOL] and ( url == [string] or url == [string] or url == [string] ) [EOL] [EOL] [EOL] @ app . route ( [string] , methods = [ [string] , [string] , [string] , [string] , [string] ] ) @ app . route ( [string] , methods = [ [string] , [string] , [string] , [string] , [string] ] ) def redirect ( url = [string] ) : [EOL] new_url = url [EOL] if request . query_string : [EOL] new_url = new_url + [string] + request . query_string . decode ( [string] ) [EOL] [EOL] headers = dict ( request . headers ) [EOL] [EOL] if ( not is_gui_search_scroll_request ( url , request ) [EOL] and request . method != [string] [EOL] and ( headers . get ( [string] ) != f" [string] { ADMIN_KEY }" [EOL] and headers . get ( [string] ) != f" [string] { ADMIN_KEY }" ) ) : [EOL] return [string] , [number] [EOL] [EOL] response = requests . request ( request . method , str ( REDIRECT_TO + new_url ) , data = request . get_data ( ) , headers = headers , cookies = request . cookies ) [EOL] [EOL] return create_flask_response ( response ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $flask.app.Flask$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.int$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $flask.app.Flask$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $flask.app.Flask$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import typing [EOL] import main [EOL] [EOL] from grpc . _channel import _Rendezvous [EOL] import pytest [EOL] [EOL] [EOL] def test_make_prediction_retrying ( mocker ) : [EOL] mocker . patch ( [string] ) [EOL] mocker . patch ( [string] ) [EOL] predict_stub_mock = mocker . MagicMock ( ) [EOL] grpc_exception = _Rendezvous ( mocker . MagicMock ( ) , None , None , mocker . MagicMock ( ) ) [EOL] [EOL] mocker . patch . object ( predict_stub_mock , [string] ) . side_effect = [ grpc_exception , grpc_exception , mocker . MagicMock ( SerializeToString = lambda : [string] ) ] [EOL] result = main . make_prediction ( [string] , predict_stub_mock ) [EOL] [EOL] assert result == [string] [EOL] [EOL] [EOL] def test_make_prediction_too_much_retrying ( mocker ) : [EOL] mocker . patch ( [string] ) [EOL] mocker . patch ( [string] ) [EOL] predict_stub_mock = mocker . MagicMock ( ) [EOL] grpc_exception = _Rendezvous ( mocker . MagicMock ( ) , None , None , mocker . MagicMock ( ) ) [EOL] [EOL] mocker . patch . object ( predict_stub_mock , [string] ) . side_effect = grpc_exception [EOL] [EOL] with pytest . raises ( _Rendezvous ) : [EOL] main . make_prediction ( [string] , predict_stub_mock ) [EOL] [EOL] [EOL] def test_input_dir_does_not_exist ( mocker ) : [EOL] mocker . patch ( [string] ) . return_value = [string] [EOL] mocker . patch ( [string] ) . return_value = False [EOL] mocker . patch ( [string] ) [EOL] [EOL] with pytest . raises ( RuntimeError ) : [EOL] main . main ( ) [EOL] [EOL] [EOL] def test_input_dir_is_empty ( mocker ) : [EOL] mocker . patch ( [string] ) . return_value = [string] [EOL] mocker . patch ( [string] ) . return_value = True [EOL] mocker . patch ( [string] ) . return_value = [ ] [EOL] mocker . patch ( [string] ) [EOL] [EOL] with pytest . raises ( RuntimeError ) : [EOL] main . main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import sqlite3 [EOL] import datetime [EOL] import typing [EOL] from datetime import datetime [EOL] import sqlite3 [EOL] [EOL] DATABASE_FILENAME = [string] [EOL] [EOL] DATETIME_STRING_FORMAT = [string] [EOL] [EOL] [EOL] def init_db ( ) : [EOL] c = sqlite3 . connect ( DATABASE_FILENAME ) [EOL] try : [EOL] c . execute ( [string] ) [EOL] current_datetime = datetime . utcnow ( ) . strftime ( DATETIME_STRING_FORMAT ) [EOL] c . execute ( f" [string] { current_datetime } [string] " ) [EOL] c . commit ( ) [EOL] except sqlite3 . OperationalError as ex : [EOL] if [string] in str ( ex ) : [EOL] pass [EOL] else : [EOL] raise [EOL] finally : [EOL] c . close ( ) [EOL] [EOL] [EOL] def update_timestamp ( ) : [EOL] c = sqlite3 . connect ( DATABASE_FILENAME ) [EOL] current_datetime = datetime . utcnow ( ) . strftime ( DATETIME_STRING_FORMAT ) [EOL] c . execute ( f" [string] { current_datetime } [string] " ) [EOL] c . commit ( ) [EOL] c . close ( ) [EOL] [EOL] [EOL] def get_timestamp ( ) : [EOL] c = sqlite3 . connect ( DATABASE_FILENAME ) [EOL] cur = c . execute ( [string] ) [EOL] db_datetimestamp = cur . fetchone ( ) [EOL] c . close ( ) [EOL] [EOL] result = datetime . strptime ( db_datetimestamp [ [number] ] , DATETIME_STRING_FORMAT ) [EOL] [EOL] return result [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , Dict [EOL] import flask [EOL] import requests [EOL] import typing [EOL] import json [EOL] import logging [EOL] [EOL] from flask import Flask , Response , request [EOL] import requests [EOL] [EOL] import database [EOL] from models import InactivityResponse [EOL] [EOL] app = Flask ( __name__ ) [EOL] logging . basicConfig ( level = logging . INFO ) [EOL] [EOL] redirect_to = [string] . format ( [string] ) [EOL] [EOL] [EOL] database . init_db ( ) [EOL] [EOL] [EOL] @ app . route ( [string] , defaults = { [string] : [string] } ) @ app . route ( [string] ) def proxy ( url ) : [EOL] new_url = url [EOL] if request . query_string : [EOL] new_url = new_url + [string] + request . query_string . decode ( [string] ) [EOL] [EOL] headers = dict ( request . headers ) [EOL] [EOL] final_url = str ( redirect_to + new_url ) [EOL] [EOL] resp = requests . request ( request . method , final_url , data = request . get_data ( ) , headers = headers , cookies = request . cookies ) [EOL] [EOL] flask_resp = Response ( response = resp . content , content_type = resp . headers [ [string] ] ) [EOL] [EOL] flask_resp . status_code = resp . status_code [EOL] [EOL] for cookie_key , cookie_value in resp . cookies . items ( ) : [EOL] flask_resp . set_cookie ( cookie_key , value = cookie_value ) [EOL] [EOL] database . update_timestamp ( ) [EOL] [EOL] return flask_resp [EOL] [EOL] [EOL] @ app . route ( [string] ) def inactivity ( ) : [EOL] timestamp = database . get_timestamp ( ) [EOL] response = InactivityResponse ( last_request_datetime = timestamp ) [EOL] return Response ( response = json . dumps ( response . to_dict ( ) ) , content_type = [string] ) [EOL] [EOL] [EOL] @ app . route ( [string] ) def healthz ( ) : [EOL] resp = requests . get ( redirect_to ) [EOL] flask_response = Response ( ) [EOL] flask_response . status_code = resp . status_code [EOL] return flask_response [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $flask.app.Flask$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $flask.app.Flask$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $flask.app.Flask$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $flask.app.Flask$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $flask.app.Flask$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import datetime [EOL] from datetime import datetime [EOL] [EOL] [EOL] class InactivityResponse : [EOL] def __init__ ( self , last_request_datetime ) : [EOL] self . last_request_datetime = last_request_datetime [EOL] [EOL] def to_dict ( self ) : [EOL] return { [string] : self . last_request_datetime . isoformat ( ) }	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $datetime.datetime.datetime$ 0 0 0 0 0 $datetime.datetime.datetime$ 0 $datetime.datetime.datetime$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import builtins [EOL] from typing import Any [EOL] import flask [EOL] import datetime [EOL] import typing [EOL] from datetime import datetime [EOL] from http import HTTPStatus [EOL] import json [EOL] from unittest . mock import MagicMock [EOL] [EOL] from flask . testing import FlaskClient [EOL] import pytest [EOL] [EOL] import database [EOL] [EOL] [EOL] @ pytest . fixture def flask_client ( mocker ) : [EOL] mocker . patch ( [string] ) [EOL] from proxy import app [EOL] client = app . test_client ( ) [EOL] yield client [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ [string] , [string] ] ) [comment] [EOL] def test_proxy ( mocker , flask_client , url ) : [EOL] fake_upstream_response = [string] [EOL] fake_upstream_response_status_code = HTTPStatus . OK [EOL] mocker . patch ( [string] ) . return_value = MagicMock ( content = fake_upstream_response . encode ( [string] ) , headers = { [string] : [string] } , status_code = fake_upstream_response_status_code . value ) [EOL] mocker . patch ( [string] ) [EOL] [EOL] response = flask_client . get ( url ) [EOL] [EOL] response_body = response . data . decode ( [string] ) [EOL] [EOL] assert response_body == [string] [EOL] assert response . status_code == HTTPStatus . OK [EOL] [comment] [EOL] assert database . update_timestamp . call_count == [number] [EOL] [EOL] [EOL] def test_inactivity ( mocker , flask_client ) : [EOL] fake_timestamp = datetime ( [number] , [number] , [number] , [number] , [number] , [number] , [number] ) [EOL] mocker . patch ( [string] ) . return_value = fake_timestamp [EOL] response = flask_client . get ( [string] ) [EOL] [EOL] response_body = response . data . decode ( [string] ) [EOL] response_json = json . loads ( response_body ) [EOL] [EOL] assert response_json [ [string] ] == fake_timestamp . isoformat ( ) [EOL] assert response . status_code == HTTPStatus . OK [EOL] [comment] [EOL] assert database . get_timestamp . call_count == [number] [EOL] [EOL] [EOL] def test_healthz ( mocker , flask_client ) : [EOL] fake_upstream_response_status_code = HTTPStatus . OK [EOL] mocker . patch ( [string] ) . return_value = MagicMock ( status_code = fake_upstream_response_status_code . value ) [EOL] [EOL] response = flask_client . get ( [string] ) [EOL] [EOL] assert response . status_code == fake_upstream_response_status_code [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import datetime [EOL] import typing [EOL] from datetime import datetime [EOL] [EOL] import sqlite3 [EOL] import pytest [EOL] [EOL] import database [EOL] [EOL] [EOL] def test_init_db ( mocker ) : [EOL] fake_connection = mocker . MagicMock ( ) [EOL] mocker . patch ( [string] ) . return_value = fake_connection [EOL] database . init_db ( ) [EOL] [EOL] assert fake_connection . execute . call_count == [number] [EOL] assert fake_connection . commit . call_count == [number] [EOL] assert fake_connection . close . call_count == [number] [EOL] [EOL] [EOL] def test_init_db_already_exists ( mocker ) : [EOL] fake_connection = mocker . MagicMock ( ) [EOL] mocker . patch . object ( fake_connection , [string] ) . side_effect = sqlite3 . OperationalError ( [string] ) [EOL] mocker . patch ( [string] ) . return_value = fake_connection [EOL] [EOL] database . init_db ( ) [EOL] [EOL] assert fake_connection . execute . call_count == [number] [EOL] assert fake_connection . commit . call_count == [number] [EOL] assert fake_connection . close . call_count == [number] [EOL] [EOL] [EOL] def test_init_db_unknown_error ( mocker ) : [EOL] fake_connection = mocker . MagicMock ( ) [EOL] mocker . patch . object ( fake_connection , [string] ) . side_effect = sqlite3 . OperationalError [EOL] mocker . patch ( [string] ) . return_value = fake_connection [EOL] [EOL] with pytest . raises ( sqlite3 . OperationalError ) : [EOL] database . init_db ( ) [EOL] [EOL] [EOL] [EOL] def test_update_timestamp ( mocker ) : [EOL] fake_connection = mocker . MagicMock ( ) [EOL] mocker . patch ( [string] ) . return_value = fake_connection [EOL] database . update_timestamp ( ) [EOL] [EOL] assert fake_connection . execute . call_count == [number] [EOL] assert fake_connection . commit . call_count == [number] [EOL] assert fake_connection . close . call_count == [number] [EOL] [EOL] [EOL] def test_get_timestamp ( mocker ) : [EOL] expected_datetime_return = datetime ( year = [number] , month = [number] , day = [number] , hour = [number] , minute = [number] , second = [number] ) [EOL] fake_cursor = mocker . MagicMock ( fetchone = lambda : ( [string] , ) ) [EOL] mocker . spy ( fake_cursor , [string] ) [EOL] fake_connection = mocker . MagicMock ( execute = lambda * args : fake_cursor ) [EOL] mocker . spy ( fake_connection , [string] ) [EOL] mocker . patch ( [string] ) . return_value = fake_connection [EOL] timestamp = database . get_timestamp ( ) [EOL] [EOL] assert timestamp == expected_datetime_return [EOL] assert fake_connection . execute . call_count == [number] [EOL] assert fake_cursor . fetchone . call_count == [number] [EOL] assert fake_connection . close . call_count == [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , Optional [EOL] import logging [EOL] import typing [EOL] import kubernetes [EOL] import logging as log [EOL] [comment] [EOL] from os import getenv , _exit , path [EOL] from time import sleep [EOL] [EOL] from kubernetes import client , config [EOL] from kubernetes . client import V1Job , V1JobStatus [EOL] [EOL] END_HOOK_FILEPATH = [string] [EOL] [EOL] log . basicConfig ( level = log . DEBUG ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] k8s_rest_logger = log . getLogger ( [string] ) [EOL] k8s_rest_logger . setLevel ( log . INFO ) [EOL] [EOL] [EOL] def main ( ) : [EOL] if path . isfile ( END_HOOK_FILEPATH ) : [EOL] log . info ( [string] ) [EOL] return [EOL] [EOL] config . load_incluster_config ( ) [EOL] [EOL] batch_wrapper_job_name = getenv ( [string] ) [EOL] [EOL] if batch_wrapper_job_name is None : [EOL] raise RuntimeError ( [string] ) [EOL] [EOL] with open ( [string] , mode = [string] ) as file : [EOL] my_current_namespace = file . read ( ) [EOL] [EOL] if not my_current_namespace : [EOL] raise RuntimeError ( f" [string] { str ( my_current_namespace ) }" ) [EOL] [EOL] v1 = client . BatchV1Api ( ) [EOL] [EOL] while True : [EOL] batch_wrapper_job = v1 . read_namespaced_job ( name = batch_wrapper_job_name , namespace = my_current_namespace ) [EOL] [EOL] batch_wrapper_job_status = batch_wrapper_job . status [EOL] [EOL] active_pods = batch_wrapper_job_status . active if batch_wrapper_job_status . active is not None else [number] [EOL] succeeded_pods = batch_wrapper_job_status . succeeded if batch_wrapper_job_status . succeeded is not None else [number] [EOL] [EOL] [comment] [EOL] if hasattr ( batch_wrapper_job_status , [string] ) and batch_wrapper_job_status . failed is not None : [EOL] failed_pods = batch_wrapper_job_status . failed [EOL] else : [EOL] failed_pods = [number] [EOL] [EOL] if active_pods == [number] and ( succeeded_pods > [number] or failed_pods > [number] ) : [EOL] log . info ( f" [string] { active_pods } [string] { succeeded_pods } [string] { failed_pods } [string] " f" [string] " ) [EOL] open ( END_HOOK_FILEPATH , [string] ) . close ( ) [EOL] log . info ( [string] ) [EOL] return [EOL] [EOL] sleep ( [number] ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL] _exit ( [number] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , List [EOL] import typing [EOL] from kubernetes . client import V1Job , V1JobStatus [EOL] from pytest import fixture , raises [EOL] [EOL] from main import main [EOL] [EOL] [EOL] @ fixture def main_mock ( mocker ) : [EOL] mocker . patch ( [string] ) . return_value = False [EOL] kubernetes_config_load = mocker . patch ( [string] ) [EOL] mocker . patch ( [string] ) . return_value = [string] [EOL] file_mock = mocker . MagicMock ( read = lambda : [string] ) [EOL] open_mock = mocker . MagicMock ( __enter__ = lambda x : file_mock ) [EOL] builtins_open = mocker . patch ( [string] ) [EOL] builtins_open . return_value = open_mock [EOL] main_sleep = mocker . patch ( [string] ) [EOL] [EOL] fake_k8s_client = mocker . MagicMock ( ) [EOL] mocker . patch ( [string] ) . return_value = fake_k8s_client [EOL] mocker . patch . object ( fake_k8s_client , [string] ) . return_value = V1Job ( status = V1JobStatus ( active = [number] , succeeded = [number] ) ) [EOL] [EOL] class MainMock : [EOL] kubernetes_config_load_mock = kubernetes_config_load [EOL] builtins_open_mock = builtins_open [EOL] kubernetes_client_mock = fake_k8s_client [EOL] time_sleep_mock = main_sleep [EOL] [EOL] return MainMock [EOL] [EOL] [EOL] def test_main ( mocker , main_mock ) : [EOL] job_status_history = [ V1Job ( status = V1JobStatus ( active = [number] , succeeded = [number] ) ) , V1Job ( status = V1JobStatus ( active = [number] , succeeded = [number] ) ) , V1Job ( status = V1JobStatus ( active = [number] , succeeded = [number] ) ) ] [EOL] [EOL] mocker . patch . object ( main_mock . kubernetes_client_mock , [string] ) . side_effect = job_status_history [EOL] [EOL] main ( ) [EOL] [EOL] assert main_mock . kubernetes_config_load_mock . call_count == [number] [EOL] assert main_mock . builtins_open_mock . call_count == [number] [EOL] assert main_mock . time_sleep_mock . call_count == len ( job_status_history ) - [number] [EOL] [EOL] [EOL] def test_main_failed_pods ( mocker , main_mock ) : [EOL] job_status_history = [ V1Job ( status = V1JobStatus ( active = [number] , succeeded = [number] ) ) , V1Job ( status = V1JobStatus ( active = [number] , succeeded = [number] ) ) , V1Job ( status = V1JobStatus ( active = [number] , succeeded = [number] , failed = [number] ) ) ] [EOL] [EOL] mocker . patch . object ( main_mock . kubernetes_client_mock , [string] ) . side_effect = job_status_history [EOL] [EOL] main ( ) [EOL] [EOL] assert main_mock . kubernetes_config_load_mock . call_count == [number] [EOL] assert main_mock . builtins_open_mock . call_count == [number] [EOL] assert main_mock . time_sleep_mock . call_count == len ( job_status_history ) - [number] [EOL] [EOL] [EOL] def test_main_end_hook_already_created ( mocker , main_mock ) : [EOL] mocker . patch ( [string] ) . return_value = True [EOL] [EOL] main ( ) [EOL] [EOL] assert main_mock . kubernetes_config_load_mock . call_count == [number] [EOL] assert main_mock . builtins_open_mock . call_count == [number] [EOL] [EOL] [EOL] [comment] [EOL] def test_main_missing_batch_wrapper_job_name ( mocker , main_mock ) : [EOL] mocker . patch ( [string] ) . return_value = None [EOL] [EOL] with raises ( RuntimeError ) : [EOL] main ( ) [EOL] [EOL] [EOL] def test_main_missing_current_namespace ( mocker , main_mock ) : [EOL] file_mock = mocker . MagicMock ( read = lambda : [string] ) [EOL] open_mock = mocker . MagicMock ( __enter__ = lambda x : file_mock ) [EOL] builtins_open = mocker . patch ( [string] ) [EOL] builtins_open . return_value = open_mock [EOL] [EOL] with raises ( RuntimeError ) : [EOL] main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , Dict [EOL] import asyncio [EOL] import nauta_resources [EOL] import typing [EOL] import asyncio [EOL] import datetime [EOL] [EOL] import kopf [EOL] import pykube [EOL] [EOL] from nauta_resources . run import Run , RunStatus [EOL] [EOL] tasks = { } [comment] [EOL] [EOL] try : [EOL] cfg = pykube . KubeConfig . from_service_account ( ) [EOL] except FileNotFoundError : [EOL] cfg = pykube . KubeConfig . from_file ( ) [EOL] api = pykube . HTTPClient ( cfg ) [EOL] [EOL] kopf . EventsConfig . events_loglevel = kopf . config . LOGLEVEL_WARNING [EOL] [EOL] [EOL] @ kopf . on . resume ( [string] , [string] , [string] ) async def handle_run_on_resume ( namespace , name , logger , spec , ** kwargs ) : [EOL] try : [EOL] run_state = RunStatus ( spec [ [string] ] ) [EOL] except ValueError : [EOL] raise kopf . PermanentError ( f' [string] { name } [string] { spec }' ) [EOL] [EOL] if run_state in { RunStatus . COMPLETE , RunStatus . FAILED , RunStatus . CANCELLED } : [EOL] logger . info ( f' [string] { name } [string] { run_state . value } [string] ' ) [EOL] if namespace in tasks and name in tasks [ namespace ] : [EOL] del tasks [ namespace ] [ name ] [EOL] return [EOL] elif not tasks . get ( namespace , { } ) . get ( name ) : [EOL] logger . info ( f' [string] { name } [string] ' ) [EOL] task = asyncio . create_task ( monitor_run ( namespace , name , logger ) ) [EOL] tasks . setdefault ( namespace , { } ) [EOL] tasks [ namespace ] [ name ] = task [EOL] [EOL] [EOL] @ kopf . on . create ( [string] , [string] , [string] ) async def run_created ( namespace , name , logger , ** kwargs ) : [EOL] logger . warning ( f' [string] { name } [string] ' ) [EOL] task = asyncio . create_task ( monitor_run ( namespace , name , logger ) ) [EOL] tasks . setdefault ( namespace , { } ) [EOL] tasks [ namespace ] [ name ] = task [EOL] [EOL] [EOL] @ kopf . on . delete ( [string] , [string] , [string] ) async def run_deleted ( namespace , name , logger , ** kwargs ) : [EOL] logger . warning ( f' [string] { name } [string] ' ) [EOL] if namespace in tasks and name in tasks [ namespace ] : [EOL] task = tasks [ namespace ] [ name ] [EOL] task . cancel ( ) [comment] [EOL] [EOL] [EOL] async def monitor_run ( namespace , name , logger ) : [EOL] interval = [number] [EOL] retry_counter = [number] [EOL] retry_limit = [number] [EOL] while True : [EOL] try : [EOL] await asyncio . sleep ( interval ) [EOL] logger . debug ( f' [string] { name }' ) [EOL] run = await Run . get ( name = name , namespace = namespace ) [EOL] [EOL] if run . state in { RunStatus . COMPLETE , RunStatus . FAILED , RunStatus . CANCELLED } : [EOL] logger . info ( f' [string] { name } [string] { run . state . value } [string] ' ) [EOL] if namespace in tasks and name in tasks [ namespace ] : [EOL] del tasks [ namespace ] [ name ] [EOL] return [EOL] [EOL] state_to_set = await run . calculate_current_state ( ) [EOL] if run . state is not state_to_set : [EOL] logger . warning ( f' [string] { name } [string] { run . state . value } [string] { state_to_set . value }' ) [EOL] utc_timestamp = datetime . datetime . utcnow ( ) . replace ( microsecond = [number] ) . isoformat ( ) [EOL] if run . state is RunStatus . QUEUED : [EOL] logger . info ( f' [string] { name } [string] ' ) [EOL] run . start_timestamp = f'{ utc_timestamp } [string] ' [EOL] if run . state in { RunStatus . QUEUED , RunStatus . RUNNING } and state_to_set not in { RunStatus . QUEUED , RunStatus . RUNNING } : [EOL] logger . info ( f' [string] { name } [string] ' ) [EOL] run . end_timestamp = f'{ utc_timestamp } [string] ' [EOL] run . state = state_to_set [EOL] await run . update ( ) [EOL] [EOL] except asyncio . CancelledError : [EOL] logger . info ( f' [string] { name } [string] ' ) [EOL] if namespace in tasks and name in tasks [ namespace ] : [EOL] del tasks [ namespace ] [ name ] [EOL] return [EOL] except Exception : [EOL] logger . exception ( f' [string] { name } [string] ' ) [EOL] retry_counter += [number] [EOL] logger . exception ( f' [string] { retry_counter } [string] { retry_limit } [string] ' ) [EOL] if retry_counter >= retry_limit : [EOL] raise [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import List , TypeVar , Dict , Any , Optional [EOL] import logging [EOL] import kubernetes_asyncio [EOL] import builtins [EOL] import typing [EOL] import http [EOL] from typing import Dict , List , Optional , TypeVar [EOL] import logging [EOL] [EOL] import dpath . util [EOL] import yaml [EOL] from kubernetes_asyncio import client , config [EOL] from kubernetes_asyncio . client import CustomObjectsApi , CoreV1Api [EOL] from kubernetes_asyncio . client . rest import ApiException [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class K8SApiClient : [EOL] [docstring] [EOL] core_api = None [EOL] [EOL] @ classmethod async def get ( cls ) : [EOL] if cls . core_api : [EOL] return cls . core_api [EOL] else : [EOL] try : [EOL] try : [EOL] await config . load_kube_config ( ) [EOL] except FileNotFoundError : [EOL] config . load_incluster_config ( ) [EOL] [EOL] cls . core_api = client . CoreV1Api ( client . ApiClient ( ) ) [EOL] return cls . core_api [EOL] except Exception : [EOL] logger . exception ( f' [string] { cls . __name__ }' ) [EOL] raise [EOL] [EOL] [EOL] class CustomResourceApiClient : [EOL] [docstring] [EOL] k8s_custom_object_api = None [EOL] [EOL] @ classmethod async def get ( cls ) : [EOL] if cls . k8s_custom_object_api : [EOL] return cls . k8s_custom_object_api [EOL] else : [EOL] try : [EOL] try : [EOL] await config . load_kube_config ( ) [EOL] except FileNotFoundError : [EOL] config . load_incluster_config ( ) [EOL] [EOL] cls . k8s_custom_object_api = client . CustomObjectsApi ( client . ApiClient ( ) ) [EOL] return cls . k8s_custom_object_api [EOL] except Exception : [EOL] logger . exception ( f' [string] { cls . __name__ }' ) [EOL] raise [EOL] [EOL] [EOL] CustomResourceTypeVar = TypeVar ( [string] , bound = [string] ) [EOL] [EOL] [EOL] class CustomResource : [EOL] [docstring] [EOL] api_group_name = ... [EOL] crd_plural_name = ... [EOL] crd_version = ... [EOL] [EOL] def __init__ ( self , body = None , name = None , namespace = None ) : [EOL] [comment] [EOL] [comment] [EOL] self . _fields_to_update = set ( ) [EOL] [EOL] self . _body = body [EOL] self . name = name [EOL] self . namespace = namespace [EOL] [EOL] @ property def metadata ( self ) : [EOL] return self . _body . get ( [string] ) [EOL] [EOL] @ metadata . setter def metadata ( self , value ) : [EOL] self . _body [ [string] ] = value [EOL] self . _fields_to_update . add ( [string] ) [EOL] [EOL] @ property def creation_timestamp ( self ) : [EOL] return self . _body . get ( [string] , { } ) . get ( [string] ) [EOL] [EOL] @ creation_timestamp . setter def creation_timestamp ( self , value ) : [EOL] if not self . _body . get ( [string] ) : [EOL] self . _body [ [string] ] = { } [EOL] self . _body [ [string] ] [ [string] ] = value [EOL] self . _fields_to_update . add ( [string] ) [EOL] [EOL] def __repr__ ( self ) : [EOL] def format_field_value ( value ) : [EOL] return f' [string] { value } [string] ' if type ( value ) == str else value [EOL] [EOL] fields = [string] . join ( [ [string] . format ( key = key , value = format_field_value ( value ) ) for key , value in self . __dict__ . items ( ) ] ) [EOL] return [string] . format ( class_name = self . __class__ . __name__ , fields = fields ) [EOL] [EOL] def __eq__ ( self , other ) : [EOL] if isinstance ( self , other . __class__ ) : [EOL] return { k : v for k , v in self . __dict__ . items ( ) } == { k : v for k , v in other . __dict__ . items ( ) } [EOL] return False [EOL] [EOL] @ classmethod def from_k8s_response_dict ( cls , object_dict ) : [EOL] [comment] [EOL] try : [EOL] del object_dict [ [string] ] [ [string] ] [EOL] del object_dict [ [string] ] [ [string] ] [EOL] except KeyError : [EOL] pass [EOL] return cls ( name = object_dict [ [string] ] [ [string] ] , body = object_dict , namespace = object_dict . get ( [string] , { } ) . get ( [string] ) ) [EOL] [EOL] @ classmethod def from_yaml ( cls , yaml_template_path , * args , ** kwargs ) : [EOL] with open ( yaml_template_path , mode = [string] , encoding = [string] ) as yaml_template_file : [EOL] resource_body = yaml . safe_load ( yaml_template_file ) [EOL] kwargs . pop ( [string] , None ) [EOL] return cls ( body = resource_body , * args , ** kwargs ) [EOL] [EOL] @ classmethod async def list ( cls , namespace = None , label_selector = None , ** kwargs ) : [EOL] logger . debug ( f' [string] { cls . __name__ } [string] ' ) [EOL] k8s_custom_object_api = await CustomResourceApiClient . get ( ) [EOL] if namespace : [EOL] raw_resources = await k8s_custom_object_api . list_namespaced_custom_object ( group = cls . api_group_name , namespace = namespace , plural = cls . crd_plural_name , version = cls . crd_version , label_selector = label_selector ) [EOL] else : [EOL] raw_resources = await k8s_custom_object_api . list_cluster_custom_object ( group = cls . api_group_name , plural = cls . crd_plural_name , version = cls . crd_version , label_selector = label_selector ) [EOL] [EOL] return [ cls . from_k8s_response_dict ( raw_resource ) for raw_resource in raw_resources [ [string] ] ] [EOL] [EOL] @ classmethod async def get ( cls , name , namespace = None ) : [EOL] logger . debug ( f' [string] { cls . __name__ } [string] { name } [string] { namespace } [string] ' ) [EOL] k8s_custom_object_api = await CustomResourceApiClient . get ( ) [EOL] try : [EOL] if namespace : [EOL] raw_object = await k8s_custom_object_api . get_namespaced_custom_object ( group = cls . api_group_name , namespace = namespace , plural = cls . crd_plural_name , version = cls . crd_version , name = name ) [EOL] else : [EOL] raw_object = await k8s_custom_object_api . get_cluster_custom_object ( group = cls . api_group_name , plural = cls . crd_plural_name , version = cls . crd_version , name = name ) [EOL] [EOL] except ApiException as e : [EOL] if e . status == http . HTTPStatus . NOT_FOUND : [EOL] logger . debug ( f' [string] { cls . __name__ } [string] { name } [string] { namespace } [string] ' ) [EOL] raw_object = None [EOL] else : [EOL] logger . exception ( f' [string] { e . status } [string] { cls . __name__ } [string] ' f'{ name } [string] { namespace } [string] ' ) [EOL] raise [EOL] [EOL] return cls . from_k8s_response_dict ( raw_object ) if raw_object else None [EOL] [EOL] @ property def labels ( self ) : [EOL] return self . _body . get ( [string] , { } ) . get ( [string] , { } ) [EOL] [EOL] @ labels . setter def labels ( self , value ) : [EOL] if not self . _body . get ( [string] ) : [EOL] self . _body [ [string] ] = { } [EOL] self . _body [ [string] ] [ [string] ] = value [EOL] [EOL] async def create ( self , namespace , labels = None , annotations = None ) : [EOL] logger . debug ( f' [string] { self . __class__ . __name__ } [string] { self . name } [string] ' ) [EOL] k8s_custom_object_api = await CustomResourceApiClient . get ( ) [EOL] try : [EOL] if labels : [EOL] self . _body [ [string] ] [ [string] ] = labels [EOL] if annotations : [EOL] self . _body [ [string] ] [ [string] ] = annotations [EOL] response = await k8s_custom_object_api . create_namespaced_custom_object ( group = self . api_group_name , namespace = namespace , body = self . _body , plural = self . crd_plural_name , version = self . crd_version ) [EOL] self . name = response [ [string] ] [ [string] ] [EOL] self . namespace = response [ [string] ] [ [string] ] [EOL] return response [EOL] except ApiException : [EOL] logger . exception ( f' [string] { self . __class__ . __name__ } [string] { self . name } [string] ' ) [EOL] raise [EOL] [EOL] async def delete ( self ) : [EOL] if not self . name : [EOL] raise RuntimeError ( f'{ self . __class__ . __name__ } [string] ' ) [EOL] [EOL] logger . debug ( f' [string] { self . __class__ . __name__ } [string] { self . name } [string] ' ) [EOL] k8s_custom_object_api = await CustomResourceApiClient . get ( ) [EOL] [EOL] try : [EOL] response = await k8s_custom_object_api . delete_namespaced_custom_object ( group = self . api_group_name , namespace = self . namespace , plural = self . crd_plural_name , version = self . crd_version , name = self . name , body = { } ) [EOL] return response [EOL] except ApiException : [EOL] logger . exception ( f' [string] { self . __class__ . __name__ } [string] { self . name } [string] ' ) [EOL] raise [EOL] [EOL] async def update ( self ) : [EOL] logger . debug ( f' [string] { self . __class__ . __name__ } [string] { self . name } [string] ' ) [EOL] k8s_custom_object_api = await CustomResourceApiClient . get ( ) [EOL] [EOL] patch_body = { } [EOL] if self . _fields_to_update : [EOL] for field in self . _fields_to_update : [EOL] dpath . util . new ( patch_body , field , dpath . util . get ( self . _body , field , separator = [string] ) , separator = [string] ) [EOL] logger . debug ( f' [string] { self . __class__ . __name__ } [string] { self . name } [string] { patch_body }' ) [EOL] else : [EOL] logger . debug ( f' [string] { self . __class__ . __name__ } [string] { self . name } [string] ' ) [EOL] return [EOL] try : [EOL] response = await k8s_custom_object_api . patch_namespaced_custom_object ( group = self . api_group_name , namespace = self . namespace , body = patch_body , plural = self . crd_plural_name , version = self . crd_version , name = self . name ) [EOL] self . _fields_to_update = set ( ) [comment] [EOL] return response [EOL] except ApiException : [EOL] logger . exception ( f' [string] { self . __class__ . __name__ } [string] { self . name } [string] ' ) [EOL] raise [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[CustomResourceTypeVar]$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Optional[CustomResourceTypeVar]$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 $None$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 $None$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import builtins [EOL] from typing import Any , Union , List , Dict [EOL] import kubernetes_asyncio [EOL] import typing [EOL] import unittest [EOL] import copy [EOL] from unittest . mock import MagicMock [EOL] [EOL] import pytest [EOL] from kubernetes_asyncio . client import CustomObjectsApi , V1Pod , V1PodStatus , CoreV1Api , V1PodList [EOL] from kubernetes_asyncio . client . rest import ApiException [EOL] from asynctest import CoroutineMock [EOL] [EOL] from nauta_resources . run import Run , RunStatus [EOL] from nauta_resources . platform_resource import CustomResourceApiClient , K8SApiClient [EOL] [EOL] TEST_RUNS = [ Run ( name = [string] , parameters = [ [string] , [string] , [string] ] , state = RunStatus . QUEUED , metrics = { [string] : [number] } , experiment_name = [string] , pod_count = [number] , pod_selector = { [string] : { [string] : [string] , [string] : [string] , [string] : [string] } } , namespace = [string] , template_name = [string] ) , Run ( name = [string] , parameters = [ [string] , [string] , [string] ] , state = RunStatus . COMPLETE , metrics = { [string] : [number] } , experiment_name = [string] , pod_count = [number] , pod_selector = { [string] : { [string] : [string] , [string] : [string] , [string] : [string] } } , namespace = [string] , template_name = [string] , start_timestamp = [string] , end_timestamp = [string] ) ] [EOL] [EOL] [EOL] @ pytest . fixture ( scope = [string] ) def mock_custom_resource_api_client ( ) : [EOL] custom_objects_api_mock = MagicMock ( ) [EOL] CustomResourceApiClient . k8s_custom_object_api = custom_objects_api_mock [EOL] [EOL] custom_objects_api_mock . list_cluster_custom_object = CoroutineMock ( ) [EOL] custom_objects_api_mock . list_namespaced_custom_object = CoroutineMock ( ) [EOL] custom_objects_api_mock . get_cluster_custom_object = CoroutineMock ( ) [EOL] custom_objects_api_mock . get_namespaced_custom_object = CoroutineMock ( ) [EOL] custom_objects_api_mock . patch_namespaced_custom_object = CoroutineMock ( ) [EOL] custom_objects_api_mock . create_namespaced_custom_object = CoroutineMock ( ) [EOL] custom_objects_api_mock . delete_namespaced_custom_object = CoroutineMock ( ) [EOL] yield custom_objects_api_mock [EOL] [EOL] CustomResourceApiClient . k8s_custom_object_api = None [EOL] [EOL] [EOL] @ pytest . fixture ( scope = [string] ) def mock_k8s_api_client ( ) : [EOL] k8s_api_mock = MagicMock ( ) [EOL] K8SApiClient . core_api = k8s_api_mock [EOL] [EOL] k8s_api_mock . list_namespaced_pod = CoroutineMock ( ) [EOL] yield k8s_api_mock [EOL] [EOL] K8SApiClient . core_api = None [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_list_runs ( mock_custom_resource_api_client ) : [EOL] mock_custom_resource_api_client . list_cluster_custom_object . return_value = LIST_RUNS_RESPONSE_RAW [EOL] runs = await Run . list ( ) [EOL] assert runs == TEST_RUNS [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_list_runs_from_namespace ( mock_custom_resource_api_client ) : [EOL] raw_runs_single_namespace = dict ( LIST_RUNS_RESPONSE_RAW ) [EOL] raw_runs_single_namespace [ [string] ] = [ raw_runs_single_namespace [ [string] ] [ [number] ] ] [EOL] mock_custom_resource_api_client . list_namespaced_custom_object . return_value = raw_runs_single_namespace [EOL] [EOL] runs = await Run . list ( namespace = [string] ) [EOL] [EOL] assert [ TEST_RUNS [ [number] ] ] == runs [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_get_run_from_namespace ( mock_custom_resource_api_client ) : [EOL] mock_custom_resource_api_client . get_namespaced_custom_object . return_value = GET_RUN_RESPONSE_RAW [EOL] run = await Run . get ( name = RUN_NAME , namespace = NAMESPACE ) [EOL] assert run is not None and type ( run ) is Run [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_get_run_not_found ( mock_custom_resource_api_client ) : [EOL] mock_custom_resource_api_client . get_namespaced_custom_object . side_effect = ApiException ( status = [number] ) [EOL] run = await Run . get ( name = RUN_NAME , namespace = NAMESPACE ) [EOL] assert run is None [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_get_run_failure ( mock_custom_resource_api_client ) : [EOL] mock_custom_resource_api_client . get_namespaced_custom_object . side_effect = ApiException ( status = [number] ) [EOL] with pytest . raises ( ApiException ) : [EOL] await Run . get ( name = RUN_NAME , namespace = NAMESPACE ) [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_update_run_failure ( mock_custom_resource_api_client ) : [EOL] mock_custom_resource_api_client . patch_namespaced_custom_object . side_effect = ApiException ( ) [EOL] test_run = copy . deepcopy ( TEST_RUNS [ [number] ] ) [EOL] test_run . experiment_name = [string] [EOL] test_run . start_timestamp = [string] [EOL] [EOL] with pytest . raises ( ApiException ) : [EOL] await test_run . update ( ) [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_update_run_empty ( mock_custom_resource_api_client ) : [EOL] mock_custom_resource_api_client . patch_namespaced_custom_object . return_value = LIST_RUNS_RESPONSE_RAW [ [string] ] [ [number] ] [EOL] [EOL] assert await TEST_RUNS [ [number] ] . update ( ) is None [EOL] [EOL] assert mock_custom_resource_api_client . patch_namespaced_custom_object . call_count == [number] [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_update_patch_proper_fields ( mock_custom_resource_api_client ) : [EOL] mock_custom_resource_api_client . patch_namespaced_custom_object . return_value = LIST_RUNS_RESPONSE_RAW [ [string] ] [ [number] ] [EOL] test_run = copy . deepcopy ( TEST_RUNS [ [number] ] ) [EOL] test_run . experiment_name = [string] [EOL] test_run . start_timestamp = [string] [EOL] [EOL] await test_run . update ( ) [EOL] [EOL] expected_patch_body = { [string] : { [string] : test_run . experiment_name , [string] : test_run . start_timestamp } } [EOL] [EOL] assert mock_custom_resource_api_client . patch_namespaced_custom_object . call_count == [number] [EOL] mock_custom_resource_api_client . patch_namespaced_custom_object . assert_called_with ( group = Run . api_group_name , namespace = test_run . namespace , plural = Run . crd_plural_name , version = Run . crd_version , name = test_run . name , body = expected_patch_body ) [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_add_run ( mock_custom_resource_api_client ) : [EOL] mock_custom_resource_api_client . create_namespaced_custom_object . return_value = GET_RUN_RESPONSE_RAW [EOL] run = Run ( name = RUN_NAME , experiment_name = [string] ) [EOL] added_run = await run . create ( namespace = NAMESPACE ) [EOL] assert added_run is not None [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_add_run_failure ( mock_custom_resource_api_client ) : [EOL] mock_custom_resource_api_client . create_namespaced_custom_object . side_effect = ApiException ( status = [number] ) [EOL] run = Run ( name = RUN_NAME , experiment_name = [string] ) [EOL] with pytest . raises ( ApiException ) : [EOL] await run . create ( namespace = NAMESPACE ) [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_delete_run ( mock_custom_resource_api_client ) : [EOL] mock_custom_resource_api_client . delete_namespaced_custom_object . return_value = { [string] : [string] } [EOL] run = Run ( name = RUN_NAME , experiment_name = [string] ) [EOL] delete_response = await run . delete ( ) [EOL] assert delete_response is not None [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_delete_run_failure ( mock_custom_resource_api_client ) : [EOL] mock_custom_resource_api_client . delete_namespaced_custom_object . side_effect = ApiException ( status = [number] ) [EOL] run = Run ( name = RUN_NAME , experiment_name = [string] ) [EOL] with pytest . raises ( ApiException ) : [EOL] await run . delete ( ) [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_get_pods ( mock_k8s_api_client ) : [EOL] pod_list = [ V1Pod ( status = V1PodStatus ( phase = [string] ) ) ] [EOL] [EOL] mock_k8s_api_client . list_namespaced_pod . return_value = V1PodList ( items = pod_list ) [EOL] run = Run ( name = RUN_NAME , experiment_name = [string] ) [EOL] [EOL] assert await run . get_pods ( ) == pod_list [EOL] [EOL] [EOL] @ pytest . mark . asyncio @ pytest . mark . parametrize ( [string] , [ ( [ V1Pod ( status = V1PodStatus ( phase = [string] ) ) , V1Pod ( status = V1PodStatus ( phase = [string] ) ) ] , RunStatus . FAILED ) , ( [ V1Pod ( status = V1PodStatus ( phase = [string] ) ) , V1Pod ( status = V1PodStatus ( phase = [string] ) ) ] , RunStatus . QUEUED ) , ( [ V1Pod ( status = V1PodStatus ( phase = [string] ) ) , V1Pod ( status = V1PodStatus ( phase = [string] ) ) ] , RunStatus . COMPLETE ) , ( [ V1Pod ( status = V1PodStatus ( phase = [string] ) ) , V1Pod ( status = V1PodStatus ( phase = [string] ) ) ] , RunStatus . RUNNING ) , ] ) async def test_calculate_run_state ( pods , state , mocker ) : [EOL] get_pods_mock = mocker . patch ( [string] , new = CoroutineMock ( ) ) [EOL] get_pods_mock . return_value = pods [EOL] [EOL] run = Run ( name = RUN_NAME , experiment_name = [string] ) [EOL] [EOL] assert await run . calculate_current_state ( ) == state [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_calculate_run_state_cancelled ( mocker ) : [EOL] get_pods_mock = mocker . patch ( [string] , new = CoroutineMock ( ) ) [EOL] get_pods_mock . return_value = [ ] [EOL] [EOL] run = Run ( name = RUN_NAME , experiment_name = [string] , state = RunStatus . CANCELLED ) [EOL] assert await run . calculate_current_state ( ) == RunStatus . CANCELLED [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_calculate_run_state_complete ( mocker ) : [EOL] get_pods_mock = mocker . patch ( [string] , new = CoroutineMock ( ) ) [EOL] get_pods_mock . return_value = [ V1Pod ( status = V1PodStatus ( phase = [string] ) ) ] [EOL] [EOL] run = Run ( name = RUN_NAME , experiment_name = [string] , state = RunStatus . COMPLETE ) [EOL] assert await run . calculate_current_state ( ) == RunStatus . COMPLETE [EOL] [EOL] [EOL] LIST_RUNS_RESPONSE_RAW = { [string] : [string] , [string] : [ { [string] : [string] , [string] : [string] , [string] : { [string] : [string] , [string] : [string] , } , [string] : { [string] : [string] , [string] : { [string] : [number] } , [string] : [string] , [string] : [ [string] , [string] , [string] ] , [string] : [number] , [string] : { [string] : { [string] : [string] , [string] : [string] , [string] : [string] } } , [string] : [string] } } , { [string] : [string] , [string] : [string] , [string] : { [string] : [string] , [string] : [string] , } , [string] : { [string] : [string] , [string] : { [string] : [number] } , [string] : [string] , [string] : [ [string] , [string] , [string] ] , [string] : [number] , [string] : { [string] : { [string] : [string] , [string] : [string] , [string] : [string] } } , [string] : [string] , [string] : [string] , [string] : [string] } } ] , [string] : [string] , [string] : { [string] : [string] , [string] : [string] , [string] : [string] } } [EOL] [EOL] NAMESPACE = [string] [EOL] RUN_NAME = [string] [EOL] GET_RUN_RESPONSE_RAW = { [string] : [string] , [string] : [string] , [string] : { [string] : [string] , [string] : [string] , } , [string] : { [string] : [string] , [string] : { [string] : [number] } , [string] : [string] , [string] : [ [string] , [string] , [string] ] , [string] : [number] , [string] : { [string] : { [string] : [string] , [string] : [string] , [string] : [string] } } , [string] : [string] , [string] : [string] , [string] : [string] } } [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import pytest [EOL] from asynctest import CoroutineMock [EOL] [EOL] from nauta_resources . platform_resource import K8SApiClient , CustomResourceApiClient [EOL] [EOL] [EOL] @ pytest . fixture ( ) def load_kube_config_mock ( mocker ) : [EOL] [EOL] return mocker . patch ( [string] , new = CoroutineMock ( ) ) [EOL] [EOL] [EOL] @ pytest . fixture ( ) def load_incluster_config_mock ( mocker ) : [EOL] return mocker . patch ( [string] ) [EOL] [EOL] [EOL] @ pytest . fixture ( autouse = True ) def kubernetes_client_mock ( mocker ) : [EOL] return mocker . patch ( [string] ) [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_k8s_api_client_incluster ( load_kube_config_mock , load_incluster_config_mock ) : [EOL] load_kube_config_mock . side_effect = FileNotFoundError [EOL] K8SApiClient . core_api = None [EOL] await K8SApiClient . get ( ) [EOL] [EOL] assert load_kube_config_mock . call_count == [number] [EOL] assert load_incluster_config_mock . call_count == [number] [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_k8s_api_client_kubeconfig ( load_kube_config_mock , load_incluster_config_mock ) : [EOL] load_kube_config_mock . side_effect = None [EOL] K8SApiClient . core_api = None [EOL] await K8SApiClient . get ( ) [EOL] [EOL] assert load_kube_config_mock . call_count == [number] [EOL] assert load_incluster_config_mock . call_count == [number] [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_k8s_api_client_failure ( load_kube_config_mock , load_incluster_config_mock ) : [EOL] load_kube_config_mock . side_effect = RuntimeError [EOL] K8SApiClient . core_api = None [EOL] with pytest . raises ( RuntimeError ) : [EOL] await K8SApiClient . get ( ) [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_k8s_api_client_get_twice ( load_kube_config_mock , load_incluster_config_mock ) : [EOL] load_kube_config_mock . side_effect = None [EOL] K8SApiClient . core_api = None [EOL] await K8SApiClient . get ( ) [EOL] [EOL] assert load_kube_config_mock . call_count == [number] [EOL] assert load_incluster_config_mock . call_count == [number] [EOL] [EOL] await K8SApiClient . get ( ) [EOL] [EOL] assert load_kube_config_mock . call_count == [number] [EOL] assert load_incluster_config_mock . call_count == [number] [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_custom_resource_client_incluster ( load_kube_config_mock , load_incluster_config_mock ) : [EOL] load_kube_config_mock . side_effect = FileNotFoundError [EOL] CustomResourceApiClient . k8s_custom_object_api = None [EOL] await CustomResourceApiClient . get ( ) [EOL] [EOL] assert load_kube_config_mock . call_count == [number] [EOL] assert load_incluster_config_mock . call_count == [number] [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_custom_resource_api_client_kubeconfig ( load_kube_config_mock , load_incluster_config_mock ) : [EOL] load_kube_config_mock . side_effect = None [EOL] CustomResourceApiClient . k8s_custom_object_api = None [EOL] await CustomResourceApiClient . get ( ) [EOL] [EOL] assert load_kube_config_mock . call_count == [number] [EOL] assert load_incluster_config_mock . call_count == [number] [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_custom_resource_api_client_failure ( load_kube_config_mock , load_incluster_config_mock ) : [EOL] load_kube_config_mock . side_effect = RuntimeError [EOL] CustomResourceApiClient . k8s_custom_object_api = None [EOL] with pytest . raises ( RuntimeError ) : [EOL] await CustomResourceApiClient . get ( ) [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_custom_resource_api_client_get_twice ( load_kube_config_mock , load_incluster_config_mock ) : [EOL] load_kube_config_mock . side_effect = None [EOL] CustomResourceApiClient . k8s_custom_object_api = None [EOL] await CustomResourceApiClient . get ( ) [EOL] [EOL] assert load_kube_config_mock . call_count == [number] [EOL] assert load_incluster_config_mock . call_count == [number] [EOL] [EOL] await CustomResourceApiClient . get ( ) [EOL] [EOL] assert load_kube_config_mock . call_count == [number] [EOL] assert load_incluster_config_mock . call_count == [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import subprocess [EOL] import time [EOL] [EOL] from kopf . testing import KopfRunner [EOL] [EOL] [EOL] def test_create_delete_run ( ) : [EOL] with KopfRunner ( [ [string] , [string] ] , timeout = [number] ) as runner : [EOL] subprocess . run ( [ [string] , [string] , [string] , [string] ] , check = False ) [EOL] time . sleep ( [number] ) [EOL] subprocess . run ( [ [string] , [string] , [string] , [string] ] , check = True ) [EOL] time . sleep ( [number] ) [EOL] subprocess . run ( [ [string] , [string] , [string] , [string] ] , check = True ) [EOL] time . sleep ( [number] ) [EOL] [EOL] assert runner . exit_code == [number] [EOL] assert runner . exception is None [EOL] assert [string] in runner . stdout [EOL] assert [string] in runner . stdout [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , List , Dict , Optional [EOL] import builtins [EOL] import typing [EOL] import kubernetes [EOL] import logging as log [EOL] [comment] [EOL] from os import getenv , _exit [EOL] from time import sleep [EOL] from typing import List [EOL] [EOL] from kubernetes import client , config [EOL] from kubernetes . client import V1Pod , V1ObjectMeta , V1PodList , V1PodStatus , V1ContainerStatus , V1ContainerState , V1ContainerStateTerminated [EOL] [EOL] [EOL] JOB_SUCCESS_CONDITION = [string] [EOL] [EOL] LOGGING_LEVEL_MAPPING = { [string] : log . DEBUG , [string] : log . INFO , [string] : log . WARNING , [string] : log . ERROR , [string] : log . CRITICAL } [EOL] [EOL] [EOL] def init_logging_level ( ) : [EOL] logging_level_str = getenv ( [string] ) [EOL] [EOL] if logging_level_str is None : [EOL] raise RuntimeError ( [string] ) [EOL] [EOL] if logging_level_str not in LOGGING_LEVEL_MAPPING . keys ( ) : [EOL] raise RuntimeError ( f" [string] { LOGGING_LEVEL_MAPPING . keys ( ) } [string] " f" [string] { logging_level_str }" ) [EOL] [EOL] log . basicConfig ( level = logging_level_str ) [EOL] log . critical ( f" [string] { logging_level_str }" ) [EOL] [EOL] [EOL] def init_kubernetes_config ( ) : [EOL] config . load_incluster_config ( ) [EOL] [EOL] [EOL] def get_my_pod_name ( ) : [EOL] my_pod_name = getenv ( [string] ) [EOL] [EOL] if my_pod_name is None : [EOL] raise RuntimeError ( [string] ) [EOL] [EOL] return my_pod_name [EOL] [EOL] [EOL] def get_my_namespace ( ) : [EOL] with open ( [string] , mode = [string] ) as file : [EOL] my_current_namespace = file . read ( ) [EOL] [EOL] if not my_current_namespace : [EOL] raise RuntimeError ( f" [string] { str ( my_current_namespace ) }" ) [EOL] [EOL] return my_current_namespace [EOL] [EOL] [EOL] def main ( ) : [EOL] init_logging_level ( ) [EOL] init_kubernetes_config ( ) [EOL] my_pod_name = get_my_pod_name ( ) [EOL] my_namespace = get_my_namespace ( ) [EOL] [EOL] v1 = client . CoreV1Api ( ) [EOL] [EOL] my_pod = v1 . read_namespaced_pod ( name = my_pod_name , namespace = my_namespace ) [EOL] [EOL] my_pod_metadata = my_pod . metadata [EOL] [EOL] my_run_name = my_pod_metadata . labels [ [string] ] [EOL] [EOL] log . info ( [string] ) [EOL] [EOL] while True : [EOL] my_run_pods = v1 . list_namespaced_pod ( namespace = my_namespace , label_selector = f" [string] { my_run_name }" ) [EOL] [EOL] for pod in my_run_pods . items : [EOL] pod_typed = pod [EOL] pod_status = pod_typed . status [EOL] container_statuses = pod_status . container_statuses [EOL] for status in container_statuses : [EOL] container_name = status . name [EOL] if container_name != [string] : [EOL] continue [EOL] [EOL] container_state = status . state [EOL] container_state_terminated = container_state . terminated [EOL] if container_state_terminated : [EOL] exit_code = container_state_terminated . exit_code [EOL] log . info ( f" [string] { pod_typed . metadata . name } [string] { exit_code } [string] " ) [EOL] open ( [string] , [string] ) . close ( ) [EOL] log . info ( [string] ) [EOL] _exit ( exit_code ) [EOL] log . info ( [string] ) [EOL] sleep ( [number] ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $typing.Dict[builtins.str,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import List , Dict [EOL] import typing [EOL] VERBOSE_RERUN_MSG = [string] [EOL] SPINNER_COLOR = [string] [EOL] [EOL] [EOL] class VersionCmdTexts : [EOL] HELP = [string] [EOL] INITIAL_PLATFORM_VERSION = [string] [EOL] KUBECTL_INT_ERROR_MSG = [string] [string] [string] [EOL] OTHER_ERROR_MSG = [string] [EOL] TABLE_APP_ROW_NAME = [string] [EOL] TABLE_PLATFORM_ROW_NAME = [string] [EOL] TABLE_HEADERS = [ [string] , [string] ] [EOL] [EOL] [EOL] class MountCmdTexts : [EOL] HELP = [string] [EOL] MAIN_MSG = [string] [EOL] [EOL] MOUNT_CMD = [string] [EOL] [EOL] HELP_L = [string] [string] [EOL] GET_MOUNT_COMMAND_ERROR_MSG = [string] [EOL] UNMOUNT_CMD = [string] [EOL] UNMOUNT_OPTIONS_MSG = [string] [string] [EOL] UNMOUNT_OPTIONS_OSX_MSG = [string] [string] [EOL] UNMOUNT_MSG_UNIX = [string] [EOL] UNMOUNT_MSG_WIN = [string] [EOL] MOUNTS_LIST_COMMAND_ERROR_MSG = [string] [EOL] ADMIN_CHECK_ERROR_MSG = [string] [EOL] [EOL] [EOL] class CmdsCommonTexts : [EOL] INVALID_REGEX_ERROR_MSG = [string] [EOL] OTHER_ERROR_MSG = [string] [EOL] PROXY_CREATION_ERROR_MSG = [string] [EOL] LOGS_GET_OTHER_ERROR_MSG = [string] [EOL] EXPERIMENT_NOT_EXISTS_ERROR_MSG = [string] [EOL] LOCAL_PORT_OCCUPIED_ERROR_MSG = [string] [EOL] PROXY_CLOSE_LOG_ERROR_MSG = [string] [EOL] PROXY_CLOSE_USER_ERROR_MSG = [string] [string] [EOL] NAME_M_BOTH_GIVEN_ERROR_MSG = [string] [EOL] NAME_M_NONE_GIVEN_ERROR_MSG = [string] [EOL] LOGS_STORING_CONF = [string] [string] [EOL] LOGS_STORING_CONF_FILE_EXISTS = [string] [string] [string] [EOL] LOGS_STORING_ERROR = [string] [EOL] LOGS_STORING_FINAL_MESSAGE = [string] [EOL] LOGS_STORING_CANCEL_MESSAGE = [string] [EOL] MORE_EXP_LOGS_MESSAGE = [string] [EOL] SAVING_LOGS_TO_FILE_PROGRESS_MSG = [string] [EOL] [EOL] [EOL] class VerifyCmdTexts : [EOL] HELP = [string] [EOL] KUBECTL_NOT_INSTALLED_ERROR_MSG = [string] [EOL] KUBECTL_INVALID_VERSION_ERROR_MSG = [string] [string] [EOL] GET_K8S_NAMESPACE_ERROR_MSG = [string] [EOL] VERSION_CHECKING_MSG = [string] [string] [EOL] DEPENDENCY_VERIFICATION_SUCCESS_MSG = [string] [EOL] INVALID_VERSION_WARNING_MSG = [string] [string] [string] [EOL] DEPENDENCY_NOT_INSTALLED_ERROR_MSG = [string] [string] [EOL] DEPENDENCY_VERSION_CHECK_ERROR_MSG = [string] [EOL] DEPENDENCY_VERIFICATION_OTHER_ERROR_MSG = [string] [EOL] OS_SUPPORTED_MSG = [string] [EOL] CHECKING_CONNECTION_TO_CLUSTER_MSG = [string] [EOL] CHECKING_OS_MSG = [string] [EOL] VERIFYING_DEPENDENCY_MSG = [string] [EOL] CHECKING_PORT_FORWARDING_FROM_CLUSTER_MSG = [string] [EOL] WRONG_REQUIREMENTS_SETTINGS = [string] [EOL] VERIFYING_RESOURCES_CORRECTNESS = [string] [EOL] INCORRECT_PACKS_EXIST = [string] [string] [EOL] [EOL] [EOL] class ModelProcessListCmdTexts : [EOL] HELP = [string] [EOL] PROCESS_LIST_ERROR_MSG = [string] [EOL] [EOL] [EOL] class UserCmdTexts : [EOL] HELP = [string] [EOL] [EOL] [EOL] class UserListCmdTexts : [EOL] HELP = [string] [EOL] HELP_C = [string] [EOL] TABLE_HEADERS = [ [string] , [string] , [string] , [string] , [string] ] [EOL] OTHER_ERROR_MSG = [string] [EOL] [EOL] [EOL] class UserCreateCmdTexts : [EOL] SHORT_HELP = [string] [EOL] HELP = [string] [EOL] HELP_L = [string] [EOL] HELP_F = [string] [string] [EOL] ADD_USER_ERROR_MSG = [string] [EOL] REMOVE_USER_ERROR_MSG = [string] [string] [EOL] F_L_OPTIONS_EXCLUSION_ERROR_MSG = [string] [string] [EOL] NAME_VALIDATION_ERROR_MSG = [string] [EOL] USER_ALREADY_EXISTS_ERROR_MSG = [string] [EOL] USER_BEING_REMOVED_ERROR_MSG = [string] [EOL] USER_VERIFICATION_ERROR_MSG = [string] [EOL] PASSWORD_GATHER_ERROR_MSG = [string] [EOL] CERT_GATHER_ERROR_MSG = [string] [EOL] GIT_REPO_MANAGER_ERROR_MSG = [string] [EOL] USER_ADD_ERROR_MSG = [string] [EOL] USER_CREATION_SUCCESS_MSG = [string] [EOL] USER_NOT_READY_ERROR_MSG = [string] [EOL] CONFIG_CREATION_ERROR_MSG = [string] [EOL] LIST_ONLY_HEADER = [string] [string] [EOL] CONFIG_SAVE_SUCCESS_MSG = [string] [EOL] CONFIG_SAVE_FAIL_MSG = [string] [EOL] CONFIG_SAVE_FAIL_INSTRUCTIONS_MSG = [string] [string] [EOL] CREATING_USER_PROGRESS_MSG = [string] [EOL] [EOL] [EOL] class UserDeleteCmdTexts : [EOL] SHORT_HELP = [string] [EOL] HELP = [string] [EOL] HELP_PR = [string] [EOL] USER_NOT_EXISTS_ERROR_MSG = [string] [EOL] USER_BEING_REMOVED_ERROR_MSG = [string] [EOL] USER_PRESENCE_VERIFICATION_ERROR_MSG = [string] [EOL] DELETE_CONFIRM_MSG = [string] [EOL] DELETE_ABORT_MSG = [string] [EOL] PURGE_ERROR_MSG = [string] [EOL] DELETE_IN_PROGRESS_MSG = [string] [EOL] DELETE_SUCCESS_MSG = [string] [EOL] PROXY_ERROR_LOG_MSG = [string] [EOL] PROXY_ERROR_USER_MSG = [string] [string] [EOL] OTHER_ERROR_LOG_MSG = [string] [EOL] OTHER_ERROR_USER_MSG = [string] [EOL] DELETION_CHECK_PRESENCE = [string] [EOL] DELETION_START_DELETING = [string] [EOL] DELETION_START_PURGING = [string] [EOL] DELETION_VERIFICATION_OF_DELETING = [string] [EOL] DELETION_DELETING_NAMESPACE = [string] [EOL] DELETION_DELETING_USERS_OBJECTS = [string] [EOL] DELETION_DELETING_USERS_EXPERIMENTS = [string] [EOL] DELETION_DELETING_USERS_REPOSITORY = [string] [EOL] [EOL] [EOL] class UserUpgradeCmdTexts : [EOL] SHORT_HELP = [string] [EOL] UPGRADE_IN_PROGRESS = [string] [EOL] UPGRADE_SUCCEEDED = [string] [EOL] UPGRADE_FAILED = [string] [EOL] [EOL] [EOL] class LaunchCmdTexts : [EOL] HELP = [string] [string] [EOL] HELP_P = [string] [EOL] HELP_N = [string] [EOL] WEBUI_HELP = [string] [EOL] APP_PROXY_EXISTS_ERROR_MSG = [string] [string] [EOL] APP_PROXY_OTHER_ERROR_MSG = [string] [EOL] SHORT_TB_HELP = [string] [EOL] TB_HELP = [string] [EOL] TB_HELP_TSCP = [string] [EOL] TB_INVALID_RUNS_MSG = [string] [string] [EOL] TB_CREATE_ERROR_MSG = [string] [EOL] TB_WAITING_MSG = [string] [EOL] TB_WAITING_FOR_TB_MSG = [string] [string] [EOL] TB_TIMEOUT_ERROR_MSG = [string] [EOL] [EOL] [EOL] class PredictCmdTexts : [EOL] HELP = [string] [EOL] [EOL] [EOL] class PredictListCmdTexts : [EOL] HELP = [string] [EOL] HELP_A = [string] [EOL] HELP_N = [string] [EOL] HELP_S = [string] [EOL] HELP_U = [string] [string] [EOL] HELP_C = [string] [EOL] HELP_B = [string] [EOL] [EOL] [EOL] class PredictLaunchCmdTexts : [EOL] HELP = [string] [string] [EOL] HELP_N = [string] [EOL] HELP_M = [string] [string] [EOL] HELP_R = [string] [string] [EOL] INSTANCE_START_ERROR_MSG = [string] [EOL] INSTANCE_INFO_MSG = [string] [string] [EOL] INSTANCE_URL_ERROR_MSG = [string] [EOL] TABLE_HEADERS = [ [string] , [string] , [string] ] [EOL] HELP_LOCAL_MODEL_LOCATION = [string] [string] [EOL] MODEL_DIR_NOT_FOUND_ERROR_MSG = [string] [string] [EOL] MISSING_MODEL_LOCATION_ERROR_MSG = [string] [string] [EOL] HELP_MODEL_NAME = [string] [string] [EOL] HELP_P = [string] [string] [EOL] HELP_RT = [string] [string] [EOL] [EOL] PREDICTION_INSTANCE_NOT_READY = [string] [EOL] [EOL] class PredictStreamCmdTexts : [EOL] HELP = [string] [EOL] HELP_N = [string] [EOL] HELP_D = [string] [string] [string] [EOL] HELP_M = [string] [EOL] INSTANCE_NOT_EXISTS_ERROR_MSG = [string] [EOL] INSTANCE_NOT_RUNNING_ERROR_MSG = [string] [EOL] INSTANCE_GET_FAIL_ERROR_MSG = [string] [EOL] JSON_LOAD_ERROR_MSG = [string] [string] [EOL] INFERENCE_OTHER_ERROR_MSG = [string] [EOL] INFERENCE_ERROR_RESPONSE_MSG = [string] [EOL] WAITING_FOR_RESPONSE_MSG = [string] [EOL] [EOL] [EOL] class PredictCancelCmdTexts : [EOL] SHORT_HELP = [string] [EOL] HELP = [string] [EOL] HELP_P = [string] [string] [EOL] HELP_M = [string] [EOL] EXPERIMENT_NAME = [string] [EOL] EXPERIMENT_NAME_PLURAL = [string] [EOL] [EOL] [EOL] class PredictBatchCmdTexts : [EOL] HELP = [string] [EOL] HELP_DATA = [string] [string] [EOL] HELP_MODEL_LOCATION = [string] [string] [string] [EOL] HELP_LOCAL_MODEL_LOCATION = [string] [string] [EOL] HELP_MODEL_NAME = [string] [string] [EOL] HELP_NAME = [string] [EOL] HELP_OUTPUT = [string] [string] [EOL] HELP_REQUIREMENTS = [string] [string] [EOL] OTHER_INSTANCE_CREATION_ERROR_MSG = [string] [EOL] TABLE_NAME_HEADER = [string] [EOL] TABLE_MODEL_LOCATION_HEADER = [string] [EOL] TABLE_STATUS_HEADER = [string] [EOL] TABLE_HEADERS = [ [string] , [string] , [string] ] [EOL] MODEL_DIR_NOT_FOUND_ERROR_MSG = [string] [string] [EOL] MISSING_MODEL_LOCATION_ERROR_MSG = [string] [string] [EOL] HELP_TF_RECORD = [string] [string] [EOL] HELP_P = [string] [string] [EOL] HELP_RT = [string] [string] [EOL] [EOL] [EOL] class ExperimentCmdTexts : [EOL] SHORT_HELP = [string] [EOL] HELP = [string] [EOL] [EOL] [EOL] class ExperimentListCmdTexts : [EOL] SHORT_HELP = [string] [EOL] HELP_A = [string] [EOL] HELP_N = [string] [EOL] HELP_S = [string] [EOL] HELP_U = [string] [EOL] HELP_C = [string] [EOL] HELP_B = [string] [string] [EOL] [EOL] [EOL] class ExperimentTemplateListCmdTexts : [EOL] SHORT_HELP = [string] [EOL] HELP = [string] [EOL] LACK_OF_PACKS_ERROR_MSG = [string] [EOL] [EOL] [EOL] class ExperimentLogsCmdTexts : [EOL] SHORT_HELP = [string] [EOL] HELP = [string] [EOL] HELP_S = [string] [EOL] HELP_SD = [string] [EOL] HELP_ED = [string] [EOL] HELP_I = [string] [EOL] HELP_P = [string] [EOL] HELP_M = [string] [string] [EOL] HELP_O = [string] [EOL] HELP_F = [string] [EOL] HELP_PAGER = [string] [EOL] [EOL] [EOL] class PredictLogsCmdTexts : [EOL] SHORT_HELP = [string] [EOL] HELP = [string] [EOL] HELP_S = [string] [EOL] HELP_SD = [string] [EOL] HELP_ED = [string] [EOL] HELP_I = [string] [EOL] HELP_P = [string] [EOL] HELP_M = [string] [string] [EOL] HELP_O = [string] [EOL] HELP_F = [string] [EOL] HELP_PAGER = [string] [EOL] [EOL] [EOL] class PredictViewCmdTexts : [EOL] SHORT_HELP = [string] [EOL] HELP = [string] [EOL] CONTAINER_DETAILS_MSG = [string] [EOL] NOT_FOUND_ERROR_MSG = [string] [EOL] PODS_PARTICIPATING_LIST_HEADER = [string] [EOL] PODS_TABLE_HEADERS = [ [string] , [string] , [string] , [string] ] [EOL] VIEW_OTHER_ERROR_MSG = [string] [EOL] CONTAINER_NOT_CREATED_MSG = [string] [EOL] CONTAINER_RUNNING_MSG = [string] [EOL] CONTAINER_TERMINATED_MSG = [string] [EOL] CONTAINER_WAITING_MSG = [string] [EOL] CONTAINER_REQUESTS_LIST_HEADER = [string] [EOL] CONTAINER_LIMITS_LIST_HEADER = [string] [EOL] RESOURCES_SUM_LIST_HEADER = [string] [EOL] RESOURCES_SUM_PARSING_ERROR_MSG = [string] [EOL] RESOURCES_SUM_TABLE_HEADERS = [ [string] , [string] ] [EOL] RESOURCES_SUM_TABLE_ROWS_HEADERS = [ [string] , [string] , [string] , [string] ] [EOL] INSUFFICIENT_RESOURCES_MESSAGE = [string] [EOL] TOP_CPU_CONSUMERS = [string] [EOL] TOP_MEMORY_CONSUMERS = [string] [EOL] PROBLEMS_WHILE_GATHERING_USAGE_DATA = [string] [string] [EOL] PROBLEMS_WHILE_GATHERING_USAGE_DATA_LOGS = [string] [EOL] HELP_U = [string] [string] [string] [EOL] REASON = [string] [EOL] [EOL] [EOL] class ExperimentSubmitCmdTexts : [EOL] SHORT_HELP = [string] [EOL] HELP = [string] [EOL] HELP_N = [string] [EOL] [EOL] HELP_SFL = [string] [EOL] HELP_T = [string] [EOL] HELP_P = [string] [string] [EOL] HELP_PR = [string] [EOL] HELP_PS = [string] [EOL] HELP_E = [string] [EOL] HELP_R = [string] [EOL] SCRIPT_NOT_FOUND_ERROR_MSG = [string] [EOL] DEFAULT_SCRIPT_NOT_FOUND_ERROR_MSG = [string] [string] [string] [EOL] SCRIPT_DIR_NOT_FOUND_ERROR_MSG = [string] [string] [EOL] DUPLICATED_PACK_PARAM = [string] [EOL] SUBMIT_START_LOG_MSG = [string] [EOL] SUBMIT_START_USER_MSG = [string] [EOL] SUBMIT_ERROR_MSG = [string] [EOL] SUBMIT_OTHER_ERROR_MSG = [string] [EOL] FAILED_RUNS_LOG_MSG = [string] [EOL] [EOL] [EOL] class ExperimentInteractCmdTexts : [EOL] SHORT_HELP = [string] [EOL] HELP = [string] [string] [EOL] HELP_N = [string] [EOL] HELP_F = [string] [EOL] HELP_PN = [string] [EOL] HELP_P = [string] [string] [EOL] HELP_NO_LAUNCH = [string] [EOL] EXPERIMENT_GET_ERROR_MSG = [string] [EOL] NAME_ALREADY_USED = [string] [string] [EOL] CONFIRM_EXPERIMENT_CREATION = [string] [string] [EOL] SUBMITTING_EXPERIMENT_USER_MSG = [string] [EOL] SUBMIT_ERROR_MSG = [string] [EOL] SUBMIT_OTHER_ERROR_MSG = [string] [EOL] SESSION_EXISTS_MSG = [string] [EOL] FILENAME_BUT_SESSION_EXISTS = [string] [string] [EOL] NOTEBOOK_STATE_CHECK_ERROR_MSG = [string] [EOL] ATTACHING_SCRIPT_NOT_SUPPORTED_MSG = [string] [string] [EOL] NOTEBOOK_NOT_READY_ERROR_MSG = [string] [string] [string] [EOL] PROXY_CLOSING_ERROR_MSG = [string] [string] [EOL] SESSION_LAUNCH_OTHER_ERROR_MSG = [string] [EOL] EXP_WITH_THE_SAME_NAME_MUST_BE_PURGED = [string] [string] [string] [EOL] HELP_E = [string] [string] [EOL] HELP_T = [string] [string] [EOL] TOO_MANY_JUPYTERS = [string] [EOL] INTERACT_ABORT_MSG = [string] [EOL] [EOL] [EOL] class ExperimentCancelCmdTexts : [EOL] SHORT_HELP = [string] [EOL] HELP = [string] [EOL] HELP_P = [string] [string] [EOL] HELP_M = [string] [string] [EOL] HELP_I = [string] [EOL] HELP_S = [string] [EOL] NAME_M_BOTH_GIVEN_ERROR_MSG = [string] [EOL] NAME_M_NONE_GIVEN_ERROR_MSG = [string] [EOL] LIST_RUNS_ERROR_MSG = [string] [EOL] LACK_OF_EXPERIMENTS_ERROR_MSG = [string] [string] [string] [string] [EOL] LACK_OF_EXP_TO_BE_CANCELLED_ERROR_MSG = [string] [string] [string] [string] [EOL] EXP_THAT_CAN_BE_PURGED_EXIST = [string] [string] [string] [EOL] CANCEL_OPERATION = { [string] : [string] , [string] : [string] } [EOL] DELETE_OPERATION = { [string] : [string] , [string] : [string] } [EOL] EXPERIMENTS_ALREADY_CANCELLED_ERROR_MSG = [string] [string] [EOL] ALREADY_CANCELLED_LIST_HEADER = [string] [string] [EOL] CAN_BE_CANCELLED_LIST_HEADER = [string] [EOL] WILL_BE_CANCELLED_LIST_HEADER = [string] [EOL] WILL_BE_PURGED_LIST_HEADER = [string] [EOL] CONFIRM_CANCEL_MSG = [string] [EOL] CANCELLATION_ABORTED_MSG = [string] [EOL] OTHER_CANCELLING_ERROR_MSG = [string] [EOL] PROXY_CLOSING_ERROR_LOG_MSG = [string] [EOL] PROXY_CLOSING_ERROR_USER_MSG = [string] [string] [EOL] PORT_OCCUPIED_ERROR_LOG_MSG = [string] [EOL] PORT_OCCUPIED_ERROR_USER_MSG = [string] [EOL] PROXY_OPEN_ERROR_MSG = [string] [EOL] SUCCESSFULLY_CANCELLED_LIST_HEADER = [string] [EOL] FAILED_TO_CANCEL_LIST_HEADER = [string] [EOL] GET_EXPERIMENT_ERROR_MSG = [string] [EOL] PURGING_START_MSG = [string] [EOL] INCOMPLETE_PURGE_ERROR_MSG = [string] [string] [EOL] CANCELING_RUNS_START_MSG = [string] [EOL] DELETING_RELATED_OBJECTS_MSG = [string] [EOL] CANCEL_SETTING_STATUS_MSG = [string] [EOL] INCOMPLETE_CANCEL_ERROR_MSG = [string] [string] [EOL] BAD_POD_STATUS_PASSED = [string] [EOL] LACK_OF_PODS_ERROR_MSG = [string] [string] [EOL] GIT_REPO_MANAGER_ERROR_MSG = [string] [EOL] CANCELING_PODS_MSG = [string] [EOL] OTHER_POD_CANCELLING_ERROR_MSG = [string] [EOL] UNINITIALIZED_EXPERIMENT_CANCEL_MSG = [string] [EOL] PURGING_PROGRESS_MSG = [string] [EOL] PURGING_LOGS_PROGRESS_MSG = [string] [EOL] [EOL] [EOL] class ExperimentViewCmdTexts : [EOL] SHORT_HELP = [string] [EOL] HELP = [string] [EOL] [EOL] HELP_T = [string] [EOL] [EOL] CONTAINER_DETAILS_MSG = [string] [EOL] NOT_FOUND_ERROR_MSG = [string] [EOL] PODS_PARTICIPATING_LIST_HEADER = [string] [EOL] PODS_TABLE_HEADERS = [ [string] , [string] , [string] , [string] ] [EOL] VIEW_OTHER_ERROR_MSG = [string] [EOL] CONTAINER_NOT_CREATED_MSG = [string] [EOL] CONTAINER_RUNNING_MSG = [string] [EOL] CONTAINER_TERMINATED_MSG = [string] [EOL] CONTAINER_WAITING_MSG = [string] [EOL] CONTAINER_REQUESTS_LIST_HEADER = [string] [EOL] CONTAINER_LIMITS_LIST_HEADER = [string] [EOL] RESOURCES_SUM_LIST_HEADER = [string] [EOL] RESOURCES_SUM_PARSING_ERROR_MSG = [string] [EOL] RESOURCES_SUM_TABLE_HEADERS = [ [string] , [string] ] [EOL] RESOURCES_SUM_TABLE_ROWS_HEADERS = [ [string] , [string] , [string] , [string] ] [EOL] INSUFFICIENT_RESOURCES_MESSAGE = [string] [EOL] TOP_CPU_CONSUMERS = [string] [EOL] TOP_MEMORY_CONSUMERS = [string] [EOL] PROBLEMS_WHILE_GATHERING_USAGE_DATA = [string] [string] [EOL] PROBLEMS_WHILE_GATHERING_USAGE_DATA_LOGS = [string] [EOL] HELP_U = [string] [string] [EOL] REASON = [string] [EOL] [EOL] [EOL] class ExperimentCommonTexts : [EOL] CONFIRM_EXP_DIR_DELETION_MSG = [string] [string] [EOL] UNABLE_TO_CONTINUE_EXP_SUBMISSION_ERROR_MSG = [string] [string] [string] [EOL] CREATE_ENV_MSG_PREFIX = [string] [EOL] DIR_CANT_BE_COPIED_ERROR_TEXT = [string] [EOL] EXP_DIR_CANT_BE_CREATED = [string] [EOL] TRAINING_SCRIPT_CANT_BE_CREATED = [string] [EOL] GET_NAMESPACE_ERROR_MSG = [string] [EOL] SUBMIT_PREPARATION_ERROR_MSG = [string] [EOL] LOCAL_DOCKER_TUNNEL_ERROR_MSG = [string] [EOL] ENV_CREATION_ERROR_MSG = [string] [EOL] CONFIRM_SUBMIT_MSG = [string] [EOL] CONFIRM_SUBMIT_QUESTION_MSG = [string] [EOL] SUBMISSION_FAIL_ERROR_MSG = [string] [string] [EOL] PROXY_CLOSE_ERROR_MSG = [string] [string] [EOL] PROXY_OPEN_ERROR_MSG = [string] [EOL] SUBMIT_OTHER_ERROR_MSG = [string] [EOL] DOCKER_TUNNEL_CLOSE_ERROR_MSG = [string] [string] [EOL] EXP_TEMPLATES_NOT_GENERATED_ERROR_MSG = [string] [EOL] JOB_NOT_DEPLOYED_ERROR_MSG = [string] [EOL] INCORRECT_PARAM_FORMAT_ERROR_MSG = [string] [EOL] PARAM_AMBIGUOUSLY_DEFINED = [string] [EOL] PARAM_SET_INCORRECT_FORMAT_ERROR_MSG = [string] [EOL] INVALID_PACK_PARAM_FORMAT_ERROR_MSG = [string] [string] [EOL] EXPERIMENT_NAME_TOO_LONG_ERROR_MSG = [string] [EOL] ERROR_DURING_PATCHING_RUN = [string] [EOL] PROBLEMS_DURING_GETTING_DRAFT_LOGS = [string] [EOL] THE_SAME_EXP_IS_SUBMITTED = [string] [string] [EOL] PREPARING_RESOURCE_DEFINITIONS_MSG = [string] [EOL] CLUSTER_CONNECTION_MSG = [string] [EOL] CREATING_ENVIRONMENT_MSG = [string] [EOL] CREATING_RESOURCES_MSG = [string] [EOL] CLUSTER_CONNECTION_CLOSING_MSG = [string] [EOL] INCORRECT_TEMPLATE_NAME = [string] [EOL] INCORRECT_ENV_PARAMETER = [string] [EOL] INCORRECT_PACK_DEFINITION = [string] [EOL] ERROR_WHILE_REMOVING_EXPERIMENT = [string] [EOL] ERROR_WHILE_REMOVING_RUNS = [string] [EOL] CTRL_C_PURGING_PROGRESS_MSG = [string] [EOL] [EOL] [EOL] class DraftCmdTexts : [EOL] DOCKER_IMAGE_NOT_BUILT = [string] [EOL] DOCKER_IMAGE_NOT_SENT = [string] [EOL] APP_NOT_RELEASED = [string] [EOL] DEPLOYMENT_NOT_CREATED = [string] [EOL] PACK_NOT_EXISTS = [string] [EOL] [EOL] [EOL] class PacksTfTrainingTexts : [EOL] CONFIG_NOT_UPDATED = [string] [EOL] CANT_PARSE_VALUE = [string] [EOL] PREPARING_IMAGES_MSG = [string] [EOL] [EOL] [EOL] class UtilSystemTexts : [EOL] COMMAND_EXE_FAIL_ERROR_MSG = [string] [EOL] UNSUPPORTED_PLATFORM_ERROR_MSG = [string] [EOL] PORT_AVAILABILITY_CHECK_ERROR_MSG = [string] [EOL] [EOL] [EOL] class UtilJupyterTexts : [EOL] IPYNB_CONVERSION_ERROR_MSG = [string] [EOL] [EOL] [EOL] class UtilLauncherTexts : [EOL] LOCAL_DOCKER_TUNNEL_ERROR_MSG = [string] [EOL] BROWSER_STARTING_MSG = [string] [EOL] CANNOT_USE_PORT = [string] [EOL] NO_WEB_BROWSER_ERROR_MSG = [string] [EOL] PROXY_CLOSE_ERROR_MSG = [string] [EOL] WEB_APP_LAUCH_FAIL_MSG = [string] [EOL] WEB_APP_CLOSING_MSG = [string] [EOL] GO_TO_MSG = [string] [EOL] PROXY_CREATED_MSG = [string] [EOL] PROXY_CREATED_ERROR_MSG = [string] [EOL] PROXY_CREATED_EXTENDED_ERROR_MSG = [string] [EOL] LAUNCHING_APP_MSG = [string] [EOL] [EOL] [EOL] class UtilHelmTexts : [EOL] HELM_RELEASE_REMOVAL_ERROR_MSG = [string] [EOL] [EOL] [EOL] class TensorboardClientTexts : [EOL] INVALID_RUNS_ERROR_MSG = [string] [EOL] RUNS_NOT_EXIST_ERROR_MSG = [string] [EOL] [EOL] [EOL] class UtilDockerTexts : [EOL] TAGS_GET_ERROR_MSG = [string] [EOL] IMAGE_DELETE_ERROR_MSG = [string] [EOL] [EOL] [EOL] class UtilDependenciesCheckerTexts : [EOL] PARSE_FAIL_ERROR_MSG = [string] [EOL] VERSION_CMD_FAIL_MSG = [string] [EOL] DEPENDENCY_NOT_INSTALLED_ERROR_MSG = [string] [EOL] VERSION_GET_FAIL_MSG = [string] [EOL] INVALID_DEPENDENCY_ERROR_MSG = [string] [string] [EOL] UNKNOWN_OS_ERROR_MSG = [string] [EOL] GET_OS_VERSION_ERROR_MSG = [string] [EOL] UNSUPPORTED_OS_ERROR_MSG = [string] [string] [EOL] INVALID_OS_VERSION_ERROR_MSG = [string] [string] [EOL] [EOL] [EOL] class UtilConfigTexts : [EOL] USER_DIR_NOT_FOUND_ERROR_MSG = [string] [EOL] NCTL_CONFIG_DIR_NOT_FOUND_ERROR_MSG = [string] [string] [string] [EOL] [EOL] [EOL] class PlatformResourcesCustomModelTexts : [EOL] INVALID_K8S_NAME = [string] [string] [EOL] [EOL] [EOL] class PlatformResourcesExperimentsTexts : [EOL] REGEX_COMPILATION_FAIL_MSG = [string] [EOL] K8S_RESPONSE_LOAD_ERROR_MSG = [string] [EOL] K8S_DUMP_PREPARATION_ERROR_MSG = [string] [EOL] EXPERIMENT_ALREADY_EXISTS_ERROR_MSG = [string] [EOL] EXPERIMENT_INVALID_STATE_MSG = [string] [string] [string] [string] [string] [EOL] EXPERIMENT_UPDATE_ERROR_MSG = [string] [EOL] EXPERIMENT_PREV_EXP_STILL_TERMINATING = [string] [string] [EOL] [EOL] [EOL] class PlatformResourcesRunsTexts : [EOL] REGEX_COMPILATION_FAIL_MSG = [string] [EOL] K8S_RESPONSE_LOAD_ERROR_MSG = [string] [EOL] K8S_DUMP_PREPARATION_ERROR_MSG = [string] [EOL] RUN_UPDATE_ERROR_MSG = [string] [EOL] [EOL] [EOL] class PlatformResourcesUsersTexts : [EOL] USERNAME_CANNOT_BE_EMPTY_ERROR_MSG = [string] [EOL] USERNAME_TOO_LONG_ERROR_MSG = [string] [EOL] INCORRECT_K8S_USERNAME_ERROR_MSG = [string] [EOL] USERNAME_IS_RESERVED_FOR_SYSTEM_USE = [string] [EOL] USER_PRESENCE_CHECK_ERROR_MSG = [string] [EOL] [EOL] [EOL] class UtilKubectlTexts : [EOL] NO_AVAILABLE_PORT_ERROR_MSG = [string] [EOL] PROXY_CREATION_OTHER_ERROR_MSG = [string] [EOL] PROXY_CREATION_MISSING_PORT_ERROR_MSG = [string] [EOL] K8S_OBJECT_DELETE_ERROR_MSG = [string] [EOL] K8S_CLUSTER_NO_CONNECTION_ERROR_MSG = [string] [EOL] TOP_COMMAND_ERROR = [string] [EOL] TOP_COMMAND_ERROR_LOG = [string] [EOL] K8S_PORT_FORWARDING_ERROR_MSG = [string] [string] [EOL] [EOL] [EOL] class UtilK8sInfoTexts : [EOL] OTHER_FIND_NAMESPACE_ERROR_MSG = [string] [EOL] NAMESPACE_DELETE_ERROR_MSG = [string] [EOL] CONFIG_MAP_ACCESS_ERROR_MSG = [string] [EOL] LACK_OF_DEFAULT_TOKEN_ERROR_MSG = [string] [EOL] EMPTY_LIST_OF_TOKENS_ERROR_MSG = [string] [EOL] GATHERING_USERS_TOKEN_ERROR_MSG = [string] [EOL] GATHERING_USER_CERTIFICATE_ERROR_MSG = [string] [EOL] GATHERING_PASSWORD_ERROR_MSG = [string] [EOL] LACK_OF_PASSWORD_ERROR_MSG = [string] [EOL] GATHERING_EVENTS_ERROR_MSG = [string] [EOL] PATCHING_CM_ERROR_MSG = [string] [EOL] [EOL] [EOL] class UtilK8sProxyTexts : [EOL] PROXY_ENTER_ERROR_MSG = [string] [EOL] PROXY_EXIT_ERROR_MSG = [string] [EOL] TUNNEL_NOT_READY_ERROR_MSG = [string] [EOL] TUNNEL_ALREADY_CLOSED = [string] [EOL] K8S_PORT_FORWARDING_ERROR_MSG = [string] [string] [EOL] [EOL] [EOL] class CliStateTexts : [EOL] INVALID_DEPENDENCY_ERROR_MSG = [string] [EOL] KUBECTL_NAMESPACE_ERROR_MSG = [string] [string] [string] [string] [EOL] NCTL_CONFIG_NOT_SET_ERROR_MSG = [string] [string] [EOL] NCTL_CONFIG_INIT_ERROR_MSG = [string] [EOL] USER_NOT_ADMIN_MSG = [string] [EOL] USER_IS_ADMIN_MSG = [string] [string] [string] [EOL] ADMIN_CHECK_ERROR_MSG = [string] [EOL] [EOL] [EOL] class LicenseAcceptanceTexts : [EOL] LICENSE_ACCEPTANCE_QUESTION_MSG = [string] [string] [string] [string] [string] [EOL] CANNOT_ACCEPT_LICENSE_MSG = [string] [string] [string] [EOL] [EOL] [EOL] class ConfigCmdTexts : [EOL] HELP = [string] [EOL] HELP_C = [string] [EOL] HELP_M = [string] [EOL] HELP_PN = [string] [string] [EOL] MISSING_ARGUMENTS = [string] [EOL] MISSING_CONFIG_FILE = [string] [EOL] CONFIG_FILE_INCORRECT = [string] [EOL] CONFIG_UPDATE = [string] [EOL] CPU_WRONG_FORMAT = [string] [EOL] MEMORY_WRONG_FORMAT = [string] [EOL] ERROR_DURING_UPDATE = [string] [EOL] SUCCESS_MESSAGE = [string] [EOL] MEMORY_SETTINGS_TOO_LOW = [string] [EOL] CPU_SETTINGS_TOO_LOW = [string] [EOL] [EOL] [EOL] class WorkflowCmdTexts : [EOL] HELP = [string] [EOL] [EOL] [EOL] class WorkflowLogsTexts : [EOL] SHORT_HELP = [string] [EOL] HELP = [string] [EOL] LOCAL_PORT_OCCUPIED_ERROR_MSG = [string] [EOL] PROXY_CLOSE_LOG_ERROR_MSG = [string] [EOL] PROXY_CLOSE_USER_ERROR_MSG = [string] [string] [EOL] PROXY_CREATION_ERROR_MSG = [string] [EOL] OTHER_ERROR_MSG = [string] [EOL] NOT_FOUND_MSG = [string] [EOL] [EOL] [EOL] class WorkflowDeleteTexts : [EOL] SHORT_HELP = [string] [EOL] HELP = [string] [EOL] OTHER_ERROR_MSG = [string] [EOL] NOT_FOUND_MSG = [string] [EOL] PROGRESS_MSG = [string] [EOL] SUCCESS_MSG = [string] [EOL] [EOL] [EOL] class WorkflowSubmitTexts : [EOL] SHORT_HELP = [string] [EOL] HELP = [string] [EOL] LOAD_SPEC_ERROR_MSG = [string] [EOL] OTHER_ERROR_MSG = [string] [EOL] PROGRESS_MSG = [string] [EOL] [EOL] class WorkflowViewTexts : [EOL] SHORT_HELP = [string] [EOL] HELP = [string] [EOL] NOT_FOUND_MSG = [string] [EOL] OTHER_ERROR_MSG = [string] [EOL] [EOL] [EOL] class WorkflowListTexts : [EOL] SHORT_HELP = [string] [EOL] NOT_FOUND_MSG = [string] [EOL] OTHER_ERROR_MSG = [string] [EOL] [EOL] [EOL] class TemplateCmdTexts : [EOL] HELP = [string] [EOL] [EOL] [EOL] class TemplateListCmdTexts : [EOL] HELP = [string] [EOL] MISSING_REPOSITORY = [string] [string] [EOL] UNAUTHORIZED = [string] [EOL] OTHER_GITHUB_ERROR = [string] [EOL] OTHER_ERROR_DURING_ACCESSING_REMOTE_REPOSITORY = [string] [EOL] ERROR_DURING_LOADING_LOCAL_TEMPLATES = [string] [string] [EOL] MISSING_CONFIGURATION_FILE = [string] [string] [EOL] GETTING_LIST_OF_TEMPLATES_MSG = [string] [EOL] CHECKING_PRESENCE_OF_TEMPLATE_MSG = [string] [EOL] [EOL] [EOL] class TemplateCopyCmdTexts : [EOL] HELP = [string] [EOL] HELP_DESCRIPTION = [string] [string] [EOL] HELP_VERSION = [string] [EOL] SRC_TEMPLATE_NOT_FOUND = [string] [EOL] TEMPLATE_ALREADY_EXISTS = [string] [EOL] DESCRIPTION_PROMPT = [string] [EOL] COPY_SUCCESS = [string] [EOL] COPY_FAILURE = [string] [EOL] [EOL] [EOL] class GithubMessages : [EOL] GET_REQUEST_ERROR = [string] [EOL] GET_OTHER_ERROR = [string] [EOL] MISSING_CHART_FILE = [string] [EOL] GET_MISSING_FILE = [string] [EOL] [EOL] [EOL] class TemplateInstallCmdTexts ( TemplateListCmdTexts ) : [EOL] HELP = [string] [EOL] REMOTE_TEMPLATE_NOT_FOUND = [string] [EOL] DOWNLOADING_TEMPLATE = [string] [EOL] LOCAL_VERSION_ALREADY_INSTALLED = [string] [string] [EOL] FAILED_TO_LOAD_TEMPLATE = [string] [EOL] FAILED_TO_INSTALL_TEMPLATE = [string] [EOL] [EOL] [EOL] [EOL] class ModelCmdTexts : [EOL] HELP = [string] [EOL] [EOL] [EOL] class ModelStatusCmdTexts : [EOL] HELP = [string] [EOL] OTHER_ERROR_MSG = [string] [EOL] HELP_U = [string] [string] [EOL] LOAD_DATA_MSG = [string] [EOL] [EOL] [EOL] class ModelExportCmdTexts : [EOL] HELP = [string] [EOL] SHORT_HELP = [string] [EOL] HELP_P = [string] [EOL] WRONG_EXPORT_FORMAT = [string] [EOL] WRONG_PROCESS_KIND = [string] [EOL] EXPORT_LIST_ERROR_MSG = [string] [EOL] MISSING_EXPORT_FORMAT = [string] [EOL] [EOL] [EOL] class ModelExportLogsCmdTexts : [EOL] SHORT_HELP = [string] [EOL] HELP = [string] [EOL] HELP_SD = [string] [EOL] HELP_ED = [string] [EOL] HELP_M = [string] [EOL] HELP_O = [string] [EOL] HELP_F = [string] [EOL] HELP_PAGER = [string] [EOL] [EOL] [EOL] class ModelExportCommonTexts : [EOL] PROXY_CREATION_ERROR_MSG = [string] [EOL] LOGS_GET_OTHER_ERROR_MSG = [string] [EOL] LOCAL_PORT_OCCUPIED_ERROR_MSG = [string] [EOL] PROXY_CLOSE_LOG_ERROR_MSG = [string] [EOL] NAME_M_BOTH_GIVEN_ERROR_MSG = [string] [EOL] NAME_M_NONE_GIVEN_ERROR_MSG = [string] [EOL] MORE_EXP_LOGS_MESSAGE = [string] [EOL] OPERATION_NOT_EXISTS_ERROR_MSG = [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] VERSION = [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import List [EOL] import builtins [EOL] import typing [EOL] import os [EOL] import shutil [EOL] from typing import List [EOL] [EOL] [EOL] def copytree_content ( src , dst , ignored_objects = None , symlinks = False , ignore = None ) : [EOL] [docstring] [EOL] for item in os . listdir ( src ) : [EOL] if not ignored_objects or item not in ignored_objects : [EOL] s = os . path . join ( src , item ) [EOL] d = os . path . join ( dst , item ) [EOL] if os . path . isdir ( s ) : [EOL] shutil . copytree ( s , d , symlinks , ignore ) [EOL] else : [EOL] shutil . copy2 ( s , d ) [EOL] [EOL] [EOL] def get_total_directory_size_in_bytes ( directory ) : [EOL] size = [number] [EOL] for path , dirs , files in os . walk ( directory ) : [EOL] for file in files : [EOL] full_filename = os . path . join ( path , file ) [EOL] size += os . path . getsize ( full_filename ) [EOL] return size [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import requests [EOL] import builtins [EOL] import typing [EOL] import requests [EOL] import time [EOL] [EOL] [EOL] def wait_for_connection ( url , retries = [number] , timeout = [number] ) : [EOL] while retries : [EOL] try : [EOL] response = requests . get ( url ) [EOL] return int ( response . status_code / [number] ) == [number] [EOL] except requests . exceptions . ConnectionError : [EOL] retries = retries - [number] [EOL] time . sleep ( timeout ) [EOL] return False [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , List , Set , Dict [EOL] import builtins [EOL] import typing [EOL] import os [EOL] import sys [EOL] [EOL] from util . k8s . k8s_info import get_config_map_data [EOL] from util . logger import initialize_logger [EOL] from cli_text_consts import UtilConfigTexts as Texts [EOL] [EOL] [EOL] [comment] [EOL] NCTL_CONFIG_ENV_NAME = [string] [EOL] NCTL_CONFIG_DIR_NAME = [string] [EOL] [EOL] [comment] [EOL] EXPERIMENTS_DIR_NAME = [string] [EOL] [comment] [EOL] FOLDER_DIR_NAME = [string] [EOL] [EOL] [comment] [EOL] DOCKER_REGISTRY_CONFIG_FILE = [string] [EOL] [EOL] NAUTA_NAMESPACE = [string] [EOL] NAUTA_CONFIGURATION_CM = [string] [EOL] [EOL] TBLT_TABLE_FORMAT = [string] [EOL] [EOL] log = initialize_logger ( __name__ ) [EOL] [EOL] [EOL] class ConfigInitError ( Exception ) : [EOL] def __init__ ( self , message ) : [EOL] self . message = message [EOL] [EOL] [EOL] class Config : [EOL] __shared_state = { } [EOL] [EOL] def __init__ ( self ) : [EOL] self . __dict__ = self . __shared_state [EOL] if not hasattr ( self , [string] ) : [EOL] self . config_path = self . get_config_path ( ) [EOL] [EOL] @ staticmethod def validate_config_path ( path ) : [EOL] if os . path . isdir ( path ) : [EOL] directory_content = os . listdir ( path ) [EOL] expected_content = { [string] } [EOL] return expected_content . issubset ( directory_content ) [EOL] return False [EOL] [EOL] @ staticmethod def get_config_path ( ) : [EOL] nctl_cli_dir = os . path . dirname ( sys . executable ) [EOL] binary_config_dir_path = os . path . join ( os . path . split ( nctl_cli_dir ) [ [number] ] , NCTL_CONFIG_DIR_NAME ) [EOL] user_local_config_dir_path = os . path . join ( os . path . expanduser ( [string] ) , NCTL_CONFIG_DIR_NAME ) [EOL] [EOL] log . debug ( f"{ NCTL_CONFIG_DIR_NAME } [string] { binary_config_dir_path }" ) [EOL] log . debug ( f'{ NCTL_CONFIG_DIR_NAME } [string] { binary_config_dir_path }' ) [EOL] [EOL] if os . environ . get ( NCTL_CONFIG_ENV_NAME ) : [EOL] user_path = os . environ [ NCTL_CONFIG_ENV_NAME ] [EOL] if os . path . exists ( user_path ) : [EOL] return user_path [EOL] else : [EOL] message = Texts . USER_DIR_NOT_FOUND_ERROR_MSG . format ( user_path = user_path , config_env_name = NCTL_CONFIG_ENV_NAME ) [EOL] raise ConfigInitError ( message ) [EOL] elif user_local_config_dir_path and os . path . exists ( user_local_config_dir_path ) : [EOL] return user_local_config_dir_path [EOL] elif binary_config_dir_path and os . path . exists ( binary_config_dir_path ) : [EOL] return binary_config_dir_path [EOL] else : [EOL] message = Texts . NCTL_CONFIG_DIR_NOT_FOUND_ERROR_MSG . format ( config_dir_name = NCTL_CONFIG_DIR_NAME , binary_config_dir_path = binary_config_dir_path , config_env_name = NCTL_CONFIG_ENV_NAME , user_local_config_dir_path = user_local_config_dir_path ) [EOL] raise ConfigInitError ( message ) [EOL] [EOL] [EOL] class NAUTAConfigMap : [EOL] [docstring] [EOL] [comment] [EOL] IMAGE_TILLER_FIELD = [string] [EOL] EXTERNAL_IP_FIELD = [string] [EOL] IMAGE_TENSORBOARD_SERVICE_FIELD = [string] [EOL] REGISTRY_FIELD = [string] [EOL] PLATFORM_VERSION = [string] [EOL] PY3_IMAGE_NAME = [string] [EOL] PY3_HOROVOD_IMAGE_CONFIG_KEY = [string] [EOL] MINIMAL_NODE_MEMORY_AMOUNT = [string] [EOL] MINIMAL_NODE_CPU_NUMBER = [string] [EOL] PY3_PYTORCH_IMAGE_CONFIG_KEY = [string] [EOL] OPENVINOMS_IMAGE_CONFIG_KEY = [string] [EOL] [EOL] __shared_state = { } [EOL] [EOL] def __init__ ( self , config_map_request_timeout = None ) : [EOL] self . __dict__ = self . __shared_state [EOL] if not self . __dict__ : [EOL] config_map_data = get_config_map_data ( name = NAUTA_CONFIGURATION_CM , namespace = NAUTA_NAMESPACE , request_timeout = config_map_request_timeout ) [EOL] self . registry = config_map_data [ self . REGISTRY_FIELD ] [EOL] self . image_tiller = [string] . format ( config_map_data [ self . REGISTRY_FIELD ] , config_map_data [ self . IMAGE_TILLER_FIELD ] ) [EOL] self . external_ip = config_map_data [ self . EXTERNAL_IP_FIELD ] [EOL] self . image_tensorboard_service = [string] . format ( config_map_data [ self . REGISTRY_FIELD ] , config_map_data [ self . IMAGE_TENSORBOARD_SERVICE_FIELD ] ) [EOL] self . platform_version = config_map_data . get ( self . PLATFORM_VERSION ) [EOL] self . py3_image_name = config_map_data . get ( self . PY3_IMAGE_NAME ) [EOL] self . py3_horovod_image_name = config_map_data . get ( NAUTAConfigMap . PY3_HOROVOD_IMAGE_CONFIG_KEY ) [EOL] self . minimal_node_memory_amount = config_map_data . get ( NAUTAConfigMap . MINIMAL_NODE_MEMORY_AMOUNT ) [EOL] self . minimal_node_cpu_number = config_map_data . get ( NAUTAConfigMap . MINIMAL_NODE_CPU_NUMBER ) [EOL] self . py3_pytorch_image_name = config_map_data . get ( NAUTAConfigMap . PY3_PYTORCH_IMAGE_CONFIG_KEY ) [EOL] self . openvinoms_image_name = config_map_data . get ( NAUTAConfigMap . OPENVINOMS_IMAGE_CONFIG_KEY ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 $builtins.str$ 0 0 $typing.Set[builtins.str]$ 0 0 0 0 0 0 $typing.Set[builtins.str]$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.Any$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $typing.Any$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.Any$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.dict$ 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 $typing.Any$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , List , Set , Optional [EOL] import click [EOL] import typing [EOL] import click [EOL] [EOL] [EOL] class AliasCmd ( click . Command ) : [EOL] def __init__ ( self , * args , ** kwargs ) : [EOL] self . _alias = kwargs . pop ( [string] , [string] ) [EOL] super ( AliasCmd , self ) . __init__ ( * args , ** kwargs ) [EOL] [EOL] def alias ( self ) : [EOL] return self . _alias [EOL] [EOL] [EOL] class AliasGroup ( click . Group ) : [EOL] def __init__ ( self , * args , ** kwargs ) : [EOL] self . _alias = kwargs . pop ( [string] , [string] ) [EOL] super ( AliasGroup , self ) . __init__ ( * args , ** kwargs ) [EOL] [EOL] def alias ( self ) : [EOL] return self . _alias [EOL] [EOL] def get_command ( self , ctx , cmd_name ) : [EOL] rv = click . Group . get_command ( self , ctx , cmd_name ) [EOL] if rv is not None : [EOL] return rv [EOL] matches = [ x for x in self . list_commands ( ctx ) if hasattr ( click . Group . get_command ( self , ctx , x ) , [string] ) [EOL] and click . Group . get_command ( self , ctx , x ) . alias ( ) == cmd_name ] [EOL] if not matches : [EOL] return None [EOL] [EOL] return click . Group . get_command ( self , ctx , matches [ [number] ] ) [EOL] [EOL] def format_commands ( self , ctx , formatter ) : [EOL] helper = [ ] [EOL] for cmd in self . list_commands ( ctx ) : [EOL] if cmd is None : [EOL] continue [EOL] c = self . get_command ( ctx , cmd ) [EOL] alias = c . alias ( ) if hasattr ( c , [string] ) else [string] [EOL] cmd_name = [string] . format ( cmd , alias ) [EOL] cmd_help = c . short_help or [string] [EOL] helper . append ( ( cmd_name , cmd_help ) ) [EOL] if helper : [EOL] with formatter . section ( [string] ) : [EOL] formatter . write_dl ( helper ) [EOL] [EOL] def collect_usage_pieces ( self , ctx ) : [EOL] [comment] [EOL] rv = super ( AliasGroup , self ) . collect_usage_pieces ( ctx ) [ [number] : ] [EOL] return rv [EOL] [EOL] def get_help_option ( self , ctx ) : [EOL] help_options = self . get_help_option_names ( ctx ) [EOL] if not help_options or not self . add_help_option : [EOL] return [EOL] [EOL] def show_help ( ctx , param , value ) : [EOL] if value and not ctx . resilient_parsing : [EOL] click . echo ( ctx . get_help ( ) , color = ctx . color ) [EOL] ctx . exit ( ) [EOL] [EOL] return click . Option ( help_options , is_flag = True , is_eager = True , expose_value = False , callback = show_help , help = [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[click.core.Command]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[click.core.Command]$ 0 0 0 0 0 0 $typing.Optional[click.core.Command]$ 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Set[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 $typing.Set[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Set[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from enum import Enum [EOL] [EOL] [EOL] [comment] [EOL] class NAUTAAppNames ( Enum ) : [EOL] ELASTICSEARCH = [string] [EOL] DOCKER_REGISTRY = [string] [EOL] WEB_GUI = [string] [EOL] TENSORBOARD = [string] [EOL] TENSORBOARD_SERVICE = [string] [EOL] INGRESS = [string] [EOL] JUPYTER = [string] [EOL] GIT_REPO_MANAGER = [string] [EOL] GIT_REPO_MANAGER_SSH = [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] from typing import List [EOL] import builtins [EOL] import typing [EOL] from http import HTTPStatus [EOL] import json [EOL] import os [EOL] from typing import List [EOL] [EOL] import requests [EOL] [EOL] from util . logger import initialize_logger [EOL] from cli_text_consts import GithubMessages as Texts [EOL] [EOL] logger = initialize_logger ( __name__ ) [EOL] [EOL] [EOL] class GithubException ( Exception ) : [EOL] def __init__ ( self , status = None ) : [EOL] super ( ) . __init__ ( ) [EOL] self . status = status [EOL] [EOL] [EOL] class GithubRepository : [EOL] def __init__ ( self , name ) : [EOL] self . name = name [EOL] [EOL] [EOL] class Github : [EOL] [EOL] GITHUB_URL = [string] [EOL] GITHUB_API_URL = [string] [EOL] GITHUB_DOWNLOAD_URL = [string] [EOL] [EOL] def __init__ ( self , repository_name , token ) : [EOL] self . token = token [EOL] self . repository_name = repository_name [EOL] [EOL] def make_get_request ( self , url ) : [EOL] headers = None [EOL] if self . token : [EOL] headers = { [string] : f' [string] { self . token }' } [EOL] try : [EOL] output = requests . get ( url , headers = headers ) [EOL] [EOL] except Exception as exe : [EOL] logger . exception ( Texts . GET_OTHER_ERROR ) [EOL] raise GithubException ( str ( HTTPStatus . SEE_OTHER ) ) from exe [EOL] [EOL] if output . status_code == HTTPStatus . NOT_FOUND : [EOL] logger . debug ( Texts . GET_MISSING_FILE . format ( url = url ) ) [EOL] raise GithubException ( output . status_code ) [EOL] elif output . status_code != HTTPStatus . OK : [EOL] logger . error ( Texts . GET_REQUEST_ERROR . format ( url = url , http_code = output . status_code ) ) [EOL] raise GithubException ( output . status_code ) [EOL] [EOL] return output . text [EOL] [EOL] def get_repository_content ( self ) : [EOL] ret_list = [ ] [EOL] request_url = [string] . join ( [ self . GITHUB_API_URL , [string] , self . repository_name , [string] ] ) [EOL] [EOL] output = self . make_get_request ( request_url ) [EOL] [EOL] repo_item_list = json . loads ( output ) [EOL] [EOL] for item in repo_item_list : [EOL] logger . debug ( item ) [EOL] if item . get ( [string] ) == [string] : [EOL] repository = GithubRepository ( name = item . get ( [string] ) ) [EOL] ret_list . append ( repository ) [EOL] [EOL] return ret_list [EOL] [EOL] def get_file_content ( self , file_path ) : [EOL] request_url = [string] . join ( [ self . GITHUB_API_URL , [string] , self . repository_name , [string] , file_path ] ) [EOL] try : [EOL] file_location = self . make_get_request ( request_url ) [EOL] download_url = json . loads ( file_location ) . get ( [string] ) [EOL] [EOL] if download_url : [EOL] file = requests . get ( download_url ) [EOL] return file . text if file else None [EOL] return None [EOL] except Exception : [EOL] logger . exception ( Texts . MISSING_CHART_FILE . format ( request_url = request_url ) ) [EOL] raise [EOL] [EOL] def download_whole_directory ( self , dirpath , output_dir_path ) : [EOL] os . makedirs ( output_dir_path ) [EOL] [EOL] request_url = [string] . join ( [ self . GITHUB_API_URL , [string] , self . repository_name , [string] , dirpath ] ) [EOL] [EOL] try : [EOL] output = self . make_get_request ( request_url ) [EOL] repo_item_list = json . loads ( output ) [EOL] except Exception : [EOL] logger . exception ( f' [string] { self . repository_name } [string] ' ) [EOL] raise [EOL] [EOL] for item in repo_item_list : [EOL] if item [ [string] ] == [string] : [EOL] file_content = self . get_file_content ( [string] . join ( [ dirpath , item [ [string] ] ] ) ) [EOL] with open ( os . path . join ( output_dir_path , item [ [string] ] ) , mode = [string] ) as file : [EOL] file . write ( file_content ) [EOL] elif item [ [string] ] == [string] : [EOL] self . download_whole_directory ( dirpath = [string] . join ( [ dirpath , item [ [string] ] ] ) , output_dir_path = os . path . join ( output_dir_path , item [ [string] ] ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , List , Tuple , Dict [EOL] import logging [EOL] import builtins [EOL] import typing [EOL] import glob [EOL] import logging [EOL] import os [EOL] from pathlib import PurePath [EOL] import re [EOL] [EOL] from ruamel . yaml import YAML [EOL] from typing import Dict , Tuple [EOL] [EOL] from util . config import Config [EOL] from util . k8s . k8s_info import get_k8s_api [EOL] from cli_text_consts import VerifyCmdTexts as Texts [EOL] [EOL] [EOL] PREFIX_VALUES = { [string] : [number] ** [number] , [string] : [number] ** [number] , [string] : [number] ** [number] , [string] : [number] ** [number] , [string] : [number] ** [number] , [string] : [number] ** [number] } [EOL] PREFIX_I_VALUES = { [string] : [number] ** [number] , [string] : [number] ** [number] , [string] : [number] ** [number] , [string] : [number] ** [number] , [string] : [number] ** [number] , [string] : [number] ** [number] } [EOL] [EOL] RESOURCE_NAMES = [ [string] , [string] , [string] , [string] ] [EOL] CPU_SINGLE_VALUES = [ [string] , [string] , [string] , [string] ] [EOL] CPU_INT_VALUES = [ [string] ] [EOL] PHYSICAL_CPU_VALUES = [ [string] ] [EOL] MEMORY_SINGLE_VALUES = [ [string] , [string] , [string] ] [EOL] [EOL] CPU_FRACTION = [string] [EOL] MEMORY_FRACTION = [string] [EOL] [EOL] logging . basicConfig ( ) [EOL] logger = logging . getLogger ( __name__ ) [EOL] logger . setLevel ( logging . DEBUG ) [EOL] [EOL] [EOL] def convert_k8s_cpu_resource ( cpu_resource ) : [EOL] [comment] [EOL] cpu_resource = str ( cpu_resource ) [EOL] if str ( cpu_resource [ - [number] ] ) == [string] : [EOL] return int ( str ( cpu_resource [ : - [number] ] ) ) [EOL] [comment] [EOL] else : [EOL] return int ( float ( cpu_resource ) * [number] ) [EOL] [EOL] [EOL] def convert_k8s_memory_resource ( mem_resource ) : [EOL] [comment] [EOL] mem_resource = str ( mem_resource ) [EOL] if mem_resource [ - [number] ] == [string] and mem_resource [ - [number] : ] in PREFIX_I_VALUES : [EOL] prefix = mem_resource [ - [number] : ] [EOL] return int ( float ( mem_resource [ : - [number] ] ) * PREFIX_I_VALUES [ prefix ] ) [EOL] [comment] [EOL] [comment] [EOL] elif mem_resource [ - [number] ] in PREFIX_VALUES : [EOL] prefix = mem_resource [ - [number] ] [EOL] return int ( float ( mem_resource [ : - [number] ] ) * PREFIX_VALUES [ prefix ] ) [EOL] [comment] [EOL] elif [string] in mem_resource : [EOL] return int ( float ( mem_resource ) ) [EOL] else : [EOL] return int ( mem_resource ) [EOL] [EOL] [EOL] def replace_cpu_configuration ( data , new_cpu_number , current_cpu_number , fraction , system_required_min = [string] , system_required_percent = [string] ) : [EOL] [EOL] if not data : [EOL] return { } [EOL] [EOL] conv_new_cpu_number = convert_k8s_cpu_resource ( new_cpu_number ) [EOL] conv_current_cpu_number = convert_k8s_cpu_resource ( current_cpu_number ) [EOL] [EOL] if fraction : [EOL] conv_system_required_min = convert_k8s_cpu_resource ( system_required_min ) [EOL] conv_system_required_percent = float ( system_required_percent ) / [number] [EOL] [EOL] conv_system_required = conv_new_cpu_number * conv_system_required_percent [EOL] if conv_system_required < conv_system_required_min : [EOL] conv_system_required = conv_system_required_min [EOL] [EOL] new_req_cpu = ( ( conv_new_cpu_number - conv_system_required ) * fraction ) / [number] [EOL] new_limit_cpu = ( ( conv_new_cpu_number - conv_system_required ) * fraction ) / [number] [EOL] else : [EOL] req_cpu = convert_k8s_cpu_resource ( data . get ( [string] , { } ) . get ( [string] ) ) [EOL] limit_cpu = convert_k8s_cpu_resource ( data . get ( [string] , { } ) . get ( [string] ) ) [EOL] [EOL] new_req_cpu = ( conv_new_cpu_number * req_cpu / conv_current_cpu_number ) / [number] [EOL] new_limit_cpu = ( conv_new_cpu_number * limit_cpu / conv_current_cpu_number ) / [number] [EOL] [EOL] data [ [string] ] . update ( { [string] : str ( new_req_cpu ) } ) [EOL] data [ [string] ] . update ( { [string] : str ( new_limit_cpu ) } ) [EOL] return data [EOL] [EOL] [EOL] def replace_memory_configuration ( data , new_memory_amount , current_mem_amount , fraction , system_required_min = [string] , system_required_percent = [string] ) : [EOL] [EOL] if not data : [EOL] return { } [EOL] [EOL] conv_new_memory_amount = convert_k8s_memory_resource ( new_memory_amount ) [EOL] conv_current_memory_amount = convert_k8s_memory_resource ( current_mem_amount ) [EOL] [EOL] if fraction : [EOL] conv_system_required_min = convert_k8s_memory_resource ( system_required_min ) [EOL] conv_system_required_percent = float ( system_required_percent ) / [number] [EOL] [EOL] conv_system_required = conv_new_memory_amount * conv_system_required_percent [EOL] if conv_system_required < conv_system_required_min : [EOL] conv_system_required = conv_system_required_min [EOL] [EOL] new_req_memory = int ( ( ( conv_new_memory_amount - conv_system_required ) * fraction ) ) [EOL] new_limit_memory = int ( ( ( conv_new_memory_amount - conv_system_required ) * fraction ) ) [EOL] else : [EOL] req_memory = convert_k8s_memory_resource ( data . get ( [string] , { } ) . get ( [string] ) ) [EOL] limit_memory = convert_k8s_memory_resource ( data . get ( [string] , { } ) . get ( [string] ) ) [EOL] [EOL] new_req_memory = int ( conv_new_memory_amount * req_memory / conv_current_memory_amount ) [EOL] new_limit_memory = int ( conv_new_memory_amount * limit_memory / conv_current_memory_amount ) [EOL] [EOL] data [ [string] ] . update ( { [string] : str ( new_req_memory ) } ) [EOL] data [ [string] ] . update ( { [string] : str ( new_limit_memory ) } ) [EOL] return data [EOL] [EOL] [EOL] def replace_single_value ( data , new_value , current_value , key , fraction = None , cpu = True , system_required_min = [string] , system_required_percent = [string] , round_to_int = False , divide_by_two = False ) : [EOL] value = data . get ( key ) [EOL] [EOL] if not value or value == [string] : [EOL] return [EOL] [EOL] conv_system_required_percent = float ( system_required_percent ) / [number] [EOL] [EOL] if cpu : [EOL] conv_new_value = convert_k8s_cpu_resource ( new_value ) [EOL] conv_system_required_min = convert_k8s_cpu_resource ( system_required_min ) [EOL] [EOL] conv_system_required = conv_new_value * conv_system_required_percent [EOL] if conv_system_required < conv_system_required_min : [EOL] conv_system_required = conv_system_required_min [EOL] [EOL] if fraction : [EOL] coefficient = fraction [EOL] conv_new_value = conv_new_value - conv_system_required [EOL] else : [EOL] conv_current_value = convert_k8s_cpu_resource ( current_value ) [EOL] conv_value = convert_k8s_cpu_resource ( value ) [EOL] coefficient = conv_value / conv_current_value [EOL] [EOL] final_value = ( conv_new_value * coefficient ) / [number] if divide_by_two else ( conv_new_value * coefficient ) / [number] [EOL] final_value = int ( final_value ) if round_to_int else final_value [EOL] final_value = [number] if final_value == [number] else final_value [EOL] else : [EOL] conv_new_value = convert_k8s_memory_resource ( new_value ) [EOL] conv_system_required_min = convert_k8s_memory_resource ( system_required_min ) [EOL] [EOL] conv_system_required = conv_new_value * conv_system_required_percent [EOL] if conv_system_required < conv_system_required_min : [EOL] conv_system_required = conv_system_required_min [EOL] [EOL] if fraction : [EOL] coefficient = fraction [EOL] conv_new_value = conv_new_value - conv_system_required [EOL] else : [EOL] conv_current_value = convert_k8s_memory_resource ( current_value ) [EOL] conv_value = convert_k8s_memory_resource ( value ) [EOL] coefficient = conv_value / conv_current_value [EOL] final_value = int ( conv_new_value * coefficient ) [EOL] [EOL] data [ key ] = str ( final_value ) [EOL] [EOL] [EOL] def override_values_in_packs ( new_cpu_number , new_memory_amount , current_cpu_number , current_mem_amount , cpu_system_required_min , cpu_system_required_percent , mem_system_required_min , mem_system_required_percent , pack_name = None ) : [EOL] [EOL] yaml_parser = YAML ( typ = [string] , plug_ins = [ [string] ] ) [EOL] values_yaml_paths = get_values_file_location ( pack_name ) [EOL] [EOL] for values_yaml_path in glob . glob ( values_yaml_paths ) : [EOL] logger . info ( f" [string] { values_yaml_path }" ) [EOL] [EOL] with open ( values_yaml_path , mode = [string] ) as values_yaml_file : [EOL] pack_values = yaml_parser . load ( values_yaml_file ) [EOL] [EOL] if not pack_values : [EOL] message = f"{ values_yaml_path } [string] " [EOL] logger . error ( message ) [EOL] raise ValueError ( message ) [EOL] [EOL] try : [EOL] cpu_fraction = pack_values . get ( CPU_FRACTION ) [EOL] if cpu_fraction : [EOL] cpu_fraction = float ( cpu_fraction ) [EOL] [EOL] for resource_name in RESOURCE_NAMES : [EOL] if pack_values . get ( resource_name ) : [EOL] pack_values [ resource_name ] = replace_cpu_configuration ( data = pack_values . get ( resource_name ) , new_cpu_number = new_cpu_number , current_cpu_number = current_cpu_number , fraction = cpu_fraction , system_required_min = cpu_system_required_min , system_required_percent = cpu_system_required_percent ) [EOL] [EOL] for cpu_single_value in CPU_SINGLE_VALUES : [EOL] replace_single_value ( data = pack_values , new_value = new_cpu_number , current_value = current_cpu_number , key = cpu_single_value , fraction = cpu_fraction , system_required_min = cpu_system_required_min , system_required_percent = cpu_system_required_percent , round_to_int = ( cpu_single_value in CPU_INT_VALUES ) , divide_by_two = ( cpu_single_value in PHYSICAL_CPU_VALUES ) ) [EOL] [EOL] except Exception : [EOL] logger . exception ( [string] ) [EOL] raise ValueError [EOL] [EOL] try : [EOL] memory_fraction = pack_values . get ( MEMORY_FRACTION ) [EOL] if memory_fraction : [EOL] memory_fraction = float ( memory_fraction ) [EOL] [EOL] for resource_name in RESOURCE_NAMES : [EOL] if pack_values . get ( resource_name ) : [EOL] pack_values [ resource_name ] = replace_memory_configuration ( data = pack_values . get ( resource_name ) , new_memory_amount = new_memory_amount , current_mem_amount = current_mem_amount , fraction = memory_fraction , system_required_min = mem_system_required_min , system_required_percent = mem_system_required_percent ) [EOL] [EOL] for memory_single_value in MEMORY_SINGLE_VALUES : [EOL] replace_single_value ( data = pack_values , new_value = new_memory_amount , current_value = current_mem_amount , key = memory_single_value , fraction = memory_fraction , system_required_min = mem_system_required_min , system_required_percent = mem_system_required_percent , cpu = False ) [EOL] [EOL] except Exception : [EOL] logger . exception ( [string] ) [EOL] raise ValueError [EOL] [EOL] with open ( values_yaml_path , mode = [string] ) as values_yaml_file : [EOL] yaml_parser . dump ( pack_values , values_yaml_file ) [EOL] logger . info ( f" [string] { values_yaml_path } [string] " ) [EOL] [EOL] [EOL] def validate_memory_settings ( memory ) : [EOL] return re . match ( [string] , memory ) [EOL] [EOL] [EOL] def validate_cpu_settings ( cpu ) : [EOL] return re . match ( [string] , cpu ) [EOL] [EOL] [EOL] def get_values_file_location ( pack_name = None ) : [EOL] dlsctl_config_dir_path = Config ( ) . get_config_path ( ) [EOL] pack = [string] if not pack_name else pack_name [EOL] return f"{ dlsctl_config_dir_path } [string] { pack } [string] " [EOL] [EOL] [EOL] def get_k8s_worker_min_resources ( ) : [EOL] api = get_k8s_api ( ) [EOL] [EOL] nodes = api . list_node ( ) [EOL] [EOL] allocatable_cpus_per_node = [ ] [EOL] allocatable_memory_per_node = [ ] [EOL] [EOL] for node in nodes . items : [EOL] allocatable_cpus_per_node . append ( node . status . allocatable [ [string] ] ) [EOL] allocatable_memory_per_node . append ( node . status . allocatable [ [string] ] ) [EOL] [EOL] return min ( allocatable_cpus_per_node ) , min ( allocatable_memory_per_node ) [EOL] [EOL] [EOL] def extract_pack_name_from_path ( path ) : [EOL] if path and os . path . basename ( path ) == [string] : [EOL] parts = PurePath ( path ) . parts [EOL] if len ( parts ) > [number] : [EOL] [comment] [EOL] [comment] [EOL] return parts [ - [number] ] [EOL] return None [EOL] [EOL] [EOL] def verify_values_in_packs ( ) : [EOL] yaml_parser = YAML ( typ = [string] , plug_ins = [ [string] ] ) [EOL] values_yaml_paths = get_values_file_location ( ) [EOL] [EOL] list_of_incorrect_packs = [ ] [EOL] [EOL] min_available_cpu , min_available_mem = get_k8s_worker_min_resources ( ) [EOL] [EOL] conv_min_available_cpu = convert_k8s_cpu_resource ( min_available_cpu ) [EOL] conv_min_available_memory = convert_k8s_memory_resource ( min_available_mem ) [EOL] [EOL] for values_yaml_path in glob . glob ( values_yaml_paths ) : [EOL] logger . info ( f" [string] { values_yaml_path }" ) [EOL] [EOL] pack_name = extract_pack_name_from_path ( values_yaml_path ) [EOL] if not pack_name : [EOL] continue [EOL] [EOL] with open ( values_yaml_path , mode = [string] ) as values_yaml_file : [EOL] pack_values = yaml_parser . load ( values_yaml_file ) [EOL] [EOL] if not pack_values : [EOL] logger . error ( f"{ values_yaml_path } [string] " ) [EOL] raise ValueError [EOL] [EOL] if not check_cpu_values ( pack_values , conv_min_available_cpu ) : [EOL] list_of_incorrect_packs . append ( Texts . WRONG_REQUIREMENTS_SETTINGS . format ( pack_name = pack_name ) ) [EOL] continue [EOL] [EOL] if not check_memory_values ( pack_values , conv_min_available_memory ) : [EOL] list_of_incorrect_packs . append ( Texts . WRONG_REQUIREMENTS_SETTINGS . format ( pack_name = pack_name ) ) [EOL] [EOL] return list_of_incorrect_packs [EOL] [EOL] [EOL] def check_cpu_values ( pack_values , conv_min_available_cpu ) : [EOL] try : [EOL] for cpu_single_value in CPU_SINGLE_VALUES : [EOL] if pack_values . get ( cpu_single_value ) : [EOL] cpu_single = convert_k8s_cpu_resource ( pack_values . get ( cpu_single_value ) ) [EOL] if cpu_single > conv_min_available_cpu : [EOL] return False [EOL] [EOL] for resource_name in RESOURCE_NAMES : [EOL] if pack_values . get ( resource_name ) : [EOL] req_cpu = convert_k8s_cpu_resource ( pack_values . get ( resource_name ) . get ( [string] , { } ) . get ( [string] ) ) [EOL] if req_cpu and req_cpu > conv_min_available_cpu : [EOL] return False [EOL] except Exception : [EOL] logger . exception ( [string] ) [EOL] raise ValueError [EOL] [EOL] return True [EOL] [EOL] [EOL] def check_memory_values ( pack_values , conv_min_available_memory ) : [EOL] try : [EOL] for memory_single_value in MEMORY_SINGLE_VALUES : [EOL] if pack_values . get ( memory_single_value ) : [EOL] memory_single = convert_k8s_memory_resource ( pack_values . get ( memory_single_value ) ) [EOL] if memory_single > conv_min_available_memory : [EOL] return False [EOL] [EOL] for resource_name in RESOURCE_NAMES : [EOL] if pack_values . get ( resource_name ) : [EOL] req_memory = convert_k8s_memory_resource ( pack_values . get ( resource_name ) . get ( [string] , { } ) . get ( [string] ) ) [EOL] if req_memory and req_memory > conv_min_available_memory : [EOL] return False [EOL] [EOL] except Exception : [EOL] logger . exception ( [string] ) [EOL] raise ValueError [EOL] [EOL] return True [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , Union , Dict [EOL] import builtins [EOL] import typing [EOL] from os import path [EOL] [EOL] import nbformat [EOL] [EOL] from util . logger import initialize_logger [EOL] from util . exceptions import ScriptConversionError [EOL] from cli_text_consts import UtilJupyterTexts as Texts [EOL] [EOL] [EOL] logger = initialize_logger ( __name__ ) [EOL] [EOL] [comment] [EOL] notebook_metadata = { [string] : { [string] : [string] , [string] : [string] , [string] : [string] } , [string] : { [string] : { [string] : [string] , [string] : [number] } , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , } } [EOL] [EOL] [EOL] def convert_py_to_ipynb ( py_filename , ipynb_location ) : [EOL] [docstring] [EOL] cells = [ ] [EOL] [EOL] try : [EOL] with open ( py_filename , [string] ) as file : [EOL] cell = nbformat . v4 . new_code_cell ( source = file . read ( ) ) [EOL] cells . append ( cell ) [EOL] [EOL] output_notebook = nbformat . v4 . new_notebook ( cells = cells , metadata = notebook_metadata ) [EOL] [EOL] py_filename = path . basename ( py_filename ) [EOL] [EOL] ipynb_filename = [string] . join ( py_filename . split ( [string] ) [ : - [number] ] ) + [string] [EOL] [EOL] ipynb_full_path = path . join ( ipynb_location , ipynb_filename ) [EOL] nbformat . write ( output_notebook , ipynb_full_path , nbformat . NO_CONVERT ) [EOL] except Exception : [EOL] err_message = Texts . IPYNB_CONVERSION_ERROR_MSG [EOL] logger . exception ( err_message ) [EOL] raise ScriptConversionError ( err_message ) [EOL] [EOL] return ipynb_filename [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Callable , List , Optional , Any [EOL] import logging [EOL] import builtins [EOL] import typing [EOL] import sys [EOL] import os [EOL] import logging [EOL] from logging . handlers import TimedRotatingFileHandler [EOL] from typing import List [EOL] [EOL] STREAM_HANDLER = logging . StreamHandler ( stream = sys . stdout ) [EOL] [EOL] [EOL] def initialize_logger ( package_name ) : [EOL] STREAM_HANDLER . setLevel ( logging . CRITICAL ) [EOL] logger = logging . getLogger ( package_name ) [EOL] logging . basicConfig ( level = logging . DEBUG , handlers = [ STREAM_HANDLER ] ) [EOL] [EOL] return logger [EOL] [EOL] [EOL] def get_verbosity_level ( ) : [EOL] return STREAM_HANDLER . level [EOL] [EOL] [EOL] def set_global_logging_level ( log_level ) : [EOL] for key in logging . Logger . manager . loggerDict : [EOL] for handler in logging . getLogger ( key ) . handlers : [EOL] if not isinstance ( handler , TimedRotatingFileHandler ) : [EOL] handler . setLevel ( log_level ) [EOL] [EOL] [EOL] [comment] [EOL] def set_verbosity_level ( verbosity ) : [EOL] if verbosity == [number] : [EOL] logging_level = logging . CRITICAL [EOL] elif verbosity == [number] : [EOL] logging_level = logging . INFO [EOL] else : [EOL] logging_level = logging . DEBUG [EOL] [EOL] set_global_logging_level ( logging_level ) [EOL] STREAM_HANDLER . setLevel ( logging_level ) [EOL] [EOL] [EOL] def setup_log_file ( log_file_directory , log_level = logging . DEBUG , log_backup_count = [number] ) : [EOL] root_logger = logging . getLogger ( ) [EOL] formatter = logging . Formatter ( [string] ) [EOL] file_handler = TimedRotatingFileHandler ( filename = f'{ log_file_directory } [string] ' , when = [string] , interval = [number] , backupCount = log_backup_count ) [EOL] file_handler . rotator = nauta_log_rotator [EOL] file_handler . setFormatter ( formatter ) [EOL] file_handler . setLevel ( log_level ) [EOL] root_logger . addHandler ( file_handler ) [EOL] [EOL] return file_handler [EOL] [EOL] [EOL] def nauta_log_rotator ( source , dest ) : [EOL] if os . path . exists ( source ) : [EOL] try : [EOL] os . rename ( source , dest ) [EOL] except PermissionError : [EOL] pass [comment] [EOL] [EOL] [EOL] def configure_logger_for_external_packages ( pack_name , initial_log_level , handlers = None ) : [EOL] logging . captureWarnings ( True ) [comment] [EOL] loggers_keys_list = [ key for key in logging . Logger . manager . loggerDict if key . startswith ( pack_name ) ] [comment] [EOL] for key in loggers_keys_list : [EOL] logger = logging . getLogger ( key ) [EOL] logger . propagate = False [EOL] if handlers : [EOL] for handler in handlers : [EOL] logger . addHandler ( handler ) [EOL] [comment] [EOL] STREAM_HANDLER . setLevel ( initial_log_level ) [EOL] logger . addHandler ( STREAM_HANDLER ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] class KubernetesError ( Exception ) : [EOL] [docstring] [EOL] pass [EOL] [EOL] [EOL] class KubectlConnectionError ( Exception ) : [EOL] [docstring] [EOL] [EOL] [EOL] class InvalidRegularExpressionError ( RuntimeError ) : [EOL] [docstring] [EOL] pass [EOL] [EOL] [EOL] class ExceptionWithMessage ( Exception ) : [EOL] [docstring] [EOL] def __init__ ( self , message = None ) : [EOL] self . message = message if message else [string] [EOL] [EOL] [EOL] class K8sProxyOpenError ( ExceptionWithMessage ) : [EOL] [docstring] [EOL] pass [EOL] [EOL] [EOL] class K8sProxyCloseError ( ExceptionWithMessage ) : [EOL] [docstring] [EOL] pass [EOL] [EOL] [EOL] class LocalPortOccupiedError ( ExceptionWithMessage ) : [EOL] [docstring] [EOL] pass [EOL] [EOL] [EOL] class SubmitExperimentError ( ExceptionWithMessage ) : [EOL] [docstring] [EOL] pass [EOL] [EOL] [EOL] class LaunchError ( ExceptionWithMessage ) : [EOL] [docstring] [EOL] pass [EOL] [EOL] [EOL] class ProxyClosingError ( ExceptionWithMessage ) : [EOL] [docstring] [EOL] [EOL] [EOL] class ScriptConversionError ( Exception ) : [EOL] [docstring] [EOL] pass [EOL] [EOL] [EOL] class InvalidDependencyError ( Exception ) : [EOL] [docstring] [EOL] pass [EOL] [EOL] [EOL] class InvalidOsError ( Exception ) : [EOL] [docstring] [EOL] pass [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import typing [EOL] import logging [EOL] [EOL] import pytest [EOL] [EOL] import util . logger as logger [EOL] [EOL] [EOL] def test_initialize_logger ( ) : [EOL] mock_package_name = [string] [EOL] default_log_level = logging . DEBUG [EOL] default_stream_handler_log_level = logging . CRITICAL [EOL] [EOL] mock_logger = logger . initialize_logger ( mock_package_name ) [EOL] [EOL] assert mock_logger [EOL] assert logging . getLogger ( mock_package_name ) . getEffectiveLevel ( ) == default_log_level [EOL] assert logger . STREAM_HANDLER . level == default_stream_handler_log_level [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [number] , logging . CRITICAL ) , ( [number] , logging . INFO ) , ( [number] , logging . DEBUG ) , ( [number] , logging . DEBUG ) ] ) def test_set_verbosity_level ( mock_verbosity , expected_log_level ) : [EOL] logger . set_verbosity_level ( mock_verbosity ) [EOL] assert logger . get_verbosity_level ( ) == expected_log_level [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import typing [EOL] import pytest [EOL] from unittest . mock import patch , mock_open [EOL] [EOL] from util . jupyter_notebook_creator import convert_py_to_ipynb [EOL] from util . exceptions import ScriptConversionError [EOL] from util . tests . nbformat_mocks import create_nb_format_mocks [comment] [EOL] [EOL] py_file = [string] [EOL] [EOL] PY_FILENAME = [string] [EOL] IPYNB_FILENAME = [string] [EOL] IPYNB_LOCATION = [string] [EOL] [EOL] [EOL] def test_conversion_success ( create_nb_format_mocks ) : [comment] [EOL] m = mock_open ( read_data = py_file ) [EOL] m . return_value . __iter__ = lambda self : self [EOL] m . return_value . __next__ = lambda self : next ( iter ( self . readline , [string] ) ) [EOL] [EOL] with patch ( [string] , m , create = True ) : [EOL] filename = convert_py_to_ipynb ( [string] , [string] ) [EOL] [EOL] assert filename == IPYNB_FILENAME [EOL] args , _ = create_nb_format_mocks . call_args [EOL] [EOL] assert args [ [number] ] [ [string] ] [ [string] ] [ [string] ] == [string] [EOL] cells_list = args [ [number] ] [ [string] ] [EOL] [EOL] for cell in cells_list : [EOL] assert cell [ [string] ] in py_file [EOL] [EOL] [EOL] def test_conversion_failure ( create_nb_format_mocks ) : [comment] [EOL] m = mock_open ( ) [EOL] m . side_effect = RuntimeError ( ) [EOL] [EOL] with pytest . raises ( ScriptConversionError ) : [EOL] with patch ( [string] , m , create = True ) : [EOL] convert_py_to_ipynb ( [string] , [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import typing [EOL] from util import network [EOL] from requests import ConnectionError [EOL] [EOL] [EOL] FAKE_URL = [string] [EOL] [EOL] [EOL] class MockedResponse ( object ) : [EOL] [EOL] def __init__ ( self , status_code ) : [EOL] self . status_code = status_code [EOL] [EOL] [EOL] def test_wait_for_connection_success ( mocker ) : [EOL] req_mock = mocker . patch ( [string] , side_effect = [ MockedResponse ( status_code = [number] ) ] ) [EOL] ready = network . wait_for_connection ( FAKE_URL ) [EOL] assert ready , [string] [EOL] assert req_mock . call_count == [number] , [string] [EOL] [EOL] [EOL] def test_wait_for_connection_fail ( mocker ) : [EOL] req_mock = mocker . patch ( [string] , side_effect = [ MockedResponse ( status_code = [number] ) ] ) [EOL] ready = network . wait_for_connection ( FAKE_URL ) [EOL] assert not ready , [string] [EOL] assert req_mock . call_count == [number] , [string] [EOL] [EOL] [EOL] def test_wait_for_connection_should_retry_when_conn_refused ( mocker ) : [EOL] req_mock = mocker . patch ( [string] , side_effect = ConnectionError ) [EOL] expected_retries = [number] [EOL] ready = network . wait_for_connection ( FAKE_URL , timeout = [number] ) [EOL] assert not ready , [string] [EOL] assert req_mock . call_count == expected_retries , [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , List , Dict [EOL] import typing [EOL] import os [EOL] [EOL] from util . filesystem import copytree_content , get_total_directory_size_in_bytes [EOL] [EOL] [EOL] def test_copytree_content ( mocker ) : [EOL] fake_src_dir_filelist = [ [string] , [string] , [string] ] [EOL] [EOL] mocker . patch ( [string] , return_value = fake_src_dir_filelist ) [EOL] shutil_copytree = mocker . patch ( [string] ) [EOL] shutil_copy2 = mocker . patch ( [string] ) [EOL] mocker . patch ( [string] , new = lambda x : [string] in os . path . basename ( x ) ) [EOL] [EOL] copytree_content ( [string] , [string] ) [EOL] [EOL] assert shutil_copytree . call_count == [number] [EOL] assert shutil_copy2 . call_count == [number] [EOL] [EOL] [EOL] def test_copytree_content_ignored_objects ( mocker ) : [EOL] fake_src_dir_filelist = [ [string] , [string] , [string] ] [EOL] [EOL] mocker . patch ( [string] , return_value = fake_src_dir_filelist ) [EOL] shutil_copytree = mocker . patch ( [string] ) [EOL] shutil_copy2 = mocker . patch ( [string] ) [EOL] mocker . patch ( [string] , new = lambda x : [string] in os . path . basename ( x ) ) [EOL] [EOL] copytree_content ( [string] , [string] , ignored_objects = [ [string] ] ) [EOL] [EOL] assert shutil_copytree . call_count == [number] [EOL] assert shutil_copy2 . call_count == [number] [EOL] [EOL] [EOL] def test_get_total_directory_size_in_bytes ( tmpdir ) : [EOL] test_dir = tmpdir . mkdir ( [string] ) [EOL] test_subdir = test_dir . mkdir ( [string] ) [EOL] [EOL] files = [ { [string] : test_dir . join ( [string] ) , [string] : [number] } , { [string] : test_subdir . join ( [string] ) , [string] : [number] } ] [EOL] [EOL] for file in files : [EOL] with open ( file [ [string] ] , [string] ) as f : [EOL] f . write ( os . urandom ( file [ [string] ] ) ) [EOL] [EOL] assert get_total_directory_size_in_bytes ( test_dir ) == sum ( file [ [string] ] for file in files ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , Union , List , Dict [EOL] import typing [EOL] import pytest [EOL] [EOL] [EOL] validator_json = { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [ [string] , [string] , [string] , [string] ] , [string] : { [string] : { [string] : [string] , [string] : [string] , [string] : [string] , [string] : { [string] : { [string] : [string] , [string] : [string] , [string] : [ [string] , [string] ] , [string] : { [string] : { [string] : [string] , [string] : [string] } , [string] : { [string] : [string] , [string] : [string] } } } , [string] : { [string] : [string] , [string] : [string] , [string] : [ [string] ] , [string] : { [string] : { [string] : [string] , [string] : [string] } , [string] : { [string] : [string] , [string] : [ { [string] : [string] } , { [string] : [string] } ] } , [string] : { [string] : [string] , [string] : [string] } , [string] : { [string] : [string] , [string] : [string] } , [string] : { [string] : [string] , [string] : [string] } } } , [string] : { [string] : [string] [string] , [string] : [string] , [string] : [number] } , [string] : { [string] : [string] , [string] : [string] } , [string] : { [string] : [string] , [string] : [string] , [string] : { [string] : [string] , [string] : { [string] : { [string] : [string] } } , [string] : [string] } } } } , [string] : { [string] : [string] [string] , [string] : [string] , [string] : [number] } , [string] : { [string] : [string] [string] , [string] : [string] , [string] : [number] , [string] : [number] } , [string] : { [string] : [string] , [string] : [string] , [string] : { [string] : [string] } } } , [string] : { [string] : { [string] : [string] , [string] : [ { [string] : [string] } , { [string] : [string] } , { [string] : [string] } ] } , [string] : { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [ [string] , [string] , [string] ] , [string] : { [string] : { [string] : [string] , [string] : [ [string] ] } , [string] : { [string] : [string] , [string] : [string] , [string] : [string] , [string] : { [string] : { [string] : [string] , [string] : [string] } , [string] : { [string] : [string] , [string] : [string] , [string] : [string] , [string] : { [string] : [string] , [string] : [string] } } , [string] : { [string] : [string] } , [string] : { [string] : [string] } } } , [string] : { [string] : [string] } , [string] : { [string] : [string] } } } , [string] : { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [ [string] , [string] , [string] ] , [string] : { [string] : { [string] : [string] , [string] : [ [string] ] } , [string] : { [string] : [string] , [string] : [string] , [string] : { [string] : { [string] : [string] } , [string] : { [string] : [string] } , [string] : { [string] : [string] , [string] : [string] , [string] : [string] , [string] : { [string] : [string] , [string] : [string] } } } , [string] : [string] } , [string] : { [string] : [string] } , [string] : { [string] : [string] } } } , [string] : { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [ [string] , [string] , [string] , [string] , [string] ] , [string] : { [string] : { [string] : [string] , [string] : [ [string] ] } , [string] : { [string] : [string] , [string] : [string] , [string] : [string] , [string] : { [string] : { [string] : [string] , [string] : [string] , [string] : [string] , [string] : { [string] : [string] , [string] : [string] } , [string] : { [string] : [string] , [string] : [string] } } , [string] : { [string] : [string] , [string] : [string] } , [string] : { [string] : [string] , [string] : [ [string] , [string] , [string] ] } , [string] : { [string] : [string] } , [string] : { [string] : [string] } } } , [string] : { [string] : [string] } , [string] : { [string] : [string] , [string] : [string] , [string] : { [string] : [string] } } , [string] : { [string] : [string] , [string] : [ [string] , [string] ] , [string] : [number] } } } , [string] : { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [ [string] , [string] ] , [string] : { [string] : { [string] : [string] , [string] : { [string] : [ [string] , [string] , [string] ] } } , [string] : { [string] : [string] , [string] : [string] , [string] : { [string] : { [string] : [string] } , [string] : { [string] : [string] } } , [string] : [string] } } } , [string] : { [string] : [string] , [string] : [ { [string] : [string] } , { [string] : [string] } , { [string] : [string] } , { [string] : [string] } ] } , [string] : { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [ [string] , [string] , [string] , [string] ] , [string] : { [string] : { [string] : [string] , [string] : [ [string] ] } , [string] : { [string] : [string] , [string] : [ [string] , [string] ] , [string] : [number] } , [string] : { [string] : [string] } , [string] : { [string] : [string] } } } , [string] : { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [ [string] , [string] , [string] ] , [string] : { [string] : { [string] : [string] , [string] : [ [string] ] } , [string] : { [string] : [string] } , [string] : { [string] : [string] } } } , [string] : { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [ [string] , [string] , [string] ] , [string] : { [string] : { [string] : [string] , [string] : [ [string] ] } , [string] : { [string] : [string] , [string] : [string] } , [string] : { [string] : [string] , [string] : [string] } } } , [string] : { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [ [string] , [string] , [string] , [string] ] , [string] : { [string] : { [string] : [string] , [string] : [ [string] ] } , [string] : { [string] : [string] , [string] : [string] } , [string] : { [string] : [string] , [string] : [string] } , [string] : { [string] : [string] , [string] : [string] , [string] : { [string] : [string] } } } } , [string] : { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [ [string] ] , [string] : { [string] : { [string] : [string] , [string] : { [string] : [ [string] , [string] , [string] , [string] ] } } } } , [string] : { [string] : { [string] : [string] [string] [string] , [string] : [string] , [string] : [string] } , [string] : { [string] : [string] , [string] : [string] , [string] : [string] , [string] : { [string] : [string] , [string] : [string] } } , [string] : { [string] : [string] , [string] : [string] , [string] : { [string] : { [string] : [string] , [string] : [string] } } } , [string] : { [string] : [string] , [string] : [string] } , [string] : { [string] : [string] , [string] : [ [string] , [string] ] , [string] : [number] } , [string] : { [string] : [string] , [string] : [string] , [string] : { [string] : [string] [string] , [string] : [string] } , [string] : { [string] : { [string] : [string] } } } , [string] : { [string] : [string] , [string] : [string] , [string] : [string] } , [string] : { [string] : [ { [string] : [string] } , { [string] : [string] , [string] : { [string] : [string] } } ] } } } } [EOL] [EOL] [EOL] @ pytest . fixture def create_nb_format_mocks ( mocker ) : [EOL] mocker . patch ( [string] , return_value = validator_json ) [EOL] mock_write = mocker . patch ( [string] ) [EOL] [EOL] return mock_write [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , List , Dict [EOL] import builtins [EOL] import applications [EOL] import typing [EOL] import kubernetes [EOL] import util [EOL] from typing import Dict , List [EOL] [EOL] from kubernetes import client , config [EOL] from kubernetes . client import V1PodList , V1Pod , V1DeleteOptions [EOL] [EOL] from util . k8s . k8s_info import PodStatus [EOL] [EOL] [EOL] class K8SPod : [EOL] def __init__ ( self , namespace , name , status , labels ) : [EOL] self . _namespace = namespace [EOL] [EOL] self . name = name [EOL] self . status = status [EOL] self . labels = labels [EOL] [EOL] def delete ( self ) : [EOL] config . load_kube_config ( ) [EOL] [EOL] v1 = client . CoreV1Api ( ) [EOL] v1 . delete_namespaced_pod ( name = self . name , namespace = self . _namespace , body = V1DeleteOptions ( ) ) [EOL] [EOL] [EOL] def list_pods ( namespace , label_selector = [string] ) : [EOL] config . load_kube_config ( ) [EOL] [EOL] v1 = client . CoreV1Api ( ) [EOL] pods_list = v1 . list_namespaced_pod ( namespace = namespace , label_selector = label_selector ) [EOL] [EOL] pods = pods_list . items [EOL] [EOL] k8s_pods = [ ] [EOL] [EOL] for pod in pods : [EOL] pod_name = pod . metadata . name [EOL] pod_status = pod . status . phase [EOL] k8s_pod_status = PodStatus ( pod_status . upper ( ) ) [EOL] pod_labels = pod . metadata . labels [EOL] [EOL] k8s_pod = K8SPod ( namespace = namespace , name = pod_name , status = k8s_pod_status , labels = pod_labels ) [EOL] [EOL] k8s_pods . append ( k8s_pod ) [EOL] [EOL] return k8s_pods [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[K8SPod]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , Union , Set , Dict [EOL] import typing [EOL] import unittest [EOL] from unittest . mock import MagicMock [EOL] [EOL] import pytest [EOL] from kubernetes . client . models import V1Service , V1ObjectMeta , V1Namespace , V1Status , V1ConfigMap , V1SecretList , V1Secret , V1ClusterRoleList , V1ClusterRole , V1PolicyRule , V1PodList , V1Pod , V1PodStatus , V1ServiceSpec , V1ServicePort , V1NamespaceStatus , V1Event , V1EventList , V1ObjectReference [EOL] from kubernetes . client . rest import ApiException [EOL] [EOL] from util . k8s . k8s_info import get_kubectl_host , get_app_services , find_namespace , delete_namespace , get_config_map_data , get_users_token , get_cluster_roles , is_current_user_administrator , check_pods_status , PodStatus , get_app_service_node_port , get_pods , NamespaceStatus , get_pod_events , get_namespaced_pods , add_bytes_to_unit [EOL] from util . config import NAUTAConfigMap [EOL] from util . app_names import NAUTAAppNames [EOL] from util . exceptions import KubernetesError [EOL] [EOL] test_namespace = [string] [EOL] [EOL] TEST_EXTERNAL_IP = [string] [EOL] TEST_IMAGE_TILLER = [string] [EOL] [EOL] TEST_TOKEN = [string] [string] [string] [string] [string] [string] [string] [string] [string] [string] [string] [string] [string] [string] [string] [string] [string] [string] [string] [EOL] [EOL] TEST_TOKEN_ENCODED = [string] [string] [string] [string] [string] [string] [string] [string] [string] [string] [string] [string] [string] [string] [string] [EOL] [EOL] K8S_RUNNING_POD_STATUS = [string] [EOL] [EOL] K8S_PENDING_POD_STATUS = [string] [EOL] [EOL] [EOL] @ pytest . fixture ( ) def mocked_k8s_config ( mocker ) : [EOL] mocker . patch ( [string] ) [EOL] mocked_conf_class = mocker . patch ( [string] ) [EOL] conf_instance = mocked_conf_class . return_value [EOL] conf_instance . host = [string] [EOL] [EOL] [EOL] def test_config_map_data ( ) : [EOL] return { NAUTAConfigMap . EXTERNAL_IP_FIELD : TEST_EXTERNAL_IP , NAUTAConfigMap . IMAGE_TILLER_FIELD : TEST_IMAGE_TILLER } [EOL] [EOL] [EOL] @ pytest . fixture ( ) def mocked_kubeconfig ( mocker ) : [EOL] mocker . patch ( [string] ) [EOL] [EOL] [EOL] @ pytest . fixture ( ) def mocked_k8s_CoreV1Api ( mocker ) : [EOL] mocked_coreV1Api_class = mocker . patch ( [string] ) [EOL] mocker . patch ( [string] ) [EOL] coreV1API_instance = mocked_coreV1Api_class . return_value [EOL] [EOL] pods_mock = MagicMock ( ) [EOL] pods_mock . items = [ MagicMock ( spec = V1Pod ) , MagicMock ( spec = V1Pod ) , MagicMock ( spec = V1Pod ) ] [EOL] coreV1API_instance . list_pod_for_all_namespaces . return_value = pods_mock [EOL] [EOL] services_mock = MagicMock ( ) [EOL] services_mock . items = [ MagicMock ( spec = V1Service ) , MagicMock ( spec = V1Service ) , MagicMock ( spec = V1Service ) ] [EOL] coreV1API_instance . list_service_for_all_namespaces . return_value = services_mock [EOL] [EOL] v1_namespace = V1Namespace ( ) [EOL] v1_metadata_namespace = V1ObjectMeta ( name = test_namespace ) [EOL] v1_namespace . metadata = v1_metadata_namespace [EOL] v1_namespace_status = V1NamespaceStatus ( phase = NamespaceStatus . ACTIVE . value ) [EOL] v1_namespace . status = v1_namespace_status [EOL] [EOL] coreV1API_instance . read_namespace . return_value = v1_namespace [EOL] coreV1API_instance . delete_namespace . return_value = V1Status ( status = [string] ) [EOL] [EOL] v1_config_map = V1ConfigMap ( data = test_config_map_data ( ) ) [EOL] [EOL] coreV1API_instance . read_namespaced_config_map . return_value = v1_config_map [EOL] [EOL] secret_data = { [string] : TEST_TOKEN } [EOL] v1_metadata_secret = V1ObjectMeta ( name = [string] ) [EOL] v1_secret = V1Secret ( metadata = v1_metadata_secret , data = secret_data ) [EOL] v1_secret_list = V1SecretList ( items = [ v1_secret ] ) [EOL] [EOL] coreV1API_instance . list_namespaced_secret . return_value = v1_secret_list [EOL] [EOL] v1_pod_status = V1PodStatus ( phase = K8S_RUNNING_POD_STATUS ) [EOL] v1_pod = V1Pod ( status = v1_pod_status ) [EOL] v1_pod_lists = V1PodList ( items = [ v1_pod ] ) [EOL] [EOL] coreV1API_instance . list_namespaced_pod . return_value = v1_pod_lists [EOL] [EOL] v1_metadata_event = V1ObjectMeta ( name = [string] ) [EOL] v1_object = V1ObjectReference ( name = [string] ) [EOL] v1_event = V1Event ( message = [string] , involved_object = v1_object , metadata = v1_metadata_event ) [EOL] v1_event_list = V1EventList ( items = [ v1_event ] ) [EOL] [EOL] coreV1API_instance . list_namespaced_event . return_value = v1_event_list [EOL] [EOL] return coreV1API_instance [EOL] [EOL] [EOL] @ pytest . fixture ( ) def mocked_k8s_RbacAuthorizationV1Api ( mocker ) : [EOL] mocked_RbacAuthorizationV1Api_class = mocker . patch ( [string] ) [EOL] mocker . patch ( [string] ) [EOL] rbacAuthorizationV1_instance = mocked_RbacAuthorizationV1Api_class . return_value [EOL] [EOL] v1_metadata_role = V1ObjectMeta ( name = [string] ) [EOL] v1_policy_rule = V1PolicyRule ( verbs = [ [string] ] ) [EOL] v1_role = V1ClusterRole ( metadata = v1_metadata_role , kind = [string] , rules = [ v1_policy_rule ] ) [EOL] v1_cluster_role_list = V1ClusterRoleList ( items = [ v1_role ] ) [EOL] [EOL] rbacAuthorizationV1_instance . list_cluster_role . return_value = v1_cluster_role_list [EOL] [EOL] [EOL] def test_get_k8s_host_w_port_replace_https ( mocked_k8s_config ) : [EOL] k8s_host = get_kubectl_host ( replace_https = True , with_port = True ) [EOL] [EOL] assert k8s_host == [string] [EOL] [EOL] [EOL] def test_get_k8s_host_wo_port_replace_https ( mocked_k8s_config ) : [EOL] k8s_host = get_kubectl_host ( replace_https = True , with_port = False ) [EOL] [EOL] assert k8s_host == [string] [EOL] [EOL] [EOL] def test_get_k8s_host_w_port ( mocked_k8s_config ) : [EOL] k8s_host = get_kubectl_host ( replace_https = False , with_port = True ) [EOL] [EOL] assert k8s_host == [string] [EOL] [EOL] [EOL] def test_get_k8s_host_wo_port ( mocked_k8s_config ) : [EOL] k8s_host = get_kubectl_host ( replace_https = False , with_port = False ) [EOL] [EOL] assert k8s_host == [string] [EOL] [EOL] [EOL] def test_get_app_services ( mocked_k8s_config , mocked_k8s_CoreV1Api ) : [EOL] services = get_app_services ( nauta_app_name = NAUTAAppNames . DOCKER_REGISTRY ) [EOL] [EOL] assert services [EOL] [EOL] [EOL] def test_get_pod_events ( mocked_k8s_config , mocked_k8s_CoreV1Api ) : [EOL] events = get_pod_events ( namespace = test_namespace ) [EOL] [EOL] assert events [EOL] [EOL] [EOL] def test_find_namespace_success ( mocker , mocked_k8s_CoreV1Api , mocked_kubeconfig ) : [EOL] assert find_namespace ( test_namespace ) == NamespaceStatus . ACTIVE [EOL] [EOL] [EOL] def test_find_namespace_failure ( mocker , mocked_k8s_CoreV1Api , mocked_kubeconfig ) : [EOL] assert find_namespace ( test_namespace + [string] ) == NamespaceStatus . NOT_EXISTS [EOL] [EOL] [EOL] def test_find_namespace_terminating ( mocker , mocked_k8s_CoreV1Api , mocked_kubeconfig ) : [EOL] mocked_k8s_CoreV1Api . read_namespace . return_value . status = V1NamespaceStatus ( phase = NamespaceStatus . TERMINATING . value ) [EOL] assert find_namespace ( test_namespace ) == NamespaceStatus . TERMINATING [EOL] [EOL] [EOL] def test_delete_namespace ( mocker , mocked_k8s_CoreV1Api , mocked_kubeconfig ) : [EOL] delete_namespace ( test_namespace ) [EOL] [EOL] assert mocked_k8s_CoreV1Api . delete_namespace . call_count == [number] [EOL] [EOL] [EOL] def test_delete_namespace_exception ( mocker , mocked_k8s_CoreV1Api , mocked_kubeconfig ) : [EOL] mocked_k8s_CoreV1Api . delete_namespace . side_effect = RuntimeError ( ) [EOL] [EOL] with pytest . raises ( KubernetesError ) : [EOL] delete_namespace ( test_namespace ) [EOL] [EOL] [EOL] def test_delete_namespace_failure ( mocker , mocked_k8s_CoreV1Api , mocked_kubeconfig ) : [EOL] mocked_k8s_CoreV1Api . delete_namespace . return_value = V1Status ( status = [string] ) [EOL] [EOL] with pytest . raises ( KubernetesError ) : [EOL] delete_namespace ( test_namespace ) [EOL] [EOL] [EOL] def test_get_config_map_data ( mocker , mocked_k8s_CoreV1Api , mocked_kubeconfig ) : [EOL] data = get_config_map_data ( [string] , test_namespace ) [EOL] [EOL] assert data . get ( NAUTAConfigMap . EXTERNAL_IP_FIELD ) == TEST_EXTERNAL_IP [EOL] assert data . get ( NAUTAConfigMap . IMAGE_TILLER_FIELD ) == TEST_IMAGE_TILLER [EOL] [EOL] [EOL] def test_get_users_token ( mocker , mocked_k8s_CoreV1Api , mocked_kubeconfig ) : [EOL] token = get_users_token ( test_namespace ) [EOL] [EOL] assert token == TEST_TOKEN_ENCODED [EOL] [EOL] [EOL] def test_get_pods ( mocker , mocked_k8s_CoreV1Api , mocked_kubeconfig ) : [EOL] pods = get_pods ( label_selector = [string] ) [EOL] assert pods [EOL] [EOL] [EOL] def test_get_pods_not_found ( mocker , mocked_k8s_CoreV1Api , mocked_kubeconfig ) : [EOL] mocked_k8s_CoreV1Api . list_pod_for_all_namespaces . side_effect = ApiException ( status = [number] ) [EOL] pods = get_pods ( label_selector = [string] ) [EOL] assert pods == [ ] [EOL] [EOL] [EOL] def test_get_pods_error ( mocker , mocked_k8s_CoreV1Api , mocked_kubeconfig ) : [EOL] mocked_k8s_CoreV1Api . list_pod_for_all_namespaces . side_effect = ApiException ( status = [number] ) [EOL] with pytest . raises ( ApiException ) : [EOL] get_pods ( label_selector = [string] ) [EOL] [EOL] [EOL] def test_get_namespaced_pods ( mocker , mocked_k8s_CoreV1Api , mocked_kubeconfig ) : [EOL] pods = get_namespaced_pods ( label_selector = [string] , namespace = test_namespace ) [EOL] assert pods [EOL] [EOL] [EOL] def test_get_namespaced_pods_not_found ( mocker , mocked_k8s_CoreV1Api , mocked_kubeconfig ) : [EOL] mocked_k8s_CoreV1Api . list_namespaced_pod . side_effect = ApiException ( status = [number] ) [EOL] pods = get_namespaced_pods ( label_selector = [string] , namespace = test_namespace ) [EOL] assert pods == [ ] [EOL] [EOL] [EOL] def test_get_namespaced_pods_error ( mocker , mocked_k8s_CoreV1Api , mocked_kubeconfig ) : [EOL] mocked_k8s_CoreV1Api . list_namespaced_pod . side_effect = ApiException ( status = [number] ) [EOL] with pytest . raises ( ApiException ) : [EOL] get_namespaced_pods ( label_selector = [string] , namespace = test_namespace ) [EOL] [EOL] [EOL] def test_get_cluster_roles ( mocked_k8s_config , mocked_k8s_RbacAuthorizationV1Api ) : [EOL] roles = get_cluster_roles ( ) [EOL] print ( roles ) [EOL] assert roles . items [ [number] ] . kind == [string] [EOL] [EOL] [EOL] def test_is_current_user_administrator_is ( mocker ) : [EOL] gcr_mock = mocker . patch ( [string] ) [EOL] [EOL] assert is_current_user_administrator ( ) [EOL] assert gcr_mock . call_count == [number] [EOL] [EOL] [EOL] def test_is_current_user_administrator_is_not ( mocker ) : [EOL] gcr_mock = mocker . patch ( [string] , side_effect = ApiException ( status = [number] ) ) [EOL] [EOL] assert not is_current_user_administrator ( ) [EOL] assert gcr_mock . call_count == [number] [EOL] [EOL] [EOL] def test_is_current_user_administrator_ ( mocker ) : [EOL] gcr_mock = mocker . patch ( [string] , side_effect = ApiException ( status = [number] ) ) [EOL] [EOL] with pytest . raises ( ApiException ) : [EOL] is_current_user_administrator ( ) [EOL] [EOL] assert gcr_mock . call_count == [number] [EOL] [EOL] [EOL] def test_check_pods_status_success ( mocked_k8s_CoreV1Api , mocked_kubeconfig ) : [EOL] assert check_pods_status ( [string] , test_namespace , PodStatus . RUNNING , None ) [EOL] [EOL] [EOL] def test_check_pods_status_failure ( mocked_k8s_CoreV1Api , mocked_kubeconfig ) : [EOL] mocked_k8s_CoreV1Api . list_namespaced_pod . return_value . items [ [number] ] . status . phase = K8S_PENDING_POD_STATUS [EOL] assert not check_pods_status ( [string] , test_namespace , PodStatus . RUNNING , None ) [EOL] mocked_k8s_CoreV1Api . list_namespaced_pod . return_value . items [ [number] ] . status . phase = K8S_RUNNING_POD_STATUS [EOL] [EOL] [EOL] def test_check_pods_status_failure_empty_list ( mocked_k8s_CoreV1Api , mocked_kubeconfig ) : [EOL] ret_value = mocked_k8s_CoreV1Api . list_namespaced_pod . return_value [EOL] mocked_k8s_CoreV1Api . list_namespaced_pod . return_value = None [EOL] assert not check_pods_status ( [string] , test_namespace , PodStatus . RUNNING , None ) [EOL] mocked_k8s_CoreV1Api . list_namespaced_pod . return_value = ret_value [EOL] [EOL] [EOL] def test_get_app_service_node_port ( mocker ) : [EOL] test_node_port = [number] [EOL] get_app_services_mock = mocker . patch ( [string] ) [EOL] get_app_services_mock . return_value = [ V1Service ( spec = V1ServiceSpec ( ports = [ V1ServicePort ( node_port = test_node_port , port = test_node_port ) ] ) ) ] [EOL] assert get_app_service_node_port ( NAUTAAppNames . DOCKER_REGISTRY ) == test_node_port [EOL] [EOL] [EOL] def test_add_bytes_to_unit ( ) : [EOL] negatives = { [string] , [number] , [number] , [string] , [string] } [EOL] [EOL] for test in negatives : [EOL] assert add_bytes_to_unit ( test ) == test [EOL] assert add_bytes_to_unit ( [string] ) == [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , List [EOL] import util [EOL] import builtins [EOL] import typing [EOL] import time [EOL] [EOL] from marshmallow import ValidationError [EOL] [EOL] from git_repo_manager . client import GitRepoManagerClient [EOL] from platform_resources . user import User [EOL] import platform_resources . user as model [EOL] from util . k8s . k8s_info import find_namespace , NamespaceStatus , get_api_key , get_kubectl_host [EOL] from util . k8s . kubectl import UserState [EOL] [EOL] from util . logger import initialize_logger [EOL] from util . k8s import k8s_proxy_context_manager [EOL] from util . exceptions import K8sProxyCloseError , KubernetesError [EOL] from util . app_names import NAUTAAppNames [EOL] from logs_aggregator . k8s_es_client import K8sElasticSearchClient [EOL] from platform_resources . custom_object_meta_model import validate_kubernetes_name [EOL] from cli_text_consts import PlatformResourcesUsersTexts as Texts [EOL] from cli_text_consts import UserDeleteCmdTexts as TextsDel [EOL] from util . spinner import spinner [EOL] [EOL] logger = initialize_logger ( __name__ ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] SAMBA_USERNAME_BLACKLIST = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] [EOL] [EOL] def purge_user ( username ) : [EOL] [docstring] [EOL] try : [EOL] [comment] [EOL] with spinner ( text = TextsDel . DELETION_DELETING_USERS_EXPERIMENTS ) : [EOL] es_client = K8sElasticSearchClient ( host = f'{ get_kubectl_host ( with_port = True ) }' f' [string] ' , verify_certs = False , use_ssl = True , headers = { [string] : get_api_key ( ) } ) [EOL] es_client . delete_logs_for_namespace ( username ) [EOL] [EOL] [comment] [EOL] with k8s_proxy_context_manager . K8sProxy ( NAUTAAppNames . GIT_REPO_MANAGER ) as proxy , spinner ( text = TextsDel . DELETION_DELETING_USERS_REPOSITORY ) : [EOL] grm_client = GitRepoManagerClient ( host = [string] , port = proxy . tunnel_port ) [EOL] grm_client . delete_nauta_user ( username = username ) [EOL] except K8sProxyCloseError as exe : [EOL] logger . exception ( [string] ) [EOL] raise exe [EOL] except Exception as exe : [EOL] logger . exception ( f" [string] { username } [string] " ) [EOL] raise exe [EOL] [EOL] [EOL] def validate_user_name ( username ) : [EOL] [docstring] [EOL] [comment] [EOL] [comment] [EOL] if not username : [EOL] raise ValueError ( Texts . USERNAME_CANNOT_BE_EMPTY_ERROR_MSG ) [EOL] [EOL] if len ( username ) > [number] : [EOL] raise ValueError ( Texts . USERNAME_TOO_LONG_ERROR_MSG ) [EOL] [EOL] [comment] [EOL] try : [EOL] validate_kubernetes_name ( username ) [EOL] except ValidationError : [EOL] raise ValueError ( Texts . INCORRECT_K8S_USERNAME_ERROR_MSG ) [EOL] [EOL] if username in SAMBA_USERNAME_BLACKLIST : [EOL] raise ValueError ( Texts . USERNAME_IS_RESERVED_FOR_SYSTEM_USE ) [EOL] [EOL] [EOL] def is_user_created ( username , timeout = [number] ) : [EOL] [docstring] [EOL] user = User . get ( username ) [EOL] if user and model . UserStatus . CREATED == user . state : [EOL] return True [EOL] [EOL] for i in range ( timeout ) : [EOL] time . sleep ( [number] ) [EOL] user = User . get ( username ) [EOL] logger . debug ( f" [string] { user . state }" ) [EOL] if user and model . UserStatus . CREATED == user . state : [EOL] return True [EOL] [EOL] return False [EOL] [EOL] [EOL] def check_users_presence ( username ) : [EOL] [docstring] [EOL] namespace = find_namespace ( username ) [EOL] [EOL] if namespace != NamespaceStatus . NOT_EXISTS : [EOL] logger . debug ( [string] . format ( username ) ) [EOL] return UserState ( namespace . value ) [EOL] [EOL] try : [EOL] user_data = User . get ( username ) [EOL] [EOL] if user_data and user_data . name == username : [EOL] return UserState . ACTIVE [EOL] else : [EOL] return UserState . NOT_EXISTS [EOL] [EOL] except Exception as exe : [EOL] error_message = Texts . USER_PRESENCE_CHECK_ERROR_MSG [EOL] logger . error ( error_message ) [EOL] raise KubernetesError ( error_message ) from exe [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $util.k8s.kubectl.UserState$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , Type , Pattern [EOL] import applications [EOL] import builtins [EOL] import typing [EOL] import re [EOL] [EOL] from kubernetes import client [EOL] from marshmallow import Schema , fields , post_load , post_dump , validates , ValidationError [EOL] from cli_text_consts import PlatformResourcesCustomModelTexts as Texts [EOL] [EOL] [EOL] [comment] [EOL] KUBERNETES_NAME_RE = re . compile ( [string] ) [EOL] [EOL] [EOL] def validate_kubernetes_name ( name ) : [EOL] match = KUBERNETES_NAME_RE . fullmatch ( name ) [EOL] if not match : [EOL] raise ValidationError ( Texts . INVALID_K8S_NAME ) [EOL] [EOL] [EOL] class V1ObjectMetaSchema ( Schema ) : [EOL] annotations = fields . Dict ( required = False , allow_none = True , missing = None ) [EOL] cluster_name = fields . String ( required = False , allow_none = True , missing = None , dump_to = [string] , load_from = [string] ) [EOL] creation_timestamp = fields . DateTime ( required = False , allow_none = True , missing = None , dump_to = [string] , load_from = [string] ) [EOL] deletion_grace_period_seconds = fields . Int ( required = False , allow_none = True , missing = None , dump_to = [string] , load_from = [string] ) [EOL] deletion_timestamp = fields . DateTime ( required = False , allow_none = True , missing = None , dump_to = [string] , load_from = [string] ) [EOL] finalizers = fields . List ( fields . String , required = False , allow_none = True , missing = None ) [EOL] generate_name = fields . String ( required = False , allow_none = True , missing = None , dump_to = [string] , load_from = [string] ) [EOL] generation = fields . Int ( required = False , allow_none = True , missing = None ) [EOL] initializers = fields . Dict ( required = False , allow_none = True , missing = None ) [comment] [EOL] labels = fields . Dict ( required = False , allow_none = True , missing = None ) [EOL] name = fields . String ( required = True , allow_none = False ) [EOL] namespace = fields . String ( required = True , allow_none = False ) [EOL] owner_references = fields . List ( fields . Dict , required = False , allow_none = True , missing = None , dump_to = [string] , load_from = [string] ) [comment] [EOL] resource_version = fields . String ( required = False , allow_none = True , missing = None , dump_to = [string] , load_from = [string] ) [EOL] self_link = fields . String ( required = False , allow_none = True , missing = None , dump_to = [string] , load_from = [string] ) [EOL] uid = fields . String ( required = False , allow_none = True , missing = None ) [EOL] [EOL] @ post_load def make_V1ObjectMeta ( self , data ) : [EOL] return client . V1ObjectMeta ( ** data ) [EOL] [EOL] @ post_dump def remove_none_value_fields ( self , data ) : [EOL] result = data . copy ( ) [EOL] for key in filter ( lambda key : data [ key ] is None , data ) : [EOL] del result [ key ] [EOL] return result [EOL] [EOL] @ validates ( [string] ) def validate_name ( self , name ) : [EOL] validate_kubernetes_name ( name ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , List , Pattern [EOL] import enum [EOL] import builtins [EOL] import typing [EOL] from enum import Enum [EOL] from typing import Pattern , List [EOL] [EOL] [EOL] def filter_by_name_regex ( resource_object_dict , name_regex = None , spec_location = True ) : [EOL] if spec_location : [EOL] rod = resource_object_dict [ [string] ] [ [string] ] [EOL] else : [EOL] rod = resource_object_dict [ [string] ] [ [string] ] [EOL] [EOL] return name_regex . search ( rod ) if name_regex else True [EOL] [EOL] [EOL] def filter_by_state ( resource_object_dict , state = None ) : [EOL] return resource_object_dict [ [string] ] [ [string] ] == state . value if state else True [EOL] [EOL] [EOL] def filter_by_excl_state ( resource_object_dict , state = None ) : [EOL] return resource_object_dict [ [string] ] [ [string] ] != state . value if state else True [EOL] [EOL] [EOL] def filter_by_experiment_name ( resource_object_dict , exp_name = None ) : [EOL] return resource_object_dict [ [string] ] [ [string] ] in exp_name if exp_name else True [EOL] [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import List , Dict , Type , Any , Optional , Pattern [EOL] import builtins [EOL] import functools [EOL] import platform_resources [EOL] import typing [EOL] import kubernetes [EOL] import applications [EOL] import re [EOL] import sre_constants [EOL] [EOL] from collections import namedtuple [EOL] from enum import Enum [EOL] from functools import partial [EOL] from typing import List , Dict [EOL] [EOL] from kubernetes import client [EOL] from kubernetes . client import CustomObjectsApi [EOL] from marshmallow import Schema , fields , post_load , validates [EOL] from marshmallow_enum import EnumField [EOL] [EOL] from cli_text_consts import PlatformResourcesExperimentsTexts as Texts [EOL] from platform_resources . custom_object_meta_model import validate_kubernetes_name [EOL] from platform_resources . platform_resource import PlatformResource , KubernetesObjectSchema , KubernetesObject , PlatformResourceApiClient [EOL] from platform_resources . resource_filters import filter_by_name_regex , filter_by_state [EOL] from platform_resources . run import Run , filter_by_run_kinds [EOL] from util . exceptions import InvalidRegularExpressionError [EOL] from util . logger import initialize_logger [EOL] from util . system import format_timestamp_for_cli [EOL] [EOL] logger = initialize_logger ( __name__ ) [EOL] [EOL] [EOL] class ExperimentStatus ( Enum ) : [EOL] CREATING = [string] [EOL] SUBMITTED = [string] [EOL] FAILED = [string] [EOL] CANCELLING = [string] [EOL] CANCELLED = [string] [EOL] [EOL] [EOL] class ExperimentSchema ( Schema ) : [EOL] name = fields . String ( required = True , allow_none = False ) [EOL] parameters_spec = fields . List ( fields . String , required = False , missing = None , allow_none = True , dump_to = [string] , load_from = [string] ) [EOL] state = EnumField ( ExperimentStatus , required = True , allow_none = False , by_value = True ) [EOL] template_name = fields . String ( required = True , allow_none = False , dump_to = [string] , load_from = [string] ) [EOL] template_version = fields . String ( required = False , allow_none = False , dump_to = [string] , load_from = [string] ) [EOL] template_namespace = fields . String ( required = True , allow_none = False , dump_to = [string] , load_from = [string] ) [EOL] [EOL] @ post_load def make_experiment ( self , data ) : [EOL] return Experiment ( ** data ) [EOL] [EOL] @ validates ( [string] ) def validate_name ( self , name ) : [EOL] validate_kubernetes_name ( name ) [EOL] [EOL] [EOL] class ExperimentKubernetesSchema ( KubernetesObjectSchema ) : [EOL] spec = fields . Nested ( ExperimentSchema ( ) , required = True , allow_none = False ) [EOL] [EOL] [EOL] class Experiment ( PlatformResource ) : [EOL] api_group_name = [string] [EOL] crd_plural_name = [string] [EOL] crd_version = [string] [EOL] [EOL] ExperimentCliModel = namedtuple ( [string] , [ [string] , [string] , [string] , [string] , [string] , [string] , [string] ] ) [EOL] [EOL] def __init__ ( self , name , template_name , template_namespace , parameters_spec = None , state = ExperimentStatus . CREATING , creation_timestamp = None , namespace = None , metadata = None , template_version = None ) : [EOL] super ( ) . __init__ ( ) [EOL] self . name = name [EOL] self . parameters_spec = parameters_spec [EOL] self . state = state [EOL] self . template_name = template_name [EOL] self . template_namespace = template_namespace [EOL] self . creation_timestamp = creation_timestamp [EOL] self . namespace = namespace [EOL] self . metadata = metadata [EOL] self . template_version = template_version [EOL] [EOL] @ classmethod def from_k8s_response_dict ( cls , object_dict ) : [EOL] return cls ( name = object_dict [ [string] ] [ [string] ] , parameters_spec = object_dict [ [string] ] [ [string] ] , creation_timestamp = object_dict [ [string] ] [ [string] ] , namespace = object_dict [ [string] ] [ [string] ] , state = ExperimentStatus [ object_dict [ [string] ] [ [string] ] ] , template_name = object_dict [ [string] ] [ [string] ] , template_namespace = object_dict [ [string] ] [ [string] ] , metadata = object_dict [ [string] ] , template_version = object_dict . get ( [string] ) . get ( [string] ) if object_dict . get ( [string] ) [EOL] else None ) [EOL] [EOL] @ property def cli_representation ( self ) : [EOL] return self . ExperimentCliModel ( name = self . name , parameters_spec = [string] . join ( self . parameters_spec ) , creation_timestamp = format_timestamp_for_cli ( self . creation_timestamp ) , submitter = self . namespace , status = self . state . value , template_name = self . template_name , template_version = self . template_version ) [EOL] [EOL] [EOL] def get_runs ( self ) : [EOL] return Run . list ( namespace = self . metadata [ [string] ] , exp_name_filter = [ self . name ] ) [EOL] [EOL] def create ( self , namespace , labels = None , annotations = None ) : [EOL] [comment] [EOL] labels = { key : value for key , value in labels . items ( ) if value } if labels else None [EOL] [EOL] exp_kubernetes = KubernetesObject ( self , client . V1ObjectMeta ( name = self . name , namespace = namespace , labels = labels ) , kind = [string] , apiVersion = f"{ self . api_group_name } [string] { self . crd_version }" ) [EOL] schema = ExperimentKubernetesSchema ( ) [EOL] body , err = schema . dump ( exp_kubernetes ) [EOL] if err : [EOL] raise RuntimeError ( Texts . K8S_DUMP_PREPARATION_ERROR_MSG . format ( err = err ) ) [EOL] self . body = body [EOL] [EOL] response = super ( ) . create ( namespace = namespace ) [EOL] created_exp , err = schema . load ( response ) [EOL] if err : [EOL] raise RuntimeError ( Texts . K8S_RESPONSE_LOAD_ERROR_MSG . format ( err = err ) ) [EOL] return created_exp [EOL] [EOL] def update ( self ) : [EOL] exp_kubernetes = KubernetesObject ( self , client . V1ObjectMeta ( name = self . name , namespace = self . namespace ) , kind = [string] , apiVersion = f"{ self . api_group_name } [string] { self . crd_version }" ) [EOL] schema = ExperimentKubernetesSchema ( ) [EOL] body , err = schema . dump ( exp_kubernetes ) [EOL] if err : [EOL] raise RuntimeError ( Texts . K8S_DUMP_PREPARATION_ERROR_MSG . format ( err = err ) ) [EOL] self . body = body [EOL] [EOL] response = super ( ) . update ( ) [EOL] updated_exp , err = schema . load ( response ) [EOL] if err : [EOL] raise RuntimeError ( Texts . K8S_RESPONSE_LOAD_ERROR_MSG . format ( err = err ) ) [EOL] return updated_exp [EOL] [EOL] @ classmethod def list ( cls , namespace = None , custom_objects_api = None , ** kwargs ) : [EOL] [docstring] [EOL] logger . debug ( [string] ) [EOL] state = kwargs . pop ( [string] , None ) [EOL] run_kinds_filter = kwargs . pop ( [string] , None ) [EOL] name_filter = kwargs . pop ( [string] , None ) [EOL] label_selector = kwargs . pop ( [string] , None ) [EOL] [EOL] raw_experiments = cls . list_raw_experiments ( namespace = namespace , label_selector = label_selector ) [EOL] try : [EOL] name_regex = re . compile ( name_filter ) if name_filter else None [EOL] except sre_constants . error as e : [EOL] error_msg = Texts . REGEX_COMPILATION_FAIL_MSG . format ( name_filter = name_filter ) [EOL] logger . exception ( error_msg ) [EOL] raise InvalidRegularExpressionError ( error_msg ) from e [EOL] [EOL] experiment_filters = [ partial ( filter_by_name_regex , name_regex = name_regex ) , partial ( filter_by_state , state = state ) , partial ( filter_by_run_kinds , run_kinds = run_kinds_filter ) ] [EOL] [EOL] experiments = [ Experiment . from_k8s_response_dict ( experiment_dict ) for experiment_dict in raw_experiments [ [string] ] if all ( f ( experiment_dict ) for f in experiment_filters ) ] [EOL] [EOL] return experiments [EOL] [EOL] @ classmethod def list_raw_experiments ( cls , namespace = None , label_selector = [string] , custom_objects_api = None ) : [EOL] [docstring] [EOL] k8s_custom_object_api = custom_objects_api if custom_objects_api else PlatformResourceApiClient . get ( ) [EOL] if namespace : [EOL] raw_experiments = k8s_custom_object_api . list_namespaced_custom_object ( group = Experiment . api_group_name , namespace = namespace , plural = Experiment . crd_plural_name , version = Experiment . crd_version , label_selector = label_selector ) [EOL] else : [EOL] raw_experiments = k8s_custom_object_api . list_cluster_custom_object ( group = Experiment . api_group_name , plural = Experiment . crd_plural_name , version = Experiment . crd_version , label_selector = label_selector ) [EOL] return raw_experiments [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[platform_resources.run.Run]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $typing.Dict[builtins.str,builtins.str]$ 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $applications.cli.platform_resources.experiment.ExperimentKubernetesSchema$ 0 0 0 0 0 0 0 0 0 $applications.cli.platform_resources.experiment.ExperimentKubernetesSchema$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 $applications.cli.platform_resources.experiment.ExperimentKubernetesSchema$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $applications.cli.platform_resources.experiment.ExperimentKubernetesSchema$ 0 0 0 0 0 0 0 0 0 $applications.cli.platform_resources.experiment.ExperimentKubernetesSchema$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $applications.cli.platform_resources.experiment.ExperimentKubernetesSchema$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $kubernetes.client.CustomObjectsApi$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 $typing.Optional[typing.Pattern[typing.Any]]$ 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.List[functools.partial[typing.Any]]$ 0 0 0 0 0 0 $typing.Optional[typing.Pattern[typing.Any]]$ 0 $typing.Optional[typing.Pattern[typing.Any]]$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[functools.partial[typing.Any]]$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 $builtins.dict$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $kubernetes.client.CustomObjectsApi$ 0 0 0 0 0 0 0 0 0 $kubernetes.client.CustomObjectsApi$ 0 $kubernetes.client.CustomObjectsApi$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $typing.Any$ 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , Union , List , Dict [EOL] import typing [EOL] import kubernetes [EOL] import pytest [EOL] [EOL] from kubernetes . client import CustomObjectsApi [EOL] from kubernetes . client . rest import ApiException [EOL] [EOL] from platform_resources . platform_resource import KubernetesObject [EOL] from platform_resources . run import Run , RunStatus [EOL] from util . exceptions import InvalidRegularExpressionError [EOL] [EOL] TEST_RUNS = [ Run ( name = [string] , parameters = [ [string] , [string] , [string] ] , state = RunStatus . QUEUED , metrics = { [string] : [number] } , experiment_name = [string] , pod_count = [number] , pod_selector = { [string] : { [string] : [string] , [string] : [string] , [string] : [string] } } , namespace = [string] , creation_timestamp = [string] , template_name = [string] , metadata = { [string] : [string] , [string] : [string] , [string] : [number] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] [string] , [string] : [string] } , start_timestamp = None , end_timestamp = None ) , Run ( name = [string] , parameters = [ [string] , [string] , [string] ] , state = RunStatus . COMPLETE , metrics = { [string] : [number] } , experiment_name = [string] , pod_count = [number] , pod_selector = { [string] : { [string] : [string] , [string] : [string] , [string] : [string] } } , namespace = [string] , creation_timestamp = [string] , template_name = [string] , metadata = { [string] : [string] , [string] : [string] , [string] : [number] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] [string] , [string] : [string] } , start_timestamp = [string] , end_timestamp = [string] ) ] [EOL] [EOL] [EOL] @ pytest . fixture ( ) def mock_k8s_api_client ( mocker ) : [EOL] mocker . patch ( [string] ) [EOL] mocker . patch ( [string] ) [EOL] custom_objects_api_mocked_class = mocker . patch ( [string] ) [EOL] return custom_objects_api_mocked_class . return_value [EOL] [EOL] [EOL] def test_list_runs ( mock_k8s_api_client ) : [EOL] mock_k8s_api_client . list_cluster_custom_object . return_value = LIST_RUNS_RESPONSE_RAW [EOL] runs = Run . list ( ) [EOL] assert runs == TEST_RUNS [EOL] [EOL] [EOL] def test_list_runs_from_namespace ( mock_k8s_api_client ) : [EOL] raw_runs_single_namespace = dict ( LIST_RUNS_RESPONSE_RAW ) [EOL] raw_runs_single_namespace [ [string] ] = [ raw_runs_single_namespace [ [string] ] [ [number] ] ] [EOL] mock_k8s_api_client . list_namespaced_custom_object . return_value = raw_runs_single_namespace [EOL] [EOL] runs = Run . list ( namespace = [string] ) [EOL] [EOL] assert [ TEST_RUNS [ [number] ] ] == runs [EOL] [EOL] [EOL] def test_list_runs_filter_status ( mock_k8s_api_client ) : [EOL] mock_k8s_api_client . list_cluster_custom_object . return_value = LIST_RUNS_RESPONSE_RAW [EOL] runs = Run . list ( state_list = [ RunStatus . QUEUED ] ) [EOL] assert [ TEST_RUNS [ [number] ] ] == runs [EOL] [EOL] [EOL] def test_list_runs_name_filter ( mock_k8s_api_client ) : [EOL] mock_k8s_api_client . list_cluster_custom_object . return_value = LIST_RUNS_RESPONSE_RAW [EOL] runs = Run . list ( name_filter = TEST_RUNS [ [number] ] . name ) [EOL] assert [ TEST_RUNS [ [number] ] ] == runs [EOL] [EOL] [EOL] def test_list_runs_invalid_name_filter ( mock_k8s_api_client ) : [EOL] mock_k8s_api_client . list_cluster_custom_object . return_value = LIST_RUNS_RESPONSE_RAW [EOL] with pytest . raises ( InvalidRegularExpressionError ) : [EOL] Run . list ( name_filter = [string] ) [EOL] [EOL] def test_get_run_from_namespace ( mock_k8s_api_client ) : [EOL] mock_k8s_api_client . get_namespaced_custom_object . return_value = GET_RUN_RESPONSE_RAW [EOL] run = Run . get ( name = RUN_NAME , namespace = NAMESPACE ) [EOL] assert run is not None and type ( run ) is Run [EOL] [EOL] [EOL] def test_get_run_not_found ( mock_k8s_api_client ) : [EOL] mock_k8s_api_client . get_namespaced_custom_object . side_effect = ApiException ( status = [number] ) [EOL] run = Run . get ( name = RUN_NAME , namespace = NAMESPACE ) [EOL] assert run is None [EOL] [EOL] [EOL] def test_get_run_failure ( mock_k8s_api_client ) : [EOL] mock_k8s_api_client . get_namespaced_custom_object . side_effect = ApiException ( status = [number] ) [EOL] with pytest . raises ( ApiException ) : [EOL] Run . get ( name = RUN_NAME , namespace = NAMESPACE ) [EOL] [EOL] LIST_RUNS_RESPONSE_RAW = { [string] : [string] , [string] : [ { [string] : [string] , [string] : [string] , [string] : { [string] : [string] , [string] : [string] , [string] : [number] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] [string] , [string] : [string] } , [string] : { [string] : [string] , [string] : { [string] : [number] } , [string] : [string] , [string] : [ [string] , [string] , [string] ] , [string] : [number] , [string] : { [string] : { [string] : [string] , [string] : [string] , [string] : [string] } } , [string] : [string] , [string] : None , [string] : None } } , { [string] : [string] , [string] : [string] , [string] : { [string] : [string] , [string] : [string] , [string] : [number] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] [string] , [string] : [string] } , [string] : { [string] : [string] , [string] : { [string] : [number] } , [string] : [string] , [string] : [ [string] , [string] , [string] ] , [string] : [number] , [string] : { [string] : { [string] : [string] , [string] : [string] , [string] : [string] } } , [string] : [string] , [string] : [string] , [string] : [string] } } ] , [string] : [string] , [string] : { [string] : [string] , [string] : [string] , [string] : [string] } } [EOL] [EOL] NAMESPACE = [string] [EOL] RUN_NAME = [string] [EOL] GET_RUN_RESPONSE_RAW = { [string] : [string] , [string] : [string] , [string] : { [string] : [string] , [string] : [string] , [string] : [number] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] [string] , [string] : [string] } , [string] : { [string] : [string] , [string] : { [string] : [number] } , [string] : [string] , [string] : [ [string] , [string] , [string] ] , [string] : [number] , [string] : { [string] : { [string] : [string] , [string] : [string] , [string] : [string] } } , [string] : [string] , [string] : [string] , [string] : [string] } } [EOL] [EOL] @ pytest . fixture ( ) def mock_k8s_run_api_client ( mocker ) : [EOL] for run in TEST_RUNS : [EOL] mocker . patch . object ( run , [string] ) [EOL] mocker . patch ( [string] ) [EOL] mocker . patch ( [string] ) [EOL] custom_objects_api_mocked_class = mocker . patch ( [string] ) [EOL] return custom_objects_api_mocked_class . return_value [EOL] [EOL] def test_update_run_success ( mock_k8s_run_api_client ) : [EOL] TEST_RUNS [ [number] ] . k8s_custom_object_api . patch_namespaced_custom_object . return_value = LIST_RUNS_RESPONSE_RAW [ [string] ] [ [number] ] [EOL] [EOL] TEST_RUNS [ [number] ] . update ( ) [EOL] [EOL] assert TEST_RUNS [ [number] ] . k8s_custom_object_api . patch_namespaced_custom_object . call_count == [number] [EOL] [EOL] [EOL] def test_update_run_failure ( mock_k8s_run_api_client ) : [EOL] TEST_RUNS [ [number] ] . k8s_custom_object_api . patch_namespaced_custom_object . side_effect = ApiException ( ) [EOL] [EOL] with pytest . raises ( ApiException ) : [EOL] TEST_RUNS [ [number] ] . update ( ) [EOL] [EOL] [EOL] def test_add_run ( mock_k8s_run_api_client ) : [EOL] mock_k8s_run_api_client . create_namespaced_custom_object . return_value = GET_RUN_RESPONSE_RAW [EOL] run = Run ( name = RUN_NAME , experiment_name = [string] ) [EOL] added_run = run . create ( namespace = NAMESPACE ) [EOL] assert added_run is not None and type ( added_run ) is KubernetesObject [EOL] [EOL] [EOL] def test_add_run_failure ( mock_k8s_run_api_client ) : [EOL] mock_k8s_run_api_client . create_namespaced_custom_object . side_effect = ApiException ( status = [number] ) [EOL] run = Run ( name = RUN_NAME , experiment_name = [string] ) [EOL] with pytest . raises ( ApiException ) : [EOL] run . create ( namespace = NAMESPACE ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $kubernetes.client.CustomObjectsApi$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $kubernetes.client.CustomObjectsApi$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import builtins [EOL] from typing import Any , Union , List , Dict [EOL] import typing [EOL] import kubernetes [EOL] import pytest [EOL] [EOL] from kubernetes . client import CustomObjectsApi [EOL] [EOL] from platform_resources . user import User , UserStatus [EOL] from platform_resources . user_utils import validate_user_name , is_user_created [EOL] from cli_text_consts import PlatformResourcesUsersTexts as Texts [EOL] [EOL] [EOL] TEST_USERS = [ User ( name = [string] , uid = [number] , state = UserStatus . DEFINED , creation_timestamp = [string] , experiment_runs = [ ] ) , User ( name = [string] , uid = [number] , state = UserStatus . DEFINED , creation_timestamp = [string] , experiment_runs = [ ] ) ] [EOL] [EOL] USER_CREATED = User ( name = [string] , uid = [number] , state = UserStatus . CREATED , creation_timestamp = [string] , experiment_runs = [ ] ) [EOL] [EOL] @ pytest . fixture ( ) def mock_k8s_api_client ( mocker ) : [EOL] mocker . patch ( [string] ) [EOL] mocker . patch ( [string] ) [EOL] custom_objects_api_mocked_class = mocker . patch ( [string] ) [EOL] return custom_objects_api_mocked_class . return_value [EOL] [EOL] [EOL] def test_list_users ( mock_k8s_api_client , mocker ) : [EOL] mocker . patch ( [string] ) [EOL] mock_k8s_api_client . list_cluster_custom_object . return_value = LIST_USERS_RESPONSE_RAW [EOL] users = User . list ( ) [EOL] assert users == TEST_USERS [EOL] [EOL] [EOL] LIST_USERS_RESPONSE_RAW = { [string] : [string] , [string] : [ { [string] : [string] , [string] : [string] , [string] : { [string] : { [string] : [string] [string] [string] [string] } , [string] : [string] , [string] : [string] , [string] : [number] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] } , [string] : { [string] : [string] , [string] : [string] , [string] : [number] } } , { [string] : [string] , [string] : [string] , [string] : { [string] : { [string] : [string] [string] [string] [string] } , [string] : [string] , [string] : [string] , [string] : [number] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] } , [string] : { [string] : [string] , [string] : [string] , [string] : [number] } } ] , [string] : [string] , [string] : { [string] : [string] , [string] : [string] , [string] : [string] } } [EOL] [EOL] [EOL] def test_get_user_data ( mock_k8s_api_client , mocker ) : [EOL] mock_k8s_api_client . get_cluster_custom_object . return_value = LIST_USERS_RESPONSE_RAW [ [string] ] [ [number] ] [EOL] [EOL] user = User . get ( [string] ) [EOL] assert user == TEST_USERS [ [number] ] [EOL] [EOL] [EOL] def test_validate_user_name_too_short ( ) : [EOL] username = [string] [EOL] with pytest . raises ( ValueError ) as exe : [EOL] validate_user_name ( username ) [EOL] assert str ( exe . value ) == Texts . USERNAME_CANNOT_BE_EMPTY_ERROR_MSG [EOL] [EOL] [EOL] def test_validate_user_name_too_long ( ) : [EOL] username = [string] * [number] [EOL] with pytest . raises ( ValueError ) as exe : [EOL] validate_user_name ( username ) [EOL] assert str ( exe . value ) == Texts . USERNAME_TOO_LONG_ERROR_MSG [EOL] [EOL] [EOL] def test_validate_user_name_incorrect_k8s_string ( ) : [EOL] username = [string] [EOL] with pytest . raises ( ValueError ) as exe : [EOL] validate_user_name ( username ) [EOL] assert str ( exe . value ) == Texts . INCORRECT_K8S_USERNAME_ERROR_MSG [EOL] [EOL] [EOL] def test_is_user_created_success ( mocker ) : [EOL] gud_mock = mocker . patch ( [string] , return_value = USER_CREATED ) [EOL] result = is_user_created ( [string] , timeout = [number] ) [EOL] [EOL] assert result [EOL] assert gud_mock . call_count == [number] [EOL] [EOL] [EOL] def test_is_user_created_failure ( mocker ) : [EOL] gud_mock = mocker . patch ( [string] , return_value = TEST_USERS [ [number] ] ) [EOL] result = is_user_created ( [string] , timeout = [number] ) [EOL] [EOL] assert not result [EOL] assert gud_mock . call_count == [number] [EOL] [EOL] [EOL] def test_is_user_created_success_with_wait ( mocker ) : [EOL] gud_mock = mocker . patch ( [string] , side_effect = [ TEST_USERS [ [number] ] , USER_CREATED ] ) [EOL] result = is_user_created ( [string] , timeout = [number] ) [EOL] [EOL] assert result [EOL] assert gud_mock . call_count == [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $kubernetes.client.CustomObjectsApi$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , List [EOL] import builtins [EOL] import typing [EOL] import unittest [EOL] import pytest [EOL] from unittest . mock import MagicMock , mock_open , patch [EOL] from typing import List [EOL] [EOL] from platform_resources . workflow import ArgoWorkflow [EOL] [EOL] workflow_w_two_param = ArgoWorkflow ( ) [EOL] workflow_w_two_param . body = { [string] : { [string] : { [string] : [ { [string] : [string] , [string] : [string] } , { [string] : [string] , [string] : [string] } ] } } } [EOL] [EOL] workflow_wo_value = ArgoWorkflow ( ) [EOL] workflow_wo_value . body = { [string] : { [string] : { [string] : [ { [string] : [string] , [string] : [string] } , { [string] : [string] } ] } } } [EOL] [EOL] process_template = [string] [EOL] [EOL] workflow_template = [string] [EOL] [EOL] workflow_steps = [string] [EOL] [EOL] [EOL] def test_parameters ( ) : [EOL] assert workflow_w_two_param . parameters == { [string] : [string] , [string] : [string] } [EOL] [EOL] [EOL] def test_set_parameters ( ) : [EOL] workflow_w_two_param . parameters = { [string] : [string] } [EOL] [EOL] assert workflow_w_two_param . parameters == { [string] : [string] , [string] : [string] } [EOL] [EOL] [EOL] def test_set_parameters_error ( ) : [EOL] with pytest . raises ( KeyError ) : [EOL] workflow_wo_value . parameters = { [string] : [string] } [EOL] [EOL] [EOL] def test_wait_for_completion ( mocker ) : [EOL] workflow_status_mock = MagicMock ( ) [EOL] workflow_status_mock . phase = [string] [EOL] get_workflow_mock = mocker . patch ( [string] , return_value = workflow_status_mock ) [EOL] [EOL] test_workflow = ArgoWorkflow ( ) [EOL] test_workflow . wait_for_completion ( ) [EOL] [EOL] assert get_workflow_mock . call_count == [number] [EOL] [EOL] [EOL] def test_wait_for_completion_failure ( mocker ) : [EOL] workflow_status_mock = MagicMock ( ) [EOL] workflow_status_mock . phase = [string] [EOL] get_workflow_mock = mocker . patch ( [string] , return_value = workflow_status_mock ) [EOL] [EOL] test_workflow = ArgoWorkflow ( ) [EOL] with pytest . raises ( RuntimeError ) : [EOL] test_workflow . wait_for_completion ( ) [EOL] [EOL] assert get_workflow_mock . call_count == [number] [EOL] [EOL] [EOL] def check_parameters ( parameters ) : [EOL] cra = None [EOL] smd = None [EOL] adp = None [EOL] for parameter in parameters : [EOL] name = parameter [ [string] ] [EOL] if name == [string] : [EOL] cra = True [EOL] elif name == [string] : [EOL] smd = True [EOL] elif name == [string] : [EOL] adp = True [EOL] [EOL] assert cra [EOL] assert smd [EOL] assert adp [EOL] [EOL] [EOL] def test_add_proces_add_steps ( mocker ) : [EOL] mocker . patch ( [string] ) [EOL] with patch ( [string] , mock_open ( read_data = workflow_template . format ( [string] , [string] ) ) ) : [EOL] main_workflow = ArgoWorkflow . from_yaml ( [string] ) [EOL] with patch ( [string] , mock_open ( read_data = process_template . format ( [string] ) ) ) : [EOL] process_workflow = ArgoWorkflow . from_yaml ( [string] ) [EOL] [EOL] main_workflow . add_process ( process_workflow ) [EOL] [EOL] spec = main_workflow . body [ [string] ] [EOL] assert spec [ [string] ] == [string] [EOL] [EOL] list_of_templates = spec [ [string] ] [EOL] [EOL] process_template_exists = False [EOL] flow_template_exists = False [EOL] [EOL] for template in list_of_templates : [EOL] if template [ [string] ] == [string] : [EOL] flow_template_exists = True [EOL] assert template . get ( [string] ) [EOL] assert len ( template . get ( [string] ) ) == [number] [EOL] [EOL] swt = None [EOL] pwt = None [EOL] [EOL] for step in template . get ( [string] ) : [EOL] step_name = step [ [number] ] [ [string] ] [EOL] if step_name == [string] : [EOL] swt = step [EOL] elif step_name == [string] : [EOL] pwt = step [EOL] [EOL] parameters = step [ [number] ] . get ( [string] , [ ] ) . get ( [string] , [ ] ) [EOL] assert parameters [EOL] check_parameters ( parameters ) [EOL] [EOL] assert swt [EOL] assert pwt [EOL] [EOL] elif template [ [string] ] == [string] : [EOL] process_template_exists = True [EOL] parameters = template . get ( [string] , [ ] ) . get ( [string] ) [EOL] assert parameters [EOL] check_parameters ( parameters ) [EOL] [EOL] assert process_template_exists [EOL] assert flow_template_exists [EOL] [EOL] [EOL] def test_add_process_with_steps ( mocker ) : [EOL] mocker . patch ( [string] ) [EOL] with patch ( [string] , mock_open ( read_data = workflow_template . format ( [string] , workflow_steps ) ) ) : [EOL] main_workflow = ArgoWorkflow . from_yaml ( [string] ) [EOL] with patch ( [string] , mock_open ( read_data = process_template . format ( [string] ) ) ) : [EOL] process_workflow = ArgoWorkflow . from_yaml ( [string] ) [EOL] [EOL] main_workflow . add_process ( process_workflow ) [EOL] [EOL] spec = main_workflow . body [ [string] ] [EOL] assert spec [ [string] ] == [string] [EOL] [EOL] list_of_templates = spec [ [string] ] [EOL] [EOL] process_template_exists = False [EOL] flow_template_exists = False [EOL] step_template_exists = False [EOL] [EOL] for template in list_of_templates : [EOL] if template [ [string] ] == [string] : [EOL] step_template_exists = True [EOL] assert template . get ( [string] ) [EOL] assert len ( template . get ( [string] ) ) == [number] [EOL] [EOL] swt = None [EOL] pwt = None [EOL] [EOL] for step in template . get ( [string] ) : [EOL] step_name = step [ [number] ] [ [string] ] [EOL] if step_name == [string] : [EOL] swt = step [EOL] elif step_name == [string] : [EOL] pwt = step [EOL] [EOL] parameters = step [ [number] ] . get ( [string] , [ ] ) . get ( [string] , [ ] ) [EOL] assert parameters [EOL] check_parameters ( parameters ) [EOL] [EOL] assert swt [EOL] assert pwt [EOL] [EOL] elif template [ [string] ] == [string] : [EOL] flow_template_exists = True [EOL] [EOL] elif template [ [string] ] == [string] : [EOL] process_template_exists = True [EOL] parameters = template . get ( [string] , [ ] ) . get ( [string] ) [EOL] assert parameters [EOL] check_parameters ( parameters ) [EOL] [EOL] assert process_template_exists [EOL] assert flow_template_exists [EOL] assert step_template_exists [EOL] [EOL] [EOL] def test_add_process_with_steps_in_process ( mocker ) : [EOL] mocker . patch ( [string] ) [EOL] with patch ( [string] , mock_open ( read_data = workflow_template . format ( [string] , [string] ) ) ) : [EOL] main_workflow = ArgoWorkflow . from_yaml ( [string] ) [EOL] with patch ( [string] , mock_open ( read_data = process_template . format ( workflow_steps ) ) ) : [EOL] process_workflow = ArgoWorkflow . from_yaml ( [string] ) [EOL] [EOL] main_workflow . add_process ( process_workflow ) [EOL] [EOL] spec = main_workflow . body [ [string] ] [EOL] list_of_templates = spec [ [string] ] [EOL] [EOL] flow_template_exists = False [EOL] [EOL] for template in list_of_templates : [EOL] if template [ [string] ] == [string] : [EOL] flow_template_exists = True [EOL] assert template . get ( [string] ) [EOL] assert len ( template . get ( [string] ) ) == [number] [EOL] [EOL] swt = None [EOL] pwt = None [EOL] [EOL] for step in template . get ( [string] ) : [EOL] step_name = step [ [number] ] [ [string] ] [EOL] if step_name == [string] : [EOL] swt = step [EOL] elif step_name == [string] : [EOL] pwt = step [EOL] [EOL] parameters = step [ [number] ] . get ( [string] , [ ] ) . get ( [string] , [ ] ) [EOL] assert parameters [EOL] check_parameters ( parameters ) [EOL] [EOL] assert swt [EOL] assert pwt [EOL] [EOL] assert flow_template_exists [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , Union , List , Dict [EOL] import typing [EOL] import kubernetes [EOL] import pytest [EOL] [EOL] from kubernetes . client import CustomObjectsApi [EOL] [EOL] from platform_resources . experiment import ExperimentStatus , Experiment [EOL] from platform_resources . experiment_utils import generate_exp_name_and_labels [EOL] from util . exceptions import SubmitExperimentError , InvalidRegularExpressionError [EOL] [EOL] EXPERIMENT_NAME = [string] [EOL] NAMESPACE = [string] [EOL] TEMPLATE_NAME = [string] [EOL] TEMPLATE_NAMESPACE = [string] [EOL] TEMPLATE_VERSION = [string] [EOL] [EOL] TEST_EXPERIMENTS = [ Experiment ( name = [string] , parameters_spec = [ [string] , [string] ] , creation_timestamp = [string] , namespace = [string] , state = ExperimentStatus . CREATING , template_name = [string] , template_version = [string] , template_namespace = [string] , metadata = { [string] : { [string] : [string] [string] [string] [string] [string] [string] [string] [string] [string] [string] } , [string] : [string] , [string] : [string] , [string] : { [string] : [string] , [string] : [string] } , [string] : [number] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] } ) , Experiment ( name = [string] , parameters_spec = [ [string] , [string] ] , creation_timestamp = [string] , namespace = [string] , state = ExperimentStatus . SUBMITTED , template_name = [string] , template_version = [string] , template_namespace = [string] , metadata = { [string] : { [string] : [string] [string] [string] [string] [string] [string] [string] } , [string] : [string] , [string] : [string] , [string] : { [string] : [string] , [string] : [string] } , [string] : [number] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] } ) ] [EOL] [EOL] @ pytest . fixture ( ) def mock_platform_resources_api_client ( mocker ) : [EOL] mocker . patch ( [string] ) [EOL] mocker . patch ( [string] ) [EOL] custom_objects_api_mocked_class = mocker . patch ( [string] ) [EOL] return custom_objects_api_mocked_class . return_value [EOL] [EOL] [EOL] def test_create_experiment ( mock_platform_resources_api_client ) : [EOL] mock_platform_resources_api_client . create_namespaced_custom_object . return_value = ADD_EXPERIMENT_RESPONSE_RAW [EOL] exp = Experiment ( name = EXPERIMENT_NAME , template_name = TEMPLATE_NAME , template_namespace = TEMPLATE_NAMESPACE , template_version = TEMPLATE_VERSION ) [EOL] result = exp . create ( namespace = NAMESPACE ) [EOL] [EOL] assert result [EOL] assert result . spec . name == EXPERIMENT_NAME [EOL] assert result . spec . template_name == TEMPLATE_NAME [EOL] assert result . spec . template_namespace == TEMPLATE_NAMESPACE [EOL] assert result . spec . template_version == TEMPLATE_VERSION [EOL] assert result . spec . state == ExperimentStatus . CREATING [EOL] assert result . metadata . name == EXPERIMENT_NAME [EOL] assert result . metadata . namespace == NAMESPACE [EOL] [EOL] def test_list_experiments ( mock_platform_resources_api_client ) : [EOL] mock_platform_resources_api_client . list_cluster_custom_object . return_value = LIST_EXPERIMENTS_RESPONSE_RAW [EOL] experiments = Experiment . list ( ) [EOL] assert TEST_EXPERIMENTS == experiments [EOL] [EOL] [EOL] def test_list_experiments_from_namespace ( mock_platform_resources_api_client ) : [EOL] raw_experiments_single_namespace = dict ( LIST_EXPERIMENTS_RESPONSE_RAW ) [EOL] raw_experiments_single_namespace [ [string] ] = [ raw_experiments_single_namespace [ [string] ] [ [number] ] ] [EOL] mock_platform_resources_api_client . list_namespaced_custom_object . return_value = raw_experiments_single_namespace [EOL] [EOL] experiments = Experiment . list ( namespace = [string] ) [EOL] [EOL] assert [ TEST_EXPERIMENTS [ [number] ] ] == experiments [EOL] [EOL] [EOL] def test_list_experiments_filter_status ( mock_platform_resources_api_client ) : [EOL] mock_platform_resources_api_client . list_cluster_custom_object . return_value = LIST_EXPERIMENTS_RESPONSE_RAW [EOL] experiments = Experiment . list ( state = ExperimentStatus . CREATING ) [EOL] assert [ TEST_EXPERIMENTS [ [number] ] ] == experiments [EOL] [EOL] [EOL] def test_list_experiments_name_filter ( mock_platform_resources_api_client ) : [EOL] mock_platform_resources_api_client . list_cluster_custom_object . return_value = LIST_EXPERIMENTS_RESPONSE_RAW [EOL] experiments = Experiment . list ( name_filter = [string] ) [EOL] assert [ TEST_EXPERIMENTS [ [number] ] ] == experiments [EOL] [EOL] [EOL] def test_list_experiments_invalid_name_filter ( mock_platform_resources_api_client ) : [EOL] mock_platform_resources_api_client . list_cluster_custom_object . return_value = LIST_EXPERIMENTS_RESPONSE_RAW [EOL] with pytest . raises ( InvalidRegularExpressionError ) : [EOL] Experiment . list ( name_filter = [string] ) [EOL] [EOL] ADD_EXPERIMENT_RESPONSE_RAW = { [string] : [string] , [string] : [string] , [string] : { [string] : EXPERIMENT_NAME , [string] : NAMESPACE } , [string] : { [string] : EXPERIMENT_NAME , [string] : [ ] , [string] : [string] , [string] : TEMPLATE_NAME , [string] : TEMPLATE_NAMESPACE , [string] : TEMPLATE_VERSION } } [EOL] [EOL] [EOL] GET_EXPERIMENT_RESPONSE_RAW = { [string] : [string] , [string] : [string] , [string] : { [string] : EXPERIMENT_NAME , [string] : NAMESPACE , [string] : [string] } , [string] : { [string] : EXPERIMENT_NAME , [string] : [ ] , [string] : [string] , [string] : TEMPLATE_NAME , [string] : TEMPLATE_NAMESPACE , [string] : TEMPLATE_VERSION } } [EOL] [EOL] LIST_EXPERIMENTS_EMPTY_RESPONSE_RAW = { [string] : [ ] } [EOL] LIST_EXPERIMENTS_RESPONSE_RAW = { [string] : [string] , [string] : [ { [string] : [string] , [string] : [string] , [string] : { [string] : { [string] : [string] [string] [string] [string] [string] [string] [string] [string] [string] [string] } , [string] : [string] , [string] : [string] , [string] : { [string] : [string] , [string] : [string] } , [string] : [number] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] } , [string] : { [string] : [string] , [string] : [ [string] , [string] ] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] } } , { [string] : [string] , [string] : [string] , [string] : { [string] : { [string] : [string] [string] [string] [string] [string] [string] [string] } , [string] : [string] , [string] : [string] , [string] : { [string] : [string] , [string] : [string] } , [string] : [number] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] } , [string] : { [string] : [string] , [string] : [ [string] , [string] ] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] } } ] , [string] : [string] , [string] : { [string] : [string] , [string] : [string] , [string] : [string] } } [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $kubernetes.client.CustomObjectsApi$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] from typing import Any , Tuple , Literal [EOL] import argparse [EOL] import typing [EOL] import typing_extensions [EOL] import argparse [EOL] import os [EOL] import sys [EOL] [EOL] from six . moves import urllib [EOL] import tensorflow as tf [EOL] [EOL] [EOL] FLAGS = None [EOL] SOURCE_URL = [string] [EOL] FILENAMES = ( [string] , [string] , [string] , [string] ) [EOL] [EOL] [EOL] def main ( _ ) : [EOL] for filename in FILENAMES : [EOL] if not tf . gfile . Exists ( FLAGS . data_dir ) : [EOL] tf . gfile . MakeDirs ( FLAGS . data_dir ) [EOL] filepath = os . path . join ( FLAGS . data_dir , filename ) [EOL] if not tf . gfile . Exists ( filepath ) : [EOL] filepath , _ = urllib . request . urlretrieve ( SOURCE_URL + filename , filepath ) [EOL] with tf . gfile . GFile ( filepath ) as f : [EOL] size = f . size ( ) [EOL] print ( [string] , filename , size , [string] ) [EOL] return [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] , type = str , default = [string] , help = [string] ) [EOL] FLAGS , unparsed = parser . parse_known_args ( ) [EOL] tf . app . run ( main = main , argv = [ sys . argv [ [number] ] ] + unparsed ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] import builtins [EOL] from typing import Any , Tuple , Dict , Literal [EOL] import typing [EOL] import typing_extensions [EOL] [docstring] [EOL] [EOL] from __future__ import absolute_import [EOL] from __future__ import division [EOL] from __future__ import print_function [EOL] [EOL] import os [EOL] import sys [EOL] import tempfile [EOL] import time [EOL] [EOL] import tensorflow as tf [EOL] from tensorflow . examples . tutorials . mnist import input_data [EOL] [EOL] [comment] [EOL] [EOL] flags = tf . app . flags [EOL] flags . DEFINE_string ( [string] , [string] , [string] ) [EOL] flags . DEFINE_boolean ( [string] , False , [string] [string] ) [EOL] flags . DEFINE_integer ( [string] , None , [string] [string] [string] ) [EOL] flags . DEFINE_integer ( [string] , [number] , [string] [string] ) [EOL] flags . DEFINE_integer ( [string] , None , [string] [string] [string] ) [EOL] flags . DEFINE_integer ( [string] , [number] , [string] ) [EOL] flags . DEFINE_integer ( [string] , [number] , [string] ) [EOL] flags . DEFINE_integer ( [string] , [number] , [string] ) [EOL] flags . DEFINE_float ( [string] , [number] , [string] ) [EOL] flags . DEFINE_boolean ( [string] , False , [string] [string] [string] ) [EOL] flags . DEFINE_boolean ( [string] , False , [string] [string] [string] [string] ) [EOL] flags . DEFINE_string ( [string] , [string] , [string] ) [EOL] flags . DEFINE_string ( [string] , [string] , [string] ) [EOL] flags . DEFINE_string ( [string] , None , [string] ) [EOL] [EOL] FLAGS = flags . FLAGS [EOL] [EOL] IMAGE_PIXELS = [number] [EOL] FILENAMES = ( [string] , [string] , [string] , [string] ) [EOL] [EOL] [EOL] def deepnn ( x ) : [EOL] [docstring] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] x_image = tf . reshape ( x , [ - [number] , [number] , [number] , [number] ] ) [EOL] [EOL] [comment] [EOL] W_conv1 = weight_variable ( [ [number] , [number] , [number] , [number] ] ) [EOL] b_conv1 = bias_variable ( [ [number] ] ) [EOL] h_conv1 = tf . nn . relu ( conv2d ( x_image , W_conv1 ) + b_conv1 ) [EOL] [EOL] [comment] [EOL] h_pool1 = max_pool_2x2 ( h_conv1 ) [EOL] [EOL] [comment] [EOL] W_conv2 = weight_variable ( [ [number] , [number] , [number] , [number] ] ) [EOL] b_conv2 = bias_variable ( [ [number] ] ) [EOL] h_conv2 = tf . nn . relu ( conv2d ( h_pool1 , W_conv2 ) + b_conv2 ) [EOL] [EOL] [comment] [EOL] h_pool2 = max_pool_2x2 ( h_conv2 ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] W_fc1 = weight_variable ( [ [number] * [number] * [number] , [number] ] ) [EOL] b_fc1 = bias_variable ( [ [number] ] ) [EOL] [EOL] h_pool2_flat = tf . reshape ( h_pool2 , [ - [number] , [number] * [number] * [number] ] ) [EOL] h_fc1 = tf . nn . relu ( tf . matmul ( h_pool2_flat , W_fc1 ) + b_fc1 ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] keep_prob = tf . placeholder ( tf . float32 ) [EOL] h_fc1_drop = tf . nn . dropout ( h_fc1 , keep_prob ) [EOL] [EOL] [comment] [EOL] W_fc2 = weight_variable ( [ [number] , [number] ] ) [EOL] b_fc2 = bias_variable ( [ [number] ] ) [EOL] [EOL] y_conv = tf . matmul ( h_fc1_drop , W_fc2 ) + b_fc2 [EOL] return y_conv , keep_prob [EOL] [EOL] [EOL] def conv2d ( x , W ) : [EOL] [docstring] [EOL] return tf . nn . conv2d ( x , W , strides = [ [number] , [number] , [number] , [number] ] , padding = [string] ) [EOL] [EOL] [EOL] def max_pool_2x2 ( x ) : [EOL] [docstring] [EOL] return tf . nn . max_pool ( x , ksize = [ [number] , [number] , [number] , [number] ] , strides = [ [number] , [number] , [number] , [number] ] , padding = [string] ) [EOL] [EOL] [EOL] def weight_variable ( shape ) : [EOL] [docstring] [EOL] initial = tf . truncated_normal ( shape , stddev = [number] ) [EOL] return tf . Variable ( initial ) [EOL] [EOL] [EOL] def bias_variable ( shape ) : [EOL] [docstring] [EOL] initial = tf . constant ( [number] , shape = shape ) [EOL] return tf . Variable ( initial ) [EOL] [EOL] [EOL] def main ( _ ) : [EOL] for filename in FILENAMES : [EOL] if not os . path . isfile ( os . path . join ( FLAGS . data_dir , filename ) ) : [EOL] print ( [string] , [string] % FLAGS . data_dir , [string] . join ( FILENAMES ) ) [EOL] return [EOL] [EOL] mnist = input_data . read_data_sets ( FLAGS . data_dir , one_hot = True ) [EOL] if FLAGS . download_only : [EOL] sys . exit ( [number] ) [EOL] [EOL] if FLAGS . job_name is None or FLAGS . job_name == [string] : [EOL] raise ValueError ( [string] ) [EOL] if FLAGS . task_index is None or FLAGS . task_index == [string] : [EOL] raise ValueError ( [string] ) [EOL] [EOL] print ( [string] % FLAGS . job_name ) [EOL] print ( [string] % FLAGS . task_index ) [EOL] [EOL] [comment] [EOL] ps_spec = FLAGS . ps_hosts . split ( [string] ) [EOL] worker_spec = FLAGS . worker_hosts . split ( [string] ) [EOL] [EOL] [comment] [EOL] num_workers = len ( worker_spec ) [EOL] [EOL] cluster = tf . train . ClusterSpec ( { [string] : ps_spec , [string] : worker_spec } ) [EOL] [EOL] if not FLAGS . existing_servers : [EOL] [comment] [EOL] server = tf . train . Server ( cluster , job_name = FLAGS . job_name , task_index = FLAGS . task_index ) [EOL] if FLAGS . job_name == [string] : [EOL] server . join ( ) [EOL] [EOL] is_chief = ( FLAGS . task_index == [number] ) [EOL] if FLAGS . num_gpus > [number] : [EOL] [comment] [EOL] [comment] [EOL] gpu = ( FLAGS . task_index % FLAGS . num_gpus ) [EOL] worker_device = [string] % ( FLAGS . task_index , gpu ) [EOL] elif FLAGS . num_gpus == [number] : [EOL] [comment] [EOL] cpu = [number] [EOL] worker_device = [string] % ( FLAGS . task_index , cpu ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] with tf . device ( tf . train . replica_device_setter ( worker_device = worker_device , ps_device = [string] , cluster = cluster ) ) : [EOL] global_step = tf . Variable ( [number] , name = [string] , trainable = False ) [EOL] [EOL] [EOL] [comment] [EOL] x = tf . placeholder ( tf . float32 , [ None , IMAGE_PIXELS * IMAGE_PIXELS ] ) [EOL] y_ = tf . placeholder ( tf . float32 , [ None , [number] ] ) [EOL] [EOL] y , keep_prob = deepnn ( x ) [EOL] cross_entropy = tf . reduce_mean ( tf . nn . softmax_cross_entropy_with_logits ( labels = y_ , logits = y ) ) [EOL] opt = tf . train . AdamOptimizer ( FLAGS . learning_rate ) [EOL] correct_prediction = tf . equal ( tf . argmax ( y , [number] ) , tf . argmax ( y_ , [number] ) ) [EOL] accuracy = tf . reduce_mean ( tf . cast ( correct_prediction , tf . float32 ) ) [EOL] [EOL] if FLAGS . sync_replicas : [EOL] if FLAGS . replicas_to_aggregate is None : [EOL] replicas_to_aggregate = num_workers [EOL] else : [EOL] replicas_to_aggregate = FLAGS . replicas_to_aggregate [EOL] [EOL] opt = tf . train . SyncReplicasOptimizer ( opt , replicas_to_aggregate = replicas_to_aggregate , total_num_replicas = num_workers , name = [string] ) [EOL] [EOL] train_step = opt . minimize ( cross_entropy , global_step = global_step ) [EOL] [EOL] if FLAGS . sync_replicas : [EOL] local_init_op = opt . local_step_init_op [EOL] if is_chief : [EOL] local_init_op = opt . chief_init_op [EOL] [EOL] ready_for_local_init_op = opt . ready_for_local_init_op [EOL] [EOL] [comment] [EOL] chief_queue_runner = opt . get_chief_queue_runner ( ) [EOL] sync_init_op = opt . get_init_tokens_op ( ) [EOL] [EOL] init_op = tf . global_variables_initializer ( ) [EOL] train_dir = tempfile . mkdtemp ( ) [EOL] [EOL] if FLAGS . sync_replicas : [EOL] sv = tf . train . Supervisor ( is_chief = is_chief , logdir = train_dir , init_op = init_op , local_init_op = local_init_op , ready_for_local_init_op = ready_for_local_init_op , recovery_wait_secs = [number] , global_step = global_step ) [EOL] else : [EOL] sv = tf . train . Supervisor ( is_chief = is_chief , logdir = train_dir , init_op = init_op , recovery_wait_secs = [number] , global_step = global_step ) [EOL] [EOL] sess_config = tf . ConfigProto ( allow_soft_placement = True , log_device_placement = False , device_filters = [ [string] , [string] % FLAGS . task_index ] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] if is_chief : [EOL] print ( [string] % FLAGS . task_index ) [EOL] else : [EOL] print ( [string] % FLAGS . task_index ) [EOL] [EOL] if FLAGS . existing_servers : [EOL] server_grpc_url = [string] + worker_spec [ FLAGS . task_index ] [EOL] print ( [string] % server_grpc_url ) [EOL] [EOL] sess = sv . prepare_or_wait_for_session ( server_grpc_url , config = sess_config ) [EOL] else : [EOL] sess = sv . prepare_or_wait_for_session ( server . target , config = sess_config ) [EOL] [EOL] print ( [string] % FLAGS . task_index ) [EOL] [EOL] if FLAGS . sync_replicas and is_chief : [EOL] [comment] [EOL] sess . run ( sync_init_op ) [EOL] sv . start_queue_runners ( sess , [ chief_queue_runner ] ) [EOL] [EOL] [comment] [EOL] time_begin = time . time ( ) [EOL] print ( [string] % time_begin ) [EOL] [EOL] local_step = [number] [EOL] while True : [EOL] [comment] [EOL] batch_xs , batch_ys = mnist . train . next_batch ( FLAGS . batch_size ) [EOL] train_feed = { x : batch_xs , y_ : batch_ys , keep_prob : [number] } [EOL] [EOL] _ , step = sess . run ( [ train_step , global_step ] , feed_dict = train_feed ) [EOL] local_step += [number] [EOL] [EOL] now = time . time ( ) [EOL] if local_step % [number] == [number] : [EOL] print ( [string] % ( now , FLAGS . task_index , local_step , step ) ) [EOL] print ( [string] % sess . run ( accuracy , feed_dict = { x : batch_xs , y_ : batch_ys , keep_prob : [number] } ) ) [EOL] [EOL] if local_step % [number] == [number] : [EOL] batch_xs_test , batch_ys_test = mnist . validation . next_batch ( FLAGS . batch_size ) [EOL] print ( [string] % sess . run ( accuracy , feed_dict = { x : batch_xs_test , y_ : batch_ys_test , keep_prob : [number] } ) ) [EOL] [EOL] if step >= FLAGS . train_steps : [EOL] time_end = time . time ( ) [EOL] print ( [string] % time_end ) [EOL] training_time = time_end - time_begin [EOL] print ( [string] % training_time ) [EOL] batch_xs_test , batch_ys_test = mnist . validation . next_batch ( [number] ) [EOL] print ( [string] % sess . run ( accuracy , feed_dict = { x : batch_xs_test , y_ : batch_ys_test , keep_prob : [number] } ) ) [EOL] break [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] tf . app . run ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] import builtins [EOL] from typing import Any , Tuple , Dict , Literal [EOL] import typing [EOL] import typing_extensions [EOL] [docstring] [EOL] [EOL] from __future__ import absolute_import [EOL] from __future__ import division [EOL] from __future__ import print_function [EOL] [EOL] import math [EOL] import os [EOL] import sys [EOL] import tempfile [EOL] import time [EOL] [EOL] import tensorflow as tf [EOL] from tensorflow . examples . tutorials . mnist import input_data [EOL] [EOL] flags = tf . app . flags [EOL] flags . DEFINE_string ( [string] , [string] , [string] ) [EOL] flags . DEFINE_boolean ( [string] , False , [string] [string] ) [EOL] flags . DEFINE_integer ( [string] , None , [string] [string] [string] ) [EOL] flags . DEFINE_integer ( [string] , [number] , [string] [string] ) [EOL] flags . DEFINE_integer ( [string] , None , [string] [string] [string] ) [EOL] flags . DEFINE_integer ( [string] , [number] , [string] ) [EOL] flags . DEFINE_integer ( [string] , [number] , [string] ) [EOL] flags . DEFINE_integer ( [string] , [number] , [string] ) [EOL] flags . DEFINE_float ( [string] , [number] , [string] ) [EOL] flags . DEFINE_boolean ( [string] , False , [string] [string] [string] ) [EOL] flags . DEFINE_boolean ( [string] , False , [string] [string] [string] [string] ) [EOL] flags . DEFINE_string ( [string] , [string] , [string] ) [EOL] flags . DEFINE_string ( [string] , [string] , [string] ) [EOL] flags . DEFINE_string ( [string] , None , [string] ) [EOL] [EOL] FLAGS = flags . FLAGS [EOL] [EOL] IMAGE_PIXELS = [number] [EOL] FILENAMES = ( [string] , [string] , [string] , [string] ) [EOL] [EOL] [EOL] def main ( unused_argv ) : [EOL] for filename in FILENAMES : [EOL] if not os . path . isfile ( os . path . join ( FLAGS . data_dir , filename ) ) : [EOL] print ( [string] , [string] % FLAGS . data_dir , [string] . join ( FILENAMES ) ) [EOL] return [EOL] [EOL] mnist = input_data . read_data_sets ( FLAGS . data_dir , one_hot = True ) [EOL] if FLAGS . download_only : [EOL] sys . exit ( [number] ) [EOL] [EOL] if FLAGS . job_name is None or FLAGS . job_name == [string] : [EOL] raise ValueError ( [string] ) [EOL] if FLAGS . task_index is None or FLAGS . task_index == [string] : [EOL] raise ValueError ( [string] ) [EOL] [EOL] print ( [string] % FLAGS . job_name ) [EOL] print ( [string] % FLAGS . task_index ) [EOL] [EOL] [comment] [EOL] ps_spec = FLAGS . ps_hosts . split ( [string] ) [EOL] worker_spec = FLAGS . worker_hosts . split ( [string] ) [EOL] [EOL] [comment] [EOL] num_workers = len ( worker_spec ) [EOL] [EOL] cluster = tf . train . ClusterSpec ( { [string] : ps_spec , [string] : worker_spec } ) [EOL] [EOL] if not FLAGS . existing_servers : [EOL] [comment] [EOL] server = tf . train . Server ( cluster , job_name = FLAGS . job_name , task_index = FLAGS . task_index ) [EOL] if FLAGS . job_name == [string] : [EOL] server . join ( ) [EOL] [EOL] is_chief = ( FLAGS . task_index == [number] ) [EOL] if FLAGS . num_gpus > [number] : [EOL] [comment] [EOL] [comment] [EOL] gpu = ( FLAGS . task_index % FLAGS . num_gpus ) [EOL] worker_device = [string] % ( FLAGS . task_index , gpu ) [EOL] elif FLAGS . num_gpus == [number] : [EOL] [comment] [EOL] cpu = [number] [EOL] worker_device = [string] % ( FLAGS . task_index , cpu ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] with tf . device ( tf . train . replica_device_setter ( worker_device = worker_device , ps_device = [string] , cluster = cluster ) ) : [EOL] global_step = tf . Variable ( [number] , name = [string] , trainable = False ) [EOL] [EOL] [comment] [EOL] hid_w = tf . Variable ( tf . truncated_normal ( [ IMAGE_PIXELS * IMAGE_PIXELS , FLAGS . hidden_units ] , stddev = [number] / IMAGE_PIXELS ) , name = [string] ) [EOL] hid_b = tf . Variable ( tf . zeros ( [ FLAGS . hidden_units ] ) , name = [string] ) [EOL] [EOL] [comment] [EOL] sm_w = tf . Variable ( tf . truncated_normal ( [ FLAGS . hidden_units , [number] ] , stddev = [number] / math . sqrt ( FLAGS . hidden_units ) ) , name = [string] ) [EOL] sm_b = tf . Variable ( tf . zeros ( [ [number] ] ) , name = [string] ) [EOL] [EOL] [comment] [EOL] x = tf . placeholder ( tf . float32 , [ None , IMAGE_PIXELS * IMAGE_PIXELS ] ) [EOL] y_ = tf . placeholder ( tf . float32 , [ None , [number] ] ) [EOL] [EOL] hid_lin = tf . nn . xw_plus_b ( x , hid_w , hid_b ) [EOL] hid = tf . nn . relu ( hid_lin ) [EOL] [EOL] y = tf . nn . softmax ( tf . nn . xw_plus_b ( hid , sm_w , sm_b ) ) [EOL] cross_entropy = - tf . reduce_sum ( y_ * tf . log ( tf . clip_by_value ( y , [number] , [number] ) ) ) [EOL] [EOL] opt = tf . train . AdamOptimizer ( FLAGS . learning_rate ) [EOL] correct_prediction = tf . equal ( tf . argmax ( y , [number] ) , tf . argmax ( y_ , [number] ) ) [EOL] accuracy = tf . reduce_mean ( tf . cast ( correct_prediction , tf . float32 ) ) [EOL] [EOL] if FLAGS . sync_replicas : [EOL] if FLAGS . replicas_to_aggregate is None : [EOL] replicas_to_aggregate = num_workers [EOL] else : [EOL] replicas_to_aggregate = FLAGS . replicas_to_aggregate [EOL] [EOL] opt = tf . train . SyncReplicasOptimizer ( opt , replicas_to_aggregate = replicas_to_aggregate , total_num_replicas = num_workers , name = [string] ) [EOL] [EOL] train_step = opt . minimize ( cross_entropy , global_step = global_step ) [EOL] [EOL] if FLAGS . sync_replicas : [EOL] local_init_op = opt . local_step_init_op [EOL] if is_chief : [EOL] local_init_op = opt . chief_init_op [EOL] [EOL] ready_for_local_init_op = opt . ready_for_local_init_op [EOL] [EOL] [comment] [EOL] chief_queue_runner = opt . get_chief_queue_runner ( ) [EOL] sync_init_op = opt . get_init_tokens_op ( ) [EOL] [EOL] init_op = tf . global_variables_initializer ( ) [EOL] train_dir = tempfile . mkdtemp ( ) [EOL] [EOL] if FLAGS . sync_replicas : [EOL] sv = tf . train . Supervisor ( is_chief = is_chief , logdir = train_dir , init_op = init_op , local_init_op = local_init_op , ready_for_local_init_op = ready_for_local_init_op , recovery_wait_secs = [number] , global_step = global_step ) [EOL] else : [EOL] sv = tf . train . Supervisor ( is_chief = is_chief , logdir = train_dir , init_op = init_op , recovery_wait_secs = [number] , global_step = global_step ) [EOL] [EOL] sess_config = tf . ConfigProto ( allow_soft_placement = True , log_device_placement = False , device_filters = [ [string] , [string] % FLAGS . task_index ] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] if is_chief : [EOL] print ( [string] % FLAGS . task_index ) [EOL] else : [EOL] print ( [string] % FLAGS . task_index ) [EOL] [EOL] if FLAGS . existing_servers : [EOL] server_grpc_url = [string] + worker_spec [ FLAGS . task_index ] [EOL] print ( [string] % server_grpc_url ) [EOL] [EOL] sess = sv . prepare_or_wait_for_session ( server_grpc_url , config = sess_config ) [EOL] else : [EOL] sess = sv . prepare_or_wait_for_session ( server . target , config = sess_config ) [EOL] [EOL] print ( [string] % FLAGS . task_index ) [EOL] [EOL] if FLAGS . sync_replicas and is_chief : [EOL] [comment] [EOL] sess . run ( sync_init_op ) [EOL] sv . start_queue_runners ( sess , [ chief_queue_runner ] ) [EOL] [EOL] [comment] [EOL] time_begin = time . time ( ) [EOL] print ( [string] % time_begin ) [EOL] [EOL] local_step = [number] [EOL] while True : [EOL] [comment] [EOL] batch_xs , batch_ys = mnist . train . next_batch ( FLAGS . batch_size ) [EOL] train_feed = { x : batch_xs , y_ : batch_ys } [EOL] [EOL] _ , step = sess . run ( [ train_step , global_step ] , feed_dict = train_feed ) [EOL] local_step += [number] [EOL] [EOL] now = time . time ( ) [EOL] print ( [string] % ( now , FLAGS . task_index , local_step , step ) ) [EOL] [EOL] if step >= FLAGS . train_steps : [EOL] break [EOL] [EOL] time_end = time . time ( ) [EOL] print ( [string] % time_end ) [EOL] training_time = time_end - time_begin [EOL] print ( [string] % training_time ) [EOL] [EOL] [comment] [EOL] val_feed = { x : mnist . validation . images , y_ : mnist . validation . labels } [EOL] val_xent = sess . run ( cross_entropy , feed_dict = val_feed ) [EOL] print ( [string] % ( FLAGS . train_steps , val_xent ) ) [EOL] [EOL] [comment] [EOL] accuracy_value = sess . run ( accuracy , feed_dict = val_feed ) [EOL] print ( [string] % accuracy_value ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] tf . app . run ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , List [EOL] import argparse [EOL] import typing [EOL] import argparse [EOL] import os [EOL] import sys [EOL] import tensorflow as tf [EOL] [EOL] [EOL] def _bytes_feature ( value ) : [EOL] return tf . train . Feature ( bytes_list = tf . train . BytesList ( value = [ value ] ) ) [EOL] [EOL] [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] , type = str , required = True ) [EOL] parser . add_argument ( [string] , type = str , required = True ) [EOL] [EOL] args = parser . parse_args ( ) [EOL] [EOL] files_to_convert = [ ] [EOL] [EOL] for root , _ , files in os . walk ( args . input_dir ) : [EOL] for name in files : [EOL] files_to_convert . append ( os . path . join ( root , name ) ) [EOL] [EOL] with tf . python_io . TFRecordWriter ( args . output_file ) as writer : [EOL] for filename in files_to_convert : [EOL] with open ( filename , mode = [string] ) as fi : [EOL] pb_bytes = fi . read ( ) [EOL] [EOL] example = tf . train . Example ( features = tf . train . Features ( feature = { [string] : _bytes_feature ( pb_bytes ) , [string] : _bytes_feature ( bytes ( os . path . basename ( filename ) , [string] ) ) } ) ) [EOL] [EOL] writer . write ( example . SerializeToString ( ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.Namespace$ 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.Namespace$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.Namespace$ 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bytes$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bytes$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] from typing import Any [EOL] import argparse [EOL] import typing [EOL] import warnings [EOL] warnings . filterwarnings ( [string] , category = FutureWarning ) [EOL] import argparse [EOL] import os [EOL] [EOL] import tensorflow as tf [EOL] [EOL] from experiment_metrics . api import publish [EOL] [EOL] [EOL] [comment] [EOL] EXPERIMENT_OUTPUT_PATH = [string] [EOL] MODEL_VERSION = [number] [EOL] [EOL] FLAGS = None [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] MODEL_SIGNATURE_NAME = [string] [EOL] MODEL_INPUT_NAME = [string] [EOL] MODEL_OUTPUT_NAME = [string] [EOL] [EOL] [EOL] def build_net ( images_placeholder , dense_dropout_placeholder ) : [EOL] [docstring] [EOL] images_input = tf . reshape ( images_placeholder , [ - [number] , [number] , [number] , [number] ] ) [EOL] [EOL] conv_1 = tf . layers . conv2d ( images_input , filters = [number] , kernel_size = [number] , activation = tf . nn . relu , padding = [string] ) [EOL] pool_1 = tf . layers . max_pooling2d ( conv_1 , pool_size = [ [number] , [number] ] , strides = [ [number] , [number] ] , padding = [string] ) [EOL] [EOL] conv_2 = tf . layers . conv2d ( pool_1 , filters = [number] , kernel_size = [number] , activation = tf . nn . relu , padding = [string] ) [EOL] pool_2 = tf . layers . max_pooling2d ( conv_2 , pool_size = [ [number] , [number] ] , strides = [ [number] , [number] ] , padding = [string] ) [EOL] [EOL] dense_input = tf . reshape ( pool_2 , [ - [number] , [number] * [number] * [number] ] ) [EOL] dense_1 = tf . layers . dense ( dense_input , [number] , activation = tf . nn . relu ) [EOL] dense_1_drop = tf . nn . dropout ( dense_1 , dense_dropout_placeholder ) [EOL] [EOL] logits = tf . layers . dense ( dense_1_drop , [number] ) [EOL] logits = tf . identity ( logits ) [EOL] scores = tf . nn . softmax ( logits ) [EOL] predictions = tf . argmax ( logits , axis = [number] ) [EOL] [EOL] return logits , scores , predictions [EOL] [EOL] [EOL] def main ( _ ) : [EOL] mnist = tf . contrib . learn . datasets . mnist . read_data_sets ( FLAGS . data_dir ) [EOL] [EOL] images_placeholder = tf . placeholder ( tf . float32 , [ None , [number] ] ) [EOL] dense_dropout_placeholder = tf . placeholder_with_default ( [number] , [ ] ) [EOL] labels_placeholder = tf . placeholder ( tf . int64 , [ None ] ) [EOL] [EOL] logits , scores , predictions = build_net ( images_placeholder , dense_dropout_placeholder ) [EOL] [EOL] loss = tf . losses . softmax_cross_entropy ( tf . one_hot ( labels_placeholder , [number] ) , logits ) [EOL] train = tf . train . AdamOptimizer ( ) . minimize ( loss ) [EOL] accuracy = tf . reduce_mean ( tf . cast ( tf . equal ( predictions , labels_placeholder ) , tf . float32 ) ) [EOL] [EOL] tf . summary . scalar ( [string] , loss ) [EOL] tf . summary . scalar ( [string] , accuracy ) [EOL] summary_op = tf . summary . merge_all ( ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] summary_writer = tf . summary . FileWriter ( os . path . join ( EXPERIMENT_OUTPUT_PATH , [string] ) ) [EOL] [EOL] session = tf . Session ( ) [EOL] session . run ( tf . global_variables_initializer ( ) ) [EOL] [EOL] saver = tf . train . Saver ( ) [EOL] [EOL] for i in range ( FLAGS . steps ) : [EOL] images , labels = mnist . train . next_batch ( [number] ) [EOL] _ , summary_out , loss_val , accuracy_val = session . run ( [ train , summary_op , loss , accuracy ] , feed_dict = { images_placeholder : images , labels_placeholder : labels , dense_dropout_placeholder : [number] } ) [EOL] [EOL] if i % [number] == [number] : [EOL] print ( [string] . format ( i , loss_val , accuracy_val ) ) [EOL] [EOL] summary_writer . add_summary ( summary_out , global_step = i ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] publish ( { [string] : str ( i ) , [string] : str ( loss_val ) , [string] : str ( accuracy_val ) } ) [EOL] [EOL] [comment] [EOL] validation_accuracy_val = session . run ( accuracy , feed_dict = { images_placeholder : mnist . validation . images , labels_placeholder : mnist . validation . labels } ) [EOL] print ( [string] . format ( validation_accuracy_val ) ) [EOL] [EOL] [comment] [EOL] saver . save ( session , os . path . join ( EXPERIMENT_OUTPUT_PATH , [string] , [string] ) ) [EOL] [EOL] [comment] [EOL] publish ( { [string] : str ( validation_accuracy_val ) } ) [EOL] [EOL] [comment] [EOL] if FLAGS . export_dir is not [string] : [EOL] export_dir = os . path . join ( FLAGS . export_dir , str ( MODEL_VERSION ) ) [EOL] builder = tf . saved_model . builder . SavedModelBuilder ( export_dir ) [EOL] [EOL] prediction_signature = ( tf . saved_model . signature_def_utils . build_signature_def ( inputs = { MODEL_INPUT_NAME : tf . saved_model . utils . build_tensor_info ( images_placeholder ) } , outputs = { MODEL_OUTPUT_NAME : tf . saved_model . utils . build_tensor_info ( scores ) } , method_name = tf . saved_model . signature_constants . PREDICT_METHOD_NAME ) ) [EOL] [EOL] builder . add_meta_graph_and_variables ( session , [ tf . saved_model . tag_constants . SERVING ] , signature_def_map = { MODEL_SIGNATURE_NAME : prediction_signature } , main_op = tf . tables_initializer ( ) , strip_default_attrs = True ) [EOL] [EOL] builder . save ( ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] , type = str , default = [string] , help = [string] ) [EOL] parser . add_argument ( [string] , type = str , default = [string] , help = [string] ) [EOL] parser . add_argument ( [string] , type = int , default = [number] , help = [string] ) [EOL] FLAGS , _ = parser . parse_known_args ( ) [EOL] tf . app . run ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , Dict [EOL] import argparse [EOL] import typing [EOL] import argparse [EOL] import os [EOL] [EOL] from torchvision import datasets , transforms [EOL] import torch [EOL] import torch . distributed as dist [EOL] import torch . nn as nn [EOL] import torch . nn . functional as F [EOL] import torch . optim as optim [EOL] [EOL] WORLD_SIZE = int ( os . environ . get ( [string] , [number] ) ) [EOL] [EOL] [EOL] class Net ( nn . Module ) : [EOL] def __init__ ( self ) : [EOL] super ( Net , self ) . __init__ ( ) [EOL] self . conv1 = nn . Conv2d ( [number] , [number] , [number] , [number] ) [EOL] self . conv2 = nn . Conv2d ( [number] , [number] , [number] , [number] ) [EOL] self . fc1 = nn . Linear ( [number] * [number] * [number] , [number] ) [EOL] self . fc2 = nn . Linear ( [number] , [number] ) [EOL] [EOL] def forward ( self , x ) : [EOL] x = F . relu ( self . conv1 ( x ) ) [EOL] x = F . max_pool2d ( x , [number] , [number] ) [EOL] x = F . relu ( self . conv2 ( x ) ) [EOL] x = F . max_pool2d ( x , [number] , [number] ) [EOL] x = x . view ( - [number] , [number] * [number] * [number] ) [EOL] x = F . relu ( self . fc1 ( x ) ) [EOL] x = self . fc2 ( x ) [EOL] return F . log_softmax ( x , dim = [number] ) [EOL] [EOL] [EOL] def train ( args , model , device , train_loader , optimizer , epoch ) : [EOL] model . train ( ) [EOL] for batch_idx , ( data , target ) in enumerate ( train_loader ) : [EOL] data , target = data . to ( device ) , target . to ( device ) [EOL] optimizer . zero_grad ( ) [EOL] output = model ( data ) [EOL] loss = F . nll_loss ( output , target ) [EOL] loss . backward ( ) [EOL] optimizer . step ( ) [EOL] if batch_idx % args . log_interval == [number] : [EOL] print ( [string] . format ( epoch , batch_idx * len ( data ) , len ( train_loader . dataset ) , [number] * batch_idx / len ( train_loader ) , loss . item ( ) ) ) [EOL] niter = epoch * len ( train_loader ) + batch_idx [EOL] [EOL] [EOL] def test ( args , model , device , test_loader , epoch ) : [EOL] model . eval ( ) [EOL] test_loss = [number] [EOL] correct = [number] [EOL] with torch . no_grad ( ) : [EOL] for data , target in test_loader : [EOL] data , target = data . to ( device ) , target . to ( device ) [EOL] output = model ( data ) [EOL] test_loss += F . nll_loss ( output , target , reduction = [string] ) . item ( ) [comment] [EOL] pred = output . max ( [number] , keepdim = True ) [ [number] ] [comment] [EOL] correct += pred . eq ( target . view_as ( pred ) ) . sum ( ) . item ( ) [EOL] [EOL] test_loss /= len ( test_loader . dataset ) [EOL] print ( [string] . format ( float ( correct ) / len ( test_loader . dataset ) ) ) [EOL] [EOL] [EOL] def should_distribute ( ) : [EOL] return dist . is_available ( ) and WORLD_SIZE > [number] [EOL] [EOL] [EOL] def is_distributed ( ) : [EOL] return dist . is_available ( ) and dist . is_initialized ( ) [EOL] [EOL] [EOL] def main ( ) : [EOL] [comment] [EOL] parser = argparse . ArgumentParser ( description = [string] ) [EOL] parser . add_argument ( [string] , type = int , default = [number] , metavar = [string] , help = [string] ) [EOL] parser . add_argument ( [string] , type = int , default = [number] , metavar = [string] , help = [string] ) [EOL] parser . add_argument ( [string] , type = int , default = [number] , metavar = [string] , help = [string] ) [EOL] parser . add_argument ( [string] , type = float , default = [number] , metavar = [string] , help = [string] ) [EOL] parser . add_argument ( [string] , type = float , default = [number] , metavar = [string] , help = [string] ) [EOL] parser . add_argument ( [string] , action = [string] , default = False , help = [string] ) [EOL] parser . add_argument ( [string] , type = int , default = [number] , metavar = [string] , help = [string] ) [EOL] parser . add_argument ( [string] , type = int , default = [number] , metavar = [string] , help = [string] ) [EOL] parser . add_argument ( [string] , action = [string] , default = False , help = [string] ) [EOL] parser . add_argument ( [string] , default = [string] , metavar = [string] , help = [string] ) [EOL] if dist . is_available ( ) : [EOL] parser . add_argument ( [string] , type = str , help = [string] , choices = [ dist . Backend . GLOO , dist . Backend . NCCL , dist . Backend . MPI ] , default = dist . Backend . GLOO ) [EOL] args = parser . parse_args ( ) [EOL] [EOL] torch . manual_seed ( args . seed ) [EOL] [EOL] device = torch . device ( [string] ) [EOL] [EOL] if should_distribute ( ) : [EOL] print ( [string] . format ( args . backend ) ) [EOL] dist . init_process_group ( backend = args . backend ) [EOL] [EOL] kwargs = { } [EOL] train_loader = torch . utils . data . DataLoader ( datasets . MNIST ( [string] , train = True , download = True , transform = transforms . Compose ( [ transforms . ToTensor ( ) , transforms . Normalize ( ( [number] , ) , ( [number] , ) ) ] ) ) , batch_size = args . batch_size , shuffle = True , ** kwargs ) [EOL] test_loader = torch . utils . data . DataLoader ( datasets . MNIST ( [string] , train = False , transform = transforms . Compose ( [ transforms . ToTensor ( ) , transforms . Normalize ( ( [number] , ) , ( [number] , ) ) ] ) ) , batch_size = args . test_batch_size , shuffle = False , ** kwargs ) [EOL] [EOL] model = Net ( ) . to ( device ) [EOL] [EOL] if is_distributed ( ) : [EOL] Distributor = nn . parallel . DistributedDataParallelCPU [EOL] model = Distributor ( model ) [EOL] [EOL] optimizer = optim . SGD ( model . parameters ( ) , lr = args . lr , momentum = args . momentum ) [EOL] [EOL] for epoch in range ( [number] , args . epochs + [number] ) : [EOL] train ( args , model , device , train_loader , optimizer , epoch ) [EOL] test ( args , model , device , test_loader , epoch ) [EOL] [EOL] if args . save_model : [EOL] torch . save ( model . state_dict ( ) , [string] ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Any , Dict [EOL] import typing [EOL] [docstring] [EOL] [EOL] from __future__ import print_function [EOL] import warnings [EOL] warnings . filterwarnings ( [string] , category = FutureWarning ) [EOL] [EOL] import os [EOL] import sys [EOL] [EOL] [comment] [EOL] [EOL] import tensorflow as tf [EOL] [EOL] import mnist_input_data [EOL] [EOL] tf . app . flags . DEFINE_integer ( [string] , [number] , [string] ) [EOL] tf . app . flags . DEFINE_integer ( [string] , [number] , [string] ) [EOL] tf . app . flags . DEFINE_string ( [string] , [string] , [string] ) [EOL] FLAGS = tf . app . flags . FLAGS [EOL] [EOL] [EOL] def main ( _ ) : [EOL] if len ( sys . argv ) < [number] or sys . argv [ - [number] ] . startswith ( [string] ) : [EOL] print ( [string] [string] ) [EOL] sys . exit ( - [number] ) [EOL] if FLAGS . training_iteration <= [number] : [EOL] print ( [string] ) [EOL] sys . exit ( - [number] ) [EOL] if FLAGS . model_version <= [number] : [EOL] print ( [string] ) [EOL] sys . exit ( - [number] ) [EOL] [EOL] [comment] [EOL] print ( [string] ) [EOL] mnist = mnist_input_data . read_data_sets ( FLAGS . work_dir , one_hot = True ) [EOL] sess = tf . InteractiveSession ( ) [EOL] serialized_tf_example = tf . placeholder ( tf . string , name = [string] ) [EOL] feature_configs = { [string] : tf . FixedLenFeature ( shape = [ [number] ] , dtype = tf . float32 ) , } [EOL] tf_example = tf . parse_example ( serialized_tf_example , feature_configs ) [EOL] x = tf . identity ( tf_example [ [string] ] , name = [string] ) [comment] [EOL] y_ = tf . placeholder ( [string] , shape = [ None , [number] ] ) [EOL] w = tf . Variable ( tf . zeros ( [ [number] , [number] ] ) ) [EOL] b = tf . Variable ( tf . zeros ( [ [number] ] ) ) [EOL] sess . run ( tf . global_variables_initializer ( ) ) [EOL] y = tf . nn . softmax ( tf . matmul ( x , w ) + b , name = [string] ) [EOL] cross_entropy = - tf . reduce_sum ( y_ * tf . log ( y ) ) [EOL] train_step = tf . train . GradientDescentOptimizer ( [number] ) . minimize ( cross_entropy ) [EOL] values , indices = tf . nn . top_k ( y , [number] ) [EOL] table = tf . contrib . lookup . index_to_string_table_from_tensor ( tf . constant ( [ str ( i ) for i in range ( [number] ) ] ) ) [EOL] prediction_classes = table . lookup ( tf . to_int64 ( indices ) ) [EOL] for _ in range ( FLAGS . training_iteration ) : [EOL] batch = mnist . train . next_batch ( [number] ) [EOL] train_step . run ( feed_dict = { x : batch [ [number] ] , y_ : batch [ [number] ] } ) [EOL] correct_prediction = tf . equal ( tf . argmax ( y , [number] ) , tf . argmax ( y_ , [number] ) ) [EOL] accuracy = tf . reduce_mean ( tf . cast ( correct_prediction , [string] ) ) [EOL] print ( [string] % sess . run ( accuracy , feed_dict = { x : mnist . test . images , y_ : mnist . test . labels } ) ) [EOL] print ( [string] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] export_path_base = sys . argv [ - [number] ] [EOL] export_path = os . path . join ( tf . compat . as_bytes ( export_path_base ) , tf . compat . as_bytes ( str ( FLAGS . model_version ) ) ) [EOL] print ( [string] , export_path ) [EOL] builder = tf . saved_model . builder . SavedModelBuilder ( export_path ) [EOL] [EOL] [comment] [EOL] classification_inputs = tf . saved_model . utils . build_tensor_info ( serialized_tf_example ) [EOL] classification_outputs_classes = tf . saved_model . utils . build_tensor_info ( prediction_classes ) [EOL] classification_outputs_scores = tf . saved_model . utils . build_tensor_info ( values ) [EOL] [EOL] classification_signature = ( tf . saved_model . signature_def_utils . build_signature_def ( inputs = { tf . saved_model . signature_constants . CLASSIFY_INPUTS : classification_inputs } , outputs = { tf . saved_model . signature_constants . CLASSIFY_OUTPUT_CLASSES : classification_outputs_classes , tf . saved_model . signature_constants . CLASSIFY_OUTPUT_SCORES : classification_outputs_scores } , method_name = tf . saved_model . signature_constants . CLASSIFY_METHOD_NAME ) ) [EOL] [EOL] tensor_info_x = tf . saved_model . utils . build_tensor_info ( x ) [EOL] tensor_info_y = tf . saved_model . utils . build_tensor_info ( y ) [EOL] [EOL] prediction_signature = ( tf . saved_model . signature_def_utils . build_signature_def ( inputs = { [string] : tensor_info_x } , outputs = { [string] : tensor_info_y } , method_name = tf . saved_model . signature_constants . PREDICT_METHOD_NAME ) ) [EOL] [EOL] builder . add_meta_graph_and_variables ( sess , [ tf . saved_model . tag_constants . SERVING ] , signature_def_map = { [string] : prediction_signature , tf . saved_model . signature_constants . DEFAULT_SERVING_SIGNATURE_DEF_KEY : classification_signature , } , main_op = tf . tables_initializer ( ) , strip_default_attrs = True ) [EOL] [EOL] builder . save ( ) [EOL] [EOL] print ( [string] ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] tf . app . run ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] from typing import Any , Tuple [EOL] import argparse [EOL] import typing [EOL] [docstring] [EOL] from __future__ import absolute_import [EOL] from __future__ import division [EOL] from __future__ import print_function [EOL] [EOL] import warnings [EOL] warnings . filterwarnings ( [string] , category = FutureWarning ) [EOL] [EOL] import argparse [EOL] import os [EOL] import sys [EOL] [EOL] import tensorflow as tf [EOL] [EOL] FLAGS = None [EOL] [EOL] [EOL] def train ( ) : [EOL] [comment] [EOL] mnist = tf . keras . datasets . mnist . load_data ( ) [EOL] [comment] [EOL] mnist = ( ( mnist [ [number] ] [ [number] ] . reshape ( [number] , [number] ) , mnist [ [number] ] [ [number] ] ) , ( mnist [ [number] ] [ [number] ] . reshape ( [number] , [number] ) , mnist [ [number] ] [ [number] ] ) ) [EOL] [EOL] sess = tf . InteractiveSession ( ) [EOL] [comment] [EOL] [EOL] [comment] [EOL] with tf . name_scope ( [string] ) : [EOL] x = tf . placeholder ( tf . float32 , [ None , [number] ] , name = [string] ) [EOL] y_ = tf . placeholder ( tf . int64 , [ None ] , name = [string] ) [EOL] [EOL] with tf . name_scope ( [string] ) : [EOL] image_shaped_input = tf . reshape ( x , [ - [number] , [number] , [number] , [number] ] ) [EOL] tf . summary . image ( [string] , image_shaped_input , [number] ) [EOL] [EOL] [comment] [EOL] def weight_variable ( shape ) : [EOL] [docstring] [EOL] initial = tf . random . truncated_normal ( shape , stddev = [number] ) [EOL] return tf . Variable ( initial ) [EOL] [EOL] def bias_variable ( shape ) : [EOL] [docstring] [EOL] initial = tf . constant ( [number] , shape = shape ) [EOL] return tf . Variable ( initial ) [EOL] [EOL] def variable_summaries ( var ) : [EOL] [docstring] [EOL] with tf . name_scope ( [string] ) : [EOL] mean = tf . reduce_mean ( var ) [EOL] tf . summary . scalar ( [string] , mean ) [EOL] with tf . name_scope ( [string] ) : [EOL] stddev = tf . sqrt ( tf . reduce_mean ( tf . square ( var - mean ) ) ) [EOL] tf . summary . scalar ( [string] , stddev ) [EOL] tf . summary . scalar ( [string] , tf . reduce_max ( var ) ) [EOL] tf . summary . scalar ( [string] , tf . reduce_min ( var ) ) [EOL] tf . summary . histogram ( [string] , var ) [EOL] [EOL] def nn_layer ( input_tensor , input_dim , output_dim , layer_name , act = tf . nn . relu ) : [EOL] [docstring] [EOL] [comment] [EOL] with tf . name_scope ( layer_name ) : [EOL] [comment] [EOL] with tf . name_scope ( [string] ) : [EOL] weights = weight_variable ( [ input_dim , output_dim ] ) [EOL] variable_summaries ( weights ) [EOL] with tf . name_scope ( [string] ) : [EOL] biases = bias_variable ( [ output_dim ] ) [EOL] variable_summaries ( biases ) [EOL] with tf . name_scope ( [string] ) : [EOL] preactivate = tf . matmul ( input_tensor , weights ) + biases [EOL] tf . summary . histogram ( [string] , preactivate ) [EOL] activations = act ( preactivate , name = [string] ) [EOL] tf . summary . histogram ( [string] , activations ) [EOL] return activations [EOL] [EOL] hidden1 = nn_layer ( x , [number] , [number] , [string] ) [EOL] [EOL] with tf . name_scope ( [string] ) : [EOL] keep_prob = tf . placeholder ( tf . float32 ) [EOL] tf . summary . scalar ( [string] , keep_prob ) [EOL] dropped = tf . nn . dropout ( hidden1 , keep_prob ) [EOL] [EOL] [comment] [EOL] y = nn_layer ( dropped , [number] , [number] , [string] , act = tf . identity ) [EOL] [EOL] with tf . name_scope ( [string] ) : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] with tf . name_scope ( [string] ) : [EOL] cross_entropy = tf . losses . sparse_softmax_cross_entropy ( labels = y_ , logits = y ) [EOL] tf . summary . scalar ( [string] , cross_entropy ) [EOL] [EOL] with tf . name_scope ( [string] ) : [EOL] train_step = tf . train . AdamOptimizer ( FLAGS . learning_rate ) . minimize ( cross_entropy ) [EOL] [EOL] with tf . name_scope ( [string] ) : [EOL] with tf . name_scope ( [string] ) : [EOL] correct_prediction = tf . equal ( tf . argmax ( y , [number] ) , y_ ) [EOL] with tf . name_scope ( [string] ) : [EOL] accuracy = tf . reduce_mean ( tf . cast ( correct_prediction , tf . float32 ) ) [EOL] tf . summary . scalar ( [string] , accuracy ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] merged = tf . summary . merge_all ( ) [EOL] train_writer = tf . summary . FileWriter ( FLAGS . log_dir + [string] , sess . graph ) [EOL] test_writer = tf . summary . FileWriter ( FLAGS . log_dir + [string] ) [EOL] tf . global_variables_initializer ( ) . run ( ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] def feed_dict ( train , num = [number] ) : [EOL] [docstring] [EOL] if train : [EOL] xs , ys = mnist [ [number] ] [ [number] ] [ num : num + [number] ] , mnist [ [number] ] [ [number] ] [ num : num + [number] ] , [EOL] k = FLAGS . dropout [EOL] else : [EOL] xs , ys = mnist [ [number] ] [ [number] ] , mnist [ [number] ] [ [number] ] [EOL] k = [number] [EOL] return { x : xs , y_ : ys , keep_prob : k } [EOL] [EOL] for i in range ( FLAGS . max_steps ) : [EOL] if i % [number] == [number] : [comment] [EOL] summary , acc = sess . run ( [ merged , accuracy ] , feed_dict = feed_dict ( False ) ) [EOL] test_writer . add_summary ( summary , i ) [EOL] print ( [string] % ( i , acc ) ) [EOL] else : [comment] [EOL] if i % [number] == [number] : [comment] [EOL] run_options = tf . RunOptions ( trace_level = tf . RunOptions . FULL_TRACE ) [EOL] run_metadata = tf . RunMetadata ( ) [EOL] summary , _ = sess . run ( [ merged , train_step ] , feed_dict = feed_dict ( True , num = ( i - ( i // [number] ) ) * [number] ) , options = run_options , run_metadata = run_metadata ) [EOL] train_writer . add_run_metadata ( run_metadata , [string] % i ) [EOL] train_writer . add_summary ( summary , i ) [EOL] print ( [string] , i ) [EOL] else : [comment] [EOL] summary , _ = sess . run ( [ merged , train_step ] , feed_dict = feed_dict ( True , num = ( i - ( i // [number] ) ) * [number] ) ) [EOL] train_writer . add_summary ( summary , i ) [EOL] train_writer . close ( ) [EOL] test_writer . close ( ) [EOL] [EOL] [EOL] def main ( _ ) : [EOL] if tf . gfile . Exists ( FLAGS . log_dir ) : [EOL] tf . gfile . DeleteRecursively ( FLAGS . log_dir ) [EOL] tf . gfile . MakeDirs ( FLAGS . log_dir ) [EOL] train ( ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] , nargs = [string] , const = True , type = bool , default = False , help = [string] ) [EOL] parser . add_argument ( [string] , type = int , default = [number] , help = [string] ) [EOL] parser . add_argument ( [string] , type = float , default = [number] , help = [string] ) [EOL] parser . add_argument ( [string] , type = float , default = [number] , help = [string] ) [EOL] parser . add_argument ( [string] , type = str , default = os . path . join ( os . getenv ( [string] , [string] ) , [string] ) , help = [string] ) [EOL] parser . add_argument ( [string] , type = str , default = os . getenv ( [string] , [string] ) , help = [string] ) [EOL] FLAGS , unparsed = parser . parse_known_args ( ) [EOL] tf . app . run ( main = main , argv = [ sys . argv [ [number] ] ] + unparsed ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import typing [EOL] import warnings [EOL] warnings . filterwarnings ( [string] , category = FutureWarning ) [EOL] import os [EOL] [EOL] import tensorflow as tf [EOL] import numpy as np [EOL] from tensorflow_serving . apis import predict_pb2 [EOL] [EOL] [EOL] tf . app . flags . DEFINE_string ( [string] , [string] , [string] ) [EOL] tf . app . flags . DEFINE_integer ( [string] , [number] , [string] ) [EOL] tf . app . flags . DEFINE_string ( [string] , [string] , [string] ) [EOL] [EOL] FLAGS = tf . app . flags . FLAGS [EOL] [EOL] [comment] [EOL] [comment] [EOL] MODEL_NAME = [string] [EOL] MODEL_SIGNATURE_NAME = [string] [EOL] MODEL_INPUT_NAME = FLAGS . model_input_name [EOL] [comment] [EOL] [EOL] [EOL] def do_conversion ( work_dir , num_tests ) : [EOL] [docstring] [EOL] conversion_out_path = os . path . join ( work_dir , [string] ) [EOL] os . makedirs ( conversion_out_path , exist_ok = True ) [EOL] [EOL] test_data_set = tf . contrib . learn . datasets . mnist . read_data_sets ( work_dir ) . test [EOL] expected_labels = [ ] [EOL] [EOL] for i in range ( num_tests ) : [EOL] request = predict_pb2 . PredictRequest ( ) [EOL] request . model_spec . name = MODEL_NAME [EOL] request . model_spec . signature_name = MODEL_SIGNATURE_NAME [EOL] image , label = test_data_set . next_batch ( [number] ) [EOL] request . inputs [ MODEL_INPUT_NAME ] . CopyFrom ( tf . contrib . util . make_tensor_proto ( image [ [number] ] , shape = [ [number] , image [ [number] ] . size ] ) ) [EOL] ser = request . SerializeToString ( ) [EOL] expected_labels . append ( label ) [EOL] [EOL] with open ( os . path . join ( conversion_out_path , [string] . format ( i ) ) , mode = [string] ) as file : [EOL] file . write ( ser ) [EOL] print ( i ) [EOL] [EOL] expected_labels = np . array ( expected_labels ) [EOL] np . save ( os . path . join ( work_dir , [string] ) , expected_labels ) [EOL] [EOL] [EOL] def main ( _ ) : [EOL] if FLAGS . num_tests > [number] : [EOL] print ( [string] ) [EOL] return [EOL] [EOL] do_conversion ( FLAGS . work_dir , FLAGS . num_tests ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] tf . app . run ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [EOL] from typing import Any , List [EOL] import python [EOL] import applications [EOL] import os [EOL] import typing [EOL] [docstring] [EOL] from __future__ import print_function [EOL] import warnings [EOL] warnings . filterwarnings ( [string] , category = FutureWarning ) [EOL] [EOL] import gzip [EOL] import os [EOL] import numpy [EOL] from six . moves import urllib [EOL] [EOL] [comment] [EOL] SOURCE_URL = [string] [EOL] TRAIN_IMAGES = [string] [EOL] TRAIN_LABELS = [string] [EOL] TEST_IMAGES = [string] [EOL] TEST_LABELS = [string] [EOL] VALIDATION_SIZE = [number] [EOL] [EOL] [EOL] def maybe_download ( filename , work_directory ) : [EOL] [docstring] [EOL] if not os . path . exists ( work_directory ) : [EOL] os . mkdir ( work_directory ) [EOL] filepath = os . path . join ( work_directory , filename ) [EOL] if not os . path . exists ( filepath ) : [EOL] filepath , _ = urllib . request . urlretrieve ( SOURCE_URL + filename , filepath ) [EOL] statinfo = os . stat ( filepath ) [EOL] print ( [string] % ( filename , statinfo . st_size ) ) [EOL] return filepath [EOL] [EOL] [EOL] def _read32 ( bytestream ) : [EOL] dt = numpy . dtype ( numpy . uint32 ) . newbyteorder ( [string] ) [EOL] return numpy . frombuffer ( bytestream . read ( [number] ) , dtype = dt ) [ [number] ] [EOL] [EOL] [EOL] def extract_images ( filename ) : [EOL] [docstring] [EOL] print ( [string] % filename ) [EOL] with gzip . open ( filename ) as bytestream : [EOL] magic = _read32 ( bytestream ) [EOL] if magic != [number] : [EOL] raise ValueError ( [string] % ( magic , filename ) ) [EOL] num_images = _read32 ( bytestream ) [EOL] rows = _read32 ( bytestream ) [EOL] cols = _read32 ( bytestream ) [EOL] buf = bytestream . read ( rows * cols * num_images ) [EOL] data = numpy . frombuffer ( buf , dtype = numpy . uint8 ) [EOL] data = data . reshape ( num_images , rows , cols , [number] ) [EOL] return data [EOL] [EOL] [EOL] def dense_to_one_hot ( labels_dense , num_classes = [number] ) : [EOL] [docstring] [EOL] num_labels = labels_dense . shape [ [number] ] [EOL] index_offset = numpy . arange ( num_labels ) * num_classes [EOL] labels_one_hot = numpy . zeros ( ( num_labels , num_classes ) ) [EOL] labels_one_hot . flat [ index_offset + labels_dense . ravel ( ) ] = [number] [EOL] return labels_one_hot [EOL] [EOL] [EOL] def extract_labels ( filename , one_hot = False ) : [EOL] [docstring] [EOL] print ( [string] % filename ) [EOL] with gzip . open ( filename ) as bytestream : [EOL] magic = _read32 ( bytestream ) [EOL] if magic != [number] : [EOL] raise ValueError ( [string] % ( magic , filename ) ) [EOL] num_items = _read32 ( bytestream ) [EOL] buf = bytestream . read ( num_items ) [EOL] labels = numpy . frombuffer ( buf , dtype = numpy . uint8 ) [EOL] if one_hot : [EOL] return dense_to_one_hot ( labels ) [EOL] return labels [EOL] [EOL] [EOL] class DataSet ( object ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , images , labels , fake_data = False , one_hot = False ) : [EOL] [docstring] [EOL] [EOL] if fake_data : [EOL] self . _num_examples = [number] [EOL] self . one_hot = one_hot [EOL] else : [EOL] assert images . shape [ [number] ] == labels . shape [ [number] ] , ( [string] % ( images . shape , labels . shape ) ) [EOL] self . _num_examples = images . shape [ [number] ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] assert images . shape [ [number] ] == [number] [EOL] images = images . reshape ( images . shape [ [number] ] , images . shape [ [number] ] * images . shape [ [number] ] ) [EOL] [comment] [EOL] images = images . astype ( numpy . float32 ) [EOL] images = numpy . multiply ( images , [number] / [number] ) [EOL] self . _images = images [EOL] self . _labels = labels [EOL] self . _epochs_completed = [number] [EOL] self . _index_in_epoch = [number] [EOL] [EOL] @ property def images ( self ) : [EOL] return self . _images [EOL] [EOL] @ property def labels ( self ) : [EOL] return self . _labels [EOL] [EOL] @ property def num_examples ( self ) : [EOL] return self . _num_examples [EOL] [EOL] @ property def epochs_completed ( self ) : [EOL] return self . _epochs_completed [EOL] [EOL] def next_batch ( self , batch_size , fake_data = False ) : [EOL] [docstring] [EOL] if fake_data : [EOL] fake_image = [ [number] ] * [number] [EOL] if self . one_hot : [EOL] fake_label = [ [number] ] + [ [number] ] * [number] [EOL] else : [EOL] fake_label = [number] [EOL] return [ fake_image for _ in range ( batch_size ) ] , [ fake_label for _ in range ( batch_size ) ] [EOL] start = self . _index_in_epoch [EOL] self . _index_in_epoch += batch_size [EOL] if self . _index_in_epoch > self . _num_examples : [EOL] [comment] [EOL] self . _epochs_completed += [number] [EOL] [comment] [EOL] perm = numpy . arange ( self . _num_examples ) [EOL] numpy . random . shuffle ( perm ) [EOL] self . _images = self . _images [ perm ] [EOL] self . _labels = self . _labels [ perm ] [EOL] [comment] [EOL] start = [number] [EOL] self . _index_in_epoch = batch_size [EOL] assert batch_size <= self . _num_examples [EOL] end = self . _index_in_epoch [EOL] return self . _images [ start : end ] , self . _labels [ start : end ] [EOL] [EOL] [EOL] def read_data_sets ( train_dir , fake_data = False , one_hot = False ) : [EOL] [docstring] [EOL] [EOL] class DataSets ( object ) : [EOL] pass [EOL] [EOL] data_sets = DataSets ( ) [EOL] [EOL] if fake_data : [EOL] data_sets . train = DataSet ( [ ] , [ ] , fake_data = True , one_hot = one_hot ) [EOL] data_sets . validation = DataSet ( [ ] , [ ] , fake_data = True , one_hot = one_hot ) [EOL] data_sets . test = DataSet ( [ ] , [ ] , fake_data = True , one_hot = one_hot ) [EOL] return data_sets [EOL] [EOL] local_file = maybe_download ( TRAIN_IMAGES , train_dir ) [EOL] train_images = extract_images ( local_file ) [EOL] [EOL] local_file = maybe_download ( TRAIN_LABELS , train_dir ) [EOL] train_labels = extract_labels ( local_file , one_hot = one_hot ) [EOL] [EOL] local_file = maybe_download ( TEST_IMAGES , train_dir ) [EOL] test_images = extract_images ( local_file ) [EOL] [EOL] local_file = maybe_download ( TEST_LABELS , train_dir ) [EOL] test_labels = extract_labels ( local_file , one_hot = one_hot ) [EOL] [EOL] validation_images = train_images [ : VALIDATION_SIZE ] [EOL] validation_labels = train_labels [ : VALIDATION_SIZE ] [EOL] train_images = train_images [ VALIDATION_SIZE : ] [EOL] train_labels = train_labels [ VALIDATION_SIZE : ] [EOL] [EOL] data_sets . train = DataSet ( train_images , train_labels ) [EOL] data_sets . validation = DataSet ( validation_images , validation_labels ) [EOL] data_sets . test = DataSet ( test_images , test_labels ) [EOL] [EOL] return data_sets [EOL] [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import python [EOL] import threading [EOL] import applications [EOL] import typing [EOL] import warnings [EOL] warnings . filterwarnings ( [string] , category = FutureWarning ) [EOL] import sys [EOL] import threading [EOL] import os [EOL] import numpy as np [EOL] import tensorflow as tf [EOL] [EOL] from tensorflow_serving . apis import predict_pb2 [EOL] [EOL] [EOL] tf . app . flags . DEFINE_integer ( [string] , [number] , [string] ) [EOL] tf . app . flags . DEFINE_integer ( [string] , [number] , [string] ) [EOL] tf . app . flags . DEFINE_string ( [string] , [string] , [string] ) [EOL] tf . app . flags . DEFINE_string ( [string] , [string] , [string] ) [EOL] [EOL] FLAGS = tf . app . flags . FLAGS [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] MODEL_OUTPUT_NAME = [string] [EOL] [EOL] [EOL] class _ResultCounter ( object ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , num_tests , concurrency ) : [EOL] self . _num_tests = num_tests [EOL] self . _concurrency = concurrency [EOL] self . _error = [number] [EOL] self . _done = [number] [EOL] self . _active = [number] [EOL] self . _condition = threading . Condition ( ) [EOL] [EOL] def inc_error ( self ) : [EOL] with self . _condition : [EOL] self . _error += [number] [EOL] [EOL] def inc_done ( self ) : [EOL] with self . _condition : [EOL] self . _done += [number] [EOL] self . _condition . notify ( ) [EOL] [EOL] def dec_active ( self ) : [EOL] with self . _condition : [EOL] self . _active -= [number] [EOL] self . _condition . notify ( ) [EOL] [EOL] def get_error_rate ( self ) : [EOL] with self . _condition : [EOL] while self . _done != self . _num_tests : [EOL] self . _condition . wait ( ) [EOL] return self . _error / float ( self . _num_tests ) [EOL] [EOL] def throttle ( self ) : [EOL] with self . _condition : [EOL] while self . _active == self . _concurrency : [EOL] self . _condition . wait ( ) [EOL] self . _active += [number] [EOL] [EOL] [EOL] def _create_rpc_callback ( label , result_counter ) : [EOL] [docstring] [EOL] [EOL] def _callback ( result_future ) : [EOL] [docstring] [EOL] sys . stdout . write ( [string] ) [EOL] sys . stdout . flush ( ) [EOL] [EOL] response = np . array ( result_future . result ( ) . outputs [ MODEL_OUTPUT_NAME ] . float_val ) [EOL] prediction = np . argmax ( response ) [EOL] if label != prediction : [EOL] result_counter . inc_error ( ) [EOL] result_counter . inc_done ( ) [EOL] result_counter . dec_active ( ) [EOL] [EOL] return _callback [EOL] [EOL] [EOL] def do_inference ( work_dir , concurrency , num_tests , input_dir ) : [EOL] [docstring] [EOL] expected_labels = np . load ( os . path . join ( work_dir , [string] ) ) [EOL] result_counter = _ResultCounter ( num_tests , concurrency ) [EOL] for i in range ( num_tests ) : [EOL] result_counter . throttle ( ) [EOL] [EOL] sys . stdout . write ( [string] ) [EOL] sys . stdout . flush ( ) [EOL] [EOL] with open ( os . path . join ( input_dir , [string] . format ( i ) ) , mode = [string] ) as pb_file : [EOL] result_pb = pb_file . read ( ) [EOL] [EOL] resp = predict_pb2 . PredictResponse ( ) [EOL] [EOL] resp . ParseFromString ( result_pb ) [EOL] [EOL] response = np . array ( resp . outputs [ MODEL_OUTPUT_NAME ] . float_val ) [EOL] prediction = np . argmax ( response ) [EOL] [EOL] if expected_labels [ i ] != prediction : [EOL] result_counter . inc_error ( ) [EOL] result_counter . inc_done ( ) [EOL] result_counter . dec_active ( ) [EOL] [EOL] return result_counter . get_error_rate ( ) [EOL] [EOL] [EOL] def main ( _ ) : [EOL] if FLAGS . num_tests > [number] : [EOL] print ( [string] ) [EOL] return [EOL] [EOL] error_rate = do_inference ( FLAGS . work_dir , FLAGS . concurrency , FLAGS . num_tests , FLAGS . input_dir ) [EOL] print ( [string] . format ( ( error_rate * [number] ) ) ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] tf . app . run ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $threading.Condition$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , List [EOL] import argparse [EOL] import typing [EOL] [docstring] [EOL] import warnings [EOL] warnings . filterwarnings ( [string] , category = FutureWarning ) [EOL] import argparse [EOL] import datetime [EOL] from random import randint [EOL] import os [EOL] import numpy as np [EOL] import tensorflow as tf [EOL] [EOL] [comment] [EOL] TESTING_START = [number] [EOL] TESTING_STOP = [number] [EOL] TRAINING_START = [number] [EOL] TRAINING_STOP = [number] [EOL] BATCH_SIZE = [number] [EOL] LSTM_UNITS = [number] [EOL] NUM_CLASSES = [number] [EOL] ITERATIONS = [number] [EOL] MAX_SEQ_LENGTH = [number] [comment] [EOL] NUM_DIMENSIONS = [number] [comment] [EOL] DROPOUT = [number] [EOL] TESTING_SIZE = TESTING_STOP - TESTING_START [EOL] [EOL] [EOL] def main ( _ ) : [EOL] [comment] [EOL] if not os . path . exists ( FLAGS . data_dir ) : [EOL] print ( [string] . format ( FLAGS . data_dir ) ) [EOL] exit ( [number] ) [EOL] [EOL] if FLAGS . export_dir == [string] : [EOL] FLAGS . export_dir = os . getcwd ( ) [EOL] [EOL] if not os . path . exists ( FLAGS . export_dir ) : [EOL] print ( [string] . format ( FLAGS . export_dir ) ) [EOL] exit ( [number] ) [EOL] [EOL] try : [EOL] word_vectors = np . load ( os . path . join ( FLAGS . data_dir , [string] ) ) [EOL] print ( [string] ) [EOL] except Exception : [EOL] print ( [string] ) [EOL] [EOL] [comment] [EOL] try : [EOL] ids = np . load ( os . path . join ( FLAGS . data_dir , [string] ) ) [EOL] print ( [string] ) [EOL] except Exception : [EOL] print ( [string] ) [EOL] [EOL] [comment] [EOL] labels = tf . placeholder ( tf . float32 , [ BATCH_SIZE , NUM_CLASSES ] ) [EOL] input_data = tf . placeholder ( tf . int32 , [ BATCH_SIZE , MAX_SEQ_LENGTH ] ) [EOL] keep_prob = tf . placeholder ( tf . float32 ) [EOL] [EOL] data = tf . Variable ( tf . zeros ( [ BATCH_SIZE , MAX_SEQ_LENGTH , NUM_DIMENSIONS ] ) , dtype = tf . float32 ) [EOL] data = tf . nn . embedding_lookup ( word_vectors , input_data ) [EOL] [EOL] lstm_cell = tf . contrib . rnn . BasicLSTMCell ( LSTM_UNITS ) [EOL] lstm_cell = tf . contrib . rnn . DropoutWrapper ( cell = lstm_cell , output_keep_prob = keep_prob ) [EOL] value , _ = tf . nn . dynamic_rnn ( lstm_cell , data , dtype = tf . float32 ) [EOL] [EOL] weight = tf . Variable ( tf . truncated_normal ( [ LSTM_UNITS , NUM_CLASSES ] ) ) [EOL] bias = tf . Variable ( tf . constant ( [number] , shape = [ NUM_CLASSES ] ) ) [EOL] value = tf . transpose ( value , [ [number] , [number] , [number] ] ) [EOL] last = tf . gather ( value , int ( value . get_shape ( ) [ [number] ] ) - [number] ) [EOL] prediction = ( tf . matmul ( last , weight ) + bias ) [EOL] [EOL] correct_pred = tf . equal ( tf . argmax ( prediction , [number] ) , tf . argmax ( labels , [number] ) ) [EOL] accuracy = tf . reduce_mean ( tf . cast ( correct_pred , tf . float32 ) ) [EOL] [EOL] loss = tf . reduce_mean ( tf . nn . softmax_cross_entropy_with_logits ( logits = prediction , labels = labels ) ) [EOL] optimizer = tf . train . AdamOptimizer ( ) . minimize ( loss ) [EOL] [EOL] sess = tf . InteractiveSession ( ) [EOL] [EOL] tf . summary . scalar ( [string] , loss ) [EOL] tf . summary . scalar ( [string] , accuracy ) [EOL] merged = tf . summary . merge_all ( ) [EOL] logdir = os . path . join ( [string] , [string] . format ( datetime . datetime . now ( ) . strftime ( [string] ) ) ) [EOL] writer = tf . summary . FileWriter ( logdir , sess . graph ) [EOL] [EOL] saver = tf . train . Saver ( ) [EOL] sess . run ( tf . global_variables_initializer ( ) ) [EOL] [EOL] [comment] [EOL] def get_train_batch ( ) : [EOL] labels = [ ] [EOL] arr = np . zeros ( [ BATCH_SIZE , MAX_SEQ_LENGTH ] ) [EOL] for i in range ( BATCH_SIZE ) : [EOL] if i % [number] == [number] : [EOL] num = randint ( TRAINING_START , TESTING_START ) [EOL] labels . append ( [ [number] , [number] ] ) [EOL] else : [EOL] num = randint ( TESTING_STOP , TRAINING_STOP ) [EOL] labels . append ( [ [number] , [number] ] ) [EOL] arr [ i ] = ids [ num - [number] : num ] [EOL] return arr , labels [EOL] [EOL] def get_test_batch ( ) : [EOL] labels = [ ] [EOL] arr = np . zeros ( [ BATCH_SIZE , MAX_SEQ_LENGTH ] ) [EOL] for i in range ( BATCH_SIZE ) : [EOL] num = randint ( TESTING_START , TESTING_STOP ) [EOL] if num <= [number] : [EOL] labels . append ( [ [number] , [number] ] ) [comment] [EOL] else : [EOL] labels . append ( [ [number] , [number] ] ) [comment] [EOL] arr [ i ] = ids [ num - [number] : num ] [EOL] return arr , labels [EOL] [EOL] [comment] [EOL] for i in range ( ITERATIONS ) : [EOL] [comment] [EOL] next_batch , next_batch_labels = get_train_batch ( ) [EOL] sess . run ( optimizer , { input_data : next_batch , labels : next_batch_labels , keep_prob : DROPOUT } ) [EOL] [EOL] [comment] [EOL] if i % [number] == [number] : [EOL] summary = sess . run ( merged , { input_data : next_batch , labels : next_batch_labels , keep_prob : [number] } ) [EOL] writer . add_summary ( summary , i ) [EOL] [EOL] [comment] [EOL] if i % [number] == [number] : [EOL] train_acc , train_loss = sess . run ( [ accuracy , loss ] , { input_data : next_batch , labels : next_batch_labels , keep_prob : [number] } ) [EOL] print ( [string] , train_acc , [string] , train_loss ) [EOL] [EOL] [comment] [EOL] if i % [number] == [number] and i != [number] : [EOL] save_path = saver . save ( sess , os . path . join ( FLAGS . export_dir , [string] ) , global_step = i ) [EOL] print ( [string] . format ( save_path ) ) [EOL] writer . close ( ) [EOL] [EOL] [comment] [EOL] accuracy_list = [ ] [EOL] [EOL] for i in range ( TESTING_SIZE // BATCH_SIZE ) : [EOL] next_batch , next_batch_labels = get_test_batch ( ) [EOL] temp_accuracy_val = sess . run ( accuracy , { input_data : next_batch , labels : next_batch_labels , keep_prob : [number] } ) [EOL] accuracy_list . append ( temp_accuracy_val ) [EOL] [EOL] print ( [string] , sum ( accuracy_list ) / len ( accuracy_list ) ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] , type = str , default = [string] , help = [string] ) [EOL] parser . add_argument ( [string] , type = str , default = [string] , help = [string] ) [EOL] FLAGS , _ = parser . parse_known_args ( ) [EOL] tf . app . run ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 $builtins.int$ 0 0 0 0 $builtins.float$ 0 0 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import List , Dict , Literal , Any , Tuple , Optional [EOL] import argparse [EOL] import typing [EOL] import typing_extensions [EOL] import warnings [EOL] warnings . filterwarnings ( [string] , category = FutureWarning ) [EOL] import json [EOL] import argparse [EOL] import os [EOL] import time [EOL] [EOL] import tensorflow as tf [EOL] from tensorflow . examples . tutorials . mnist import input_data [EOL] [EOL] [comment] [EOL] EXPERIMENT_OUTPUT_PATH = [string] [EOL] [EOL] FLAGS = tf . app . flags . FLAGS [EOL] [EOL] [comment] [EOL] [comment] [EOL] INPUT_NAME = [string] [EOL] SCORES_NAME = [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] MODEL_SIGNATURE_NAME = [string] [EOL] MODEL_INPUT_NAME = [string] [EOL] MODEL_OUTPUT_NAME = [string] [EOL] MODEL_VERSION = [number] [EOL] [EOL] [EOL] def parse_tf_config ( ) : [EOL] tf_config = os . environ . get ( [string] ) [EOL] if not tf_config : [EOL] raise RuntimeError ( [string] ) [EOL] [EOL] tf_config_json = json . loads ( tf_config ) [EOL] [EOL] cluster = tf_config_json . get ( [string] ) [EOL] job_name = tf_config_json . get ( [string] , { } ) . get ( [string] ) [EOL] task_index = tf_config_json . get ( [string] , { } ) . get ( [string] ) [EOL] [EOL] if job_name is None or task_index is None : [EOL] raise RuntimeError ( [string] ) [EOL] [EOL] allowed_job_names = ( [string] , [string] ) [EOL] [EOL] if job_name not in allowed_job_names : [EOL] raise RuntimeError ( [string] . format ( job_name = job_name , allowed_job_names = allowed_job_names ) ) [EOL] [EOL] return cluster , job_name , task_index [EOL] [EOL] [EOL] def build_net ( images_placeholder , dense_dropout_placeholder ) : [EOL] [docstring] [EOL] images_input = tf . reshape ( images_placeholder , [ - [number] , [number] , [number] , [number] ] ) [EOL] [EOL] conv_1 = tf . layers . conv2d ( images_input , filters = [number] , kernel_size = [number] , activation = tf . nn . relu , padding = [string] ) [EOL] pool_1 = tf . layers . max_pooling2d ( conv_1 , pool_size = [ [number] , [number] ] , strides = [ [number] , [number] ] , padding = [string] ) [EOL] [EOL] conv_2 = tf . layers . conv2d ( pool_1 , filters = [number] , kernel_size = [number] , activation = tf . nn . relu , padding = [string] ) [EOL] pool_2 = tf . layers . max_pooling2d ( conv_2 , pool_size = [ [number] , [number] ] , strides = [ [number] , [number] ] , padding = [string] ) [EOL] [EOL] dense_input = tf . reshape ( pool_2 , [ - [number] , [number] * [number] * [number] ] ) [EOL] dense_1 = tf . layers . dense ( dense_input , [number] , activation = tf . nn . relu ) [EOL] dense_1_drop = tf . nn . dropout ( dense_1 , dense_dropout_placeholder ) [EOL] [EOL] logits = tf . layers . dense ( dense_1_drop , [number] ) [EOL] logits = tf . identity ( logits ) [EOL] [EOL] [comment] [EOL] scores = tf . nn . softmax ( logits , name = SCORES_NAME ) [EOL] [EOL] predictions = tf . argmax ( logits , axis = [number] ) [EOL] [EOL] return logits , scores , predictions [EOL] [EOL] def convert_to_session ( session ) : [EOL] while type ( session ) . __name__ != [string] : [EOL] session = session . _sess [EOL] return session [EOL] [EOL] def convert_to_session ( session ) : [EOL] while type ( session ) . __name__ != [string] : [EOL] session = session . _sess [EOL] return session [EOL] [EOL] [EOL] def main ( _ ) : [EOL] cluster , job_name , task_index = parse_tf_config ( ) [EOL] [EOL] [comment] [EOL] cluster_spec = tf . train . ClusterSpec ( cluster ) [EOL] [EOL] [comment] [EOL] server = tf . train . Server ( cluster_spec , job_name = job_name , task_index = task_index ) [EOL] [EOL] if job_name == [string] : [EOL] server . join ( ) [EOL] return [EOL] [EOL] [comment] [EOL] with tf . device ( tf . train . replica_device_setter ( worker_device = [string] . format ( task_index = task_index ) , cluster = cluster ) ) : [EOL] [comment] [EOL] images_placeholder = tf . placeholder ( tf . float32 , [ None , [number] ] , name = INPUT_NAME ) [EOL] [EOL] dense_dropout_placeholder = tf . placeholder_with_default ( [number] , [ ] ) [EOL] labels_placeholder = tf . placeholder ( tf . int64 , [ None ] ) [EOL] [EOL] logits , scores , predictions = build_net ( images_placeholder , dense_dropout_placeholder ) [EOL] [EOL] loss = tf . losses . softmax_cross_entropy ( tf . one_hot ( labels_placeholder , [number] ) , logits ) [EOL] global_step = tf . train . get_or_create_global_step ( ) [EOL] accuracy = tf . reduce_mean ( tf . cast ( tf . equal ( predictions , labels_placeholder ) , tf . float32 ) ) [EOL] [EOL] tf . summary . scalar ( [string] , loss ) [EOL] tf . summary . scalar ( [string] , accuracy ) [EOL] tf . summary . merge_all ( ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] summary_dir = os . path . join ( EXPERIMENT_OUTPUT_PATH , [string] ) [EOL] [EOL] [comment] [EOL] tf . global_variables_initializer ( ) [EOL] saver = tf . train . Saver ( ) [EOL] [EOL] [comment] [EOL] tf . train . export_meta_graph ( [string] , as_text = True ) [EOL] [EOL] is_chief = task_index == [number] [EOL] [EOL] train_op = tf . train . AdagradOptimizer ( [number] ) . minimize ( loss , global_step = global_step ) [EOL] hooks = [ tf . train . StopAtStepHook ( last_step = [number] ) ] [EOL] [EOL] [comment] [EOL] mnist = input_data . read_data_sets ( FLAGS . data_dir ) [EOL] [EOL] with tf . train . MonitoredTrainingSession ( master = server . target , is_chief = ( task_index == [number] ) , hooks = hooks , summary_dir = summary_dir ) as mon_sess : [EOL] [EOL] [EOL] step = [number] [EOL] while not mon_sess . should_stop ( ) and step < [number] : [EOL] batch_xs , batch_ys = mnist . train . next_batch ( FLAGS . batch_size ) [EOL] train_feed = { images_placeholder : batch_xs , labels_placeholder : batch_ys } [EOL] [EOL] _ , step , accuracy_val = mon_sess . run ( [ train_op , global_step , accuracy ] , feed_dict = train_feed ) [EOL] if step % [number] == [number] : [EOL] print ( [string] % step ) [EOL] print ( [string] . format ( accuracy_val ) ) [EOL] [EOL] session = convert_to_session ( mon_sess ) [EOL] [comment] [EOL] if is_chief : [EOL] saver . save ( session , os . path . join ( EXPERIMENT_OUTPUT_PATH , [string] , [string] ) , global_step = step ) [EOL] [EOL] [comment] [EOL] tf . get_default_graph ( ) . _unsafe_unfinalize ( ) [EOL] [EOL] [comment] [EOL] export_path = os . path . join ( EXPERIMENT_OUTPUT_PATH , str ( MODEL_VERSION ) ) [EOL] print ( [string] , export_path ) [EOL] builder = tf . saved_model . builder . SavedModelBuilder ( export_path ) [EOL] [EOL] prediction_signature = ( tf . saved_model . signature_def_utils . build_signature_def ( inputs = { MODEL_INPUT_NAME : tf . saved_model . utils . build_tensor_info ( images_placeholder ) } , outputs = { MODEL_OUTPUT_NAME : tf . saved_model . utils . build_tensor_info ( scores ) } , method_name = tf . saved_model . signature_constants . PREDICT_METHOD_NAME ) ) [EOL] [EOL] builder . add_meta_graph_and_variables ( session , [ tf . saved_model . tag_constants . SERVING ] , signature_def_map = { MODEL_SIGNATURE_NAME : prediction_signature } , main_op = tf . tables_initializer ( ) , clear_devices = True , strip_default_attrs = True ) [EOL] [EOL] builder . save ( ) [EOL] [EOL] [comment] [EOL] time . sleep ( [number] ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] , type = str , default = [string] , help = [string] ) [EOL] parser . add_argument ( [string] , type = int , default = [number] , help = [string] ) [EOL] FLAGS , _ = parser . parse_known_args ( ) [EOL] tf . app . run ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import builtins [EOL] import typing [EOL] import sys [EOL] [EOL] from keras . datasets import imdb [EOL] from keras . preprocessing . text import Tokenizer [EOL] from keras . preprocessing import sequence [EOL] [EOL] [EOL] def vectorize_text ( text , maxlen = [number] , max_features = [number] ) : [EOL] word_index = imdb . get_word_index ( ) [EOL] tokenizer = Tokenizer ( ) [EOL] tokenizer . word_index = word_index [EOL] vectorized_texts = tokenizer . texts_to_sequences ( [ text ] ) [EOL] vectorized_texts = [ [ v for v in vectorized_texts [ [number] ] if v < max_features ] ] [comment] [EOL] vectorized_texts = sequence . pad_sequences ( vectorized_texts , maxlen = maxlen ) [EOL] return vectorized_texts [ [number] ] . tolist ( ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] if len ( sys . argv ) < [number] : [EOL] print ( f' [string] { sys . argv [ [number] ] } [string] ' ) [EOL] exit ( [number] ) [EOL] vectorized_text = vectorize_text ( [string] . join ( sys . argv [ [number] : ] ) ) [EOL] print ( f' [string] { vectorized_text } [string] ' ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [EOL] [EOL] import builtins [EOL] import argparse [EOL] import multiprocessing [EOL] import os [EOL] [EOL] import keras [EOL] from keras . preprocessing import sequence [EOL] from keras . models import Sequential [EOL] from keras . layers import Dense , Dropout , Activation [EOL] from keras . layers import Embedding [EOL] from keras . layers import Conv1D , GlobalMaxPooling1D [EOL] from keras . datasets import imdb [EOL] from keras import backend as K [EOL] from keras_preprocessing . sequence import _remove_long_seq [EOL] from tensorflow import saved_model [EOL] import tensorflow as tf [EOL] import numpy as np [EOL] [EOL] try : [EOL] from experiment_metrics . api import publish [EOL] except ImportError : [EOL] print ( [string] ) [EOL] publish = print [comment] [EOL] [EOL] [EOL] class TensorflowModelCheckpoint ( keras . callbacks . ModelCheckpoint ) : [EOL] [docstring] [EOL] def __init__ ( self , * args , ** kwargs ) : [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] self . saver = tf . train . Saver ( ) [EOL] [EOL] def on_epoch_end ( self , epoch , logs = None ) : [EOL] super ( ) . on_epoch_end ( epoch , logs ) [EOL] sess = keras . backend . get_session ( ) [EOL] self . saver . save ( sess , self . filepath . replace ( [string] , str ( epoch ) ) . replace ( [string] , [string] ) ) [EOL] [EOL] [EOL] class NautaExperimentMetricsCallback ( keras . callbacks . Callback ) : [EOL] def on_epoch_end ( self , epoch , logs = None ) : [EOL] publish ( { [string] : str ( logs . get ( [string] ) ) , [string] : str ( logs . get ( [string] ) ) [ : [number] ] , [string] : str ( logs . get ( [string] ) ) , [string] : str ( logs . get ( [string] ) ) [ : [number] ] } ) [EOL] [EOL] [EOL] [EOL] def load_data ( dataset_path = None , num_words = None , skip_top = [number] , maxlen = None , seed = [number] , start_char = [number] , oov_char = [number] , index_from = [number] ) : [EOL] print ( [string] ) [EOL] if dataset_path : [EOL] with np . load ( dataset_path ) as f : [EOL] x_train , labels_train = f [ [string] ] , f [ [string] ] [EOL] x_test , labels_test = f [ [string] ] , f [ [string] ] [EOL] [EOL] np . random . seed ( seed ) [EOL] indices = np . arange ( len ( x_train ) ) [EOL] np . random . shuffle ( indices ) [EOL] x_train = x_train [ indices ] [EOL] labels_train = labels_train [ indices ] [EOL] [EOL] indices = np . arange ( len ( x_test ) ) [EOL] np . random . shuffle ( indices ) [EOL] x_test = x_test [ indices ] [EOL] labels_test = labels_test [ indices ] [EOL] [EOL] xs = np . concatenate ( [ x_train , x_test ] ) [EOL] labels = np . concatenate ( [ labels_train , labels_test ] ) [EOL] [EOL] if start_char is not None : [EOL] xs = [ [ start_char ] + [ w + index_from for w in x ] for x in xs ] [EOL] elif index_from : [EOL] xs = [ [ w + index_from for w in x ] for x in xs ] [EOL] [EOL] if maxlen : [EOL] xs , labels = _remove_long_seq ( maxlen , xs , labels ) [EOL] if not xs : [EOL] raise ValueError ( [string] + str ( maxlen ) + [string] [string] ) [EOL] if not num_words : [EOL] num_words = max ( [ max ( x ) for x in xs ] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] if oov_char is not None : [EOL] xs = [ [ w if ( skip_top <= w < num_words ) else oov_char for w in x ] for x in xs ] [EOL] else : [EOL] xs = [ [ w for w in x if skip_top <= w < num_words ] for x in xs ] [EOL] [EOL] idx = len ( x_train ) [EOL] x_train , y_train = np . array ( xs [ : idx ] ) , np . array ( labels [ : idx ] ) [EOL] x_test , y_test = np . array ( xs [ idx : ] ) , np . array ( labels [ idx : ] ) [EOL] [EOL] print ( len ( x_train ) , [string] ) [EOL] print ( len ( x_test ) , [string] ) [EOL] return x_train , y_train , x_test , y_test [EOL] else : [EOL] ( x_train , y_train ) , ( x_test , y_test ) = imdb . load_data ( num_words = num_words ) [EOL] print ( len ( x_train ) , [string] ) [EOL] print ( len ( x_test ) , [string] ) [EOL] return x_train , y_train , x_test , y_test [EOL] [EOL] [EOL] def preprocess_data ( x_train , x_test ) : [EOL] print ( [string] ) [EOL] x_train = sequence . pad_sequences ( x_train , maxlen = maxlen ) [EOL] x_test = sequence . pad_sequences ( x_test , maxlen = maxlen ) [EOL] print ( [string] , x_train . shape ) [EOL] print ( [string] , x_test . shape ) [EOL] return x_train , x_test [EOL] [EOL] [EOL] def create_model ( ) : [EOL] print ( [string] ) [EOL] model = Sequential ( ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] model . add ( Embedding ( max_features , embedding_dims , input_length = maxlen ) ) [EOL] model . add ( Dropout ( [number] ) ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] model . add ( Conv1D ( filters , kernel_size , padding = [string] , activation = [string] , strides = [number] ) ) [EOL] [comment] [EOL] model . add ( GlobalMaxPooling1D ( ) ) [EOL] [EOL] [comment] [EOL] model . add ( Dense ( hidden_dims ) ) [EOL] model . add ( Dropout ( [number] ) ) [EOL] model . add ( Activation ( [string] ) ) [EOL] [EOL] [comment] [EOL] model . add ( Dense ( [number] ) ) [EOL] model . add ( Activation ( [string] ) ) [EOL] [EOL] model . compile ( loss = [string] , optimizer = [string] , metrics = [ [string] ] ) [EOL] return model [EOL] [EOL] [EOL] def train ( model , x_train , y_train , x_test , y_test , output_path = None ) : [EOL] if not output_path : [EOL] output_path = [string] [EOL] [EOL] print ( model . summary ( ) ) [EOL] [EOL] callbacks = [ ] [EOL] callbacks . append ( TensorflowModelCheckpoint ( f'{ output_path } [string] ' ) ) [EOL] callbacks . append ( NautaExperimentMetricsCallback ( ) ) [EOL] callbacks . append ( keras . callbacks . TensorBoard ( log_dir = f'{ output_path } [string] ' , update_freq = [number] , histogram_freq = [number] , write_graph = True ) ) [EOL] [EOL] model . fit ( x_train , y_train , batch_size = batch_size , epochs = epochs , callbacks = callbacks , validation_data = ( x_test , y_test ) ) [EOL] [EOL] return model [EOL] [EOL] [EOL] def save_model ( model , output_path = None , model_name = [string] ) : [EOL] if not output_path : [EOL] output_path = os . path . join ( os . getcwd ( ) , [string] ) [EOL] [EOL] [comment] [EOL] if not os . path . isdir ( output_path ) : [EOL] os . makedirs ( output_path ) [EOL] model_path = os . path . join ( output_path , model_name ) [EOL] model . save ( model_path ) [EOL] print ( f' [string] { model_path }' ) [EOL] [EOL] sess = K . get_session ( ) [EOL] tf_model_export_dir = f'{ output_path } [string] ' [EOL] saved_model . simple_save ( session = sess , export_dir = tf_model_export_dir , inputs = { [string] : model . layers [ [number] ] . input } , outputs = { [string] : model . layers [ - [number] ] . output } ) [EOL] [EOL] def parse_args ( ) : [EOL] parser = argparse . ArgumentParser ( [string] ) [EOL] parser . add_argument ( [string] , default = [number] ) [EOL] parser . add_argument ( [string] , default = [number] ) [EOL] parser . add_argument ( [string] , default = [number] ) [EOL] parser . add_argument ( [string] , default = [number] ) [EOL] parser . add_argument ( [string] , default = [number] ) [EOL] parser . add_argument ( [string] , default = [number] ) [EOL] parser . add_argument ( [string] , help = [string] [string] , default = None , type = str ) [EOL] parser . add_argument ( [string] , help = [string] , default = None , type = str ) [EOL] parser . add_argument ( [string] , help = [string] [string] , default = None ) [EOL] return parser . parse_args ( ) [EOL] [EOL] if __name__ == [string] : [EOL] args = parse_args ( ) [EOL] [EOL] [comment] [EOL] if not args . cpu_count : [EOL] args . cpu_count = multiprocessing . cpu_count ( ) [EOL] config = tf . ConfigProto ( intra_op_parallelism_threads = int ( args . cpu_count ) , inter_op_parallelism_threads = [number] , allow_soft_placement = True , device_count = { [string] : int ( args . cpu_count ) } ) [EOL] session = tf . Session ( config = config ) [EOL] K . set_session ( session ) [EOL] os . environ [ [string] ] = str ( args . cpu_count ) [EOL] os . environ [ [string] ] = [string] [EOL] os . environ [ [string] ] = [string] [EOL] os . environ [ [string] ] = [string] [EOL] [EOL] [comment] [EOL] max_features = [number] [EOL] maxlen = [number] [EOL] batch_size = int ( args . batch_size ) [EOL] embedding_dims = int ( args . embedding_dims ) [EOL] filters = int ( args . filters ) [EOL] kernel_size = int ( args . kernel_size ) [EOL] hidden_dims = int ( args . hidden_dims ) [EOL] epochs = int ( args . epochs ) [EOL] [EOL] x_train , y_train , x_test , y_test = load_data ( dataset_path = args . dataset_path , num_words = max_features ) [EOL] x_train , x_test = preprocess_data ( x_train , x_test ) [EOL] model = create_model ( ) [EOL] model = train ( model , x_train , y_train , x_test , y_test , output_path = args . output_path ) [EOL] save_model ( model = model , output_path = args . output_path ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] import keras [EOL] import builtins [EOL] import argparse [EOL] import multiprocessing [EOL] import os [EOL] from keras . datasets . cifar import load_batch [EOL] [EOL] import keras [EOL] from keras . models import Sequential [EOL] from keras . layers import Dense , Dropout , Activation , Flatten [EOL] from keras . layers import Conv2D , MaxPooling2D [EOL] import keras . backend as K [EOL] from tensorflow import saved_model [EOL] import tensorflow as tf [EOL] import numpy as np [EOL] [EOL] try : [EOL] from experiment_metrics . api import publish [EOL] except ImportError : [EOL] print ( [string] ) [EOL] publish = print [comment] [EOL] [EOL] [EOL] class TensorflowModelCheckpoint ( keras . callbacks . ModelCheckpoint ) : [EOL] [docstring] [EOL] def __init__ ( self , * args , ** kwargs ) : [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] self . saver = tf . train . Saver ( ) [EOL] [EOL] def on_epoch_end ( self , epoch , logs = None ) : [EOL] super ( ) . on_epoch_end ( epoch , logs ) [EOL] sess = keras . backend . get_session ( ) [EOL] self . saver . save ( sess , self . filepath . replace ( [string] , str ( epoch ) ) . replace ( [string] , [string] ) ) [EOL] [EOL] [EOL] class NautaExperimentMetricsCallback ( keras . callbacks . Callback ) : [EOL] def on_epoch_end ( self , epoch , logs = None ) : [EOL] publish ( { [string] : str ( logs . get ( [string] ) ) , [string] : str ( logs . get ( [string] ) ) , [string] : str ( logs . get ( [string] ) ) , [string] : str ( logs . get ( [string] ) ) } ) [EOL] [EOL] [EOL] def load_data ( dataset_path = None , label_mode = [string] ) : [EOL] if dataset_path : [EOL] fpath = os . path . join ( dataset_path , [string] ) [EOL] x_train , y_train = load_batch ( fpath , label_key = label_mode + [string] ) [EOL] [EOL] fpath = os . path . join ( dataset_path , [string] ) [EOL] x_test , y_test = load_batch ( fpath , label_key = label_mode + [string] ) [EOL] [EOL] y_train = np . reshape ( y_train , ( len ( y_train ) , [number] ) ) [EOL] y_test = np . reshape ( y_test , ( len ( y_test ) , [number] ) ) [EOL] [EOL] if K . image_data_format ( ) == [string] : [EOL] x_train = x_train . transpose ( [number] , [number] , [number] , [number] ) [EOL] x_test = x_test . transpose ( [number] , [number] , [number] , [number] ) [EOL] [EOL] return x_train , y_train , x_test , y_test [EOL] else : [EOL] ( x_train , y_train ) , ( x_test , y_test ) = keras . datasets . cifar100 . load_data ( label_mode = [string] ) [EOL] return x_train , y_train , x_test , y_test [EOL] [EOL] [EOL] def create_model ( input_shape , num_classes = [number] ) : [EOL] [docstring] [EOL] model = Sequential ( ) [EOL] model . add ( Conv2D ( [number] , ( [number] , [number] ) , padding = [string] , input_shape = input_shape ) ) [EOL] model . add ( Activation ( [string] ) ) [EOL] model . add ( Conv2D ( [number] , ( [number] , [number] ) ) ) [EOL] model . add ( Activation ( [string] ) ) [EOL] model . add ( MaxPooling2D ( pool_size = ( [number] , [number] ) ) ) [EOL] model . add ( Dropout ( [number] ) ) [EOL] [EOL] model . add ( Conv2D ( [number] , ( [number] , [number] ) , padding = [string] ) ) [EOL] model . add ( Activation ( [string] ) ) [EOL] model . add ( Conv2D ( [number] , ( [number] , [number] ) ) ) [EOL] model . add ( Activation ( [string] ) ) [EOL] model . add ( MaxPooling2D ( pool_size = ( [number] , [number] ) ) ) [EOL] model . add ( Dropout ( [number] ) ) [EOL] [EOL] model . add ( Flatten ( ) ) [EOL] model . add ( Dense ( [number] ) ) [EOL] model . add ( Activation ( [string] ) ) [EOL] model . add ( Dropout ( [number] ) ) [EOL] model . add ( Dense ( num_classes ) ) [EOL] model . add ( Activation ( [string] ) ) [EOL] return model [EOL] [EOL] [EOL] def train ( dataset_path = None , batch_size = [number] , epochs = [number] , use_horovod = False , output_path = None , model_name = [string] ) : [EOL] x_train , y_train , x_test , y_test = load_data ( dataset_path ) [EOL] print ( [string] , x_train . shape ) [EOL] print ( x_train . shape [ [number] ] , [string] ) [EOL] print ( x_test . shape [ [number] ] , [string] ) [EOL] [EOL] num_classes = [number] [EOL] [EOL] if not output_path : [EOL] output_path = os . path . join ( os . getcwd ( ) , [string] ) [EOL] [EOL] [comment] [EOL] y_train = keras . utils . to_categorical ( y_train , num_classes ) [EOL] y_test = keras . utils . to_categorical ( y_test , num_classes ) [EOL] [EOL] model = create_model ( input_shape = x_train . shape [ [number] : ] , num_classes = num_classes ) [EOL] if use_horovod : [EOL] import horovod . keras as hvd [EOL] hvd . init ( ) [EOL] opt = keras . optimizers . rmsprop ( lr = [number] * hvd . size ( ) , decay = [number] ) [EOL] opt = hvd . DistributedOptimizer ( opt ) [EOL] with tf . Graph ( ) . as_default ( ) : [EOL] inference_model = create_model ( input_shape = x_train . shape [ [number] : ] , num_classes = num_classes ) [EOL] inference_dummy_opt = keras . optimizers . rmsprop ( lr = [number] , decay = [number] ) [EOL] inference_model . compile ( loss = [string] , optimizer = inference_dummy_opt , metrics = [ [string] ] ) [EOL] else : [EOL] opt = keras . optimizers . rmsprop ( lr = [number] , decay = [number] ) [EOL] inference_model = model [EOL] [EOL] [comment] [EOL] serve_graph_file = f'{ output_path } [string] ' [EOL] tf . train . export_meta_graph ( serve_graph_file , as_text = True ) [EOL] [EOL] model . compile ( loss = [string] , optimizer = opt , metrics = [ [string] ] ) [EOL] [EOL] x_train = x_train . astype ( [string] ) [EOL] x_test = x_test . astype ( [string] ) [EOL] x_train /= [number] [EOL] x_test /= [number] [EOL] [EOL] model . summary ( ) [EOL] [EOL] callbacks = [ ] [EOL] if use_horovod : [EOL] callbacks . append ( hvd . callbacks . BroadcastGlobalVariablesCallback ( [number] ) ) [EOL] [comment] [EOL] if not use_horovod or hvd . rank ( ) == [number] : [EOL] callbacks . append ( TensorflowModelCheckpoint ( f'{ output_path } [string] ' ) ) [EOL] callbacks . append ( NautaExperimentMetricsCallback ( ) ) [EOL] callbacks . append ( keras . callbacks . TensorBoard ( log_dir = f'{ output_path } [string] ' , update_freq = [number] , histogram_freq = [number] , write_graph = True ) ) [EOL] [EOL] [EOL] model . fit ( x_train , y_train , batch_size = batch_size , epochs = epochs , validation_data = ( x_test , y_test ) , shuffle = True , callbacks = callbacks ) [EOL] [EOL] [comment] [EOL] if not os . path . isdir ( output_path ) : [EOL] os . makedirs ( output_path ) [EOL] model_path = os . path . join ( output_path , model_name ) [EOL] model . save ( model_path ) [EOL] print ( f' [string] { model_path }' ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] if not use_horovod or hvd . rank ( ) == [number] : [EOL] [comment] [EOL] [comment] [EOL] checkpoint_file = tf . train . latest_checkpoint ( output_path ) [EOL] tf_model_export_dir = f'{ output_path } [string] ' [EOL] [comment] [EOL] with tf . Graph ( ) . as_default ( ) : [EOL] [comment] [EOL] restorer = tf . train . import_meta_graph ( serve_graph_file ) [EOL] with tf . Session ( ) as sess : [EOL] restorer . restore ( sess , checkpoint_file ) [EOL] saved_model . simple_save ( session = sess , export_dir = tf_model_export_dir , inputs = { [string] : inference_model . layers [ [number] ] . input } , outputs = { [string] : inference_model . layers [ - [number] ] . output } ) [EOL] print ( f' [string] { tf_model_export_dir }' ) [EOL] [EOL] [comment] [EOL] scores = model . evaluate ( x_test , y_test , verbose = [number] ) [EOL] print ( [string] , scores [ [number] ] ) [EOL] print ( [string] , scores [ [number] ] ) [EOL] [EOL] [EOL] def parse_args ( ) : [EOL] parser = argparse . ArgumentParser ( description = [string] ) [EOL] parser . add_argument ( [string] , default = [number] , type = int ) [EOL] parser . add_argument ( [string] , default = [number] , type = int ) [EOL] parser . add_argument ( [string] , help = [string] , default = False , action = [string] ) [EOL] parser . add_argument ( [string] , help = [string] , default = False , action = [string] ) [EOL] parser . add_argument ( [string] , help = [string] [string] , default = None , type = str ) [EOL] parser . add_argument ( [string] , help = [string] , default = None , type = str ) [EOL] parser . add_argument ( [string] , help = [string] [string] , default = None ) [EOL] return parser . parse_args ( ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] args = parse_args ( ) [EOL] [comment] [EOL] if not args . cpu_count : [EOL] args . cpu_count = multiprocessing . cpu_count ( ) [EOL] config = tf . ConfigProto ( intra_op_parallelism_threads = int ( args . cpu_count ) , inter_op_parallelism_threads = [number] , allow_soft_placement = True , device_count = { [string] : int ( args . cpu_count ) } ) [EOL] session = tf . Session ( config = config ) [EOL] K . set_session ( session ) [EOL] os . environ [ [string] ] = str ( args . cpu_count ) [EOL] os . environ [ [string] ] = [string] [EOL] os . environ [ [string] ] = [string] [EOL] os . environ [ [string] ] = [string] [EOL] train ( dataset_path = args . dataset_path , epochs = args . epochs , batch_size = args . batch_size , use_horovod = args . use_horovod , output_path = args . output_path ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] from typing import Any , List [EOL] import typing [EOL] [docstring] [EOL] [EOL] from __future__ import absolute_import [EOL] from __future__ import division [EOL] from __future__ import print_function [EOL] [EOL] import tensorflow as tf [EOL] [EOL] _R_MEAN = [number] [EOL] _G_MEAN = [number] [EOL] _B_MEAN = [number] [EOL] _CHANNEL_MEANS = [ _R_MEAN , _G_MEAN , _B_MEAN ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] _RESIZE_MIN = [number] [EOL] [EOL] [EOL] def _decode_crop_and_flip ( image_buffer , bbox , num_channels ) : [EOL] [docstring] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] sample_distorted_bounding_box = tf . image . sample_distorted_bounding_box ( tf . image . extract_jpeg_shape ( image_buffer ) , bounding_boxes = bbox , min_object_covered = [number] , aspect_ratio_range = [ [number] , [number] ] , area_range = [ [number] , [number] ] , max_attempts = [number] , use_image_if_no_bounding_boxes = True ) [EOL] bbox_begin , bbox_size , _ = sample_distorted_bounding_box [EOL] [EOL] [comment] [EOL] offset_y , offset_x , _ = tf . unstack ( bbox_begin ) [EOL] target_height , target_width , _ = tf . unstack ( bbox_size ) [EOL] crop_window = tf . stack ( [ offset_y , offset_x , target_height , target_width ] ) [EOL] [EOL] [comment] [EOL] cropped = tf . image . decode_and_crop_jpeg ( image_buffer , crop_window , channels = num_channels ) [EOL] [EOL] [comment] [EOL] cropped = tf . image . random_flip_left_right ( cropped ) [EOL] return cropped [EOL] [EOL] [EOL] def _central_crop ( image , crop_height , crop_width ) : [EOL] [docstring] [EOL] shape = tf . shape ( image ) [EOL] height , width = shape [ [number] ] , shape [ [number] ] [EOL] [EOL] amount_to_be_cropped_h = ( height - crop_height ) [EOL] crop_top = amount_to_be_cropped_h // [number] [EOL] amount_to_be_cropped_w = ( width - crop_width ) [EOL] crop_left = amount_to_be_cropped_w // [number] [EOL] return tf . slice ( image , [ crop_top , crop_left , [number] ] , [ crop_height , crop_width , - [number] ] ) [EOL] [EOL] [EOL] def _mean_image_subtraction ( image , means , num_channels ) : [EOL] [docstring] [EOL] if image . get_shape ( ) . ndims != [number] : [EOL] raise ValueError ( [string] ) [EOL] [EOL] if len ( means ) != num_channels : [EOL] raise ValueError ( [string] ) [EOL] [EOL] [comment] [EOL] means = tf . expand_dims ( tf . expand_dims ( means , [number] ) , [number] ) [EOL] [EOL] return image - means [EOL] [EOL] [EOL] def _smallest_size_at_least ( height , width , resize_min ) : [EOL] [docstring] [EOL] resize_min = tf . cast ( resize_min , tf . float32 ) [EOL] [EOL] [comment] [EOL] height , width = tf . cast ( height , tf . float32 ) , tf . cast ( width , tf . float32 ) [EOL] [EOL] smaller_dim = tf . minimum ( height , width ) [EOL] scale_ratio = resize_min / smaller_dim [EOL] [EOL] [comment] [EOL] new_height = tf . cast ( height * scale_ratio , tf . int32 ) [EOL] new_width = tf . cast ( width * scale_ratio , tf . int32 ) [EOL] [EOL] return new_height , new_width [EOL] [EOL] [EOL] def _aspect_preserving_resize ( image , resize_min ) : [EOL] [docstring] [EOL] shape = tf . shape ( image ) [EOL] height , width = shape [ [number] ] , shape [ [number] ] [EOL] [EOL] new_height , new_width = _smallest_size_at_least ( height , width , resize_min ) [EOL] [EOL] return _resize_image ( image , new_height , new_width ) [EOL] [EOL] [EOL] def _resize_image ( image , height , width ) : [EOL] [docstring] [EOL] return tf . image . resize_images ( image , [ height , width ] , method = tf . image . ResizeMethod . BILINEAR , align_corners = False ) [EOL] [EOL] [EOL] def preprocess_image ( image_buffer , bbox , output_height , output_width , num_channels , is_training = False ) : [EOL] [docstring] [EOL] if is_training : [EOL] [comment] [EOL] image = _decode_crop_and_flip ( image_buffer , bbox , num_channels ) [EOL] image = _resize_image ( image , output_height , output_width ) [EOL] else : [EOL] [comment] [EOL] image = tf . image . decode_jpeg ( image_buffer , channels = num_channels ) [EOL] image = _aspect_preserving_resize ( image , _RESIZE_MIN ) [EOL] image = _central_crop ( image , output_height , output_width ) [EOL] [EOL] image . set_shape ( [ output_height , output_width , num_channels ] ) [EOL] [EOL] return _mean_image_subtraction ( image , _CHANNEL_MEANS , num_channels ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 $typing.List[builtins.float]$ 0 0 $builtins.float$ 0 $builtins.float$ 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.float]$ 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] import builtins [EOL] from typing import Any , List , Tuple [EOL] import typing [EOL] [docstring] [EOL] [EOL] from __future__ import absolute_import [EOL] from __future__ import division [EOL] from __future__ import print_function [EOL] [EOL] import tensorflow as tf [EOL] [EOL] _BATCH_NORM_DECAY = [number] [EOL] _BATCH_NORM_EPSILON = [number] [EOL] DEFAULT_VERSION = [number] [EOL] DEFAULT_DTYPE = tf . float32 [EOL] CASTABLE_TYPES = ( tf . float16 , ) [EOL] ALLOWED_TYPES = ( DEFAULT_DTYPE , ) + CASTABLE_TYPES [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] def batch_norm ( inputs , training , data_format ) : [EOL] [docstring] [EOL] [comment] [EOL] [comment] [EOL] return tf . layers . batch_normalization ( inputs = inputs , axis = [number] if data_format == [string] else [number] , momentum = _BATCH_NORM_DECAY , epsilon = _BATCH_NORM_EPSILON , center = True , scale = True , training = training , fused = True ) [EOL] [EOL] [EOL] def fixed_padding ( inputs , kernel_size , data_format ) : [EOL] [docstring] [EOL] pad_total = kernel_size - [number] [EOL] pad_beg = pad_total // [number] [EOL] pad_end = pad_total - pad_beg [EOL] [EOL] if data_format == [string] : [EOL] padded_inputs = tf . pad ( inputs , [ [ [number] , [number] ] , [ [number] , [number] ] , [ pad_beg , pad_end ] , [ pad_beg , pad_end ] ] ) [EOL] else : [EOL] padded_inputs = tf . pad ( inputs , [ [ [number] , [number] ] , [ pad_beg , pad_end ] , [ pad_beg , pad_end ] , [ [number] , [number] ] ] ) [EOL] return padded_inputs [EOL] [EOL] [EOL] def conv2d_fixed_padding ( inputs , filters , kernel_size , strides , data_format ) : [EOL] [docstring] [EOL] [comment] [EOL] [comment] [EOL] if strides > [number] : [EOL] inputs = fixed_padding ( inputs , kernel_size , data_format ) [EOL] [EOL] return tf . layers . conv2d ( inputs = inputs , filters = filters , kernel_size = kernel_size , strides = strides , padding = ( [string] if strides == [number] else [string] ) , use_bias = False , kernel_initializer = tf . variance_scaling_initializer ( ) , data_format = data_format ) [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] def _building_block_v1 ( inputs , filters , training , projection_shortcut , strides , data_format ) : [EOL] [docstring] [EOL] shortcut = inputs [EOL] [EOL] if projection_shortcut is not None : [EOL] shortcut = projection_shortcut ( inputs ) [EOL] shortcut = batch_norm ( inputs = shortcut , training = training , data_format = data_format ) [EOL] [EOL] inputs = conv2d_fixed_padding ( inputs = inputs , filters = filters , kernel_size = [number] , strides = strides , data_format = data_format ) [EOL] inputs = batch_norm ( inputs , training , data_format ) [EOL] inputs = tf . nn . relu ( inputs ) [EOL] [EOL] inputs = conv2d_fixed_padding ( inputs = inputs , filters = filters , kernel_size = [number] , strides = [number] , data_format = data_format ) [EOL] inputs = batch_norm ( inputs , training , data_format ) [EOL] inputs += shortcut [EOL] inputs = tf . nn . relu ( inputs ) [EOL] [EOL] return inputs [EOL] [EOL] [EOL] def _building_block_v2 ( inputs , filters , training , projection_shortcut , strides , data_format ) : [EOL] [docstring] [EOL] shortcut = inputs [EOL] inputs = batch_norm ( inputs , training , data_format ) [EOL] inputs = tf . nn . relu ( inputs ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] if projection_shortcut is not None : [EOL] shortcut = projection_shortcut ( inputs ) [EOL] [EOL] inputs = conv2d_fixed_padding ( inputs = inputs , filters = filters , kernel_size = [number] , strides = strides , data_format = data_format ) [EOL] [EOL] inputs = batch_norm ( inputs , training , data_format ) [EOL] inputs = tf . nn . relu ( inputs ) [EOL] inputs = conv2d_fixed_padding ( inputs = inputs , filters = filters , kernel_size = [number] , strides = [number] , data_format = data_format ) [EOL] [EOL] return inputs + shortcut [EOL] [EOL] [EOL] def _bottleneck_block_v1 ( inputs , filters , training , projection_shortcut , strides , data_format ) : [EOL] [docstring] [EOL] shortcut = inputs [EOL] [EOL] if projection_shortcut is not None : [EOL] shortcut = projection_shortcut ( inputs ) [EOL] shortcut = batch_norm ( inputs = shortcut , training = training , data_format = data_format ) [EOL] [EOL] inputs = conv2d_fixed_padding ( inputs = inputs , filters = filters , kernel_size = [number] , strides = [number] , data_format = data_format ) [EOL] inputs = batch_norm ( inputs , training , data_format ) [EOL] inputs = tf . nn . relu ( inputs ) [EOL] [EOL] inputs = conv2d_fixed_padding ( inputs = inputs , filters = filters , kernel_size = [number] , strides = strides , data_format = data_format ) [EOL] inputs = batch_norm ( inputs , training , data_format ) [EOL] inputs = tf . nn . relu ( inputs ) [EOL] [EOL] inputs = conv2d_fixed_padding ( inputs = inputs , filters = [number] * filters , kernel_size = [number] , strides = [number] , data_format = data_format ) [EOL] inputs = batch_norm ( inputs , training , data_format ) [EOL] inputs += shortcut [EOL] inputs = tf . nn . relu ( inputs ) [EOL] [EOL] return inputs [EOL] [EOL] [EOL] def _bottleneck_block_v2 ( inputs , filters , training , projection_shortcut , strides , data_format ) : [EOL] [docstring] [EOL] shortcut = inputs [EOL] inputs = batch_norm ( inputs , training , data_format ) [EOL] inputs = tf . nn . relu ( inputs ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] if projection_shortcut is not None : [EOL] shortcut = projection_shortcut ( inputs ) [EOL] [EOL] inputs = conv2d_fixed_padding ( inputs = inputs , filters = filters , kernel_size = [number] , strides = [number] , data_format = data_format ) [EOL] [EOL] inputs = batch_norm ( inputs , training , data_format ) [EOL] inputs = tf . nn . relu ( inputs ) [EOL] inputs = conv2d_fixed_padding ( inputs = inputs , filters = filters , kernel_size = [number] , strides = strides , data_format = data_format ) [EOL] [EOL] inputs = batch_norm ( inputs , training , data_format ) [EOL] inputs = tf . nn . relu ( inputs ) [EOL] inputs = conv2d_fixed_padding ( inputs = inputs , filters = [number] * filters , kernel_size = [number] , strides = [number] , data_format = data_format ) [EOL] [EOL] return inputs + shortcut [EOL] [EOL] [EOL] def block_layer ( inputs , filters , bottleneck , block_fn , blocks , strides , training , name , data_format ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] filters_out = filters * [number] if bottleneck else filters [EOL] [EOL] def projection_shortcut ( inputs ) : [EOL] return conv2d_fixed_padding ( inputs = inputs , filters = filters_out , kernel_size = [number] , strides = strides , data_format = data_format ) [EOL] [EOL] [comment] [EOL] inputs = block_fn ( inputs , filters , training , projection_shortcut , strides , data_format ) [EOL] [EOL] for _ in range ( [number] , blocks ) : [EOL] inputs = block_fn ( inputs , filters , training , None , [number] , data_format ) [EOL] [EOL] return tf . identity ( inputs , name ) [EOL] [EOL] [EOL] class Model ( object ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , resnet_size , bottleneck , num_classes , num_filters , kernel_size , conv_stride , first_pool_size , first_pool_stride , block_sizes , block_strides , final_size , resnet_version = DEFAULT_VERSION , data_format = None , dtype = DEFAULT_DTYPE ) : [EOL] [docstring] [EOL] self . resnet_size = resnet_size [EOL] [EOL] if not data_format : [EOL] data_format = ( [string] if tf . test . is_built_with_cuda ( ) else [string] ) [EOL] [EOL] self . resnet_version = resnet_version [EOL] if resnet_version not in ( [number] , [number] ) : [EOL] raise ValueError ( [string] ) [EOL] [EOL] self . bottleneck = bottleneck [EOL] if bottleneck : [EOL] if resnet_version == [number] : [EOL] self . block_fn = _bottleneck_block_v1 [EOL] else : [EOL] self . block_fn = _bottleneck_block_v2 [EOL] else : [EOL] if resnet_version == [number] : [EOL] self . block_fn = _building_block_v1 [EOL] else : [EOL] self . block_fn = _building_block_v2 [EOL] [EOL] if dtype not in ALLOWED_TYPES : [EOL] raise ValueError ( [string] . format ( ALLOWED_TYPES ) ) [EOL] [EOL] self . data_format = data_format [EOL] self . num_classes = num_classes [EOL] self . num_filters = num_filters [EOL] self . kernel_size = kernel_size [EOL] self . conv_stride = conv_stride [EOL] self . first_pool_size = first_pool_size [EOL] self . first_pool_stride = first_pool_stride [EOL] self . block_sizes = block_sizes [EOL] self . block_strides = block_strides [EOL] self . final_size = final_size [EOL] self . dtype = dtype [EOL] [EOL] def _custom_dtype_getter ( self , getter , name , shape = None , dtype = DEFAULT_DTYPE , * args , ** kwargs ) : [EOL] [docstring] [EOL] [EOL] if dtype in CASTABLE_TYPES : [EOL] var = getter ( name , shape , tf . float32 , * args , ** kwargs ) [EOL] return tf . cast ( var , dtype = dtype , name = name + [string] ) [EOL] else : [EOL] return getter ( name , shape , dtype , * args , ** kwargs ) [EOL] [EOL] def _model_variable_scope ( self ) : [EOL] [docstring] [EOL] [EOL] return tf . variable_scope ( [string] , custom_getter = self . _custom_dtype_getter ) [EOL] [EOL] def __call__ ( self , inputs , training ) : [EOL] [docstring] [EOL] [EOL] with self . _model_variable_scope ( ) : [EOL] if self . data_format == [string] : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] inputs = tf . transpose ( inputs , [ [number] , [number] , [number] , [number] ] ) [EOL] [EOL] inputs = conv2d_fixed_padding ( inputs = inputs , filters = self . num_filters , kernel_size = self . kernel_size , strides = self . conv_stride , data_format = self . data_format ) [EOL] inputs = tf . identity ( inputs , [string] ) [EOL] [EOL] if self . first_pool_size : [EOL] inputs = tf . layers . max_pooling2d ( inputs = inputs , pool_size = self . first_pool_size , strides = self . first_pool_stride , padding = [string] , data_format = self . data_format ) [EOL] inputs = tf . identity ( inputs , [string] ) [EOL] [EOL] for i , num_blocks in enumerate ( self . block_sizes ) : [EOL] num_filters = self . num_filters * ( [number] ** i ) [EOL] inputs = block_layer ( inputs = inputs , filters = num_filters , bottleneck = self . bottleneck , block_fn = self . block_fn , blocks = num_blocks , strides = self . block_strides [ i ] , training = training , name = [string] . format ( i + [number] ) , data_format = self . data_format ) [EOL] [EOL] inputs = batch_norm ( inputs , training , self . data_format ) [EOL] inputs = tf . nn . relu ( inputs ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] axes = [ [number] , [number] ] if self . data_format == [string] else [ [number] , [number] ] [EOL] inputs = tf . reduce_mean ( inputs , axes , keepdims = True ) [EOL] inputs = tf . identity ( inputs , [string] ) [EOL] [EOL] inputs = tf . reshape ( inputs , [ - [number] , self . final_size ] ) [EOL] inputs = tf . layers . dense ( inputs = inputs , units = self . num_classes ) [EOL] inputs = tf . identity ( inputs , [string] ) [EOL] return inputs [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] from typing import Any [EOL] import typing [EOL] [docstring] [EOL] [EOL] from __future__ import absolute_import [EOL] from __future__ import division [EOL] from __future__ import print_function [EOL] [EOL] import tensorflow as tf [EOL] [EOL] [EOL] def build_tensor_serving_input_receiver_fn ( shape , dtype = tf . float32 , batch_size = [number] ) : [EOL] [docstring] [EOL] def serving_input_receiver_fn ( ) : [EOL] [comment] [EOL] features = tf . placeholder ( dtype = dtype , shape = [ batch_size ] + shape , name = [string] ) [EOL] [EOL] return tf . estimator . export . TensorServingInputReceiver ( features = features , receiver_tensors = features ) [EOL] [EOL] return serving_input_receiver_fn [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] from typing import Any , List [EOL] import typing [EOL] [docstring] [EOL] [EOL] from __future__ import absolute_import [EOL] from __future__ import division [EOL] from __future__ import print_function [EOL] [EOL] from absl import flags [EOL] [EOL] from flags . _conventions import help_wrap [EOL] [EOL] [EOL] def define_benchmark ( benchmark_log_dir = True , bigquery_uploader = True ) : [EOL] [docstring] [EOL] [EOL] key_flags = [ ] [EOL] [EOL] if benchmark_log_dir : [EOL] flags . DEFINE_string ( name = [string] , short_name = [string] , default = None , help = help_wrap ( [string] ) ) [EOL] [EOL] if bigquery_uploader : [EOL] flags . DEFINE_string ( name = [string] , short_name = [string] , default = None , help = help_wrap ( [string] ) ) [EOL] [EOL] flags . DEFINE_string ( name = [string] , short_name = [string] , default = [string] , help = help_wrap ( [string] ) ) [EOL] [EOL] flags . DEFINE_string ( name = [string] , short_name = [string] , default = [string] , help = help_wrap ( [string] [string] ) ) [EOL] [EOL] flags . DEFINE_string ( name = [string] , short_name = [string] , default = [string] , help = help_wrap ( [string] [string] ) ) [EOL] [EOL] return key_flags [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] from typing import Any [EOL] import typing [EOL] [docstring] [EOL] [EOL] from __future__ import absolute_import [EOL] from __future__ import division [EOL] from __future__ import print_function [EOL] [EOL] import functools [EOL] import sys [EOL] [EOL] from absl import app as absl_app [EOL] from absl import flags [EOL] [EOL] from flags import _base [EOL] from flags import _benchmark [EOL] from flags import _conventions [EOL] from flags import _misc [EOL] from flags import _performance [EOL] [EOL] [EOL] def set_defaults ( ** kwargs ) : [EOL] for key , value in kwargs . items ( ) : [EOL] flags . FLAGS . set_default ( name = key , value = value ) [EOL] [EOL] [EOL] def parse_flags ( argv = None ) : [EOL] [docstring] [EOL] flags . FLAGS . unparse_flags ( ) [EOL] absl_app . parse_flags_with_usage ( argv or sys . argv ) [EOL] [EOL] [EOL] def register_key_flags_in_core ( f ) : [EOL] [docstring] [EOL] [EOL] def core_fn ( * args , ** kwargs ) : [EOL] key_flags = f ( * args , ** kwargs ) [EOL] [ flags . declare_key_flag ( fl ) for fl in key_flags ] [comment] [EOL] return core_fn [EOL] [EOL] [EOL] define_base = register_key_flags_in_core ( _base . define_base ) [EOL] [comment] [EOL] define_base_eager = register_key_flags_in_core ( functools . partial ( _base . define_base , epochs_between_evals = False , stop_threshold = False , multi_gpu = False , hooks = False ) ) [EOL] define_benchmark = register_key_flags_in_core ( _benchmark . define_benchmark ) [EOL] define_image = register_key_flags_in_core ( _misc . define_image ) [EOL] define_performance = register_key_flags_in_core ( _performance . define_performance ) [EOL] [EOL] [EOL] help_wrap = _conventions . help_wrap [EOL] [EOL] [EOL] get_num_gpus = _base . get_num_gpus [EOL] get_tf_dtype = _performance . get_tf_dtype [EOL] get_loss_scale = _performance . get_loss_scale [EOL] DTYPE_MAP = _performance . DTYPE_MAP [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] from typing import Any , List [EOL] import typing [EOL] [docstring] [EOL] [EOL] from __future__ import absolute_import [EOL] from __future__ import division [EOL] from __future__ import print_function [EOL] [EOL] from absl import flags [EOL] import tensorflow as tf [EOL] [EOL] from flags . _conventions import help_wrap [EOL] from logs import hooks_helper [EOL] [EOL] [EOL] def define_base ( data_dir = True , model_dir = True , train_epochs = True , epochs_between_evals = True , stop_threshold = True , batch_size = True , multi_gpu = False , num_gpu = True , hooks = True , export_dir = True ) : [EOL] [docstring] [EOL] key_flags = [ ] [EOL] [EOL] if data_dir : [EOL] flags . DEFINE_string ( name = [string] , short_name = [string] , default = [string] , help = help_wrap ( [string] ) ) [EOL] key_flags . append ( [string] ) [EOL] [EOL] if model_dir : [EOL] flags . DEFINE_string ( name = [string] , short_name = [string] , default = [string] , help = help_wrap ( [string] ) ) [EOL] key_flags . append ( [string] ) [EOL] [EOL] if train_epochs : [EOL] flags . DEFINE_integer ( name = [string] , short_name = [string] , default = [number] , help = help_wrap ( [string] ) ) [EOL] key_flags . append ( [string] ) [EOL] [EOL] if epochs_between_evals : [EOL] flags . DEFINE_integer ( name = [string] , short_name = [string] , default = [number] , help = help_wrap ( [string] [string] ) ) [EOL] key_flags . append ( [string] ) [EOL] [EOL] if stop_threshold : [EOL] flags . DEFINE_float ( name = [string] , short_name = [string] , default = None , help = help_wrap ( [string] [string] [string] ) ) [EOL] [EOL] if batch_size : [EOL] flags . DEFINE_integer ( name = [string] , short_name = [string] , default = [number] , help = help_wrap ( [string] ) ) [EOL] key_flags . append ( [string] ) [EOL] [EOL] assert not ( multi_gpu and num_gpu ) [EOL] [EOL] if multi_gpu : [EOL] flags . DEFINE_bool ( name = [string] , default = False , help = help_wrap ( [string] ) ) [EOL] key_flags . append ( [string] ) [EOL] [EOL] if num_gpu : [EOL] flags . DEFINE_integer ( name = [string] , short_name = [string] , default = [number] if tf . test . is_gpu_available ( ) else [number] , help = help_wrap ( [string] [string] ) ) [EOL] [EOL] if hooks : [EOL] [comment] [EOL] hook_list_str = ( [string] + [string] . join ( [ [string] . format ( key ) for key in hooks_helper . HOOKS ] ) ) [EOL] flags . DEFINE_list ( name = [string] , short_name = [string] , default = [string] , help = help_wrap ( [string] [string] [string] [string] . format ( hook_list_str ) ) ) [EOL] key_flags . append ( [string] ) [EOL] [EOL] if export_dir : [EOL] flags . DEFINE_string ( name = [string] , short_name = [string] , default = None , help = help_wrap ( [string] [string] [string] ) ) [EOL] key_flags . append ( [string] ) [EOL] [EOL] return key_flags [EOL] [EOL] [EOL] def get_num_gpus ( flags_obj ) : [EOL] [docstring] [EOL] if flags_obj . num_gpus != - [number] : [EOL] return flags_obj . num_gpus [EOL] [EOL] from tensorflow . python . client import device_lib [comment] [EOL] local_device_protos = device_lib . list_local_devices ( ) [EOL] return sum ( [ [number] for d in local_device_protos if d . device_type == [string] ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] from typing import Any [EOL] import functools [EOL] import typing [EOL] [docstring] [EOL] [EOL] from __future__ import absolute_import [EOL] from __future__ import division [EOL] from __future__ import print_function [EOL] [EOL] import functools [EOL] [EOL] from absl import app as absl_app [EOL] from absl import flags [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] help_wrap = functools . partial ( flags . text_wrap , length = [number] , indent = [string] , firstline_indent = [string] ) [EOL] [EOL] [EOL] [comment] [EOL] absl_app . HelpshortFlag . SHORT_NAME = [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $functools.partial[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] from typing import Any , List [EOL] import typing [EOL] [docstring] [EOL] [EOL] from __future__ import absolute_import [EOL] from __future__ import division [EOL] from __future__ import print_function [EOL] [EOL] from absl import flags [EOL] [EOL] from flags . _conventions import help_wrap [EOL] [EOL] [EOL] def define_image ( data_format = True ) : [EOL] [docstring] [EOL] [EOL] key_flags = [ ] [EOL] [EOL] if data_format : [EOL] flags . DEFINE_enum ( name = [string] , short_name = [string] , default = None , enum_values = [ [string] , [string] ] , help = help_wrap ( [string] [string] [string] [string] [string] ) ) [EOL] key_flags . append ( [string] ) [EOL] [EOL] return key_flags [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] import builtins [EOL] from typing import Any , List , Tuple , Dict [EOL] import typing [EOL] [docstring] [EOL] [EOL] from __future__ import absolute_import [EOL] from __future__ import division [EOL] from __future__ import print_function [EOL] [EOL] import multiprocessing [EOL] [EOL] from absl import flags [comment] [EOL] import tensorflow as tf [comment] [EOL] [EOL] from flags . _conventions import help_wrap [EOL] [EOL] [EOL] [comment] [EOL] DTYPE_MAP = { [string] : ( tf . float16 , [number] ) , [string] : ( tf . float32 , [number] ) , } [EOL] [EOL] [EOL] def get_tf_dtype ( flags_obj ) : [EOL] return DTYPE_MAP [ flags_obj . dtype ] [ [number] ] [EOL] [EOL] [EOL] def get_loss_scale ( flags_obj ) : [EOL] if flags_obj . loss_scale is not None : [EOL] return flags_obj . loss_scale [EOL] return DTYPE_MAP [ flags_obj . dtype ] [ [number] ] [EOL] [EOL] [EOL] def define_performance ( num_parallel_calls = True , inter_op = True , intra_op = True , synthetic_data = True , max_train_steps = True , dtype = True ) : [EOL] [docstring] [EOL] [EOL] key_flags = [ ] [EOL] if num_parallel_calls : [EOL] flags . DEFINE_integer ( name = [string] , short_name = [string] , default = multiprocessing . cpu_count ( ) , help = help_wrap ( [string] [string] [string] [string] [string] ) ) [EOL] [EOL] if inter_op : [EOL] flags . DEFINE_integer ( name = [string] , short_name = [string] , default = [number] , help = help_wrap ( [string] [string] ) ) [EOL] [EOL] if intra_op : [EOL] flags . DEFINE_integer ( name = [string] , short_name = [string] , default = [number] , help = help_wrap ( [string] [string] ) ) [EOL] [EOL] if synthetic_data : [EOL] flags . DEFINE_bool ( name = [string] , short_name = [string] , default = False , help = help_wrap ( [string] [string] [string] ) ) [EOL] [EOL] if max_train_steps : [EOL] flags . DEFINE_integer ( name = [string] , short_name = [string] , default = None , help = help_wrap ( [string] [string] [string] [string] ) ) [EOL] [EOL] if dtype : [EOL] flags . DEFINE_enum ( name = [string] , short_name = [string] , default = [string] , enum_values = DTYPE_MAP . keys ( ) , help = help_wrap ( [string] [string] [string] ) ) [EOL] [EOL] flags . DEFINE_integer ( name = [string] , short_name = [string] , default = None , help = help_wrap ( [string] [string] [string] [string] [string] [string] [string] [string] ) ) [EOL] [EOL] loss_scale_val_msg = [string] [EOL] @ flags . validator ( flag_name = [string] , message = loss_scale_val_msg ) def _check_loss_scale ( loss_scale ) : [comment] [EOL] if loss_scale is None : [EOL] return True [comment] [EOL] [EOL] return loss_scale > [number] [EOL] [EOL] return key_flags [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [docstring] [EOL] [EOL] from __future__ import absolute_import [EOL] from __future__ import division [EOL] from __future__ import print_function [EOL] [EOL] import numbers [EOL] [EOL] import tensorflow as tf [EOL] [EOL] [EOL] def past_stop_threshold ( stop_threshold , eval_metric ) : [EOL] [docstring] [EOL] if stop_threshold is None : [EOL] return False [EOL] [EOL] if not isinstance ( stop_threshold , numbers . Number ) : [EOL] raise ValueError ( [string] ) [EOL] if not isinstance ( eval_metric , numbers . Number ) : [EOL] raise ValueError ( [string] [string] ) [EOL] [EOL] if eval_metric >= stop_threshold : [EOL] tf . logging . info ( [string] . format ( stop_threshold , eval_metric ) ) [EOL] return True [EOL] [EOL] return False [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
	0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import typing [EOL] [docstring] [EOL] [EOL] [EOL] from __future__ import absolute_import [EOL] from __future__ import division [EOL] from __future__ import print_function [EOL] [EOL] import tensorflow as tf [EOL] [EOL] [EOL] class ExamplesPerSecondHook ( tf . train . SessionRunHook ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , batch_size , every_n_steps = None , every_n_secs = None , warm_steps = [number] ) : [EOL] [docstring] [EOL] [EOL] if ( every_n_steps is None ) == ( every_n_secs is None ) : [EOL] raise ValueError ( [string] [string] ) [EOL] [EOL] self . _timer = tf . train . SecondOrStepTimer ( every_steps = every_n_steps , every_secs = every_n_secs ) [EOL] [EOL] self . _step_train_time = [number] [EOL] self . _total_steps = [number] [EOL] self . _batch_size = batch_size [EOL] self . _warm_steps = warm_steps [EOL] [EOL] def begin ( self ) : [EOL] [docstring] [EOL] self . _global_step_tensor = tf . train . get_global_step ( ) [EOL] if self . _global_step_tensor is None : [EOL] raise RuntimeError ( [string] ) [EOL] [EOL] def before_run ( self , run_context ) : [comment] [EOL] [docstring] [EOL] return tf . train . SessionRunArgs ( self . _global_step_tensor ) [EOL] [EOL] def after_run ( self , run_context , run_values ) : [comment] [EOL] [docstring] [EOL] global_step = run_values . results [EOL] [EOL] if self . _timer . should_trigger_for_step ( global_step ) and global_step > self . _warm_steps : [EOL] elapsed_time , elapsed_steps = self . _timer . update_last_triggered_step ( global_step ) [EOL] if elapsed_time is not None : [EOL] self . _step_train_time += elapsed_time [EOL] self . _total_steps += elapsed_steps [EOL] [EOL] [comment] [EOL] [comment] [EOL] average_examples_per_sec = self . _batch_size * ( self . _total_steps / self . _step_train_time ) [EOL] [comment] [EOL] [comment] [EOL] current_examples_per_sec = self . _batch_size * ( elapsed_steps / elapsed_time ) [EOL] [comment] [EOL] tf . logging . info ( [string] [string] , self . _total_steps , current_examples_per_sec , average_examples_per_sec ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $builtins.float$ 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , Union , Dict , Type [EOL] import python [EOL] import threading [EOL] import applications [EOL] import typing [EOL] [docstring] [EOL] from __future__ import absolute_import [EOL] from __future__ import division [EOL] from __future__ import print_function [EOL] [EOL] import datetime [EOL] import json [EOL] import multiprocessing [EOL] import numbers [EOL] import os [EOL] import threading [EOL] [EOL] import tensorflow as tf [EOL] from tensorflow . python . client import device_lib [EOL] [EOL] METRIC_LOG_FILE_NAME = [string] [EOL] BENCHMARK_RUN_LOG_FILE_NAME = [string] [EOL] _DATE_TIME_FORMAT_PATTERN = [string] [EOL] [EOL] [EOL] [comment] [EOL] _benchmark_logger = None [EOL] _logger_lock = threading . Lock ( ) [EOL] [EOL] [EOL] def config_benchmark_logger ( logging_dir ) : [EOL] [docstring] [EOL] _logger_lock . acquire ( ) [EOL] try : [EOL] global _benchmark_logger [EOL] if logging_dir : [EOL] _benchmark_logger = BenchmarkFileLogger ( logging_dir ) [EOL] else : [EOL] _benchmark_logger = BaseBenchmarkLogger ( ) [EOL] finally : [EOL] _logger_lock . release ( ) [EOL] return _benchmark_logger [EOL] [EOL] [EOL] def get_benchmark_logger ( ) : [EOL] if not _benchmark_logger : [EOL] config_benchmark_logger ( None ) [EOL] [EOL] return _benchmark_logger [EOL] [EOL] [EOL] class BaseBenchmarkLogger ( object ) : [EOL] [docstring] [EOL] [EOL] def log_evaluation_result ( self , eval_results ) : [EOL] [docstring] [EOL] if not isinstance ( eval_results , dict ) : [EOL] tf . logging . warning ( [string] [string] , type ( eval_results ) ) [EOL] return [EOL] global_step = eval_results [ tf . GraphKeys . GLOBAL_STEP ] [EOL] for key in sorted ( eval_results ) : [EOL] if key != tf . GraphKeys . GLOBAL_STEP : [EOL] self . log_metric ( key , eval_results [ key ] , global_step = global_step ) [EOL] [EOL] def log_metric ( self , name , value , unit = None , global_step = None , extras = None ) : [EOL] [docstring] [EOL] if not isinstance ( value , numbers . Number ) : [EOL] tf . logging . warning ( [string] , type ( value ) ) [EOL] return [EOL] extras = _convert_to_json_dict ( extras ) [EOL] [EOL] tf . logging . info ( [string] [string] , name , value , unit , global_step , extras ) [EOL] [EOL] def log_run_info ( self , model_name , dataset_name , run_params ) : [EOL] tf . logging . info ( [string] , _gather_run_info ( model_name , dataset_name , run_params ) ) [EOL] [EOL] [EOL] class BenchmarkFileLogger ( BaseBenchmarkLogger ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , logging_dir ) : [EOL] super ( BenchmarkFileLogger , self ) . __init__ ( ) [EOL] self . _logging_dir = logging_dir [EOL] if not tf . gfile . IsDirectory ( self . _logging_dir ) : [EOL] tf . gfile . MakeDirs ( self . _logging_dir ) [EOL] [EOL] def log_metric ( self , name , value , unit = None , global_step = None , extras = None ) : [EOL] [docstring] [EOL] if not isinstance ( value , numbers . Number ) : [EOL] tf . logging . warning ( [string] , type ( value ) ) [EOL] return [EOL] extras = _convert_to_json_dict ( extras ) [EOL] [EOL] with tf . gfile . GFile ( os . path . join ( self . _logging_dir , METRIC_LOG_FILE_NAME ) , [string] ) as f : [EOL] metric = { [string] : name , [string] : float ( value ) , [string] : unit , [string] : global_step , [string] : datetime . datetime . utcnow ( ) . strftime ( _DATE_TIME_FORMAT_PATTERN ) , [string] : extras } [EOL] try : [EOL] json . dump ( metric , f ) [EOL] f . write ( [string] ) [EOL] except ( TypeError , ValueError ) as e : [EOL] tf . logging . warning ( [string] [string] , name , value , e ) [EOL] [EOL] def log_run_info ( self , model_name , dataset_name , run_params ) : [EOL] [docstring] [EOL] run_info = _gather_run_info ( model_name , dataset_name , run_params ) [EOL] [EOL] with tf . gfile . GFile ( os . path . join ( self . _logging_dir , BENCHMARK_RUN_LOG_FILE_NAME ) , [string] ) as f : [EOL] try : [EOL] json . dump ( run_info , f ) [EOL] f . write ( [string] ) [EOL] except ( TypeError , ValueError ) as e : [EOL] tf . logging . warning ( [string] , e ) [EOL] [EOL] [EOL] def _gather_run_info ( model_name , dataset_name , run_params ) : [EOL] [docstring] [EOL] run_info = { [string] : model_name , [string] : { [string] : dataset_name } , [string] : { } , [string] : datetime . datetime . utcnow ( ) . strftime ( _DATE_TIME_FORMAT_PATTERN ) } [EOL] _collect_tensorflow_info ( run_info ) [EOL] _collect_tensorflow_environment_variables ( run_info ) [EOL] _collect_run_params ( run_info , run_params ) [EOL] _collect_cpu_info ( run_info ) [EOL] _collect_gpu_info ( run_info ) [EOL] _collect_memory_info ( run_info ) [EOL] return run_info [EOL] [EOL] [EOL] def _collect_tensorflow_info ( run_info ) : [EOL] run_info [ [string] ] = { [string] : tf . VERSION , [string] : tf . GIT_VERSION } [EOL] [EOL] [EOL] def _collect_run_params ( run_info , run_params ) : [EOL] [docstring] [EOL] def process_param ( name , value ) : [EOL] type_check = { str : { [string] : name , [string] : value } , int : { [string] : name , [string] : value } , bool : { [string] : name , [string] : str ( value ) } , float : { [string] : name , [string] : value } , } [EOL] return type_check . get ( type ( value ) , { [string] : name , [string] : str ( value ) } ) [EOL] if run_params : [EOL] run_info [ [string] ] = [ process_param ( k , v ) for k , v in sorted ( run_params . items ( ) ) ] [EOL] [EOL] def _collect_tensorflow_environment_variables ( run_info ) : [EOL] run_info [ [string] ] = [ { [string] : k , [string] : v } for k , v in sorted ( os . environ . items ( ) ) if k . startswith ( [string] ) ] [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] def _collect_cpu_info ( run_info ) : [EOL] [docstring] [EOL] cpu_info = { } [EOL] [EOL] cpu_info [ [string] ] = multiprocessing . cpu_count ( ) [EOL] [EOL] try : [EOL] [comment] [EOL] [comment] [EOL] import cpuinfo [comment] [EOL] [EOL] info = cpuinfo . get_cpu_info ( ) [EOL] cpu_info [ [string] ] = info [ [string] ] [EOL] cpu_info [ [string] ] = info [ [string] ] [ [number] ] / [number] [EOL] [EOL] run_info [ [string] ] [ [string] ] = cpu_info [EOL] except ImportError : [EOL] tf . logging . warn ( [string] ) [EOL] [EOL] [EOL] def _collect_gpu_info ( run_info ) : [EOL] [docstring] [EOL] gpu_info = { } [EOL] local_device_protos = device_lib . list_local_devices ( ) [EOL] [EOL] gpu_info [ [string] ] = len ( [ d for d in local_device_protos if d . device_type == [string] ] ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] for d in local_device_protos : [EOL] if d . device_type == [string] : [EOL] gpu_info [ [string] ] = _parse_gpu_model ( d . physical_device_desc ) [EOL] [comment] [EOL] break [EOL] run_info [ [string] ] [ [string] ] = gpu_info [EOL] [EOL] [EOL] def _collect_memory_info ( run_info ) : [EOL] try : [EOL] [comment] [EOL] [comment] [EOL] import psutil [comment] [EOL] vmem = psutil . virtual_memory ( ) [EOL] run_info [ [string] ] [ [string] ] = vmem . total [EOL] run_info [ [string] ] [ [string] ] = vmem . available [EOL] except ImportError : [EOL] tf . logging . warn ( [string] ) [EOL] [EOL] [EOL] def _parse_gpu_model ( physical_device_desc ) : [EOL] [comment] [EOL] for kv in physical_device_desc . split ( [string] ) : [EOL] k , _ , v = kv . partition ( [string] ) [EOL] if k . strip ( ) == [string] : [EOL] return v . strip ( ) [EOL] return None [EOL] [EOL] [EOL] def _convert_to_json_dict ( input_dict ) : [EOL] if input_dict : [EOL] return [ { [string] : k , [string] : v } for k , v in sorted ( input_dict . items ( ) ) ] [EOL] else : [EOL] return [ ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $None$ 0 0 0 $threading.Lock$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $threading.Lock$ 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 $threading.Lock$ 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import typing [EOL] from keras . datasets import mnist [EOL] import sys [EOL] import numpy [EOL] import tensorflow [EOL] [EOL] tensorflow . app . flags . DEFINE_string ( [string] , [string] , [string] ) [EOL] FLAGS = tensorflow . app . flags . FLAGS [EOL] [EOL] [EOL] def main ( _ ) : [EOL] if len ( sys . argv ) < [number] or sys . argv [ - [number] ] . startswith ( [string] ) : [EOL] print ( [string] ) [EOL] [EOL] ( x_train , y_train ) , ( x_test , y_test ) = mnist . load_data ( ) [EOL] [EOL] test_image = x_train [ int ( FLAGS . image_id ) ] . reshape ( [number] ) . astype ( numpy . float32 ) [EOL] test_image = numpy . multiply ( test_image , [number] / [number] ) [EOL] [EOL] with open ( [string] , [string] ) as output : [EOL] output . write ( [string] % ( test_image . tolist ( ) ) ) [EOL] [EOL] print ( [string] % y_train [ int ( FLAGS . image_id ) ] ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] tensorflow . app . run ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Dict , Literal , Any , Tuple , Optional [EOL] import typing [EOL] import typing_extensions [EOL] import json [EOL] import math [EOL] import os [EOL] [EOL] import tensorflow as tf [EOL] from tensorflow . examples . tutorials . mnist import input_data [EOL] [EOL] [comment] [EOL] tf . app . flags . DEFINE_integer ( [string] , [number] , [string] ) [EOL] [comment] [EOL] tf . app . flags . DEFINE_string ( [string] , [string] , [string] ) [EOL] [comment] [EOL] tf . app . flags . DEFINE_integer ( [string] , [number] , [string] ) [EOL] [EOL] [comment] [EOL] FLAGS = tf . app . flags . FLAGS [EOL] [EOL] IMAGE_PIXELS = [number] [EOL] [EOL] [EOL] def parse_tf_config ( ) : [EOL] tf_config = os . environ . get ( [string] ) [EOL] if not tf_config : [EOL] raise RuntimeError ( [string] ) [EOL] [EOL] tf_config_json = json . loads ( tf_config ) [EOL] [EOL] cluster = tf_config_json . get ( [string] ) [EOL] job_name = tf_config_json . get ( [string] , { } ) . get ( [string] ) [EOL] task_index = tf_config_json . get ( [string] , { } ) . get ( [string] ) [EOL] [EOL] if job_name is None or task_index is None : [EOL] raise RuntimeError ( [string] ) [EOL] [EOL] allowed_job_names = ( [string] , [string] ) [EOL] [EOL] if job_name not in allowed_job_names : [EOL] raise RuntimeError ( [string] . format ( job_name = job_name , allowed_job_names = allowed_job_names ) ) [EOL] [EOL] return cluster , job_name , task_index [EOL] [EOL] [EOL] def main ( _ ) : [EOL] cluster , job_name , task_index = parse_tf_config ( ) [EOL] [EOL] [comment] [EOL] cluster_spec = tf . train . ClusterSpec ( cluster ) [EOL] [EOL] [comment] [EOL] server = tf . train . Server ( cluster_spec , job_name = job_name , task_index = task_index ) [EOL] [EOL] if job_name == [string] : [EOL] server . join ( ) [EOL] return [EOL] [EOL] [comment] [EOL] with tf . device ( tf . train . replica_device_setter ( worker_device = [string] . format ( task_index = task_index ) , cluster = cluster ) ) : [EOL] [EOL] [comment] [EOL] hid_w = tf . Variable ( tf . truncated_normal ( [ IMAGE_PIXELS * IMAGE_PIXELS , FLAGS . hidden_units ] , stddev = [number] / IMAGE_PIXELS ) , name = [string] ) [EOL] hid_b = tf . Variable ( tf . zeros ( [ FLAGS . hidden_units ] ) , name = [string] ) [EOL] [EOL] [comment] [EOL] sm_w = tf . Variable ( tf . truncated_normal ( [ FLAGS . hidden_units , [number] ] , stddev = [number] / math . sqrt ( FLAGS . hidden_units ) ) , name = [string] ) [EOL] sm_b = tf . Variable ( tf . zeros ( [ [number] ] ) , name = [string] ) [EOL] [EOL] x = tf . placeholder ( tf . float32 , [ None , IMAGE_PIXELS * IMAGE_PIXELS ] ) [EOL] y_ = tf . placeholder ( tf . float32 , [ None , [number] ] ) [EOL] [EOL] hid_lin = tf . nn . xw_plus_b ( x , hid_w , hid_b ) [EOL] hid = tf . nn . relu ( hid_lin ) [EOL] [EOL] y = tf . nn . softmax ( tf . nn . xw_plus_b ( hid , sm_w , sm_b ) ) [EOL] loss = - tf . reduce_sum ( y_ * tf . log ( tf . clip_by_value ( y , [number] , [number] ) ) ) [EOL] [EOL] global_step = tf . Variable ( [number] ) [EOL] [EOL] train_op = tf . train . AdagradOptimizer ( [number] ) . minimize ( loss , global_step = global_step ) [EOL] [EOL] saver = tf . train . Saver ( ) [EOL] summary_op = tf . summary . merge_all ( ) [EOL] init_op = tf . initialize_all_variables ( ) [EOL] [EOL] [comment] [EOL] sv = tf . train . Supervisor ( is_chief = ( task_index == [number] ) , logdir = [string] , init_op = init_op , summary_op = summary_op , saver = saver , global_step = global_step , save_model_secs = [number] ) [EOL] [EOL] mnist = input_data . read_data_sets ( FLAGS . data_dir , one_hot = True ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] with sv . managed_session ( server . target ) as sess : [EOL] [comment] [EOL] step = [number] [EOL] while not sv . should_stop ( ) and step < [number] : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] batch_xs , batch_ys = mnist . train . next_batch ( FLAGS . batch_size ) [EOL] train_feed = { x : batch_xs , y_ : batch_ys } [EOL] [EOL] _ , step = sess . run ( [ train_op , global_step ] , feed_dict = train_feed ) [EOL] if step % [number] == [number] : [EOL] print ( [string] % step ) [EOL] [EOL] [comment] [EOL] sv . stop ( ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] tf . app . run ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , Union , Literal [EOL] import typing [EOL] import typing_extensions [EOL] import os [EOL] [EOL] import tensorflow as tf [EOL] import tensorflow . contrib . keras as keras [EOL] [EOL] tf . app . flags . DEFINE_string ( [string] , [string] , [string] ) [EOL] [EOL] FLAGS = tf . app . flags . FLAGS [EOL] [EOL] N_CATEGORY = [number] [EOL] WEIGHT_DECAY = [number] [EOL] MOMENTUM = [number] [EOL] BATCH_SIZE = [number] [EOL] LEARNING_RATE = [number] [EOL] DROPOUT = [number] [EOL] ALPHA = [number] [EOL] BETA = [number] [EOL] [EOL] [EOL] class LrCallback ( keras . callbacks . Callback ) : [EOL] def on_batch_end ( self , batch , logs = None ) : [EOL] lr = self . model . optimizer . lr [EOL] decay = self . model . optimizer . decay [EOL] iterations = self . model . optimizer . iterations [EOL] lr_with_decay = lr / ( [number] + decay * keras . backend . cast ( iterations , keras . backend . dtype ( decay ) ) ) [EOL] print ( [string] . format ( keras . backend . eval ( lr_with_decay ) ) ) [EOL] [EOL] [EOL] def main ( _ ) : [EOL] datagen = keras . preprocessing . image . ImageDataGenerator ( data_format = [string] ) [EOL] train_generator = datagen . flow_from_directory ( os . path . join ( FLAGS . data_dir , [string] ) , target_size = ( [number] , [number] ) , batch_size = [number] , class_mode = [string] ) [EOL] [EOL] validation_generator = datagen . flow_from_directory ( os . path . join ( FLAGS . data_dir , [string] ) , target_size = ( [number] , [number] ) , batch_size = [number] , class_mode = [string] ) [EOL] [EOL] DROPOUT = [number] [EOL] model_input = keras . layers . Input ( shape = ( [number] , [number] , [number] ) ) [EOL] [EOL] [comment] [EOL] z = keras . layers . Conv2D ( filters = [number] , kernel_size = ( [number] , [number] ) , strides = ( [number] , [number] ) , activation = [string] ) ( model_input ) [EOL] z = keras . layers . MaxPooling2D ( pool_size = ( [number] , [number] ) , strides = ( [number] , [number] ) ) ( z ) [EOL] z = keras . layers . BatchNormalization ( ) ( z ) [EOL] [EOL] [comment] [EOL] z = keras . layers . ZeroPadding2D ( padding = ( [number] , [number] ) ) ( z ) [EOL] z = keras . layers . Convolution2D ( filters = [number] , kernel_size = ( [number] , [number] ) , strides = ( [number] , [number] ) , activation = [string] ) ( z ) [EOL] z = keras . layers . MaxPooling2D ( pool_size = ( [number] , [number] ) , strides = ( [number] , [number] ) ) ( z ) [EOL] z = keras . layers . BatchNormalization ( ) ( z ) [EOL] [EOL] [comment] [EOL] z = keras . layers . ZeroPadding2D ( padding = ( [number] , [number] ) ) ( z ) [EOL] z = keras . layers . Convolution2D ( filters = [number] , kernel_size = ( [number] , [number] ) , strides = ( [number] , [number] ) , activation = [string] ) ( z ) [EOL] [EOL] z = keras . layers . ZeroPadding2D ( padding = ( [number] , [number] ) ) ( z ) [EOL] z = keras . layers . Convolution2D ( filters = [number] , kernel_size = ( [number] , [number] ) , strides = ( [number] , [number] ) , activation = [string] ) ( z ) [EOL] [EOL] z = keras . layers . ZeroPadding2D ( padding = ( [number] , [number] ) ) ( z ) [EOL] z = keras . layers . Convolution2D ( filters = [number] , kernel_size = ( [number] , [number] ) , strides = ( [number] , [number] ) , activation = [string] ) ( z ) [EOL] [EOL] z = keras . layers . MaxPooling2D ( pool_size = ( [number] , [number] ) , strides = ( [number] , [number] ) ) ( z ) [EOL] z = keras . layers . Flatten ( ) ( z ) [EOL] [EOL] z = keras . layers . Dense ( [number] , activation = [string] ) ( z ) [EOL] z = keras . layers . Dropout ( DROPOUT ) ( z ) [EOL] [EOL] z = keras . layers . Dense ( [number] , activation = [string] ) ( z ) [EOL] z = keras . layers . Dropout ( DROPOUT ) ( z ) [EOL] [EOL] final_dim = [number] if N_CATEGORY == [number] else N_CATEGORY [EOL] final_act = [string] if N_CATEGORY == [number] else [string] [EOL] model_output = keras . layers . Dense ( final_dim , activation = final_act ) ( z ) [EOL] [EOL] model = keras . models . Model ( model_input , model_output ) [EOL] model . summary ( ) [EOL] [EOL] n = [number] [EOL] k = [number] [EOL] [EOL] loss_metric = [string] if N_CATEGORY == [number] else [string] [EOL] model . compile ( loss = loss_metric , metrics = [ [string] ] , optimizer = keras . optimizers . SGD ( lr = LEARNING_RATE , momentum = MOMENTUM , decay = WEIGHT_DECAY ) ) [EOL] [EOL] res = model . fit_generator ( train_generator , epochs = [number] , steps_per_epoch = [number] // [number] , validation_data = validation_generator , validation_steps = [number] // [number] , verbose = [number] , callbacks = [ LrCallback ( ) ] ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] tf . app . run ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 $builtins.int$ 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import typing [EOL] import tensorflow . contrib . keras as keras [EOL] [EOL] [EOL] def create_generator ( path_train , path_val , batch_size = [number] ) : [EOL] datagen = keras . preprocessing . image . ImageDataGenerator ( data_format = [string] ) [EOL] train_generator = datagen . flow_from_directory ( path_train , target_size = ( [number] , [number] ) , batch_size = batch_size , class_mode = [string] ) [EOL] [EOL] validation_generator = datagen . flow_from_directory ( path_val , target_size = ( [number] , [number] ) , batch_size = batch_size , class_mode = [string] ) [EOL] return train_generator , validation_generator [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , Union , List , Literal [EOL] import typing [EOL] import typing_extensions [EOL] import os [EOL] import time [EOL] [EOL] import tensorflow as tf [EOL] import tensorflow . contrib . keras as keras [EOL] from tensorflow . python . framework . errors_impl import UnavailableError [EOL] [EOL] [comment] [EOL] [comment] [EOL] tf . app . flags . DEFINE_string ( [string] , [string] , [string] ) [EOL] tf . app . flags . DEFINE_string ( [string] , [string] , [string] ) [EOL] tf . app . flags . DEFINE_integer ( [string] , [number] , [string] ) [EOL] tf . app . flags . DEFINE_string ( [string] , [string] , [string] ) [EOL] tf . app . flags . DEFINE_string ( [string] , [string] , [string] ) [EOL] FLAGS = tf . app . flags . FLAGS [EOL] [EOL] ps_hosts = FLAGS . ps_hosts . split ( [string] ) [EOL] worker_hosts = FLAGS . worker_hosts . split ( [string] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] cluster = tf . train . ClusterSpec ( { [string] : ps_hosts , [string] : worker_hosts } ) [EOL] [EOL] [EOL] [comment] [EOL] server = tf . train . Server ( cluster , job_name = FLAGS . job_name , task_index = FLAGS . task_index ) [EOL] [EOL] [EOL] N_CATEGORY = [number] [EOL] [EOL] [EOL] def load_data ( ) : [EOL] global train_generator [EOL] global validation_generator [EOL] datagen = keras . preprocessing . image . ImageDataGenerator ( data_format = [string] ) [EOL] [EOL] train_generator = datagen . flow_from_directory ( os . path . join ( FLAGS . data_dir , [string] ) , target_size = ( [number] , [number] ) , batch_size = [number] , class_mode = [string] ) [EOL] [EOL] validation_generator = datagen . flow_from_directory ( os . path . join ( FLAGS . data_dir , [string] ) , target_size = ( [number] , [number] ) , batch_size = [number] , class_mode = [string] , shuffle = False ) [EOL] [EOL] [EOL] def create_model ( ) : [EOL] DROPOUT = [number] [EOL] model_input = keras . layers . Input ( shape = ( [number] , [number] , [number] ) ) [EOL] [EOL] [comment] [EOL] z = keras . layers . Conv2D ( filters = [number] , kernel_size = ( [number] , [number] ) , strides = ( [number] , [number] ) , activation = [string] ) ( model_input ) [EOL] z = keras . layers . MaxPooling2D ( pool_size = ( [number] , [number] ) , strides = ( [number] , [number] ) ) ( z ) [EOL] z = keras . layers . BatchNormalization ( ) ( z ) [EOL] [EOL] [comment] [EOL] z = keras . layers . ZeroPadding2D ( padding = ( [number] , [number] ) ) ( z ) [EOL] z = keras . layers . Convolution2D ( filters = [number] , kernel_size = ( [number] , [number] ) , strides = ( [number] , [number] ) , activation = [string] ) ( z ) [EOL] z = keras . layers . MaxPooling2D ( pool_size = ( [number] , [number] ) , strides = ( [number] , [number] ) ) ( z ) [EOL] z = keras . layers . BatchNormalization ( ) ( z ) [EOL] [EOL] [comment] [EOL] z = keras . layers . ZeroPadding2D ( padding = ( [number] , [number] ) ) ( z ) [EOL] z = keras . layers . Convolution2D ( filters = [number] , kernel_size = ( [number] , [number] ) , strides = ( [number] , [number] ) , activation = [string] ) ( z ) [EOL] [EOL] z = keras . layers . ZeroPadding2D ( padding = ( [number] , [number] ) ) ( z ) [EOL] z = keras . layers . Convolution2D ( filters = [number] , kernel_size = ( [number] , [number] ) , strides = ( [number] , [number] ) , activation = [string] ) ( z ) [EOL] [EOL] z = keras . layers . ZeroPadding2D ( padding = ( [number] , [number] ) ) ( z ) [EOL] z = keras . layers . Convolution2D ( filters = [number] , kernel_size = ( [number] , [number] ) , strides = ( [number] , [number] ) , activation = [string] ) ( z ) [EOL] [EOL] z = keras . layers . MaxPooling2D ( pool_size = ( [number] , [number] ) , strides = ( [number] , [number] ) ) ( z ) [EOL] z = keras . layers . Flatten ( ) ( z ) [EOL] [EOL] z = keras . layers . Dense ( [number] , activation = [string] ) ( z ) [EOL] z = keras . layers . Dropout ( DROPOUT ) ( z ) [EOL] [EOL] z = keras . layers . Dense ( [number] , activation = [string] ) ( z ) [EOL] z = keras . layers . Dropout ( DROPOUT ) ( z ) [EOL] [EOL] final_dim = [number] if N_CATEGORY == [number] else N_CATEGORY [EOL] final_act = [string] if N_CATEGORY == [number] else [string] [EOL] model_output = keras . layers . Dense ( final_dim , activation = final_act ) ( z ) [EOL] [EOL] model = keras . models . Model ( model_input , model_output ) [EOL] model . summary ( ) [EOL] return model [EOL] [EOL] [EOL] def create_optimizer ( model , targets ) : [EOL] WEIGHT_DECAY = [number] [EOL] MOMENTUM = [number] [EOL] LEARNING_RATE = [number] [EOL] [EOL] predictions = model . output [EOL] loss = tf . reduce_mean ( keras . losses . categorical_crossentropy ( targets , predictions ) ) [EOL] [EOL] [comment] [EOL] learning_rate = tf . constant ( LEARNING_RATE , dtype = tf . float32 ) [EOL] weight_decay = tf . constant ( WEIGHT_DECAY , dtype = tf . float32 ) [EOL] [EOL] lr_compute_decay = tf . multiply ( tf . cast ( global_step , dtype = tf . float32 ) , weight_decay ) [EOL] lr_compute_denominator = tf . add ( lr_compute_decay , tf . constant ( [number] , dtype = tf . float32 ) ) [EOL] lr_compute_multiplier = tf . div ( tf . constant ( [number] , dtype = tf . float32 ) , lr_compute_denominator ) [EOL] lr_operation = tf . multiply ( learning_rate , lr_compute_multiplier ) [EOL] [EOL] optimizer = tf . train . MomentumOptimizer ( learning_rate = lr_operation , momentum = MOMENTUM ) [EOL] [EOL] [comment] [EOL] with tf . control_dependencies ( model . updates ) : [EOL] barrier = tf . no_op ( name = [string] ) [EOL] [EOL] with tf . control_dependencies ( [ barrier ] ) : [EOL] grads = optimizer . compute_gradients ( loss , model . trainable_weights ) [EOL] grad_updates = optimizer . apply_gradients ( grads , global_step = global_step ) [EOL] [EOL] with tf . control_dependencies ( [ grad_updates ] ) : [EOL] train_op = tf . identity ( loss , name = [string] ) [EOL] [EOL] accuracy = tf . contrib . metrics . accuracy ( labels = tf . argmax ( targets , [number] ) , predictions = tf . argmax ( predictions , [number] ) ) [EOL] [EOL] return ( train_op , loss , predictions , accuracy , optimizer . _learning_rate ) [EOL] [EOL] [EOL] [comment] [EOL] def train ( train_op , global_step , step , accuracy , learning_rate ) : [EOL] log_frequency = [number] [EOL] start_time = time . time ( ) [EOL] batch_x , batch_y = train_generator . next ( ) [EOL] [comment] [EOL] loss_value , step_value = sess . run ( [ train_op , global_step ] , feed_dict = { model . inputs [ [number] ] : batch_x , targets : batch_y } ) [EOL] if step % log_frequency == [number] : [EOL] elapsed_time = time . time ( ) - start_time [EOL] acc = sess . run ( accuracy , feed_dict = { model . inputs [ [number] ] : batch_x , targets : batch_y } ) [EOL] [EOL] lr_val = sess . run ( learning_rate ) [EOL] [EOL] print ( [string] . format ( time . strftime ( [string] ) ) , [string] % step_value , [string] % step , [string] % loss_value , [string] % acc , [string] % float ( elapsed_time * [number] / log_frequency ) , [string] % lr_val ) [EOL] [EOL] [EOL] def validate ( epoch , total_loss , accuracy ) : [EOL] batch_test_x , batch_test_y = validation_generator . next ( ) [EOL] test_accuracies = [ ] [EOL] test_losses = [ ] [EOL] test_batch_index = [number] [EOL] while test_batch_index * [number] < [number] : [EOL] test_batch_loss , test_batch_acc = sess . run ( [ total_loss , accuracy ] , feed_dict = { model . inputs [ [number] ] : batch_test_x , targets : batch_test_y } ) [EOL] [EOL] test_accuracies . append ( test_batch_acc ) [EOL] test_losses . append ( test_batch_loss ) [EOL] [EOL] test_batch_index += [number] [EOL] [EOL] mean_test_accuracy = sum ( test_accuracies ) / test_batch_index [EOL] mean_test_loss = sum ( test_losses ) / test_batch_index [EOL] [EOL] print ( [string] [string] . format ( time . strftime ( [string] ) , epoch , mean_test_loss ) ) [EOL] print ( [string] . format ( mean_test_accuracy ) ) [EOL] [EOL] [EOL] if FLAGS . job_name == [string] : [EOL] server . join ( ) [EOL] elif FLAGS . job_name == [string] : [EOL] load_data ( ) [EOL] [EOL] [comment] [EOL] with tf . device ( tf . train . replica_device_setter ( worker_device = [string] % FLAGS . task_index , cluster = cluster ) ) : [EOL] keras . backend . set_learning_phase ( True ) [EOL] keras . backend . manual_variable_initialization ( True ) [EOL] model = create_model ( ) [EOL] targets = tf . placeholder ( tf . float32 , shape = [ None , [number] ] , name = [string] ) [EOL] global_step = tf . get_variable ( [string] , [ ] , initializer = tf . constant_initializer ( [number] ) , trainable = False ) [EOL] train_op , total_loss , predictions , accuracy , learning_rate = create_optimizer ( model , targets ) [EOL] [EOL] init_op = tf . global_variables_initializer ( ) [EOL] [EOL] saver = tf . train . Saver ( ) [EOL] sv = tf . train . Supervisor ( is_chief = ( FLAGS . task_index == [number] ) , global_step = global_step , logdir = [string] , saver = saver , save_model_secs = [number] , init_op = init_op ) [EOL] [EOL] print ( [string] ) [EOL] with sv . managed_session ( server . target ) as sess : [EOL] keras . backend . set_session ( sess ) [EOL] step = [number] [EOL] epoch = [number] [EOL] while not sv . should_stop ( ) and step < [number] : [EOL] try : [EOL] train ( train_op , global_step , step , accuracy = accuracy , learning_rate = learning_rate ) [EOL] step += [number] [EOL] if step % [number] == [number] : [EOL] keras . backend . set_learning_phase ( False ) [EOL] validate ( epoch , total_loss , accuracy = accuracy ) [EOL] epoch += [number] [EOL] keras . backend . set_learning_phase ( True ) [EOL] except UnavailableError as e : [EOL] print ( [string] . format ( e ) ) [EOL] [EOL] sv . stop ( ) [EOL] print ( [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Set , List , Dict , Any , Tuple , Optional , Pattern [EOL] import builtins [EOL] import jinja2 [EOL] import typing [EOL] import ast [EOL] import os [EOL] import re [EOL] import shutil [EOL] from typing import Tuple , List , Optional [EOL] import jinja2 [EOL] [EOL] import yaml [EOL] [EOL] [EOL] from util . logger import initialize_logger [EOL] from util . config import FOLDER_DIR_NAME [EOL] from util . config import NAUTAConfigMap , NAUTA_NAMESPACE [EOL] import packs . common as common [EOL] import dpath . util as dutil [EOL] from cli_text_consts import PacksTfTrainingTexts as Texts [EOL] from util . template import convert_k8s_cpu_resource [EOL] [EOL] log = initialize_logger ( __name__ ) [EOL] [EOL] [EOL] WORK_CNT_PARAM = [string] [EOL] P_SERV_CNT_PARAM = [string] [EOL] POD_COUNT_PARAM = [string] [EOL] [EOL] NAUTA_REGISTRY_ADDRESS = f' [string] { NAUTA_NAMESPACE } [string] ' [EOL] [EOL] [EOL] def update_configuration ( run_folder , script_location , script_parameters , experiment_name , cluster_registry_port , pack_type , username , pack_params = None , script_folder_location = None , env_variables = None ) : [EOL] [docstring] [EOL] log . debug ( [string] ) [EOL] [EOL] try : [EOL] modify_values_yaml ( run_folder , script_location , script_parameters , pack_params = pack_params , experiment_name = experiment_name , pack_type = pack_type , cluster_registry_port = cluster_registry_port , env_variables = env_variables , username = username ) [EOL] modify_dockerfile ( experiment_folder = run_folder , script_location = script_location , experiment_name = experiment_name , username = username , script_folder_location = script_folder_location ) [EOL] except Exception as exe : [EOL] log . exception ( [string] . format ( exe ) ) [EOL] raise RuntimeError ( Texts . CONFIG_NOT_UPDATED ) from exe [EOL] [EOL] log . debug ( [string] ) [EOL] [EOL] [EOL] def modify_dockerfile ( experiment_folder , experiment_name , username , script_location = None , script_folder_location = None ) : [EOL] log . debug ( [string] ) [EOL] dockerfile_name = os . path . join ( experiment_folder , [string] ) [EOL] dockerfile_temp_name = os . path . join ( experiment_folder , [string] ) [EOL] dockerfile_temp_content = [string] [EOL] [EOL] with open ( dockerfile_name , [string] ) as dockerfile : [EOL] for line in dockerfile : [EOL] if line . startswith ( [string] ) or line . startswith ( [string] ) : [EOL] if script_location or script_folder_location : [EOL] dockerfile_temp_content = dockerfile_temp_content + f" [string] { FOLDER_DIR_NAME } [string] " [EOL] elif line . startswith ( [string] ) : [EOL] nauta_config_map = NAUTAConfigMap ( ) [EOL] tf_image_name = nauta_config_map . py3_image_name [EOL] tf_image_repository = f'{ NAUTA_REGISTRY_ADDRESS } [string] { tf_image_name }' [EOL] dockerfile_temp_content = dockerfile_temp_content + f' [string] { tf_image_repository }' [EOL] [EOL] elif line . startswith ( [string] ) : [EOL] nauta_config_map = NAUTAConfigMap ( ) [EOL] horovod_image_name = nauta_config_map . py3_horovod_image_name [EOL] image_repository = f'{ NAUTA_REGISTRY_ADDRESS } [string] { horovod_image_name }' [EOL] dockerfile_temp_content = dockerfile_temp_content + f' [string] { image_repository }' [EOL] elif line . startswith ( [string] ) : [EOL] nauta_config_map = NAUTAConfigMap ( ) [EOL] pytorch_image_name = nauta_config_map . py3_pytorch_image_name [EOL] image_repository = f'{ NAUTA_REGISTRY_ADDRESS } [string] { pytorch_image_name }' [EOL] dockerfile_temp_content = dockerfile_temp_content + f' [string] { image_repository }' [EOL] elif line . startswith ( [string] ) : [EOL] nauta_config_map = NAUTAConfigMap ( ) [EOL] openvinoms_image_name = nauta_config_map . openvinoms_image_name [EOL] image_repository = f'{ NAUTA_REGISTRY_ADDRESS } [string] { openvinoms_image_name }' [EOL] dockerfile_temp_content = dockerfile_temp_content + f' [string] { image_repository }' [EOL] else : [EOL] dockerfile_temp_content = dockerfile_temp_content + line [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] dockerfile_temp_content += f' [string] { experiment_name } [string] ' [EOL] dockerfile_temp_content += f' [string] { username } [string] ' [EOL] [EOL] with open ( dockerfile_temp_name , [string] ) as dockerfile_temp : [EOL] dockerfile_temp . write ( dockerfile_temp_content ) [EOL] [EOL] shutil . move ( dockerfile_temp_name , dockerfile_name ) [EOL] log . debug ( [string] ) [EOL] [EOL] [EOL] def modify_values_yaml ( experiment_folder , script_location , script_parameters , experiment_name , pack_type , username , cluster_registry_port , pack_params = None , env_variables = None ) : [EOL] log . debug ( [string] ) [EOL] pack_params = pack_params if pack_params else [ ] [EOL] [EOL] values_yaml_filename = os . path . join ( experiment_folder , f" [string] { pack_type } [string] " ) [EOL] values_yaml_temp_filename = os . path . join ( experiment_folder , f" [string] { pack_type } [string] " ) [EOL] [EOL] with open ( values_yaml_filename , [string] ) as values_yaml_file : [EOL] [EOL] template = jinja2 . Template ( values_yaml_file . read ( ) ) [EOL] [EOL] rendered_values = template . render ( NAUTA = { [string] : experiment_name , [string] : common . prepare_script_paramaters ( script_parameters , script_location ) , [string] : str ( cluster_registry_port ) , [string] : f' [string] { cluster_registry_port } [string] { username } [string] { experiment_name } [string] ' , [string] : f' [string] { cluster_registry_port } [string] { username } [string] { experiment_name } [string] ' } ) [EOL] [EOL] v = yaml . safe_load ( rendered_values ) [EOL] [EOL] workersCount = None [EOL] pServersCount = None [EOL] [EOL] regex = re . compile ( [string] ) [comment] [EOL] for key , value in pack_params : [EOL] if re . match ( regex , value ) : [EOL] try : [EOL] value = ast . literal_eval ( value ) [EOL] except Exception as e : [EOL] raise AttributeError ( Texts . CANT_PARSE_VALUE . format ( value = value , error = e ) ) [EOL] [comment] [EOL] elif value in { [string] , [string] } : [EOL] value = str ( _parse_yaml_boolean ( value ) ) [EOL] if key == WORK_CNT_PARAM : [EOL] workersCount = value [EOL] if key == P_SERV_CNT_PARAM : [EOL] pServersCount = value [EOL] [EOL] dutil . new ( v , key , value , [string] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] if ( WORK_CNT_PARAM in v or workersCount ) and ( P_SERV_CNT_PARAM in v or pServersCount ) : [EOL] number_of_replicas = int ( v . get ( WORK_CNT_PARAM ) ) if not workersCount else int ( workersCount ) [EOL] number_of_replicas += int ( v . get ( P_SERV_CNT_PARAM ) ) if not pServersCount else int ( pServersCount ) [EOL] v [ POD_COUNT_PARAM ] = number_of_replicas [EOL] elif ( WORK_CNT_PARAM in v or workersCount ) and ( POD_COUNT_PARAM not in v ) : [EOL] number_of_replicas = int ( v . get ( WORK_CNT_PARAM ) ) if not workersCount else int ( workersCount ) [EOL] v [ POD_COUNT_PARAM ] = number_of_replicas + [number] [EOL] [EOL] env_variables = env_variables if env_variables else [ ] [EOL] parsed_envs = [ ] [EOL] for variable in env_variables : [EOL] key , value = variable . split ( [string] ) [EOL] one_env_map = { [string] : key , [string] : value } [EOL] parsed_envs . append ( one_env_map ) [EOL] [EOL] [comment] [EOL] if [string] not in ( env [ [string] ] for env in parsed_envs ) : [EOL] try : [EOL] cpu_limit = calculate_omp_num_threads ( v ) [EOL] if cpu_limit : [EOL] parsed_envs . append ( { [string] : [string] , [string] : str ( cpu_limit ) } ) [EOL] except ( ValueError , TypeError , KeyError ) : [EOL] log . exception ( [string] ) [EOL] [EOL] envs_to_set = { [string] , [string] , [string] } [comment] [EOL] for env in envs_to_set : [EOL] if dutil . search ( v , env , separator = [string] ) : [EOL] dutil . get ( v , env , separator = [string] ) . extend ( parsed_envs ) [EOL] [EOL] with open ( values_yaml_temp_filename , [string] ) as values_yaml_file : [EOL] yaml . safe_dump ( v , values_yaml_file ) [EOL] [EOL] shutil . move ( values_yaml_temp_filename , values_yaml_filename ) [EOL] log . debug ( [string] ) [EOL] [EOL] [EOL] def get_pod_count ( run_folder , pack_type ) : [EOL] log . debug ( f" [string] { run_folder }" ) [EOL] values_yaml_filename = os . path . join ( run_folder , f" [string] { pack_type } [string] " ) [EOL] [EOL] with open ( values_yaml_filename , [string] ) as values_yaml_file : [EOL] values = yaml . safe_load ( values_yaml_file ) [EOL] [EOL] pod_count = values . get ( POD_COUNT_PARAM ) [EOL] [EOL] log . debug ( f" [string] { run_folder } [string] { pod_count }" ) [EOL] [EOL] return int ( pod_count ) if pod_count else None [EOL] [EOL] [EOL] def calculate_omp_num_threads ( values_dict ) : [EOL] [docstring] [EOL] if values_dict . get ( [string] ) and values_dict . get ( [string] ) != [string] : [EOL] cpu_limit = values_dict . get ( [string] ) [EOL] elif values_dict . get ( [string] ) : [EOL] cpu_limit = dutil . get ( values_dict , [string] , separator = [string] ) [EOL] elif values_dict . get ( [string] ) : [EOL] cpu_limit = dutil . get ( values_dict , [string] , separator = [string] ) [EOL] else : [EOL] raise ValueError ( [string] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] return int ( max ( convert_k8s_cpu_resource ( cpu_limit ) // [number] , [number] ) ) [EOL] [EOL] [EOL] def _parse_yaml_boolean ( value ) : [EOL] [docstring] [EOL] value = str ( value ) [EOL] if value == [string] : [EOL] return True [EOL] elif value == [string] : [EOL] return False [EOL] else : [EOL] raise ValueError ( f' [string] { value } [string] ' ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import List , Tuple [EOL] import builtins [EOL] import typing [EOL] from typing import List , Tuple [EOL] [EOL] [EOL] def prepare_script_paramaters ( script_parameters , script_location ) : [EOL] [docstring] [EOL] args = [ script_location ] [EOL] [EOL] if script_parameters : [EOL] for param in script_parameters : [EOL] if [string] in param or [string] in param : [EOL] param = f' [string] { param } [string] ' [EOL] if [string] in param : [EOL] [comment] [EOL] [comment] [EOL] param = param . replace ( [string] , [string] ) [EOL] args . append ( param ) [EOL] [EOL] return args [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] from typing import Any , Union , Tuple , List [EOL] import typing [EOL] import packs . common as common [EOL] [EOL] PREP_LIST_OUTPUT = [string] [EOL] [EOL] PREP_LIST_INPUT = [ ( [string] , [ ] , [ ] ) , ( [string] , [ [string] ] , [ [string] , [string] , [string] , [string] ] ) , ( [string] , [ [string] ] , [ ] ) , ( [string] , [ [string] , [string] ] , [ [string] , [string] , [string] ] ) , ( [string] , [ ] , [ [string] , [string] ] ) , ( [string] , [ ] , [ ] ) , ( [string] , [ [string] ] , [ [string] , [string] , [string] , [string] ] ) , ( [string] , [ [string] ] , [ ] ) , ( [string] , [ [string] , [string] ] , [ [string] , [string] , [string] ] ) , ( [string] , [ ] , [ [string] , [string] ] ) , ( [string] , [ ] , [ ] ) ] [EOL] [EOL] PARAMETERS = ( [string] , [string] , [string] ) [EOL] SCRIPT_LOCATION = [string] [EOL] [EOL] [EOL] def compare_list ( param_list , str , script_name ) : [EOL] if script_name : [EOL] assert param_list [ [number] ] == script_name , [string] [EOL] [EOL] local_list = list ( str ) [EOL] index = [number] [EOL] [EOL] for param in param_list : [EOL] if script_name : [EOL] continue [EOL] [EOL] assert param == local_list [ index ] , [string] [EOL] index = index + [number] [EOL] [EOL] [EOL] def test_prepare_script_parameters ( ) : [EOL] output = common . prepare_script_paramaters ( PARAMETERS , SCRIPT_LOCATION ) [EOL] [EOL] assert len ( output ) == [number] , [string] [EOL] compare_list ( output , PARAMETERS , SCRIPT_LOCATION ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $typing.List[typing.Union[typing.Tuple[builtins.str,typing.List[typing.Any],typing.List[typing.Any]],typing.Tuple[builtins.str,typing.List[typing.Any],typing.List[builtins.str]],typing.Tuple[builtins.str,typing.List[builtins.str],typing.List[typing.Any]],typing.Tuple[builtins.str,typing.List[builtins.str],typing.List[builtins.str]]]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.str,builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.str,builtins.str,builtins.str]$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.str,builtins.str,builtins.str]$ 0 $builtins.str$ 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , List , Tuple , Dict [EOL] import typing [EOL] import unittest . mock as mock [EOL] import pytest [EOL] [EOL] import packs . tf_training as tf_training [EOL] [EOL] [EOL] SCRIPT_PARAMETERS = [ [string] , [string] , [string] ] [EOL] PACK_PARAMETERS = [ ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) ] [EOL] SCRIPT_LOCATION = [string] [EOL] EXPERIMENT_FOLDER = [string] [EOL] ENV_VARIABLES = ( [string] , [string] ) [EOL] [EOL] ENV_VARIABLES_OUTPUT = [ { [string] : [string] , [string] : [string] } , { [string] : [string] , [string] : [string] } , { [string] : [string] , [string] : [string] } ] [EOL] TEST_POD_COUNT = [number] [EOL] TEST_YAML_FILE = [string] [EOL] TEST_YAML_FILE_WITHOUT_POD_COUNT = f''' [string] ''' [EOL] [EOL] TEST_YAML_FILE_WITH_POD_COUNT = f''' [string] { TEST_POD_COUNT } [string] ''' [EOL] [EOL] TEST_DOCKERFILE = [string] [EOL] [EOL] t = [string] [EOL] [EOL] EXAMPLE_PACK_TYPE = [string] [EOL] [EOL] [EOL] def test_modify_values_yaml ( mocker ) : [EOL] open_mock = mocker . patch ( [string] , new_callable = mock . mock_open , read_data = TEST_YAML_FILE ) [EOL] sh_move_mock = mocker . patch ( [string] ) [EOL] yaml_dump_mock = mocker . patch ( [string] ) [EOL] [EOL] tf_training . modify_values_yaml ( experiment_folder = EXPERIMENT_FOLDER , script_location = SCRIPT_LOCATION , script_parameters = SCRIPT_PARAMETERS , pack_params = PACK_PARAMETERS , experiment_name = [string] , pack_type = EXAMPLE_PACK_TYPE , cluster_registry_port = [number] , env_variables = ENV_VARIABLES , username = [string] ) [EOL] [EOL] assert sh_move_mock . call_count == [number] , [string] [EOL] output = yaml_dump_mock . call_args [ [number] ] [ [number] ] [EOL] compare_yaml ( output [ [string] ] [ [string] ] , SCRIPT_LOCATION ) [EOL] assert [string] and [string] in output [EOL] assert output [ [string] ] == [string] [EOL] assert output [ [string] ] == [ [string] , [string] ] [EOL] assert output [ [string] ] == [string] [EOL] [EOL] assert output [ [string] ] == ENV_VARIABLES_OUTPUT [EOL] [EOL] assert yaml_dump_mock . call_count == [number] , [string] [EOL] assert open_mock . call_count == [number] , [string] [EOL] assert all ( EXAMPLE_PACK_TYPE in call [ [number] ] [ [number] ] for call in open_mock . call_args_list ) [EOL] [EOL] assert output [ [string] ] == [number] or int ( output [ [string] ] ) == [number] [EOL] assert output [ [string] ] == [number] or int ( output [ [string] ] ) == [number] [EOL] assert output [ [string] ] == [number] or int ( output [ [string] ] ) == [number] [EOL] [EOL] [EOL] def test_modify_values_yaml_without_pod_count ( mocker ) : [EOL] open_mock = mocker . patch ( [string] , new_callable = mock . mock_open , read_data = TEST_YAML_FILE_WITHOUT_POD_COUNT ) [EOL] sh_move_mock = mocker . patch ( [string] ) [EOL] yaml_dump_mock = mocker . patch ( [string] ) [EOL] [EOL] tf_training . modify_values_yaml ( experiment_folder = EXPERIMENT_FOLDER , script_location = SCRIPT_LOCATION , script_parameters = SCRIPT_PARAMETERS , pack_params = PACK_PARAMETERS , experiment_name = [string] , pack_type = EXAMPLE_PACK_TYPE , cluster_registry_port = [number] , env_variables = None , username = [string] ) [EOL] [EOL] assert sh_move_mock . call_count == [number] , [string] [EOL] output = yaml_dump_mock . call_args [ [number] ] [ [number] ] [EOL] compare_yaml ( output [ [string] ] [ [string] ] , SCRIPT_LOCATION ) [EOL] assert [string] and [string] in output [EOL] assert output [ [string] ] == [string] [EOL] assert output [ [string] ] == [ [string] , [string] ] [EOL] [EOL] assert yaml_dump_mock . call_count == [number] , [string] [EOL] assert open_mock . call_count == [number] , [string] [EOL] assert all ( EXAMPLE_PACK_TYPE in call [ [number] ] [ [number] ] for call in open_mock . call_args_list ) [EOL] [EOL] assert output [ [string] ] == [number] or int ( output [ [string] ] ) == [number] [EOL] assert output [ [string] ] == [number] or int ( output [ [string] ] ) == [number] [EOL] assert output [ [string] ] == [number] or int ( output [ [string] ] ) == [number] [EOL] [EOL] [EOL] def test_modify_values_yaml_raise_error_if_bad_argument ( mocker ) : [EOL] open_mock = mocker . patch ( [string] , new_callable = mock . mock_open , read_data = TEST_YAML_FILE ) [EOL] sh_move_mock = mocker . patch ( [string] ) [EOL] yaml_dump_mock = mocker . patch ( [string] ) [EOL] [EOL] wrong_pack_params = [ ( [string] , [string] ) ] [EOL] [EOL] with pytest . raises ( AttributeError ) : [EOL] tf_training . modify_values_yaml ( experiment_folder = EXPERIMENT_FOLDER , script_location = SCRIPT_LOCATION , script_parameters = SCRIPT_PARAMETERS , pack_params = wrong_pack_params , experiment_name = [string] , username = [string] , pack_type = EXAMPLE_PACK_TYPE , cluster_registry_port = [number] , env_variables = None ) [EOL] [EOL] assert sh_move_mock . call_count == [number] , [string] [EOL] assert yaml_dump_mock . call_count == [number] , [string] [EOL] assert all ( EXAMPLE_PACK_TYPE in call [ [number] ] [ [number] ] for call in open_mock . call_args_list ) [EOL] [EOL] [EOL] def compare_yaml ( args_list , script_location ) : [EOL] assert script_location == args_list [ [number] ] , [string] [EOL] local_list = str . split ( [string] ) [EOL] [EOL] index = [number] [EOL] [EOL] for param in local_list : [EOL] assert param == args_list [ index ] , [string] [EOL] [EOL] index = index + [number] [EOL] [EOL] [EOL] def test_modify_dockerfile ( mocker ) : [EOL] open_mock = mocker . patch ( [string] , new_callable = mock . mock_open , read_data = TEST_DOCKERFILE ) [EOL] sh_move_mock = mocker . patch ( [string] ) [EOL] [EOL] tf_training . modify_dockerfile ( EXPERIMENT_FOLDER , [string] , [string] ) [EOL] [EOL] assert sh_move_mock . call_count == [number] , [string] [EOL] assert open_mock . call_count == [number] , [string] [EOL] [EOL] [EOL] def test_modify_dockerfile_if_script_path_provided ( mocker ) : [EOL] script_folder_location = [string] [EOL] open_mock = mocker . patch ( [string] , new_callable = mock . mock_open , read_data = TEST_DOCKERFILE ) [EOL] sh_move_mock = mocker . patch ( [string] ) [EOL] [EOL] tf_training . modify_dockerfile ( experiment_folder = EXPERIMENT_FOLDER , script_location = None , script_folder_location = script_folder_location , experiment_name = [string] , username = [string] ) [EOL] [EOL] assert sh_move_mock . call_count == [number] , [string] [EOL] assert open_mock . call_count == [number] , [string] [EOL] [EOL] [EOL] def test_update_configuration_success ( mocker ) : [EOL] modify_values_yaml_mock = mocker . patch ( [string] ) [EOL] modify_dockerfile_mock = mocker . patch ( [string] ) [EOL] [EOL] output = tf_training . update_configuration ( run_folder = EXPERIMENT_FOLDER , script_location = SCRIPT_LOCATION , script_parameters = SCRIPT_PARAMETERS , experiment_name = [string] , username = [string] , cluster_registry_port = [number] , pack_type = EXAMPLE_PACK_TYPE , pack_params = [ ] ) [EOL] [EOL] assert not output , [string] [EOL] assert modify_dockerfile_mock . call_count == [number] , [string] [EOL] assert modify_values_yaml_mock . call_count == [number] , [string] [EOL] [EOL] [EOL] def test_update_configuration_failure ( mocker ) : [EOL] modify_values_yaml_mock = mocker . patch ( [string] ) [EOL] modify_dockerfile_mock = mocker . patch ( [string] ) [EOL] [EOL] modify_values_yaml_mock . side_effect = Exception ( [string] ) [EOL] with pytest . raises ( RuntimeError ) : [EOL] tf_training . update_configuration ( run_folder = EXPERIMENT_FOLDER , script_location = SCRIPT_LOCATION , script_parameters = SCRIPT_PARAMETERS , experiment_name = [string] , cluster_registry_port = [number] , username = [string] , pack_type = EXAMPLE_PACK_TYPE , pack_params = [ ] ) [EOL] [EOL] assert modify_dockerfile_mock . call_count == [number] , [string] [EOL] assert modify_values_yaml_mock . call_count == [number] , [string] [EOL] [EOL] [EOL] def test_get_pod_count ( mocker ) : [EOL] mocker . patch ( [string] , new_callable = mock . mock_open , read_data = TEST_YAML_FILE_WITH_POD_COUNT ) [EOL] pod_count = tf_training . get_pod_count ( run_folder = EXPERIMENT_FOLDER , pack_type = EXAMPLE_PACK_TYPE ) [EOL] assert pod_count == TEST_POD_COUNT [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [number] , [number] ) , ( [string] , [number] ) , ( [string] , [number] ) ] ) def test_calculate_omp_num_threads ( cpus , omp_num_threads ) : [EOL] values = { [string] : { [string] : { [string] : cpus } } } [EOL] assert tf_training . calculate_omp_num_threads ( values ) == omp_num_threads [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [number] , [number] ) , ( [string] , [number] ) , ( [string] , [number] ) ] ) def test_calculate_omp_num_threads_worker_resources ( cpus , omp_num_threads ) : [EOL] values = { [string] : { [string] : { [string] : cpus } } } [EOL] assert tf_training . calculate_omp_num_threads ( values ) == omp_num_threads [EOL] [EOL] [EOL] def test_calculate_omp_num_threads_error ( ) : [EOL] values = { [string] : { [string] : { [string] : [number] } } } [EOL] with pytest . raises ( ValueError ) : [EOL] tf_training . calculate_omp_num_threads ( values ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $typing.Tuple[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 $typing.List[typing.Dict[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $typing.Tuple[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Dict[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] from typing import Any , Union , List , Dict [EOL] import builtins [EOL] import typing [EOL] from http import HTTPStatus [EOL] import json [EOL] from unittest . mock import MagicMock [EOL] [EOL] import pytest [EOL] [EOL] from tensorboard . client import TensorboardServiceClient , TensorboardStatus , TensorboardServiceAPIException , TensorboardRun , build_tensorboard_run_list [EOL] from cli_text_consts import TensorboardClientTexts as Texts [EOL] [EOL] [EOL] def test_get_tensorboard ( mocker ) : [EOL] fake_id = [string] [EOL] fake_url = f' [string] { fake_id } [string] ' [EOL] [EOL] content = { [string] : fake_id , [string] : [string] , [string] : fake_url } [EOL] [EOL] content_bytes = json . dumps ( content ) . encode ( [string] ) [EOL] [EOL] mocker . patch ( [string] ) . return_value = MagicMock ( status_code = HTTPStatus . OK . value , content = content_bytes ) [EOL] [EOL] client = TensorboardServiceClient ( address = [string] ) [EOL] [EOL] tensorboard = client . get_tensorboard ( tensorboard_id = fake_id ) [EOL] [EOL] assert tensorboard . id == fake_id [EOL] assert tensorboard . status == TensorboardStatus . RUNNING [EOL] assert tensorboard . url == fake_url [EOL] [EOL] [EOL] def test_get_tensorboard_not_found ( mocker ) : [EOL] fake_id = [string] [EOL] [EOL] mocker . patch ( [string] ) . return_value = MagicMock ( status_code = HTTPStatus . NOT_FOUND . value ) [EOL] [EOL] client = TensorboardServiceClient ( address = [string] ) [EOL] [EOL] tensorboard = client . get_tensorboard ( tensorboard_id = fake_id ) [EOL] [EOL] assert not tensorboard [EOL] [EOL] [EOL] def test_get_tensorboard_server_error ( mocker ) : [EOL] fake_id = [string] [EOL] [EOL] content = { [string] : HTTPStatus . INTERNAL_SERVER_ERROR . value , [string] : [string] } [EOL] [EOL] content_bytes = json . dumps ( content ) . encode ( [string] ) [EOL] [EOL] mocker . patch ( [string] ) . return_value = MagicMock ( status_code = HTTPStatus . INTERNAL_SERVER_ERROR . value , content = content_bytes ) [EOL] [EOL] client = TensorboardServiceClient ( address = [string] ) [EOL] [EOL] with pytest . raises ( TensorboardServiceAPIException ) : [EOL] client . get_tensorboard ( tensorboard_id = fake_id ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ HTTPStatus . ACCEPTED . value , HTTPStatus . CONFLICT . value ] ) def test_create_tensorboard ( mocker , requests_post_return_status_code ) : [EOL] fake_id = [string] [EOL] fake_url = f' [string] { fake_id } [string] ' [EOL] [EOL] content = { [string] : fake_id , [string] : [string] , [string] : fake_url } [EOL] [EOL] fake_runs_list = [ TensorboardRun ( name = [string] , owner = [string] ) ] [EOL] [EOL] content_bytes = json . dumps ( content ) . encode ( [string] ) [EOL] mocker . patch ( [string] ) . return_value = MagicMock ( status_code = requests_post_return_status_code , content = content_bytes ) [EOL] [EOL] client = TensorboardServiceClient ( address = [string] ) [EOL] [EOL] tensorboard = client . create_tensorboard ( runs = fake_runs_list ) [EOL] [EOL] assert tensorboard . id == fake_id [EOL] assert tensorboard . status == TensorboardStatus . RUNNING [EOL] assert tensorboard . url == fake_url [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ HTTPStatus . BAD_REQUEST . value , HTTPStatus . INTERNAL_SERVER_ERROR . value , HTTPStatus . UNPROCESSABLE_ENTITY ] ) def test_create_tensorboard_error ( mocker , requests_post_return_status_code ) : [EOL] [EOL] fake_runs_list = [ TensorboardRun ( name = [string] , owner = [string] ) ] [EOL] [EOL] content = { [string] : HTTPStatus . INTERNAL_SERVER_ERROR . value , [string] : [string] } [EOL] [EOL] content_bytes = json . dumps ( content ) . encode ( [string] ) [EOL] [EOL] mocker . patch ( [string] ) . return_value = MagicMock ( status_code = requests_post_return_status_code , content = content_bytes ) [EOL] [EOL] client = TensorboardServiceClient ( address = [string] ) [EOL] [EOL] with pytest . raises ( TensorboardServiceAPIException ) : [EOL] client . create_tensorboard ( runs = fake_runs_list ) [EOL] [EOL] [EOL] def test_tensorboard_runs_list ( ) : [EOL] EXP1_NAME = [string] [EOL] EXP2_NAME = [string] [EOL] CURR_NAMESPACE = [string] [EOL] OWN_NAMESPACE = [string] [EOL] [EOL] experiment_list = [ EXP1_NAME , f'{ OWN_NAMESPACE } [string] { EXP2_NAME }' ] [EOL] [EOL] tensorboard_runs_list = build_tensorboard_run_list ( exp_list = experiment_list , current_namespace = CURR_NAMESPACE ) [EOL] [EOL] assert len ( tensorboard_runs_list ) == [number] [EOL] assert tensorboard_runs_list [ [number] ] . name == EXP1_NAME [EOL] assert tensorboard_runs_list [ [number] ] . owner == CURR_NAMESPACE [EOL] assert tensorboard_runs_list [ [number] ] . name == EXP2_NAME [EOL] assert tensorboard_runs_list [ [number] ] . owner == OWN_NAMESPACE [EOL] [EOL] [EOL] def test_create_tensorboard_missing_experiments ( mocker ) : [EOL] [EOL] fake_runs_list = [ TensorboardRun ( name = [string] , owner = [string] ) ] [EOL] fake_exp_name = [string] [EOL] fake_owner = [string] [EOL] content = { [string] : HTTPStatus . INTERNAL_SERVER_ERROR . value , [string] : [string] , [string] : [ { [string] : fake_exp_name , [string] : fake_owner } ] } [EOL] [EOL] content_bytes = json . dumps ( content ) . encode ( [string] ) [EOL] [EOL] mocker . patch ( [string] ) . return_value = MagicMock ( status_code = HTTPStatus . UNPROCESSABLE_ENTITY , content = content_bytes ) [EOL] [EOL] client = TensorboardServiceClient ( address = [string] ) [EOL] [EOL] with pytest . raises ( TensorboardServiceAPIException ) as exe : [EOL] client . create_tensorboard ( runs = fake_runs_list ) [EOL] [EOL] assert Texts . INVALID_RUNS_ERROR_MSG . format ( invalid_runs_list = f"{ fake_owner } [string] { fake_exp_name }" ) in str ( exe . value ) [EOL] [EOL] content [ [string] ] = [ ] [EOL] content_bytes = json . dumps ( content ) . encode ( [string] ) [EOL] [EOL] mocker . patch ( [string] ) . return_value = MagicMock ( status_code = HTTPStatus . UNPROCESSABLE_ENTITY , content = content_bytes ) [EOL] [EOL] client = TensorboardServiceClient ( address = [string] ) [EOL] [EOL] with pytest . raises ( TensorboardServiceAPIException ) as exe : [EOL] client . create_tensorboard ( runs = fake_runs_list ) [EOL] [EOL] assert Texts . RUNS_NOT_EXIST_ERROR_MSG in str ( exe . value ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import pytest [EOL] [EOL] [EOL] @ pytest . fixture ( autouse = True ) def mock_cli_validation ( mocker ) : [EOL] mocker . patch ( [string] ) [EOL] mocker . patch ( [string] ) [EOL] [EOL] [EOL] @ pytest . fixture ( autouse = True ) def mock_check_nauta_pods ( mocker ) : [EOL] mocker . patch ( [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import List [EOL] import typing [EOL] HEADERS = [ [string] , [string] , [string] , [string] , [string] ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , List [EOL] import click [EOL] import typing [EOL] from unittest . mock import MagicMock [EOL] [EOL] import pytest [EOL] from click . testing import CliRunner [EOL] from kubernetes . client import CustomObjectsApi [EOL] [EOL] from commands . workflow . workflow_list import workflow_list [EOL] from cli_text_consts import WorkflowViewTexts as Texts [EOL] from platform_resources . workflow import ArgoWorkflow [EOL] [EOL] FAKE_WORKFLOWS = [ ArgoWorkflow ( name = [string] , namespace = [string] , k8s_custom_object_api = MagicMock ( spec = CustomObjectsApi ) , status = { [string] : [string] } ) , ArgoWorkflow ( name = [string] , namespace = [string] , k8s_custom_object_api = MagicMock ( spec = CustomObjectsApi ) , status = { [string] : [string] } ) , ] [EOL] [EOL] [EOL] class WorkflowListMocks : [EOL] def __init__ ( self , mocker ) : [EOL] self . get_namespace = mocker . patch ( [string] , return_value = [string] ) [EOL] self . list_workflows = mocker . patch ( [string] , return_value = FAKE_WORKFLOWS ) [EOL] [EOL] [EOL] @ pytest . fixture ( ) def list_mocks ( mocker ) : [EOL] return WorkflowListMocks ( mocker = mocker ) [EOL] [EOL] [EOL] def test_list ( list_mocks ) : [EOL] result = CliRunner ( ) . invoke ( workflow_list , [ ] , catch_exceptions = False ) [EOL] [EOL] assert result . exit_code == [number] [EOL] for workflow in FAKE_WORKFLOWS : [EOL] assert workflow . name in result . output [EOL] assert workflow . namespace in result . output [EOL] [EOL] [EOL] def test_cancel_other_error ( list_mocks ) : [EOL] list_mocks . list_workflows . side_effect = RuntimeError [EOL] result = CliRunner ( ) . invoke ( workflow_list , [ ] ) [EOL] [EOL] assert result . exit_code == [number] [EOL] assert Texts . OTHER_ERROR_MSG in result . output [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $WorkflowListMocks$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import click [EOL] import typing [EOL] from unittest . mock import MagicMock [EOL] [EOL] import pytest [EOL] from click . testing import CliRunner [EOL] from kubernetes . client import CustomObjectsApi [EOL] [EOL] from commands . workflow . submit import submit [EOL] from cli_text_consts import WorkflowSubmitTexts as Texts [EOL] from platform_resources . workflow import ArgoWorkflow [EOL] [EOL] FAKE_WORKFLOW = ArgoWorkflow ( name = [string] , namespace = [string] , k8s_custom_object_api = MagicMock ( spec = CustomObjectsApi ) ) [EOL] [EOL] FAKE_WORKFLOW_PATH = [string] [EOL] [EOL] [EOL] class WorkflowSubmitMocks : [EOL] def __init__ ( self , mocker , tmpdir ) : [EOL] self . get_namespace = mocker . patch ( [string] , return_value = [string] ) [EOL] self . from_yaml = mocker . patch ( [string] , return_value = FAKE_WORKFLOW ) [EOL] self . create_workflow = mocker . patch . object ( self . from_yaml . return_value , [string] ) [EOL] [EOL] self . fake_workflow_spec_file = tmpdir . mkdir ( [string] ) . join ( [string] ) [EOL] self . fake_workflow_spec_file . write ( [string] ) [EOL] self . fake_workflow_spec_path = self . fake_workflow_spec_file . strpath [EOL] [EOL] [EOL] @ pytest . fixture ( ) def submit_mocks ( mocker , tmpdir ) : [EOL] return WorkflowSubmitMocks ( mocker = mocker , tmpdir = tmpdir ) [EOL] [EOL] [EOL] def test_submit ( submit_mocks ) : [EOL] result = CliRunner ( ) . invoke ( submit , [ submit_mocks . fake_workflow_spec_path ] , catch_exceptions = False ) [EOL] [EOL] assert result . exit_code == [number] [EOL] assert FAKE_WORKFLOW . name in result . output [EOL] [EOL] [EOL] def test_submit_io_error ( submit_mocks ) : [EOL] submit_mocks . from_yaml . side_effect = IOError [EOL] result = CliRunner ( ) . invoke ( submit , [ submit_mocks . fake_workflow_spec_path ] ) [EOL] [EOL] assert result . exit_code == [number] [EOL] assert Texts . LOAD_SPEC_ERROR_MSG . format ( msg = [string] ) in result . output [EOL] [EOL] [EOL] def test_cancel_other_error ( submit_mocks ) : [EOL] submit_mocks . create_workflow . side_effect = RuntimeError [EOL] result = CliRunner ( ) . invoke ( submit , [ submit_mocks . fake_workflow_spec_path ] ) [EOL] [EOL] assert result . exit_code == [number] [EOL] assert Texts . OTHER_ERROR_MSG in result . output [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $WorkflowSubmitMocks$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import click [EOL] import typing [EOL] from unittest . mock import MagicMock [EOL] [EOL] import pytest [EOL] from click . testing import CliRunner [EOL] from kubernetes . client import CustomObjectsApi [EOL] [EOL] from commands . workflow . cancel import cancel [EOL] from cli_text_consts import WorkflowDeleteTexts as Texts [EOL] from platform_resources . workflow import ArgoWorkflow [EOL] [EOL] FAKE_WORKFLOW = ArgoWorkflow ( name = [string] , namespace = [string] , k8s_custom_object_api = MagicMock ( spec = CustomObjectsApi ) ) [EOL] [EOL] [EOL] class WorkflowCancelMocks : [EOL] def __init__ ( self , mocker ) : [EOL] self . get_namespace = mocker . patch ( [string] , return_value = [string] ) [EOL] self . get_workflow = mocker . patch ( [string] , return_value = FAKE_WORKFLOW ) [EOL] self . delete_workflow = mocker . patch . object ( self . get_workflow . return_value , [string] ) [EOL] [EOL] [EOL] @ pytest . fixture ( ) def cancel_mocks ( mocker ) : [EOL] return WorkflowCancelMocks ( mocker = mocker ) [EOL] [EOL] [EOL] def test_cancel ( cancel_mocks ) : [EOL] result = CliRunner ( ) . invoke ( cancel , [ FAKE_WORKFLOW . name ] , catch_exceptions = False ) [EOL] [EOL] assert result . exit_code == [number] [EOL] assert Texts . SUCCESS_MSG . format ( workflow_name = FAKE_WORKFLOW . name ) in result . output [EOL] [EOL] [EOL] def test_cancel_not_found ( cancel_mocks ) : [EOL] cancel_mocks . get_workflow . return_value = None [EOL] result = CliRunner ( ) . invoke ( cancel , [ FAKE_WORKFLOW . name ] ) [EOL] [EOL] assert result . exit_code == [number] [EOL] assert Texts . NOT_FOUND_MSG . format ( workflow_name = FAKE_WORKFLOW . name ) in result . output [EOL] [EOL] [EOL] def test_cancel_other_error ( cancel_mocks ) : [EOL] cancel_mocks . delete_workflow . side_effect = RuntimeError [EOL] result = CliRunner ( ) . invoke ( cancel , [ FAKE_WORKFLOW . name ] ) [EOL] [EOL] assert result . exit_code == [number] [EOL] assert Texts . OTHER_ERROR_MSG in result . output [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $WorkflowCancelMocks$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import click [EOL] import typing [EOL] from unittest . mock import MagicMock [EOL] [EOL] import pytest [EOL] from click . testing import CliRunner [EOL] from kubernetes . client import CustomObjectsApi [EOL] [EOL] from commands . workflow . view import view [EOL] from cli_text_consts import WorkflowViewTexts as Texts [EOL] from platform_resources . workflow import ArgoWorkflow [EOL] [EOL] FAKE_WORKFLOW = ArgoWorkflow ( name = [string] , namespace = [string] , k8s_custom_object_api = MagicMock ( spec = CustomObjectsApi ) , status = { [string] : [string] } ) [EOL] [EOL] FAKE_WORKFLOW_PATH = [string] [EOL] [EOL] [EOL] class WorkflowViewMocks : [EOL] def __init__ ( self , mocker ) : [EOL] self . get_namespace = mocker . patch ( [string] , return_value = [string] ) [EOL] self . get_workflow = mocker . patch ( [string] , return_value = FAKE_WORKFLOW ) [EOL] [EOL] [EOL] @ pytest . fixture ( ) def view_mocks ( mocker ) : [EOL] return WorkflowViewMocks ( mocker = mocker ) [EOL] [EOL] [EOL] def test_view ( view_mocks ) : [EOL] result = CliRunner ( ) . invoke ( view , [ FAKE_WORKFLOW . name ] , catch_exceptions = False ) [EOL] [EOL] assert result . exit_code == [number] [EOL] assert FAKE_WORKFLOW . name in result . output [EOL] assert FAKE_WORKFLOW . status [ [string] ] in result . output [EOL] [EOL] [EOL] def test_cancel_other_error ( view_mocks ) : [EOL] view_mocks . get_workflow . side_effect = RuntimeError [EOL] result = CliRunner ( ) . invoke ( view , [ FAKE_WORKFLOW . name ] ) [EOL] [EOL] assert result . exit_code == [number] [EOL] assert Texts . OTHER_ERROR_MSG in result . output [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $WorkflowViewMocks$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , List [EOL] import click [EOL] import typing [EOL] from unittest . mock import MagicMock [EOL] [EOL] import pytest [EOL] from click . testing import CliRunner [EOL] from kubernetes . client import CustomObjectsApi [EOL] [EOL] from commands . workflow . logs import logs [EOL] from cli_text_consts import WorkflowLogsTexts as Texts [EOL] from logs_aggregator . k8s_log_entry import LogEntry [EOL] from platform_resources . workflow import ArgoWorkflow [EOL] [EOL] FAKE_WORKFLOW = ArgoWorkflow ( name = [string] , namespace = [string] , k8s_custom_object_api = MagicMock ( spec = CustomObjectsApi ) ) [EOL] [EOL] FAKE_LOGS = [ LogEntry ( date = [string] , content = [string] [string] , pod_name = [string] , namespace = [string] ) , LogEntry ( date = [string] , content = [string] , pod_name = [string] , namespace = [string] ) ] [EOL] [EOL] [EOL] class WorkflowLogsMocks : [EOL] def __init__ ( self , mocker ) : [EOL] self . get_namespace = mocker . patch ( [string] , return_value = [string] ) [EOL] self . get_workflow = mocker . patch ( [string] , return_value = FAKE_WORKFLOW ) [EOL] self . get_k8s_host = mocker . patch ( [string] ) [EOL] self . get_k8s_api_key = mocker . patch ( [string] ) [EOL] self . es_client = mocker . patch ( [string] ) [EOL] self . workflow_logs_generator = mocker . patch . object ( self . es_client . return_value , [string] ) [EOL] [EOL] [EOL] @ pytest . fixture ( ) def logs_mocks ( mocker ) : [EOL] return WorkflowLogsMocks ( mocker = mocker ) [EOL] [EOL] [EOL] def test_logs ( logs_mocks ) : [EOL] logs_mocks . workflow_logs_generator . return_value = iter ( FAKE_LOGS ) [EOL] result = CliRunner ( ) . invoke ( logs , [ FAKE_WORKFLOW . name ] , catch_exceptions = False ) [EOL] [EOL] assert result . exit_code == [number] [EOL] for log in FAKE_LOGS : [EOL] assert log . content in result . output [EOL] [EOL] [EOL] def test_logs_not_found ( logs_mocks ) : [EOL] logs_mocks . get_workflow . return_value = None [EOL] result = CliRunner ( ) . invoke ( logs , [ FAKE_WORKFLOW . name ] ) [EOL] [EOL] assert result . exit_code == [number] [EOL] assert Texts . NOT_FOUND_MSG . format ( workflow_name = FAKE_WORKFLOW . name ) in result . output [EOL] [EOL] [EOL] def test_cancel_other_error ( logs_mocks ) : [EOL] logs_mocks . es_client . side_effect = RuntimeError [EOL] result = CliRunner ( ) . invoke ( logs , [ FAKE_WORKFLOW . name ] ) [EOL] [EOL] assert result . exit_code == [number] [EOL] assert Texts . OTHER_ERROR_MSG in result . output [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $WorkflowLogsMocks$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import typing [EOL] import pytest [EOL] [EOL] [EOL] @ pytest . fixture ( autouse = True ) def mock_cli_validation ( mocker ) : [EOL] mocker . patch ( [string] ) [EOL] mocker . patch ( [string] ) [EOL] mocker . patch ( [string] ) [EOL] [EOL] [EOL] @ pytest . fixture ( autouse = True ) def mock_k8s_client ( mocker ) : [EOL] mocker . patch ( [string] ) [EOL] [EOL] [EOL] @ pytest . fixture ( autouse = True ) def mock_check_nauta_pods ( mocker ) : [EOL] mocker . patch ( [string] ) [EOL] [EOL] [EOL] @ pytest . fixture ( autouse = True ) def mock_get_click_context ( mocker ) : [EOL] click_context = mocker . patch ( [string] ) [EOL] click_context . return_value . obj . force = False [EOL] return click_context [EOL] [EOL] [EOL] @ pytest . fixture ( ) def mock_exp_script_file ( tmpdir ) : [EOL] test_dir = tmpdir . mkdir ( [string] ) [EOL] test_file = test_dir . join ( [string] ) [EOL] test_file . write ( [string] ) [EOL] return test_file . strpath [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import pytest [EOL] [EOL] [EOL] @ pytest . fixture ( autouse = True ) def mock_cli_validation ( mocker ) : [EOL] mocker . patch ( [string] ) [EOL] mocker . patch ( [string] ) [EOL] mocker . patch ( [string] ) [EOL] [EOL] [EOL] @ pytest . fixture ( autouse = True ) def mock_check_nauta_pods ( mocker ) : [EOL] mocker . patch ( [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import builtins [EOL] from typing import Any , List [EOL] import click [EOL] import applications [EOL] import typing [EOL] import unittest [EOL] from click . testing import CliRunner [EOL] import pytest [EOL] from unittest . mock import MagicMock [EOL] from kubernetes . client import V1Pod , V1PodStatus , V1ContainerStatus [EOL] [EOL] from commands . predict import launch [EOL] [EOL] [EOL] mocked_test_pod = MagicMock ( spec = V1Pod ) [EOL] mocked_test_pod . status = V1PodStatus ( container_statuses = [ V1ContainerStatus ( ready = True , image = [string] , image_id = [string] , name = [string] , restart_count = [number] ) ] , phase = [string] ) [EOL] TEST_PODS = [ mocked_test_pod ] [EOL] [EOL] [EOL] class LaunchPredictMocks : [EOL] def __init__ ( self , mocker ) : [EOL] self . generate_name_mock = mocker . patch ( [string] ) [EOL] self . start_inference_instance_mock = mocker . patch ( [string] ) [EOL] self . get_inference_instance_url_mock = mocker . patch ( [string] ) [EOL] self . get_authorization_header_mock = mocker . patch ( [string] ) [EOL] self . get_namespace_mock = mocker . patch ( [string] ) [EOL] self . validate_local_model_location = mocker . patch ( [string] ) [EOL] self . get_namespaced_pods = mocker . patch ( [string] ) [EOL] self . get_namespaced_pods . return_value = TEST_PODS [EOL] [EOL] [EOL] @ pytest . fixture def launch_mocks ( mocker ) : [EOL] mocks = LaunchPredictMocks ( mocker = mocker ) [EOL] return mocks [EOL] [EOL] [EOL] def test_launch ( launch_mocks ) : [EOL] model_location = [string] [EOL] name = [string] [EOL] [EOL] runner = CliRunner ( ) [EOL] result = runner . invoke ( launch . launch , [ [string] , model_location , [string] , name ] ) [EOL] [EOL] assert launch_mocks . generate_name_mock . call_count == [number] [EOL] assert launch_mocks . start_inference_instance_mock . call_count == [number] [EOL] assert launch_mocks . get_namespace_mock . call_count == [number] [EOL] assert launch_mocks . get_inference_instance_url_mock . call_count == [number] [EOL] assert launch_mocks . get_authorization_header_mock . call_count == [number] [EOL] assert result . exit_code == [number] [EOL] [EOL] [EOL] def test_launch_generate_name ( launch_mocks ) : [EOL] model_location = [string] [EOL] [EOL] runner = CliRunner ( ) [EOL] result = runner . invoke ( launch . launch , [ [string] , model_location ] ) [EOL] [EOL] assert launch_mocks . generate_name_mock . call_count == [number] [EOL] assert launch_mocks . start_inference_instance_mock . call_count == [number] [EOL] assert launch_mocks . get_namespace_mock . call_count == [number] [EOL] assert launch_mocks . get_inference_instance_url_mock . call_count == [number] [EOL] assert launch_mocks . get_authorization_header_mock . call_count == [number] [EOL] assert result . exit_code == [number] [EOL] [EOL] [EOL] def test_launch_fail ( launch_mocks ) : [EOL] launch_mocks . start_inference_instance_mock . side_effect = RuntimeError [EOL] [EOL] model_location = [string] [EOL] [EOL] runner = CliRunner ( ) [EOL] result = runner . invoke ( launch . launch , [ [string] , model_location ] ) [EOL] [EOL] assert launch_mocks . generate_name_mock . call_count == [number] [EOL] assert launch_mocks . start_inference_instance_mock . call_count == [number] [EOL] assert launch_mocks . get_namespace_mock . call_count == [number] [EOL] assert launch_mocks . get_inference_instance_url_mock . call_count == [number] [EOL] assert launch_mocks . get_authorization_header_mock . call_count == [number] [EOL] assert result . exit_code == [number] [EOL] [EOL] [EOL] def test_launch_pod_fail ( launch_mocks ) : [EOL] failed_pod_mock = MagicMock ( spec = V1Pod ) [EOL] failed_pod_mock . status = V1PodStatus ( container_statuses = [ V1ContainerStatus ( ready = True , image = [string] , image_id = [string] , name = [string] , restart_count = [number] ) ] , phase = [string] ) [EOL] launch_mocks . get_namespaced_pods . return_value = [ failed_pod_mock ] [EOL] [EOL] model_location = [string] [EOL] [EOL] runner = CliRunner ( ) [EOL] result = runner . invoke ( launch . launch , [ [string] , model_location ] ) [EOL] [EOL] assert launch_mocks . generate_name_mock . call_count == [number] [EOL] assert launch_mocks . start_inference_instance_mock . call_count == [number] [EOL] assert launch_mocks . get_namespace_mock . call_count == [number] [EOL] assert launch_mocks . get_inference_instance_url_mock . call_count == [number] [EOL] assert launch_mocks . get_authorization_header_mock . call_count == [number] [EOL] assert launch_mocks . get_namespaced_pods . call_count == [number] [EOL] assert result . exit_code == [number] [EOL] [EOL] [EOL] def test_launch_url_fail ( launch_mocks ) : [EOL] launch_mocks . get_inference_instance_url_mock . side_effect = RuntimeError [EOL] [EOL] model_location = [string] [EOL] [EOL] runner = CliRunner ( ) [EOL] result = runner . invoke ( launch . launch , [ [string] , model_location ] ) [EOL] [EOL] assert launch_mocks . get_authorization_header_mock . call_count == [number] [EOL] assert result . exit_code == [number] [EOL] [EOL] [EOL] [comment] [EOL] def test_batch_missing_model_location ( launch_mocks ) : [EOL] runner = CliRunner ( ) [EOL] result = runner . invoke ( launch . launch , [ ] ) [EOL] [EOL] assert launch_mocks . generate_name_mock . call_count == [number] [EOL] assert launch_mocks . start_inference_instance_mock . call_count == [number] [EOL] assert launch_mocks . get_namespace_mock . call_count == [number] [EOL] assert launch_mocks . get_inference_instance_url_mock . call_count == [number] [EOL] assert launch_mocks . get_authorization_header_mock . call_count == [number] [EOL] [EOL] assert result . exit_code == [number] [EOL] [EOL] [EOL] def test_missing_file ( mocker , launch_mocks ) : [EOL] local_model_location = [string] [EOL] mocker . patch . object ( launch , [string] ) . side_effect = SystemExit ( [number] ) [EOL] [EOL] runner = CliRunner ( ) [EOL] result = runner . invoke ( launch . launch , [ [string] , local_model_location ] ) [EOL] [EOL] assert launch_mocks . generate_name_mock . call_count == [number] [EOL] assert launch_mocks . start_inference_instance_mock . call_count == [number] [EOL] assert launch_mocks . get_namespace_mock . call_count == [number] [EOL] assert launch_mocks . get_inference_instance_url_mock . call_count == [number] [EOL] assert launch_mocks . get_authorization_header_mock . call_count == [number] [EOL] [EOL] assert result . exit_code == [number] [EOL] [EOL] [EOL] [comment] [EOL] def test_validate_local_model_location ( mocker ) : [EOL] [EOL] mocker . patch ( [string] , return_value = False ) [EOL] [EOL] with pytest . raises ( SystemExit ) : [EOL] launch . validate_local_model_location ( [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import click [EOL] import applications [EOL] from click . testing import CliRunner [EOL] import pytest [EOL] [EOL] from commands . predict import stream [EOL] from commands . predict . common import InferenceVerb [EOL] from platform_resources . run import RunStatus [EOL] from cli_text_consts import PredictStreamCmdTexts as Texts [EOL] [EOL] [EOL] TEST_DATA = [string] [EOL] TEST_RESPONSE = [string] [EOL] TEST_URL = [string] [EOL] TEST_API_KEY = [string] [EOL] [EOL] [EOL] class StreamPredictMocks : [EOL] def __init__ ( self , mocker ) : [EOL] self . get_namespace_mock = mocker . patch ( [string] ) [EOL] self . get_run_mock = mocker . patch ( [string] ) [EOL] self . get_run_mock . return_value . state = RunStatus . RUNNING [EOL] self . get_inference_instance_url_mock = mocker . patch ( [string] ) [EOL] self . get_inference_instance_url_mock . return_value = TEST_URL [EOL] self . get_api_key_mock = mocker . patch ( [string] ) [EOL] self . get_api_key_mock . return_value = TEST_API_KEY [EOL] self . inference_post_mock = mocker . patch ( [string] ) [EOL] self . inference_post_mock . return_value . text = TEST_RESPONSE [EOL] [EOL] [EOL] @ pytest . fixture def stream_mocks ( mocker ) : [EOL] mocks = StreamPredictMocks ( mocker = mocker ) [EOL] return mocks [EOL] [EOL] [EOL] def test_stream ( stream_mocks ) : [EOL] data_location = [string] [EOL] name = [string] [EOL] verb = InferenceVerb . CLASSIFY . value [EOL] [EOL] runner = CliRunner ( ) [EOL] with runner . isolated_filesystem ( ) : [EOL] with open ( data_location , [string] ) as data_file : [EOL] data_file . write ( TEST_DATA ) [EOL] result = runner . invoke ( stream . stream , [ [string] , data_location , [string] , name , [string] , verb ] , catch_exceptions = False ) [EOL] [EOL] assert stream_mocks . get_namespace_mock . call_count == [number] [EOL] assert stream_mocks . get_run_mock . call_count == [number] [EOL] assert stream_mocks . get_inference_instance_url_mock . call_count == [number] [EOL] assert stream_mocks . get_api_key_mock . call_count == [number] [EOL] [EOL] stream_mocks . inference_post_mock . assert_called_with ( f'{ TEST_URL } [string] { verb }' , data = TEST_DATA , verify = False , headers = { [string] : TEST_API_KEY , [string] : [string] , [string] : [string] } ) [EOL] [EOL] assert TEST_RESPONSE in result . output [EOL] assert result . exit_code == [number] [EOL] [EOL] [EOL] def test_stream_get_run_fail ( stream_mocks ) : [EOL] stream_mocks . get_run_mock . return_value = None [EOL] [EOL] data_location = [string] [EOL] name = [string] [EOL] [EOL] runner = CliRunner ( ) [EOL] with runner . isolated_filesystem ( ) : [EOL] with open ( data_location , [string] ) as data_file : [EOL] data_file . write ( TEST_DATA ) [EOL] result = runner . invoke ( stream . stream , [ [string] , data_location , [string] , name ] , catch_exceptions = False ) [EOL] [EOL] assert stream_mocks . get_namespace_mock . call_count == [number] [EOL] assert stream_mocks . get_run_mock . call_count == [number] [EOL] assert stream_mocks . get_inference_instance_url_mock . call_count == [number] [EOL] assert stream_mocks . get_api_key_mock . call_count == [number] [EOL] [EOL] assert Texts . INSTANCE_NOT_EXISTS_ERROR_MSG . format ( name = name ) in result . output [EOL] assert result . exit_code == [number] [EOL] [EOL] [EOL] def test_stream_instance_not_running_fail ( stream_mocks ) : [EOL] stream_mocks . get_run_mock . return_value . state = RunStatus . QUEUED [EOL] [EOL] data_location = [string] [EOL] name = [string] [EOL] [EOL] runner = CliRunner ( ) [EOL] with runner . isolated_filesystem ( ) : [EOL] with open ( data_location , [string] ) as data_file : [EOL] data_file . write ( TEST_DATA ) [EOL] result = runner . invoke ( stream . stream , [ [string] , data_location , [string] , name ] , catch_exceptions = False ) [EOL] [EOL] assert stream_mocks . get_namespace_mock . call_count == [number] [EOL] assert stream_mocks . get_run_mock . call_count == [number] [EOL] assert stream_mocks . get_inference_instance_url_mock . call_count == [number] [EOL] assert stream_mocks . get_api_key_mock . call_count == [number] [EOL] [EOL] assert Texts . INSTANCE_NOT_RUNNING_ERROR_MSG . format ( name = name , running_code = RunStatus . RUNNING . value ) in result . output [EOL] assert result . exit_code == [number] [EOL] [EOL] [EOL] def test_stream_get_run_url_fail ( stream_mocks ) : [EOL] stream_mocks . get_inference_instance_url_mock . side_effect = RuntimeError [EOL] [EOL] data_location = [string] [EOL] name = [string] [EOL] [EOL] runner = CliRunner ( ) [EOL] with runner . isolated_filesystem ( ) : [EOL] with open ( data_location , [string] ) as data_file : [EOL] data_file . write ( TEST_DATA ) [EOL] result = runner . invoke ( stream . stream , [ [string] , data_location , [string] , name ] , catch_exceptions = False ) [EOL] [EOL] assert stream_mocks . get_namespace_mock . call_count == [number] [EOL] assert stream_mocks . get_run_mock . call_count == [number] [EOL] assert stream_mocks . get_inference_instance_url_mock . call_count == [number] [EOL] assert stream_mocks . get_api_key_mock . call_count == [number] [EOL] [EOL] assert Texts . INSTANCE_GET_FAIL_ERROR_MSG . format ( name = name ) in result . output [EOL] assert result . exit_code == [number] [EOL] [EOL] [EOL] def test_stream_data_load_fail ( stream_mocks ) : [EOL] data_location = [string] [EOL] name = [string] [EOL] [EOL] runner = CliRunner ( ) [EOL] with runner . isolated_filesystem ( ) : [EOL] with open ( data_location , [string] ) as data_file : [EOL] data_file . write ( [string] ) [EOL] result = runner . invoke ( stream . stream , [ [string] , data_location , [string] , name ] , catch_exceptions = False ) [EOL] [EOL] assert stream_mocks . get_namespace_mock . call_count == [number] [EOL] assert stream_mocks . get_run_mock . call_count == [number] [EOL] assert stream_mocks . get_inference_instance_url_mock . call_count == [number] [EOL] assert stream_mocks . get_api_key_mock . call_count == [number] [EOL] [EOL] assert Texts . JSON_LOAD_ERROR_MSG . format ( data = data_location ) in result . output [EOL] assert result . exit_code == [number] [EOL] [EOL] [EOL] def test_stream_inference_fail ( stream_mocks ) : [EOL] request_error = [string] [EOL] stream_mocks . inference_post_mock . return_value . raise_for_status . side_effect = RuntimeError ( request_error ) [EOL] data_location = [string] [EOL] name = [string] [EOL] [EOL] runner = CliRunner ( ) [EOL] with runner . isolated_filesystem ( ) : [EOL] with open ( data_location , [string] ) as data_file : [EOL] data_file . write ( TEST_DATA ) [EOL] result = runner . invoke ( stream . stream , [ [string] , data_location , [string] , name ] , catch_exceptions = False ) [EOL] [EOL] assert stream_mocks . get_namespace_mock . call_count == [number] [EOL] assert stream_mocks . get_run_mock . call_count == [number] [EOL] assert stream_mocks . get_inference_instance_url_mock . call_count == [number] [EOL] assert stream_mocks . get_api_key_mock . call_count == [number] [EOL] [EOL] assert Texts . INFERENCE_OTHER_ERROR_MSG . format ( exception = request_error ) in result . output [EOL] assert result . exit_code == [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import typing [EOL] import unittest [EOL] from unittest . mock import MagicMock [EOL] [EOL] from platform_resources . run import Run [EOL] from commands . predict . common import start_inference_instance , get_inference_instance_url [EOL] [EOL] [EOL] def test_start_inference_instance ( mocker ) : [EOL] submit_experiment_mock = mocker . patch ( [string] ) [EOL] fake_experiment = MagicMock ( ) [EOL] submit_experiment_mock . return_value = [ fake_experiment ] , { } , [string] [EOL] [EOL] inference_instance = start_inference_instance ( name = [string] , model_location = [string] , model_name = [string] , local_model_location = [string] , template = [string] ) [EOL] [EOL] assert inference_instance == fake_experiment [EOL] [EOL] [EOL] def test_get_inference_instance_url_run_description ( mocker ) : [EOL] fake_instance = MagicMock ( spec = Run ) [EOL] fake_instance . name = [string] [EOL] fake_host = [string] [EOL] fake_namespace = [string] [EOL] fake_model_name = [string] [EOL] [EOL] get_kubectl_host_mock = mocker . patch ( [string] ) [EOL] get_kubectl_host_mock . return_value = fake_host [EOL] [EOL] get_namespace_mock = mocker . patch ( [string] ) [EOL] get_namespace_mock . return_value = fake_namespace [EOL] [EOL] instance_url = get_inference_instance_url ( inference_instance = fake_instance , model_name = fake_model_name ) [EOL] [EOL] assert instance_url == f'{ fake_host } [string] { fake_namespace } [string] ' f' [string] { fake_instance . name } [string] { fake_model_name }' [EOL] [EOL] [EOL] def test_get_inference_instance_url_run ( mocker ) : [EOL] fake_instance = MagicMock ( spec = Run ) [EOL] fake_model_name = [string] [EOL] fake_instance . name = [string] [EOL] fake_instance . metadata = { [string] : { [string] : fake_model_name } } [EOL] fake_host = [string] [EOL] fake_namespace = [string] [EOL] [EOL] get_kubectl_host_mock = mocker . patch ( [string] ) [EOL] get_kubectl_host_mock . return_value = fake_host [EOL] [EOL] get_namespace_mock = mocker . patch ( [string] ) [EOL] get_namespace_mock . return_value = fake_namespace [EOL] [EOL] instance_url = get_inference_instance_url ( inference_instance = fake_instance ) [EOL] [EOL] assert instance_url == f'{ fake_host } [string] { fake_namespace } [string] ' f' [string] { fake_instance . name } [string] { fake_model_name }' [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import click [EOL] from click . testing import CliRunner [EOL] import pytest [EOL] [EOL] from commands . predict import batch [EOL] from util . exceptions import SubmitExperimentError [EOL] [EOL] [EOL] @ pytest . fixture def launch_mocks ( mocker ) : [EOL] mocker . patch . object ( batch , [string] ) [EOL] mocker . patch . object ( batch , [string] ) [EOL] [EOL] [EOL] [comment] [EOL] def test_batch ( launch_mocks ) : [EOL] model_location = [string] [EOL] data_location = [string] [EOL] [EOL] runner = CliRunner ( ) [EOL] result = runner . invoke ( batch . batch , [ [string] , model_location , [string] , data_location , [string] , [string] , [string] ] ) [EOL] [EOL] assert batch . generate_name . call_count == [number] [EOL] assert batch . start_inference_instance . call_count == [number] [EOL] [EOL] assert result . exit_code == [number] [EOL] [EOL] [EOL] [comment] [EOL] def test_batch_name_provided ( launch_mocks ) : [EOL] model_location = [string] [EOL] data_location = [string] [EOL] fake_name = [string] [EOL] [EOL] runner = CliRunner ( ) [EOL] result = runner . invoke ( batch . batch , [ [string] , model_location , [string] , data_location , [string] , fake_name ] ) [EOL] [EOL] assert batch . generate_name . call_count == [number] [EOL] assert batch . start_inference_instance . call_count == [number] [EOL] [EOL] assert result . exit_code == [number] [EOL] [EOL] [EOL] [comment] [EOL] def test_batch_exception ( mocker , launch_mocks ) : [EOL] model_location = [string] [EOL] data_location = [string] [EOL] [EOL] mocker . patch . object ( batch , [string] ) . side_effect = SubmitExperimentError [EOL] [EOL] runner = CliRunner ( ) [EOL] result = runner . invoke ( batch . batch , [ [string] , model_location , [string] , data_location ] ) [EOL] [EOL] assert batch . generate_name . call_count == [number] [EOL] assert batch . start_inference_instance . call_count == [number] [EOL] [EOL] assert result . exit_code == [number] [EOL] [EOL] [EOL] [comment] [EOL] def test_batch_missing_model_location ( launch_mocks ) : [EOL] data_location = [string] [EOL] [EOL] runner = CliRunner ( ) [EOL] result = runner . invoke ( batch . batch , [ [string] , data_location ] ) [EOL] [EOL] assert batch . generate_name . call_count == [number] [EOL] assert batch . start_inference_instance . call_count == [number] [EOL] [EOL] assert result . exit_code == [number] [EOL] [EOL] [EOL] def test_missing_file ( mocker , launch_mocks ) : [EOL] data_location = [string] [EOL] local_model_location = [string] [EOL] [EOL] runner = CliRunner ( ) [EOL] result = runner . invoke ( batch . batch , [ [string] , data_location , [string] , local_model_location ] ) [EOL] [EOL] assert result . exit_code == [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , List [EOL] import click [EOL] import builtins [EOL] import typing [EOL] import re [EOL] [EOL] import pytest [EOL] from kubernetes . client . models import V1ConfigMap [EOL] from click . testing import CliRunner [EOL] [EOL] from commands import version [EOL] from version import VERSION [EOL] from util . config import NAUTAConfigMap [EOL] from util . exceptions import KubernetesError [EOL] from cli_text_consts import VersionCmdTexts as Texts , VERBOSE_RERUN_MSG [EOL] [EOL] [EOL] PLATFORM_VERSION = [string] [EOL] [EOL] APPLICATION_VERSION_REGEX = [string] . format ( application_row_name = Texts . TABLE_APP_ROW_NAME , version = VERSION ) [EOL] PLATFORM_VERSION_ON_SUCCESS_REGEX = [string] . format ( platform_row_name = Texts . TABLE_PLATFORM_ROW_NAME , version = PLATFORM_VERSION ) [EOL] PLATFORM_VERSION_ON_FAIL_REGEX = [string] . format ( platform_row_name = Texts . TABLE_PLATFORM_ROW_NAME , version = Texts . INITIAL_PLATFORM_VERSION ) [EOL] [EOL] [EOL] def assert_version_table_rows ( cmd_output , on_cmd_fail ) : [EOL] [docstring] [EOL] application_row_matches = re . findall ( APPLICATION_VERSION_REGEX , cmd_output ) [EOL] platform_row_matches = re . findall ( PLATFORM_VERSION_ON_FAIL_REGEX if on_cmd_fail else PLATFORM_VERSION_ON_SUCCESS_REGEX , cmd_output ) [EOL] [EOL] assert len ( application_row_matches ) == [number] [EOL] assert len ( platform_row_matches ) == [number] [EOL] [EOL] [EOL] @ pytest . fixture ( ) def mocked_k8s_CoreV1Api ( mocker ) : [EOL] mocked_coreV1Api_class = mocker . patch ( [string] ) [EOL] mocker . patch ( [string] ) [EOL] coreV1API_instance = mocked_coreV1Api_class . return_value [EOL] [EOL] v1_config_map = V1ConfigMap ( data = { NAUTAConfigMap . PLATFORM_VERSION : PLATFORM_VERSION , NAUTAConfigMap . IMAGE_TILLER_FIELD : [string] , NAUTAConfigMap . EXTERNAL_IP_FIELD : [string] , NAUTAConfigMap . IMAGE_TENSORBOARD_SERVICE_FIELD : [string] , NAUTAConfigMap . REGISTRY_FIELD : [string] } ) [EOL] [EOL] coreV1API_instance . read_namespaced_config_map . return_value = v1_config_map [EOL] [EOL] return coreV1API_instance [EOL] [EOL] [EOL] @ pytest . fixture ( ) def mocked_k8s_config ( mocker ) : [EOL] mocker . patch ( [string] ) [EOL] mocked_conf_class = mocker . patch ( [string] ) [EOL] conf_instance = mocked_conf_class . return_value [EOL] conf_instance . host = [string] [EOL] [EOL] [EOL] def test_version ( mocked_k8s_config , mocked_k8s_CoreV1Api ) : [EOL] runner = CliRunner ( ) [EOL] result = runner . invoke ( version . version , [ ] ) [EOL] [EOL] assert_version_table_rows ( result . output , on_cmd_fail = False ) [EOL] [EOL] [EOL] def test_version_with_kubernetes_exception ( mocker ) : [EOL] config_map_mock = mocker . patch ( [string] ) [EOL] config_map_mock . side_effect = KubernetesError ( [string] ) [EOL] runner = CliRunner ( ) [EOL] result = runner . invoke ( version . version , [ ] ) [EOL] [EOL] assert_version_table_rows ( result . output , on_cmd_fail = True ) [EOL] [EOL] assert Texts . KUBECTL_INT_ERROR_MSG + [string] + VERBOSE_RERUN_MSG in result . output [EOL] [EOL] [EOL] def test_version_with_unknown_exception ( mocker ) : [EOL] config_map_mock = mocker . patch ( [string] ) [EOL] config_map_mock . side_effect = Exception ( [string] ) [EOL] runner = CliRunner ( ) [EOL] result = runner . invoke ( version . version , [ ] ) [EOL] [EOL] assert_version_table_rows ( result . output , on_cmd_fail = True ) [EOL] [EOL] assert Texts . OTHER_ERROR_MSG + [string] + VERBOSE_RERUN_MSG in result . output [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import click [EOL] import typing [EOL] from click . testing import CliRunner [EOL] from unittest . mock import patch , mock_open [EOL] [EOL] from cli_text_consts import ConfigCmdTexts as Texts [EOL] from commands . config import config , update_resources_in_packs [EOL] import util . config [EOL] [EOL] WRONG_CONFIGURATION_FILE = [string] [EOL] [EOL] CORRECT_CONFIGURATION_FILE = [string] [string] [EOL] [EOL] CORRECT_CONFIGURATION_FILE_W_FRACTIONS = [string] [string] [string] [string] [EOL] [EOL] [EOL] def test_nauta_config ( mocker ) : [EOL] nauta_config = mocker . patch ( [string] ) [EOL] nauta_config . return_value . minimal_node_memory_amount = [string] [EOL] nauta_config . return_value . minimal_node_cpu_number = [string] [EOL] [EOL] [EOL] def test_config_missing_arguments ( ) : [EOL] [EOL] runner = CliRunner ( ) [EOL] [EOL] result = runner . invoke ( config ) [EOL] [EOL] assert Texts . MISSING_ARGUMENTS in result . output [EOL] [EOL] [EOL] def test_config_incorrect_cpu_format ( mocker ) : [EOL] mocker . patch ( [string] , return_value = [string] ) [EOL] runner = CliRunner ( ) [EOL] [EOL] with patch . object ( util . config . Config , [string] , return_value = [string] ) : [comment] [EOL] result = runner . invoke ( config , [ [string] , [string] , [string] , [string] ] ) [EOL] [EOL] assert Texts . CPU_WRONG_FORMAT in result . output [EOL] [EOL] [EOL] def test_config_incorrect_memory_format ( mocker ) : [EOL] mocker . patch ( [string] , return_value = [string] ) [EOL] runner = CliRunner ( ) [EOL] [EOL] with patch . object ( util . config . Config , [string] , return_value = [string] ) : [comment] [EOL] result = runner . invoke ( config , [ [string] , [string] , [string] , [string] ] ) [EOL] [EOL] assert Texts . MEMORY_WRONG_FORMAT in result . output [EOL] [EOL] [EOL] def test_config_cpu_number_too_low ( mocker ) : [EOL] mocker . patch ( [string] , return_value = [string] ) [EOL] test_nauta_config ( mocker ) [EOL] runner = CliRunner ( ) [EOL] [EOL] with patch . object ( util . config . Config , [string] , return_value = [string] ) : [comment] [EOL] result = runner . invoke ( config , [ [string] , [string] , [string] , [string] ] ) [EOL] [EOL] assert Texts . CPU_SETTINGS_TOO_LOW . format ( cpu_value = [string] ) in result . output [EOL] [EOL] [EOL] def test_config_memory_amount_too_low ( mocker ) : [EOL] mocker . patch ( [string] , return_value = [string] ) [EOL] test_nauta_config ( mocker ) [EOL] runner = CliRunner ( ) [EOL] [EOL] with patch . object ( util . config . Config , [string] , return_value = [string] ) : [comment] [EOL] result = runner . invoke ( config , [ [string] , [string] , [string] , [string] ] ) [EOL] [EOL] assert Texts . MEMORY_SETTINGS_TOO_LOW . format ( memory_value = [string] ) in result . output [EOL] [EOL] [EOL] def test_config_non_existing_config_file ( mocker ) : [EOL] mocker . patch ( [string] , return_value = [string] ) [EOL] mocker . patch ( [string] , return_value = False ) [EOL] test_nauta_config ( mocker ) [EOL] runner = CliRunner ( ) [EOL] [EOL] with patch . object ( util . config . Config , [string] , return_value = [string] ) : [comment] [EOL] result = runner . invoke ( config , [ [string] , [string] , [string] , [string] ] ) [EOL] [EOL] assert Texts . MISSING_CONFIG_FILE in result . output [EOL] [EOL] [EOL] def test_error_during_changing_configuration ( mocker ) : [EOL] mocker . patch ( [string] , return_value = [string] ) [EOL] mocker . patch ( [string] , return_value = True ) [EOL] mocker . patch ( [string] ) [EOL] ovvp_mock = mocker . patch ( [string] , side_effect = RuntimeError ) [EOL] test_nauta_config ( mocker ) [EOL] runner = CliRunner ( ) [EOL] [EOL] with patch ( [string] , mock_open ( read_data = CORRECT_CONFIGURATION_FILE ) ) , patch . object ( util . config . Config , [string] , return_value = [string] ) : [comment] [EOL] result = runner . invoke ( config , [ [string] , [string] , [string] , [string] ] ) [EOL] [EOL] assert Texts . ERROR_DURING_UPDATE in result . output [EOL] assert ovvp_mock . call_count == [number] [EOL] [EOL] [EOL] def test_change_configuration_success ( mocker ) : [EOL] mocker . patch ( [string] , return_value = [string] ) [EOL] mocker . patch ( [string] , return_value = True ) [EOL] mocker . patch ( [string] ) [EOL] ovvp_mock = mocker . patch ( [string] ) [EOL] test_nauta_config ( mocker ) [EOL] [EOL] runner = CliRunner ( ) [EOL] [EOL] with patch ( [string] , mock_open ( read_data = CORRECT_CONFIGURATION_FILE ) ) , patch . object ( util . config . Config , [string] , return_value = [string] ) : [comment] [EOL] result = runner . invoke ( config , [ [string] , [string] , [string] , [string] ] ) [EOL] [EOL] assert Texts . SUCCESS_MESSAGE in result . output [EOL] assert ovvp_mock . call_count == [number] [EOL] [EOL] [EOL] def test_incorrect_config_file ( mocker ) : [EOL] mocker . patch ( [string] , return_value = [string] ) [EOL] mocker . patch ( [string] , return_value = True ) [EOL] mocker . patch ( [string] ) [EOL] mocker . patch ( [string] ) [EOL] sys_exit_mock = mocker . patch ( [string] ) [EOL] [EOL] with patch ( [string] , mock_open ( read_data = WRONG_CONFIGURATION_FILE ) ) , patch . object ( util . config . Config , [string] , return_value = [string] ) : [comment] [EOL] update_resources_in_packs ( ) [EOL] [EOL] assert sys_exit_mock . call_count == [number] , [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import click [EOL] import typing [EOL] import platform [EOL] [EOL] from click . testing import CliRunner [EOL] [EOL] from commands . mount import get_mount_command_linux , get_mount_command_windows , get_mount_command_osx , mount , get_unmount_command_linux , get_unmount_command_windows , get_unmount_command_osx , get_mounts_windows , get_mounts_linux_osx [EOL] [EOL] from cli_text_consts import MountCmdTexts as Texts [EOL] [EOL] [EOL] TEST_USR = [string] [EOL] TEST_PSW = [string] [EOL] TEST_ADR = [string] [EOL] [EOL] CORRECT_LINUX_MOUNT = f" [string] { TEST_USR } [string] " f"{ TEST_PSW } [string] { TEST_ADR } [string] " [EOL] CORRECT_LINUX_UNMOUNT = [string] [EOL] [EOL] CORRECT_WINDOWS_MOUNT = f" [string] { TEST_ADR } [string] { TEST_USR } [string] { TEST_PSW }" [EOL] CORRECT_WINDOWS_UNMOUNT = [string] [EOL] [EOL] CORRECT_OSX_MOUNT = f" [string] { TEST_USR } [string] { TEST_PSW } [string] { TEST_ADR } [string] " [EOL] CORRECT_OSX_UNMOUNT = [string] [EOL] [EOL] MOUNT_IP = [string] [EOL] [EOL] WIN_NET_USE_OUTPUT = f" [string] " f" [string] " f" [string] { MOUNT_IP } [string] " [string] f" [string] { MOUNT_IP } [string] " [string] [string] [string] f" [string] { MOUNT_IP } [string] " [string] f" [string] { MOUNT_IP } [string] " [string] f" [string] " [EOL] [EOL] [EOL] LINUX_MOUNT_OUTPUT = [string] [string] [string] [string] [string] f" [string] { MOUNT_IP } [string] " [string] [string] [string] f" [string] { MOUNT_IP } [string] " [string] [string] [string] [EOL] [EOL] [EOL] OSX_MOUNT_OUTPUT = [string] [string] [string] [string] [string] [string] [string] [string] f" [string] { MOUNT_IP } [string] " [string] f" [string] { MOUNT_IP } [string] " [string] [EOL] [EOL] [EOL] def test_get_mount_command_linux ( mocker ) : [EOL] [comment] [EOL] if platform . system ( ) != [string] : [EOL] mocker . patch ( [string] , return_value = [string] ) [EOL] [EOL] mount = get_mount_command_linux ( TEST_USR , TEST_PSW , TEST_ADR ) [EOL] [EOL] assert mount == CORRECT_LINUX_MOUNT [EOL] else : [EOL] assert True [EOL] [EOL] [EOL] def test_get_mount_command_windows ( mocker ) : [EOL] mount = get_mount_command_windows ( TEST_USR , TEST_PSW , TEST_ADR ) [EOL] [EOL] assert mount == CORRECT_WINDOWS_MOUNT [EOL] [EOL] [EOL] def test_get_mount_command_osx ( mocker ) : [EOL] mount = get_mount_command_osx ( TEST_USR , TEST_PSW , TEST_ADR ) [EOL] [EOL] assert mount == CORRECT_OSX_MOUNT [EOL] [EOL] [EOL] def test_get_unmount_command_linux ( mocker ) : [EOL] [comment] [EOL] unmount = get_unmount_command_linux ( ) [EOL] [EOL] assert unmount == CORRECT_LINUX_UNMOUNT [EOL] [EOL] [EOL] def test_get_unmount_command_windows ( mocker ) : [EOL] unmount = get_unmount_command_windows ( ) [EOL] [EOL] assert unmount == CORRECT_WINDOWS_UNMOUNT [EOL] [EOL] [EOL] def test_get_unmount_command_osx ( mocker ) : [EOL] unmount = get_unmount_command_osx ( ) [EOL] [EOL] assert unmount == CORRECT_OSX_UNMOUNT [EOL] [EOL] [EOL] def test_mount ( mocker ) : [EOL] host_system = platform . system ( ) [EOL] [EOL] mocker . patch ( [string] ) [EOL] mocker . patch ( [string] , return_value = False ) [EOL] gcu_mock = mocker . patch ( [string] , return_value = TEST_USR ) [EOL] gus_mock = mocker . patch ( [string] , return_value = TEST_PSW ) [EOL] cmp_mock = mocker . patch ( [string] , return_value = TEST_ADR ) [EOL] [EOL] runner = CliRunner ( ) [EOL] [comment] [EOL] if host_system != [string] : [EOL] os_getuid_mock = mocker . patch ( [string] , return_value = [string] ) [EOL] [EOL] mocker . patch ( [string] , return_value = [string] ) [EOL] [EOL] result = runner . invoke ( mount ) [EOL] [EOL] assert CORRECT_LINUX_MOUNT in result . output [EOL] assert CORRECT_LINUX_UNMOUNT in result . output [EOL] assert Texts . UNMOUNT_OPTIONS_MSG in result . output [EOL] assert os_getuid_mock . call_count == [number] [EOL] [EOL] mocker . patch ( [string] , return_value = [string] ) [EOL] [EOL] result = runner . invoke ( mount ) [EOL] [EOL] assert CORRECT_WINDOWS_MOUNT in result . output [EOL] assert CORRECT_WINDOWS_UNMOUNT in result . output [EOL] assert Texts . UNMOUNT_OPTIONS_MSG not in result . output [EOL] [EOL] mocker . patch ( [string] , return_value = [string] ) [EOL] [EOL] result = runner . invoke ( mount ) [EOL] [EOL] assert CORRECT_OSX_MOUNT in result . output [EOL] assert CORRECT_OSX_UNMOUNT in result . output [EOL] assert Texts . UNMOUNT_OPTIONS_OSX_MSG in result . output [EOL] [EOL] if host_system != [string] : [EOL] call_number = [number] [EOL] else : [EOL] call_number = [number] [EOL] [EOL] assert gcu_mock . call_count == call_number [EOL] assert gus_mock . call_count == call_number [EOL] assert cmp_mock . call_count == call_number [EOL] [EOL] [EOL] def test_get_mounts_windows ( mocker , capsys ) : [EOL] esc_mock = mocker . patch ( [string] ) [EOL] esc_mock . return_value = WIN_NET_USE_OUTPUT , [number] , WIN_NET_USE_OUTPUT [EOL] gkh_mock = mocker . patch ( [string] ) [EOL] gkh_mock . return_value = MOUNT_IP [EOL] [EOL] get_mounts_windows ( ) [EOL] out , err = capsys . readouterr ( ) [EOL] [EOL] split_output = out . split ( [string] ) [EOL] assert len ( split_output ) == [number] [EOL] assert f" [string] { MOUNT_IP } [string] " in split_output [ [number] ] [EOL] assert [string] in split_output [ [number] ] [EOL] assert [string] in split_output [ [number] ] [EOL] assert [string] in split_output [ [number] ] [EOL] assert f" [string] { MOUNT_IP } [string] " in split_output [ [number] ] [EOL] [EOL] [EOL] def test_get_mounts_linux_non_admin ( mocker , capsys ) : [EOL] esc_mock = mocker . patch ( [string] ) [EOL] esc_mock . return_value = LINUX_MOUNT_OUTPUT , [number] , LINUX_MOUNT_OUTPUT [EOL] gkh_mock = mocker . patch ( [string] ) [EOL] gkh_mock . return_value = MOUNT_IP [EOL] [EOL] get_mounts_linux_osx ( username = [string] , is_admin = False ) [EOL] out , err = capsys . readouterr ( ) [EOL] [EOL] split_output = out . split ( [string] ) [EOL] assert len ( split_output ) == [number] [EOL] assert f" [string] { MOUNT_IP } [string] " in split_output [ [number] ] [EOL] assert [string] in split_output [ [number] ] [EOL] assert [string] in split_output [ [number] ] [EOL] [EOL] [EOL] def test_get_mounts_linux_admin ( mocker , capsys ) : [EOL] esc_mock = mocker . patch ( [string] ) [EOL] esc_mock . return_value = LINUX_MOUNT_OUTPUT , [number] , LINUX_MOUNT_OUTPUT [EOL] gkh_mock = mocker . patch ( [string] ) [EOL] gkh_mock . return_value = MOUNT_IP [EOL] [EOL] get_mounts_linux_osx ( username = [string] , is_admin = True ) [EOL] out , err = capsys . readouterr ( ) [EOL] [EOL] split_output = out . split ( [string] ) [EOL] assert len ( split_output ) == [number] [EOL] assert f" [string] { MOUNT_IP } [string] " in split_output [ [number] ] [EOL] assert [string] in split_output [ [number] ] [EOL] assert [string] in split_output [ [number] ] [EOL] assert [string] in split_output [ [number] ] [EOL] [EOL] [EOL] def test_get_mounts_osx_non_admin ( mocker , capsys ) : [EOL] esc_mock = mocker . patch ( [string] ) [EOL] esc_mock . return_value = OSX_MOUNT_OUTPUT , [number] , OSX_MOUNT_OUTPUT [EOL] gkh_mock = mocker . patch ( [string] ) [EOL] gkh_mock . return_value = MOUNT_IP [EOL] [EOL] get_mounts_linux_osx ( username = [string] , is_admin = False , osx = True ) [EOL] out , err = capsys . readouterr ( ) [EOL] [EOL] split_output = out . split ( [string] ) [EOL] assert len ( split_output ) == [number] [EOL] assert f"{ MOUNT_IP } [string] " in split_output [ [number] ] [EOL] assert [string] in split_output [ [number] ] [EOL] assert [string] in split_output [ [number] ] [EOL] [EOL] [EOL] def test_get_mounts_osx_admin ( mocker , capsys ) : [EOL] esc_mock = mocker . patch ( [string] ) [EOL] esc_mock . return_value = OSX_MOUNT_OUTPUT , [number] , OSX_MOUNT_OUTPUT [EOL] gkh_mock = mocker . patch ( [string] ) [EOL] gkh_mock . return_value = MOUNT_IP [EOL] [EOL] get_mounts_linux_osx ( username = [string] , is_admin = True , osx = True ) [EOL] out , err = capsys . readouterr ( ) [EOL] [EOL] split_output = out . split ( [string] ) [EOL] assert len ( split_output ) == [number] [EOL] assert f"{ MOUNT_IP } [string] " in split_output [ [number] ] [EOL] assert [string] in split_output [ [number] ] [EOL] assert [string] in split_output [ [number] ] [EOL] assert [string] in split_output [ [number] ] [EOL] assert [string] in split_output [ [number] ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] [docstring] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import typing [EOL] import pytest [EOL] [EOL] [EOL] @ pytest . fixture ( autouse = True ) def mock_cli_validation ( mocker ) : [EOL] mocker . patch ( [string] ) [EOL] mocker . patch ( [string] ) [EOL] mocker . patch ( [string] ) [EOL] [EOL] [EOL] @ pytest . fixture ( autouse = True ) def mock_k8s_client ( mocker ) : [EOL] mocker . patch ( [string] ) [EOL] [EOL] [EOL] @ pytest . fixture ( autouse = True ) def mock_check_nauta_pods ( mocker ) : [EOL] mocker . patch ( [string] ) [EOL] [EOL] [EOL] @ pytest . fixture ( autouse = True ) def mock_get_click_context ( mocker ) : [EOL] click_context = mocker . patch ( [string] ) [EOL] click_context . return_value . obj . force = False [EOL] return click_context [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import setuptools [EOL] [EOL] setuptools . setup ( name = [string] , version = [string] , description = [string] , packages = [ [string] ] , keywords = [ [string] , [string] , [string] ] , install_requires = [ [string] , ] , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , Dict , Optional [EOL] import logging [EOL] import typing [EOL] try : [EOL] from http import HTTPStatus [comment] [EOL] except ImportError : [EOL] import httplib as HTTPStatus [comment] [EOL] import logging [EOL] import os [EOL] [EOL] from kubernetes import config , client [EOL] from kubernetes . client . rest import ApiException [EOL] [EOL] [EOL] API_GROUP_NAME = [string] [EOL] RUN_PLURAL = [string] [EOL] RUN_VERSION = [string] [EOL] [EOL] MAX_RETRIES_COUNT = [number] [EOL] [EOL] ch = logging . StreamHandler ( ) [EOL] ch . setLevel ( logging . INFO ) [EOL] logger = logging . getLogger ( [string] ) [EOL] logger . setLevel ( logging . INFO ) [EOL] logger . addHandler ( ch ) [EOL] [EOL] run_k8s_name = os . getenv ( [string] ) [EOL] [EOL] if run_k8s_name : [EOL] config . load_incluster_config ( ) [EOL] api = client . CustomObjectsApi ( client . ApiClient ( ) ) [EOL] [EOL] [EOL] def publish ( metrics , raise_exception = False ) : [EOL] [docstring] [EOL] if not run_k8s_name : [EOL] logger . info ( [string] . format ( metrics ) ) [EOL] return [EOL] [EOL] with open ( [string] , [string] ) as ns_file : [EOL] namespace = ns_file . read ( ) [EOL] [EOL] body = { [string] : { [string] : metrics } } [EOL] [EOL] for i in range ( MAX_RETRIES_COUNT ) : [EOL] try : [EOL] api . patch_namespaced_custom_object ( group = [string] , namespace = namespace , body = body , plural = RUN_PLURAL , version = RUN_VERSION , name = run_k8s_name ) [EOL] break [EOL] except ApiException as e : [EOL] if e . status != HTTPStatus . CONFLICT or i == MAX_RETRIES_COUNT - [number] : [EOL] logger . exception ( [string] . format ( MAX_RETRIES_COUNT ) , e ) [EOL] if raise_exception : [EOL] raise e [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.int$ 0 0 0 0 $logging.StreamHandler$ 0 0 0 0 0 0 0 $logging.StreamHandler$ 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 $logging.StreamHandler$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] from typing import Type [EOL] import applications [EOL] import typing [EOL] from collections import namedtuple [EOL] [EOL] LogEntry = namedtuple ( [string] , [ [string] , [string] , [string] , [string] ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[applications.cli.logs_aggregator.k8s_log_entry.LogEntry]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import builtins [EOL] from typing import Any , Union , List , Dict [EOL] import typing [EOL] import unittest [EOL] from unittest . mock import MagicMock [EOL] [EOL] import pytest [EOL] [EOL] from logs_aggregator . k8s_es_client import K8sElasticSearchClient [EOL] from logs_aggregator . k8s_log_entry import LogEntry [EOL] from platform_resources . run import Run [EOL] from platform_resources . workflow import ArgoWorkflow [EOL] [EOL] TEST_SCAN_OUTPUT = [ { [string] : [string] , [string] : [string] , [string] : [string] , [string] : None , [string] : { [string] : [string] , [string] : [string] , [string] : { [string] : [string] } , [string] : { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : { [string] : [string] , [string] : [string] } , [string] : [string] , [string] : [string] , [string] : [string] } , [string] : [string] , [string] : [string] [string] [string] } , [string] : [ [number] ] } , { [string] : [string] , [string] : [string] , [string] : [string] , [string] : None , [string] : { [string] : [string] , [string] : [string] , [string] : { [string] : [string] } , [string] : { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : { [string] : [string] , [string] : [string] } , [string] : [string] , [string] : [string] , [string] : [string] } , [string] : [string] , [string] : [string] [string] [string] } , [string] : [ [number] ] } , ] [EOL] [EOL] TEST_LOG_ENTRIES = [ LogEntry ( date = [string] , content = [string] , pod_name = [string] , namespace = [string] ) , LogEntry ( date = [string] , content = [string] , pod_name = [string] , namespace = [string] ) ] [EOL] [EOL] TEST_SEARCH_OUTPUT_EMPTY = { [string] : [number] , [string] : False , [string] : { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] } , [string] : { [string] : [number] , [string] : None , [string] : [ ] } } [EOL] [EOL] [EOL] @ pytest . fixture ( ) def mock_k8s_info ( mocker ) : [EOL] get_secret_mock = mocker . patch ( [string] ) [EOL] get_secret_mock . return_value = [string] [EOL] [EOL] [EOL] def test_full_log_search ( mock_k8s_info , mocker ) : [EOL] client = K8sElasticSearchClient ( host = [string] , port = [number] , namespace = [string] ) [EOL] es_scan_mock = mocker . patch ( [string] ) [EOL] es_scan_mock . return_value = iter ( TEST_SCAN_OUTPUT ) [EOL] [EOL] assert list ( client . get_log_generator ( ) ) == TEST_LOG_ENTRIES [EOL] [EOL] [EOL] def test_full_log_search_filter ( mock_k8s_info , mocker ) : [EOL] client = K8sElasticSearchClient ( host = [string] , port = [number] , namespace = [string] ) [EOL] es_scan_mock = mocker . patch ( [string] ) [EOL] es_scan_mock . return_value = iter ( TEST_SCAN_OUTPUT ) [EOL] [EOL] filter_all_results = list ( client . get_log_generator ( filters = [ lambda x : False ] ) ) [EOL] assert filter_all_results == [ ] [EOL] [EOL] [EOL] def test_full_log_search_filter_idempotent ( mock_k8s_info , mocker ) : [EOL] client = K8sElasticSearchClient ( host = [string] , port = [number] , namespace = [string] ) [EOL] es_scan_mock = mocker . patch ( [string] ) [EOL] es_scan_mock . return_value = iter ( TEST_SCAN_OUTPUT ) [EOL] [EOL] filter_all_results = list ( client . get_log_generator ( filters = [ lambda x : True ] ) ) [EOL] assert filter_all_results == TEST_LOG_ENTRIES [EOL] [EOL] [EOL] def test_get_experiment_logs ( mock_k8s_info , mocker ) : [EOL] client = K8sElasticSearchClient ( host = [string] , port = [number] , namespace = [string] ) [EOL] mocked_log_search = mocker . patch . object ( client , [string] ) [EOL] mocked_log_search . return_value = iter ( TEST_LOG_ENTRIES ) [EOL] [EOL] experiment_name = [string] [EOL] namespace = [string] [EOL] [EOL] run_mock = MagicMock ( spec = Run ) [EOL] run_mock . name = experiment_name [EOL] [EOL] run_start_date = [string] [EOL] [EOL] experiment_logs = client . get_experiment_logs_generator ( run = run_mock , namespace = namespace , start_date = run_start_date ) [EOL] [EOL] for log , expected_log in zip ( experiment_logs , TEST_LOG_ENTRIES ) : [EOL] assert log == expected_log [EOL] [EOL] mocked_log_search . assert_called_with ( query_body = { [string] : { [string] : { [string] : [ { [string] : { [string] : experiment_name } } , { [string] : { [string] : namespace } } ] , [string] : { [string] : { [string] : { [string] : run_start_date } } } } } , [string] : { [string] : { [string] : [string] } } } , filters = [ ] , index = [string] ) [EOL] [EOL] [EOL] def test_get_workflow_logs ( mocker ) : [EOL] client = K8sElasticSearchClient ( host = [string] , port = [number] , namespace = [string] ) [EOL] mocked_log_search = mocker . patch . object ( client , [string] ) [EOL] mocked_log_search . return_value = iter ( TEST_LOG_ENTRIES ) [EOL] [EOL] namespace = [string] [EOL] [EOL] workflow_name = [string] [EOL] workflow_mock = MagicMock ( spec = ArgoWorkflow ) [EOL] workflow_mock . name = workflow_name [EOL] [EOL] workflow_start_date = [string] [EOL] [EOL] experiment_logs = client . get_argo_workflow_logs_generator ( workflow = workflow_mock , namespace = namespace , start_date = workflow_start_date ) [EOL] [EOL] for log , expected_log in zip ( experiment_logs , TEST_LOG_ENTRIES ) : [EOL] assert log == expected_log [EOL] [EOL] mocked_log_search . assert_called_with ( query_body = { [string] : { [string] : { [string] : [ { [string] : { [string] : workflow_mock . name } } , { [string] : { [string] : namespace } } ] , [string] : { [string] : { [string] : { [string] : workflow_start_date } } } } } , [string] : { [string] : { [string] : [string] } } } , index = [string] ) [EOL] [EOL] [EOL] def test_get_experiment_logs_time_range ( mock_k8s_info , mocker ) : [EOL] client = K8sElasticSearchClient ( host = [string] , port = [number] , namespace = [string] ) [EOL] mocked_log_search = mocker . patch . object ( client , [string] ) [EOL] mocked_log_search . return_value = iter ( TEST_LOG_ENTRIES ) [EOL] [EOL] experiment_name = [string] [EOL] namespace = [string] [EOL] [EOL] run_mock = MagicMock ( spec = Run ) [EOL] run_mock . name = experiment_name [EOL] [EOL] start_date = [string] [EOL] end_date = [string] [EOL] [EOL] experiment_logs = client . get_experiment_logs_generator ( run = run_mock , namespace = namespace , start_date = start_date , end_date = end_date ) [EOL] [EOL] for log , expected_log in zip ( experiment_logs , TEST_LOG_ENTRIES ) : [EOL] assert log == expected_log [EOL] [EOL] mocked_log_search . assert_called_with ( query_body = { [string] : { [string] : { [string] : [ { [string] : { [string] : experiment_name } } , { [string] : { [string] : namespace } } ] , [string] : { [string] : { [string] : { [string] : start_date , [string] : end_date } } } } } , [string] : { [string] : { [string] : [string] } } } , filters = [ ] , index = [string] ) [EOL] [EOL] [EOL] def test_delete_logs_for_namespace ( mock_k8s_info , mocker ) : [EOL] client = K8sElasticSearchClient ( host = [string] , port = [number] , namespace = [string] ) [EOL] mocked_delete_logs = mocker . patch . object ( client , [string] ) [EOL] [EOL] client . delete_logs_for_namespace ( [string] ) [EOL] [EOL] assert mocked_delete_logs . call_count == [number] [EOL] [EOL] [EOL] def test_delete_logs_for_run ( mock_k8s_info , mocker ) : [EOL] client = K8sElasticSearchClient ( host = [string] , port = [number] , namespace = [string] ) [EOL] mocked_delete_logs = mocker . patch . object ( client , [string] ) [EOL] [EOL] run_name = [string] [EOL] namespace = [string] [EOL] [EOL] client . delete_logs_for_run ( run_name , namespace ) [EOL] [EOL] delete_query = { [string] : { [string] : { [string] : [ { [string] : { [string] : run_name } } , { [string] : { [string] : namespace } } ] } } } [EOL] [EOL] mocked_delete_logs . assert_called_with ( index = [string] , body = delete_query ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Union[typing.Dict[builtins.str,builtins.int],typing.Dict[builtins.str,typing.Union[None,typing.List[typing.Any],builtins.int]],builtins.int]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import typing [EOL] import pytest [EOL] [EOL] [EOL] from logs_aggregator . log_filters import filter_log_by_severity , filter_log_by_pod_status , SeverityLevel , filter_log_by_pod_ids [EOL] from logs_aggregator . k8s_log_entry import LogEntry [EOL] from util . k8s . k8s_info import PodStatus [EOL] [EOL] no_severity_log_entry = LogEntry ( date = [string] , content = [string] , pod_name = [string] , namespace = [string] ) [EOL] debug_log_entry = LogEntry ( date = [string] , content = [string] , pod_name = [string] , namespace = [string] ) [EOL] info_log_entry = LogEntry ( date = [string] , content = [string] , pod_name = [string] , namespace = [string] ) [EOL] warning_log_entry = LogEntry ( date = [string] , content = [string] , pod_name = [string] , namespace = [string] ) [EOL] error_log_entry = LogEntry ( date = [string] , content = [string] , pod_name = [string] , namespace = [string] ) [EOL] critical_log_entry = LogEntry ( date = [string] , content = [string] , pod_name = [string] , namespace = [string] ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ debug_log_entry , info_log_entry , warning_log_entry , error_log_entry , critical_log_entry ] ) def test_filter_log_by_severity_debug ( log_entry ) : [EOL] assert filter_log_by_severity ( log_entry , SeverityLevel . DEBUG ) == True [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ info_log_entry , warning_log_entry , error_log_entry , critical_log_entry ] ) def test_filter_log_by_severity_info ( log_entry ) : [EOL] assert filter_log_by_severity ( log_entry , SeverityLevel . INFO ) == True [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ debug_log_entry ] ) def test_filter_log_by_severity_info_negative ( log_entry ) : [EOL] assert filter_log_by_severity ( log_entry , SeverityLevel . INFO ) == False [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ warning_log_entry , error_log_entry , critical_log_entry ] ) def test_filter_log_by_severity_warning ( log_entry ) : [EOL] assert filter_log_by_severity ( log_entry , SeverityLevel . WARNING ) == True [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ debug_log_entry , info_log_entry ] ) def test_filter_log_by_severity_warning_negative ( log_entry ) : [EOL] assert filter_log_by_severity ( log_entry , SeverityLevel . WARNING ) == False [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ error_log_entry , critical_log_entry ] ) def test_filter_log_by_severity_error ( log_entry ) : [EOL] assert filter_log_by_severity ( log_entry , SeverityLevel . ERROR ) == True [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ debug_log_entry , info_log_entry , warning_log_entry ] ) def test_filter_log_by_severity_error_negative ( log_entry ) : [EOL] assert filter_log_by_severity ( log_entry , SeverityLevel . ERROR ) == False [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ critical_log_entry ] ) def test_filter_log_by_severity_critical ( log_entry ) : [EOL] assert filter_log_by_severity ( log_entry , SeverityLevel . CRITICAL ) == True [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ debug_log_entry , info_log_entry , warning_log_entry , error_log_entry ] ) def test_filter_log_by_severity_critical_negative ( log_entry ) : [EOL] assert filter_log_by_severity ( log_entry , SeverityLevel . CRITICAL ) == False [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , list ( PodStatus ) ) def test_filter_log_by_pod_status ( status , mocker ) : [EOL] [EOL] log_entry = LogEntry ( date = [string] , pod_name = [string] , namespace = [string] , content = [string] ) [EOL] [EOL] mocked_get_pod_status = mocker . patch ( [string] ) [EOL] mocked_get_pod_status . return_value = status [EOL] [EOL] assert filter_log_by_pod_status ( log_entry , status ) == True [EOL] [EOL] [EOL] def test_filter_log_by_pod_ids ( ) : [EOL] pod_id = [string] [EOL] [EOL] log_entry = LogEntry ( date = [string] , pod_name = [string] , namespace = [string] , content = [string] ) [EOL] [EOL] assert filter_log_by_pod_ids ( pod_ids = { pod_id } , log_entry = log_entry ) == True [EOL] assert filter_log_by_pod_ids ( pod_ids = { [string] } , log_entry = log_entry ) == False [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , List , Set [EOL] import subprocess [EOL] import builtins [EOL] import argparse [EOL] import typing [EOL] import argparse [EOL] import subprocess [EOL] from typing import List [EOL] [EOL] [EOL] IGNORED_ERRORS = { [string] , [string] , } [EOL] [EOL] [EOL] def run_mypy_check ( target , config_file ) : [EOL] try : [EOL] result = subprocess . run ( [ [string] , [string] , config_file , target ] , stdout = subprocess . PIPE ) [EOL] errors = result . stdout . decode ( [string] ) . split ( [string] ) [EOL] errors = [ e for e in errors if e ] [comment] [EOL] return errors [EOL] except subprocess . CalledProcessError as e : [EOL] print ( e . output ) [EOL] raise [EOL] [EOL] [EOL] def filter_mypy_results ( mypy_results ) : [EOL] return [ error for error in mypy_results if not any ( ignored_error in error for ignored_error in IGNORED_ERRORS ) ] [EOL] [EOL] [EOL] def parse_args ( ) : [EOL] parser = argparse . ArgumentParser ( description = [string] ) [EOL] parser . add_argument ( [string] , default = [string] , help = [string] ) [EOL] parser . add_argument ( [string] , default = [string] , help = [string] ) [EOL] return parser . parse_args ( ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] args = parse_args ( ) [EOL] mypy_results = run_mypy_check ( target = args . target , config_file = args . config_file ) [EOL] filtered_mypy_results = filter_mypy_results ( mypy_results ) [EOL] if filtered_mypy_results : [EOL] print ( [string] ) [EOL] print ( filtered_mypy_results ) [EOL] print ( [string] . join ( filtered_mypy_results ) ) [EOL] exit ( [number] ) [EOL] else : [EOL] print ( [string] ) [EOL] exit ( [number] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Set[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 $typing.Set[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import unittest [EOL] import git_repo_manager [EOL] import typing [EOL] import requests_mock [EOL] from unittest . mock import MagicMock [EOL] [EOL] import pytest [EOL] from requests . exceptions import HTTPError [EOL] from requests_mock import Mocker [EOL] [EOL] from git_repo_manager . client import GitRepoManagerClient [EOL] [EOL] FAKE_USER = [string] [EOL] [EOL] [EOL] @ pytest . fixture ( ) def git_repo_manager ( mocker ) : [EOL] grm = GitRepoManagerClient ( host = [string] ) [EOL] mocker . patch . object ( grm , [string] , return_value = [string] ) [EOL] return grm [EOL] [EOL] [EOL] def test_get_user ( requests_mock , git_repo_manager ) : [EOL] get_user_mock = requests_mock . get ( f'{ git_repo_manager . base_url } [string] { FAKE_USER }' , status_code = [number] ) [EOL] response = git_repo_manager . get_user ( FAKE_USER ) [EOL] [EOL] assert response [EOL] assert get_user_mock . call_count == [number] [EOL] [EOL] [EOL] def test_get_user_not_found ( requests_mock , git_repo_manager ) : [EOL] get_user_mock = requests_mock . get ( f'{ git_repo_manager . base_url } [string] { FAKE_USER }' , status_code = [number] ) [EOL] response = git_repo_manager . get_user ( FAKE_USER ) [EOL] [EOL] assert not response [EOL] assert get_user_mock . call_count == [number] [EOL] [EOL] [EOL] def test_get_user_error ( requests_mock , git_repo_manager ) : [EOL] get_user_mock = requests_mock . get ( f'{ git_repo_manager . base_url } [string] { FAKE_USER }' , status_code = [number] ) [EOL] with pytest . raises ( HTTPError ) : [EOL] git_repo_manager . get_user ( FAKE_USER ) [EOL] [EOL] assert get_user_mock . call_count == [number] [EOL] [EOL] [EOL] def test_create_user_exists ( requests_mock , git_repo_manager ) : [EOL] requests_mock . get ( f'{ git_repo_manager . base_url } [string] { FAKE_USER }' , status_code = [number] ) [EOL] post_user_mock = requests_mock . post ( f'{ git_repo_manager . base_url } [string] ' ) [EOL] response = git_repo_manager . create_user ( username = FAKE_USER , email = [string] ) [EOL] [EOL] assert response [EOL] assert post_user_mock . call_count == [number] [EOL] [EOL] [EOL] def test_create_user_new ( requests_mock , git_repo_manager ) : [EOL] requests_mock . get ( f'{ git_repo_manager . base_url } [string] { FAKE_USER }' , status_code = [number] ) [EOL] post_user_mock = requests_mock . post ( f'{ git_repo_manager . base_url } [string] ' ) [EOL] response = git_repo_manager . create_user ( username = FAKE_USER , email = [string] ) [EOL] [EOL] assert response [EOL] assert post_user_mock . call_count == [number] [EOL] [EOL] [EOL] def test_create_user_error ( requests_mock , git_repo_manager ) : [EOL] requests_mock . get ( f'{ git_repo_manager . base_url } [string] { FAKE_USER }' , status_code = [number] ) [EOL] post_user_mock = requests_mock . post ( f'{ git_repo_manager . base_url } [string] ' , status_code = [number] ) [EOL] with pytest . raises ( HTTPError ) : [EOL] git_repo_manager . create_user ( username = FAKE_USER , email = [string] ) [EOL] [EOL] assert post_user_mock . call_count == [number] [EOL] [EOL] [EOL] def test_delete_user ( requests_mock , git_repo_manager ) : [EOL] requests_mock . get ( f'{ git_repo_manager . base_url } [string] { FAKE_USER }' , status_code = [number] ) [EOL] delete_user_mock = requests_mock . delete ( f'{ git_repo_manager . base_url } [string] { FAKE_USER }' ) [EOL] response = git_repo_manager . delete_user ( username = FAKE_USER ) [EOL] [EOL] assert response [EOL] assert delete_user_mock . call_count == [number] [EOL] [EOL] [EOL] def test_delete_user_does_not_exist ( requests_mock , git_repo_manager ) : [EOL] requests_mock . get ( f'{ git_repo_manager . base_url } [string] { FAKE_USER }' , status_code = [number] ) [EOL] delete_user_mock = requests_mock . delete ( f'{ git_repo_manager . base_url } [string] { FAKE_USER }' ) [EOL] response = git_repo_manager . delete_user ( username = FAKE_USER ) [EOL] [EOL] assert response is None [EOL] assert delete_user_mock . call_count == [number] [EOL] [EOL] [EOL] def test_add_public_key_for_user ( requests_mock , git_repo_manager ) : [EOL] add_key_mock = requests_mock . post ( f'{ git_repo_manager . base_url } [string] { FAKE_USER } [string] ' ) [EOL] response = git_repo_manager . add_public_key_for_user ( username = FAKE_USER , public_key = [string] ) [EOL] [EOL] assert response [EOL] assert add_key_mock . call_count == [number] [EOL] [EOL] [EOL] def test_add_public_key_for_user_error ( requests_mock , git_repo_manager ) : [EOL] add_key_mock = requests_mock . post ( f'{ git_repo_manager . base_url } [string] { FAKE_USER } [string] ' , status_code = [number] ) [EOL] with pytest . raises ( HTTPError ) : [EOL] git_repo_manager . add_public_key_for_user ( username = FAKE_USER , public_key = [string] ) [EOL] [EOL] assert add_key_mock . call_count == [number] [EOL] [EOL] [EOL] def test_get_repository ( requests_mock , git_repo_manager ) : [EOL] repo_name = [string] [EOL] get_repo_mock = requests_mock . get ( f'{ git_repo_manager . base_url } [string] { FAKE_USER } [string] { repo_name }' , status_code = [number] ) [EOL] response = git_repo_manager . get_repository ( username = FAKE_USER , repository_name = repo_name ) [EOL] [EOL] assert response [EOL] assert get_repo_mock . call_count == [number] [EOL] [EOL] [EOL] def test_get_repository_not_found ( requests_mock , git_repo_manager ) : [EOL] repo_name = [string] [EOL] get_repo_mock = requests_mock . get ( f'{ git_repo_manager . base_url } [string] { FAKE_USER } [string] { repo_name }' , status_code = [number] ) [EOL] response = git_repo_manager . get_repository ( username = FAKE_USER , repository_name = repo_name ) [EOL] [EOL] assert not response [EOL] assert get_repo_mock . call_count == [number] [EOL] [EOL] [EOL] def test_get_repository_error ( requests_mock , git_repo_manager ) : [EOL] repo_name = [string] [EOL] get_repo_mock = requests_mock . get ( f'{ git_repo_manager . base_url } [string] { FAKE_USER } [string] { repo_name }' , status_code = [number] ) [EOL] with pytest . raises ( HTTPError ) : [EOL] git_repo_manager . get_repository ( username = FAKE_USER , repository_name = repo_name ) [EOL] [EOL] assert get_repo_mock . call_count == [number] [EOL] [EOL] [EOL] def test_create_repository ( requests_mock , git_repo_manager ) : [EOL] repo_name = [string] [EOL] get_repo_mock = requests_mock . get ( f'{ git_repo_manager . base_url } [string] { FAKE_USER } [string] { repo_name }' , status_code = [number] ) [EOL] post_repo_mock = requests_mock . post ( f'{ git_repo_manager . base_url } [string] { FAKE_USER } [string] ' ) [EOL] response = git_repo_manager . create_repository ( username = FAKE_USER , repository_name = repo_name ) [EOL] [EOL] assert response [EOL] assert get_repo_mock . call_count == [number] [EOL] assert post_repo_mock . call_count == [number] [EOL] [EOL] [EOL] def test_create_repository_exists ( requests_mock , git_repo_manager ) : [EOL] repo_name = [string] [EOL] get_repo_mock = requests_mock . get ( f'{ git_repo_manager . base_url } [string] { FAKE_USER } [string] { repo_name }' , status_code = [number] ) [EOL] post_repo_mock = requests_mock . post ( f'{ git_repo_manager . base_url } [string] { FAKE_USER } [string] ' ) [EOL] response = git_repo_manager . create_repository ( username = FAKE_USER , repository_name = repo_name ) [EOL] [EOL] assert response [EOL] assert get_repo_mock . call_count == [number] [EOL] assert post_repo_mock . call_count == [number] [EOL] [EOL] [EOL] def test_create_repository_error ( requests_mock , git_repo_manager ) : [EOL] repo_name = [string] [EOL] get_repo_mock = requests_mock . get ( f'{ git_repo_manager . base_url } [string] { FAKE_USER } [string] { repo_name }' , status_code = [number] ) [EOL] post_repo_mock = requests_mock . post ( f'{ git_repo_manager . base_url } [string] { FAKE_USER } [string] ' , status_code = [number] ) [EOL] with pytest . raises ( HTTPError ) : [EOL] git_repo_manager . create_repository ( username = FAKE_USER , repository_name = repo_name ) [EOL] [EOL] assert get_repo_mock . call_count == [number] [EOL] assert post_repo_mock . call_count == [number] [EOL] [EOL] [EOL] def test_delete_repository ( requests_mock , git_repo_manager ) : [EOL] repo_name = [string] [EOL] get_repo_mock = requests_mock . get ( f'{ git_repo_manager . base_url } [string] { FAKE_USER } [string] { repo_name }' , status_code = [number] ) [EOL] delete_repo_mock = requests_mock . delete ( f'{ git_repo_manager . base_url } [string] { FAKE_USER } [string] { repo_name }' ) [EOL] response = git_repo_manager . delete_repository ( username = FAKE_USER , repository_name = repo_name ) [EOL] [EOL] assert response [EOL] assert get_repo_mock . call_count == [number] [EOL] assert delete_repo_mock . call_count == [number] [EOL] [EOL] [EOL] def test_token_saved ( mocker ) : [EOL] fake_token = [string] [EOL] secret_mock = MagicMock ( ) [EOL] secret_mock . data = { [string] : fake_token } [EOL] get_secret_mock = mocker . patch ( [string] , return_value = secret_mock ) [EOL] create_token_mock = mocker . patch ( [string] ) [EOL] save_token_mock = mocker . patch ( [string] ) [EOL] grm = GitRepoManagerClient ( host = [string] ) [EOL] [EOL] assert grm . session is not None [EOL] assert grm . _token == f' [string] { fake_token }' [EOL] assert get_secret_mock . call_count == [number] [EOL] assert create_token_mock . call_count == [number] [EOL] assert save_token_mock . call_count == [number] [EOL] [EOL] [EOL] def test_token_create ( mocker ) : [EOL] fake_token = [string] [EOL] secret_mock = MagicMock ( ) [EOL] secret_mock . data = { } [EOL] get_secret_mock = mocker . patch ( [string] , return_value = secret_mock ) [EOL] create_token_mock = mocker . patch ( [string] , return_value = fake_token ) [EOL] save_token_mock = mocker . patch ( [string] ) [EOL] grm = GitRepoManagerClient ( host = [string] ) [EOL] [EOL] assert grm . session is not None [EOL] assert grm . _token == f' [string] { fake_token }' [EOL] assert get_secret_mock . call_count == [number] [EOL] assert create_token_mock . call_count == [number] [EOL] assert save_token_mock . call_count == [number] [EOL] [EOL] [EOL] def test_add_nauta_user ( mocker , git_repo_manager ) : [EOL] generate_key = mocker . patch . object ( git_repo_manager , [string] , return_value = ( [string] , [string] ) ) [EOL] create_user = mocker . patch . object ( git_repo_manager , [string] ) [EOL] add_key = mocker . patch . object ( git_repo_manager , [string] ) [EOL] create_repo = mocker . patch . object ( git_repo_manager , [string] ) [EOL] create_secret = mocker . patch ( [string] ) [EOL] [EOL] git_repo_manager . add_nauta_user ( username = [string] ) [EOL] [EOL] assert generate_key . call_count == [number] [EOL] assert create_user . call_count == [number] [EOL] assert add_key . call_count == [number] [EOL] assert create_repo . call_count == [number] [EOL] assert create_secret . call_count == [number] [EOL] [EOL] [EOL] def test_add_nauta_user_failure ( mocker , git_repo_manager ) : [EOL] generate_key = mocker . patch . object ( git_repo_manager , [string] , return_value = ( [string] , [string] ) ) [EOL] create_user = mocker . patch . object ( git_repo_manager , [string] , side_effect = RuntimeError ) [EOL] add_key = mocker . patch . object ( git_repo_manager , [string] ) [EOL] create_repo = mocker . patch . object ( git_repo_manager , [string] ) [EOL] create_secret = mocker . patch ( [string] ) [EOL] [EOL] with pytest . raises ( RuntimeError ) : [EOL] git_repo_manager . add_nauta_user ( username = [string] ) [EOL] [EOL] assert generate_key . call_count == [number] [EOL] assert create_user . call_count == [number] [EOL] assert add_key . call_count == [number] [EOL] assert create_repo . call_count == [number] [EOL] assert create_secret . call_count == [number] [EOL] [EOL] [EOL] def test_delete_nauta_user ( mocker , git_repo_manager ) : [EOL] delete_user = mocker . patch . object ( git_repo_manager , [string] ) [EOL] delete_repo = mocker . patch . object ( git_repo_manager , [string] ) [EOL] [EOL] git_repo_manager . delete_nauta_user ( username = [string] ) [EOL] [EOL] assert delete_user . call_count == [number] [EOL] assert delete_repo . call_count == [number] [EOL] [EOL] [EOL] def test_delete_nauta_user_failure ( mocker , git_repo_manager ) : [EOL] delete_user = mocker . patch . object ( git_repo_manager , [string] , side_effect = RuntimeError ) [EOL] delete_repo = mocker . patch . object ( git_repo_manager , [string] ) [EOL] [EOL] with pytest . raises ( RuntimeError ) : [EOL] git_repo_manager . delete_nauta_user ( username = [string] ) [EOL] [EOL] assert delete_user . call_count == [number] [EOL] assert delete_repo . call_count == [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $git_repo_manager.client.GitRepoManagerClient$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import typing [EOL] import unittest [EOL] import base64 [EOL] import pytest [EOL] from unittest . mock import MagicMock [EOL] [EOL] from git_repo_manager . utils import get_fake_ssh_path , upload_experiment_to_git_repo_manager , create_gitignore_file_for_experiments , compute_hash_of_k8s_env_address , delete_exp_tag_from_git_repo_manager [EOL] [EOL] [EOL] def test_get_fake_ssh_path ( mocker , tmpdir ) : [EOL] fake_secret = MagicMock ( ) [EOL] fake_key = [string] [EOL] fake_username = [string] [EOL] fake_hash = [string] [EOL] fake_secret . data = { [string] : base64 . encodebytes ( str . encode ( fake_key ) ) . decode ( encoding = [string] ) } [EOL] get_secret_mock = mocker . patch ( [string] , return_value = fake_secret ) [EOL] env_hash_mock = mocker . patch ( [string] , return_value = fake_hash ) [EOL] config_dir = tmpdir . mkdir ( [string] ) [EOL] private_key_file = config_dir . join ( f' [string] { fake_username } [string] { fake_hash }' ) [EOL] fake_ssh_file = config_dir . join ( f' [string] { fake_username } [string] { fake_hash }' ) [EOL] get_fake_ssh_path ( config_dir = config_dir , username = fake_username ) [EOL] [EOL] get_secret_mock . assert_called_with ( namespace = fake_username , secret_name = [string] ) [EOL] assert env_hash_mock . call_count == [number] [EOL] assert private_key_file . read ( ) == fake_key [EOL] assert [string] in fake_ssh_file . read ( ) [EOL] [EOL] [EOL] def test_get_fake_ssh_path_exists ( mocker , tmpdir ) : [EOL] fake_secret = MagicMock ( ) [EOL] fake_key = [string] [EOL] fake_username = [string] [EOL] fake_hash = [string] [EOL] fake_secret . data = { [string] : base64 . encodebytes ( str . encode ( fake_key ) ) . decode ( encoding = [string] ) } [EOL] [EOL] get_secret_mock = mocker . patch ( [string] , return_value = fake_secret ) [EOL] env_hash_mock = mocker . patch ( [string] , return_value = fake_hash ) [EOL] config_dir = tmpdir . mkdir ( [string] ) [EOL] private_key_file = config_dir . join ( f' [string] { fake_username } [string] { fake_hash }' ) [EOL] private_key_file . write ( fake_key ) [EOL] fake_ssh = f' [string] ' [EOL] fake_ssh_file = config_dir . join ( f' [string] { fake_username } [string] { fake_hash }' ) [EOL] fake_ssh_file . write ( fake_ssh ) [EOL] [EOL] get_fake_ssh_path ( config_dir = config_dir , username = fake_username ) [EOL] [EOL] assert get_secret_mock . call_count == [number] [EOL] assert env_hash_mock . call_count == [number] [EOL] assert private_key_file . read ( ) == fake_key [EOL] assert fake_ssh_file . read ( ) == fake_ssh [EOL] [EOL] [EOL] @ pytest . fixture ( ) def git_client_mock ( mocker ) : [EOL] external_cli_mock = mocker . patch ( [string] ) [EOL] git_command_mock = MagicMock ( ) [EOL] git_command_mock . branch . return_value = [string] , [number] , [string] [EOL] git_command_mock . _make_command . return_value = lambda : ( [string] , [number] , [string] ) [comment] [EOL] external_cli_mock . return_value = git_command_mock [EOL] return git_command_mock [EOL] [EOL] [EOL] def test_upload_experiment_to_git_repo_manager ( mocker , tmpdir , git_client_mock ) : [EOL] get_private_key_path_mock = mocker . patch ( [string] , return_value = [string] ) [EOL] proxy_mock = mocker . patch ( [string] ) [EOL] config_mock = mocker . patch ( [string] ) [EOL] fake_hash = [string] [EOL] env_hash_mock = mocker . patch ( [string] , return_value = fake_hash ) [EOL] [EOL] experiment_name = [string] [EOL] experiments_workdir = tmpdir . mkdir ( f' [string] ' ) [EOL] experiments_workdir . mkdir ( experiment_name ) [EOL] [EOL] upload_experiment_to_git_repo_manager ( experiments_workdir = experiments_workdir , experiment_name = experiment_name , run_name = experiment_name , username = [string] ) [EOL] [EOL] assert env_hash_mock . call_count == [number] [EOL] assert config_mock . call_count == [number] [EOL] assert get_private_key_path_mock . call_count == [number] [EOL] assert proxy_mock . call_count == [number] [EOL] [EOL] [comment] [EOL] assert git_client_mock . remote . call_count == [number] [EOL] [EOL] assert git_client_mock . clone . call_count == [number] [EOL] [EOL] assert git_client_mock . config . call_count == [number] [EOL] assert git_client_mock . checkout . call_count == [number] [EOL] assert git_client_mock . pull . call_count == [number] [EOL] assert git_client_mock . add . call_count == [number] [EOL] assert git_client_mock . commit . call_count == [number] [EOL] assert git_client_mock . tag . call_count == [number] [EOL] assert git_client_mock . push . call_count == [number] [EOL] [EOL] [EOL] def test_upload_experiment_to_git_repo_manager_already_cloned ( mocker , tmpdir , git_client_mock ) : [EOL] get_private_key_path_mock = mocker . patch ( [string] , return_value = [string] ) [EOL] proxy_mock = mocker . patch ( [string] ) [EOL] config_mock = mocker . patch ( [string] ) [EOL] fake_hash = [string] [EOL] env_hash_mock = mocker . patch ( [string] , return_value = fake_hash ) [EOL] [EOL] experiment_name = [string] [EOL] experiments_workdir = tmpdir . mkdir ( f' [string] ' ) [EOL] experiments_workdir . mkdir ( f' [string] { fake_hash }' ) [EOL] experiments_workdir . mkdir ( experiment_name ) [EOL] [EOL] [EOL] upload_experiment_to_git_repo_manager ( experiments_workdir = experiments_workdir , experiment_name = experiment_name , run_name = experiment_name , username = [string] ) [EOL] [EOL] assert env_hash_mock . call_count == [number] [EOL] assert config_mock . call_count == [number] [EOL] assert get_private_key_path_mock . call_count == [number] [EOL] assert proxy_mock . call_count == [number] [EOL] [EOL] assert git_client_mock . remote . call_count == [number] [EOL] [EOL] assert git_client_mock . clone . call_count == [number] [EOL] [EOL] assert git_client_mock . config . call_count == [number] [EOL] assert git_client_mock . checkout . call_count == [number] [EOL] assert git_client_mock . pull . call_count == [number] [EOL] assert git_client_mock . add . call_count == [number] [EOL] assert git_client_mock . commit . call_count == [number] [EOL] assert git_client_mock . tag . call_count == [number] [EOL] assert git_client_mock . push . call_count == [number] [EOL] [EOL] [EOL] def test_upload_experiment_to_git_repo_manager_error ( mocker , tmpdir , git_client_mock ) : [EOL] get_private_key_path_mock = mocker . patch ( [string] , return_value = [string] ) [EOL] git_client_mock . push . side_effect = RuntimeError [EOL] proxy_mock = mocker . patch ( [string] ) [EOL] config_mock = mocker . patch ( [string] ) [EOL] fake_hash = [string] [EOL] env_hash_mock = mocker . patch ( [string] , return_value = fake_hash ) [EOL] [EOL] experiment_name = [string] [EOL] experiments_workdir = tmpdir . mkdir ( f' [string] ' ) [EOL] experiments_workdir . mkdir ( f' [string] { fake_hash }' ) [EOL] experiments_workdir . mkdir ( experiment_name ) [EOL] [EOL] with pytest . raises ( RuntimeError ) : [EOL] upload_experiment_to_git_repo_manager ( experiments_workdir = experiments_workdir , run_name = experiment_name , experiment_name = experiment_name , username = [string] ) [EOL] [EOL] [comment] [EOL] assert env_hash_mock . call_count == [number] [EOL] assert config_mock . call_count == [number] [EOL] assert get_private_key_path_mock . call_count == [number] [EOL] assert proxy_mock . call_count == [number] [EOL] [EOL] [comment] [EOL] assert git_client_mock . reset . call_count == [number] [EOL] [EOL] [EOL] def test_create_gitignore_file_for_experiments ( tmpdir ) : [EOL] experiments_workdir = tmpdir . mkdir ( [string] ) [EOL] gitignore_file = experiments_workdir . join ( [string] ) [EOL] [EOL] create_gitignore_file_for_experiments ( experiments_workdir ) [EOL] [EOL] assert gitignore_file . read ( ) == [string] [EOL] [EOL] [EOL] def test_compute_hash_of_k8s_env_address ( mocker ) : [EOL] mocker . patch ( [string] , return_value = [string] ) [EOL] assert compute_hash_of_k8s_env_address ( ) == [string] [EOL] [EOL] [EOL] def test_delete_exp_tag_from_git_repo_manager_experiments_dir_not_exist ( mocker ) : [EOL] config_mock = mocker . patch ( [string] ) [EOL] compute_hash_of_k8s_env_address_mock = mocker . patch ( [string] , return_value = [string] ) [EOL] get_private_key_path_mock = mocker . patch ( [string] ) [EOL] external_cli_mock = mocker . patch ( [string] ) [EOL] git_command_mock = MagicMock ( ) [EOL] git_command_mock . tag . return_value = [string] , [number] , [string] [EOL] external_cli_mock . return_value = git_command_mock [EOL] proxy_mock = mocker . patch ( [string] ) [EOL] os_path_is_dir_mock = mocker . patch ( [string] , return_value = False ) [EOL] os_makedirs_mock = mocker . patch ( [string] ) [EOL] [EOL] delete_exp_tag_from_git_repo_manager ( username = [string] , experiment_name = [string] , experiments_workdir = [string] ) [EOL] [EOL] assert config_mock . call_count == [number] [EOL] assert compute_hash_of_k8s_env_address_mock . call_count == [number] [EOL] assert get_private_key_path_mock . call_count == [number] [EOL] assert external_cli_mock . call_count == [number] [EOL] assert proxy_mock . call_count == [number] [EOL] assert os_path_is_dir_mock . call_count == [number] [EOL] assert os_makedirs_mock . call_count == [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import typing [EOL] import logging as log [EOL] from time import sleep [EOL] [EOL] from tensorboard . tensorboard import TensorboardManager [EOL] [EOL] [EOL] log . basicConfig ( level = log . DEBUG ) [EOL] [EOL] log . debug ( [string] ) [EOL] [EOL] mgr = TensorboardManager . incluster_init ( ) [EOL] [EOL] while True : [EOL] mgr . delete_garbage ( ) [EOL] log . debug ( [string] ) [EOL] sleep ( [number] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , Dict [EOL] import builtins [EOL] import typing [EOL] import kubernetes [EOL] from typing import Dict [EOL] [EOL] from kubernetes import client , config [EOL] from kubernetes . client import V1ConfigMap [EOL] [EOL] NAUTA_CONFIG_CONFIGMAP_NAME = [string] [EOL] NAUTA_CONFIG_CONFIGMAP_NAMESPACE = [string] [EOL] [EOL] NAUTA_CONFIG_TENSORBOARD_TIMEOUT = [string] [EOL] NAUTA_DEFAULT_TENSORBOARD_TIMEOUT = [string] [EOL] [EOL] [EOL] class NautaPlatformConfig : [EOL] def __init__ ( self , k8s_api_client ) : [EOL] self . client = k8s_api_client [EOL] [EOL] @ classmethod def incluster_init ( cls ) : [EOL] config . load_incluster_config ( ) [EOL] v1 = client . CoreV1Api ( ) [EOL] return cls ( k8s_api_client = v1 ) [EOL] [EOL] def _fetch_platform_configmap ( self ) : [EOL] configmap = self . client . read_namespaced_config_map ( name = NAUTA_CONFIG_CONFIGMAP_NAME , namespace = NAUTA_CONFIG_CONFIGMAP_NAMESPACE ) [EOL] [EOL] configmap_data = configmap . data [EOL] [EOL] return configmap_data [EOL] [EOL] def get_tensorboard_image ( self ) : [EOL] data = self . _fetch_platform_configmap ( ) [EOL] return f"{ data [ [string] ] } [string] { data [ [string] ] }" [EOL] [EOL] def get_activity_proxy_image ( self ) : [EOL] data = self . _fetch_platform_configmap ( ) [EOL] return f"{ data [ [string] ] } [string] { data [ [string] ] }" [EOL] [EOL] def get_tensorboard_timeout ( self ) : [EOL] data = self . _fetch_platform_configmap ( ) [EOL] if data . get ( NAUTA_CONFIG_TENSORBOARD_TIMEOUT ) : [EOL] return data . get ( NAUTA_CONFIG_TENSORBOARD_TIMEOUT ) [EOL] return NAUTA_CONFIG_TENSORBOARD_TIMEOUT [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $kubernetes.client.CoreV1Api$ 0 0 0 0 0 0 0 $kubernetes.client.CoreV1Api$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 $kubernetes.client.V1ConfigMap$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 $kubernetes.client.V1ConfigMap$ 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 $builtins.str$ 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] from typing import Any [EOL] import nauta [EOL] import typing [EOL] from unittest . mock import MagicMock [EOL] [EOL] from kubernetes . client import V1ConfigMap [EOL] import pytest [EOL] [EOL] from nauta . config import NautaPlatformConfig [EOL] [EOL] [EOL] fake_cm = V1ConfigMap ( data = { [string] : [string] , [string] : [string] , [string] : [string] } ) [EOL] [EOL] [EOL] @ pytest . fixture def nauta_platform_config_mocked ( ) : [EOL] [comment] [EOL] config = NautaPlatformConfig ( k8s_api_client = MagicMock ( ) ) [EOL] [EOL] return config [EOL] [EOL] [EOL] def test_incluster_init ( mocker ) : [EOL] mocker . patch ( [string] ) [EOL] [EOL] nauta_config = NautaPlatformConfig . incluster_init ( ) [EOL] [EOL] assert nauta_config [EOL] assert nauta_config . client [EOL] [EOL] [EOL] [comment] [EOL] def test_fetch_platform_configmap ( mocker , nauta_platform_config_mocked ) : [EOL] mocker . patch . object ( nauta_platform_config_mocked . client , [string] ) . return_value = fake_cm [EOL] [EOL] [comment] [EOL] configmap_dict = nauta_platform_config_mocked . _fetch_platform_configmap ( ) [EOL] [EOL] assert configmap_dict == fake_cm . data [EOL] [EOL] [EOL] [comment] [EOL] def test_get_tensorboard_image ( mocker , nauta_platform_config_mocked ) : [EOL] mocker . patch . object ( nauta_platform_config_mocked , [string] ) . return_value = fake_cm . data [EOL] [EOL] tb_image = nauta_platform_config_mocked . get_tensorboard_image ( ) [EOL] [EOL] assert tb_image == [string] [EOL] [EOL] [EOL] [comment] [EOL] def test_get_activity_proxy_image ( mocker , nauta_platform_config_mocked ) : [EOL] mocker . patch . object ( nauta_platform_config_mocked , [string] ) . return_value = fake_cm . data [EOL] [EOL] ap_image = nauta_platform_config_mocked . get_activity_proxy_image ( ) [EOL] [EOL] assert ap_image == [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , List , Dict [EOL] import tensorboard [EOL] import builtins [EOL] import typing [EOL] import kubernetes [EOL] from hashlib import sha1 [EOL] import os [EOL] from typing import List [EOL] [EOL] from kubernetes import client as k8s [EOL] from nauta . config import NautaPlatformConfig [EOL] from tensorboard . models import Run [EOL] [EOL] [EOL] class K8STensorboardInstance : [EOL] EXPERIMENTS_OUTPUT_VOLUME_NAME = [string] [EOL] TENSORBOARD_CONTAINER_MOUNT_PATH_PREFIX = [string] [EOL] [EOL] def __init__ ( self , deployment , service , ingress , pod = None ) : [EOL] self . deployment = deployment [EOL] self . service = service [EOL] self . ingress = ingress [EOL] self . pod = pod [EOL] [EOL] @ staticmethod def generate_run_names_hash ( runs ) : [EOL] run_names_condensed = [ ] [EOL] [EOL] for run in runs : [EOL] run_names_condensed . append ( run . owner + [string] + run . name ) [EOL] [EOL] run_names_condensed . sort ( ) [EOL] run_names_str = [string] . join ( run_names_condensed ) [EOL] run_names_hash = sha1 ( run_names_str . encode ( [string] ) ) . hexdigest ( ) [EOL] return run_names_hash [EOL] [EOL] @ classmethod def from_runs ( cls , id , runs ) : [EOL] k8s_name = [string] + id [EOL] run_names_hash = K8STensorboardInstance . generate_run_names_hash ( runs ) [EOL] [EOL] volume_mounts = [ ] [EOL] [EOL] for run in runs : [EOL] mount = k8s . V1VolumeMount ( name = cls . EXPERIMENTS_OUTPUT_VOLUME_NAME , mount_path = os . path . join ( cls . TENSORBOARD_CONTAINER_MOUNT_PATH_PREFIX , run . owner , run . name ) , sub_path = os . path . join ( run . owner , run . name ) ) [EOL] volume_mounts . append ( mount ) [EOL] [EOL] deployment_labels = { [string] : k8s_name , [string] : [string] , [string] : [string] , [string] : id , [string] : run_names_hash } [EOL] [EOL] tensorboard_command = [ [string] , [string] , cls . TENSORBOARD_CONTAINER_MOUNT_PATH_PREFIX , [string] , [string] , [string] , [string] ] [EOL] [EOL] nauta_config = NautaPlatformConfig . incluster_init ( ) [EOL] [EOL] tensorboard_image = nauta_config . get_tensorboard_image ( ) [EOL] tensorboard_proxy_image = nauta_config . get_activity_proxy_image ( ) [EOL] [EOL] deployment = k8s . V1Deployment ( api_version = [string] , kind = [string] , metadata = k8s . V1ObjectMeta ( name = k8s_name , labels = deployment_labels ) , spec = k8s . V1DeploymentSpec ( replicas = [number] , selector = k8s . V1LabelSelector ( match_labels = deployment_labels ) , template = k8s . V1PodTemplateSpec ( metadata = k8s . V1ObjectMeta ( labels = deployment_labels ) , spec = k8s . V1PodSpec ( tolerations = [ k8s . V1Toleration ( key = [string] , operator = [string] , effect = [string] ) ] , affinity = k8s . V1Affinity ( node_affinity = k8s . V1NodeAffinity ( required_during_scheduling_ignored_during_execution = k8s . V1NodeSelector ( node_selector_terms = [ k8s . V1NodeSelectorTerm ( match_expressions = [ k8s . V1NodeSelectorRequirement ( key = [string] , operator = [string] , values = [ [string] ] ) ] ) ] ) ) ) , containers = [ k8s . V1Container ( name = [string] , image = tensorboard_image , command = tensorboard_command , volume_mounts = volume_mounts ) , k8s . V1Container ( name = [string] , image = tensorboard_proxy_image , ports = [ k8s . V1ContainerPort ( container_port = [number] ) ] , readiness_probe = k8s . V1Probe ( period_seconds = [number] , http_get = k8s . V1HTTPGetAction ( path = [string] , port = [number] ) ) ) ] , volumes = [ k8s . V1Volume ( name = cls . EXPERIMENTS_OUTPUT_VOLUME_NAME , persistent_volume_claim = k8s . V1PersistentVolumeClaimVolumeSource ( claim_name = cls . EXPERIMENTS_OUTPUT_VOLUME_NAME , read_only = True ) ) ] ) ) ) ) [EOL] [EOL] service = k8s . V1Service ( api_version = [string] , kind = [string] , metadata = k8s . V1ObjectMeta ( name = k8s_name , labels = { [string] : k8s_name , [string] : [string] , [string] : [string] , [string] : id } ) , spec = k8s . V1ServiceSpec ( type = [string] , ports = [ k8s . V1ServicePort ( name = [string] , port = [number] , target_port = [number] ) ] , selector = { [string] : k8s_name , [string] : [string] , [string] : [string] , [string] : id } ) ) [EOL] [EOL] ingress = k8s . V1beta1Ingress ( api_version = [string] , kind = [string] , metadata = k8s . V1ObjectMeta ( name = k8s_name , labels = { [string] : k8s_name , [string] : [string] , [string] : [string] , [string] : id } , annotations = { [string] : [string] , [string] : [string] } ) , spec = k8s . V1beta1IngressSpec ( rules = [ k8s . V1beta1IngressRule ( host = [string] , http = k8s . V1beta1HTTPIngressRuleValue ( paths = [ k8s . V1beta1HTTPIngressPath ( path = [string] + id + [string] , backend = k8s . V1beta1IngressBackend ( service_name = k8s_name , service_port = [number] ) ) ] ) ) ] ) ) [EOL] [EOL] return cls ( deployment = deployment , service = service , ingress = ingress ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $typing.List[tensorboard.models.Run]$ 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 $typing.List[tensorboard.models.Run]$ 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $typing.List[tensorboard.models.Run]$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 $typing.List[tensorboard.models.Run]$ 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 $typing.List[tensorboard.models.Run]$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $typing.Any$ 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.List[builtins.str]$ 0 $typing.List[typing.Any]$ 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , List , Optional [EOL] import builtins [EOL] import typing [EOL] import kubernetes [EOL] from enum import Enum [EOL] import logging as log [EOL] from http import HTTPStatus [EOL] from typing import List , Optional [EOL] [EOL] from kubernetes import client [EOL] from kubernetes . client import V1DeploymentList , V1Deployment , V1Service , V1beta1Ingress , V1DeleteOptions , V1Pod , V1beta1IngressList , V1PodList [EOL] from kubernetes . client . rest import ApiException [EOL] [EOL] [EOL] [comment] [EOL] class K8SPodPhase ( Enum ) : [EOL] PENDING = [string] [EOL] RUNNING = [string] [EOL] SUCCEEDED = [string] [EOL] FAILED = [string] [EOL] UNKNOWN = [string] [EOL] [EOL] [EOL] class K8SAPIClient : [EOL] def __init__ ( self ) : [EOL] self . apps_api_client = client . AppsV1Api ( ) [EOL] self . extensions_v1beta1_api_client = client . ExtensionsV1beta1Api ( ) [EOL] self . v1_api_client = client . CoreV1Api ( ) [EOL] self . custom_objects_client = client . CustomObjectsApi ( ) [EOL] [EOL] def create_deployment ( self , namespace , body , ** kwargs ) : [EOL] self . apps_api_client . create_namespaced_deployment ( namespace = namespace , body = body , ** kwargs ) [EOL] [EOL] def list_deployments ( self , namespace , label_selector = None , ** kwargs ) : [EOL] deployments = self . apps_api_client . list_namespaced_deployment ( namespace = namespace , label_selector = label_selector , ** kwargs ) [EOL] deployments_list = deployments . items [EOL] return deployments_list [EOL] [EOL] def get_deployment ( self , name , namespace , ** kwargs ) : [EOL] try : [EOL] deployment = self . apps_api_client . read_namespaced_deployment ( name = name , namespace = namespace , ** kwargs ) [EOL] except ApiException as ex : [EOL] log . warning ( [string] ) [EOL] if ex . status == HTTPStatus . NOT_FOUND : [EOL] return None [EOL] raise ex [EOL] [EOL] return deployment [EOL] [EOL] def delete_deployment ( self , name , namespace , ** kwargs ) : [EOL] self . apps_api_client . delete_namespaced_deployment ( name = name , namespace = namespace , body = V1DeleteOptions ( ) , ** kwargs ) [EOL] [EOL] def create_service ( self , namespace , body , ** kwargs ) : [EOL] self . v1_api_client . create_namespaced_service ( namespace = namespace , body = body , ** kwargs ) [EOL] [EOL] def get_service ( self , name , namespace , ** kwargs ) : [EOL] return self . v1_api_client . read_namespaced_service ( name = name , namespace = namespace , ** kwargs ) [EOL] [EOL] def delete_service ( self , name , namespace , ** kwargs ) : [EOL] self . v1_api_client . delete_namespaced_service ( name = name , namespace = namespace , body = V1DeleteOptions ( ) , ** kwargs ) [EOL] [EOL] def create_ingress ( self , namespace , body , ** kwargs ) : [EOL] self . extensions_v1beta1_api_client . create_namespaced_ingress ( namespace = namespace , body = body , ** kwargs ) [EOL] [EOL] def get_ingress ( self , name , namespace , ** kwargs ) : [EOL] return self . extensions_v1beta1_api_client . read_namespaced_ingress ( name = name , namespace = namespace , ** kwargs ) [EOL] [EOL] def list_ingresses ( self , namespace , label_selector = None , ** kwargs ) : [EOL] ingresses = self . extensions_v1beta1_api_client . list_namespaced_ingress ( namespace = namespace , label_selector = label_selector , ** kwargs ) [EOL] [EOL] ingresses_list = ingresses . items [EOL] return ingresses_list [EOL] [EOL] def delete_ingress ( self , name , namespace , ** kwargs ) : [EOL] self . extensions_v1beta1_api_client . delete_namespaced_ingress ( name = name , namespace = namespace , body = V1DeleteOptions ( ) , ** kwargs ) [EOL] [EOL] def get_pod ( self , namespace , label_selector = None , ** kwargs ) : [EOL] try : [EOL] pods = self . v1_api_client . list_namespaced_pod ( namespace = namespace , label_selector = label_selector , ** kwargs ) [EOL] except ApiException as ex : [EOL] if ex . status == HTTPStatus . NOT_FOUND : [EOL] return None [EOL] raise ex [EOL] [EOL] pods_list = pods . items [EOL] [EOL] if len ( pods_list ) < [number] : [EOL] return None [EOL] [EOL] return pods_list [ [number] ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $kubernetes.client.V1Deployment$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $kubernetes.client.V1Deployment$ 0 $kubernetes.client.V1Deployment$ 0 0 0 0 0 0 0 $typing.List[kubernetes.client.V1Deployment]$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 $kubernetes.client.V1DeploymentList$ 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 $typing.List[kubernetes.client.V1Deployment]$ 0 $kubernetes.client.V1DeploymentList$ 0 0 0 0 $typing.List[kubernetes.client.V1Deployment]$ 0 0 0 $typing.Optional[kubernetes.client.V1Deployment]$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $kubernetes.client.V1Service$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $kubernetes.client.V1Service$ 0 $kubernetes.client.V1Service$ 0 0 0 0 0 0 0 $kubernetes.client.V1Service$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $kubernetes.client.V1beta1Ingress$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $kubernetes.client.V1beta1Ingress$ 0 $kubernetes.client.V1beta1Ingress$ 0 0 0 0 0 0 0 $kubernetes.client.V1beta1Ingress$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 $typing.List[kubernetes.client.V1beta1Ingress]$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 $kubernetes.client.V1beta1Ingress.List$ 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 $typing.List[kubernetes.client.V1beta1Ingress]$ 0 $kubernetes.client.V1beta1Ingress.List$ 0 0 0 0 $typing.List[kubernetes.client.V1beta1Ingress]$ 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[kubernetes.client.V1Pod]$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $kubernetes.client.V1PodList$ 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[kubernetes.client.V1Pod]$ 0 $kubernetes.client.V1PodList$ 0 0 0 0 0 0 0 $typing.List[kubernetes.client.V1Pod]$ 0 0 0 0 0 0 0 0 0 0 $typing.List[kubernetes.client.V1Pod]$ 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , List [EOL] import typing [EOL] import kubernetes [EOL] import random [EOL] from typing import List [EOL] [EOL] from k8s . models import K8STensorboardInstance [EOL] from kubernetes import client as kube_models [EOL] from tensorboard . models import Run [EOL] [EOL] [EOL] def test_generate_tensorboard_deployment ( mocker ) : [EOL] mocker . patch ( [string] ) [EOL] fake_runs = [ Run ( name = [string] , owner = [string] ) , Run ( name = [string] , owner = [string] ) , Run ( name = [string] , owner = [string] ) , ] [EOL] [EOL] model_instance = K8STensorboardInstance . from_runs ( id = [string] , runs = fake_runs ) [EOL] [EOL] assert model_instance . deployment . metadata . name == [string] [EOL] [EOL] volume_mounts = model_instance . deployment . spec . template . spec . containers [ [number] ] . volume_mounts [EOL] [EOL] assert len ( volume_mounts ) == len ( fake_runs ) [EOL] [EOL] [EOL] def test_generate_run_names_hash ( ) : [EOL] fake_runs = [ Run ( name = [string] , owner = [string] ) , Run ( name = [string] , owner = [string] ) , Run ( name = [string] , owner = [string] ) , ] [EOL] [EOL] expected_hash = [string] [EOL] [EOL] run_names_hash_original = K8STensorboardInstance . generate_run_names_hash ( fake_runs ) [EOL] [EOL] random . shuffle ( fake_runs ) [EOL] [EOL] run_names_hash_suffled = K8STensorboardInstance . generate_run_names_hash ( fake_runs ) [EOL] [EOL] assert run_names_hash_original == expected_hash [EOL] assert run_names_hash_suffled == expected_hash [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , Union , Dict [EOL] import typing [EOL] import flask [EOL] import builtins [EOL] import http [EOL] from http import HTTPStatus [EOL] import json [EOL] import logging as log [EOL] [EOL] from flask import Flask , request [EOL] [EOL] from tensorboard . tensorboard import TensorboardManager [EOL] from api . models import TensorboardCreationRequestBody , TensorboardResponse , TensorboardResponsePreconditionFailed [EOL] [EOL] log . basicConfig ( level = log . DEBUG ) [EOL] [EOL] app = Flask ( __name__ ) [EOL] [EOL] [comment] [EOL] CONTENT_TYPE_SLUG = { [string] : [string] } [EOL] [EOL] [EOL] def _generate_error_response ( error_code , message ) : [EOL] response = { [string] : error_code , [string] : message } [EOL] return json . dumps ( response ) , error_code , CONTENT_TYPE_SLUG [EOL] [EOL] [EOL] @ app . route ( [string] , methods = [ [string] ] ) def create ( ) : [EOL] request_json_body = request . get_json ( force = True ) [EOL] [EOL] try : [EOL] run_names = request_json_body [ [string] ] [EOL] except ( KeyError , TypeError ) : [EOL] return _generate_error_response ( HTTPStatus . BAD_REQUEST , [string] ) [EOL] [EOL] if len ( run_names ) < [number] : [EOL] return _generate_error_response ( HTTPStatus . BAD_REQUEST , [string] ) [EOL] [EOL] try : [EOL] request_body = TensorboardCreationRequestBody . from_dict ( request_json_body ) [EOL] except ( KeyError , TypeError ) : [EOL] return _generate_error_response ( HTTPStatus . BAD_REQUEST , [string] ) [EOL] [EOL] tensb_mgr = TensorboardManager . incluster_init ( ) [EOL] [EOL] valid_runs , invalid_runs = tensb_mgr . validate_runs ( request_body . run_names ) [EOL] [EOL] if not valid_runs : [EOL] response = TensorboardResponsePreconditionFailed ( code = HTTPStatus . UNPROCESSABLE_ENTITY . value , invalid_runs = invalid_runs ) [EOL] [EOL] return json . dumps ( response . to_dict ( ) ) , HTTPStatus . UNPROCESSABLE_ENTITY , CONTENT_TYPE_SLUG [EOL] [EOL] current_tensorboard_instance = tensb_mgr . get_by_runs ( valid_runs ) [EOL] [EOL] if current_tensorboard_instance : [EOL] response = TensorboardResponse . from_tensorboard ( current_tensorboard_instance ) [EOL] [EOL] if invalid_runs : [EOL] response . invalid_runs = invalid_runs [EOL] [EOL] return json . dumps ( response . to_dict ( ) ) , HTTPStatus . CONFLICT , CONTENT_TYPE_SLUG [EOL] [EOL] tensorboard = tensb_mgr . create ( valid_runs ) [EOL] [EOL] response = TensorboardResponse . from_tensorboard ( tensorboard ) [EOL] [EOL] if invalid_runs : [EOL] response . invalid_runs = invalid_runs [EOL] [EOL] return json . dumps ( response . to_dict ( ) ) , HTTPStatus . ACCEPTED , CONTENT_TYPE_SLUG [EOL] [EOL] [EOL] @ app . route ( [string] , methods = [ [string] ] ) def get ( id ) : [EOL] tensb_mgr = TensorboardManager . incluster_init ( ) [EOL] [EOL] current_tensorboard_instance = tensb_mgr . get_by_id ( id ) [EOL] [EOL] if current_tensorboard_instance is None : [EOL] return _generate_error_response ( HTTPStatus . NOT_FOUND , [string] ) [EOL] [EOL] return json . dumps ( current_tensorboard_instance . to_dict ( ) ) , CONTENT_TYPE_SLUG [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $flask.app.Flask$ 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 $(str,HTTPStatus,dict)$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 $flask.app.Flask$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 $flask.app.Flask$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , List , Dict [EOL] import tensorboard [EOL] import builtins [EOL] import typing [EOL] from typing import List [EOL] [EOL] from tensorboard . tensorboard import Tensorboard [EOL] from tensorboard . models import Run , TensorboardStatus [EOL] [EOL] [EOL] class TensorboardCreationRequestBody : [EOL] def __init__ ( self , run_names ) : [EOL] self . run_names = run_names [EOL] [EOL] @ classmethod def from_dict ( cls , body ) : [EOL] runs_from_json = body [ [string] ] [EOL] runs = [ ] [EOL] for json_run in runs_from_json : [EOL] name = json_run [ [string] ] [EOL] owner = json_run [ [string] ] [EOL] new_run = Run ( name = name , owner = owner ) [EOL] runs . append ( new_run ) [EOL] [EOL] return cls ( run_names = runs ) [EOL] [EOL] [EOL] class TensorboardResponse : [EOL] def __init__ ( self , id , status , url , invalid_runs = None ) : [EOL] self . id = id [EOL] self . status = status [EOL] self . url = url [EOL] self . invalid_runs = invalid_runs [EOL] [EOL] def to_dict ( self ) : [EOL] tb_dict = { [string] : self . id , [string] : self . status . value , [string] : self . url } [EOL] [EOL] if self . invalid_runs : [EOL] runs = [ ] [EOL] for run in self . invalid_runs : [EOL] runs . append ( run . to_dict ( ) ) [EOL] [EOL] tb_dict [ [string] ] = runs [EOL] [EOL] return tb_dict [EOL] [EOL] @ classmethod def from_tensorboard ( cls , tb ) : [EOL] return cls ( id = tb . id , status = tb . status , url = tb . url ) [EOL] [EOL] [EOL] class TensorboardResponsePreconditionFailed : [EOL] def __init__ ( self , code , invalid_runs ) : [EOL] self . code = code [EOL] self . invalid_runs = invalid_runs [EOL] [EOL] def to_dict ( self ) : [EOL] initial = { [string] : self . code } [EOL] [EOL] invalid_runs_dict = [ ] [EOL] [EOL] for run in self . invalid_runs : [EOL] invalid_runs_dict . append ( run . to_dict ( ) ) [EOL] [EOL] initial [ [string] ] = invalid_runs_dict [EOL] [EOL] return initial [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 $typing.List[typing.Any]$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,unknown]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,unknown]$ 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $typing.Dict[builtins.str,unknown]$ 0 0 0 0 0 0 0 0 0 $tensorboard.tensorboard.Tensorboard$ 0 0 0 0 0 0 0 0 $tensorboard.tensorboard.Tensorboard$ 0 0 0 0 0 $tensorboard.tensorboard.Tensorboard$ 0 0 0 0 0 $tensorboard.tensorboard.Tensorboard$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.int]$ 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $typing.Dict[builtins.str,builtins.int]$ 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , List , Dict [EOL] import unittest [EOL] import flask [EOL] import builtins [EOL] import typing [EOL] import pytest_mock [EOL] from flask . testing import FlaskClient [EOL] from http import HTTPStatus [EOL] import json [EOL] from unittest . mock import MagicMock [EOL] [EOL] import pytest [EOL] from pytest_mock import MockFixture [EOL] [EOL] import api . main [EOL] from tensorboard . models import Tensorboard , TensorboardStatus [EOL] [EOL] [EOL] @ pytest . fixture def flask_client ( ) : [EOL] client = api . main . app . test_client ( ) [EOL] yield client [EOL] [EOL] [EOL] [comment] [EOL] def test_create ( mocker , flask_client ) : [EOL] tensorboard_mgr = MagicMock ( incluster_init = lambda * args , ** kwargs : MagicMock ( get_by_runs = lambda * args , ** kwargs : None , create = lambda * args , ** kwargs : Tensorboard ( id = [string] , url = [string] ) , validate_runs = lambda runs : ( runs , [ ] ) ) ) [EOL] mocker . patch . object ( api . main , [string] , new = tensorboard_mgr ) [EOL] request_body = { [string] : [ { [string] : [string] , [string] : [string] } , { [string] : [string] , [string] : [string] } , { [string] : [string] , [string] : [string] } ] } [EOL] [EOL] response = flask_client . post ( [string] , data = json . dumps ( request_body ) ) [EOL] [EOL] assert response . status_code == HTTPStatus . ACCEPTED [EOL] [EOL] response_body = response . data . decode ( [string] ) [EOL] response_body_json = json . loads ( response_body ) [EOL] [EOL] assert response_body_json [ [string] ] == [string] [EOL] assert response_body_json [ [string] ] == [string] [EOL] assert response_body_json [ [string] ] == [string] [EOL] assert not response_body_json . get ( [string] , None ) [EOL] [EOL] [EOL] [comment] [EOL] @ pytest . mark . parametrize ( [string] , [ { } , { [string] : [ ] } , { [string] : [string] } , [ ] , [ { } ] , { [string] : [ { } ] } , { [string] : [ { [string] : [string] } ] } , { [string] : [ { [string] : [string] } ] } , { [string] : [ { [string] : [string] , [string] : [string] } , { } ] } , { [string] : [ { [string] : [string] , [string] : [string] } , { [string] : [string] } ] } ] ) def test_create_bad_request ( flask_client , request_body ) : [EOL] response = flask_client . post ( [string] , data = json . dumps ( request_body ) ) [EOL] [EOL] assert response . status_code == HTTPStatus . BAD_REQUEST [EOL] [EOL] [EOL] [comment] [EOL] def test_create_conflict ( mocker , flask_client ) : [EOL] fake_tensorboard_id = [string] [EOL] fake_tensorboard_url = [string] [EOL] tensorboard_mgr = MagicMock ( incluster_init = lambda * args , ** kwargs : MagicMock ( get_by_runs = lambda * args , ** kwargs : Tensorboard ( id = fake_tensorboard_id , url = fake_tensorboard_url , status = TensorboardStatus . RUNNING ) , validate_runs = lambda runs : ( runs , [ ] ) ) ) [EOL] mocker . patch . object ( api . main , [string] , new = tensorboard_mgr ) [EOL] request_body = { [string] : [ { [string] : [string] , [string] : [string] } , { [string] : [string] , [string] : [string] } , { [string] : [string] , [string] : [string] } ] } [EOL] [EOL] response = flask_client . post ( [string] , data = json . dumps ( request_body ) ) [EOL] [EOL] assert response . status_code == HTTPStatus . CONFLICT [EOL] [EOL] response_body = response . data . decode ( [string] ) [EOL] response_body_json = json . loads ( response_body ) [EOL] [EOL] assert response_body_json [ [string] ] == fake_tensorboard_id [EOL] assert response_body_json [ [string] ] == [string] [EOL] assert response_body_json [ [string] ] == fake_tensorboard_url [EOL] assert not response_body_json . get ( [string] , None ) [EOL] [EOL] [EOL] [comment] [EOL] def test_get ( mocker , flask_client ) : [EOL] fake_tensorboard = Tensorboard ( id = [string] , url = [string] , status = TensorboardStatus . RUNNING ) [EOL] [EOL] tensorboard_mgr = MagicMock ( incluster_init = lambda * args , ** kwargs : MagicMock ( get_by_id = lambda * args , ** kwargs : fake_tensorboard ) ) [EOL] mocker . patch . object ( api . main , [string] , new = tensorboard_mgr ) [EOL] [EOL] response = flask_client . get ( f' [string] { fake_tensorboard . id }' ) [EOL] [EOL] assert response . status_code == HTTPStatus . OK [EOL] [EOL] response_body = response . data . decode ( [string] ) [EOL] response_body_json = json . loads ( response_body ) [EOL] [EOL] assert response_body_json [ [string] ] == fake_tensorboard . id [EOL] assert response_body_json [ [string] ] == fake_tensorboard . status . value [EOL] assert response_body_json [ [string] ] == fake_tensorboard . url [EOL] [EOL] [EOL] [comment] [EOL] def test_get_not_found ( mocker , flask_client ) : [EOL] tensorboard_mgr = MagicMock ( incluster_init = lambda * args , ** kwargs : MagicMock ( get_by_id = lambda * args , ** kwargs : None ) ) [EOL] mocker . patch . object ( api . main , [string] , new = tensorboard_mgr ) [EOL] [EOL] response = flask_client . get ( f' [string] ' ) [EOL] [EOL] assert response . status_code == HTTPStatus . NOT_FOUND [EOL] [EOL] [EOL] [comment] [EOL] def test_create_all_invalid_runs ( mocker , flask_client ) : [EOL] tensorboard_mgr = MagicMock ( incluster_init = lambda * args , ** kwargs : MagicMock ( validate_runs = lambda runs : ( [ ] , runs ) , get_by_runs = lambda * args , ** kwargs : None ) ) [EOL] mocker . patch . object ( api . main , [string] , new = tensorboard_mgr ) [EOL] request_body = { [string] : [ { [string] : [string] , [string] : [string] } , { [string] : [string] , [string] : [string] } , { [string] : [string] , [string] : [string] } ] } [EOL] [EOL] response = flask_client . post ( [string] , data = json . dumps ( request_body ) ) [EOL] [EOL] assert response . status_code == HTTPStatus . UNPROCESSABLE_ENTITY [EOL] [EOL] response_body = response . data . decode ( [string] ) [EOL] response_body_json = json . loads ( response_body ) [EOL] [EOL] assert response_body_json [ [string] ] == HTTPStatus . UNPROCESSABLE_ENTITY . value [EOL] assert response_body_json [ [string] ] == request_body [ [string] ] [EOL] [EOL] [EOL] [comment] [EOL] def test_create_partial_invalid_runs ( mocker , flask_client ) : [EOL] fake_tensorboard_id = [string] [EOL] fake_tensorboard_url = [string] [EOL] [EOL] tensorboard_mgr = MagicMock ( incluster_init = lambda * args , ** kwargs : MagicMock ( validate_runs = lambda runs : ( [ runs [ [number] ] , runs [ [number] ] ] , [ runs [ [number] ] ] ) , create = lambda * args , ** kwargs : Tensorboard ( id = fake_tensorboard_id , url = fake_tensorboard_url ) , get_by_runs = lambda * args , ** kwargs : None ) ) [EOL] mocker . patch . object ( api . main , [string] , new = tensorboard_mgr ) [EOL] request_body = { [string] : [ { [string] : [string] , [string] : [string] } , { [string] : [string] , [string] : [string] } , { [string] : [string] , [string] : [string] } ] } [EOL] [EOL] response = flask_client . post ( [string] , data = json . dumps ( request_body ) ) [EOL] [EOL] assert response . status_code == HTTPStatus . ACCEPTED [EOL] [EOL] response_body = response . data . decode ( [string] ) [EOL] response_body_json = json . loads ( response_body ) [EOL] [EOL] assert response_body_json [ [string] ] == fake_tensorboard_id [EOL] assert response_body_json [ [string] ] == [string] [EOL] assert response_body_json [ [string] ] == fake_tensorboard_url [EOL] assert response_body_json [ [string] ] == [ request_body [ [string] ] [ [number] ] ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Dict [EOL] import service [EOL] import applications [EOL] import builtins [EOL] import typing [EOL] from enum import Enum [EOL] from typing import Dict [EOL] [EOL] [EOL] class TensorboardStatus ( Enum ) : [EOL] CREATING = [string] [EOL] RUNNING = [string] [EOL] [EOL] [EOL] class Tensorboard : [EOL] def __init__ ( self , id , status = TensorboardStatus . CREATING , url = [string] ) : [EOL] self . id = id [EOL] self . status = status [EOL] self . url = url [EOL] [EOL] def to_dict ( self ) : [EOL] return { [string] : self . id , [string] : self . status . value , [string] : self . url } [EOL] [EOL] [EOL] class Run : [EOL] def __init__ ( self , name , owner ) : [EOL] self . name = name [EOL] self . owner = owner [EOL] [EOL] def to_dict ( self ) : [EOL] return { [string] : self . name , [string] : self . owner } [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $applications.tensorboard-service.app.tensorboard.models.TensorboardStatus$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $applications.tensorboard-service.app.tensorboard.models.TensorboardStatus$ 0 $applications.tensorboard-service.app.tensorboard.models.TensorboardStatus$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , Optional [EOL] import requests [EOL] import builtins [EOL] import datetime [EOL] import typing [EOL] from datetime import datetime [EOL] import json [EOL] import logging as log [EOL] from typing import Optional [EOL] [EOL] import dateutil . parser [EOL] import requests [EOL] import requests . exceptions [EOL] [EOL] [EOL] def try_get_last_request_datetime ( proxy_address ) : [EOL] [comment] [EOL] [comment] [EOL] try : [EOL] proxy_response = requests . get ( f' [string] { proxy_address } [string] ' , timeout = [number] ) [EOL] except requests . exceptions . ConnectionError : [EOL] log . exception ( [string] ) [EOL] return None [EOL] [EOL] proxy_resonse_body = proxy_response . content . decode ( [string] ) [EOL] [EOL] proxy_response_dict = json . loads ( proxy_resonse_body ) [EOL] [EOL] last_request_datetime_str = proxy_response_dict [ [string] ] [EOL] [EOL] last_request_datetime = dateutil . parser . parse ( last_request_datetime_str ) [EOL] [EOL] return last_request_datetime [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[datetime.datetime.datetime]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import typing [EOL] from datetime import datetime [EOL] from unittest . mock import MagicMock [EOL] [EOL] import pytest [EOL] import requests . exceptions [EOL] [EOL] import tensorboard . proxy_client [EOL] [EOL] [EOL] def test_try_get_last_request_datetime ( mocker ) : [EOL] resp = [string] [EOL] [EOL] mocker . patch ( [string] ) . return_value = MagicMock ( content = resp ) [EOL] [EOL] last_request_datetimestamp = tensorboard . proxy_client . try_get_last_request_datetime ( proxy_address = [string] ) [EOL] [EOL] assert last_request_datetimestamp == datetime ( year = [number] , month = [number] , day = [number] , hour = [number] , minute = [number] , second = [number] ) [EOL] [EOL] [EOL] def test_try_get_last_request_datetime_raise_known_ex ( mocker ) : [EOL] mocker . patch ( [string] ) . side_effect = requests . exceptions . ConnectionError [EOL] [EOL] last_request_datetimestamp = tensorboard . proxy_client . try_get_last_request_datetime ( proxy_address = [string] ) [EOL] [EOL] assert last_request_datetimestamp is None [EOL] [EOL] [EOL] def test_try_get_last_request_datetime_raise_unknown_ex ( mocker ) : [EOL] mocker . patch ( [string] ) . side_effect = TypeError [EOL] [EOL] with pytest . raises ( TypeError ) : [EOL] tensorboard . proxy_client . try_get_last_request_datetime ( proxy_address = [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , List [EOL] from collections import deque [EOL] import collections [EOL] import applications [EOL] import docs [EOL] import typing [EOL] import getopt [EOL] import sys [EOL] import os [EOL] import re [EOL] from collections import deque [EOL] [EOL] [EOL] class ConversionParameters ( object ) : [EOL] docs_directory = [string] [EOL] [EOL] [EOL] class Chapter ( object ) : [EOL] def __init__ ( self , title , file ) : [EOL] self . title = title [EOL] self . file = file [EOL] self . subchapters = list ( ) [EOL] [EOL] [EOL] def add_chapters_to_menu ( local_chapters , file , menu ) : [EOL] if len ( local_chapters ) == [number] : [EOL] return [EOL] local_chapters = deque ( local_chapters ) [EOL] while len ( local_chapters ) : [EOL] new_chapter = Chapter ( remove_hash ( local_chapters . popleft ( ) ) , file ) [EOL] subchapters = list ( ) [EOL] while len ( local_chapters ) : [EOL] if local_chapters [ [number] ] . startswith ( [string] ) : [EOL] subchapters . append ( remove_hash ( local_chapters . popleft ( ) ) ) [EOL] else : [EOL] break [EOL] new_chapter . subchapters = subchapters [EOL] menu . append ( new_chapter ) [EOL] [EOL] [EOL] def remove_hash ( text ) : [EOL] while text . startswith ( [string] ) : [EOL] text = text [ [number] : ] [EOL] return text [EOL] [EOL] [EOL] def get_chapters ( file , menu ) : [EOL] local_chapters = list ( ) [EOL] with open ( file , [string] , encoding = [string] ) as f : [EOL] for line in f : [EOL] if re . match ( [string] , line ) : [EOL] local_chapters . append ( line ) [EOL] add_chapters_to_menu ( local_chapters , file , menu ) [EOL] [EOL] [EOL] def convert_directory ( param , menu ) : [EOL] for path , dirs , files in os . walk ( param . docs_directory , topdown = True ) : [EOL] for file in files : [EOL] if file . endswith ( [string] ) : [EOL] get_chapters ( os . path . join ( path , file ) , menu ) [EOL] [EOL] [EOL] def handle_parameters ( argv ) : [EOL] help_line = [string] [EOL] [EOL] if len ( argv ) == [number] : [EOL] print ( help_line ) [EOL] sys . exit ( [number] ) [EOL] try : [EOL] opts , args = getopt . getopt ( argv , [string] , [ [string] ] ) [EOL] except getopt . GetoptError : [EOL] print ( help_line ) [EOL] sys . exit ( [number] ) [EOL] params = ConversionParameters ( ) [EOL] for opt , arg in opts : [EOL] if opt == [string] : [EOL] print ( help_line ) [EOL] sys . exit ( ) [EOL] elif opt in ( [string] , [string] ) : [EOL] params . docs_directory = arg [EOL] return params [EOL] [EOL] [EOL] def fix_link ( link , directory ) : [EOL] link = link . replace ( [string] , [string] ) [EOL] return [string] + link . replace ( directory , [string] ) [EOL] [EOL] [EOL] def generate_html ( menu , directory ) : [EOL] print ( [string] ) [EOL] for option in menu : [EOL] print ( f' [string] { fix_link ( option . file , directory ) } [string] { option . title } [string] ' ) [EOL] for suboption in option . subchapters : [EOL] print ( f' [string] { fix_link ( option . file , directory ) } [string] { suboption } [string] ' ) [EOL] print ( [string] ) [EOL] print ( [string] ) [EOL] [EOL] [EOL] def sort_menu ( menu ) : [EOL] menu . sort ( key = lambda x : x . title ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] params = handle_parameters ( sys . argv [ [number] : ] ) [EOL] menu = list ( ) [EOL] convert_directory ( params , menu ) [EOL] sort_menu ( menu ) [EOL] generate_html ( menu , params . docs_directory ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.List[typing.Any]$ 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 $typing.List[typing.Any]$ 0 $typing.Any$ 0 0 0 0