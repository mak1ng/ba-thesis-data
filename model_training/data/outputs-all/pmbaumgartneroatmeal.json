	0
from typing import Any , List , Optional , Tuple , Dict , Type , Union [EOL] import pytorch_pretrained_bert [EOL] import torch [EOL] import builtins [EOL] import typing [EOL] import numpy [EOL] from typing import Union , Optional , List [EOL] [EOL] import numpy as np [EOL] import torch [EOL] from torch import Tensor [EOL] from numpy import array [EOL] from pytorch_pretrained_bert . modeling import ( BertForSequenceClassification , BertModel , BertPreTrainedModel , BertConfig , ) [EOL] from pytorch_pretrained_bert . optimization import BertAdam [EOL] from torch . nn import BCEWithLogitsLoss [EOL] from torch . utils . data import DataLoader [EOL] from tqdm import tqdm , trange [EOL] [EOL] [EOL] n_gpu = torch . cuda . device_count ( ) [EOL] device = torch . device ( [string] if torch . cuda . is_available ( ) else [string] ) [EOL] [EOL] [EOL] class BertForMultiLabelSequenceClassification ( BertPreTrainedModel ) : [comment] [EOL] [docstring] [EOL] [EOL] def __init__ ( self , config , num_labels = [number] ) : [EOL] super ( BertForMultiLabelSequenceClassification , self ) . __init__ ( config ) [EOL] self . num_labels = num_labels [EOL] self . bert = BertModel ( config ) [EOL] self . dropout = torch . nn . Dropout ( config . hidden_dropout_prob ) [EOL] self . classifier = torch . nn . Linear ( config . hidden_size , num_labels ) [EOL] self . apply ( self . init_bert_weights ) [EOL] [EOL] def forward ( self , input_ids , token_type_ids = None , attention_mask = None , labels = None , pos_weight = None , ) : [EOL] _ , pooled_output = self . bert ( input_ids , token_type_ids , attention_mask , output_all_encoded_layers = False ) [EOL] pooled_output = self . dropout ( pooled_output ) [EOL] logits = self . classifier ( pooled_output ) [EOL] [EOL] if labels is not None : [EOL] if pos_weight is None : [EOL] loss_fct = BCEWithLogitsLoss ( ) [EOL] else : [EOL] loss_fct = BCEWithLogitsLoss ( pos_weight = pos_weight ) [EOL] loss = loss_fct ( logits . view ( - [number] , self . num_labels ) , labels . view ( - [number] , self . num_labels ) ) [EOL] return loss [EOL] else : [EOL] return logits [EOL] [EOL] def freeze_bert_encoder ( self ) : [EOL] for param in self . bert . parameters ( ) : [EOL] param . requires_grad = False [EOL] [EOL] def unfreeze_bert_encoder ( self ) : [EOL] for param in self . bert . parameters ( ) : [EOL] param . requires_grad = True [EOL] [EOL] [EOL] def get_bert_binary_model ( ) : [EOL] bert_model = BertForSequenceClassification . from_pretrained ( [string] , num_labels = [number] ) [EOL] if n_gpu > [number] : [EOL] bert_model = torch . nn . DataParallel ( bert_model ) [EOL] [EOL] return bert_model [EOL] [EOL] [EOL] def get_bert_multiclass_model ( num_labels ) : [EOL] bert_model = BertForSequenceClassification . from_pretrained ( [string] , num_labels = num_labels ) [EOL] if n_gpu > [number] : [EOL] bert_model = torch . nn . DataParallel ( bert_model ) [EOL] [EOL] return bert_model [EOL] [EOL] [EOL] def get_bert_multilabel_model ( num_labels ) : [EOL] bert_model = BertForMultiLabelSequenceClassification . from_pretrained ( [string] , num_labels = num_labels ) [EOL] if n_gpu > [number] : [EOL] bert_model = torch . nn . DataParallel ( bert_model ) [EOL] return bert_model [EOL] [EOL] [EOL] bert_model_types = Union [ BertForSequenceClassification , BertForMultiLabelSequenceClassification ] [EOL] [EOL] [EOL] def get_bert_opt ( model , n_train_examples , train_batch_size , num_train_epochs , ) : [EOL] param_opt = list ( model . named_parameters ( ) ) [EOL] no_decay = [ [string] , [string] , [string] ] [EOL] opt_grouped_parameters = [ { [string] : [ p for n , p in param_opt if not any ( nd in n for nd in no_decay ) ] , [string] : [number] , } , { [string] : [ p for n , p in param_opt if any ( nd in n for nd in no_decay ) ] , [string] : [number] , } , ] [EOL] num_train_optimization_steps = ( int ( n_train_examples / train_batch_size ) * num_train_epochs ) [EOL] opt = BertAdam ( opt_grouped_parameters , lr = [number] , warmup = [number] , t_total = num_train_optimization_steps , ) [EOL] return opt [EOL] [EOL] [EOL] def run_model_training ( model , opt , dataloader , epochs , pos_weight = None , ) : [EOL] model . to ( device ) [EOL] model . train ( ) [EOL] if pos_weight is not None : [EOL] pos_weight = Tensor ( pos_weight ) . to ( device ) [EOL] for _ in trange ( epochs , desc = [string] ) : [EOL] for batch in tqdm ( dataloader , desc = [string] ) : [EOL] batch = tuple ( t . to ( device ) for t in batch ) [EOL] x0 , x1 , x2 , y = batch [EOL] if pos_weight is not None : [EOL] loss = model ( x0 , x1 , x2 , y , pos_weight = pos_weight ) [EOL] else : [EOL] loss = model ( x0 , x1 , x2 , y ) [EOL] if n_gpu > [number] : [EOL] loss = loss . mean ( ) [EOL] loss . backward ( ) [EOL] opt . step ( ) [EOL] opt . zero_grad ( ) [EOL] [EOL] return model [EOL] [EOL] [EOL] def run_prediction_softmax ( model , dataloader ) : [EOL] model . to ( device ) [EOL] model . eval ( ) [EOL] all_logits = None [EOL] for batch in tqdm ( dataloader , desc = [string] ) : [EOL] with torch . no_grad ( ) : [EOL] batch = tuple ( t . to ( device ) for t in batch ) [EOL] x0 , x1 , x2 = batch [EOL] logits = model ( x0 , x1 , x2 ) [EOL] [EOL] if all_logits is None : [EOL] all_logits = logits . softmax ( [number] ) . detach ( ) . cpu ( ) . numpy ( ) [EOL] else : [EOL] all_logits = np . concatenate ( ( all_logits , logits . softmax ( [number] ) . detach ( ) . cpu ( ) . numpy ( ) ) , axis = [number] ) [EOL] [EOL] return all_logits [EOL] [EOL] [EOL] def run_prediction_sigmoid ( model , dataloader ) : [EOL] model . to ( device ) [EOL] model . eval ( ) [EOL] all_logits = None [EOL] for batch in tqdm ( dataloader , desc = [string] ) : [EOL] with torch . no_grad ( ) : [EOL] batch = tuple ( t . to ( device ) for t in batch ) [EOL] x0 , x1 , x2 = batch [EOL] logits = model ( x0 , x1 , x2 ) [EOL] if all_logits is None : [EOL] all_logits = logits . sigmoid ( ) . detach ( ) . cpu ( ) . numpy ( ) [EOL] else : [EOL] all_logits = np . concatenate ( ( all_logits , logits . sigmoid ( ) . detach ( ) . cpu ( ) . numpy ( ) ) , axis = [number] ) [EOL] [EOL] return all_logits [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pytorch_pretrained_bert.modeling.BertConfig$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pytorch_pretrained_bert.modeling.BertConfig$ 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 $pytorch_pretrained_bert.modeling.BertConfig$ 0 0 0 0 0 0 0 0 0 0 0 0 $pytorch_pretrained_bert.modeling.BertConfig$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pytorch_pretrained_bert.modeling.BertConfig$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $torch.Tensor$ 0 0 0 $torch.Tensor$ 0 $torch.Tensor$ 0 0 0 $torch.Tensor$ 0 0 0 $torch.Tensor$ 0 0 0 $torch.Tensor$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $torch.Tensor$ 0 $torch.Tensor$ 0 $torch.Tensor$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 $torch.Tensor$ 0 0 0 0 0 0 $torch.Tensor$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $torch.Tensor$ 0 $torch.Tensor$ 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $torch.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List , Optional , Tuple , Dict , Type [EOL] import pytorch_pretrained_bert [EOL] import pandas [EOL] import builtins [EOL] import typing [EOL] import models [EOL] import pathlib [EOL] import numpy [EOL] import json [EOL] from datetime import datetime [EOL] from pathlib import Path [EOL] from typing import Dict , Optional , Tuple , Union , List , Any [EOL] [EOL] import pandas as pd [EOL] from numpy import array [EOL] from pandas import DataFrame [EOL] import torch [EOL] [EOL] from pytorch_pretrained_bert . modeling import BertForSequenceClassification , BertConfig [EOL] from models import BertForMultiLabelSequenceClassification [EOL] [EOL] bert_model_types = Union [ BertForSequenceClassification , BertForMultiLabelSequenceClassification ] [EOL] [EOL] device = torch . device ( [string] if torch . cuda . is_available ( ) else [string] ) [EOL] [EOL] [EOL] def save_model ( model , training_parameters , export_dir , model_name , ) : [EOL] if not export_dir : [EOL] now_timestamp = datetime . now ( ) . strftime ( [string] ) [EOL] export_path = Path ( f" [string] { now_timestamp }" ) [EOL] else : [EOL] export_path = Path ( export_dir ) [EOL] [EOL] export_path . mkdir ( parents = True , exist_ok = True ) [EOL] [EOL] torch . save ( model . state_dict ( ) , export_path / f"{ model_name } [string] " ) [EOL] json_config = export_path / f"{ model_name } [string] " [EOL] json_config . write_text ( model . config . to_json_string ( ) ) [EOL] training_config = export_path / f"{ model_name } [string] " [EOL] training_config . write_text ( json . dumps ( training_parameters ) ) [EOL] [EOL] [EOL] def load_model_classification ( model_path , model_name , num_labels = [number] ) : [EOL] model_path = Path ( model_path ) [EOL] config = BertConfig ( str ( model_path / f"{ model_name } [string] " ) ) [EOL] model = BertForSequenceClassification ( config , num_labels = num_labels ) [EOL] model . load_state_dict ( torch . load ( str ( model_path / f"{ model_name } [string] " ) , map_location = device ) ) [EOL] return model [EOL] [EOL] [EOL] def load_model_multilabel ( model_path , model_name , num_labels = [number] ) : [EOL] model_path = Path ( model_path ) [EOL] config = BertConfig ( str ( model_path / f"{ model_name } [string] " ) ) [EOL] model = BertForMultiLabelSequenceClassification ( config , num_labels = num_labels ) [EOL] model . load_state_dict ( torch . load ( str ( model_path / f"{ model_name } [string] " ) , map_location = device ) ) [EOL] return model [EOL] [EOL] [EOL] def load_classification_data ( input_csv , text_column , label_column ) : [EOL] df = pd . read_csv ( input_csv ) [EOL] texts = df [ text_column ] . values [EOL] labelmap = None [EOL] if df [ label_column ] . dtype == [string] : [EOL] labelmap = { label : i for i , label in enumerate ( df [ label_column ] . unique ( ) ) } [EOL] labels = df [ label_column ] . map ( labelmap ) . values [EOL] else : [EOL] labels = df [ label_column ] . values [EOL] return texts , labels , labelmap [EOL] [EOL] [EOL] def load_multilabel_data ( input_csv , text_column , label_names ) : [EOL] df = pd . read_csv ( input_csv ) [EOL] texts = df [ text_column ] . values [EOL] labels = df [ label_names ] . values [EOL] return texts , labels [EOL] [EOL] [EOL] def load_evaluation_data ( input_csv , text_column ) : [EOL] df = pd . read_csv ( input_csv ) [EOL] texts = df [ text_column ] . values [EOL] return texts , df [EOL] [EOL] [EOL] def create_training_parameters ( num_labels , problem_type , max_seq_len , epochs , label_names , ) : [EOL] return dict ( num_labels = num_labels , problem_type = problem_type , epochs = epochs , max_seq_len = max_seq_len , label_names = label_names , ) [EOL] [EOL] [EOL] def load_training_config ( json_path ) : [EOL] with open ( json_path , [string] ) as f : [EOL] training_config = json . load ( f ) [EOL] return training_config [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List , Dict [EOL] import typing [EOL] import click [EOL] [EOL] import torch [EOL] [EOL] from models import ( get_bert_binary_model , get_bert_multiclass_model , get_bert_multilabel_model , get_bert_opt , run_model_training , run_prediction_sigmoid , run_prediction_softmax , ) [EOL] from persistance import ( create_training_parameters , load_classification_data , load_evaluation_data , load_model_classification , load_model_multilabel , load_multilabel_data , load_training_config , save_model , ) [EOL] from processing import ( build_binary_predictions_df , build_multi_predictions_df , create_prediction_dataloader , create_training_dataloader , ) [EOL] [EOL] TRAIN_EPOCHS = [number] [EOL] PRED_BATCH_SIZE = [number] [EOL] [EOL] [EOL] device = torch . device ( [string] if torch . cuda . is_available ( ) else [string] ) [EOL] print ( device ) [EOL] [EOL] if device == torch . device ( [string] ) : [EOL] TRAIN_BATCH_SIZE = [number] [EOL] MAX_SEQ_LEN = [number] [EOL] else : [EOL] TRAIN_BATCH_SIZE = [number] [EOL] MAX_SEQ_LEN = [number] [EOL] [EOL] [EOL] @ click . group ( ) def cli ( ) : [EOL] pass [EOL] [EOL] [EOL] @ cli . group ( [string] ) @ click . option ( [string] , [string] , required = True , type = click . Path ( exists = True , file_okay = True , dir_okay = False , resolve_path = True ) , nargs = [number] , ) @ click . option ( [string] , [string] , type = click . Path ( exists = True , file_okay = True , dir_okay = False , resolve_path = True ) , nargs = [number] , ) @ click . option ( [string] , [string] , type = click . Path ( exists = False , file_okay = False , dir_okay = True , resolve_path = True ) , nargs = [number] , ) @ click . option ( [string] , [string] , type = str , nargs = [number] ) @ click . option ( [string] , [string] , type = int , default = TRAIN_BATCH_SIZE , nargs = [number] ) @ click . option ( [string] , [string] , type = int , default = TRAIN_EPOCHS , nargs = [number] ) @ click . option ( [string] , [string] , type = int , default = MAX_SEQ_LEN , nargs = [number] ) @ click . pass_context def train ( ctx , input_data , eval_data , export_path , model_name , batch_size , epochs , max_seq_len ) : [EOL] args = locals ( ) [EOL] for key in args : [EOL] if key != [string] : [EOL] ctx . obj [ key ] = args [ key ] [EOL] [EOL] [EOL] @ train . command ( [string] ) @ click . option ( [string] , [string] , required = True , type = str , help = [string] ) @ click . option ( [string] , [string] , required = True , type = str , help = [string] ) @ click . argument ( [string] , nargs = - [number] , type = str ) @ click . pass_obj def multiclass ( ctx , text_column , label_column , label_names ) : [EOL] [docstring] [EOL] [EOL] texts , labels , labelmap = load_classification_data ( ctx [ [string] ] , text_column = text_column , label_column = label_column ) [EOL] num_labels = len ( set ( labels ) ) [EOL] n_train_examples = len ( texts ) [EOL] [EOL] if len ( label_names ) != [number] and num_labels != len ( label_names ) : [EOL] raise click . BadParameter ( f"{ num_labels } [string] { len ( label_names ) } [string] " ) [EOL] [EOL] training_dataloader = create_training_dataloader ( texts , labels , ctx [ [string] ] , ctx [ [string] ] ) [EOL] [EOL] bert_model = get_bert_multiclass_model ( num_labels = num_labels ) [EOL] bert_opt = get_bert_opt ( bert_model , n_train_examples , ctx [ [string] ] , ctx [ [string] ] ) [EOL] [EOL] trained_model = run_model_training ( bert_model , bert_opt , training_dataloader , ctx [ [string] ] ) [EOL] [EOL] if not ctx [ [string] ] : [EOL] ctx [ [string] ] = [string] [EOL] if labelmap : [EOL] label_names = [ label for ( label , _ ) in sorted ( labelmap . items ( ) , key = lambda x : x [ [number] ] ) ] [EOL] [EOL] training_parameters = create_training_parameters ( num_labels = num_labels , problem_type = [string] , max_seq_len = ctx [ [string] ] , epochs = ctx [ [string] ] , label_names = label_names , ) [EOL] [EOL] save_model ( trained_model , training_parameters , ctx [ [string] ] , ctx [ [string] ] ) [EOL] [EOL] [EOL] @ train . command ( [string] ) @ click . option ( [string] , [string] , required = True , type = str ) @ click . option ( [string] , [string] , is_flag = True , help = [string] ) @ click . argument ( [string] , required = True , nargs = - [number] , type = str ) @ click . pass_obj def multilabel ( ctx , text_column , label_names , balance ) : [EOL] [docstring] [EOL] texts , labels = load_multilabel_data ( ctx [ [string] ] , text_column = text_column , label_names = list ( label_names ) ) [EOL] if balance : [EOL] pos_weight = ( labels . sum ( axis = [number] ) / labels . shape [ [number] ] ) . tolist ( ) [EOL] num_labels = labels . shape [ [number] ] [EOL] n_train_examples = len ( texts ) [EOL] training_dataloader = create_training_dataloader ( texts , labels , ctx [ [string] ] , ctx [ [string] ] , multilabel = True ) [EOL] [EOL] bert_model = get_bert_multilabel_model ( num_labels = num_labels ) [EOL] bert_opt = get_bert_opt ( bert_model , n_train_examples , ctx [ [string] ] , ctx [ [string] ] ) [EOL] [EOL] if balance : [EOL] trained_model = run_model_training ( bert_model , bert_opt , training_dataloader , ctx [ [string] ] , pos_weight = pos_weight , ) [EOL] else : [EOL] trained_model = run_model_training ( bert_model , bert_opt , training_dataloader , ctx [ [string] ] ) [EOL] [EOL] if not ctx [ [string] ] : [EOL] ctx [ [string] ] = [string] [EOL] [EOL] training_parameters = create_training_parameters ( num_labels = num_labels , problem_type = [string] , max_seq_len = ctx [ [string] ] , epochs = ctx [ [string] ] , label_names = label_names , ) [EOL] [EOL] save_model ( trained_model , training_parameters , ctx [ [string] ] , ctx [ [string] ] ) [EOL] [EOL] [EOL] @ cli . command ( [string] ) @ click . option ( [string] , [string] , required = True , type = click . Path ( exists = True , file_okay = True , dir_okay = False , resolve_path = True ) , nargs = [number] , ) @ click . option ( [string] , [string] , type = click . Path ( exists = False , file_okay = False , dir_okay = True , resolve_path = True ) , nargs = [number] , ) @ click . option ( [string] , [string] , type = str , nargs = [number] ) @ click . option ( [string] , [string] , type = int , default = TRAIN_BATCH_SIZE , nargs = [number] ) @ click . option ( [string] , [string] , required = True , type = str ) def predict ( input_data , model_path , model_name , batch_size , text_column ) : [EOL] texts , df = load_evaluation_data ( input_data , text_column ) [EOL] training_parameters = load_training_config ( str ( model_path + f" [string] { model_name } [string] " ) ) [EOL] problem_type = training_parameters [ [string] ] [EOL] num_labels = training_parameters [ [string] ] [EOL] max_seq_len = training_parameters [ [string] ] [EOL] label_names = training_parameters [ [string] ] [EOL] if problem_type == [string] : [EOL] model_load = load_model_classification [EOL] run_predictions = run_prediction_softmax [EOL] elif problem_type == [string] : [EOL] model_load = load_model_multilabel [EOL] run_predictions = run_prediction_sigmoid [EOL] model = model_load ( model_path , model_name , num_labels = num_labels ) [EOL] prediction_loader = create_prediction_dataloader ( texts , max_seq_len , batch_size ) [EOL] predictions = run_predictions ( model , prediction_loader ) [EOL] predictions_df = build_multi_predictions_df ( df , predictions , label_names ) [EOL] predictions_df . to_csv ( model_path + [string] ) [EOL] [EOL] [EOL] @ cli . command ( [string] ) @ click . option ( [string] , [string] , required = True , type = str , nargs = [number] ) @ click . option ( [string] , [string] , type = click . Path ( exists = False , file_okay = False , dir_okay = True , resolve_path = True ) , nargs = [number] , ) @ click . option ( [string] , [string] , type = str , nargs = [number] ) def predict ( input_text , model_path , model_name ) : [EOL] training_parameters = load_training_config ( str ( model_path + f" [string] { model_name } [string] " ) ) [EOL] problem_type = training_parameters [ [string] ] [EOL] num_labels = training_parameters [ [string] ] [EOL] max_seq_len = training_parameters [ [string] ] [EOL] label_names = training_parameters [ [string] ] [EOL] if problem_type == [string] : [EOL] model_load = load_model_classification [EOL] run_predictions = run_prediction_softmax [EOL] elif problem_type == [string] : [EOL] model_load = load_model_multilabel [EOL] run_predictions = run_prediction_sigmoid [EOL] model = model_load ( model_path , model_name , num_labels = num_labels ) [EOL] prediction_loader = create_prediction_dataloader ( [ input_text ] , max_seq_len , [number] ) [EOL] predictions = run_predictions ( model , prediction_loader ) [EOL] [comment] [EOL] for label , p in zip ( label_names , predictions [ [number] , : ] . tolist ( ) ) : [EOL] print ( f"{ label } [string] { p : [string] }" ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] cli ( obj = { } ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List , Tuple [EOL] import typing [EOL] from oatmeal . processing import ( text_to_token_ids , tensorize_texts , labels_to_tensor , create_training_dataloader , create_prediction_dataloader , ) [EOL] import torch [EOL] import numpy as np [EOL] [EOL] [EOL] def test_tokenization ( ) : [EOL] sentence = [string] [EOL] MAX_SEQ_LEN = [number] [EOL] [EOL] result = text_to_token_ids ( sentence , max_seq_len = MAX_SEQ_LEN ) [EOL] result_ids , result_mask , result_segment_ids = result [EOL] [EOL] assert all ( isinstance ( x , int ) for x in result_ids ) [EOL] assert len ( result_ids ) == MAX_SEQ_LEN [EOL] assert len ( result_mask ) == MAX_SEQ_LEN [EOL] assert len ( result_segment_ids ) == MAX_SEQ_LEN [EOL] [EOL] [EOL] def test_tensorize ( ) : [EOL] sentences = [ [string] , [string] , [string] , ] [EOL] [EOL] MAX_SEQ_LEN = [number] [EOL] [EOL] result = tensorize_texts ( sentences , max_seq_len = MAX_SEQ_LEN ) [EOL] result_ids , result_mask , result_segment_ids = result [EOL] [EOL] assert tuple ( result_ids . size ( ) ) == ( len ( sentences ) , MAX_SEQ_LEN ) [EOL] assert tuple ( result_mask . size ( ) ) == ( len ( sentences ) , MAX_SEQ_LEN ) [EOL] assert tuple ( result_segment_ids . size ( ) ) == ( len ( sentences ) , MAX_SEQ_LEN ) [EOL] [EOL] [EOL] def test_labels_to_tensor ( ) : [EOL] labels = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] [EOL] result = labels_to_tensor ( labels ) [EOL] [EOL] assert torch . equal ( result , torch . tensor ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) ) [EOL] [EOL] [EOL] def test_create_train_dataloader ( ) : [EOL] sentences = [ [string] , [string] , [string] , ] [EOL] labels = [ [number] , [number] , [number] ] [EOL] [EOL] sentence_array = np . array ( sentences ) [EOL] labels_array = np . array ( labels ) [EOL] [EOL] dataloader = create_training_dataloader ( sentence_array , labels_array , [number] , [number] ) [EOL] [EOL] assert len ( dataloader ) == len ( sentences ) [EOL] [EOL] [EOL] def test_create_predict_dataloader ( ) : [EOL] sentences = [ [string] , [string] , [string] , ] [EOL] [EOL] sentence_array = np . array ( sentences ) [EOL] [EOL] dataloader = create_prediction_dataloader ( sentence_array , [number] , [number] ) [EOL] [EOL] assert len ( dataloader ) == len ( sentences ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0