[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Dict [EOL] import typing [EOL] cookies = { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] } [EOL] [EOL] simply_energy = [string] [EOL] [EOL] red_energy = [string] [EOL] [EOL] origin_energy = [string] [EOL] [EOL] energy_oz = [string] [EOL] [EOL] [EOL] bunnings = [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0
from typing import Any [EOL] import typing [EOL] import sys [EOL] import scrapy [EOL] import time [EOL] from scrapy import spiderloader [EOL] from scrapy . utils import project [EOL] from scrapy . crawler import CrawlerProcess [EOL] from facebook import db [EOL] from facebook . help import cookies , url [EOL] [EOL] num = int ( sys . argv [ [number] ] ) [EOL] [EOL] settings = project . get_project_settings ( ) [EOL] spider_loader = spiderloader . SpiderLoader . from_settings ( settings ) [EOL] comment_spider = spider_loader . load ( [string] ) [EOL] [EOL] user_id = [number] [EOL] [EOL] database = db . db ( ) [EOL] suppliers = database . get_suppliers ( ) [EOL] cookies_to_use = cookies . get_facebook_cookie ( [string] , [string] ) [EOL] [EOL] print ( cookies_to_use ) [EOL] [EOL] supplier = suppliers [ num ] [EOL] [EOL] supplier_id = supplier [ [number] ] [EOL] [EOL] if supplier_id not in [ [number] ] : [EOL] [EOL] process = CrawlerProcess ( { [string] : [string] } ) [EOL] [EOL] process . crawl ( comment_spider , supplier [ [number] ] , supplier [ [number] ] , user_id , cookies_to_use , supplier_id , [string] ) [EOL] [EOL] process . start ( )	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $builtins.int$ 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 $builtins.int$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0
from typing import Any [EOL] import typing [EOL] import sys [EOL] import time [EOL] import random [EOL] from likers import steps [EOL] from likers import save [EOL] from lep . selenium import setup [EOL] from facebook import db [EOL] [EOL] database = db . db ( ) [EOL] suppliers = database . get_suppliers ( ) [EOL] [EOL] driver = setup . moz ( ) [EOL] [EOL] user_email = [string] [EOL] user_password = [string] [EOL] steps . login ( driver , user_email , user_password ) [EOL] [EOL] for supplier in suppliers : [EOL] supplier_id , page_name , page_id = supplier [EOL] [EOL] if supplier_id not in [ [number] ] : [EOL] [EOL] likers_url = [string] . format ( page_id ) [EOL] [EOL] driver . get ( likers_url ) [EOL] [EOL] database = db . db ( ) [EOL] supplier_id = database . save_supplier ( page_name , page_id ) [EOL] [EOL] while True : [EOL] try : [EOL] likers = steps . get_likers ( driver ) [EOL] for liker in likers : [EOL] database . save_like ( liker , supplier_id ) [EOL] except Exception as e : [EOL] print ( e ) [EOL] database . rollback ( ) [EOL] continue [EOL] [EOL] warning = steps . get_facebook_warning ( driver ) [EOL] if warning : [EOL] print ( [string] ) [EOL] break [EOL] [EOL] success = steps . get_next_likers ( driver ) [EOL] if not success : [EOL] print ( [string] ) [EOL] break [EOL] [EOL] time . sleep ( [number] ) [EOL] [EOL] print ( [string] . format ( page_name ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $typing.Any$ 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $builtins.str$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import builtins [EOL] import typing [EOL] import psycopg2 [EOL] [EOL] conn_str = [string] [comment] [EOL] [EOL] def truncate ( value , length ) : [EOL] if len ( value ) > length : [EOL] return value [ : length ] + [string] [EOL] [EOL] return value [EOL] [EOL] [EOL] class db : [EOL] def __init__ ( self ) : [EOL] self . connection = psycopg2 . connect ( conn_str ) [EOL] self . cursor = self . connection . cursor ( ) [EOL] [EOL] def commit ( self ) : [EOL] self . connection . commit ( ) [EOL] [EOL] def rollback ( self ) : [EOL] self . connection . rollback ( ) [EOL] [EOL] def get_highest_cn ( self , kind ) : [EOL] self . cursor . execute ( [string] , ( kind , ) ) [EOL] return self . cursor . fetchone ( ) [ [number] ] [EOL] [EOL] def update_highest_cn ( self , new_highest , kind ) : [EOL] self . cursor . execute ( [string] , ( new_highest , kind ) ) [EOL] self . commit ( ) [EOL] [EOL] def save_comment ( self , comment_data , supplier_id ) : [EOL] user_id = self . save_user ( comment_data ) [EOL] comment_id = self . save_comment_details ( user_id , supplier_id , comment_data ) [EOL] self . commit ( ) [EOL] return comment_id [EOL] [EOL] def save_like ( self , user_data , supplier_id ) : [EOL] user_id = self . save_user ( user_data ) [EOL] self . save_like_details ( user_id , supplier_id ) [EOL] self . commit ( ) [EOL] [EOL] def save_user ( self , comment_data ) : [EOL] name = truncate ( comment_data [ [string] ] , [number] ) [EOL] link = truncate ( comment_data [ [string] ] , [number] ) [EOL] uid = [number] [EOL] [EOL] if [string] in comment_data : [EOL] uid = comment_data [ [string] ] [EOL] [EOL] self . cursor . execute ( [string] , ( name , link , uid , name ) ) [EOL] self . commit ( ) [EOL] return self . cursor . fetchone ( ) [ [number] ] [EOL] [EOL] def save_comment_details ( self , user_id , supplier_id , comment_data ) : [EOL] comment = truncate ( comment_data [ [string] ] , [number] ) [EOL] [EOL] [comment] [EOL] [EOL] tagged = comment_data [ [string] ] [EOL] self . cursor . execute ( [string] , ( user_id , supplier_id , comment , comment_data [ [string] ] , tagged , comment_data [ [string] ] , tagged ) ) [EOL] self . commit ( ) [EOL] return self . cursor . fetchone ( ) [ [number] ] [EOL] [EOL] def save_like_details ( self , user_id , supplier_id ) : [EOL] self . cursor . execute ( [string] , ( user_id , supplier_id ) ) [EOL] [EOL] def save_supplier ( self , supplier_name , page_id ) : [EOL] self . cursor . execute ( [string] , ( supplier_name , page_id , supplier_name ) ) [EOL] self . commit ( ) [EOL] return self . cursor . fetchone ( ) [ [number] ] [EOL] [EOL] def get_suppliers ( self ) : [EOL] self . cursor . execute ( [string] ) [EOL] return self . cursor . fetchall ( ) [EOL] [EOL] def get_community_suppliers ( self ) : [EOL] self . cursor . execute ( [string] ) [EOL] return self . cursor . fetchall ( ) [EOL] [EOL] def save_meta_comment ( self , comment_id , meta_comment ) : [EOL] user_id = self . save_user ( meta_comment ) [EOL] self . save_meta_commenter ( user_id , comment_id , meta_comment ) [EOL] self . commit ( ) [EOL] [EOL] def save_meta_commenter ( self , user_id , comment_id , meta_comments ) : [EOL] for comment in meta_comments [ [string] ] : [EOL] self . cursor . execute ( [string] , ( user_id , comment_id , truncate ( comment [ [string] ] , [number] ) , truncate ( str ( comment [ [string] ] ) , [number] ) , comment [ [string] ] ) ) [EOL] [EOL] def save_reactions ( self , comment_id , reactions ) : [EOL] for reaction in reactions : [EOL] user_id = self . save_user ( reaction [ [string] ] ) [EOL] self . cursor . execute ( [string] , ( user_id , comment_id , reaction [ [string] ] ) ) [EOL] self . commit ( ) [EOL] [EOL] def get_meta_comment_by_mcid ( self , mcid ) : [EOL] self . cursor . execute ( [string] , [ mcid ] ) [EOL] return self . cursor . fetchone ( ) [ [number] ] [EOL] [EOL] def save_meta_reactions ( self , mcid , reactions ) : [EOL] [EOL] meta_comment_id = self . get_meta_comment_by_mcid ( mcid ) [EOL] [EOL] for reaction in reactions : [EOL] user_id = self . save_user ( reaction [ [string] ] ) [EOL] self . cursor . execute ( [string] , ( user_id , meta_comment_id , reaction [ [string] ] ) ) [EOL] self . commit ( )	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.dict$ 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.dict$ 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.dict$ 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 $builtins.dict$ 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.dict$ 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.dict$ 0 0 0 $builtins.str$ 0 0 0 $builtins.dict$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.dict$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $builtins.dict$ 0 0 $typing.Any$ 0 $builtins.dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $typing.Any$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.dict$ 0 0 0 $builtins.str$ 0 0 0 $builtins.dict$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $builtins.dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.str$ 0 $builtins.dict$ 0 0 0 0 $typing.Any$ 0 $builtins.dict$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.dict$ 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.dict$ 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.dict$ 0 0 0 0 0 0 $builtins.dict$ 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.dict$ 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.dict$ 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] class FacebookPipeline ( object ) : [EOL] def process_item ( self , item , spider ) : [EOL] return item [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import scrapy [EOL] [EOL] [EOL] class FacebookItem ( scrapy . Item ) : [EOL] [comment] [EOL] [comment] [EOL] pass [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from help import cookies [EOL] import time [EOL] [EOL] print ( cookies . get_facebook_cookie ( [string] , [string] ) ) [EOL] time . sleep ( [number] )	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
[comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import List [EOL] import typing [EOL] BOT_NAME = [string] [EOL] [EOL] SPIDER_MODULES = [ [string] ] [EOL] NEWSPIDER_MODULE = [string] [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] ROBOTSTXT_OBEY = False [EOL] CONCURRENT_REQUESTS_PER_DOMAIN = [number] [EOL] [EOL] [comment] [EOL] [EOL] CONCURRENT_REQUESTS = [number] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , List , Any [EOL] import builtins [EOL] import typing [EOL] import scrapy [EOL] from facebook . help import sel , conv , brain , url [EOL] from facebook import db [EOL] [EOL] max_cn = [number] [EOL] small_step = [number] [EOL] step_size = [number] [EOL] dub_step = [number] [EOL] huge_step = [number] [EOL] [EOL] [EOL] home_mid_step = [number] [EOL] home_minimum = [number] [EOL] [EOL] class CommentsSpider ( scrapy . Spider ) : [EOL] name = [string] [EOL] [EOL] def __init__ ( self , supplier_name , page_id , user_id , cookies , supplier_id , kind ) : [EOL] self . page_id = page_id [EOL] self . user_id = user_id [EOL] self . kind = kind [EOL] self . supplier_name = supplier_name [EOL] self . supplier_id = supplier_id [EOL] self . cookies = cookies [EOL] [EOL] self . db = db . db ( ) [EOL] self . prev_highest_cn = self . db . get_highest_cn ( kind ) [EOL] self . brain = brain . brain ( kind ) [EOL] self . set_page_url ( ) [EOL] self . set_max_cn ( ) [EOL] self . reaction_url = url . reaction_url ( user_id ) [EOL] self . meta_comment_url = url . meta_comment_url ( ) [EOL] self . meta_comment_body = url . meta_comment_body ( user_id ) [EOL] self . meta_comment_react_url = url . meta_comment_react ( user_id ) [EOL] [EOL] self . reaction_types = { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , } [EOL] [EOL] def set_page_url ( self ) : [EOL] self . page_url = url . home_page_url ( self . page_id , self . user_id ) if self . kind == [string] else url . community_page_url ( self . page_id , self . user_id ) [EOL] [EOL] def set_max_cn ( self ) : [EOL] self . max_cn = [number] if self . kind == [string] else [number] [EOL] [EOL] def meta_commenter_request ( self , comment_id , facebook_comment_id ) : [EOL] return scrapy . Request ( url = self . meta_comment_url , method = [string] , cookies = self . cookies , callback = self . save_meta_comments , body = self . meta_comment_body . format ( cid = facebook_comment_id ) , headers = { [string] : [string] } , meta = { [string] : comment_id } , ) [EOL] [EOL] def start_requests ( self ) : [EOL] [comment] [EOL] yield scrapy . Request ( url = self . page_url . format ( cn = self . max_cn ) , cookies = self . cookies , callback = self . find_starting_cn ) [EOL] [EOL] def parse ( self , response ) : [EOL] print ( [string] + str ( self . brain . current_step ) ) [EOL] if CommentsSpider . has_correct_content_type ( response ) and CommentsSpider . response_long_enough ( response ) and self . brain . steps_without_new_content < [number] : [EOL] comments_to_save = [ ] [EOL] for comment in sel . all_comments ( conv . body_html ( response . body ) ) : [EOL] comment_data = sel . comment_data ( comment ) [EOL] if not self . brain . is_duplicate ( comment_data ) : [EOL] comments_to_save . append ( comment_data ) [EOL] [EOL] self . current_cn -= self . brain . step ( ) [EOL] yield scrapy . Request ( url = self . page_url . format ( cn = self . current_cn ) , cookies = self . cookies , callback = self . parse ) [EOL] [EOL] for comment in comments_to_save : [EOL] comment_id = self . db . save_comment ( comment , self . supplier_id ) [EOL] [EOL] for name , reaction_id in self . reaction_types . items ( ) : [EOL] yield scrapy . Request ( url = self . reaction_url . format ( cid = comment [ [string] ] , reaction_id = reaction_id ) , cookies = self . cookies , callback = self . save_reactions , meta = { [string] : comment_id , [string] : name , } ) [EOL] [EOL] print ( [string] ) [EOL] yield self . meta_commenter_request ( comment_id , comment [ [string] ] ) [EOL] else : [EOL] print ( [string] . format ( self . supplier_name ) ) [EOL] [EOL] def save_reactions ( self , response ) : [EOL] comment_id = response . meta . get ( [string] ) [EOL] reaction_kind = response . meta . get ( [string] ) [EOL] reactions = sel . reactions ( conv . body_html ( response . body ) , reaction_kind ) [EOL] self . db . save_reactions ( comment_id , reactions ) [EOL] [EOL] def save_meta_comments ( self , response ) : [EOL] comment_id = response . meta . get ( [string] ) [EOL] json_body = conv . to_json ( response . body ) [EOL] meta_comments = sel . meta_comments ( json_body ) [EOL] for commenter in meta_comments : [EOL] self . db . save_meta_comment ( comment_id , commenter ) [EOL] [EOL] for comment in commenter [ [string] ] : [EOL] yield scrapy . Request ( url = self . meta_comment_react_url . format ( mcid = comment [ [string] ] ) , cookies = self . cookies , callback = self . save_meta_comment_reactions , meta = { [string] : comment [ [string] ] } ) [EOL] [EOL] def save_meta_comment_reactions ( self , response ) : [EOL] meta_comment_id = response . meta . get ( [string] ) [EOL] meta_reactions = sel . meta_comment_reacts ( conv . to_json ( response . body ) ) [EOL] self . db . save_meta_reactions ( meta_comment_id , meta_reactions ) [EOL] [EOL] [EOL] def find_starting_cn ( self , response ) : [EOL] if CommentsSpider . has_correct_content_type ( response ) : [EOL] self . starting_cn = self . prev_highest_cn [EOL] self . higher_cn = self . starting_cn + dub_step [EOL] self . first_user = sel . first_user ( conv . body_html ( response . body ) ) [EOL] yield scrapy . Request ( url = self . page_url . format ( cn = self . higher_cn ) , cookies = self . cookies , callback = self . check_higher_cn ) [EOL] [EOL] def check_higher_cn ( self , response ) : [EOL] [comment] [EOL] if CommentsSpider . has_correct_content_type ( response ) : [EOL] new_first_user = sel . first_user ( conv . body_html ( response . body ) ) [EOL] if new_first_user != self . first_user : [EOL] self . first_user = new_first_user [EOL] self . starting_cn = self . higher_cn [EOL] self . higher_cn = self . starting_cn + dub_step [EOL] yield scrapy . Request ( url = self . page_url . format ( cn = self . higher_cn ) , cookies = self . cookies , callback = self . check_higher_cn ) [EOL] else : [EOL] if self . prev_highest_cn != self . starting_cn : [EOL] print ( [string] . format ( self . starting_cn ) ) [EOL] self . db . update_highest_cn ( self . starting_cn , self . kind ) [EOL] [EOL] [comment] [EOL] self . current_cn = self . starting_cn [EOL] yield scrapy . Request ( url = self . page_url . format ( cn = self . current_cn ) , cookies = self . cookies , callback = self . parse ) [EOL] [EOL] @ staticmethod def has_correct_content_type ( response ) : [EOL] content_type = conv . to_str ( response . headers [ [string] ] ) [EOL] if [string] not in content_type : [EOL] if [string] in content_type : [EOL] print ( [string] ) [EOL] return False [EOL] [EOL] print ( [string] ) [EOL] return False [EOL] [EOL] return True [EOL] [EOL] @ staticmethod def response_long_enough ( response ) : [EOL] return len ( response . body ) > [number]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.List[typing.Any]$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $builtins.list$ 0 0 0 $builtins.list$ 0 $typing.Any$ 0 0 0 0 0 $builtins.list$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0
from typing import Any [EOL] import builtins [EOL] import typing [EOL] small_step = [number] [EOL] [EOL] home_small_step = [number] [comment] [EOL] [EOL] [EOL] class brain ( ) : [EOL] def __init__ ( self , kind = [string] ) : [EOL] self . kind = kind [EOL] self . recent_identifiers = [ ] [EOL] self . new_posts = [number] [EOL] self . reached_start = False [EOL] self . steps_without_new_content = [number] [EOL] self . set_small_step ( ) [EOL] [EOL] def set_small_step ( self ) : [EOL] if self . kind == [string] : [EOL] self . current_step = home_small_step [EOL] else : [EOL] self . current_step = small_step [EOL] [EOL] def is_duplicate ( self , comment ) : [EOL] identifier = str ( comment [ [string] ] ) + comment [ [string] ] [EOL] print ( [string] + identifier ) [EOL] if identifier in self . recent_identifiers : [EOL] return True [EOL] [EOL] self . new_posts += [number] [EOL] self . update_duplicates ( identifier ) [EOL] return False [EOL] [EOL] def update_duplicates ( self , new_identifier ) : [EOL] if len ( self . recent_identifiers ) > [number] : [EOL] self . recent_identifiers . pop ( [number] ) [EOL] [EOL] self . recent_identifiers . append ( new_identifier ) [EOL] [EOL] def track_new_content ( self ) : [EOL] if self . new_posts < [number] : [EOL] self . steps_without_new_content = [number] [EOL] else : [EOL] self . steps_without_new_content += [number] [EOL] [EOL] def calculate_next_step ( self ) : [EOL] if self . reached_start : [EOL] self . track_new_content ( ) [EOL] self . update_step ( ) [EOL] else : [EOL] if self . new_posts > [number] : [EOL] self . reached_start = True [EOL] self . current_step = small_step [EOL] [EOL] def update_step ( self ) : [EOL] if self . new_posts < [number] : [EOL] self . increase_step ( ) [EOL] elif self . new_posts > [number] : [EOL] self . decrease_step ( ) [EOL] [EOL] def increase_step ( self ) : [EOL] self . current_step += self . current_step // [number] [EOL] [EOL] def decrease_step ( self ) : [EOL] self . current_step -= self . current_step // [number] [EOL] [EOL] def step ( self ) : [EOL] self . calculate_next_step ( ) [EOL] self . new_posts = [number] [EOL] print ( [string] . format ( self . current_step ) ) [EOL] return self . current_step	0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.bool$ 0 0 0 $builtins.dict$ 0 0 0 $typing.Any$ 0 0 0 $builtins.dict$ 0 0 0 0 0 $builtins.dict$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , Any [EOL] import builtins [EOL] import typing [EOL] from selenium import webdriver [EOL] [EOL] def get_facebook_cookie ( user_email , user_password ) : [EOL] driver = webdriver . Chrome ( [string] ) [EOL] driver . get ( [string] ) [EOL] [EOL] email = driver . find_element_by_id ( [string] ) [EOL] password = driver . find_element_by_id ( [string] ) [EOL] submit = driver . find_element_by_id ( [string] ) [EOL] [EOL] email . send_keys ( user_email ) [EOL] password . send_keys ( user_password ) [EOL] submit . click ( ) [EOL] [EOL] cookies = { } [EOL] for cookie in driver . get_cookies ( ) : [EOL] cookies [ cookie [ [string] ] ] = cookie [ [string] ] [EOL] [EOL] return cookies	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , List , Any , Union [EOL] import builtins [EOL] import typing [EOL] import scrapy [EOL] from scrapy . http import HtmlResponse [EOL] from scrapy . selector import Selector [EOL] from jsonpath_ng . ext import parse [EOL] [EOL] def all_comments ( body ) : [EOL] return body . xpath ( [string] ) . extract ( ) [EOL] [EOL] def get_if_exists ( selector , xpath ) : [EOL] content = selector . xpath ( xpath ) . extract ( ) [EOL] if len ( content ) > [number] : [EOL] return content [ [number] ] [EOL] [EOL] return [string] [EOL] [EOL] def get_int_if_exists ( selector , xpath ) : [EOL] content = selector . xpath ( xpath ) . extract ( ) [EOL] if len ( content ) > [number] : [EOL] return int ( content [ [number] ] ) [EOL] [EOL] return [number] [EOL] [EOL] def get_comment_number ( selector ) : [EOL] content = selector . xpath ( [string] ) . extract ( ) [EOL] if len ( content ) > [number] : [EOL] return int ( content [ [number] ] . split ( [string] ) [ [number] ] ) [EOL] [EOL] return [number] [EOL] [EOL] def get_name ( selector ) : [EOL] private_name = get_if_exists ( selector , [string] ) [EOL] if private_name == [string] : [EOL] return get_if_exists ( selector , [string] ) [EOL] [EOL] return private_name [EOL] [EOL] def contains_node ( selector , xpath ) : [EOL] nodes = selector . xpath ( xpath ) [EOL] return len ( nodes ) > [number] [EOL] [EOL] def get_comment_content ( selector ) : [EOL] content = selector . xpath ( [string] ) . extract ( ) [EOL] if len ( content ) > [number] : [EOL] return [string] . join ( content ) [EOL] [EOL] return [string] [EOL] [EOL] def comment_data ( comment ) : [EOL] selector = HtmlResponse ( url = [string] , body = comment , encoding = [string] ) [EOL] [EOL] data = { [string] : get_if_exists ( selector , [string] ) , [string] : get_name ( selector ) , [string] : get_comment_content ( selector ) , [string] : get_int_if_exists ( selector , [string] ) , [string] : contains_node ( selector , [string] ) , [string] : get_int_if_exists ( selector , [string] ) } [EOL] [EOL] return data [EOL] [EOL] def first_user ( body ) : [EOL] return body . xpath ( [string] ) . extract ( ) [ [number] ] [EOL] [EOL] [EOL] def meta_comment_ids ( json_body ) : [EOL] legacy_ids = list ( parse ( [string] ) . find ( json_body ) ) [EOL] facebook_ids = list ( parse ( [string] ) . find ( json_body ) ) [EOL] [EOL] ids = [ ] [EOL] [EOL] if len ( legacy_ids ) != len ( facebook_ids ) : [EOL] return ids [EOL] [EOL] for i in range ( len ( legacy_ids ) ) : [EOL] ids . append ( facebook_ids [ i ] . value + [string] + legacy_ids [ i ] . value ) [EOL] [EOL] return ids [EOL] [EOL] [EOL] def meta_comments ( json_body ) : [EOL] links = list ( parse ( [string] ) . find ( json_body ) ) [EOL] full_names = list ( parse ( [string] ) . find ( json_body ) ) [EOL] first_names = list ( parse ( [string] ) . find ( json_body ) ) [EOL] uids = list ( parse ( [string] ) . find ( json_body ) ) [EOL] [EOL] comments = list ( parse ( [string] ) . find ( json_body ) ) [EOL] authors = list ( parse ( [string] ) . find ( json_body ) ) [EOL] comment_ids = meta_comment_ids ( json_body ) [EOL] [EOL] commenters = [ ] [EOL] [EOL] if len ( comments ) is not len ( authors ) or ( len ( links ) is not len ( full_names ) or len ( links ) is not len ( uids ) ) : [EOL] print ( [string] ) [EOL] return commenters [EOL] [EOL] meta_comments = create_meta_comments ( uids , comments , authors , comment_ids ) [EOL] [EOL] for i in range ( len ( links ) ) : [EOL] commenters . append ( { [string] : full_names [ i ] . value , [string] : links [ i ] . value , [string] : uids [ i ] . value , [string] : meta_comments [ i ] } ) [EOL] [EOL] return commenters [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] def create_meta_comments ( user_ids , comments , authors , comment_ids ) : [EOL] [comment] [EOL] [comment] [EOL] meta_comments = [ ] [EOL] [EOL] for i in range ( len ( user_ids ) ) : [EOL] meta_comments . append ( [ ] ) [EOL] for j in range ( len ( authors ) ) : [EOL] if authors [ j ] . value == user_ids [ i ] . value : [EOL] meta_comments [ i ] . append ( { [string] : comments [ j ] . value [ [string] ] , [string] : comments [ j ] . value [ [string] ] , [string] : comment_ids [ j ] , } ) [EOL] [EOL] return meta_comments [EOL] [EOL] def reactions ( response , kind ) : [EOL] names = response . xpath ( [string] ) [EOL] links = response . xpath ( [string] ) [EOL] [EOL] reactions = [ ] [EOL] [EOL] if len ( names ) != len ( links ) : [EOL] print ( [string] ) [EOL] return reactions [EOL] [EOL] for i in range ( len ( names ) ) : [EOL] reactions . append ( { [string] : kind , [string] : { [string] : names [ i ] . extract ( ) , [string] : links [ i ] . extract ( ) } } ) [EOL] [EOL] return reactions [EOL] [EOL] def meta_comment_reacts ( json_body ) : [EOL] reaction_body = list ( parse ( [string] ) . find ( json_body ) ) [EOL] [EOL] if len ( reaction_body ) == [number] : [EOL] return [ ] [EOL] [EOL] return reactions ( Selector ( text = reaction_body [ [number] ] . value ) , [string] ) [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.list$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.list$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.list$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.list$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.list$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.list$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
import scrapy [EOL] import builtins [EOL] import json [EOL] from scrapy . http import HtmlResponse [EOL] [EOL] def to_str ( byte_string ) : [EOL] return byte_string . decode ( [string] ) [EOL] [EOL] def to_json ( response_body ) : [EOL] return json . loads ( response_body [ [number] : ] . decode ( [string] ) ) [EOL] [EOL] def body_html ( response_body ) : [EOL] return HtmlResponse ( url = [string] , body = to_json ( response_body ) [ [string] ] [ [number] ] [ [number] ] [ [string] ] , encoding = [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $scrapy.http.HtmlResponse$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
[comment] [EOL] [EOL] import builtins [EOL] path = [string] [EOL] page_id_param = [string] [EOL] user_id_param = [string] [EOL] cursor = [string] [EOL] remaining_params = [string] [EOL] [EOL] page_type_community = [string] [EOL] [EOL] [EOL] home_cursor = [string] [EOL] page_type_home = [string] [EOL] [EOL] def home_page_url ( page_id , user_id ) : [EOL] return [string] . join ( [ path , page_id_param . format ( pid = page_id ) , home_cursor , user_id_param . format ( uid = user_id ) , page_type_home , remaining_params , ] ) [EOL] [EOL] def community_page_url ( page_id , user_id ) : [EOL] return [string] . join ( [ path , page_id_param . format ( pid = page_id ) , cursor , user_id_param . format ( uid = user_id ) , page_type_community , remaining_params , ] ) [EOL] [EOL] react_url = [string] [EOL] [EOL] def reaction_url ( user_id ) : [EOL] return react_url + user_id_param . format ( uid = user_id ) [EOL] [EOL] def meta_comment_url ( ) : [EOL] return [string] [EOL] [EOL] def meta_comment_body ( user_id ) : [EOL] [comment] [EOL] return [string] + user_id_param . format ( uid = user_id ) [EOL] [EOL] def meta_comment_react ( user_id ) : [EOL] return [string] + user_id_param . format ( uid = user_id )	0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0
	0
from typing import Any [EOL] import builtins [EOL] import typing [EOL] from lxml import etree [EOL] from facebook import db [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] def save_likers ( html , page_name , page_id ) : [EOL] database = db . db ( ) [EOL] supplier_id = database . save_supplier ( page_name , page_id ) [EOL] tree = etree . HTML ( html ) [EOL] [EOL] results = tree . xpath ( [string] ) [EOL] for result in results : [EOL] database . save_like ( { [string] : result . xpath ( [string] ) [ [number] ] , [string] : result . xpath ( [string] ) [ [number] ] , } , supplier_id )	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import List , Any [EOL] import builtins [EOL] import typing [EOL] import time [EOL] [EOL] def login ( driver , user_email , user_password ) : [EOL] driver . get ( [string] ) [EOL] [EOL] email = driver . find_element_by_id ( [string] ) [EOL] password = driver . find_element_by_id ( [string] ) [EOL] submit = driver . find_element_by_id ( [string] ) [EOL] [EOL] email . send_keys ( user_email ) [EOL] password . send_keys ( user_password ) [EOL] submit . click ( ) [EOL] [EOL] def keep_scrolling ( driver , times = [number] ) : [EOL] while times > [number] : [EOL] times -= [number] [EOL] results_end_notifiers = driver . find_elements_by_xpath ( [string] ) [EOL] if len ( results_end_notifiers ) > [number] : [EOL] print ( [string] ) [EOL] return True [EOL] [EOL] else : [EOL] driver . execute_script ( [string] ) [EOL] time . sleep ( [number] ) [EOL] [EOL] def get_likers ( driver ) : [EOL] likers = [ ] [EOL] links = [ link . get_attribute ( [string] ) for link in driver . find_elements_by_xpath ( [string] ) ] [EOL] names = [ name . text for name in driver . find_elements_by_xpath ( [string] ) ] [EOL] [EOL] if len ( names ) > [number] and len ( names ) == len ( links ) : [EOL] for i in range ( len ( links ) ) : [EOL] likers . append ( { [string] : names [ i ] , [string] : links [ i ] , } ) [EOL] else : [EOL] print ( [string] ) [EOL] [EOL] return likers [EOL] [EOL] def get_next_likers ( driver ) : [EOL] for _ in range ( [number] ) : [EOL] try : [EOL] next_page_link = driver . find_elements_by_xpath ( [string] ) [EOL] [EOL] if len ( next_page_link ) > [number] : [EOL] next_page_link [ [number] ] . click ( ) [EOL] return True [EOL] [EOL] return False [EOL] except : [EOL] print ( [string] ) [EOL] pass [EOL] [EOL] [EOL] def get_facebook_warning ( driver ) : [EOL] for _ in range ( [number] ) : [EOL] try : [EOL] warning = driver . find_elements_by_xpath ( [string] ) [EOL] [EOL] return len ( warning ) > [number] [EOL] except : [EOL] print ( [string] ) [EOL] pass	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , Any [EOL] import typing [EOL] from selenium import webdriver [EOL] [EOL] def driver_chrome ( ) : [EOL] options = webdriver . ChromeOptions ( ) [EOL] options . add_argument ( [string] ) [EOL] options . add_argument ( [string] ) [EOL] options . add_argument ( [string] ) [EOL] prefs = { [string] : [number] , [string] : [number] , } [EOL] options . add_experimental_option ( [string] , prefs ) [EOL] [EOL] return webdriver . Chrome ( chrome_options = options ) [EOL] [EOL] def driver_moz ( ) : [EOL] firefox_profile = webdriver . FirefoxProfile ( ) [EOL] firefox_profile . set_preference ( [string] , [number] ) [EOL] firefox_profile . set_preference ( [string] , [string] ) [EOL] firefox_profile . set_preference ( [string] , False ) [EOL] [EOL] return webdriver . Firefox ( firefox_profile = firefox_profile )	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0