[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] [comment] [EOL] from typing import Any , List [EOL] import typing [EOL] import urllib [EOL] import logging [EOL] import logging [EOL] import urllib . parse [EOL] import datetime [EOL] [comment] [EOL] import requests_mock [comment] [EOL] [comment] [EOL] from son_analyze . ops import batch [EOL] [EOL] [EOL] _LOGGER = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def test__create_batches ( ) : [EOL] [comment] [EOL] assert not batch . _create_batches ( [number] , [number] , [number] ) [EOL] [comment] [EOL] assert ( batch . _create_batches ( [number] , [number] , [number] ) == [ ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) ] ) [EOL] tmp = batch . _create_batches ( [number] , [number] , [number] ) [EOL] assert ( tmp == [ ( [number] , [number] + [number] ) , ( [number] + [number] , [number] + [number] ) , ( [number] + [number] , [number] + [number] ) ] ) [EOL] [EOL] [EOL] def test_batch_raw_query ( caplog , sonemu_batches_cnt_mem ) : [EOL] caplog . setLevel ( logging . DEBUG ) [EOL] with requests_mock . Mocker ( ) as mocker : [EOL] query = [string] [EOL] raw_query = ( [string] [string] ) [EOL] sstamps = [ [number] , [number] + [number] , [number] + [number] ] [EOL] estamps = [ [number] + [number] , [number] + [number] , [number] + [number] ] [EOL] for elt in zip ( sonemu_batches_cnt_mem , sstamps , estamps ) : [EOL] url = ( [string] [string] ) . format ( elt [ [number] ] , elt [ [number] ] , [string] , raw_query ) [EOL] mocker . get ( url , text = elt [ [number] ] ) [EOL] prom = urllib . parse . urlparse ( [string] ) [EOL] tmp = batch . batch_raw_query ( prom , [number] , [number] , datetime . timedelta ( seconds = [number] ) , query , [number] ) [EOL] size = [number] [EOL] for rawdata in tmp : [EOL] size += [number] [EOL] assert rawdata [EOL] assert size == [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] [comment] [EOL] from typing import Any [EOL] import typing [EOL] import urllib [EOL] import builtins [EOL] import os [EOL] import logging [EOL] import urllib . parse [EOL] import typing [comment] [EOL] import requests_mock [comment] [EOL] from son_analyze . ops import fetch [EOL] [EOL] [EOL] def test_tmp_workspace_dir ( caplog , tmp_workspace_dir ) : [EOL] caplog . setLevel ( logging . DEBUG ) [EOL] assert all ( [ tmp_workspace_dir , os . path . isdir ( tmp_workspace_dir ) , os . access ( tmp_workspace_dir , os . R_OK ) , ] ) [EOL] token_path = os . path . join ( tmp_workspace_dir , [string] , [string] ) [EOL] assert all ( [ token_path , os . path . isfile ( token_path ) , os . access ( token_path , os . R_OK ) , ] ) [EOL] [EOL] [EOL] def test_fetch_nsd ( caplog , tmp_workspace_dir , sonata_demo_mock ) : [EOL] caplog . setLevel ( logging . DEBUG ) [EOL] with requests_mock . Mocker ( ) as mocker : [EOL] for ( url , value ) in sonata_demo_mock : [EOL] mocker . get ( url . geturl ( ) , json = value ) [EOL] gate = urllib . parse . urlparse ( [string] ) [EOL] ( nsd , vnfds ) = fetch . fetch_resources ( gate , tmp_workspace_dir , fetch . Kind . nsd , [string] , [string] , [string] ) [EOL] assert nsd [ [string] ] == [string] [EOL] assert len ( vnfds ) == [number] [EOL] assert vnfds [ [number] ] [ [string] ] == [string] [EOL] [EOL] [EOL] def test_fetch_vnfd_by_uuid ( caplog , tmp_workspace_dir , sonata_demo_mock ) : [EOL] caplog . setLevel ( logging . DEBUG ) [EOL] with requests_mock . Mocker ( ) as mocker : [EOL] for ( url , value ) in sonata_demo_mock : [EOL] mocker . get ( url . geturl ( ) , json = value ) [EOL] mocker . get ( [string] [string] , status_code = [number] , text = [string] ) [EOL] gate = urllib . parse . urlparse ( [string] ) [EOL] vnfd1 = fetch . fetch_resource_by_uuid ( gate , tmp_workspace_dir , fetch . Kind . vnfd , [string] ) [EOL] assert not vnfd1 [EOL] vnfd2 = fetch . fetch_resource_by_uuid ( gate , tmp_workspace_dir , fetch . Kind . vnfd , [string] ) [EOL] assert len ( vnfd2 [ [string] ] ) == [number] [EOL] [EOL] [EOL] def test_fetch_nfd_by_uuid ( caplog , tmp_workspace_dir , sonata_demo_mock ) : [EOL] caplog . setLevel ( logging . DEBUG ) [EOL] with requests_mock . Mocker ( ) as mocker : [EOL] for ( url , value ) in sonata_demo_mock : [EOL] mocker . get ( url . geturl ( ) , json = value ) [EOL] mocker . get ( [string] [string] , status_code = [number] , text = [string] ) [EOL] gate = urllib . parse . urlparse ( [string] ) [EOL] nsd1 = fetch . fetch_resource_by_uuid ( gate , tmp_workspace_dir , fetch . Kind . nsd , [string] ) [EOL] assert not nsd1 [EOL] ( nsd2 , vnfds2 ) = fetch . fetch_resources_by_uuid ( gate , tmp_workspace_dir , fetch . Kind . nsd , [string] ) [EOL] assert len ( nsd2 [ [string] ] ) == [number] [EOL] assert len ( vnfds2 ) == [number] [EOL] assert vnfds2 [ [number] ] [ [string] ] == [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] [comment] [EOL] import builtins [EOL] from typing import Any , Literal , Union , Dict [EOL] import requests [EOL] import multiprocessing [EOL] import typing [EOL] import typing_extensions [EOL] import logging [EOL] import os [EOL] from time import sleep [EOL] import logging [EOL] from multiprocessing import Process [EOL] import typing [comment] [EOL] import pytest [comment] [EOL] import requests [EOL] from docker import APIClient [comment] [EOL] import son_analyze . cli . main [EOL] from son_analyze import __version__ [EOL] [EOL] [EOL] _LOGGER = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] @ pytest . fixture ( scope = [string] ) def docker_cli ( ) : [EOL] return APIClient ( base_url = [string] ) [EOL] [EOL] [EOL] def test_version ( capsys ) : [EOL] with pytest . raises ( SystemExit ) : [EOL] son_analyze . cli . main . dispatch ( [ [string] ] ) [EOL] out , _ = capsys . readouterr ( ) [EOL] assert out == [string] . format ( __version__ ) [EOL] with pytest . raises ( SystemExit ) as boxed_ex : [EOL] son_analyze . cli . main . dispatch ( [ [string] , [string] ] ) [EOL] out , _ = capsys . readouterr ( ) [EOL] assert out == __version__ + [string] [EOL] assert boxed_ex . value . code == [number] [EOL] [EOL] [EOL] @ pytest . fixture ( scope = [string] ) def run_bg ( request ) : [EOL] run_process = Process ( target = son_analyze . cli . main . dispatch , args = ( [ [string] , [string] ] , ) ) [EOL] run_process . start ( ) [comment] [EOL] [EOL] def fin ( ) : [EOL] run_process . terminate ( ) [comment] [EOL] _LOGGER . info ( [string] , run_process . exitcode ) [EOL] request . addfinalizer ( fin ) [EOL] [EOL] [EOL] @ pytest . mark . skipif ( os . getenv ( [string] ) is not None , reason = [string] ) @ pytest . mark . usefixtures ( [string] ) def test_run ( docker_cli ) : [comment] [EOL] req = None [EOL] loop_run = os . getenv ( [string] , [string] ) [EOL] for loopi in range ( int ( loop_run ) ) : [EOL] _LOGGER . debug ( [string] , loopi , loop_run ) [EOL] try : [EOL] filters = { [string] : [string] } [EOL] targets = docker_cli . containers ( filters = filters ) [EOL] if len ( targets ) == [number] : [EOL] container_id = targets [ [number] ] . get ( [string] ) [EOL] inspection = docker_cli . inspect_container ( container_id ) [EOL] container_ip = inspection . get ( [string] ) . get ( [string] ) [EOL] req = requests . get ( [string] . format ( container_ip ) ) [EOL] else : [EOL] msg = [string] [EOL] _LOGGER . debug ( msg , targets ) [EOL] except requests . exceptions . ConnectionError as exc : [EOL] _LOGGER . warning ( [string] , exc ) [EOL] if req and hasattr ( req , [string] ) and req . status_code == [number] : [EOL] break [EOL] sleep ( [number] ) [EOL] assert req and hasattr ( req , [string] ) [EOL] assert req . status_code == [number] [EOL] base = [string] [EOL] [comment] [EOL] cmd = [string] . format ( base ) [EOL] exec_cmd = docker_cli . exec_create ( container = container_id , cmd = cmd ) [EOL] exec_out = docker_cli . exec_start ( exec_cmd ) [EOL] assert exec_out . startswith ( str . encode ( base ) ) [EOL] [comment] [EOL] cmd = [string] . format ( base ) [EOL] exec_cmd = docker_cli . exec_create ( container = container_id , cmd = cmd ) [EOL] exec_out = docker_cli . exec_start ( exec_cmd ) [EOL] assert not exec_out [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] [comment] [EOL] from typing import Any , Pattern [EOL] import typing [EOL] import urllib [EOL] from urllib . parse import urlparse [EOL] import re [EOL] import typing [comment] [EOL] import requests_mock [comment] [EOL] from son_analyze . cli import fetch_cmd [EOL] from son_analyze . core import types [EOL] [EOL] [EOL] def test_fetch_cmd ( capsys , tmp_workspace_dir , sonata_demo_mock ) : [EOL] target1 = types . ResourceTargetTuple ( [string] , [string] , [string] , None ) [EOL] target2 = types . ResourceTargetTuple ( None , None , None , [string] ) [EOL] gate = urlparse ( [string] ) [EOL] with requests_mock . Mocker ( ) as mocker : [EOL] for ( url , value ) in sonata_demo_mock : [EOL] mocker . get ( url . geturl ( ) , json = value ) [EOL] fetch_cmd . fetch_cmd ( gate , tmp_workspace_dir , [string] , target1 ) [EOL] out , _ = capsys . readouterr ( ) [EOL] reg = re . compile ( [string] ) [EOL] assert reg . match ( out ) [EOL] reg = re . compile ( [string] , re . MULTILINE ) [EOL] assert reg . search ( out ) [EOL] fetch_cmd . fetch_cmd ( gate , tmp_workspace_dir , [string] , target2 ) [EOL] out , _ = capsys . readouterr ( ) [EOL] reg = re . compile ( [string] , re . MULTILINE ) [EOL] assert reg . search ( out ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] [comment] [EOL] from typing import Any [EOL] import typing [EOL] import typing [comment] [EOL] import copy [EOL] from son_analyze . core import prometheus [EOL] [EOL] [EOL] def test_prometheus_data_load ( basic_query_01 , empty_result , error_result ) : [EOL] x = prometheus . PrometheusData ( basic_query_01 ) [EOL] assert x . is_success ( ) [EOL] assert len ( x . raw [ [string] ] [ [string] ] ) == [number] [EOL] assert len ( x . raw [ [string] ] [ [string] ] [ [number] ] [ [string] ] ) == [number] [EOL] assert x . raw [ [string] ] [ [string] ] [ [number] ] [ [string] ] [ [string] ] == [string] [EOL] cnt_id = [string] [EOL] assert len ( x . get_metric_values ( [string] , cnt_id ) [ [string] ] ) == [number] [EOL] assert len ( x . _by_id ) == [number] [EOL] assert len ( x . _by_metric_name ) == [number] [EOL] assert len ( x . _by_id [ cnt_id ] ) == [number] [EOL] assert len ( x . _by_id [ cnt_id ] [ [number] ] [ [string] ] ) == [number] [EOL] v = x . _by_id [ cnt_id ] [ [number] ] [ [string] ] [ [number] ] [EOL] assert type ( v [ [number] ] ) == float [EOL] assert [string] in x . get_metric_values ( [string] , cnt_id ) [ [string] ] [EOL] assert [string] not in x . get_metric_values ( [string] , cnt_id ) [ [string] ] [EOL] x = prometheus . PrometheusData ( empty_result ) [EOL] assert x . is_success ( ) [EOL] assert x . raw [ [string] ] [ [string] ] == [ ] [EOL] assert len ( x . _by_id ) == [number] [EOL] assert len ( x . _by_metric_name ) == [number] [EOL] x = prometheus . PrometheusData ( error_result ) [EOL] assert not x . is_success ( ) [EOL] assert len ( x . _by_id ) == [number] [EOL] assert len ( x . _by_metric_name ) == [number] [EOL] [EOL] [EOL] def test_add_metric_entry ( basic_query_01 ) : [EOL] x = prometheus . PrometheusData ( basic_query_01 ) [EOL] base_entry = x . raw [ [string] ] [ [string] ] [ [number] ] [EOL] new_entry = copy . deepcopy ( base_entry ) [EOL] new_entry [ [string] ] [ [string] ] = [string] [EOL] x . add_entry ( new_entry ) [EOL] assert len ( x . raw [ [string] ] [ [string] ] ) == [number] [EOL] assert x . raw [ [string] ] [ [string] ] [ [number] ] [ [string] ] [ [string] ] == [string] [EOL] assert x . raw [ [string] ] [ [string] ] [ [number] ] [ [string] ] [ [string] ] == [string] [EOL] [EOL] [EOL] def test_prometheus_data_medium_cnt_load ( mn_empty_vnf1_container_memory_usage_bytes ) : [EOL] x = prometheus . PrometheusData ( mn_empty_vnf1_container_memory_usage_bytes ) [EOL] assert x . is_success ( ) [EOL] metrics = x . get_metric_values ( [string] , ( [string] [string] [string] ) ) [EOL] assert metrics [ [string] ] [ [string] ] == [string] [EOL] assert metrics [ [string] ] [ [string] ] == [string] [EOL] assert ( len ( metrics [ [string] ] ) == [number] ) [EOL] [EOL] [EOL] def test_prometheus_data_medium_emu_load ( empty_vnf1_sonemu_rx_count_packets ) : [EOL] x = prometheus . PrometheusData ( empty_vnf1_sonemu_rx_count_packets ) [EOL] assert x . is_success ( ) [EOL] metrics = x . _by_metric_name [ [string] ] [EOL] print ( metrics ) [EOL] assert ( len ( metrics [ [string] ] [ [string] ] ) == [number] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] [docstring] [EOL] [EOL] __version__ = [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] from typing import Any , Iterable , Dict [EOL] import urllib [EOL] import builtins [EOL] import son_analyze [EOL] import typing [EOL] import logging [EOL] [docstring] [EOL] [EOL] [comment] [EOL] import logging [EOL] from urllib . parse import ParseResult [EOL] from typing import Dict , Iterable , Any [EOL] import yaml [comment] [EOL] from son_analyze . ops import fetch [EOL] from son_analyze . core import types [EOL] [EOL] [EOL] _LOGGER = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def _print_yml_to_stdout ( values ) : [EOL] [docstring] [EOL] print ( yaml . dump_all ( values ) ) [EOL] [EOL] [EOL] def _not_available ( * _ ) : [EOL] [docstring] [EOL] _ = ( [string] [string] ) [EOL] raise RuntimeError ( _ ) [EOL] [EOL] [EOL] def fetch_cmd ( gatekeeper , workspace_path , skind , target ) : [EOL] [docstring] [EOL] try : [EOL] kind = fetch . Kind [ skind ] [EOL] except KeyError : [EOL] raise RuntimeError ( [string] . format ( skind ) ) [EOL] if target . uuid : [EOL] base , children = fetch . fetch_resources_by_uuid ( gatekeeper , workspace_path , kind , target . uuid ) [EOL] else : [EOL] base , children = fetch . fetch_resources ( gatekeeper , workspace_path , kind , target . vendor , target . name , target . version ) [EOL] _print_yml_to_stdout ( [ base ] + children ) [EOL] return [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] from typing import Type [EOL] import typing [EOL] import src [EOL] [docstring] [EOL] [EOL] import collections [EOL] import typing [comment] [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] ResourceTargetTuple = collections . namedtuple ( [string] , [ [string] , [string] , [string] , [string] ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[src.son_analyze.core.types.ResourceTargetTuple]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] from typing import Any , List , OrderedDict , Optional , Tuple , Dict , Type [EOL] import requests [EOL] import urllib [EOL] import builtins [EOL] import typing [EOL] import logging [EOL] import src [EOL] import collections [EOL] [docstring] [EOL] [EOL] import os [EOL] from enum import Enum [EOL] import logging [EOL] import collections [EOL] from urllib . parse import ParseResult , urljoin [EOL] from typing import Dict , Any , Tuple , List [EOL] import requests [EOL] [EOL] [EOL] _LOGGER = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class FetchError ( Exception ) : [EOL] [docstring] [EOL] pass [EOL] [EOL] [EOL] class InvalidResourceReferenceError ( FetchError ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] def __init__ ( self , nsd , missing_vnf_id ) : [EOL] super ( ) . __init__ ( ) [EOL] self . nsd = nsd [EOL] self . missing_vnf_id = missing_vnf_id [EOL] self . message = ( [string] [string] ) . format ( nsd [ [string] ] , nsd [ [string] ] , nsd [ [string] ] , missing_vnf_id ) [EOL] [EOL] [EOL] def _get_workspace_token ( workspace_dir ) : [EOL] [docstring] [EOL] _LOGGER . debug ( [string] , workspace_dir ) [EOL] path = os . path . join ( workspace_dir , [string] , [string] ) [EOL] if os . path . isfile ( path ) and os . access ( path , os . R_OK ) : [EOL] with open ( path ) as tkn : [EOL] return tkn . read ( ) [EOL] else : [EOL] _ = [string] . format ( path ) [EOL] exc = RuntimeError ( _ ) [EOL] _LOGGER . error ( [string] , exc ) [EOL] raise exc [EOL] [EOL] [EOL] class Kind ( Enum ) : [EOL] [docstring] [EOL] nsd = [number] [EOL] vnfd = [number] [EOL] vnfr = [number] [EOL] nsr = [number] [EOL] [EOL] [EOL] def _get_path_from_kind ( kind ) : [EOL] [docstring] [EOL] table = { Kind . nsd : [string] , Kind . vnfd : [string] , Kind . vnfr : [string] , Kind . nsr : [string] } [EOL] try : [EOL] return table [ kind ] [EOL] except KeyError : [EOL] _ = [string] . format ( kind ) [EOL] raise RuntimeError ( _ ) [EOL] [EOL] [EOL] def _get_childrend_kind ( kind ) : [EOL] [docstring] [EOL] table = { Kind . nsd : Kind . vnfd , Kind . vnfd : None , Kind . vnfr : None , Kind . nsr : Kind . vnfr } [EOL] try : [EOL] return table [ kind ] [EOL] except KeyError : [EOL] _ = [string] . format ( kind ) [EOL] raise RuntimeError ( _ ) [EOL] [EOL] [EOL] FETCHTYPE = Tuple [ Dict [ str , Any ] , List [ Dict [ str , Any ] ] ] [EOL] [EOL] [EOL] [comment] [EOL] def fetch_resource_by_uuid ( gatekeeper_endpoint , workspace_dir , kind , uuid ) : [EOL] [docstring] [EOL] url = urljoin ( gatekeeper_endpoint . geturl ( ) , os . path . join ( _get_path_from_kind ( kind ) , uuid ) ) [EOL] _LOGGER . info ( [string] , url ) [EOL] auth = [string] + _get_workspace_token ( workspace_dir ) [EOL] res_resp = requests . get ( url , headers = { [string] : [string] , [string] : auth } ) [EOL] try : [EOL] res_resp . raise_for_status ( ) [EOL] except requests . exceptions . HTTPError as exc_notfound : [EOL] _LOGGER . exception ( [string] [string] , res_resp . url , res_resp . status_code ) [EOL] if exc_notfound . response . status_code == [number] : [EOL] return None [EOL] else : [EOL] raise [EOL] tmp = res_resp . json ( ) [EOL] if not isinstance ( tmp , dict ) or len ( tmp ) <= [number] : [EOL] exc = RuntimeError ( [string] . format ( tmp ) ) [EOL] _LOGGER . error ( [string] , exc ) [EOL] raise exc [EOL] _LOGGER . info ( [string] , res_resp . url , res_resp . status_code ) [EOL] if kind . name in tmp : [comment] [EOL] tmp = tmp [ kind . name ] [EOL] return tmp [EOL] [EOL] [EOL] [comment] [EOL] def fetch_resource ( gatekeeper_endpoint , workspace_dir , kind , vendor , name , version ) : [EOL] [docstring] [EOL] url = urljoin ( gatekeeper_endpoint . geturl ( ) , _get_path_from_kind ( kind ) ) [EOL] _LOGGER . info ( [string] , kind , url ) [EOL] query_params_raw = { [string] : vendor , [string] : name , [string] : version } [EOL] [comment] [EOL] [comment] [EOL] query_params = collections . OrderedDict ( sorted ( query_params_raw . items ( ) ) ) [EOL] auth = [string] + _get_workspace_token ( workspace_dir ) [EOL] res_resp = requests . get ( url , params = query_params , headers = { [string] : [string] , [string] : auth } ) [EOL] try : [EOL] res_resp . raise_for_status ( ) [EOL] except requests . exceptions . HTTPError : [EOL] _LOGGER . exception ( [string] [string] , res_resp . url , res_resp . status_code ) [EOL] [comment] [EOL] [comment] [EOL] raise [EOL] tmp = res_resp . json ( ) [EOL] if not isinstance ( tmp , list ) : [EOL] exc = RuntimeError ( [string] ) [EOL] _LOGGER . error ( [string] , exc ) [EOL] raise exc [EOL] _LOGGER . info ( [string] , res_resp . url , res_resp . status_code , tmp [ : [number] ] ) [EOL] for elt in tmp : [EOL] this_uuid = elt [ [string] ] [EOL] if not this_uuid : [EOL] _LOGGER . warning ( [string] , elt ) [EOL] continue [EOL] if kind . name in elt : [comment] [EOL] elt = elt [ kind . name ] [EOL] if all ( [ elt [ [string] ] == vendor , elt [ [string] ] == name , elt [ [string] ] == version ] ) : [EOL] return ( this_uuid , elt ) [EOL] return None [EOL] [EOL] [EOL] [comment] [EOL] def _complete_nsd_with_vnfds ( gatekeeper_endpoint , workspace_dir , uuid , nsd , kchildren ) : [EOL] [docstring] [EOL] _LOGGER . info ( [string] , uuid ) [EOL] acc = [ ] [comment] [EOL] for fun_desc in nsd [ [string] ] : [EOL] if [string] in fun_desc : [EOL] vnfd = fetch_resource_by_uuid ( gatekeeper_endpoint , workspace_dir , kchildren , fun_desc [ [string] ] ) [EOL] else : [EOL] ( _ , vnfd ) = fetch_resource ( gatekeeper_endpoint , workspace_dir , kchildren , fun_desc [ [string] ] , fun_desc [ [string] ] , fun_desc [ [string] ] ) [EOL] if not vnfd : [EOL] exc = InvalidResourceReferenceError ( nsd , fun_desc [ [string] ] ) [EOL] _LOGGER . error ( [string] , exc ) [EOL] raise exc [EOL] acc . append ( vnfd ) [comment] [EOL] return ( nsd , acc ) [EOL] [EOL] [EOL] [comment] [EOL] def fetch_resources ( gatekeeper_endpoint , workspace_dir , kind , vendor , name , version ) : [EOL] [docstring] [EOL] ( uuid , base ) = fetch_resource ( gatekeeper_endpoint , workspace_dir , kind , vendor , name , version ) [EOL] kchildren = _get_childrend_kind ( kind ) [EOL] if base and kchildren : [EOL] return _complete_nsd_with_vnfds ( gatekeeper_endpoint , workspace_dir , uuid , base , kchildren ) [EOL] return base , [ ] [EOL] [EOL] [EOL] [comment] [EOL] def fetch_resources_by_uuid ( gatekeeper_endpoint , workspace_dir , kind , uuid ) : [EOL] [docstring] [EOL] base = fetch_resource_by_uuid ( gatekeeper_endpoint , workspace_dir , kind , uuid ) [EOL] kchildren = _get_childrend_kind ( kind ) [EOL] if base and kchildren : [EOL] return _complete_nsd_with_vnfds ( gatekeeper_endpoint , workspace_dir , uuid , base , kchildren ) [EOL] return base , [ ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] from typing import Any [EOL] import socket [EOL] import multiprocessing [EOL] import utils [EOL] import typing [EOL] import logging [EOL] import threading [EOL] import sys [EOL] import time [EOL] import signal [EOL] import threading [EOL] import multiprocessing as mp [EOL] import logging [EOL] import os [EOL] import socket [EOL] import stat [EOL] from emuvim . api . rest . rest_api_endpoint import RestApiEndpoint [EOL] from emuvim . dcemulator . net import DCNetwork [EOL] from mininet . node import RemoteController [EOL] from mininet . log import setLogLevel [EOL] from emuvim . api . sonata import SonataDummyGatekeeperEndpoint [EOL] [EOL] [EOL] _LOGGER = logging . getLogger ( __name__ ) [EOL] logging . basicConfig ( level = logging . DEBUG ) [EOL] [EOL] [EOL] class SigTermCatcher : [comment] [EOL] [EOL] def __init__ ( self ) : [EOL] _LOGGER . info ( [string] ) [EOL] self . restart_lock = mp . Lock ( ) [EOL] self . terminating = False [EOL] self . stop_hooks = [ ] [EOL] self . org_term = signal . getsignal ( signal . SIGTERM ) [EOL] self . org_int = signal . getsignal ( signal . SIGINT ) [EOL] self . org_usr1 = signal . getsignal ( signal . SIGUSR1 ) [EOL] [EOL] def setup_signal ( self ) : [EOL] signal . signal ( signal . SIGTERM , self . stop_containernet ) [EOL] signal . signal ( signal . SIGINT , self . stop_containernet ) [EOL] signal . signal ( signal . SIGUSR1 , self . restart_containernet ) [EOL] [EOL] def ignore_signal ( self ) : [EOL] signal . signal ( signal . SIGTERM , signal . SIG_IGN ) [EOL] signal . signal ( signal . SIGINT , signal . SIG_IGN ) [EOL] signal . signal ( signal . SIGUSR1 , signal . SIG_IGN ) [EOL] [EOL] def restore_signal ( self ) : [EOL] signal . signal ( signal . SIGTERM , self . org_term ) [EOL] signal . signal ( signal . SIGINT , self . org_int ) [EOL] signal . signal ( signal . SIGUSR1 , self . org_usr1 ) [EOL] [EOL] def register ( self , forked_process , lock ) : [EOL] self . forked_process = forked_process [EOL] self . lock = lock [EOL] [EOL] def stop_containernet ( self , signum , frame ) : [EOL] msg = [string] . format ( signum , frame , os . getpid ( ) , os . getppid ( ) ) [EOL] _LOGGER . warn ( msg ) [EOL] [comment] [EOL] self . lock . release ( ) [EOL] [comment] [EOL] [comment] [EOL] for i in range ( [number] ) : [EOL] if self . forked_process . is_alive ( ) : [EOL] self . forked_process . terminate ( ) [EOL] time . sleep ( [number] ) [EOL] else : [EOL] break [EOL] self . terminating = True [EOL] [EOL] def restart_containernet ( self , signum , frame ) : [EOL] msg = [string] . format ( signum , frame , os . getpid ( ) , os . getppid ( ) ) [EOL] _LOGGER . warn ( msg ) [EOL] [comment] [EOL] self . lock . release ( ) [EOL] for i in range ( [number] ) : [EOL] if self . forked_process . is_alive ( ) : [EOL] self . forked_process . terminate ( ) [EOL] time . sleep ( [number] ) [EOL] else : [EOL] break [EOL] [EOL] def is_alive ( self ) : [EOL] return not self . terminating [EOL] [EOL] def add ( self , to_be_stopped ) : [EOL] self . stop_hooks . insert ( [number] , to_be_stopped ) [EOL] [EOL] [EOL] def setup_topology ( net ) : [EOL] _LOGGER . info ( [string] ) [EOL] dc = net . addDatacenter ( [string] ) [comment] [EOL] net . addLink ( dc , net . addSwitch ( [string] ) , delay = [string] ) [EOL] [comment] [EOL] rapi1 = RestApiEndpoint ( [string] , [number] ) [EOL] rapi1 . connectDCNetwork ( net ) [EOL] rapi1 . connectDatacenter ( dc ) [EOL] rapi1 . start ( ) [EOL] sdkg1 = SonataDummyGatekeeperEndpoint ( [string] , [number] , deploy_sap = False ) [EOL] sdkg1 . connectDatacenter ( dc ) [EOL] [comment] [EOL] sdkg1 . start ( ) [EOL] [EOL] [EOL] def create_and_start_topology ( lock , restart_lock ) : [EOL] _LOGGER . info ( [string] ) [EOL] net = DCNetwork ( controller = RemoteController , monitor = True , enable_learning = True ) [EOL] restart_lock . acquire ( ) [EOL] setup_topology ( net ) [EOL] try : [EOL] net . start ( ) [comment] [EOL] _LOGGER . info ( [string] ) [EOL] lock . acquire ( ) [EOL] _LOGGER . info ( [string] ) [EOL] net . stop ( ) [EOL] lock . release ( ) [EOL] except Exception as e : [EOL] _LOGGER . error ( [string] . format ( e ) ) [EOL] restart_lock . release ( ) [EOL] exit ( [number] ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] def spawn_process ( sc ) : [EOL] _LOGGER . info ( [string] ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] lock = mp . Lock ( ) [EOL] lock . acquire ( ) [EOL] forked_process = mp . Process ( target = create_and_start_topology , args = ( lock , sc . restart_lock ) ) [EOL] sc . register ( forked_process , lock ) [EOL] return forked_process [EOL] [EOL] [EOL] def create_socket ( ) : [EOL] _LOGGER . info ( [string] ) [EOL] path = [string] [EOL] if os . path . exists ( path ) : [EOL] os . remove ( path ) [EOL] [comment] [EOL] server = socket . socket ( socket . AF_UNIX , socket . SOCK_STREAM ) [EOL] server . setsockopt ( socket . SOL_SOCKET , socket . SO_REUSEADDR , [number] ) [EOL] server . bind ( path ) [EOL] os . chmod ( path , stat . S_IRWXO ) [EOL] server . listen ( [number] ) [EOL] return server [EOL] [EOL] [EOL] def listen_socket ( server , sc ) : [EOL] while sc . is_alive ( ) : [EOL] [comment] [EOL] try : [EOL] client , addr = server . accept ( ) [EOL] except socket . error as e : [EOL] _LOGGER . error ( [string] . format ( e ) ) [EOL] exit ( [number] ) [EOL] _LOGGER . info ( [string] . format ( addr ) ) [EOL] datagram = client . recv ( len ( [string] ) ) [EOL] if datagram : [EOL] _LOGGER . info ( [string] . format ( datagram , addr ) ) [EOL] if datagram == [string] : [EOL] sc . restart_containernet ( - [number] , - [number] ) [EOL] sc . restart_lock . acquire ( ) [EOL] _LOGGER . info ( [string] ) [EOL] [comment] [EOL] client . send ( [string] ) [EOL] sc . restart_lock . release ( ) [EOL] client . close ( ) [EOL] else : [EOL] client . close ( ) [EOL] break [EOL] [EOL] [EOL] def spawn_socket_thread ( sc ) : [EOL] _LOGGER . info ( [string] ) [EOL] server = create_socket ( ) [EOL] t = threading . Thread ( target = listen_socket , args = ( server , sc ) ) [EOL] return ( t , server ) [EOL] [EOL] [EOL] def main ( ) : [EOL] _LOGGER . info ( [string] . format ( os . getpid ( ) , os . getppid ( ) ) ) [EOL] setLogLevel ( [string] ) [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] sc = SigTermCatcher ( ) [EOL] ( server_thread , server ) = spawn_socket_thread ( sc ) [EOL] server_thread . start ( ) [EOL] [EOL] while True : [EOL] if sc . is_alive ( ) : [EOL] forked_process = spawn_process ( sc ) [EOL] sc . ignore_signal ( ) [EOL] forked_process . start ( ) [EOL] sc . setup_signal ( ) [EOL] forked_process . join ( ) [EOL] else : [EOL] break [EOL] time . sleep ( [number] ) [EOL] [EOL] _LOGGER . info ( [string] ) [EOL] server . shutdown ( socket . SHUT_RDWR ) [EOL] server_thread . join ( ) [EOL] exit ( [number] ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] try : [EOL] main ( ) [EOL] except Exception as e : [EOL] _LOGGER . error ( [string] . format ( os . getpid ( ) , os . getppid ( ) , e ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List [EOL] import typing [EOL] import sys [EOL] import gc [EOL] import time [EOL] import math [EOL] from twisted . internet import epollreactor [EOL] epollreactor . install ( ) [EOL] from twisted . internet import reactor [EOL] from twisted . web . client import HTTPConnectionPool [EOL] import treq [EOL] [EOL] [EOL] pool = HTTPConnectionPool ( reactor ) [EOL] loop_counter = [number] [EOL] acc = [ ] [EOL] [EOL] [EOL] p = [number] [EOL] sp = [number] [EOL] [EOL] [EOL] def c ( x_in_period ) : [EOL] [comment] [EOL] tmp = math . fabs ( x_in_period - x_in_period % sp ) [EOL] if tmp == [number] : [EOL] return [number] [EOL] else : [EOL] return [number] [EOL] [EOL] [EOL] def d ( x ) : [EOL] x_in_period = x % p [EOL] return int ( [number] * math . sin ( ( math . pi * x_in_period ) / sp ) ) * c ( x_in_period ) [EOL] [EOL] def inverse ( y ) : [EOL] if y == [number] : [EOL] return [number] [EOL] else : [EOL] return [number] [EOL] [EOL] [EOL] def loop ( limit ) : [EOL] global loop_counter [EOL] global acc [EOL] loop_counter += [number] [EOL] size = [number] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] nb_request = d ( loop_counter ) [EOL] if ( loop_counter % p ) == [number] : [EOL] acc = [ ] [EOL] gc . collect ( ) [EOL] if sp <= ( loop_counter % p ) : [EOL] size = [number] * math . log ( [number] + ( ( loop_counter % ( p - sp ) ) / ( p - sp ) ) * p ) [EOL] acc . append ( bytearray ( int ( size ) ) ) [EOL] print ( [string] . format ( loop_counter , nb_request , len ( acc ) , size ) ) [EOL] for _ in range ( nb_request ) : [EOL] [comment] [EOL] [comment] [EOL] tmp = treq . get ( [string] , timeout = [number] , persistent = True , pool = pool ) [EOL] tmp . addErrback ( lambda _ : None ) [EOL] if limit < [number] or loop_counter < limit : [EOL] reactor . callLater ( [number] , loop , limit ) [EOL] else : [EOL] reactor . stop ( ) [EOL] [EOL] [EOL] def main ( args ) : [EOL] limit = - [number] [EOL] if len ( args ) == [number] : [EOL] limit = int ( args [ [number] ] ) [EOL] print ( [string] . format ( limit , args ) ) [EOL] target = [string] [EOL] d = treq . get ( target ) [EOL] d . addCallback ( lambda _ : None ) [EOL] reactor . callLater ( [number] , loop , limit ) [EOL] reactor . run ( ) [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] [comment] [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( sys . argv ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 $typing.List[typing.Any]$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] from typing import Any , Match , Optional [EOL] import typing [EOL] [docstring] [EOL] [EOL] import codecs [EOL] import os [EOL] import re [EOL] import sys [EOL] from setuptools import setup , find_packages [comment] [EOL] [EOL] [EOL] def read ( * parts ) : [EOL] [docstring] [EOL] path = os . path . join ( os . path . dirname ( __file__ ) , * parts ) [EOL] with codecs . open ( path , encoding = [string] ) as fobj : [EOL] return fobj . read ( ) [EOL] [EOL] [EOL] def find_version ( * file_paths ) : [EOL] [docstring] [EOL] version_file = read ( * file_paths ) [EOL] version_match = re . search ( [string] , version_file , re . M ) [EOL] if version_match : [EOL] return version_match . group ( [number] ) [EOL] raise RuntimeError ( [string] ) [EOL] [EOL] if not ( sys . version_info . major == [number] and sys . version_info . minor >= [number] ) : [EOL] sys . exit ( [string] ) [EOL] [EOL] setup ( name = [string] , version = find_version ( [string] , [string] ) , license = [string] , description = [string] , url = [string] , author_email = [string] , package_dir = { [string] : [string] } , packages = find_packages ( [string] ) , install_requires = [ [string] , [string] , [string] , [string] , [string] ] , zip_safe = False , tests_require = [ [string] , [string] , [string] , ] , include_package_data = True ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] [docstring] [EOL] [EOL] __version__ = [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] from typing import Any , Tuple [EOL] import typing [EOL] import pandas [EOL] [docstring] [EOL] [EOL] [EOL] import arrow [comment] [EOL] from typing import Any , Tuple [comment] [EOL] import pandas [comment] [EOL] [EOL] [EOL] def reset ( arr ) : [EOL] [docstring] [EOL] return arr . replace ( second = [number] , microsecond = [number] ) [EOL] [EOL] [EOL] def interval_to_now ( grace_seconds = - [number] , ** kwargs ) : [EOL] [docstring] [EOL] end = reset ( arrow . utcnow ( ) . shift ( seconds = grace_seconds ) ) [EOL] start = end . shift ( ** kwargs ) [EOL] return start , end . shift ( seconds = - [number] ) [EOL] [EOL] [EOL] def smooth_dataframe ( dataf , window = [number] ) : [EOL] [docstring] [EOL] return dataf . rolling ( center = False , window = window ) . mean ( ) . interpolate ( limit_direction = [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] from typing import Any , List , Dict [EOL] import pandas [EOL] import builtins [EOL] import son_analyze [EOL] import datetime [EOL] import typing [EOL] [docstring] [EOL] [EOL] import datetime [EOL] import typing [comment] [EOL] from typing import Dict [EOL] import pandas [comment] [EOL] from son_analyze . core . prometheus import PrometheusData [EOL] [EOL] [EOL] def convert_timestamp_to_posix ( timestamp ) : [EOL] [docstring] [EOL] return datetime . datetime . fromtimestamp ( float ( timestamp ) , tz = datetime . timezone . utc ) [EOL] [EOL] [EOL] [comment] [EOL] def build_sonata_df_by_id ( prom_data ) : [EOL] [docstring] [EOL] [comment] [EOL] [comment] [EOL] result = { } [EOL] items_itr = prom_data . _by_id . items ( ) [comment] [EOL] for id_index , all_metrics in items_itr : [EOL] acc_ts = [ ] [EOL] for elt in all_metrics : [EOL] metric_name = elt [ [string] ] [ [string] ] [EOL] index , data = zip ( * elt [ [string] ] ) [EOL] index = [ convert_timestamp_to_posix ( z ) for z in index ] [EOL] this_serie = pandas . Series ( data , index = index ) [EOL] this_serie . name = metric_name [EOL] acc_ts . append ( this_serie ) [EOL] dataframe = pandas . concat ( acc_ts , join = [string] , axis = [number] ) [EOL] dataframe . index = pandas . date_range ( start = dataframe . index [ [number] ] , periods = len ( dataframe . index ) , freq = [string] ) [EOL] dataframe = dataframe . interpolate ( method = [string] ) [EOL] [comment] [EOL] result [ id_index ] = dataframe [EOL] return result [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $datetime.datetime$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,pandas.DataFrame]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List , Literal , Tuple , Dict [EOL] import typing [EOL] import typing_extensions [EOL] [docstring] [EOL] [EOL] from colorsys import rgb_to_hls , hls_to_rgb [EOL] import numpy as np [EOL] import pandas [EOL] import matplotlib . pyplot as plt [EOL] import matplotlib . colors as mcolors [EOL] import warnings [EOL] warnings . simplefilter ( [string] , category = FutureWarning ) [EOL] from statsmodels . tsa . stattools import adfuller [comment] [EOL] warnings . resetwarnings ( ) [EOL] import statsmodels as smt [comment] [EOL] [EOL] [EOL] def foobar ( ) : [EOL] [docstring] [EOL] return [string] [EOL] [EOL] [EOL] def shade_color ( color , percent ) : [EOL] [docstring] [EOL] rgb = mcolors . colorConverter . to_rgb ( color ) [EOL] h , l , s = rgb_to_hls ( * rgb ) [EOL] l *= [number] + float ( percent ) / [number] [EOL] l = np . clip ( l , [number] , [number] ) [EOL] r , g , b = hls_to_rgb ( h , l , s ) [EOL] return r , g , b [EOL] [EOL] [EOL] def test_stationarity ( dataf ) : [EOL] rolbase = dataf . rolling ( center = False , window = [number] ) [EOL] rolmean = rolbase . mean ( ) [EOL] rolstd = rolbase . std ( ) [EOL] fig = plt . figure ( ) [EOL] pos = [number] [EOL] for k , elt in dataf . items ( ) : [EOL] ax1 = fig . add_subplot ( len ( dataf . columns ) , [number] , [number] + pos ) [EOL] ax3 = fig . add_subplot ( len ( dataf . columns ) , [number] , [number] + pos ) [EOL] pos += [number] [EOL] bcolor = np . random . rand ( [number] ) [EOL] bcolor = bcolor * [ [number] , [number] , [number] ] [EOL] _ = ax1 . plot ( elt , [string] , linewidth = [number] , label = k , c = bcolor ) [EOL] _ = ax1 . plot ( rolmean [ k ] , [string] , linewidth = [number] , color = [string] , label = [string] ) [EOL] _ = ax1 . plot ( rolstd [ k ] , [string] , linewidth = [number] , color = [string] , label = [string] ) [EOL] ax1 . legend ( loc = [string] ) [EOL] _ = ax3 . plot ( rolstd [ k ] , [string] , linewidth = [number] , color = [string] , label = [string] ) [EOL] assert _ [EOL] ax3 . legend ( loc = [string] ) [EOL] fig . suptitle ( [string] ) [EOL] print ( [string] ) [EOL] adf_results = { } [EOL] for col in dataf . columns . values : [EOL] try : [EOL] dftest = adfuller ( dataf [ col ] , autolag = [string] ) [EOL] except np . linalg . LinAlgError as e : [EOL] print ( [string] . format ( col , e ) ) [EOL] continue [EOL] dfoutput = pandas . Series ( dftest [ [number] : [number] ] , index = [ [string] , [string] , [string] , [string] ] ) [EOL] for key , value in dftest [ [number] ] . items ( ) : [EOL] dfoutput [ [string] % key ] = value [EOL] adf_results [ col ] = dfoutput [EOL] tmp = pandas . DataFrame ( adf_results ) [EOL] print ( tmp ) [EOL] return fig [EOL] [EOL] [EOL] def autocorrelation_plot ( tserie , lags = [number] ) : [EOL] fig = plt . figure ( ) [EOL] fig . suptitle ( [string] . format ( tserie . name ) ) [EOL] layout = ( [number] , [number] ) [EOL] tmp = { [string] : [ plt . subplot2grid ( layout , ( [number] , [number] ) ) , smt . tsa . stattools . acf ( tserie , nlags = lags ) , [string] ] , [string] : [ plt . subplot2grid ( layout , ( [number] , [number] ) ) , smt . tsa . stattools . pacf ( tserie , nlags = lags , method = [string] ) , [string] ] } [EOL] z95 = [number] [EOL] z99 = [number] [EOL] for k , v in tmp . items ( ) : [EOL] target_ax = v [ [number] ] [EOL] lenv1 = len ( v [ [number] ] ) [EOL] target_ax . set_xlim ( [ [number] , lenv1 ] ) [EOL] target_ax . set_ylim ( [ - [number] , [number] ] ) [EOL] target_ax . set_xticks ( np . arange ( [number] , lags + [number] , [number] ) ) [EOL] target_ax . set_xticks ( np . arange ( [number] , lags + [number] , [number] ) , minor = True ) [EOL] target_ax . plot ( v [ [number] ] , label = k ) [EOL] target_ax . axhline ( y = [number] , linestyle = [string] , color = [string] ) [EOL] target_ax . axhline ( y = z99 / np . sqrt ( lenv1 ) , linestyle = [string] , color = [string] , label = [string] ) [EOL] target_ax . axhline ( y = z95 / np . sqrt ( lenv1 ) , linestyle = [string] , color = [string] , label = [string] ) [EOL] target_ax . axhline ( y = - z95 / np . sqrt ( lenv1 ) , linestyle = [string] , color = [string] , label = [string] ) [EOL] target_ax . axhline ( y = - z99 / np . sqrt ( lenv1 ) , linestyle = [string] , color = [string] , label = [string] ) [EOL] target_ax . set_xlabel ( [string] ) [EOL] target_ax . set_ylabel ( [string] ) [EOL] target_ax . legend ( loc = [string] ) [EOL] target_ax . set_title ( v [ [number] ] ) [EOL] target_ax . grid ( b = True , which = [string] ) [EOL] return fig [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] [comment] [EOL] import builtins [EOL] import sys [EOL] import os [EOL] import typing [comment] [EOL] from pkg_resources import resource_filename [comment] [EOL] import pytest [comment] [EOL] [EOL] [EOL] def _find_sonanalyze_fixtures ( ) : [EOL] path = os . path . realpath ( resource_filename ( [string] , [string] ) ) [EOL] return os . path . join ( path , [string] ) [EOL] [EOL] [EOL] def _read_static_fixtures_file ( relative_path , from_sonanalyze = False ) : [EOL] [docstring] [EOL] base = os . path . join ( sys . modules [ __name__ ] . __file__ , [string] , [string] ) [EOL] if from_sonanalyze : [EOL] base = _find_sonanalyze_fixtures ( ) [EOL] path = os . path . realpath ( os . path . join ( base , relative_path ) ) [EOL] with open ( path , [string] ) as data_file : [EOL] return data_file . read ( ) [EOL] [EOL] [EOL] @ pytest . fixture def basic_query_01 ( ) : [EOL] return _read_static_fixtures_file ( [string] , True ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import typing [EOL] import copy [EOL] import datetime [EOL] import typing [comment] [EOL] from son_analyze . core import prometheus [EOL] import son_scikit . hl_prometheus as hl [EOL] [EOL] [EOL] def test_build_sonata_df ( basic_query_01 ) : [EOL] x = prometheus . PrometheusData ( basic_query_01 ) [EOL] base_entry = x . raw [ [string] ] [ [string] ] [ [number] ] [EOL] new_entry1 = copy . deepcopy ( base_entry ) [EOL] new_entry1 [ [string] ] [ [string] ] = [string] [EOL] x . add_entry ( new_entry1 ) [EOL] new_entry2 = copy . deepcopy ( base_entry ) [EOL] new_entry2 [ [string] ] [ [string] ] = [string] [EOL] new_entry2 [ [string] ] = [ ( i [ [number] ] , [number] + i [ [number] ] ) for i in new_entry2 [ [string] ] ] [EOL] x . add_entry ( new_entry2 ) [EOL] new_entry3 = copy . deepcopy ( base_entry ) [EOL] new_entry3 [ [string] ] [ [string] ] = [string] [EOL] [EOL] def trans ( t ) : [comment] [EOL] d = hl . convert_timestamp_to_posix ( t [ [number] ] ) [EOL] d = d + datetime . timedelta ( [number] , [number] ) [EOL] return ( d . timestamp ( ) , [number] + t [ [number] ] ) [EOL] [EOL] new_entry3 [ [string] ] = [ trans ( i ) for i in new_entry3 [ [string] ] ] [EOL] x . add_entry ( new_entry3 ) [EOL] tmp = hl . build_sonata_df_by_id ( x ) [EOL] for _ , elt in tmp . items ( ) : [EOL] assert elt . index . freq == [string] [EOL] assert any ( elt . notnull ( ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import typing [EOL] import typing [comment] [EOL] import arrow [EOL] import son_scikit . hl_utils as hu [EOL] [EOL] [EOL] def test_now ( ) : [EOL] tmp = arrow . utcnow ( ) [EOL] assert tmp == tmp . shift ( seconds = [number] ) [EOL] n = hu . reset ( arrow . utcnow ( ) ) [EOL] assert n . second == [number] [EOL] assert n . microsecond == [number] [EOL] ( start , end ) = hu . interval_to_now ( - [number] , minutes = - [number] , seconds = - [number] ) [EOL] assert end . second == [number] [EOL] assert len ( arrow . Arrow . range ( [string] , start , end ) ) == [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0