[comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] from typing import Any , Optional , Generator [EOL] import typing [EOL] [docstring] [EOL] [EOL] import logging [EOL] import os [EOL] import random [EOL] [EOL] import numpy as np [EOL] import mxnet as mx [EOL] import gluonts [EOL] import pytest [EOL] [EOL] [EOL] [comment] [EOL] def pytest_configure ( ) : [EOL] [docstring] [EOL] [EOL] module_seed_str = os . getenv ( [string] ) [EOL] if module_seed_str is None : [EOL] seed = np . random . randint ( [number] , np . iinfo ( np . int32 ) . max ) [EOL] else : [EOL] seed = int ( module_seed_str ) [EOL] logging . warning ( [string] [string] ) [EOL] print ( [string] [string] . format ( seed ) ) [EOL] [EOL] np . random . seed ( seed ) [EOL] mx . random . seed ( seed ) [EOL] random . seed ( seed ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] if os . getenv ( [string] ) is not None : [EOL] logging . warning ( [string] [string] ) [EOL] [EOL] [EOL] @ pytest . hookimpl ( tryfirst = True , hookwrapper = True ) def pytest_runtest_makereport ( item , call ) : [EOL] [docstring] [EOL] [comment] [EOL] outcome = yield [EOL] rep = outcome . get_result ( ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] setattr ( item , [string] + rep . when , rep ) [EOL] [EOL] [EOL] @ pytest . fixture ( scope = [string] , autouse = True ) def function_scope_seed ( request ) : [EOL] [docstring] [EOL] [EOL] seed = request . node . get_marker ( [string] ) [EOL] env_seed_str = os . getenv ( [string] ) [EOL] [EOL] if seed is not None : [EOL] seed = seed . args [ [number] ] [EOL] assert isinstance ( seed , int ) [EOL] elif env_seed_str is not None : [EOL] seed = int ( env_seed_str ) [EOL] else : [EOL] seed = np . random . randint ( [number] , np . iinfo ( np . int32 ) . max ) [EOL] [EOL] post_test_state = np . random . get_state ( ) [EOL] np . random . seed ( seed ) [EOL] mx . random . seed ( seed ) [EOL] random . seed ( seed ) [EOL] [EOL] seed_message = ( [string] [string] ) [EOL] seed_message = seed_message . format ( seed , seed ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] logging . debug ( seed_message ) [EOL] [EOL] yield [comment] [EOL] [EOL] if request . node . rep_call . outcome == [string] : [EOL] [comment] [EOL] logging . info ( seed_message ) [EOL] [EOL] np . random . set_state ( post_test_state ) [EOL] [EOL] [EOL] [comment] [EOL] @ pytest . fixture ( params = [ True , False ] ) def hybridize ( request ) : [EOL] return request . param [EOL] [EOL] [EOL] @ pytest . fixture ( autouse = True ) def doctest ( doctest_namespace ) : [EOL] doctest_namespace [ [string] ] = np [EOL] doctest_namespace [ [string] ] = gluonts [EOL] doctest_namespace [ [string] ] = mx [EOL] doctest_namespace [ [string] ] = mx . gluon [EOL] import doctest [EOL] [EOL] doctest . ELLIPSIS_MARKER = [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import os [EOL] [EOL] [docstring] [EOL] GLUONTS_MAX_IDLE_TRANSFORMS = int ( os . environ . get ( [string] , [string] ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Any , Dict [EOL] import typing [EOL] import functools [EOL] import sys [EOL] [EOL] [comment] [EOL] from tqdm import tqdm as _tqdm [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] [comment] [EOL] USE_TQDM = True [EOL] [EOL] [EOL] @ functools . wraps ( _tqdm ) def tqdm ( it , * args , ** kwargs ) : [EOL] [EOL] kwargs = kwargs . copy ( ) [EOL] if not sys . stdout . isatty ( ) : [EOL] kwargs . update ( mininterval = [number] ) [EOL] [EOL] return _tqdm ( it , * args , disable = not USE_TQDM , ** kwargs ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import importlib [EOL] import sys [EOL] import warnings [EOL] [EOL] import gluonts . mx . block [EOL] [EOL] warnings . warn ( [string] , DeprecationWarning , stacklevel = [number] , ) [EOL] [EOL] [EOL] sys . modules [ [string] ] = gluonts . mx . block [EOL] [EOL] for submodule in ( [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , ) : [EOL] sys . modules [ f" [string] { submodule }" ] = importlib . import_module ( f" [string] { submodule }" ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import importlib [EOL] import sys [EOL] import warnings [EOL] [EOL] import gluonts . mx . distribution [EOL] [EOL] warnings . warn ( [string] , DeprecationWarning , stacklevel = [number] , ) [EOL] [EOL] [EOL] sys . modules [ [string] ] = gluonts . mx . distribution [EOL] [EOL] [EOL] for submodule in ( [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , ) : [EOL] sys . modules [ f" [string] { submodule }" ] = importlib . import_module ( f" [string] { submodule }" ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [EOL] from typing import Iterable [EOL] import typing [EOL] from pkgutil import extend_path [EOL] [EOL] from pkg_resources import DistributionNotFound , get_distribution [EOL] [EOL] from gluonts . mx . prelude import * [EOL] [EOL] __path__ = extend_path ( __path__ , __name__ ) [comment] [EOL] [EOL] try : [EOL] __version__ = get_distribution ( __name__ ) . version [EOL] except DistributionNotFound : [EOL] __version__ = [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterable[builtins.str]$ 0 0 0 $typing.Iterable[builtins.str]$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import importlib [EOL] import sys [EOL] import warnings [EOL] [EOL] import gluonts . mx . kernels [EOL] [EOL] warnings . warn ( [string] , DeprecationWarning , stacklevel = [number] , ) [EOL] [EOL] [EOL] sys . modules [ [string] ] = gluonts . mx . kernels [EOL] [EOL] for submodule in ( [string] , [string] , [string] , [string] , ) : [EOL] sys . modules [ f" [string] { submodule }" ] = importlib . import_module ( f" [string] { submodule }" ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] [comment] [EOL] from typing import Callable , Any , Union , List , Iterator , Optional [EOL] import queue [EOL] import numpy [EOL] import multiprocessing [EOL] import mxnet [EOL] import gluonts [EOL] import typing [EOL] import builtins [EOL] import functools [EOL] import io [EOL] import itertools [EOL] import logging [EOL] import multiprocessing [EOL] import multiprocessing . queues [EOL] import pickle [EOL] import random [EOL] import sys [EOL] import time [EOL] from collections . abc import Sized [EOL] from multiprocessing . managers import SyncManager [EOL] from multiprocessing . pool import Pool [EOL] from multiprocessing . reduction import ForkingPickler [EOL] from queue import Queue [EOL] from typing import Any , Callable , Iterator , List , Optional , Union [EOL] [EOL] import mxnet as mx [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] from mxnet import context , nd [EOL] [EOL] [comment] [EOL] from gluonts . core . component import DType [EOL] from gluonts . dataset . common import DataBatch , DataEntry , Dataset , FileDataset [EOL] from gluonts . dataset . util import MPWorkerInfo [EOL] from gluonts . transform import Transformation [EOL] [EOL] try : [EOL] import multiprocessing . resource_sharer [EOL] except ImportError : [EOL] pass [EOL] [EOL] [EOL] [comment] [EOL] if sys . platform == [string] or sys . platform == [string] : [EOL] [EOL] def rebuild_ndarray ( * args ) : [EOL] [docstring] [EOL] [comment] [EOL] return nd . NDArray ( nd . ndarray . _new_from_shared_mem ( * args ) ) [EOL] [EOL] def reduce_ndarray ( data ) : [EOL] [docstring] [EOL] return rebuild_ndarray , data . _to_shared_mem ( ) [EOL] [EOL] [EOL] else : [EOL] [EOL] def rebuild_ndarray ( pid , fd , shape , dtype ) : [EOL] [docstring] [EOL] [comment] [EOL] fd = fd . detach ( ) [EOL] return nd . NDArray ( nd . ndarray . _new_from_shared_mem ( pid , fd , shape , dtype ) ) [EOL] [EOL] def reduce_ndarray ( data ) : [EOL] [docstring] [EOL] [comment] [EOL] data = data . as_in_context ( context . Context ( [string] , [number] ) ) [EOL] pid , fd , shape , dtype = data . _to_shared_mem ( ) [EOL] fd = multiprocessing . reduction . DupFd ( fd ) [EOL] return rebuild_ndarray , ( pid , fd , shape , dtype ) [EOL] [EOL] [EOL] ForkingPickler . register ( nd . NDArray , reduce_ndarray ) [EOL] [EOL] [EOL] def _is_stackable ( arrays , axis = [number] ) : [EOL] [docstring] [EOL] if isinstance ( arrays [ [number] ] , ( mx . nd . NDArray , np . ndarray ) ) : [EOL] s = set ( arr . shape [ axis ] for arr in arrays ) [EOL] return len ( s ) <= [number] and arrays [ [number] ] . shape [ axis ] != [number] [EOL] return True [EOL] [EOL] [EOL] def _pad_arrays ( data , axis = [number] ) : [EOL] assert isinstance ( data [ [number] ] , ( np . ndarray , mx . nd . NDArray ) ) [EOL] is_mx = isinstance ( data [ [number] ] , mx . nd . NDArray ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] max_len = max ( [number] , functools . reduce ( max , ( x . shape [ axis ] for x in data ) ) ) [EOL] padded_data = [ ] [EOL] [EOL] for x in data : [EOL] [comment] [EOL] [comment] [EOL] if is_mx : [EOL] x = x . asnumpy ( ) [EOL] [EOL] pad_size = max_len - x . shape [ axis ] [EOL] pad_lengths = [ ( [number] , [number] ) ] * x . ndim [EOL] pad_lengths [ axis ] = ( [number] , pad_size ) [EOL] x_padded = np . pad ( x , mode = [string] , pad_width = pad_lengths ) [EOL] [EOL] padded_data . append ( x_padded if not is_mx else mx . nd . array ( x_padded ) ) [EOL] [EOL] return padded_data [EOL] [EOL] [EOL] def stack ( data , multi_processing , dtype , single_process_ctx = None , variable_length = False , ) : [EOL] [docstring] [EOL] if variable_length and not _is_stackable ( data ) : [EOL] data = _pad_arrays ( data , axis = [number] ) [EOL] [EOL] if isinstance ( data [ [number] ] , mx . nd . NDArray ) : [EOL] if multi_processing : [EOL] out = nd . empty ( ( len ( data ) , ) + data [ [number] ] . shape , dtype = data [ [number] ] . dtype , ctx = context . Context ( [string] , [number] ) , ) [EOL] return mx . nd . stack ( * data , out = out ) [EOL] else : [EOL] return mx . nd . stack ( * data ) [EOL] elif isinstance ( data [ [number] ] , np . ndarray ) : [EOL] data = np . asarray ( data ) [EOL] if data . dtype . kind == [string] : [EOL] data = data . astype ( dtype ) [EOL] if multi_processing : [EOL] [comment] [EOL] if [number] in data . shape : [EOL] return data [EOL] return mx . nd . array ( data , dtype = data . dtype , ctx = context . Context ( [string] , [number] ) ) [EOL] else : [EOL] return mx . nd . array ( data , dtype = data . dtype , ctx = single_process_ctx ) [EOL] elif isinstance ( data [ [number] ] , list ) : [EOL] return list ( stack ( t , multi_processing , dtype , single_process_ctx ) for t in zip ( * data ) ) [EOL] elif isinstance ( data [ [number] ] , tuple ) : [EOL] return tuple ( stack ( t , multi_processing , dtype , single_process_ctx ) for t in zip ( * data ) ) [EOL] [EOL] return data [EOL] [EOL] [EOL] def batchify ( data , dtype , multi_processing , single_process_ctx = None , variable_length = False , ) : [EOL] [docstring] [EOL] return { key : stack ( data = [ item [ key ] for item in data ] , multi_processing = multi_processing , dtype = dtype , single_process_ctx = single_process_ctx , variable_length = variable_length , ) for key in data [ [number] ] . keys ( ) } [EOL] [EOL] [EOL] def _as_in_context ( batch , ctx ) : [EOL] [docstring] [EOL] assert ( not MPWorkerInfo . worker_process ) , [string] [EOL] batch = { k : v . as_in_context ( ctx ) if isinstance ( v , nd . NDArray ) [EOL] [comment] [EOL] else ( stack ( v , False , v . dtype , ctx ) [EOL] if isinstance ( v [ [number] ] , np . ndarray ) and [number] in v [ [number] ] . shape [EOL] else v ) for k , v in batch . items ( ) } [EOL] return batch [EOL] [EOL] [EOL] def _sequential_sample_generator ( dataset , transformation , is_train , cyclic , ) : [EOL] while True : [EOL] yield from transformation ( data_it = dataset , is_train = is_train ) [EOL] [comment] [EOL] if not cyclic : [EOL] return [EOL] [EOL] [EOL] [comment] [EOL] class _WorkerData : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] dataset = ... [EOL] [comment] [EOL] transformation = ... [EOL] [comment] [EOL] dataset_iterator = ... [EOL] [comment] [EOL] iterator_latest_reset_cycle = [number] [EOL] [comment] [EOL] iterator_exhausted_indicator = False [EOL] [EOL] [EOL] [comment] [EOL] def _worker_reset_iterator ( is_train , cyclic , cycle_num , shuffle_buffer_length , ) : [EOL] [docstring] [EOL] [EOL] generator = _sequential_sample_generator ( dataset = _WorkerData . dataset , transformation = _WorkerData . transformation , is_train = is_train , cyclic = cyclic , ) [EOL] if shuffle_buffer_length is not None : [EOL] generator = ShuffleIter ( base_iterator = generator , shuffle_buffer_length = shuffle_buffer_length , ) [EOL] _WorkerData . dataset_iterator = generator [EOL] [EOL] _WorkerData . iterator_latest_reset_cycle = cycle_num [EOL] _WorkerData . iterator_exhausted_indicator = False [EOL] [EOL] [EOL] def _worker_initializer ( dataset , transformation , num_workers , worker_id_queue , ) : [EOL] [docstring] [EOL] [EOL] _WorkerData . dataset = dataset [EOL] _WorkerData . transformation = transformation [EOL] [EOL] [comment] [EOL] worker_id = int ( worker_id_queue . get ( ) ) [EOL] multiprocessing . current_process ( ) . name = f" [string] { worker_id }" [EOL] [EOL] [comment] [EOL] MPWorkerInfo . set_worker_info ( num_workers = num_workers , worker_id = worker_id , worker_process = True ) [EOL] [EOL] [EOL] def _worker_fn ( batch_size , batchify_fn , dtype , is_train , cyclic , cycle_num , shuffle_buffer_length , ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] if ( _WorkerData . iterator_latest_reset_cycle < cycle_num ) and ( _WorkerData . iterator_latest_reset_cycle == [number] or not cyclic ) : [EOL] _worker_reset_iterator ( is_train , cyclic , cycle_num , shuffle_buffer_length ) [EOL] [EOL] [comment] [EOL] batch_samples = list ( itertools . islice ( _WorkerData . dataset_iterator , batch_size ) ) [EOL] [comment] [EOL] if batch_samples : [EOL] success = True [EOL] batch = batchify_fn ( data = batch_samples , dtype = dtype , multi_processing = True ) [EOL] else : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] if _WorkerData . iterator_exhausted_indicator : [EOL] time . sleep ( [number] ) [EOL] else : [EOL] _WorkerData . iterator_exhausted_indicator = True [EOL] success = False [EOL] batch = None [EOL] [EOL] buf = io . BytesIO ( ) [EOL] ForkingPickler ( buf , pickle . HIGHEST_PROTOCOL ) . dump ( ( success , MPWorkerInfo . worker_id , batch ) ) [EOL] return buf . getvalue ( ) [EOL] [EOL] [EOL] class ShuffleIter ( Iterator [ DataEntry ] ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , base_iterator , shuffle_buffer_length ) : [EOL] self . shuffle_buffer = [ ] [EOL] self . shuffle_buffer_length = shuffle_buffer_length [EOL] self . base_iterator = base_iterator [EOL] self . base_iter_finished = False [EOL] [EOL] def __next__ ( self ) : [EOL] [comment] [EOL] [comment] [EOL] if not self . shuffle_buffer : [EOL] self . shuffle_buffer = list ( itertools . islice ( self . base_iterator , self . shuffle_buffer_length ) ) [EOL] [comment] [EOL] [comment] [EOL] if not self . shuffle_buffer : [EOL] raise StopIteration [EOL] [comment] [EOL] [comment] [EOL] idx = random . randint ( [number] , len ( self . shuffle_buffer ) - [number] ) [EOL] next_sample = self . shuffle_buffer [ idx ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] try : [EOL] self . shuffle_buffer [ idx ] = next ( self . base_iterator ) [EOL] except StopIteration : [EOL] del self . shuffle_buffer [ idx ] [EOL] [EOL] return next_sample [EOL] [EOL] [EOL] class _MultiWorkerIter ( object ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , worker_pool , batchify_fn , dtype , ctx , is_train , num_workers , batch_size , cyclic , cycle_num , num_prefetch , worker_fn , dataset_len , timeout , shuffle_buffer_length , ) : [EOL] self . _worker_pool = worker_pool [EOL] self . _batchify_fn = batchify_fn [EOL] self . _data_buffer = ( { } ) [comment] [EOL] self . _rcvd_idx = [number] [EOL] self . _sent_idx = [number] [EOL] self . _worker_fn = worker_fn [EOL] self . _timeout = timeout [EOL] [EOL] self . _is_train = is_train [EOL] self . _dtype = dtype [EOL] self . _ctx = ctx [EOL] self . _cyclic = cyclic [EOL] self . _cycle_num = cycle_num [EOL] [comment] [EOL] self . _exhausted_iterators = set ( ) [EOL] self . _num_workers = num_workers [EOL] self . _batch_size = batch_size [EOL] self . _dataset_len = dataset_len [EOL] [comment] [EOL] self . shuffle_buffer_length = shuffle_buffer_length [EOL] [comment] [EOL] self . _num_prefetch = num_prefetch [EOL] for i in range ( self . _num_prefetch ) : [EOL] self . _push_next ( ) [EOL] [EOL] def __len__ ( self ) : [EOL] return self . _dataset_len [EOL] [EOL] def _push_next ( self ) : [EOL] [docstring] [EOL] [comment] [EOL] [comment] [EOL] async_ret = self . _worker_pool . apply_async ( self . _worker_fn , ( self . _batch_size , self . _batchify_fn , self . _dtype , self . _is_train , self . _cyclic , self . _cycle_num , self . shuffle_buffer_length , ) , ) [EOL] self . _data_buffer [ self . _sent_idx ] = async_ret [EOL] self . _sent_idx += [number] [EOL] [EOL] def __next__ ( self ) : [EOL] [comment] [EOL] [comment] [EOL] logger = logging . getLogger ( __name__ ) [EOL] success = False [EOL] while not success : [EOL] try : [EOL] self . _push_next ( ) [EOL] [EOL] if self . _rcvd_idx == self . _sent_idx : [EOL] assert ( not self . _data_buffer ) , [string] [EOL] raise StopIteration [EOL] assert ( self . _rcvd_idx < self . _sent_idx ) , [string] [EOL] assert ( self . _rcvd_idx in self . _data_buffer ) , [string] [EOL] [EOL] ret = self . _data_buffer . pop ( self . _rcvd_idx ) [EOL] got = ret . get ( self . _timeout ) [EOL] self . _rcvd_idx += [number] [EOL] [EOL] [comment] [EOL] success , worker_id , batch = pickle . loads ( got ) [EOL] [EOL] [comment] [EOL] if not success : [EOL] self . _exhausted_iterators . add ( worker_id ) [EOL] if self . _num_workers == len ( self . _exhausted_iterators ) : [EOL] [comment] [EOL] return { } [EOL] else : [EOL] self . _push_next ( ) [EOL] else : [EOL] [comment] [EOL] [comment] [EOL] return _as_in_context ( batch , self . _ctx ) [EOL] except multiprocessing . context . TimeoutError : [EOL] logger . error ( f" [string] { self . _timeout } [string] " [string] [string] [string] ) [EOL] raise [EOL] except Exception as e : [EOL] logger . error ( f" [string] { e } [string] " ) [EOL] self . _worker_pool . terminate ( ) [EOL] raise [EOL] return { } [EOL] [EOL] def __iter__ ( self ) : [EOL] while True : [EOL] next_batch = next ( self ) [EOL] if not next_batch : [EOL] return [EOL] yield next_batch [EOL] [EOL] [EOL] class ParallelDataLoader ( object ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , dataset , transformation , cyclic , is_train , batch_size , ctx , dtype = np . float32 , batchify_fn = batchify , num_prefetch = None , num_workers = None , shuffle_buffer_length = None , ) : [EOL] self . logger = logging . getLogger ( __name__ ) [EOL] [comment] [EOL] if sys . platform == [string] : [EOL] self . logger . warning ( [string] [string] [string] ) [EOL] num_workers = [number] [EOL] [comment] [EOL] if num_workers is not None and num_workers > [number] : [EOL] if isinstance ( dataset , FileDataset ) : [EOL] if not dataset . cache : [EOL] self . logger . warning ( [string] [string] [string] ) [EOL] assert ( batch_size > [number] ) , [string] [EOL] assert ( num_workers is None or [number] <= num_workers ) , [string] [EOL] assert ( num_prefetch is None or num_prefetch >= [number] ) , [string] [EOL] assert ( shuffle_buffer_length is None or shuffle_buffer_length >= batch_size ) , [string] [EOL] [EOL] self . dataset = dataset [EOL] self . dataset_len = ... [EOL] if isinstance ( dataset , Sized ) : [EOL] if isinstance ( dataset , FileDataset ) : [EOL] [comment] [EOL] self . dataset_len = min ( filter ( lambda x : x > [number] , dataset . len_per_file ( ) ) ) [EOL] else : [EOL] self . dataset_len = len ( dataset ) [EOL] else : [EOL] self . dataset_len = len ( list ( dataset ) ) [EOL] self . transformation = transformation [EOL] [comment] [EOL] self . cyclic = cyclic [EOL] [comment] [EOL] self . cycle_num = [number] [EOL] self . is_train = is_train [EOL] self . batch_size = batch_size [EOL] self . ctx = ctx [EOL] self . batchify_fn = batchify_fn [EOL] [EOL] self . dtype = dtype [EOL] [EOL] [comment] [EOL] default_num_workers = [number] [EOL] self . num_workers = min ( num_workers if num_workers is not None else default_num_workers , self . dataset_len , ) [comment] [EOL] self . logger . info ( f" [string] { self . num_workers }" ) [EOL] if self . num_workers > multiprocessing . cpu_count ( ) : [EOL] self . logger . warning ( f" [string] { self . num_workers } [string] { multiprocessing . cpu_count ( ) } [string] " f" [string] " ) [EOL] self . num_prefetch = ( num_prefetch if num_prefetch is not None else [number] * self . num_workers ) [EOL] self . logger . info ( f" [string] { self . num_prefetch }" ) [EOL] if self . num_prefetch < self . num_workers : [EOL] self . logger . warning ( [string] [string] ) [EOL] self . worker_pool = None [EOL] self . worker_manager = None [EOL] [comment] [EOL] self . worker_id_queue = None [EOL] [comment] [EOL] self . multi_worker_cache = None [EOL] self . shuffle_buffer_length = shuffle_buffer_length [EOL] self . logger . info ( f" [string] { self . shuffle_buffer_length }" ) [EOL] [EOL] if self . num_workers > [number] : [EOL] [comment] [EOL] self . worker_manager = multiprocessing . Manager ( ) [EOL] self . worker_id_queue = self . worker_manager . Queue ( ) [EOL] for i in range ( self . num_workers ) : [EOL] self . worker_id_queue . put ( i ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] self . worker_pool = multiprocessing . Pool ( self . num_workers , initializer = _worker_initializer , initargs = [ self . dataset , self . transformation , self . num_workers , self . worker_id_queue , ] , ) [EOL] [EOL] def __iter__ ( self ) : [EOL] self . cycle_num += [number] [EOL] if self . num_workers == [number] : [EOL] generator = _sequential_sample_generator ( self . dataset , self . transformation , self . is_train , self . cyclic ) [EOL] if self . shuffle_buffer_length is not None : [EOL] generator = ShuffleIter ( base_iterator = generator , shuffle_buffer_length = self . shuffle_buffer_length , ) [EOL] [EOL] def same_process_iter ( ) : [EOL] while True : [EOL] [comment] [EOL] batch_samples = list ( itertools . islice ( generator , self . batch_size ) ) [EOL] [comment] [EOL] if len ( batch_samples ) == [number] : [EOL] return [EOL] [EOL] [comment] [EOL] batch = self . batchify_fn ( data = batch_samples , multi_processing = False , dtype = self . dtype , single_process_ctx = self . ctx , ) [EOL] yield batch [EOL] [EOL] return same_process_iter ( ) [EOL] else : [EOL] [comment] [EOL] assert isinstance ( self . worker_pool , Pool ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] if self . multi_worker_cache is None : [EOL] multi_worker = _MultiWorkerIter ( worker_pool = self . worker_pool , num_workers = self . num_workers , batch_size = self . batch_size , batchify_fn = self . batchify_fn , dtype = self . dtype , ctx = self . ctx , is_train = self . is_train , cyclic = self . cyclic , worker_fn = _worker_fn , num_prefetch = self . num_prefetch , dataset_len = self . dataset_len , cycle_num = self . cycle_num , timeout = [number] , shuffle_buffer_length = self . shuffle_buffer_length , ) [EOL] if self . cyclic : [EOL] self . multi_worker_cache = iter ( multi_worker ) [EOL] return iter ( multi_worker ) [EOL] else : [EOL] [comment] [EOL] [comment] [EOL] return self . multi_worker_cache [EOL] [EOL] def __len__ ( self ) : [EOL] return self . dataset_len [EOL] [EOL] def __del__ ( self ) : [EOL] if self . worker_pool : [EOL] [comment] [EOL] assert isinstance ( self . worker_pool , multiprocessing . pool . Pool ) [EOL] self . worker_pool . close ( ) [EOL] self . worker_pool . join ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.Dataset$ 0 0 0 0 0 $gluonts.transform.Transformation$ 0 0 0 0 0 $typing.Iterator[gluonts.dataset.common.DataEntry]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.Iterator[gluonts.dataset.common.DataBatch]]$ 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterator[gluonts.dataset.common.DataBatch]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Any , Optional [EOL] import typing [EOL] import builtins [EOL] import math [EOL] from collections import defaultdict [EOL] from typing import Any , List , NamedTuple , Optional , Set [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . core . exception import assert_data_error [EOL] from gluonts . dataset . field_names import FieldName [EOL] from gluonts . gluonts_tqdm import tqdm [EOL] [EOL] [EOL] class ScaleHistogram : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , base = [number] , bin_counts = None , empty_target_count = [number] , ) : [EOL] self . _base = base [EOL] self . bin_counts = defaultdict ( int , { } if bin_counts is None else bin_counts ) [EOL] self . empty_target_count = empty_target_count [EOL] self . __init_args__ = dict ( base = self . _base , bin_counts = self . bin_counts , empty_target_count = empty_target_count , ) [EOL] [EOL] def bucket_index ( self , target_values ) : [EOL] assert len ( target_values ) > [number] [EOL] scale = np . mean ( np . abs ( target_values ) ) [EOL] scale_bin = int ( math . log ( scale + [number] , self . _base ) ) [EOL] return scale_bin [EOL] [EOL] def add ( self , target_values ) : [EOL] if len ( target_values ) > [number] : [EOL] bucket = self . bucket_index ( target_values ) [EOL] self . bin_counts [ bucket ] = self . bin_counts [ bucket ] + [number] [EOL] else : [EOL] self . empty_target_count = self . empty_target_count + [number] [EOL] [EOL] def count ( self , target ) : [EOL] if len ( target ) > [number] : [EOL] return self . bin_counts [ self . bucket_index ( target ) ] [EOL] else : [EOL] return self . empty_target_count [EOL] [EOL] def __len__ ( self ) : [EOL] return self . empty_target_count + sum ( self . bin_counts . values ( ) ) [EOL] [EOL] def __eq__ ( self , other ) : [EOL] return ( isinstance ( other , ScaleHistogram ) [EOL] and self . bin_counts == other . bin_counts [EOL] and self . empty_target_count == other . empty_target_count [EOL] and self . _base == other . _base ) [EOL] [EOL] def __str__ ( self ) : [EOL] string_repr = [ [string] . format ( min = self . _base ** base_index - [number] , max = self . _base ** ( base_index + [number] ) - [number] , count = count , ) for base_index , count in sorted ( self . bin_counts . items ( ) , key = lambda x : x [ [number] ] ) ] [EOL] return [string] . join ( string_repr ) [EOL] [EOL] [EOL] class DatasetStatistics ( NamedTuple ) : [EOL] [docstring] [EOL] [EOL] integer_dataset = ... [EOL] max_target = ... [EOL] mean_abs_target = ... [EOL] mean_target = ... [EOL] mean_target_length = ... [EOL] min_target = ... [EOL] feat_static_real = ... [EOL] feat_static_cat = ... [EOL] num_past_feat_dynamic_real = ... [EOL] num_feat_dynamic_real = ... [EOL] num_feat_dynamic_cat = ... [EOL] num_missing_values = ... [EOL] num_time_observations = ... [EOL] num_time_series = ... [EOL] scale_histogram = ... [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] def __eq__ ( self , other ) : [EOL] for x , y in zip ( self . _asdict ( ) . values ( ) , other . _asdict ( ) . values ( ) ) : [EOL] if isinstance ( x , float ) : [EOL] if abs ( x - y ) > abs ( [number] * x ) : [EOL] return False [EOL] elif x != y : [EOL] return False [EOL] return True [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] def calculate_dataset_statistics ( ts_dataset ) : [EOL] [docstring] [EOL] num_time_observations = [number] [EOL] num_time_series = [number] [EOL] min_target = [number] [EOL] max_target = - [number] [EOL] sum_target = [number] [EOL] sum_abs_target = [number] [EOL] integer_dataset = True [EOL] observed_feat_static_cat = None [EOL] observed_feat_static_real = None [EOL] num_feat_static_real = None [EOL] num_feat_static_cat = None [EOL] num_past_feat_dynamic_real = None [EOL] num_feat_dynamic_real = None [EOL] num_feat_dynamic_cat = None [EOL] num_missing_values = [number] [EOL] [EOL] scale_histogram = ScaleHistogram ( ) [EOL] [EOL] with tqdm ( enumerate ( ts_dataset , start = [number] ) , total = len ( ts_dataset ) ) as it : [EOL] for num_time_series , ts in it : [EOL] [EOL] [comment] [EOL] target = ts [ FieldName . TARGET ] [EOL] observed_target = target [ ~ np . isnan ( target ) ] [EOL] num_observations = len ( observed_target ) [EOL] [EOL] if num_observations > [number] : [EOL] [comment] [EOL] assert_data_error ( np . all ( np . isfinite ( observed_target ) ) , [string] [string] [string] , ) [EOL] [EOL] num_time_observations += num_observations [EOL] min_target = float ( min ( min_target , observed_target . min ( ) ) ) [EOL] max_target = float ( max ( max_target , observed_target . max ( ) ) ) [EOL] num_missing_values += int ( np . isnan ( target ) . sum ( ) ) [EOL] sum_target += float ( observed_target . sum ( ) ) [EOL] sum_abs_target += float ( np . abs ( observed_target ) . sum ( ) ) [EOL] integer_dataset = integer_dataset and bool ( np . all ( np . mod ( observed_target , [number] ) == [number] ) ) [EOL] [EOL] scale_histogram . add ( observed_target ) [comment] [EOL] [EOL] [comment] [EOL] feat_static_cat = ( ts [ FieldName . FEAT_STATIC_CAT ] [EOL] if FieldName . FEAT_STATIC_CAT in ts [EOL] else [ ] ) [EOL] [EOL] if num_feat_static_cat is None : [EOL] num_feat_static_cat = len ( feat_static_cat ) [EOL] observed_feat_static_cat = [ set ( ) for _ in range ( num_feat_static_cat ) ] [EOL] [EOL] [comment] [EOL] assert num_feat_static_cat is not None [EOL] assert observed_feat_static_cat is not None [EOL] [EOL] assert_data_error ( num_feat_static_cat == len ( feat_static_cat ) , [string] , num_feat_static_cat , len ( feat_static_cat ) , ) [EOL] for i , c in enumerate ( feat_static_cat ) : [EOL] observed_feat_static_cat [ i ] . add ( c ) [EOL] [EOL] [comment] [EOL] feat_static_real = ( ts [ FieldName . FEAT_STATIC_REAL ] [EOL] if FieldName . FEAT_STATIC_REAL in ts [EOL] else [ ] ) [EOL] [EOL] if num_feat_static_real is None : [EOL] num_feat_static_real = len ( feat_static_real ) [EOL] observed_feat_static_real = [ set ( ) for _ in range ( num_feat_static_real ) ] [EOL] [EOL] [comment] [EOL] assert num_feat_static_real is not None [EOL] assert observed_feat_static_real is not None [EOL] [EOL] assert_data_error ( num_feat_static_real == len ( feat_static_real ) , [string] , num_feat_static_real , len ( feat_static_real ) , ) [EOL] for i , c in enumerate ( feat_static_real ) : [EOL] observed_feat_static_real [ i ] . add ( c ) [EOL] [EOL] [comment] [EOL] feat_dynamic_cat = ( ts [ FieldName . FEAT_DYNAMIC_CAT ] [EOL] if FieldName . FEAT_DYNAMIC_CAT in ts [EOL] else None ) [EOL] [EOL] if feat_dynamic_cat is None : [EOL] [comment] [EOL] [comment] [EOL] assert_data_error ( num_feat_dynamic_cat is None or num_feat_dynamic_cat == [number] , [string] , ) [EOL] num_feat_dynamic_cat = [number] [EOL] else : [EOL] if num_feat_dynamic_cat is None : [EOL] [comment] [EOL] num_feat_dynamic_cat = len ( feat_dynamic_cat ) [EOL] else : [EOL] assert_data_error ( num_feat_dynamic_cat == len ( feat_dynamic_cat ) , [string] [string] , num_feat_dynamic_cat , len ( feat_dynamic_cat ) , ) [EOL] [EOL] assert_data_error ( np . all ( np . isfinite ( feat_dynamic_cat ) ) , [string] [string] , ) [EOL] num_feat_dynamic_cat_time_steps = len ( feat_dynamic_cat [ [number] ] ) [EOL] assert_data_error ( num_feat_dynamic_cat_time_steps == len ( target ) , [string] [string] [string] , num_feat_dynamic_cat_time_steps , len ( target ) , ) [EOL] [EOL] [comment] [EOL] feat_dynamic_real = None [EOL] if FieldName . FEAT_DYNAMIC_REAL in ts : [EOL] feat_dynamic_real = ts [ FieldName . FEAT_DYNAMIC_REAL ] [EOL] elif FieldName . FEAT_DYNAMIC_REAL_LEGACY in ts : [EOL] feat_dynamic_real = ts [ FieldName . FEAT_DYNAMIC_REAL_LEGACY ] [EOL] [EOL] if feat_dynamic_real is None : [EOL] [comment] [EOL] [comment] [EOL] assert_data_error ( num_feat_dynamic_real is None or num_feat_dynamic_real == [number] , [string] , ) [EOL] num_feat_dynamic_real = [number] [EOL] else : [EOL] if num_feat_dynamic_real is None : [EOL] [comment] [EOL] num_feat_dynamic_real = len ( feat_dynamic_real ) [EOL] else : [EOL] assert_data_error ( num_feat_dynamic_real == len ( feat_dynamic_real ) , [string] [string] , num_feat_dynamic_real , len ( feat_dynamic_real ) , ) [EOL] [EOL] assert_data_error ( np . all ( np . isfinite ( feat_dynamic_real ) ) , [string] [string] , ) [EOL] num_feat_dynamic_real_time_steps = len ( feat_dynamic_real [ [number] ] ) [EOL] assert_data_error ( num_feat_dynamic_real_time_steps == len ( target ) , [string] [string] [string] , num_feat_dynamic_real_time_steps , len ( target ) , ) [EOL] [EOL] [comment] [EOL] past_feat_dynamic_real = None [EOL] if FieldName . PAST_FEAT_DYNAMIC_REAL in ts : [EOL] past_feat_dynamic_real = ts [ FieldName . PAST_FEAT_DYNAMIC_REAL ] [EOL] [EOL] if past_feat_dynamic_real is None : [EOL] [comment] [EOL] [comment] [EOL] assert_data_error ( num_past_feat_dynamic_real is None or num_past_feat_dynamic_real == [number] , [string] , ) [EOL] num_past_feat_dynamic_real = [number] [EOL] else : [EOL] if num_past_feat_dynamic_real is None : [EOL] [comment] [EOL] num_past_feat_dynamic_real = len ( past_feat_dynamic_real ) [EOL] else : [EOL] assert_data_error ( num_past_feat_dynamic_real == len ( past_feat_dynamic_real ) , [string] [string] , num_past_feat_dynamic_real , len ( past_feat_dynamic_real ) , ) [EOL] [EOL] assert_data_error ( np . all ( np . isfinite ( past_feat_dynamic_real ) ) , [string] [string] , ) [EOL] [EOL] assert_data_error ( num_time_series > [number] , [string] ) [EOL] assert_data_error ( num_time_observations > [number] , [string] , ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] mean_target_length = num_time_observations / num_time_series [EOL] [EOL] [comment] [EOL] [comment] [EOL] mean_target = sum_target / num_time_observations [EOL] mean_abs_target = sum_abs_target / num_time_observations [EOL] [EOL] integer_dataset = integer_dataset and min_target >= [number] [EOL] [EOL] assert len ( scale_histogram ) == num_time_series [EOL] [EOL] return DatasetStatistics ( integer_dataset = integer_dataset , max_target = max_target , mean_abs_target = mean_abs_target , mean_target = mean_target , mean_target_length = mean_target_length , min_target = min_target , num_missing_values = num_missing_values , feat_static_real = observed_feat_static_real [EOL] if observed_feat_static_real [EOL] else [ ] , feat_static_cat = observed_feat_static_cat [EOL] if observed_feat_static_cat [EOL] else [ ] , num_past_feat_dynamic_real = num_past_feat_dynamic_real , num_feat_dynamic_real = num_feat_dynamic_real , num_feat_dynamic_cat = num_feat_dynamic_cat , num_time_observations = num_time_observations , num_time_series = num_time_series , scale_histogram = scale_histogram , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 $typing.List[typing.Set[builtins.float]]$ 0 0 0 $typing.List[typing.Set[builtins.int]]$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $ScaleHistogram$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import builtins [EOL] import pathlib [EOL] import gzip [EOL] import functools [EOL] from pathlib import Path [EOL] from typing import NamedTuple [EOL] [EOL] [comment] [EOL] import ujson as json [EOL] [EOL] [comment] [EOL] from gluonts . core . exception import GluonTSDataError [EOL] from gluonts . dataset . util import get_bounds_for_mp_data_loading [EOL] [EOL] [EOL] def load ( file_obj ) : [EOL] for line in file_obj : [EOL] yield json . loads ( line ) [EOL] [EOL] [EOL] def dump ( objects , file_obj ) : [EOL] for object_ in objects : [EOL] file_obj . writeline ( json . dumps ( object_ ) ) [EOL] [EOL] [EOL] class Span ( NamedTuple ) : [EOL] path = ... [EOL] line = ... [EOL] [EOL] [EOL] class Line ( NamedTuple ) : [EOL] content = ... [EOL] span = ... [EOL] [EOL] [EOL] class JsonLinesFile : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , path , cache = False ) : [EOL] self . path = path [EOL] self . open = gzip . open if path . suffix == [string] else open [EOL] self . cache = cache [EOL] self . _len = None [EOL] self . _data_cache = [ ] [EOL] [EOL] def __iter__ ( self ) : [EOL] [comment] [EOL] [comment] [EOL] bounds = get_bounds_for_mp_data_loading ( len ( self ) ) [EOL] if not self . cache or ( self . cache and not self . _data_cache ) : [EOL] with self . open ( self . path ) as jsonl_file : [EOL] for line_number , raw in enumerate ( jsonl_file ) : [EOL] if not bounds . lower <= line_number < bounds . upper : [EOL] continue [EOL] [EOL] span = Span ( path = self . path , line = line_number ) [EOL] try : [EOL] parsed_line = Line ( json . loads ( raw ) , span = span ) [EOL] if self . cache : [EOL] self . _data_cache . append ( parsed_line ) [EOL] yield parsed_line [EOL] except ValueError : [EOL] raise GluonTSDataError ( f" [string] { line_number } [string] { raw }" ) [EOL] else : [EOL] yield from self . _data_cache [EOL] [EOL] def __len__ ( self ) : [EOL] if self . _len is None : [EOL] [comment] [EOL] BUF_SIZE = [number] ** [number] [EOL] [EOL] with self . open ( self . path , [string] ) as file_obj : [EOL] read_chunk = functools . partial ( file_obj . read , BUF_SIZE ) [EOL] file_len = sum ( chunk . count ( [string] ) for chunk in iter ( read_chunk , [string] ) ) [EOL] self . _len = file_len [EOL] return self . _len [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pathlib.Path$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.object$ 0 0 0 $Span$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.list$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Iterator , Optional [EOL] import gluonts [EOL] import builtins [EOL] import mxnet [EOL] import typing [EOL] import logging [EOL] from typing import Iterable , Iterator , Optional [EOL] [EOL] [comment] [EOL] import mxnet as mx [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from gluonts . core . component import DType [EOL] from gluonts . dataset . common import DataBatch , DataEntry , Dataset [EOL] from gluonts . dataset . parallelized_loader import ParallelDataLoader [EOL] from gluonts . transform import Transformation [EOL] [EOL] [EOL] class DataLoader ( Iterable [ DataEntry ] ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , dataset , * , transform , cyclic , is_train , batch_size , ctx , dtype = np . float32 , num_workers = None , num_prefetch = None , shuffle_buffer_length = None , ** kwargs , ) : [EOL] self . batch_size = batch_size [EOL] self . ctx = ctx [EOL] self . dtype = dtype [EOL] self . is_train = is_train [EOL] self . transform = transform [EOL] self . cyclic = cyclic [EOL] self . logger = logging . getLogger ( __name__ ) [EOL] self . num_workers = num_workers [EOL] self . num_prefetch = num_prefetch [EOL] self . shuffle_buffer_length = shuffle_buffer_length [EOL] [EOL] self . parallel_data_loader = ParallelDataLoader ( dataset = dataset , transformation = self . transform , cyclic = self . cyclic , is_train = self . is_train , batch_size = self . batch_size , ctx = self . ctx , dtype = self . dtype , num_workers = self . num_workers , num_prefetch = self . num_prefetch , shuffle_buffer_length = self . shuffle_buffer_length , ** kwargs , ) [EOL] [EOL] def __iter__ ( self ) : [EOL] [comment] [EOL] yield from self . parallel_data_loader [EOL] [EOL] [EOL] class TrainDataLoader ( DataLoader ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , dataset , transform , batch_size , ctx , num_batches_per_epoch , num_workers = None , num_prefetch = None , shuffle_buffer_length = None , dtype = np . float32 , ** kwargs , ) : [EOL] assert dataset , [string] [EOL] [EOL] super ( ) . __init__ ( dataset = dataset , transform = transform , batch_size = batch_size , ctx = ctx , dtype = dtype , is_train = True , cyclic = True , num_workers = num_workers , num_prefetch = num_prefetch , shuffle_buffer_length = shuffle_buffer_length , ** kwargs , ) [EOL] [EOL] self . num_batches_per_epoch = num_batches_per_epoch [EOL] self . _it = iter ( self . parallel_data_loader ) [EOL] [EOL] def __len__ ( self ) : [EOL] return self . num_batches_per_epoch [EOL] [EOL] def __iter__ ( self ) : [EOL] i = [number] [EOL] while True : [EOL] for batch in self . _it : [EOL] yield batch [EOL] i += [number] [EOL] if i == self . num_batches_per_epoch : [EOL] return [EOL] self . _it = iter ( self . parallel_data_loader ) [EOL] [EOL] [EOL] class ValidationDataLoader ( DataLoader ) : [EOL] def __init__ ( self , dataset , * , transform , batch_size , ctx , num_workers = None , num_prefetch = None , dtype = np . float32 , ** kwargs , ) : [EOL] super ( ) . __init__ ( dataset = dataset , transform = transform , is_train = True , batch_size = batch_size , ctx = ctx , dtype = dtype , cyclic = False , num_workers = num_workers , num_prefetch = num_prefetch , shuffle_buffer_length = None , ** kwargs , ) [EOL] [EOL] [EOL] class InferenceDataLoader ( DataLoader ) : [EOL] def __init__ ( self , dataset , * , transform , batch_size , ctx , num_workers = None , num_prefetch = None , dtype = np . float32 , ** kwargs , ) : [EOL] super ( ) . __init__ ( dataset = dataset , transform = transform , is_train = False , batch_size = batch_size , ctx = ctx , dtype = dtype , cyclic = False , num_workers = num_workers , num_prefetch = num_prefetch , shuffle_buffer_length = None , ** kwargs , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] class FieldName : [EOL] [docstring] [EOL] [EOL] ITEM_ID = [string] [EOL] [EOL] START = [string] [EOL] TARGET = [string] [EOL] [EOL] FEAT_STATIC_CAT = [string] [EOL] FEAT_STATIC_REAL = [string] [EOL] FEAT_DYNAMIC_CAT = [string] [EOL] FEAT_DYNAMIC_REAL = [string] [EOL] PAST_FEAT_DYNAMIC_REAL = [string] [EOL] FEAT_DYNAMIC_REAL_LEGACY = [string] [EOL] [EOL] FEAT_DYNAMIC = [string] [EOL] PAST_FEAT_DYNAMIC = [string] [EOL] [EOL] FEAT_DYNAMIC = [string] [EOL] [EOL] FEAT_TIME = [string] [EOL] FEAT_CONST = [string] [EOL] FEAT_AGE = [string] [EOL] [EOL] OBSERVED_VALUES = [string] [EOL] IS_PAD = [string] [EOL] FORECAST_START = [string] [EOL] [EOL] TARGET_DIM_INDICATOR = [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Iterable , List , Iterator , Optional [EOL] import pandas [EOL] import typing [EOL] import builtins [EOL] import pathlib [EOL] from enum import Enum [EOL] from functools import lru_cache [EOL] from pathlib import Path [EOL] from typing import ( Any , Callable , Dict , Iterable , Iterator , List , NamedTuple , Optional , Union , cast , ) [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] import pandas as pd [EOL] import pydantic [EOL] from pandas . tseries . offsets import Tick [EOL] [EOL] [comment] [EOL] from gluonts . core . exception import GluonTSDataError [EOL] from gluonts . dataset import jsonl , util [EOL] [EOL] [comment] [EOL] DataEntry = Dict [ str , Any ] [EOL] DataBatch = Dict [ str , Any ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] Dataset = Iterable [ DataEntry ] [EOL] [EOL] [EOL] class Timestamp ( pd . Timestamp ) : [EOL] [comment] [EOL] [comment] [EOL] @ classmethod def __get_validators__ ( cls ) : [EOL] def conv ( val ) : [EOL] if isinstance ( val , pd . Timestamp ) : [EOL] return val [EOL] else : [EOL] return pd . Timestamp ( val ) [EOL] [EOL] yield conv [EOL] [EOL] [EOL] class BasicFeatureInfo ( pydantic . BaseModel ) : [EOL] name = ... [EOL] [EOL] [EOL] class CategoricalFeatureInfo ( pydantic . BaseModel ) : [EOL] name = ... [EOL] cardinality = ... [EOL] [EOL] [EOL] class MetaData ( pydantic . BaseModel ) : [EOL] freq = pydantic . Field ( ... , alias = [string] ) [comment] [EOL] target = None [EOL] [EOL] feat_static_cat = [ ] [EOL] feat_static_real = [ ] [EOL] feat_dynamic_real = [ ] [EOL] feat_dynamic_cat = [ ] [EOL] [EOL] prediction_length = None [EOL] [EOL] class Config ( pydantic . BaseConfig ) : [EOL] allow_population_by_field_name = True [EOL] [EOL] [EOL] class SourceContext ( NamedTuple ) : [EOL] source = ... [EOL] row = ... [EOL] [EOL] [EOL] class TrainDatasets ( NamedTuple ) : [EOL] [docstring] [EOL] [EOL] metadata = ... [EOL] train = ... [EOL] test = None [EOL] [EOL] def save ( self , path_str , overwrite = True ) : [EOL] [docstring] [EOL] import shutil [EOL] import ujson as json [EOL] [EOL] path = Path ( path_str ) [EOL] [EOL] if overwrite : [EOL] shutil . rmtree ( path , ignore_errors = True ) [EOL] [EOL] def dump_line ( f , line ) : [EOL] f . write ( json . dumps ( line ) . encode ( [string] ) ) [EOL] f . write ( [string] . encode ( [string] ) ) [EOL] [EOL] ( path / [string] ) . mkdir ( parents = True ) [EOL] with open ( path / [string] , [string] ) as f : [EOL] dump_line ( f , self . metadata . dict ( ) ) [EOL] [EOL] ( path / [string] ) . mkdir ( parents = True ) [EOL] with open ( path / [string] , [string] ) as f : [EOL] for entry in self . train : [EOL] dump_line ( f , serialize_data_entry ( entry ) ) [EOL] [EOL] if self . test is not None : [EOL] ( path / [string] ) . mkdir ( parents = True ) [EOL] with open ( path / [string] , [string] ) as f : [EOL] for entry in self . test : [EOL] dump_line ( f , serialize_data_entry ( entry ) ) [EOL] [EOL] [EOL] class FileDataset ( Dataset ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , path , freq , one_dim_target = True , cache = False , ) : [EOL] self . cache = cache [EOL] self . path = path [EOL] self . process = ProcessDataEntry ( freq , one_dim_target = one_dim_target ) [EOL] self . _len_per_file = None [EOL] [EOL] if not self . files ( ) : [EOL] raise OSError ( f" [string] { path }" ) [EOL] [EOL] [comment] [EOL] self . _json_line_files = [ jsonl . JsonLinesFile ( path = path , cache = cache ) for path in self . files ( ) ] [EOL] [EOL] def __iter__ ( self ) : [EOL] for json_line_file in self . _json_line_files : [EOL] for line in json_line_file : [EOL] data = self . process ( line . content ) [EOL] data [ [string] ] = SourceContext ( source = line . span . path , row = line . span . line ) [EOL] yield data [EOL] [EOL] [comment] [EOL] def len_per_file ( self ) : [EOL] if self . _len_per_file is None : [EOL] len_per_file = [ len ( json_line_file ) for json_line_file in self . _json_line_files ] [EOL] self . _len_per_file = len_per_file [EOL] return self . _len_per_file [EOL] [EOL] def __len__ ( self ) : [EOL] return sum ( self . len_per_file ( ) ) [EOL] [EOL] def files ( self ) : [EOL] [docstring] [EOL] return util . find_files ( self . path , self . is_valid ) [EOL] [EOL] @ classmethod def is_valid ( cls , path ) : [EOL] [comment] [EOL] [comment] [EOL] return not ( path . name . startswith ( [string] ) or path . name == [string] ) [EOL] [EOL] [EOL] class ListDataset ( Dataset ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , data_iter , freq , one_dim_target = True , ) : [EOL] self . process = ProcessDataEntry ( freq , one_dim_target ) [EOL] self . list_data = list ( data_iter ) [comment] [EOL] [EOL] def __iter__ ( self ) : [EOL] source_name = [string] [EOL] [comment] [EOL] [comment] [EOL] bounds = util . get_bounds_for_mp_data_loading ( len ( self ) ) [EOL] for row_number , data in enumerate ( self . list_data ) : [EOL] if not bounds . lower <= row_number < bounds . upper : [EOL] continue [EOL] [EOL] data = data . copy ( ) [EOL] data = self . process ( data ) [EOL] data [ [string] ] = SourceContext ( source = source_name , row = row_number ) [EOL] yield data [EOL] [EOL] def __len__ ( self ) : [EOL] return len ( self . list_data ) [EOL] [EOL] [EOL] class TimeZoneStrategy ( Enum ) : [EOL] ignore = [string] [EOL] utc = [string] [EOL] error = [string] [EOL] [EOL] [EOL] [comment] [EOL] class ProcessStartField ( pydantic . BaseModel ) : [EOL] [docstring] [EOL] [EOL] class Config : [EOL] arbitrary_types_allowed = True [EOL] [EOL] freq = ... [EOL] name = [string] [EOL] tz_strategy = TimeZoneStrategy . error [EOL] [EOL] def __call__ ( self , data ) : [EOL] try : [EOL] timestamp = ProcessStartField . process ( data [ self . name ] , self . freq ) [EOL] except ( TypeError , ValueError ) as e : [EOL] raise GluonTSDataError ( f' [string] { e } [string] { self . name } [string] ' ) [EOL] [EOL] if timestamp . tz is not None : [EOL] if self . tz_strategy == TimeZoneStrategy . error : [EOL] raise GluonTSDataError ( [string] f' [string] { self . name } [string] ' ) [EOL] elif self . tz_strategy == TimeZoneStrategy . utc : [EOL] [comment] [EOL] timestamp = timestamp . tz_convert ( [string] ) [EOL] [EOL] [comment] [EOL] timestamp = timestamp . tz_localize ( None ) [EOL] [EOL] data [ self . name ] = timestamp [EOL] [EOL] return data [EOL] [EOL] @ staticmethod @ lru_cache ( maxsize = [number] ) def process ( string , freq ) : [EOL] [docstring] [EOL] [EOL] timestamp = pd . Timestamp ( string , freq = freq ) [EOL] [EOL] [comment] [EOL] if isinstance ( timestamp . freq , Tick ) : [EOL] return pd . Timestamp ( timestamp . floor ( timestamp . freq ) , timestamp . freq ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] timestamp = timestamp . replace ( hour = [number] , minute = [number] , second = [number] , microsecond = [number] , nanosecond = [number] ) [EOL] [EOL] return timestamp . freq . rollforward ( timestamp ) [EOL] [EOL] [EOL] class ProcessTimeSeriesField : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] [EOL] def __init__ ( self , name , is_required , is_static , is_cat ) : [EOL] self . name = name [EOL] self . is_required = is_required [EOL] self . req_ndim = [number] if is_static else [number] [EOL] self . dtype = np . int32 if is_cat else np . float32 [EOL] [EOL] def __call__ ( self , data ) : [EOL] value = data . get ( self . name , None ) [EOL] if value is not None : [EOL] value = np . asarray ( value , dtype = self . dtype ) [EOL] [EOL] if self . req_ndim != value . ndim : [EOL] raise GluonTSDataError ( f" [string] { self . name } [string] " f"{ self . req_ndim } [string] { value . ndim } [string] " ) [EOL] [EOL] data [ self . name ] = value [EOL] [EOL] return data [EOL] elif not self . is_required : [EOL] return data [EOL] else : [EOL] raise GluonTSDataError ( f" [string] { self . name } [string] " ) [EOL] [EOL] [EOL] class ProcessDataEntry : [EOL] def __init__ ( self , freq , one_dim_target = True ) : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] self . trans = cast ( List [ Callable [ [ DataEntry ] , DataEntry ] ] , [ ProcessStartField ( freq = freq ) , ProcessTimeSeriesField ( [string] , is_required = True , is_cat = False , is_static = one_dim_target , ) , ProcessTimeSeriesField ( [string] , is_required = False , is_cat = True , is_static = False , ) , ProcessTimeSeriesField ( [string] , is_required = False , is_cat = False , is_static = False , ) , ProcessTimeSeriesField ( [string] , is_required = False , is_cat = False , is_static = False , ) , ProcessTimeSeriesField ( [string] , is_required = False , is_cat = False , is_static = False , ) , ProcessTimeSeriesField ( [string] , is_required = False , is_cat = True , is_static = True , ) , ProcessTimeSeriesField ( [string] , is_required = False , is_cat = False , is_static = True , ) , ] , ) [EOL] [EOL] def __call__ ( self , data ) : [EOL] for t in self . trans : [EOL] data = t ( data ) [EOL] return data [EOL] [EOL] [EOL] def load_datasets ( metadata , train , test ) : [EOL] [docstring] [EOL] meta = MetaData . parse_file ( Path ( metadata ) / [string] ) [EOL] train_ds = FileDataset ( path = train , freq = meta . freq ) [EOL] test_ds = FileDataset ( path = test , freq = meta . freq ) if test else None [EOL] [EOL] return TrainDatasets ( metadata = meta , train = train_ds , test = test_ds ) [EOL] [EOL] [EOL] def serialize_data_entry ( data ) : [EOL] [docstring] [EOL] [EOL] def serialize_field ( field ) : [EOL] if isinstance ( field , np . ndarray ) : [EOL] [comment] [EOL] nan_ix = np . isnan ( field ) [EOL] field = field . astype ( np . object_ ) [EOL] field [ nan_ix ] = [string] [EOL] return field . tolist ( ) [EOL] return str ( field ) [EOL] [EOL] return { k : serialize_field ( v ) for k , v in data . items ( ) if v is not None } [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[BasicFeatureInfo]$ 0 0 0 0 $typing.List[CategoricalFeatureInfo]$ 0 0 0 0 $typing.List[BasicFeatureInfo]$ 0 0 0 0 $typing.List[BasicFeatureInfo]$ 0 0 0 0 $typing.List[CategoricalFeatureInfo]$ 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $MetaData$ 0 0 0 $Dataset$ 0 0 0 $typing.Optional[Dataset]$ 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 $builtins.str$ 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.bool$ 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterator[DataEntry]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[pathlib.Path]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 $pathlib.Path$ 0 0 0 0 0 0 0 0 0 0 $pathlib.Path$ 0 0 0 0 0 0 0 0 $pathlib.Path$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $typing.Iterable[DataEntry]$ 0 $builtins.str$ 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.bool$ 0 0 0 0 0 0 0 0 $typing.Iterable[DataEntry]$ 0 0 0 0 0 $typing.Iterator[DataEntry]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Union[builtins.str,pandas.DateOffset]$ 0 0 0 $builtins.str$ 0 0 0 $TimeZoneStrategy$ 0 0 0 0 0 0 0 $DataEntry$ 0 0 0 $DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 $DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $DataEntry$ 0 0 0 0 0 0 0 0 0 0 $DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.Timestamp$ 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 $builtins.bool$ 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 $DataEntry$ 0 0 0 $DataEntry$ 0 0 0 0 0 $DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $DataEntry$ 0 0 0 0 0 0 0 0 0 0 $DataEntry$ 0 0 0 0 0 0 0 0 0 $DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $TrainDatasets$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [EOL] from pkgutil import extend_path [EOL] [EOL] __path__ = extend_path ( __path__ , __name__ ) [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] __all__ = [ [string] , [string] ] [EOL] [EOL] [comment] [EOL] from . splitter import DateSplitter , OffsetSplitter [EOL] [EOL] [comment] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import List , Optional [EOL] import pandas [EOL] import typing [EOL] import builtins [EOL] import gluonts [EOL] [docstring] [EOL] [EOL] [comment] [EOL] from abc import ABC , abstractmethod [EOL] from typing import List , Optional [EOL] [EOL] [comment] [EOL] import pandas as pd [EOL] import pydantic [EOL] [EOL] [comment] [EOL] from gluonts . dataset . common import DataEntry [EOL] [EOL] [EOL] class TimeSeriesSlice ( pydantic . BaseModel ) : [EOL] [docstring] [EOL] [EOL] class Config : [EOL] arbitrary_types_allowed = True [EOL] [EOL] target = ... [EOL] item = ... [EOL] [EOL] feat_static_cat = [ ] [EOL] feat_static_real = [ ] [EOL] [EOL] feat_dynamic_cat = [ ] [EOL] feat_dynamic_real = [ ] [EOL] [EOL] @ classmethod def from_data_entry ( cls , item , freq = None ) : [EOL] if freq is None : [EOL] freq = item [ [string] ] . freq [EOL] [EOL] index = pd . date_range ( start = item [ [string] ] , freq = freq , periods = len ( item [ [string] ] ) ) [EOL] [EOL] feat_dynamic_cat = [ pd . Series ( cat , index = index ) for cat in list ( item . get ( [string] , [ ] ) ) ] [EOL] [EOL] feat_dynamic_real = [ pd . Series ( real , index = index ) for real in list ( item . get ( [string] , [ ] ) ) ] [EOL] [EOL] feat_static_cat = list ( item . get ( [string] , [ ] ) ) [EOL] [EOL] feat_static_real = list ( item . get ( [string] , [ ] ) ) [EOL] [EOL] return TimeSeriesSlice ( target = pd . Series ( item [ [string] ] , index = index ) , item = item [ [string] ] , feat_static_cat = feat_static_cat , feat_static_real = feat_static_real , feat_dynamic_cat = feat_dynamic_cat , feat_dynamic_real = feat_dynamic_real , ) [EOL] [EOL] def to_data_entry ( self ) : [EOL] ret = { [string] : self . start , [string] : self . item , [string] : self . target . values , } [EOL] [EOL] if self . feat_static_cat : [EOL] ret [ [string] ] = self . feat_static_cat [EOL] if self . feat_static_real : [EOL] ret [ [string] ] = self . feat_static_real [EOL] if self . feat_dynamic_cat : [EOL] ret [ [string] ] = [ cat . values . tolist ( ) for cat in self . feat_dynamic_cat ] [EOL] if self . feat_dynamic_real : [EOL] ret [ [string] ] = [ real . values . tolist ( ) for real in self . feat_dynamic_real ] [EOL] [EOL] return ret [EOL] [EOL] @ property def start ( self ) : [EOL] return self . target . index [ [number] ] [EOL] [EOL] @ property def end ( self ) : [EOL] return self . target . index [ - [number] ] [EOL] [EOL] def __len__ ( self ) : [EOL] return len ( self . target ) [EOL] [EOL] def __getitem__ ( self , slice_ ) : [EOL] feat_dynamic_real = None [EOL] feat_dynamic_cat = None [EOL] [EOL] if self . feat_dynamic_real is not None : [EOL] feat_dynamic_real = [ feat [ slice_ ] for feat in self . feat_dynamic_real ] [EOL] [EOL] if self . feat_dynamic_cat is not None : [EOL] feat_dynamic_cat = [ feat [ slice_ ] for feat in self . feat_dynamic_cat ] [EOL] [EOL] target = self . target [ slice_ ] [EOL] [EOL] assert all ( [ len ( target ) == len ( feat ) for feat in feat_dynamic_real ] ) [EOL] assert all ( [ len ( target ) == len ( feat ) for feat in feat_dynamic_cat ] ) [EOL] [EOL] return TimeSeriesSlice ( target = target , item = self . item , feat_dynamic_cat = feat_dynamic_cat , feat_dynamic_real = feat_dynamic_real , feat_static_cat = self . feat_static_cat , feat_static_real = self . feat_static_real , ) [EOL] [EOL] [EOL] class TrainTestSplit ( pydantic . BaseModel ) : [EOL] train = [ ] [EOL] test = [ ] [EOL] [EOL] def _add_train_slice ( self , train_slice ) : [EOL] [comment] [EOL] if train_slice : [EOL] self . train . append ( train_slice . to_data_entry ( ) ) [EOL] [EOL] def _add_test_slice ( self , test_slice ) : [EOL] self . test . append ( test_slice . to_data_entry ( ) ) [EOL] [EOL] [EOL] class AbstractBaseSplitter ( ABC ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] @ abstractmethod def _train_slice ( self , item ) : [EOL] pass [EOL] [EOL] @ abstractmethod def _test_slice ( self , item , offset = [number] ) : [EOL] pass [EOL] [EOL] def _trim_history ( self , item ) : [EOL] if getattr ( self , [string] ) is not None : [EOL] return item [ : - getattr ( self , [string] ) ] [EOL] else : [EOL] return item [EOL] [EOL] def split ( self , items ) : [EOL] split = TrainTestSplit ( ) [EOL] [EOL] for item in map ( TimeSeriesSlice . from_data_entry , items ) : [EOL] [EOL] train = self . _train_slice ( item ) [EOL] test = self . _trim_history ( self . _test_slice ( item ) ) [EOL] [EOL] split . _add_train_slice ( train ) [EOL] [EOL] assert len ( test ) - len ( train ) >= getattr ( self , [string] ) [EOL] split . _add_test_slice ( test ) [EOL] [EOL] return split [EOL] [EOL] def rolling_split ( self , items , windows , distance = None , ) : [EOL] [comment] [EOL] if distance is None : [EOL] distance = getattr ( self , [string] ) [EOL] assert distance is not None [EOL] [EOL] split = TrainTestSplit ( ) [EOL] [EOL] for item in map ( TimeSeriesSlice . from_data_entry , items ) : [EOL] train = self . _train_slice ( item ) [EOL] split . _add_train_slice ( train ) [EOL] [EOL] for window in range ( windows ) : [EOL] offset = window * distance [EOL] test = self . _trim_history ( self . _test_slice ( item , offset = offset ) ) [EOL] [EOL] assert len ( test ) - len ( train ) >= getattr ( self , [string] ) [EOL] split . _add_test_slice ( test ) [EOL] [EOL] return split [EOL] [EOL] [EOL] class OffsetSplitter ( pydantic . BaseModel , AbstractBaseSplitter ) : [EOL] [docstring] [EOL] [EOL] prediction_length = ... [EOL] split_offset = ... [EOL] max_history = None [EOL] [EOL] def _train_slice ( self , item ) : [EOL] return item [ : self . split_offset ] [EOL] [EOL] def _test_slice ( self , item , offset = [number] ) : [EOL] offset_ = self . split_offset + offset + self . prediction_length [EOL] assert offset_ <= len ( item ) [EOL] return item [ : offset_ ] [EOL] [EOL] [EOL] class DateSplitter ( AbstractBaseSplitter , pydantic . BaseModel ) : [EOL] prediction_length = ... [EOL] split_date = ... [EOL] max_history = None [EOL] [EOL] def _train_slice ( self , item ) : [EOL] [comment] [EOL] return item [ : self . split_date ] [EOL] [EOL] def _test_slice ( self , item , offset = [number] ) : [EOL] freq = item . start . freqstr [EOL] return item [ : self . split_date + pd . Timedelta ( self . prediction_length + offset , unit = freq ) ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.Series$ 0 0 0 $builtins.str$ 0 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 $typing.List[builtins.float]$ 0 0 0 0 0 $typing.List[pandas.Series]$ 0 0 0 0 $typing.List[pandas.Series]$ 0 0 0 0 0 0 0 0 $"TimeSeriesSlice"$ 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $"TimeSeriesSlice"$ 0 0 0 $builtins.slice$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.slice$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.slice$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.slice$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[gluonts.dataset.common.DataEntry]$ 0 0 0 0 $typing.List[gluonts.dataset.common.DataEntry]$ 0 0 0 0 0 0 $None$ 0 0 0 $TimeSeriesSlice$ 0 0 0 0 0 0 $TimeSeriesSlice$ 0 0 0 0 0 0 0 0 $TimeSeriesSlice$ 0 0 0 0 0 0 0 0 $None$ 0 0 0 $TimeSeriesSlice$ 0 0 0 0 0 0 0 0 0 $TimeSeriesSlice$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $TimeSeriesSlice$ 0 0 0 $TimeSeriesSlice$ 0 0 0 0 0 0 0 0 0 $TimeSeriesSlice$ 0 0 0 $TimeSeriesSlice$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 $TimeSeriesSlice$ 0 0 0 $TimeSeriesSlice$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $TimeSeriesSlice$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $TimeSeriesSlice$ 0 0 0 $TrainTestSplit$ 0 0 0 $typing.List[gluonts.dataset.common.DataEntry]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[gluonts.dataset.common.DataEntry]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $TrainTestSplit$ 0 0 0 $typing.List[gluonts.dataset.common.DataEntry]$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[gluonts.dataset.common.DataEntry]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 $TimeSeriesSlice$ 0 0 0 $TimeSeriesSlice$ 0 0 0 0 $TimeSeriesSlice$ 0 0 0 0 0 0 0 0 0 $TimeSeriesSlice$ 0 0 0 $TimeSeriesSlice$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $TimeSeriesSlice$ 0 0 0 $TimeSeriesSlice$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $pandas.Timestamp$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 $TimeSeriesSlice$ 0 0 0 $TimeSeriesSlice$ 0 0 0 0 0 0 $TimeSeriesSlice$ 0 0 0 0 0 0 0 0 0 $TimeSeriesSlice$ 0 0 0 $TimeSeriesSlice$ 0 $builtins.int$ 0 0 0 0 0 0 0 $TimeSeriesSlice$ 0 0 0 0 0 0 $TimeSeriesSlice$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import gluonts [EOL] import pathlib [EOL] import json [EOL] from pathlib import Path [EOL] [EOL] [comment] [EOL] from gluonts . dataset . artificial import ArtificialDataset [EOL] from gluonts . dataset . artificial . generate_synthetic import generate_sf2 [EOL] from gluonts . dataset . common import serialize_data_entry [EOL] [EOL] [EOL] def generate_artificial_dataset ( dataset_path , dataset ) : [EOL] dataset_path_train = dataset_path / [string] [EOL] dataset_path_test = dataset_path / [string] [EOL] [EOL] dataset_path . mkdir ( exist_ok = True ) [EOL] dataset_path_train . mkdir ( exist_ok = False ) [EOL] dataset_path_test . mkdir ( exist_ok = False ) [EOL] [EOL] ds = dataset . generate ( ) [EOL] assert ds . test is not None [EOL] [EOL] with ( dataset_path / [string] ) . open ( [string] ) as fp : [EOL] json . dump ( ds . metadata . dict ( ) , fp , indent = [number] , sort_keys = True ) [EOL] [EOL] generate_sf2 ( filename = str ( dataset_path_train / [string] ) , time_series = list ( map ( serialize_data_entry , ds . train ) ) , is_missing = False , num_missing = [number] , ) [EOL] [EOL] generate_sf2 ( filename = str ( dataset_path_test / [string] ) , time_series = list ( map ( serialize_data_entry , ds . test ) ) , is_missing = False , num_missing = [number] , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Optional [EOL] import typing [EOL] import builtins [EOL] import pathlib [EOL] [docstring] [EOL] import json [EOL] import os [EOL] import shutil [EOL] import tarfile [EOL] from pathlib import Path [EOL] from typing import NamedTuple , Optional [EOL] from urllib import request [EOL] [EOL] from gluonts . dataset . common import FileDataset [EOL] from gluonts . dataset . field_names import FieldName [EOL] from gluonts . dataset . repository . _util import metadata , save_to_file , to_dict [EOL] [EOL] [EOL] class GPCopulaDataset ( NamedTuple ) : [EOL] name = ... [EOL] url = ... [EOL] num_series = ... [EOL] prediction_length = ... [EOL] freq = ... [EOL] rolling_evaluations = ... [EOL] max_target_dim = None [EOL] [EOL] [EOL] root = [string] [EOL] [EOL] datasets_info = { [string] : GPCopulaDataset ( name = [string] , url = root + [string] , num_series = [number] , prediction_length = [number] , freq = [string] , rolling_evaluations = [number] , max_target_dim = None , ) , [string] : GPCopulaDataset ( name = [string] , url = root + [string] , num_series = [number] , prediction_length = [number] , freq = [string] , rolling_evaluations = [number] , max_target_dim = None , ) , [string] : GPCopulaDataset ( name = [string] , url = root + [string] , num_series = [number] , prediction_length = [number] , freq = [string] , rolling_evaluations = [number] , max_target_dim = None , ) , [string] : GPCopulaDataset ( name = [string] , url = root + [string] , num_series = [number] , prediction_length = [number] , freq = [string] , rolling_evaluations = [number] , max_target_dim = None , ) , [string] : GPCopulaDataset ( name = [string] , url = [string] , num_series = [number] , prediction_length = [number] , freq = [string] , rolling_evaluations = [number] , max_target_dim = [number] , ) , [string] : GPCopulaDataset ( name = [string] , url = root + [string] , num_series = [number] , prediction_length = [number] , freq = [string] , rolling_evaluations = [number] , max_target_dim = None , ) , } [EOL] [EOL] [EOL] def generate_gp_copula_dataset ( dataset_path , dataset_name ) : [EOL] ds_info = datasets_info [ dataset_name ] [EOL] os . makedirs ( dataset_path , exist_ok = True ) [EOL] [EOL] download_dataset ( dataset_path . parent , ds_info ) [EOL] save_metadata ( dataset_path , ds_info ) [EOL] save_dataset ( dataset_path / [string] , ds_info ) [EOL] save_dataset ( dataset_path / [string] , ds_info ) [EOL] clean_up_dataset ( dataset_path , ds_info ) [EOL] [EOL] [EOL] def download_dataset ( dataset_path , ds_info ) : [EOL] request . urlretrieve ( ds_info . url , dataset_path / f"{ ds_info . name } [string] " ) [EOL] [EOL] with tarfile . open ( dataset_path / f"{ ds_info . name } [string] " ) as tar : [EOL] tar . extractall ( path = dataset_path ) [EOL] [EOL] [EOL] def save_metadata ( dataset_path , ds_info ) : [EOL] with open ( dataset_path / [string] , [string] ) as f : [EOL] f . write ( json . dumps ( metadata ( cardinality = ds_info . num_series , freq = ds_info . freq , prediction_length = ds_info . prediction_length , ) ) ) [EOL] [EOL] [EOL] def save_dataset ( dataset_path , ds_info ) : [EOL] dataset = list ( FileDataset ( dataset_path , freq = ds_info . freq ) ) [EOL] shutil . rmtree ( dataset_path ) [EOL] train_file = dataset_path / [string] [EOL] save_to_file ( train_file , [ to_dict ( target_values = data_entry [ FieldName . TARGET ] , start = data_entry [ FieldName . START ] , cat = [ cat - ds_info . num_series * ( cat // ds_info . num_series ) ] , item_id = cat , ) for cat , data_entry in enumerate ( dataset ) ] , ) [EOL] [EOL] [EOL] def clean_up_dataset ( dataset_path , ds_info ) : [EOL] os . remove ( dataset_path . parent / f"{ ds_info . name } [string] " ) [EOL] shutil . rmtree ( dataset_path / [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.str$ 0 0 0 $builtins.int$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import List , Optional [EOL] import pandas [EOL] import typing [EOL] import builtins [EOL] import pathlib [EOL] [docstring] [EOL] import json [EOL] import os [EOL] from pathlib import Path [EOL] from typing import List , NamedTuple , Optional [EOL] [EOL] import pandas as pd [EOL] [EOL] from gluonts . dataset . repository . _util import metadata , save_to_file , to_dict [EOL] from gluonts . support . pandas import frequency_add [EOL] [EOL] [EOL] def load_from_pandas ( df , time_index , agg_freq = None , ) : [EOL] df = df . set_index ( time_index ) [EOL] [EOL] pivot_df = df . transpose ( ) [EOL] pivot_df . head ( ) [EOL] [EOL] timeseries = [ ] [EOL] for row in pivot_df . iterrows ( ) : [EOL] ts = pd . Series ( row [ [number] ] . values , index = time_index ) [EOL] if agg_freq is not None : [EOL] ts = ts . resample ( agg_freq ) . sum ( ) [EOL] first_valid = ts [ ts . notnull ( ) ] . index [ [number] ] [EOL] last_valid = ts [ ts . notnull ( ) ] . index [ - [number] ] [EOL] ts = ts [ first_valid : last_valid ] [EOL] [EOL] timeseries . append ( ts ) [EOL] [EOL] return timeseries [EOL] [EOL] [EOL] class LstnetDataset ( NamedTuple ) : [EOL] name = ... [EOL] url = ... [EOL] num_series = ... [EOL] num_time_steps = ... [EOL] prediction_length = ... [EOL] rolling_evaluations = ... [EOL] freq = ... [EOL] start_date = ... [EOL] agg_freq = None [EOL] [EOL] [EOL] root = [string] [EOL] [EOL] datasets_info = { [string] : LstnetDataset ( name = [string] , url = root + [string] , num_series = [number] , num_time_steps = [number] , prediction_length = [number] , rolling_evaluations = [number] , start_date = [string] , freq = [string] , agg_freq = None , ) , [string] : LstnetDataset ( name = [string] , url = root + [string] , num_series = [number] , num_time_steps = [number] , prediction_length = [number] , rolling_evaluations = [number] , start_date = [string] , freq = [string] , agg_freq = None , ) , [string] : LstnetDataset ( name = [string] , url = root + [string] , num_series = [number] , num_time_steps = [number] , prediction_length = [number] , rolling_evaluations = [number] , start_date = [string] , freq = [string] , agg_freq = None , ) , [string] : LstnetDataset ( name = [string] , url = root + [string] , num_series = [number] , num_time_steps = [number] , prediction_length = [number] , rolling_evaluations = [number] , start_date = [string] , freq = [string] , agg_freq = [string] , ) , } [EOL] [EOL] [EOL] def generate_lstnet_dataset ( dataset_path , dataset_name ) : [EOL] ds_info = datasets_info [ dataset_name ] [EOL] [EOL] os . makedirs ( dataset_path , exist_ok = True ) [EOL] [EOL] with open ( dataset_path / [string] , [string] ) as f : [EOL] f . write ( json . dumps ( metadata ( cardinality = ds_info . num_series , freq = ds_info . freq , prediction_length = ds_info . prediction_length , ) ) ) [EOL] [EOL] train_file = dataset_path / [string] / [string] [EOL] test_file = dataset_path / [string] / [string] [EOL] [EOL] time_index = pd . date_range ( start = ds_info . start_date , freq = ds_info . freq , periods = ds_info . num_time_steps , ) [EOL] [EOL] df = pd . read_csv ( ds_info . url , header = None ) [EOL] [EOL] assert df . shape == ( ds_info . num_time_steps , ds_info . num_series , ) , f" [string] { ( ds_info . num_time_steps , ds_info . num_series ) } [string] { df . shape }" [EOL] [EOL] timeseries = load_from_pandas ( df = df , time_index = time_index , agg_freq = ds_info . agg_freq ) [EOL] [EOL] [comment] [EOL] ts_index = timeseries [ [number] ] . index [EOL] training_end = ts_index [ int ( len ( ts_index ) * ( [number] / [number] ) ) ] [EOL] [EOL] train_ts = [ ] [EOL] for cat , ts in enumerate ( timeseries ) : [EOL] sliced_ts = ts [ : training_end ] [EOL] if len ( sliced_ts ) > [number] : [EOL] train_ts . append ( to_dict ( target_values = sliced_ts . values , start = sliced_ts . index [ [number] ] , cat = [ cat ] , item_id = cat , ) ) [EOL] [EOL] assert len ( train_ts ) == ds_info . num_series [EOL] [EOL] save_to_file ( train_file , train_ts ) [EOL] [EOL] [comment] [EOL] prediction_dates = [ frequency_add ( training_end , i * ds_info . prediction_length ) for i in range ( ds_info . rolling_evaluations ) ] [EOL] [EOL] test_ts = [ ] [EOL] for prediction_start_date in prediction_dates : [EOL] for cat , ts in enumerate ( timeseries ) : [EOL] [comment] [EOL] prediction_end_date = frequency_add ( prediction_start_date , ds_info . prediction_length ) [EOL] sliced_ts = ts [ : prediction_end_date ] [EOL] test_ts . append ( to_dict ( target_values = sliced_ts . values , start = sliced_ts . index [ [number] ] , cat = [ cat ] , item_id = cat , ) ) [EOL] [EOL] assert len ( test_ts ) == ds_info . num_series * ds_info . rolling_evaluations [EOL] [EOL] save_to_file ( test_file , test_ts ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[pandas.Series]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import builtins [EOL] import pathlib [EOL] import json [EOL] import os [EOL] from pathlib import Path [EOL] [EOL] import numpy as np [EOL] import pandas as pd [EOL] [EOL] from gluonts . dataset . repository . _util import metadata , save_to_file , to_dict [EOL] [EOL] [EOL] def generate_m4_dataset ( dataset_path , m4_freq , pandas_freq , prediction_length ) : [EOL] m4_dataset_url = ( [string] ) [EOL] train_df = pd . read_csv ( f"{ m4_dataset_url } [string] { m4_freq } [string] " , index_col = [number] ) [EOL] test_df = pd . read_csv ( f"{ m4_dataset_url } [string] { m4_freq } [string] " , index_col = [number] ) [EOL] [EOL] os . makedirs ( dataset_path , exist_ok = True ) [EOL] [EOL] with open ( dataset_path / [string] , [string] ) as f : [EOL] f . write ( json . dumps ( metadata ( cardinality = len ( train_df ) , freq = pandas_freq , prediction_length = prediction_length , ) ) ) [EOL] [EOL] train_file = dataset_path / [string] / [string] [EOL] test_file = dataset_path / [string] / [string] [EOL] [EOL] train_target_values = [ ts [ ~ np . isnan ( ts ) ] for ts in train_df . values ] [EOL] [EOL] test_target_values = [ np . hstack ( [ train_ts , test_ts ] ) for train_ts , test_ts in zip ( train_target_values , test_df . values ) ] [EOL] [EOL] if m4_freq == [string] : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] train_target_values = [ ts [ - [number] : ] for ts in train_target_values ] [EOL] test_target_values = [ ts [ - [number] : ] for ts in test_target_values ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] mock_start_dataset = [string] [EOL] [EOL] save_to_file ( train_file , [ to_dict ( target_values = target , start = mock_start_dataset , cat = [ cat ] , item_id = cat , ) for cat , target in enumerate ( train_target_values ) ] , ) [EOL] [EOL] save_to_file ( test_file , [ to_dict ( target_values = target , start = mock_start_dataset , cat = [ cat ] , item_id = cat , ) for cat , target in enumerate ( test_target_values ) ] , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import gluonts [EOL] import builtins [EOL] import pathlib [EOL] import logging [EOL] from collections import OrderedDict [EOL] from functools import partial [EOL] from pathlib import Path [EOL] [EOL] from gluonts . dataset . artificial import ConstantDataset [EOL] from gluonts . dataset . common import TrainDatasets , load_datasets [EOL] from gluonts . dataset . repository . _artificial import generate_artificial_dataset [EOL] from gluonts . dataset . repository . _gp_copula_2019 import ( generate_gp_copula_dataset , ) [EOL] from gluonts . dataset . repository . _lstnet import generate_lstnet_dataset [EOL] from gluonts . dataset . repository . _m4 import generate_m4_dataset [EOL] from gluonts . dataset . repository . _m5 import generate_m5_dataset [EOL] from gluonts . support . util import get_download_path [EOL] [EOL] m4_freq = [string] [EOL] pandas_freq = [string] [EOL] dataset_path = Path ( f" [string] { m4_freq }" ) [EOL] prediction_length = [number] [EOL] [EOL] dataset_recipes = OrderedDict ( { [string] : partial ( generate_artificial_dataset , dataset = ConstantDataset ( ) ) , [string] : partial ( generate_lstnet_dataset , dataset_name = [string] ) , [string] : partial ( generate_lstnet_dataset , dataset_name = [string] ) , [string] : partial ( generate_lstnet_dataset , dataset_name = [string] ) , [string] : partial ( generate_lstnet_dataset , dataset_name = [string] ) , [string] : partial ( generate_gp_copula_dataset , dataset_name = [string] ) , [string] : partial ( generate_gp_copula_dataset , dataset_name = [string] ) , [string] : partial ( generate_gp_copula_dataset , dataset_name = [string] ) , [string] : partial ( generate_gp_copula_dataset , dataset_name = [string] ) , [string] : partial ( generate_gp_copula_dataset , dataset_name = [string] ) , [string] : partial ( generate_gp_copula_dataset , dataset_name = [string] ) , [string] : partial ( generate_m4_dataset , m4_freq = [string] , pandas_freq = [string] , prediction_length = [number] , ) , [string] : partial ( generate_m4_dataset , m4_freq = [string] , pandas_freq = [string] , prediction_length = [number] , ) , [string] : partial ( generate_m4_dataset , m4_freq = [string] , pandas_freq = [string] , prediction_length = [number] , ) , [string] : partial ( generate_m4_dataset , m4_freq = [string] , pandas_freq = [string] , prediction_length = [number] , ) , [string] : partial ( generate_m4_dataset , m4_freq = [string] , pandas_freq = [string] , prediction_length = [number] , ) , [string] : partial ( generate_m4_dataset , m4_freq = [string] , pandas_freq = [string] , prediction_length = [number] , ) , [string] : partial ( generate_m5_dataset , pandas_freq = [string] , prediction_length = [number] ) , } ) [EOL] [EOL] dataset_names = list ( dataset_recipes . keys ( ) ) [EOL] [EOL] default_dataset_path = get_download_path ( ) / [string] [EOL] [EOL] [EOL] def materialize_dataset ( dataset_name , path = default_dataset_path , regenerate = False , ) : [EOL] [docstring] [EOL] assert dataset_name in dataset_recipes . keys ( ) , ( f"{ dataset_name } [string] " f"{ dataset_recipes . keys ( ) } [string] " ) [EOL] [EOL] path . mkdir ( parents = True , exist_ok = True ) [EOL] dataset_path = path / dataset_name [EOL] [EOL] dataset_recipe = dataset_recipes [ dataset_name ] [EOL] [EOL] if not dataset_path . exists ( ) or regenerate : [EOL] logging . info ( f" [string] { dataset_name }" ) [EOL] dataset_recipe ( dataset_path = dataset_path ) [EOL] else : [EOL] logging . info ( f" [string] { dataset_path } [string] " ) [EOL] [EOL] return dataset_path [EOL] [EOL] [EOL] def get_dataset ( dataset_name , path = default_dataset_path , regenerate = False , ) : [EOL] [docstring] [EOL] dataset_path = materialize_dataset ( dataset_name , path , regenerate ) [EOL] [EOL] return load_datasets ( metadata = dataset_path , train = dataset_path / [string] , test = dataset_path / [string] , ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] [EOL] for dataset in dataset_names : [EOL] print ( f" [string] { dataset }" ) [EOL] ds = get_dataset ( dataset , regenerate = True ) [EOL] print ( ds . metadata ) [EOL] print ( sum ( [number] for _ in list ( iter ( ds . train ) ) ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pathlib.Path$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.TrainDatasets$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import builtins [EOL] import pathlib [EOL] import json [EOL] import os [EOL] from pathlib import Path [EOL] [EOL] import numpy as np [EOL] import pandas as pd [EOL] [EOL] from gluonts . dataset . field_names import FieldName [EOL] from gluonts . dataset . repository . _util import metadata , save_to_file [EOL] [EOL] [EOL] def generate_m5_dataset ( dataset_path , pandas_freq , prediction_length ) : [EOL] cal_path = f"{ dataset_path } [string] " [EOL] sales_path = f"{ dataset_path } [string] " [EOL] [EOL] if not os . path . exists ( cal_path ) or not os . path . exists ( sales_path ) : [EOL] raise RuntimeError ( f" [string] " f" [string] " f" [string] { dataset_path } [string] " ) [EOL] [EOL] [comment] [EOL] calendar = pd . read_csv ( cal_path ) [EOL] sales_train_validation = pd . read_csv ( sales_path ) [EOL] submission_prediction_length = prediction_length * [number] [EOL] [EOL] [comment] [EOL] cal_features = calendar . drop ( [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , ] , axis = [number] , ) [EOL] cal_features [ [string] ] = cal_features [ [string] ] . apply ( lambda x : [number] if str ( x ) == [string] else [number] ) [EOL] cal_features [ [string] ] = cal_features [ [string] ] . apply ( lambda x : [number] if str ( x ) == [string] else [number] ) [EOL] test_cal_features = cal_features . values . T [EOL] train_cal_features = test_cal_features [ : , : - submission_prediction_length - prediction_length ] [EOL] test_cal_features = test_cal_features [ : , : - submission_prediction_length ] [EOL] [EOL] test_cal_features_list = [ test_cal_features ] * len ( sales_train_validation ) [EOL] train_cal_features_list = [ train_cal_features ] * len ( sales_train_validation ) [EOL] [EOL] [comment] [EOL] state_ids = ( sales_train_validation [ [string] ] . astype ( [string] ) . cat . codes . values ) [EOL] state_ids_un = np . unique ( state_ids ) [EOL] store_ids = ( sales_train_validation [ [string] ] . astype ( [string] ) . cat . codes . values ) [EOL] store_ids_un = np . unique ( store_ids ) [EOL] cat_ids = ( sales_train_validation [ [string] ] . astype ( [string] ) . cat . codes . values ) [EOL] cat_ids_un = np . unique ( cat_ids ) [EOL] dept_ids = ( sales_train_validation [ [string] ] . astype ( [string] ) . cat . codes . values ) [EOL] dept_ids_un = np . unique ( dept_ids ) [EOL] item_ids = ( sales_train_validation [ [string] ] . astype ( [string] ) . cat . codes . values ) [EOL] item_ids_un = np . unique ( item_ids ) [EOL] stat_cat_list = [ item_ids , dept_ids , cat_ids , store_ids , state_ids ] [EOL] stat_cat = np . concatenate ( stat_cat_list ) [EOL] stat_cat = stat_cat . reshape ( len ( stat_cat_list ) , len ( item_ids ) ) . T [EOL] cardinalities = [ len ( item_ids_un ) , len ( dept_ids_un ) , len ( cat_ids_un ) , len ( store_ids_un ) , len ( state_ids_un ) , ] [EOL] [EOL] [comment] [EOL] train_df = sales_train_validation . drop ( [ [string] , [string] , [string] , [string] , [string] , [string] ] , axis = [number] ) [EOL] test_target_values = train_df . values . copy ( ) [EOL] train_target_values = [ ts [ : - prediction_length ] for ts in train_df . values ] [EOL] dates = [ [string] for _ in range ( len ( sales_train_validation ) ) ] [EOL] [EOL] [comment] [EOL] meta_file = dataset_path / [string] [EOL] with open ( meta_file , [string] ) as f : [EOL] f . write ( json . dumps ( metadata ( cardinality = cardinalities , freq = pandas_freq , prediction_length = prediction_length , ) ) ) [EOL] [EOL] [comment] [EOL] train_file = dataset_path / [string] / [string] [EOL] train_ds = [ { FieldName . TARGET : target . tolist ( ) , FieldName . START : start , FieldName . FEAT_DYNAMIC_REAL : fdr . tolist ( ) , FieldName . FEAT_STATIC_CAT : fsc . tolist ( ) , } for ( target , start , fdr , fsc ) in zip ( train_target_values , dates , train_cal_features_list , stat_cat ) ] [EOL] save_to_file ( train_file , train_ds ) [EOL] [EOL] [comment] [EOL] test_file = dataset_path / [string] / [string] [EOL] test_ds = [ { FieldName . TARGET : target . tolist ( ) , FieldName . START : start , FieldName . FEAT_DYNAMIC_REAL : fdr . tolist ( ) , FieldName . FEAT_STATIC_CAT : fsc . tolist ( ) , } for ( target , start , fdr , fsc ) in zip ( test_target_values , dates , test_cal_features_list , stat_cat ) ] [EOL] save_to_file ( test_file , test_ds ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , Union , List , Dict , Optional [EOL] import typing [EOL] import builtins [EOL] import numpy [EOL] import pathlib [EOL] import json [EOL] import os [EOL] from pathlib import Path [EOL] from typing import Any , Dict , List , Optional , Union [EOL] [EOL] import numpy as np [EOL] [EOL] [EOL] def to_dict ( target_values , start , cat = None , item_id = None , ) : [EOL] def serialize ( x ) : [EOL] if np . isnan ( x ) : [EOL] return [string] [EOL] else : [EOL] [comment] [EOL] return float ( [string] . format ( float ( x ) ) ) [EOL] [EOL] res = { [string] : str ( start ) , [string] : [ serialize ( x ) for x in target_values ] , } [EOL] [EOL] if cat is not None : [EOL] res [ [string] ] = cat [EOL] [EOL] if item_id is not None : [EOL] res [ [string] ] = item_id [EOL] [EOL] return res [EOL] [EOL] [EOL] def save_to_file ( path , data ) : [EOL] print ( f" [string] { path }" ) [EOL] path_dir = os . path . dirname ( path ) [EOL] os . makedirs ( path_dir , exist_ok = True ) [EOL] with open ( path , [string] ) as fp : [EOL] for d in data : [EOL] fp . write ( json . dumps ( d ) . encode ( [string] ) ) [EOL] fp . write ( [string] . encode ( [string] ) ) [EOL] [EOL] [EOL] def metadata ( cardinality , freq , prediction_length ) : [EOL] return { [string] : freq , [string] : prediction_length , [string] : [ { [string] : [string] , [string] : str ( cardinality ) } ] , } [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , TextIO [EOL] import typing [EOL] import builtins [EOL] import gluonts [EOL] import csv [EOL] import json [EOL] import os [EOL] from typing import List , TextIO [EOL] [EOL] [comment] [EOL] import holidays [EOL] [EOL] [comment] [EOL] import pandas as pd [EOL] [EOL] [comment] [EOL] from gluonts . dataset . artificial . _base import ( ArtificialDataset , ComplexSeasonalTimeSeries , ConstantDataset , ) [EOL] from gluonts . dataset . field_names import FieldName [EOL] [EOL] [EOL] def write_csv_row ( time_series , freq , csv_file , is_missing , num_missing , ) : [EOL] csv_writer = csv . writer ( csv_file ) [EOL] [comment] [EOL] week_dict = { [number] : [string] , [number] : [string] , [number] : [string] , [number] : [string] , [number] : [string] , [number] : [string] , [number] : [string] , } [EOL] for i in range ( len ( time_series ) ) : [EOL] data = time_series [ i ] [EOL] timestamp = pd . Timestamp ( data [ FieldName . START ] ) [EOL] freq_week_start = freq [EOL] if freq_week_start == [string] : [EOL] freq_week_start = f" [string] { week_dict [ timestamp . weekday ( ) ] }" [EOL] timestamp = pd . Timestamp ( data [ FieldName . START ] , freq = freq_week_start ) [EOL] item_id = int ( data [ FieldName . ITEM_ID ] ) [EOL] for j , target in enumerate ( data [ FieldName . TARGET ] ) : [EOL] [comment] [EOL] if is_missing and j != [number] and j % num_missing == [number] : [EOL] timestamp += [number] [EOL] continue [comment] [EOL] else : [EOL] timestamp_row = timestamp [EOL] if freq in [ [string] , [string] , [string] ] : [EOL] timestamp_row = timestamp . date ( ) [EOL] row = [ item_id , timestamp_row , target ] [EOL] [comment] [EOL] if FieldName . FEAT_DYNAMIC_REAL in data . keys ( ) : [EOL] for feat_dynamic_real in data [ FieldName . FEAT_DYNAMIC_REAL ] : [EOL] row . append ( feat_dynamic_real [ j ] ) [EOL] csv_writer . writerow ( row ) [EOL] timestamp += [number] [EOL] [EOL] [EOL] def generate_sf2 ( filename , time_series , is_missing , num_missing ) : [EOL] [comment] [EOL] if not os . path . exists ( os . path . dirname ( filename ) ) : [EOL] os . makedirs ( os . path . dirname ( filename ) ) [EOL] with open ( filename , [string] ) as json_file : [EOL] for ts in time_series : [EOL] if is_missing : [EOL] target = [ ] [comment] [EOL] [comment] [EOL] for j , val in enumerate ( ts [ FieldName . TARGET ] ) : [EOL] [comment] [EOL] if j != [number] and j % num_missing == [number] : [EOL] target . append ( None ) [EOL] else : [EOL] target . append ( val ) [EOL] ts [ FieldName . TARGET ] = target [EOL] ts . pop ( FieldName . FEAT_STATIC_CAT , None ) [EOL] ts . pop ( FieldName . FEAT_STATIC_REAL , None ) [EOL] [comment] [EOL] if ( FieldName . FEAT_DYNAMIC_REAL in ts . keys ( ) [EOL] and [string] in filename ) : [EOL] [comment] [EOL] for i , feat_dynamic_real in enumerate ( ts [ FieldName . FEAT_DYNAMIC_REAL ] ) : [EOL] ts [ FieldName . FEAT_DYNAMIC_REAL ] [ i ] = feat_dynamic_real [ : len ( ts [ FieldName . TARGET ] ) ] [EOL] json . dump ( ts , json_file ) [EOL] json_file . write ( [string] ) [EOL] [EOL] [EOL] def generate_sf2s_and_csv ( file_path , folder_name , artificial_dataset , is_missing = False , num_missing = [number] , ) : [EOL] file_path += f"{ folder_name }" [EOL] if not os . path . exists ( os . path . dirname ( file_path ) ) : [EOL] os . makedirs ( os . path . dirname ( file_path ) ) [EOL] freq = artificial_dataset . metadata . freq [EOL] train_set = artificial_dataset . train [EOL] generate_sf2 ( file_path + [string] , train_set , is_missing , num_missing ) [EOL] test_set = artificial_dataset . test [EOL] generate_sf2 ( file_path + [string] , test_set , is_missing , num_missing ) [EOL] with open ( file_path + [string] , [string] ) as csv_file : [EOL] [comment] [EOL] write_csv_row ( test_set , freq , csv_file , is_missing , num_missing ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] num_timeseries = [number] [EOL] file_path = [string] [EOL] generate_sf2s_and_csv ( file_path , [string] , ConstantDataset ( ) ) [EOL] generate_sf2s_and_csv ( file_path , [string] , ConstantDataset ( ) , is_missing = True ) [EOL] generate_sf2s_and_csv ( file_path , [string] , ConstantDataset ( is_random_constant = True ) ) [EOL] generate_sf2s_and_csv ( file_path , [string] , ConstantDataset ( num_timeseries = num_timeseries , is_random_constant = True ) , ) [EOL] generate_sf2s_and_csv ( file_path , [string] , ConstantDataset ( is_different_scales = True ) , ) [EOL] generate_sf2s_and_csv ( file_path , [string] , ConstantDataset ( is_noise = True ) ) [EOL] generate_sf2s_and_csv ( file_path , [string] , ConstantDataset ( is_trend = True ) ) [EOL] generate_sf2s_and_csv ( file_path , [string] , ConstantDataset ( is_noise = True , is_trend = True ) , ) [EOL] generate_sf2s_and_csv ( file_path , [string] , ConstantDataset ( is_noise = True , is_long = True ) , ) [EOL] generate_sf2s_and_csv ( file_path , [string] , ConstantDataset ( is_noise = True , is_short = True ) , ) [EOL] generate_sf2s_and_csv ( file_path , [string] , ConstantDataset ( is_noise = True , is_different_scales = True ) , ) [EOL] generate_sf2s_and_csv ( file_path , [string] , ConstantDataset ( is_nan = True ) ) [EOL] generate_sf2s_and_csv ( file_path , [string] , ConstantDataset ( is_piecewise = True , is_random_constant = True ) , ) [EOL] generate_sf2s_and_csv ( file_path , [string] , ComplexSeasonalTimeSeries ( ) ) [EOL] generate_sf2s_and_csv ( file_path , [string] , ComplexSeasonalTimeSeries ( is_scale = False ) , ) [EOL] generate_sf2s_and_csv ( file_path , [string] , ComplexSeasonalTimeSeries ( is_scale = False , is_noise = False ) , ) [EOL] generate_sf2s_and_csv ( file_path , [string] , ComplexSeasonalTimeSeries ( proportion_missing_values = [number] ) , ) [EOL] generate_sf2s_and_csv ( file_path , [string] , ConstantDataset ( num_steps = [number] , num_missing_middle = [number] ) , ) [EOL] generate_sf2s_and_csv ( file_path , [string] , ComplexSeasonalTimeSeries ( freq_str = [string] , percentage_unique_timestamps = [number] , is_out_of_bounds_date = True , ) , ) [EOL] generate_sf2s_and_csv ( file_path , [string] , ConstantDataset ( is_promotions = True , freq = [string] , start = [string] , num_timeseries = [number] , num_steps = [number] , ) , ) [EOL] generate_sf2s_and_csv ( file_path , [string] , ConstantDataset ( start = [string] , freq = [string] , holidays = list ( holidays . UnitedStates ( years = [ [number] , [number] ] ) . keys ( ) ) , num_steps = [number] , ) , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from . _base import ( ArtificialDataset , ComplexSeasonalTimeSeries , ConstantDataset , RecipeDataset , constant_dataset , default_synthetic , ) [EOL] [EOL] __all__ = [ [string] , [string] , [string] , [string] , [string] , [string] , ] [EOL] [EOL] [comment] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import builtins [EOL] import pydoc [EOL] from typing import Type , Union , cast [EOL] [EOL] import pkg_resources [EOL] [EOL] from gluonts . core . exception import GluonTSForecasterNotFoundError [EOL] [EOL] from gluonts . model . estimator import Estimator [EOL] from gluonts . model . predictor import Predictor [EOL] [EOL] Forecaster = Type [ Union [ Estimator , Predictor ] ] [EOL] [EOL] [EOL] def forecaster_type_by_name ( name ) : [EOL] [docstring] [EOL] forecaster = None [EOL] [EOL] for entry_point in pkg_resources . iter_entry_points ( [string] ) : [EOL] if entry_point . name == name : [EOL] forecaster = entry_point . load ( ) [EOL] break [EOL] else : [EOL] forecaster = pydoc . locate ( name ) [EOL] [EOL] if forecaster is None : [EOL] raise GluonTSForecasterNotFoundError ( f' [string] { name } [string] ' ) [EOL] [EOL] return cast ( Forecaster , forecaster ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $Forecaster$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Optional [EOL] import typing [EOL] import builtins [EOL] import logging [EOL] import traceback [EOL] from pathlib import Path [EOL] from typing import Optional [EOL] [EOL] [comment] [EOL] import click [EOL] [EOL] [comment] [EOL] from gluonts . core . exception import GluonTSForecasterNotFoundError [EOL] from gluonts . shell . sagemaker import TrainPaths [EOL] from gluonts . shell . serve import Settings [EOL] [EOL] from . sagemaker import ServeEnv , TrainEnv [EOL] from . util import forecaster_type_by_name , Forecaster [EOL] [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] @ click . group ( ) def cli ( ) : [EOL] pass [EOL] [EOL] [EOL] @ cli . command ( name = [string] ) @ click . option ( [string] , type = click . Path ( ) , envvar = [string] , default = [string] , help = [string] , ) @ click . option ( [string] , metavar = [string] , envvar = [string] , help = ( [string] [string] [string] [string] [string] [string] [string] ) , ) @ click . option ( [string] , envvar = [string] , default = False , help = ( [string] [string] ) , ) def serve_command ( data_path , forecaster , force_static ) : [EOL] from gluonts . shell import serve [EOL] [EOL] logger . info ( [string] ) [EOL] [EOL] if not force_static and forecaster is not None : [EOL] forecaster_type = forecaster_type_by_name ( forecaster ) [EOL] else : [EOL] forecaster_type = None [EOL] [EOL] gunicorn_app = serve . make_gunicorn_app ( env = ServeEnv ( Path ( data_path ) ) , forecaster_type = forecaster_type , settings = Settings ( ) , ) [EOL] gunicorn_app . run ( ) [EOL] [EOL] [EOL] @ cli . command ( name = [string] ) @ click . option ( [string] , type = click . Path ( exists = True ) , envvar = [string] , default = [string] , help = [string] , ) @ click . option ( [string] , type = str , envvar = [string] , help = ( [string] [string] [string] [string] [string] ) , ) def train_command ( data_path , forecaster ) : [EOL] from gluonts . shell import train [EOL] [EOL] logger . info ( [string] ) [EOL] train_paths = TrainPaths ( Path ( data_path ) ) [EOL] [EOL] try : [EOL] env = TrainEnv ( train_paths ) [EOL] if forecaster is None : [EOL] try : [EOL] forecaster = env . hyperparameters [ [string] ] [EOL] except KeyError : [EOL] msg = ( [string] [string] [string] ) [EOL] raise GluonTSForecasterNotFoundError ( msg ) [EOL] [EOL] assert forecaster is not None [EOL] train . run_train_and_test ( env , forecaster_type_by_name ( forecaster ) ) [EOL] except Exception as error : [EOL] with open ( train_paths . output / [string] , [string] ) as out_file : [EOL] out_file . write ( str ( error ) ) [EOL] out_file . write ( [string] ) [EOL] out_file . write ( traceback . format_exc ( ) ) [EOL] raise [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] import logging [EOL] import os [EOL] [EOL] from gluonts import gluonts_tqdm [EOL] [EOL] if [string] in os . environ : [EOL] gluonts_tqdm . USE_TQDM = False [EOL] [EOL] logging . basicConfig ( level = logging . INFO , format = [string] , datefmt = [string] , ) [EOL] cli ( prog_name = __package__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Any , Union , Type , Optional [EOL] import typing [EOL] import builtins [EOL] import gluonts [EOL] import sagemaker [EOL] import logging [EOL] from typing import Any , Optional , Type , Union [EOL] [EOL] [comment] [EOL] import gluonts [EOL] from gluonts . core import fqname_for [EOL] from gluonts . core . serde import dump_code [EOL] from gluonts . dataset . common import Dataset [EOL] from gluonts . evaluation import Evaluator , backtest [EOL] from gluonts . model . estimator import Estimator , GluonEstimator [EOL] from gluonts . model . predictor import Predictor [EOL] from gluonts . support . util import maybe_len [EOL] from gluonts . transform import FilterTransformation , TransformedDataset [EOL] [EOL] [comment] [EOL] import json [EOL] [EOL] [comment] [EOL] from . sagemaker import TrainEnv [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def log_metric ( metric , value ) : [EOL] [docstring] [EOL] logger . info ( f" [string] { metric } [string] { dump_code ( value ) }" ) [EOL] [EOL] [EOL] def run_train_and_test ( env , forecaster_type ) : [EOL] [comment] [EOL] [comment] [EOL] [EOL] forecaster_fq_name = fqname_for ( forecaster_type ) [EOL] forecaster_version = forecaster_type . __version__ [EOL] [EOL] logger . info ( f" [string] { gluonts . __version__ }" ) [EOL] logger . info ( f" [string] { forecaster_fq_name } [string] { forecaster_version }" ) [EOL] [EOL] forecaster = forecaster_type . from_inputs ( env . datasets [ [string] ] , ** env . hyperparameters ) [EOL] [EOL] logger . info ( f" [string] " f"{ dump_code ( forecaster ) }" ) [EOL] [EOL] logger . info ( [string] f"{ [string] . join ( name for name in [ [string] , [string] , [string] ] if name in env . datasets ) }" ) [EOL] [EOL] if isinstance ( forecaster , Predictor ) : [EOL] predictor = forecaster [EOL] else : [EOL] predictor = run_train ( forecaster = forecaster , train_dataset = env . datasets [ [string] ] , validation_dataset = env . datasets . get ( [string] ) , hyperparameters = env . hyperparameters , ) [EOL] [EOL] predictor . serialize ( env . path . model ) [EOL] [EOL] if [string] in env . datasets : [EOL] run_test ( env , predictor , env . datasets [ [string] ] ) [EOL] [EOL] [EOL] def run_train ( forecaster , train_dataset , hyperparameters , validation_dataset , ) : [EOL] num_workers = ( int ( hyperparameters [ [string] ] ) [EOL] if [string] in hyperparameters . keys ( ) [EOL] else None ) [EOL] shuffle_buffer_length = ( int ( hyperparameters [ [string] ] ) [EOL] if [string] in hyperparameters . keys ( ) [EOL] else None ) [EOL] num_prefetch = ( int ( hyperparameters [ [string] ] ) [EOL] if [string] in hyperparameters . keys ( ) [EOL] else None ) [EOL] if isinstance ( forecaster , GluonEstimator ) : [EOL] return forecaster . train ( training_data = train_dataset , validation_data = validation_dataset , num_workers = num_workers , num_prefetch = num_prefetch , shuffle_buffer_length = shuffle_buffer_length , ) [EOL] else : [EOL] return forecaster . train ( training_data = train_dataset , validation_data = validation_dataset , ) [EOL] [EOL] [EOL] def run_test ( env , predictor , test_dataset ) : [EOL] len_original = maybe_len ( test_dataset ) [EOL] [EOL] test_dataset = TransformedDataset ( base_dataset = test_dataset , transformations = [ FilterTransformation ( lambda x : x [ [string] ] . shape [ - [number] ] > predictor . prediction_length ) ] , ) [EOL] [EOL] len_filtered = len ( test_dataset ) [EOL] [EOL] if len_original is not None and len_original > len_filtered : [EOL] logger . warning ( f" [string] " f" [string] " f"{ len_filtered } [string] { len_original } [string] " f" [string] { int ( len_filtered / len_original * [number] ) } [string] " ) [EOL] [EOL] forecast_it , ts_it = backtest . make_evaluation_predictions ( dataset = test_dataset , predictor = predictor , num_samples = [number] ) [EOL] [EOL] agg_metrics , item_metrics = Evaluator ( ) ( ts_iterator = ts_it , fcst_iterator = forecast_it , num_series = len ( test_dataset ) , ) [EOL] [EOL] [comment] [EOL] for name , score in agg_metrics . items ( ) : [EOL] logger . info ( f" [string] { env . current_host } [string] { name } [string] { score }" ) [EOL] [EOL] [comment] [EOL] with open ( env . path . model / [string] , [string] ) as agg_metric_file : [EOL] json . dump ( agg_metrics , agg_metric_file ) [EOL] with open ( env . path . model / [string] , [string] ) as item_metrics_file : [EOL] item_metrics . to_csv ( item_metrics_file , index = False ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.predictor.Predictor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Union , Type , Optional [EOL] import gluonts [EOL] import flask [EOL] import ipaddress [EOL] import typing [EOL] import builtins [EOL] import logging [EOL] import multiprocessing [EOL] from ipaddress import IPv4Address [EOL] from typing import Optional , Type , Union [EOL] [EOL] [comment] [EOL] from flask import Flask [EOL] from gunicorn . app . base import BaseApplication [EOL] from pydantic import BaseSettings [EOL] [EOL] [comment] [EOL] import gluonts [EOL] from gluonts . core import fqname_for [EOL] from gluonts . model . estimator import Estimator [EOL] from gluonts . model . predictor import Predictor [EOL] from gluonts . shell . sagemaker import ServeEnv [EOL] [EOL] from . app import make_app [EOL] [EOL] logging . basicConfig ( level = logging . INFO , format = [string] , datefmt = [string] , ) [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] MB = [number] * [number] [EOL] [EOL] [EOL] class Settings ( BaseSettings ) : [EOL] [comment] [EOL] class Config : [EOL] env_prefix = [string] [EOL] [EOL] model_server_workers = None [EOL] max_content_length = [number] * MB [EOL] [EOL] sagemaker_server_address = IPv4Address ( [string] ) [EOL] sagemaker_server_port = [number] [EOL] sagemaker_server_timeout = [number] [EOL] [EOL] gluonts_batch_timeout = [number] [EOL] gluonts_batch_fallback_predictor = [string] [EOL] [EOL] sagemaker_batch = False [EOL] sagemaker_batch_strategy = [string] [EOL] [EOL] sagemaker_max_payload_in_mb = [number] [EOL] sagemaker_max_concurrent_transforms = [number] ** [number] - [number] [EOL] [EOL] @ property def sagemaker_server_bind ( self ) : [EOL] return f"{ self . sagemaker_server_address } [string] { self . sagemaker_server_port }" [EOL] [EOL] @ property def number_of_workers ( self ) : [EOL] cpu_count = multiprocessing . cpu_count ( ) [EOL] [EOL] if self . model_server_workers : [EOL] logging . info ( f" [string] { self . model_server_workers } [string] " f" [string] " ) [EOL] return self . model_server_workers [EOL] [EOL] elif ( self . sagemaker_batch [EOL] and self . sagemaker_max_concurrent_transforms < cpu_count ) : [EOL] logger . info ( f" [string] { self . sagemaker_max_concurrent_transforms } [string] " f" [string] " ) [EOL] return self . sagemaker_max_concurrent_transforms [EOL] [EOL] else : [EOL] logger . info ( f" [string] { cpu_count } [string] " ) [EOL] return cpu_count [EOL] [EOL] [EOL] class Application ( BaseApplication ) : [EOL] def __init__ ( self , app , config ) : [EOL] self . app = app [EOL] self . config = config [EOL] BaseApplication . __init__ ( self ) [EOL] [EOL] def load_config ( self ) : [EOL] for key , value in self . config . items ( ) : [EOL] if key in self . cfg . settings and value is not None : [EOL] self . cfg . set ( key , value ) [EOL] [EOL] def init ( self , parser , opts , args ) : [EOL] pass [EOL] [EOL] def load ( self ) : [EOL] return self . app [EOL] [EOL] def stop ( self , * args , ** kwargs ) : [EOL] logger . info ( [string] ) [EOL] [EOL] [EOL] def make_gunicorn_app ( env , forecaster_type , settings , ) : [EOL] if forecaster_type is not None : [EOL] logger . info ( f" [string] " ) [EOL] [EOL] ctor = forecaster_type . from_hyperparameters [EOL] [EOL] forecaster_fq_name = fqname_for ( forecaster_type ) [EOL] forecaster_version = forecaster_type . __version__ [EOL] [EOL] def predictor_factory ( request ) : [EOL] return ctor ( ** request [ [string] ] ) [EOL] [EOL] else : [EOL] logger . info ( f" [string] " ) [EOL] [EOL] assert env is not None [EOL] predictor = Predictor . deserialize ( env . path . model ) [EOL] [EOL] forecaster_fq_name = fqname_for ( type ( predictor ) ) [EOL] forecaster_version = predictor . __version__ [EOL] [EOL] def predictor_factory ( request ) : [EOL] return predictor [EOL] [EOL] logger . info ( f" [string] { gluonts . __version__ }" ) [EOL] logger . info ( f" [string] { forecaster_fq_name } [string] { forecaster_version }" ) [EOL] [EOL] execution_params = { [string] : settings . number_of_workers , [string] : settings . sagemaker_batch_strategy , [string] : settings . sagemaker_max_payload_in_mb , } [EOL] [EOL] flask_app = make_app ( predictor_factory , execution_params , batch_transform_config = env . batch_config , settings = settings , ) [EOL] [EOL] gunicorn_app = Application ( app = flask_app , config = { [string] : settings . sagemaker_server_bind , [string] : settings . number_of_workers , [string] : settings . sagemaker_server_timeout , } , ) [EOL] [EOL] return gunicorn_app [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 $ipaddress.IPv4Address$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 $builtins.int$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.bool$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $flask.Flask$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $Application$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.predictor.Predictor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.predictor.Predictor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] from typing import Callable , Iterable , List , Tuple [EOL] import typing [EOL] import builtins [EOL] import flask [EOL] import json [EOL] import logging [EOL] import os [EOL] import signal [EOL] import time [EOL] import traceback [EOL] import multiprocessing as mp [EOL] from queue import Empty as QueueEmpty [EOL] from typing import Callable , Iterable , List , Tuple [EOL] [EOL] from flask import Flask , Response , jsonify , request [EOL] from pydantic import BaseModel [EOL] [EOL] from gluonts . dataset . common import ListDataset [EOL] from gluonts . model . forecast import Config as ForecastConfig [EOL] from gluonts . shell . util import forecaster_type_by_name [EOL] [EOL] from . util import jsonify_floats [EOL] [EOL] logger = logging . getLogger ( [string] ) [EOL] [EOL] [EOL] class InferenceRequest ( BaseModel ) : [EOL] instances = ... [EOL] configuration = ... [EOL] [EOL] [EOL] class ThrougputIter : [EOL] def __init__ ( self , iterable ) : [EOL] self . iter = iter ( iterable ) [EOL] self . timings = [ ] [EOL] [EOL] def __iter__ ( self ) : [EOL] try : [EOL] while True : [EOL] start = time . time ( ) [EOL] element = next ( self . iter ) [EOL] self . timings . append ( time . time ( ) - start ) [EOL] yield element [EOL] except StopIteration : [EOL] return None [EOL] [EOL] [EOL] def log_throughput ( instances , timings ) : [EOL] item_lengths = [ len ( item [ [string] ] ) for item in instances ] [EOL] [EOL] if timings : [EOL] total_time = sum ( timings ) [EOL] avg_time = total_time / len ( timings ) [EOL] logger . info ( [string] f"{ total_time : [string] } [string] { len ( timings ) } [string] " f"{ avg_time : [string] } [string] " ) [EOL] for idx , ( duration , input_length ) in enumerate ( zip ( timings , item_lengths ) , start = [number] ) : [EOL] logger . info ( f" [string] { idx } [string] { duration : [string] } [string] { input_length } [string] " ) [EOL] else : [EOL] logger . info ( [string] ) [EOL] [EOL] [EOL] def get_base_app ( execution_params ) : [EOL] app = Flask ( [string] ) [EOL] [EOL] @ app . errorhandler ( Exception ) def handle_error ( error ) : [EOL] return traceback . format_exc ( ) , [number] [EOL] [EOL] @ app . route ( [string] ) def ping ( ) : [EOL] return [string] [EOL] [EOL] @ app . route ( [string] ) def execution_parameters ( ) : [EOL] return jsonify ( execution_params ) [EOL] [EOL] return app [EOL] [EOL] [EOL] def handle_predictions ( predictor , instances , configuration ) : [EOL] [comment] [EOL] forecasts = ThrougputIter ( predictor . predict ( ListDataset ( instances , predictor . freq ) , num_samples = configuration . num_samples , ) ) [EOL] [EOL] predictions = [ forecast . as_json_dict ( configuration ) for forecast in forecasts ] [EOL] [EOL] log_throughput ( instances , forecasts . timings ) [EOL] return predictions [EOL] [EOL] [EOL] def inference_invocations ( predictor_factory ) : [EOL] def invocations ( ) : [EOL] predictor = predictor_factory ( request . json ) [EOL] req = InferenceRequest . parse_obj ( request . json ) [EOL] [EOL] predictions = handle_predictions ( predictor , req . instances , req . configuration ) [EOL] return jsonify ( predictions = jsonify_floats ( predictions ) ) [EOL] [EOL] return invocations [EOL] [EOL] [EOL] def do ( fn , args , queue ) : [EOL] queue . put ( fn ( * args ) ) [EOL] [EOL] [EOL] def with_timeout ( fn , args , timeout ) : [EOL] queue = mp . Queue ( ) [EOL] process = mp . Process ( target = do , args = ( fn , args , queue ) ) [EOL] process . start ( ) [EOL] [EOL] try : [EOL] return queue . get ( True , timeout = timeout ) [EOL] except QueueEmpty : [EOL] os . kill ( process . pid , signal . SIGKILL ) [EOL] return None [EOL] [EOL] [EOL] def make_predictions ( predictor , dataset , configuration ) : [EOL] DEBUG = configuration . dict ( ) . get ( [string] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] start = time . time ( ) [EOL] [EOL] predictions = [ ] [EOL] [EOL] forecast_iter = predictor . predict ( dataset , num_samples = configuration . num_samples , ) [EOL] [EOL] for forecast in forecast_iter : [EOL] end = time . time ( ) [EOL] prediction = forecast . as_json_dict ( configuration ) [EOL] [EOL] if DEBUG : [EOL] prediction [ [string] ] = { [string] : end - start } [EOL] [EOL] predictions . append ( prediction ) [EOL] [EOL] start = time . time ( ) [EOL] [EOL] return predictions [EOL] [EOL] [EOL] def batch_inference_invocations ( predictor_factory , configuration , settings ) : [EOL] predictor = predictor_factory ( { [string] : configuration . dict ( ) } ) [EOL] [EOL] scored_instances = [ ] [EOL] last_scored = [ time . time ( ) ] [EOL] [EOL] def invocations ( ) : [EOL] request_data = request . data . decode ( [string] ) . strip ( ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] if request_data : [EOL] instances = list ( map ( json . loads , request_data . split ( [string] ) ) ) [EOL] else : [EOL] instances = [ ] [EOL] [EOL] dataset = ListDataset ( instances , predictor . freq ) [EOL] [EOL] if settings . gluonts_batch_timeout > [number] : [EOL] predictions = with_timeout ( make_predictions , args = ( predictor , dataset , configuration ) , timeout = settings . gluonts_batch_timeout , ) [EOL] [EOL] [comment] [EOL] if predictions is None : [EOL] logger . warning ( f" [string] { request_data }" ) [EOL] FallbackPredictor = forecaster_type_by_name ( settings . gluonts_batch_fallback_predictor ) [EOL] fallback_predictor = FallbackPredictor ( freq = predictor . freq , prediction_length = predictor . prediction_length , ) [EOL] [EOL] predictions = make_predictions ( fallback_predictor , dataset , configuration ) [EOL] else : [EOL] predictions = make_predictions ( predictor , dataset , configuration ) [EOL] [EOL] scored_instances . append ( len ( predictions ) ) [EOL] N = [number] [EOL] diff = time . time ( ) - last_scored [ [number] ] [EOL] if diff > N : [EOL] logger . info ( f" [string] { os . getpid ( ) } [string] { sum ( scored_instances ) } [string] " f"{ int ( diff ) } [string] " ) [EOL] scored_instances . clear ( ) [EOL] last_scored [ [number] ] = time . time ( ) [EOL] [EOL] lines = list ( map ( json . dumps , map ( jsonify_floats , predictions ) ) ) [EOL] return Response ( [string] . join ( lines ) , mimetype = [string] ) [EOL] [EOL] return invocations [EOL] [EOL] [EOL] def make_app ( predictor_factory , execution_params , batch_transform_config , settings ) : [EOL] app = get_base_app ( execution_params ) [EOL] [EOL] if batch_transform_config is not None : [EOL] invocations_fn = batch_inference_invocations ( predictor_factory , batch_transform_config , settings ) [EOL] else : [EOL] invocations_fn = inference_invocations ( predictor_factory ) [EOL] [EOL] app . route ( [string] , methods = [ [string] ] ) ( invocations_fn ) [EOL] return app [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.list$ 0 0 0 $gluonts.model.forecast.Config$ 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $typing.Iterable$ 0 0 0 0 0 0 0 0 0 $typing.Iterable$ 0 0 0 0 $typing.List[builtins.float]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.str,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $flask.Response$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Callable[[],flask.Response]$ 0 0 0 0 0 0 $flask.Response$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Callable[[],flask.Response]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $flask.Response$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import numpy as np [EOL] [EOL] [EOL] def jsonify_floats ( json_object ) : [EOL] [docstring] [EOL] if isinstance ( json_object , dict ) : [EOL] return { k : jsonify_floats ( v ) for k , v in json_object . items ( ) } [EOL] elif isinstance ( json_object , list ) : [EOL] return [ jsonify_floats ( item ) for item in json_object ] [EOL] elif isinstance ( json_object , float ) : [EOL] if np . isnan ( json_object ) : [EOL] return [string] [EOL] elif np . isposinf ( json_object ) : [EOL] return [string] [EOL] elif np . isneginf ( json_object ) : [EOL] return [string] [EOL] return json_object [EOL] return json_object [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Optional , Dict [EOL] import pathlib [EOL] import gluonts [EOL] import path [EOL] import typing [EOL] import builtins [EOL] from distutils . util import strtobool [EOL] import json [EOL] import logging [EOL] import os [EOL] from pathlib import Path [EOL] from pydantic import BaseModel [EOL] from typing import Dict , Optional [EOL] [EOL] [comment] [EOL] from gluonts . dataset . common import Dataset , FileDataset , ListDataset , MetaData [EOL] from gluonts . model . forecast import Config as ForecastConfig [EOL] from gluonts . support . util import map_dct_values [EOL] [EOL] [comment] [EOL] from . params import decode_sagemaker_parameters [EOL] from . path import ServePaths , TrainPaths [EOL] [EOL] [EOL] class DataConfig ( BaseModel ) : [EOL] ContentType = None [EOL] [EOL] [EOL] [comment] [EOL] DATASET_NAMES = [string] , [string] [EOL] [EOL] [EOL] class TrainEnv : [EOL] def __init__ ( self , path ) : [EOL] self . path = path [EOL] self . inputdataconfig = _load_inputdataconfig ( self . path . inputdataconfig ) [EOL] self . channels = _load_channels ( self . path , self . inputdataconfig ) [EOL] self . hyperparameters = _load_hyperparameters ( self . path . hyperparameters , self . channels ) [EOL] self . current_host = _get_current_host ( self . path . resourceconfig ) [EOL] self . datasets = _load_datasets ( self . hyperparameters , self . channels ) [EOL] [EOL] [EOL] class ServeEnv : [EOL] path = ... [EOL] batch_config = ... [EOL] [EOL] def __init__ ( self , path = Path ( [string] ) ) : [EOL] self . path = ServePaths ( path ) [EOL] [EOL] batch_transform = os . environ . get ( [string] , [string] ) == [string] [EOL] if batch_transform : [EOL] self . batch_config = ForecastConfig . parse_raw ( os . environ [ [string] ] ) [EOL] else : [EOL] self . batch_config = None [EOL] [EOL] [EOL] def _load_inputdataconfig ( inputdataconfig , ) : [EOL] if inputdataconfig . exists ( ) : [EOL] with inputdataconfig . open ( ) as json_file : [EOL] return map_dct_values ( DataConfig . parse_obj , json . load ( json_file ) ) [EOL] [EOL] return None [EOL] [EOL] [EOL] def _load_channels ( path , inputdataconfig ) : [EOL] [docstring] [EOL] if inputdataconfig is not None : [EOL] return { name : path . data / name for name in inputdataconfig . keys ( ) } [EOL] else : [EOL] return { channel . name : channel for channel in path . data . iterdir ( ) } [EOL] [EOL] [EOL] def _load_hyperparameters ( path , channels ) : [EOL] with path . open ( ) as json_file : [EOL] hyperparameters = decode_sagemaker_parameters ( json . load ( json_file ) ) [EOL] [EOL] for old_freq_name in [ [string] , [string] , [string] ] : [EOL] if old_freq_name in hyperparameters : [EOL] hyperparameters [ [string] ] = hyperparameters . pop ( old_freq_name ) [EOL] [EOL] if [string] in channels : [EOL] with ( channels [ [string] ] / [string] ) . open ( ) as file : [EOL] metadata = MetaData ( ** json . load ( file ) ) [EOL] hyperparameters . update ( freq = metadata . freq ) [EOL] [EOL] assert [string] in hyperparameters , ( [string] [string] [string] ) [EOL] [EOL] return hyperparameters [EOL] [EOL] [EOL] def _get_current_host ( resourceconfig ) : [EOL] if not resourceconfig . exists ( ) : [EOL] return [string] [EOL] else : [EOL] with resourceconfig . open ( ) as json_file : [EOL] config = json . load ( json_file ) [EOL] return config [ [string] ] [EOL] [EOL] [EOL] def _load_datasets ( hyperparameters , channels ) : [EOL] logger = logging . getLogger ( __name__ ) [EOL] freq = hyperparameters [ [string] ] [EOL] listify_dataset = strtobool ( hyperparameters . get ( [string] , [string] ) ) [EOL] logger . info ( f" [string] { listify_dataset }" ) [EOL] dataset_dict = { } [EOL] for name in DATASET_NAMES : [EOL] if name in channels : [EOL] file_dataset = FileDataset ( channels [ name ] , freq ) [EOL] dataset_dict [ name ] = ( ListDataset ( file_dataset , freq ) [EOL] if listify_dataset [EOL] else file_dataset ) [EOL] logger . info ( f" [string] { name } [string] { type ( dataset_dict [ name ] ) }" ) [EOL] return dataset_dict [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $path.ServePaths$ 0 0 0 $typing.Optional[gluonts.model.forecast.Config]$ 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.Dict[builtins.str,DataConfig]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,pathlib.Path]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,gluonts.dataset.common.Dataset]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] [comment] [EOL] from typing import Any , Union [EOL] import typing [EOL] import builtins [EOL] from typing import Any , Union [EOL] from itertools import count [EOL] [EOL] [comment] [EOL] from gluonts . core . serde import load_json , dump_json [EOL] from gluonts . support . util import map_dct_values [EOL] from gluonts . dataset . util import batcher [EOL] [EOL] [EOL] def decode_sagemaker_parameter ( value ) : [EOL] [docstring] [EOL] value = value . strip ( ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] is_list = value . startswith ( [string] ) and value . endswith ( [string] ) [EOL] is_dict = value . startswith ( [string] ) and value . endswith ( [string] ) [EOL] [EOL] if is_list or is_dict : [EOL] return load_json ( value ) [EOL] else : [EOL] return value [EOL] [EOL] [EOL] def encode_sagemaker_parameter ( value ) : [EOL] [docstring] [EOL] if not isinstance ( value , str ) : [EOL] return dump_json ( value ) [EOL] else : [EOL] return value [EOL] [EOL] [EOL] def decode_sagemaker_parameters ( encoded_params ) : [EOL] [docstring] [EOL] return map_dct_values ( decode_sagemaker_parameter , encoded_params ) [EOL] [EOL] [EOL] def encode_sagemaker_parameters ( decoded_params ) : [EOL] [docstring] [EOL] return map_dct_values ( encode_sagemaker_parameter , decoded_params ) [EOL] [EOL] [EOL] def detrim_and_decode_sagemaker_parameters ( trimmed_params ) : [EOL] [docstring] [EOL] encoded_params = detrim_sagemaker_parameters ( trimmed_params ) [EOL] return map_dct_values ( decode_sagemaker_parameter , encoded_params ) [EOL] [EOL] [EOL] def encode_and_trim_sagemaker_parameters ( decoded_params , max_len = [number] ) : [EOL] [docstring] [EOL] endoded_params = map_dct_values ( encode_sagemaker_parameter , decoded_params ) [EOL] return trim_encoded_sagemaker_parameters ( endoded_params , max_len ) [EOL] [EOL] [EOL] def trim_encoded_sagemaker_parameters ( encoded_params , max_len = [number] ) : [EOL] [docstring] [EOL] trimmed_params = { } [EOL] for key , value in encoded_params . items ( ) : [EOL] if len ( value ) > max_len : [EOL] for idx , substr in enumerate ( batcher ( value , max_len ) ) : [EOL] trimmed_params [ f" [string] { idx } [string] { key }" ] = [string] . join ( substr ) [EOL] else : [EOL] trimmed_params [ key ] = value [EOL] return trimmed_params [EOL] [EOL] [EOL] def detrim_sagemaker_parameters ( trimmed_params ) : [EOL] [docstring] [EOL] detrimmed_params = trimmed_params . copy ( ) [EOL] [EOL] trimmed_param_names = [ param [ [number] : ] for param in detrimmed_params if param . startswith ( [string] ) ] [EOL] [EOL] for name in trimmed_param_names : [EOL] value = [string] [EOL] for idx in count ( ) : [EOL] part = detrimmed_params . pop ( f" [string] { idx } [string] { name }" , None ) [EOL] if part is None : [EOL] break [EOL] value += part [EOL] [EOL] detrimmed_params [ name ] = value [EOL] [EOL] return detrimmed_params [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Union[builtins.list,builtins.dict,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] [comment] [EOL] import pathlib [EOL] from pathlib import Path [EOL] [EOL] [EOL] class TrainPaths : [EOL] def __init__ ( self , base = Path ( [string] ) ) : [EOL] self . base = base . expanduser ( ) . resolve ( ) [EOL] self . config = self . base / [string] / [string] [EOL] self . data = self . base / [string] / [string] [EOL] self . model = self . base / [string] [EOL] self . output = self . base / [string] [EOL] [EOL] self . hyperparameters = self . config / [string] [EOL] self . inputdataconfig = self . config / [string] [EOL] self . resourceconfig = self . config / [string] [EOL] [EOL] self . config . mkdir ( parents = True , exist_ok = True ) [EOL] self . data . mkdir ( parents = True , exist_ok = True ) [EOL] self . model . mkdir ( parents = True , exist_ok = True ) [EOL] self . output . mkdir ( parents = True , exist_ok = True ) [EOL] [EOL] [EOL] class ServePaths : [EOL] def __init__ ( self , base = Path ( [string] ) ) : [EOL] self . base = base . expanduser ( ) . resolve ( ) [EOL] self . model = self . base / [string] [EOL] self . output = self . base / [string] [EOL] [EOL] self . model . mkdir ( parents = True , exist_ok = True ) [EOL] self . output . mkdir ( parents = True , exist_ok = True ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $pathlib.Path$ 0 0 0 0 0 0 0 0 0 0 $pathlib.Path$ 0 $pathlib.Path$ 0 0 0 0 0 0 0 0 0 0 0 $pathlib.Path$ 0 0 0 $pathlib.Path$ 0 0 0 0 0 0 0 $pathlib.Path$ 0 0 0 $pathlib.Path$ 0 0 0 0 0 0 0 $pathlib.Path$ 0 0 0 $pathlib.Path$ 0 0 0 0 0 $pathlib.Path$ 0 0 0 $pathlib.Path$ 0 0 0 0 0 0 $pathlib.Path$ 0 0 0 $pathlib.Path$ 0 0 0 0 0 $pathlib.Path$ 0 0 0 $pathlib.Path$ 0 0 0 0 0 $pathlib.Path$ 0 0 0 $pathlib.Path$ 0 0 0 0 0 0 $pathlib.Path$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pathlib.Path$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pathlib.Path$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pathlib.Path$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $pathlib.Path$ 0 0 0 0 0 0 0 0 0 0 $pathlib.Path$ 0 $pathlib.Path$ 0 0 0 0 0 0 0 0 0 0 0 $pathlib.Path$ 0 0 0 $pathlib.Path$ 0 0 0 0 0 $pathlib.Path$ 0 0 0 $pathlib.Path$ 0 0 0 0 0 0 $pathlib.Path$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pathlib.Path$ 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from . _base import Evaluator , MultivariateEvaluator [EOL] [EOL] __all__ = [ [string] , [string] ] [EOL] [EOL] [comment] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Iterator , Optional , Tuple [EOL] import pandas [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] import logging [EOL] import re [EOL] from typing import Dict , Iterator , NamedTuple , Optional , Tuple [EOL] [EOL] [comment] [EOL] import pandas as pd [EOL] [EOL] [comment] [EOL] import gluonts [comment] [EOL] from gluonts import transform [EOL] from gluonts . core . serde import load_code [EOL] from gluonts . dataset . common import DataEntry , Dataset [EOL] from gluonts . dataset . stat import ( DatasetStatistics , calculate_dataset_statistics , ) [EOL] from gluonts . evaluation import Evaluator [EOL] from gluonts . model . estimator import Estimator [EOL] from gluonts . model . forecast import Forecast [EOL] from gluonts . model . predictor import Predictor [EOL] from gluonts . support . util import maybe_len [EOL] from gluonts . transform import TransformedDataset [EOL] [EOL] [EOL] def make_evaluation_predictions ( dataset , predictor , num_samples ) : [EOL] [docstring] [EOL] [EOL] prediction_length = predictor . prediction_length [EOL] freq = predictor . freq [EOL] lead_time = predictor . lead_time [EOL] [EOL] def add_ts_dataframe ( data_iterator , ) : [EOL] for data_entry in data_iterator : [EOL] data = data_entry . copy ( ) [EOL] index = pd . date_range ( start = data [ [string] ] , freq = freq , periods = data [ [string] ] . shape [ - [number] ] , ) [EOL] data [ [string] ] = pd . DataFrame ( index = index , data = data [ [string] ] . transpose ( ) ) [EOL] yield data [EOL] [EOL] def ts_iter ( dataset ) : [EOL] for data_entry in add_ts_dataframe ( iter ( dataset ) ) : [EOL] yield data_entry [ [string] ] [EOL] [EOL] def truncate_target ( data ) : [EOL] data = data . copy ( ) [EOL] target = data [ [string] ] [EOL] assert ( target . shape [ - [number] ] >= prediction_length ) [comment] [EOL] data [ [string] ] = target [ ... , : - prediction_length - lead_time ] [EOL] return data [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] dataset_trunc = TransformedDataset ( dataset , transformations = [ transform . AdhocTransform ( truncate_target ) ] ) [EOL] [EOL] return ( predictor . predict ( dataset_trunc , num_samples = num_samples ) , ts_iter ( dataset ) , ) [EOL] [EOL] [EOL] train_dataset_stats_key = [string] [EOL] test_dataset_stats_key = [string] [EOL] estimator_key = [string] [EOL] agg_metrics_key = [string] [EOL] [EOL] [EOL] def serialize_message ( logger , message , variable ) : [EOL] logger . info ( f" [string] { message } [string] { variable }" ) [EOL] [EOL] [EOL] def backtest_metrics ( test_dataset , predictor , evaluator = Evaluator ( quantiles = ( [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ) ) , num_samples = [number] , logging_file = None , ) : [EOL] [docstring] [EOL] [EOL] if logging_file is not None : [EOL] log_formatter = logging . Formatter ( [string] , datefmt = [string] , ) [EOL] logger = logging . getLogger ( __name__ ) [EOL] handler = logging . FileHandler ( logging_file ) [EOL] handler . setFormatter ( log_formatter ) [EOL] logger . addHandler ( handler ) [EOL] else : [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] test_statistics = calculate_dataset_statistics ( test_dataset ) [EOL] serialize_message ( logger , test_dataset_stats_key , test_statistics ) [EOL] [EOL] forecast_it , ts_it = make_evaluation_predictions ( test_dataset , predictor = predictor , num_samples = num_samples ) [EOL] [EOL] agg_metrics , item_metrics = evaluator ( ts_it , forecast_it , num_series = maybe_len ( test_dataset ) ) [EOL] [EOL] [comment] [EOL] for name , value in agg_metrics . items ( ) : [EOL] serialize_message ( logger , f" [string] { name }" , value ) [EOL] [EOL] if logging_file is not None : [EOL] [comment] [EOL] [comment] [EOL] logger . removeHandler ( handler ) [EOL] del logger , handler [EOL] [EOL] return agg_metrics , item_metrics [EOL] [EOL] [EOL] [comment] [EOL] class BacktestInformation ( NamedTuple ) : [EOL] train_dataset_stats = ... [EOL] test_dataset_stats = ... [EOL] estimator = ... [EOL] agg_metrics = ... [EOL] [EOL] @ staticmethod def make_from_log ( log_file ) : [EOL] with open ( log_file , [string] ) as f : [EOL] return BacktestInformation . make_from_log_contents ( [string] . join ( f . readlines ( ) ) ) [EOL] [EOL] @ staticmethod def make_from_log_contents ( log_contents ) : [EOL] messages = dict ( re . findall ( [string] , log_contents ) ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] try : [EOL] return BacktestInformation ( train_dataset_stats = eval ( messages [ train_dataset_stats_key ] ) , test_dataset_stats = eval ( messages [ test_dataset_stats_key ] ) , estimator = load_code ( messages [ estimator_key ] ) , agg_metrics = { k : load_code ( v ) for k , v in messages . items ( ) if k . startswith ( [string] ) and v != [string] } , ) [EOL] except Exception as error : [EOL] logging . error ( error ) [EOL] return None [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing.Iterator[gluonts.model.forecast.Forecast],typing.Iterator[pandas.Series]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterator[gluonts.dataset.common.DataEntry]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.stat.DatasetStatistics$ 0 0 0 $gluonts.dataset.stat.DatasetStatistics$ 0 0 0 $gluonts.model.estimator.Estimator$ 0 0 0 $typing.Dict[builtins.str,builtins.float]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Iterator , List , Optional [EOL] import sampler [EOL] import pandas [EOL] import numpy [EOL] import gluonts [EOL] import typing [EOL] import builtins [EOL] from functools import lru_cache [EOL] from typing import Iterator , List , Optional [EOL] [EOL] import numpy as np [EOL] import pandas as pd [EOL] [EOL] from gluonts . core . component import validated [EOL] from gluonts . core . exception import GluonTSDateBoundsError [EOL] from gluonts . dataset . common import DataEntry [EOL] from gluonts . dataset . field_names import FieldName [EOL] [EOL] from . _base import FlatMapTransformation [EOL] from . sampler import ContinuousTimePointSampler , InstanceSampler [EOL] [EOL] [EOL] def shift_timestamp ( ts , offset ) : [EOL] [docstring] [EOL] return _shift_timestamp_helper ( ts , ts . freq , offset ) [EOL] [EOL] [EOL] @ lru_cache ( maxsize = [number] ) def _shift_timestamp_helper ( ts , freq , offset ) : [EOL] [docstring] [EOL] try : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] return ts + offset * ts . freq [EOL] except ( ValueError , pd . _libs . OutOfBoundsDatetime ) as ex : [EOL] raise GluonTSDateBoundsError ( ex ) [EOL] [EOL] [EOL] class InstanceSplitter ( FlatMapTransformation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , target_field , is_pad_field , start_field , forecast_start_field , train_sampler , past_length , future_length , lead_time = [number] , output_NTC = True , time_series_fields = None , pick_incomplete = True , dummy_value = [number] , ) : [EOL] [EOL] assert future_length > [number] [EOL] [EOL] self . train_sampler = train_sampler [EOL] self . past_length = past_length [EOL] self . future_length = future_length [EOL] self . lead_time = lead_time [EOL] self . output_NTC = output_NTC [EOL] self . ts_fields = ( time_series_fields if time_series_fields is not None else [ ] ) [EOL] self . target_field = target_field [EOL] self . is_pad_field = is_pad_field [EOL] self . start_field = start_field [EOL] self . forecast_start_field = forecast_start_field [EOL] self . pick_incomplete = pick_incomplete [EOL] self . dummy_value = dummy_value [EOL] [EOL] def _past ( self , col_name ) : [EOL] return f" [string] { col_name }" [EOL] [EOL] def _future ( self , col_name ) : [EOL] return f" [string] { col_name }" [EOL] [EOL] def flatmap_transform ( self , data , is_train ) : [EOL] pl = self . future_length [EOL] lt = self . lead_time [EOL] slice_cols = self . ts_fields + [ self . target_field ] [EOL] target = data [ self . target_field ] [EOL] [EOL] len_target = target . shape [ - [number] ] [EOL] [EOL] minimum_length = ( self . future_length [EOL] if self . pick_incomplete [EOL] else self . past_length + self . future_length ) + self . lead_time [EOL] [EOL] if is_train : [EOL] sampling_bounds = ( ( [number] , len_target - self . future_length - self . lead_time , ) [comment] [EOL] if self . pick_incomplete [EOL] else ( self . past_length , len_target - self . future_length - self . lead_time , ) ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] sampled_indices = ( np . array ( [ ] , dtype = int ) [EOL] if len_target < minimum_length [EOL] else self . train_sampler ( target , * sampling_bounds ) ) [EOL] else : [EOL] assert self . pick_incomplete or len_target >= self . past_length [EOL] sampled_indices = np . array ( [ len_target ] , dtype = int ) [EOL] for i in sampled_indices : [EOL] pad_length = max ( self . past_length - i , [number] ) [EOL] if not self . pick_incomplete : [EOL] assert ( pad_length == [number] ) , f" [string] { pad_length }" [EOL] d = data . copy ( ) [EOL] for ts_field in slice_cols : [EOL] if i > self . past_length : [EOL] [comment] [EOL] past_piece = d [ ts_field ] [ ... , i - self . past_length : i ] [EOL] elif i < self . past_length : [EOL] pad_block = ( np . ones ( d [ ts_field ] . shape [ : - [number] ] + ( pad_length , ) , dtype = d [ ts_field ] . dtype , ) * self . dummy_value ) [EOL] past_piece = np . concatenate ( [ pad_block , d [ ts_field ] [ ... , : i ] ] , axis = - [number] ) [EOL] else : [EOL] past_piece = d [ ts_field ] [ ... , : i ] [EOL] d [ self . _past ( ts_field ) ] = past_piece [EOL] d [ self . _future ( ts_field ) ] = d [ ts_field ] [ ... , i + lt : i + lt + pl ] [EOL] del d [ ts_field ] [EOL] pad_indicator = np . zeros ( self . past_length ) [EOL] if pad_length > [number] : [EOL] pad_indicator [ : pad_length ] = [number] [EOL] [EOL] if self . output_NTC : [EOL] for ts_field in slice_cols : [EOL] d [ self . _past ( ts_field ) ] = d [ self . _past ( ts_field ) ] . transpose ( ) [EOL] d [ self . _future ( ts_field ) ] = d [ self . _future ( ts_field ) ] . transpose ( ) [EOL] [EOL] d [ self . _past ( self . is_pad_field ) ] = pad_indicator [EOL] d [ self . forecast_start_field ] = shift_timestamp ( d [ self . start_field ] , i + lt ) [EOL] yield d [EOL] [EOL] [EOL] class CanonicalInstanceSplitter ( FlatMapTransformation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , target_field , is_pad_field , start_field , forecast_start_field , instance_sampler , instance_length , output_NTC = True , time_series_fields = [ ] , allow_target_padding = False , pad_value = [number] , use_prediction_features = False , prediction_length = None , ) : [EOL] self . instance_sampler = instance_sampler [EOL] self . instance_length = instance_length [EOL] self . output_NTC = output_NTC [EOL] self . dynamic_feature_fields = time_series_fields [EOL] self . target_field = target_field [EOL] self . allow_target_padding = allow_target_padding [EOL] self . pad_value = pad_value [EOL] self . is_pad_field = is_pad_field [EOL] self . start_field = start_field [EOL] self . forecast_start_field = forecast_start_field [EOL] [EOL] assert ( not use_prediction_features or prediction_length is not None ) , [string] [EOL] [EOL] self . use_prediction_features = use_prediction_features [EOL] self . prediction_length = prediction_length [EOL] [EOL] def _past ( self , col_name ) : [EOL] return f" [string] { col_name }" [EOL] [EOL] def _future ( self , col_name ) : [EOL] return f" [string] { col_name }" [EOL] [EOL] def flatmap_transform ( self , data , is_train ) : [EOL] ts_fields = self . dynamic_feature_fields + [ self . target_field ] [EOL] ts_target = data [ self . target_field ] [EOL] [EOL] len_target = ts_target . shape [ - [number] ] [EOL] [EOL] if is_train : [EOL] if len_target < self . instance_length : [EOL] sampling_indices = ( [ len_target ] [EOL] if self . allow_target_padding [EOL] else [ ] ) [EOL] else : [EOL] sampling_indices = self . instance_sampler ( ts_target , self . instance_length , len_target ) [EOL] else : [EOL] sampling_indices = [ len_target ] [EOL] [EOL] for i in sampling_indices : [EOL] d = data . copy ( ) [EOL] [EOL] pad_length = max ( self . instance_length - i , [number] ) [EOL] [EOL] [comment] [EOL] d [ self . start_field ] = shift_timestamp ( data [ self . start_field ] , i - self . instance_length ) [EOL] [EOL] [comment] [EOL] is_pad = np . zeros ( self . instance_length ) [EOL] if pad_length > [number] : [EOL] is_pad [ : pad_length ] = [number] [EOL] d [ self . is_pad_field ] = is_pad [EOL] [EOL] [comment] [EOL] for ts_field in ts_fields : [EOL] full_ts = data [ ts_field ] [EOL] if pad_length > [number] : [EOL] pad_pre = self . pad_value * np . ones ( shape = full_ts . shape [ : - [number] ] + ( pad_length , ) ) [EOL] past_ts = np . concatenate ( [ pad_pre , full_ts [ ... , : i ] ] , axis = - [number] ) [EOL] else : [EOL] past_ts = full_ts [ ... , ( i - self . instance_length ) : i ] [EOL] [EOL] past_ts = past_ts . transpose ( ) if self . output_NTC else past_ts [EOL] d [ self . _past ( ts_field ) ] = past_ts [EOL] [EOL] if self . use_prediction_features and not is_train : [EOL] if not ts_field == self . target_field : [EOL] future_ts = full_ts [ ... , i : i + self . prediction_length ] [EOL] future_ts = ( future_ts . transpose ( ) [EOL] if self . output_NTC [EOL] else future_ts ) [EOL] d [ self . _future ( ts_field ) ] = future_ts [EOL] [EOL] del d [ ts_field ] [EOL] [EOL] d [ self . forecast_start_field ] = shift_timestamp ( d [ self . start_field ] , self . instance_length ) [EOL] [EOL] yield d [EOL] [EOL] [EOL] class ContinuousTimeInstanceSplitter ( FlatMapTransformation ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , past_interval_length , future_interval_length , train_sampler , target_field = FieldName . TARGET , start_field = FieldName . START , end_field = [string] , forecast_start_field = FieldName . FORECAST_START , ) : [EOL] [EOL] assert ( future_interval_length > [number] ) , [string] [EOL] [EOL] self . train_sampler = train_sampler [EOL] self . past_interval_length = past_interval_length [EOL] self . future_interval_length = future_interval_length [EOL] self . target_field = target_field [EOL] self . start_field = start_field [EOL] self . end_field = end_field [EOL] self . forecast_start_field = forecast_start_field [EOL] [EOL] [comment] [EOL] def _mask_sorted ( self , a , lb , ub ) : [EOL] start = np . searchsorted ( a , lb ) [EOL] end = np . searchsorted ( a , ub ) [EOL] return np . arange ( start , end ) [EOL] [EOL] def flatmap_transform ( self , data , is_train ) : [EOL] [EOL] assert data [ self . start_field ] . freq == data [ self . end_field ] . freq [EOL] [EOL] total_interval_length = ( data [ self . end_field ] - data [ self . start_field ] ) / data [ self . start_field ] . freq . delta [EOL] [EOL] [comment] [EOL] if is_train : [EOL] if total_interval_length < ( self . future_interval_length + self . past_interval_length ) : [EOL] sampling_times = np . array ( [ ] ) [EOL] else : [EOL] sampling_times = self . train_sampler ( self . past_interval_length , total_interval_length - self . future_interval_length , ) [EOL] else : [EOL] sampling_times = np . array ( [ total_interval_length ] ) [EOL] [EOL] ia_times = data [ self . target_field ] [ [number] , : ] [EOL] marks = data [ self . target_field ] [ [number] : , : ] [EOL] [EOL] ts = np . cumsum ( ia_times ) [EOL] assert ts [ - [number] ] < total_interval_length , ( [string] [string] ) [EOL] [EOL] [comment] [EOL] keep_cols = { k : v for k , v in data . items ( ) if k not in [ self . target_field , self . start_field , self . end_field ] } [EOL] [EOL] for future_start in sampling_times : [EOL] [EOL] r = dict ( ) [EOL] [EOL] past_start = future_start - self . past_interval_length [EOL] future_end = future_start + self . future_interval_length [EOL] [EOL] assert past_start >= [number] [EOL] [EOL] past_mask = self . _mask_sorted ( ts , past_start , future_start ) [EOL] [EOL] past_ia_times = np . diff ( np . r_ [ [number] , ts [ past_mask ] - past_start ] ) [ np . newaxis ] [EOL] [EOL] r [ f" [string] { self . target_field }" ] = np . concatenate ( [ past_ia_times , marks [ : , past_mask ] ] , axis = [number] ) . transpose ( ) [EOL] [EOL] r [ [string] ] = np . array ( [ len ( past_mask ) ] ) [EOL] [EOL] r [ self . forecast_start_field ] = ( data [ self . start_field ] + data [ self . start_field ] . freq . delta * future_start ) [EOL] [EOL] if is_train : [comment] [EOL] assert future_end <= total_interval_length [EOL] [EOL] future_mask = self . _mask_sorted ( ts , future_start , future_end ) [EOL] [EOL] future_ia_times = np . diff ( np . r_ [ [number] , ts [ future_mask ] - future_start ] ) [ np . newaxis ] [EOL] [EOL] r [ f" [string] { self . target_field }" ] = np . concatenate ( [ future_ia_times , marks [ : , future_mask ] ] , axis = [number] ) . transpose ( ) [EOL] [EOL] r [ [string] ] = np . array ( [ len ( future_mask ) ] ) [EOL] [EOL] [comment] [EOL] r . update ( keep_cols . copy ( ) ) [EOL] [EOL] yield r [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.Timestamp$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.Timestamp$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.List[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.List[builtins.str]]$ 0 $typing.Optional[typing.List[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterator[gluonts.dataset.common.DataEntry]$ 0 0 0 $gluonts.dataset.common.DataEntry$ 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterator[gluonts.dataset.common.DataEntry]$ 0 0 0 $gluonts.dataset.common.DataEntry$ 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 $builtins.float$ 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 $builtins.float$ 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterator[gluonts.dataset.common.DataEntry]$ 0 0 0 $gluonts.dataset.common.DataEntry$ 0 $builtins.bool$ 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Iterator , List , Optional , Tuple [EOL] import numpy [EOL] import builtins [EOL] import gluonts [EOL] import typing [EOL] from typing import Iterator , List , Optional , Tuple [EOL] [EOL] import numpy as np [EOL] [EOL] from gluonts . core . component import DType , validated [EOL] from gluonts . core . exception import assert_data_error [EOL] from gluonts . dataset . common import DataEntry [EOL] from gluonts . model . common import Tensor [EOL] from gluonts . support . util import erf , erfinv [EOL] [EOL] from . _base import ( FlatMapTransformation , MapTransformation , SimpleTransformation , ) [EOL] [EOL] [EOL] class AsNumpyArray ( SimpleTransformation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , field , expected_ndim , dtype = np . float32 ) : [EOL] self . field = field [EOL] self . expected_ndim = expected_ndim [EOL] self . dtype = dtype [EOL] [EOL] def transform ( self , data ) : [EOL] value = np . asarray ( data [ self . field ] , dtype = self . dtype ) [EOL] [EOL] assert_data_error ( value . ndim == self . expected_ndim , [string] [string] [string] , value = value , self = self , ) [EOL] data [ self . field ] = value [EOL] return data [EOL] [EOL] [EOL] class ExpandDimArray ( SimpleTransformation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , field , axis = None ) : [EOL] self . field = field [EOL] self . axis = axis [EOL] [EOL] def transform ( self , data ) : [EOL] if self . axis is not None : [EOL] data [ self . field ] = np . expand_dims ( data [ self . field ] , axis = self . axis ) [EOL] return data [EOL] [EOL] [EOL] class VstackFeatures ( SimpleTransformation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , output_field , input_fields , drop_inputs = True , h_stack = False , ) : [EOL] self . output_field = output_field [EOL] self . input_fields = input_fields [EOL] self . cols_to_drop = ( [ ] [EOL] if not drop_inputs [EOL] else [ fname for fname in self . input_fields if fname != output_field ] ) [EOL] self . h_stack = h_stack [EOL] [EOL] def transform ( self , data ) : [EOL] r = [ data [ fname ] for fname in self . input_fields if data [ fname ] is not None ] [EOL] output = np . vstack ( r ) if not self . h_stack else np . hstack ( r ) [EOL] data [ self . output_field ] = output [EOL] for fname in self . cols_to_drop : [EOL] del data [ fname ] [EOL] return data [EOL] [EOL] [EOL] class ConcatFeatures ( SimpleTransformation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , output_field , input_fields , drop_inputs = True , ) : [EOL] self . output_field = output_field [EOL] self . input_fields = input_fields [EOL] self . cols_to_drop = ( [ ] [EOL] if not drop_inputs [EOL] else [ fname for fname in self . input_fields if fname != output_field ] ) [EOL] [EOL] def transform ( self , data ) : [EOL] r = [ data [ fname ] for fname in self . input_fields if data [ fname ] is not None ] [EOL] output = np . concatenate ( r ) [EOL] data [ self . output_field ] = output [EOL] for fname in self . cols_to_drop : [EOL] del data [ fname ] [EOL] return data [EOL] [EOL] [EOL] class SwapAxes ( SimpleTransformation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , input_fields , axes ) : [EOL] self . input_fields = input_fields [EOL] self . axis1 , self . axis2 = axes [EOL] [EOL] def transform ( self , data ) : [EOL] for field in self . input_fields : [EOL] data [ field ] = self . swap ( data [ field ] ) [EOL] return data [EOL] [EOL] def swap ( self , v ) : [EOL] if isinstance ( v , np . ndarray ) : [EOL] return np . swapaxes ( v , self . axis1 , self . axis2 ) [EOL] if isinstance ( v , list ) : [EOL] return [ self . swap ( x ) for x in v ] [EOL] else : [EOL] raise ValueError ( f" [string] { type ( v ) . __name__ } [string] " f" [string] " ) [EOL] [EOL] [EOL] class ListFeatures ( SimpleTransformation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , output_field , input_fields , drop_inputs = True , ) : [EOL] self . output_field = output_field [EOL] self . input_fields = input_fields [EOL] self . cols_to_drop = ( [ ] [EOL] if not drop_inputs [EOL] else [ fname for fname in self . input_fields if fname != output_field ] ) [EOL] [EOL] def transform ( self , data ) : [EOL] data [ self . output_field ] = [ data [ fname ] for fname in self . input_fields ] [EOL] for fname in self . cols_to_drop : [EOL] del data [ fname ] [EOL] return data [EOL] [EOL] [EOL] class TargetDimIndicator ( SimpleTransformation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , field_name , target_field ) : [EOL] self . field_name = field_name [EOL] self . target_field = target_field [EOL] [EOL] def transform ( self , data ) : [EOL] data [ self . field_name ] = np . arange ( [number] , data [ self . target_field ] . shape [ [number] ] ) [EOL] return data [EOL] [EOL] [EOL] class SampleTargetDim ( FlatMapTransformation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , field_name , target_field , observed_values_field , num_samples , shuffle = True , ) : [EOL] self . field_name = field_name [EOL] self . target_field = target_field [EOL] self . observed_values_field = observed_values_field [EOL] self . num_samples = num_samples [EOL] self . shuffle = shuffle [EOL] [EOL] def flatmap_transform ( self , data , is_train , slice_future_target = True ) : [EOL] if not is_train : [EOL] yield data [EOL] else : [EOL] [comment] [EOL] target_dimensions = data [ self . field_name ] [EOL] [EOL] if self . shuffle : [EOL] np . random . shuffle ( target_dimensions ) [EOL] [EOL] target_dimensions = target_dimensions [ : self . num_samples ] [EOL] [EOL] data [ self . field_name ] = target_dimensions [EOL] [comment] [EOL] [EOL] for field in [ f" [string] { self . target_field }" , f" [string] { self . target_field }" , f" [string] { self . observed_values_field }" , f" [string] { self . observed_values_field }" , ] : [EOL] data [ field ] = data [ field ] [ : , target_dimensions ] [EOL] [EOL] yield data [EOL] [EOL] [EOL] class CDFtoGaussianTransform ( MapTransformation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , target_dim , target_field , observed_values_field , cdf_suffix = [string] , max_context_length = None , ) : [EOL] [docstring] [EOL] self . target_field = target_field [EOL] self . past_target_field = [string] + self . target_field [EOL] self . future_target_field = [string] + self . target_field [EOL] self . past_observed_field = f" [string] { observed_values_field }" [EOL] self . sort_target_field = f" [string] { target_field } [string] " [EOL] self . slopes_field = [string] [EOL] self . intercepts_field = [string] [EOL] self . cdf_suffix = cdf_suffix [EOL] self . max_context_length = max_context_length [EOL] self . target_dim = target_dim [EOL] [EOL] def map_transform ( self , data , is_train ) : [EOL] self . _preprocess_data ( data , is_train = is_train ) [EOL] self . _calc_pw_linear_params ( data ) [EOL] [EOL] for target_field in [ self . past_target_field , self . future_target_field ] : [EOL] data [ target_field + self . cdf_suffix ] = self . standard_gaussian_ppf ( self . _empirical_cdf_forward_transform ( data [ self . sort_target_field ] , data [ target_field ] , data [ self . slopes_field ] , data [ self . intercepts_field ] , ) ) [EOL] return data [EOL] [EOL] def _preprocess_data ( self , data , is_train ) : [EOL] [docstring] [EOL] [comment] [EOL] past_target_vec = data [ self . past_target_field ] . copy ( ) [EOL] [EOL] [comment] [EOL] target_length , target_dim = past_target_vec . shape [EOL] [EOL] [comment] [EOL] past_observed = ( data [ self . past_observed_field ] > [number] ) * ( data [ [string] ] . reshape ( ( - [number] , [number] ) ) == [number] ) [EOL] assert past_observed . ndim == [number] [EOL] assert target_dim == self . target_dim [EOL] [EOL] past_target_vec = past_target_vec [ past_observed . min ( axis = [number] ) ] [EOL] [EOL] assert past_target_vec . ndim == [number] [EOL] assert past_target_vec . shape [ [number] ] == self . target_dim [EOL] [EOL] expected_length = ( target_length [EOL] if self . max_context_length is None [EOL] else self . max_context_length ) [EOL] [EOL] if target_length != expected_length : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] past_target_vec = CDFtoGaussianTransform . _fill ( past_target_vec , expected_length ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] if is_train : [EOL] past_target_vec = self . _add_noise ( past_target_vec ) [EOL] [EOL] past_target_vec . sort ( axis = [number] ) [EOL] [EOL] assert past_target_vec . shape == ( expected_length , self . target_dim ) [EOL] [EOL] data [ self . sort_target_field ] = past_target_vec [EOL] [EOL] def _calc_pw_linear_params ( self , data ) : [EOL] [docstring] [EOL] sorted_target = data [ self . sort_target_field ] [EOL] sorted_target_length , target_dim = sorted_target . shape [EOL] [EOL] quantiles = np . stack ( [ np . arange ( sorted_target_length ) for _ in range ( target_dim ) ] , axis = [number] , ) / float ( sorted_target_length ) [EOL] [EOL] x_diff = np . diff ( sorted_target , axis = [number] ) [EOL] y_diff = np . diff ( quantiles , axis = [number] ) [EOL] [EOL] [comment] [EOL] slopes = np . where ( x_diff == [number] , np . zeros_like ( x_diff ) , y_diff / x_diff ) [EOL] [EOL] zeroes = np . zeros_like ( np . expand_dims ( slopes [ [number] , : ] , axis = [number] ) ) [EOL] slopes = np . append ( slopes , zeroes , axis = [number] ) [EOL] [EOL] [comment] [EOL] intercepts = quantiles - slopes * sorted_target [EOL] [EOL] [comment] [EOL] data [ self . slopes_field ] = slopes [EOL] data [ self . intercepts_field ] = intercepts [EOL] [EOL] def _empirical_cdf_forward_transform ( self , sorted_values , values , slopes , intercepts , ) : [EOL] [docstring] [EOL] m = sorted_values . shape [ [number] ] [EOL] quantiles = self . _forward_transform ( sorted_values , values , slopes , intercepts ) [EOL] [EOL] quantiles = np . clip ( quantiles , self . winsorized_cutoff ( m ) , [number] - self . winsorized_cutoff ( m ) ) [EOL] return quantiles [EOL] [EOL] @ staticmethod def _add_noise ( x ) : [EOL] scale_noise = [number] [EOL] std = np . sqrt ( ( np . square ( x - x . mean ( axis = [number] , keepdims = True ) ) ) . mean ( axis = [number] , keepdims = True ) ) [EOL] noise = np . random . normal ( loc = np . zeros_like ( x ) , scale = np . ones_like ( x ) * std * scale_noise ) [EOL] x = x + noise [EOL] return x [EOL] [EOL] @ staticmethod def _search_sorted ( sorted_vec , to_insert_vec ) : [EOL] [docstring] [EOL] indices_left = np . searchsorted ( sorted_vec , to_insert_vec , side = [string] ) [EOL] indices_right = np . searchsorted ( sorted_vec , to_insert_vec , side = [string] ) [EOL] [EOL] indices = indices_left + ( indices_right - indices_left ) // [number] [EOL] indices = indices - [number] [EOL] indices = np . minimum ( indices , len ( sorted_vec ) - [number] ) [EOL] indices [ indices < [number] ] = [number] [EOL] return indices [EOL] [EOL] def _forward_transform ( self , sorted_vec , target , slopes , intercepts , ) : [EOL] [docstring] [EOL] transformed = list ( ) [EOL] for sorted , t , slope , intercept in zip ( sorted_vec . transpose ( ) , target . transpose ( ) , slopes . transpose ( ) , intercepts . transpose ( ) , ) : [EOL] indices = self . _search_sorted ( sorted , t ) [EOL] transformed_value = slope [ indices ] * t + intercept [ indices ] [EOL] transformed . append ( transformed_value ) [EOL] return np . array ( transformed ) . transpose ( ) [EOL] [EOL] @ staticmethod def standard_gaussian_cdf ( x ) : [EOL] u = x / ( np . sqrt ( [number] ) ) [EOL] return ( erf ( np , u ) + [number] ) / [number] [EOL] [EOL] @ staticmethod def standard_gaussian_ppf ( y ) : [EOL] y_clipped = np . clip ( y , a_min = [number] , a_max = [number] - [number] ) [EOL] return np . sqrt ( [number] ) * erfinv ( np , [number] * y_clipped - [number] ) [EOL] [EOL] @ staticmethod def winsorized_cutoff ( m ) : [EOL] [docstring] [EOL] res = [number] / ( [number] * m ** [number] * np . sqrt ( [number] * np . log ( m ) ) ) [EOL] assert [number] < res < [number] [EOL] return res [EOL] [EOL] @ staticmethod def _fill ( target , expected_length ) : [EOL] [docstring] [EOL] [EOL] current_length , target_dim = target . shape [EOL] if current_length == [number] : [EOL] [comment] [EOL] [comment] [EOL] filled_target = np . zeros ( ( expected_length , target_dim ) ) [EOL] elif current_length < expected_length : [EOL] filled_target = np . vstack ( [ target for _ in range ( expected_length // current_length + [number] ) ] ) [EOL] filled_target = filled_target [ : expected_length ] [EOL] elif current_length > expected_length : [EOL] filled_target = target [ - expected_length : ] [EOL] else : [EOL] filled_target = target [EOL] [EOL] assert filled_target . shape == ( expected_length , target_dim ) [EOL] [EOL] return filled_target [EOL] [EOL] [EOL] def cdf_to_gaussian_forward_transform ( input_batch , outputs ) : [EOL] [docstring] [EOL] [EOL] def _empirical_cdf_inverse_transform ( batch_target_sorted , batch_predictions , slopes , intercepts , ) : [EOL] [docstring] [EOL] slopes = slopes . asnumpy ( ) [EOL] intercepts = intercepts . asnumpy ( ) [EOL] [EOL] batch_target_sorted = batch_target_sorted . asnumpy ( ) [EOL] batch_size , num_timesteps , target_dim = batch_target_sorted . shape [EOL] indices = np . floor ( batch_predictions * num_timesteps ) [EOL] [comment] [EOL] [comment] [EOL] indices = np . clip ( indices , [number] , num_timesteps - [number] ) [EOL] indices = indices . astype ( np . int ) [EOL] [EOL] transformed = np . where ( np . take_along_axis ( slopes , indices , axis = [number] ) != [number] , ( batch_predictions - np . take_along_axis ( intercepts , indices , axis = [number] ) ) / np . take_along_axis ( slopes , indices , axis = [number] ) , np . take_along_axis ( batch_target_sorted , indices , axis = [number] ) , ) [EOL] return transformed [EOL] [EOL] [comment] [EOL] batch_size , samples , target_dim , time = outputs . shape [EOL] for sample_index in range ( [number] , samples ) : [EOL] outputs [ : , sample_index , : , : ] = _empirical_cdf_inverse_transform ( input_batch [ [string] ] , CDFtoGaussianTransform . standard_gaussian_cdf ( outputs [ : , sample_index , : , : ] ) , input_batch [ [string] ] , input_batch [ [string] ] , ) [EOL] return outputs [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 $numpy.ndarray$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 $numpy.ndarray$ 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import numpy [EOL] import builtins [EOL] import gluonts [EOL] import numpy as np [EOL] [EOL] from gluonts . core . component import validated [EOL] from gluonts . dataset . stat import ScaleHistogram [EOL] [EOL] [EOL] class InstanceSampler : [EOL] [docstring] [EOL] [EOL] def __call__ ( self , ts , a , b ) : [EOL] raise NotImplementedError ( ) [EOL] [EOL] [EOL] class UniformSplitSampler ( InstanceSampler ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , p ) : [EOL] self . p = p [EOL] [EOL] def __call__ ( self , ts , a , b ) : [EOL] assert ( a <= b ) , [string] [EOL] [EOL] window_size = b - a + [number] [EOL] ( indices , ) = np . where ( np . random . random_sample ( window_size ) < self . p ) [EOL] return indices + a [EOL] [EOL] [EOL] class TestSplitSampler ( InstanceSampler ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self ) : [EOL] pass [EOL] [EOL] def __call__ ( self , ts , a , b ) : [EOL] return np . array ( [ b ] ) [EOL] [EOL] [EOL] class ExpectedNumInstanceSampler ( InstanceSampler ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , num_instances ) : [EOL] self . num_instances = num_instances [EOL] self . total_length = [number] [EOL] self . n = [number] [EOL] [EOL] def __call__ ( self , ts , a , b ) : [EOL] window_size = b - a + [number] [EOL] [EOL] self . n += [number] [EOL] self . total_length += window_size [EOL] avg_length = self . total_length / self . n [EOL] [EOL] sampler = UniformSplitSampler ( self . num_instances / avg_length ) [EOL] return sampler ( ts , a , b ) [EOL] [EOL] [EOL] class BucketInstanceSampler ( InstanceSampler ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , scale_histogram ) : [EOL] [comment] [EOL] [comment] [EOL] self . scale_histogram = scale_histogram [EOL] self . lookup = np . arange ( [number] ** [number] ) [EOL] [EOL] def __call__ ( self , ts , a , b ) : [EOL] while ts . shape [ - [number] ] >= len ( self . lookup ) : [EOL] self . lookup = np . arange ( [number] * len ( self . lookup ) ) [EOL] p = [number] / self . scale_histogram . count ( ts ) [EOL] mask = np . random . uniform ( low = [number] , high = [number] , size = b - a + [number] ) < p [EOL] indices = self . lookup [ a : a + len ( mask ) ] [ mask ] [EOL] return indices [EOL] [EOL] [EOL] class ContinuousTimePointSampler : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , num_instances ) : [EOL] self . num_instances = num_instances [EOL] [EOL] def __call__ ( self , a , b ) : [EOL] [docstring] [EOL] raise NotImplementedError ( ) [EOL] [EOL] [EOL] class ContinuousTimeUniformSampler ( ContinuousTimePointSampler ) : [EOL] [docstring] [EOL] [EOL] def __call__ ( self , a , b ) : [EOL] assert a <= b , [string] [EOL] return np . random . rand ( self . num_instances ) * ( b - a ) + a [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 $numpy.ndarray$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 $numpy.ndarray$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 $numpy.ndarray$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $numpy.ndarray$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 $numpy.ndarray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 $builtins.float$ 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 $builtins.float$ 0 $builtins.float$ 0 0 0 0 $builtins.float$ 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 $builtins.float$ 0 0 $builtins.float$ 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import List , Optional [EOL] import pandas [EOL] import numpy [EOL] import gluonts [EOL] import typing [EOL] import builtins [EOL] from typing import List , Optional [EOL] [EOL] import numpy as np [EOL] import pandas as pd [EOL] [EOL] from gluonts . core . component import DType , validated [EOL] from gluonts . dataset . common import DataEntry [EOL] from gluonts . time_feature import TimeFeature [EOL] [EOL] from . _base import MapTransformation , SimpleTransformation [EOL] from . split import shift_timestamp [EOL] [EOL] [EOL] def target_transformation_length ( target , pred_length , is_train ) : [EOL] return target . shape [ - [number] ] + ( [number] if is_train else pred_length ) [EOL] [EOL] [EOL] class MissingValueImputation : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self ) : [EOL] pass [EOL] [EOL] def __call__ ( self , values ) : [EOL] [docstring] [EOL] raise NotImplementedError ( ) [EOL] [EOL] [EOL] class LeavesMissingValues ( MissingValueImputation ) : [EOL] [docstring] [EOL] [EOL] def __call__ ( self , values ) : [EOL] return values [EOL] [EOL] [EOL] class DummyValueImputation ( MissingValueImputation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , dummy_value = [number] ) : [EOL] self . dummy_value = dummy_value [EOL] [EOL] def __call__ ( self , values ) : [EOL] nan_indices = np . where ( np . isnan ( values ) ) [EOL] values [ nan_indices ] = self . dummy_value [EOL] return values [EOL] [EOL] [EOL] class MeanValueImputation ( MissingValueImputation ) : [EOL] [docstring] [EOL] [EOL] def __call__ ( self , values ) : [EOL] if len ( values ) == [number] : [EOL] return DummyValueImputation ( ) ( values ) [EOL] nan_indices = np . where ( np . isnan ( values ) ) [EOL] values [ nan_indices ] = np . nanmean ( values ) [EOL] return values [EOL] [EOL] [EOL] class LastValueImputation ( MissingValueImputation ) : [EOL] [docstring] [EOL] [EOL] def __call__ ( self , values ) : [EOL] if len ( values ) == [number] : [EOL] return DummyValueImputation ( ) ( values ) [EOL] values = np . expand_dims ( values , axis = [number] ) [EOL] [EOL] mask = np . isnan ( values ) [EOL] idx = np . where ( ~ mask , np . arange ( mask . shape [ [number] ] ) , [number] ) [EOL] np . maximum . accumulate ( idx , axis = [number] , out = idx ) [EOL] out = values [ np . arange ( idx . shape [ [number] ] ) [ : , None ] , idx ] [EOL] [EOL] values = np . squeeze ( out ) [EOL] [comment] [EOL] mask = np . isnan ( values ) [EOL] values [ mask ] = np . interp ( np . flatnonzero ( mask ) , np . flatnonzero ( ~ mask ) , values [ ~ mask ] ) [EOL] [EOL] return values [EOL] [EOL] [EOL] class CausalMeanValueImputation ( MissingValueImputation ) : [EOL] [docstring] [EOL] [EOL] def __call__ ( self , values ) : [EOL] if len ( values ) == [number] : [EOL] return DummyValueImputation ( ) ( values ) [EOL] mask = np . isnan ( values ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] last_value_imputation = LastValueImputation ( ) [EOL] value_no_nans = last_value_imputation ( values ) [EOL] [EOL] [comment] [EOL] adjusted_values_to_causality = np . concatenate ( ( np . repeat ( [number] , [number] ) , value_no_nans [ : - [number] ] ) ) [EOL] cumsum = np . cumsum ( adjusted_values_to_causality ) [EOL] [EOL] [comment] [EOL] indices = np . linspace ( [number] , len ( value_no_nans ) - [number] , len ( value_no_nans ) ) [EOL] [EOL] ar_res = cumsum / indices . astype ( float ) [EOL] values [ mask ] = ar_res [ mask ] [EOL] [EOL] [comment] [EOL] values [ [number] ] = value_no_nans [ [number] ] [EOL] [EOL] return values [EOL] [EOL] [EOL] class RollingMeanValueImputation ( MissingValueImputation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , window_size = [number] ) : [EOL] self . window_size = [number] if window_size < [number] else window_size [EOL] [EOL] def __call__ ( self , values ) : [EOL] if len ( values ) == [number] : [EOL] return DummyValueImputation ( ) ( values ) [EOL] mask = np . isnan ( values ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] last_value_imputation = LastValueImputation ( ) [EOL] value_no_nans = last_value_imputation ( values ) [EOL] [EOL] adjusted_values_to_causality = np . concatenate ( ( np . repeat ( value_no_nans [ [number] ] , self . window_size + [number] ) , value_no_nans [ : - [number] ] , ) ) [EOL] [EOL] cumsum = np . cumsum ( adjusted_values_to_causality ) [EOL] [EOL] ar_res = ( cumsum [ self . window_size : ] - cumsum [ : - self . window_size ] ) / float ( self . window_size ) [EOL] [EOL] values [ mask ] = ar_res [ mask ] [EOL] [EOL] [comment] [EOL] values [ [number] ] = value_no_nans [ [number] ] [EOL] [EOL] return values [EOL] [EOL] [EOL] class AddObservedValuesIndicator ( SimpleTransformation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , target_field , output_field , imputation_method = DummyValueImputation ( [number] ) , dtype = np . float32 , ) : [EOL] self . target_field = target_field [EOL] self . output_field = output_field [EOL] self . dtype = dtype [EOL] self . imputation_method = imputation_method [EOL] [EOL] def transform ( self , data ) : [EOL] value = data [ self . target_field ] [EOL] nan_entries = np . isnan ( value ) [EOL] [EOL] if self . imputation_method is not None : [EOL] data [ self . target_field ] = self . imputation_method ( value ) [EOL] [EOL] data [ self . output_field ] = np . invert ( nan_entries , out = nan_entries ) . astype ( self . dtype , copy = False ) [EOL] return data [EOL] [EOL] [EOL] class AddConstFeature ( MapTransformation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , output_field , target_field , pred_length , const = [number] , dtype = np . float32 , ) : [EOL] self . pred_length = pred_length [EOL] self . const = const [EOL] self . dtype = dtype [EOL] self . output_field = output_field [EOL] self . target_field = target_field [EOL] [EOL] def map_transform ( self , data , is_train ) : [EOL] length = target_transformation_length ( data [ self . target_field ] , self . pred_length , is_train = is_train ) [EOL] data [ self . output_field ] = self . const * np . ones ( shape = ( [number] , length ) , dtype = self . dtype ) [EOL] return data [EOL] [EOL] [EOL] class AddTimeFeatures ( MapTransformation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , start_field , target_field , output_field , time_features , pred_length , dtype = np . float32 , ) : [EOL] self . date_features = time_features [EOL] self . pred_length = pred_length [EOL] self . start_field = start_field [EOL] self . target_field = target_field [EOL] self . output_field = output_field [EOL] self . _min_time_point = None [EOL] self . _max_time_point = None [EOL] self . _full_range_date_features = None [EOL] self . _date_index = None [EOL] self . dtype = dtype [EOL] [EOL] def _update_cache ( self , start , length ) : [EOL] end = shift_timestamp ( start , length ) [EOL] if self . _min_time_point is not None : [EOL] if self . _min_time_point <= start and end <= self . _max_time_point : [EOL] return [EOL] if self . _min_time_point is None : [EOL] self . _min_time_point = start [EOL] self . _max_time_point = end [EOL] self . _min_time_point = min ( shift_timestamp ( start , - [number] ) , self . _min_time_point ) [EOL] self . _max_time_point = max ( shift_timestamp ( end , [number] ) , self . _max_time_point ) [EOL] self . full_date_range = pd . date_range ( self . _min_time_point , self . _max_time_point , freq = start . freq ) [EOL] self . _full_range_date_features = ( np . vstack ( [ feat ( self . full_date_range ) for feat in self . date_features ] ) . astype ( self . dtype ) [EOL] if self . date_features [EOL] else None ) [EOL] self . _date_index = pd . Series ( index = self . full_date_range , data = np . arange ( len ( self . full_date_range ) ) , ) [EOL] [EOL] def map_transform ( self , data , is_train ) : [EOL] start = data [ self . start_field ] [EOL] length = target_transformation_length ( data [ self . target_field ] , self . pred_length , is_train = is_train ) [EOL] self . _update_cache ( start , length ) [EOL] i0 = self . _date_index [ start ] [EOL] features = ( self . _full_range_date_features [ ... , i0 : i0 + length ] [EOL] if self . date_features [EOL] else None ) [EOL] data [ self . output_field ] = features [EOL] return data [EOL] [EOL] [EOL] class AddAgeFeature ( MapTransformation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , target_field , output_field , pred_length , log_scale = True , dtype = np . float32 , ) : [EOL] self . pred_length = pred_length [EOL] self . target_field = target_field [EOL] self . feature_name = output_field [EOL] self . log_scale = log_scale [EOL] self . _age_feature = np . zeros ( [number] ) [EOL] self . dtype = dtype [EOL] [EOL] def map_transform ( self , data , is_train ) : [EOL] length = target_transformation_length ( data [ self . target_field ] , self . pred_length , is_train = is_train ) [EOL] [EOL] if self . log_scale : [EOL] age = np . log10 ( [number] + np . arange ( length , dtype = self . dtype ) ) [EOL] else : [EOL] age = np . arange ( length , dtype = self . dtype ) [EOL] [EOL] data [ self . feature_name ] = age . reshape ( ( [number] , length ) ) [EOL] [EOL] return data [EOL] [EOL] [EOL] class AddAggregateLags ( MapTransformation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , target_field , output_field , pred_length , base_freq , agg_freq , agg_lags , agg_fun = [string] , dtype = np . float32 , ) : [EOL] self . pred_length = pred_length [EOL] self . target_field = target_field [EOL] self . feature_name = output_field [EOL] self . base_freq = base_freq [EOL] self . agg_freq = agg_freq [EOL] self . agg_lags = agg_lags [EOL] self . agg_fun = agg_fun [EOL] self . dtype = dtype [EOL] [EOL] self . ratio = pd . Timedelta ( self . agg_freq ) / pd . Timedelta ( self . base_freq ) [EOL] assert ( self . ratio . is_integer ( ) and self . ratio >= [number] ) , [string] [EOL] self . ratio = int ( self . ratio ) [EOL] [EOL] self . half_window = ( self . ratio - [number] ) // [number] [EOL] self . valid_lags = [ x for x in self . agg_lags if x > ( self . pred_length - [number] + self . half_window ) / self . ratio ] [EOL] [EOL] if set ( self . agg_lags ) - set ( self . valid_lags ) : [EOL] print ( f" [string] { set ( self . agg_lags ) - set ( self . valid_lags ) } [string] " f" [string] { self . agg_freq } [string] " ) [EOL] [EOL] def map_transform ( self , data , is_train ) : [EOL] assert self . base_freq == data [ [string] ] . freq [EOL] [EOL] [comment] [EOL] if is_train : [EOL] t = data [ self . target_field ] [EOL] else : [EOL] t = np . concatenate ( [ data [ self . target_field ] , np . zeros ( shape = ( self . pred_length , ) ) ] , axis = [number] , ) [EOL] [EOL] [comment] [EOL] t_agg = ( pd . Series ( t ) . rolling ( self . ratio ) . agg ( self . agg_fun ) ) [ self . ratio - [number] : ] [EOL] [EOL] [comment] [EOL] agg_vals = np . concatenate ( [ np . zeros ( ( max ( self . valid_lags ) * self . ratio + self . half_window + [number] , ) ) , t_agg . values , ] , axis = [number] , ) [EOL] lags = np . vstack ( [ agg_vals [ - ( l * self . ratio - self . half_window + len ( t ) ) : - ( l * self . ratio - self . half_window ) [EOL] if - ( l * self . ratio - self . half_window ) is not [number] [EOL] else None ] for l in self . valid_lags ] ) [EOL] [EOL] [comment] [EOL] data [ self . feature_name ] = np . nan_to_num ( lags ) [EOL] [EOL] assert data [ self . feature_name ] . shape == ( len ( self . valid_lags ) , len ( data [ self . target_field ] ) + self . pred_length * ( not is_train ) , ) [EOL] [EOL] return data [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 $gluonts.dataset.common.DataEntry$ 0 $builtins.bool$ 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Callable , Iterable , List , Iterator [EOL] import typing [EOL] import builtins [EOL] import gluonts [EOL] import abc [EOL] from typing import Callable , Iterable , Iterator , List [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . dataset . common import DataEntry [EOL] from gluonts . runtime_params import GLUONTS_MAX_IDLE_TRANSFORMS [EOL] [EOL] [EOL] class Transformation ( metaclass = abc . ABCMeta ) : [EOL] [docstring] [EOL] [EOL] @ abc . abstractmethod def __call__ ( self , data_it , is_train ) : [EOL] pass [EOL] [EOL] def chain ( self , other ) : [EOL] return Chain ( self , other ) [EOL] [EOL] def __add__ ( self , other ) : [EOL] return self . chain ( other ) [EOL] [EOL] [EOL] class Chain ( Transformation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , trans ) : [EOL] self . transformations = [ ] [EOL] for transformation in trans : [EOL] [comment] [EOL] if isinstance ( transformation , Chain ) : [EOL] self . transformations . extend ( transformation . transformations ) [EOL] else : [EOL] self . transformations . append ( transformation ) [EOL] [EOL] def __call__ ( self , data_it , is_train ) : [EOL] tmp = data_it [EOL] for t in self . transformations : [EOL] tmp = t ( tmp , is_train ) [EOL] return tmp [EOL] [EOL] [EOL] class Identity ( Transformation ) : [EOL] def __call__ ( self , data_it , is_train ) : [EOL] return data_it [EOL] [EOL] [EOL] class MapTransformation ( Transformation ) : [EOL] [docstring] [EOL] [EOL] def __call__ ( self , data_it , is_train ) : [EOL] for data_entry in data_it : [EOL] try : [EOL] yield self . map_transform ( data_entry . copy ( ) , is_train ) [EOL] except Exception as e : [EOL] raise e [EOL] [EOL] @ abc . abstractmethod def map_transform ( self , data , is_train ) : [EOL] pass [EOL] [EOL] [EOL] class SimpleTransformation ( MapTransformation ) : [EOL] [docstring] [EOL] [EOL] def map_transform ( self , data , is_train ) : [EOL] return self . transform ( data ) [EOL] [EOL] @ abc . abstractmethod def transform ( self , data ) : [EOL] pass [EOL] [EOL] [EOL] class AdhocTransform ( SimpleTransformation ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , func ) : [EOL] self . func = func [EOL] [EOL] def transform ( self , data ) : [EOL] return self . func ( data . copy ( ) ) [EOL] [EOL] [EOL] class FlatMapTransformation ( Transformation ) : [EOL] [docstring] [EOL] [EOL] def __call__ ( self , data_it , is_train ) : [EOL] num_idle_transforms = [number] [EOL] for data_entry in data_it : [EOL] num_idle_transforms += [number] [EOL] try : [EOL] for result in self . flatmap_transform ( data_entry . copy ( ) , is_train ) : [EOL] num_idle_transforms = [number] [EOL] yield result [EOL] except Exception as e : [EOL] raise e [EOL] if num_idle_transforms > GLUONTS_MAX_IDLE_TRANSFORMS : [EOL] raise Exception ( f" [string] " f" [string] " f" [string] { GLUONTS_MAX_IDLE_TRANSFORMS } [string] " f" [string] " f" [string] { self }" ) [EOL] [EOL] @ abc . abstractmethod def flatmap_transform ( self , data , is_train ) : [EOL] pass [EOL] [EOL] [EOL] class FilterTransformation ( FlatMapTransformation ) : [EOL] def __init__ ( self , condition ) : [EOL] self . condition = condition [EOL] [EOL] def flatmap_transform ( self , data , is_train ) : [EOL] if self . condition ( data ) : [EOL] yield data [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterator[gluonts.dataset.common.DataEntry]$ 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterator$ 0 0 0 $typing.Iterable[gluonts.dataset.common.DataEntry]$ 0 $builtins.bool$ 0 0 0 0 0 0 $typing.Iterable[gluonts.dataset.common.DataEntry]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 $gluonts.dataset.common.DataEntry$ 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 $gluonts.dataset.common.DataEntry$ 0 $builtins.bool$ 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterator$ 0 0 0 $typing.Iterable[gluonts.dataset.common.DataEntry]$ 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 $typing.Iterable[gluonts.dataset.common.DataEntry]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterator[gluonts.dataset.common.DataEntry]$ 0 0 0 $gluonts.dataset.common.DataEntry$ 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterator[gluonts.dataset.common.DataEntry]$ 0 0 0 $gluonts.dataset.common.DataEntry$ 0 $builtins.bool$ 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import List , Any , Dict [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] from collections import Counter [EOL] from typing import Any , Dict , List [EOL] [EOL] from gluonts . core . component import validated [EOL] from gluonts . dataset . common import DataEntry [EOL] [EOL] from . _base import MapTransformation , SimpleTransformation [EOL] [EOL] [EOL] class RenameFields ( SimpleTransformation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , mapping ) : [EOL] self . mapping = mapping [EOL] values_count = Counter ( mapping . values ( ) ) [EOL] for new_key , count in values_count . items ( ) : [EOL] assert count == [number] , f" [string] { new_key } [string] " [EOL] [EOL] def transform ( self , data ) : [EOL] for key , new_key in self . mapping . items ( ) : [EOL] if key in data : [EOL] [comment] [EOL] assert new_key not in data [EOL] data [ new_key ] = data [ key ] [EOL] del data [ key ] [EOL] return data [EOL] [EOL] [EOL] class RemoveFields ( SimpleTransformation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , field_names ) : [EOL] self . field_names = field_names [EOL] [EOL] def transform ( self , data ) : [EOL] for k in self . field_names : [EOL] data . pop ( k , None ) [EOL] return data [EOL] [EOL] [EOL] class SetField ( SimpleTransformation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , output_field , value ) : [EOL] self . output_field = output_field [EOL] self . value = value [EOL] [EOL] def transform ( self , data ) : [EOL] data [ self . output_field ] = self . value [EOL] return data [EOL] [EOL] [EOL] class SetFieldIfNotPresent ( SimpleTransformation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , field , value ) : [EOL] self . output_field = field [EOL] self . value = value [EOL] [EOL] def transform ( self , data ) : [EOL] if self . output_field not in data . keys ( ) : [EOL] data [ self . output_field ] = self . value [EOL] return data [EOL] [EOL] [EOL] class SelectFields ( MapTransformation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , input_fields ) : [EOL] self . input_fields = input_fields [EOL] [EOL] def map_transform ( self , data , is_train ) : [EOL] return { f : data [ f ] for f in self . input_fields } [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 $gluonts.dataset.common.DataEntry$ 0 $builtins.bool$ 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] from typing import Iterator , List [EOL] import typing [EOL] import gluonts [EOL] from typing import Iterator , List [EOL] [EOL] from gluonts . dataset . common import DataEntry , Dataset [EOL] from gluonts . transform import Chain , Transformation [EOL] [EOL] [EOL] class TransformedDataset ( Dataset ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , base_dataset , transformations ) : [EOL] self . base_dataset = base_dataset [EOL] self . transformations = Chain ( transformations ) [EOL] [EOL] def __iter__ ( self ) : [EOL] yield from self . transformations ( self . base_dataset , is_train = True ) [EOL] [EOL] def __len__ ( self ) : [EOL] return sum ( [number] for _ in self ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterator[gluonts.dataset.common.DataEntry]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] __all__ = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , ] [EOL] [EOL] from . _base import ( AdhocTransform , Chain , FilterTransformation , FlatMapTransformation , Identity , MapTransformation , SimpleTransformation , Transformation , ) [EOL] from . convert import ( AsNumpyArray , CDFtoGaussianTransform , ConcatFeatures , ExpandDimArray , ListFeatures , SampleTargetDim , SwapAxes , TargetDimIndicator , VstackFeatures , cdf_to_gaussian_forward_transform , ) [EOL] from . dataset import TransformedDataset [EOL] from . feature import ( AddAgeFeature , AddAggregateLags , AddConstFeature , AddObservedValuesIndicator , AddTimeFeatures , CausalMeanValueImputation , DummyValueImputation , LastValueImputation , LeavesMissingValues , MeanValueImputation , MissingValueImputation , RollingMeanValueImputation , target_transformation_length , ) [EOL] from . field import ( RemoveFields , RenameFields , SelectFields , SetField , SetFieldIfNotPresent , ) [EOL] from . sampler import ( BucketInstanceSampler , ContinuousTimePointSampler , ContinuousTimeUniformSampler , ExpectedNumInstanceSampler , InstanceSampler , TestSplitSampler , UniformSplitSampler , ) [EOL] from . split import ( CanonicalInstanceSplitter , ContinuousTimeInstanceSplitter , InstanceSplitter , shift_timestamp , ) [EOL] [EOL] [comment] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Iterator , List , Any , Optional [EOL] import typing [EOL] import builtins [EOL] import gluonts [EOL] import logging [EOL] from typing import Any , Callable , Iterator , List , Optional [EOL] [EOL] [comment] [EOL] import mxnet as mx [EOL] import numpy as np [EOL] [EOL] from gluonts . core . component import validated [EOL] from gluonts . dataset . common import DataEntry [EOL] from gluonts . dataset . field_names import FieldName [EOL] from gluonts . dataset . loader import InferenceDataLoader [EOL] from gluonts . model . forecast import ( DistributionForecast , Forecast , QuantileForecast , SampleForecast , ) [EOL] [EOL] [comment] [EOL] from gluonts . mx . distribution import DistributionOutput [EOL] [EOL] OutputTransform = Callable [ [ DataEntry , np . ndarray ] , np . ndarray ] [EOL] BlockType = mx . gluon . Block [EOL] [EOL] [EOL] LOG_CACHE = set ( [ ] ) [EOL] [EOL] [EOL] def log_once ( msg ) : [EOL] global LOG_CACHE [EOL] if msg not in LOG_CACHE : [EOL] logging . info ( msg ) [EOL] LOG_CACHE . add ( msg ) [EOL] [EOL] [EOL] def _extract_instances ( x ) : [EOL] [docstring] [EOL] if isinstance ( x , ( np . ndarray , mx . nd . NDArray ) ) : [EOL] for i in range ( x . shape [ [number] ] ) : [EOL] [comment] [EOL] yield x [ i ] [EOL] elif isinstance ( x , tuple ) : [EOL] for m in zip ( * [ _extract_instances ( y ) for y in x ] ) : [EOL] yield tuple ( [ r for r in m ] ) [EOL] elif isinstance ( x , list ) : [EOL] for m in zip ( * [ _extract_instances ( y ) for y in x ] ) : [EOL] yield [ r for r in m ] [EOL] elif x is None : [EOL] while True : [EOL] yield None [EOL] else : [EOL] assert False [EOL] [EOL] [EOL] class ForecastGenerator : [EOL] [docstring] [EOL] [EOL] def __call__ ( self , inference_data_loader , prediction_net , input_names , freq , output_transform , num_samples , ** kwargs ) : [EOL] raise NotImplementedError ( ) [EOL] [EOL] [EOL] class DistributionForecastGenerator ( ForecastGenerator ) : [EOL] @ validated ( ) def __init__ ( self , distr_output ) : [EOL] self . distr_output = distr_output [EOL] [EOL] def __call__ ( self , inference_data_loader , prediction_net , input_names , freq , output_transform , num_samples , ** kwargs ) : [EOL] for batch in inference_data_loader : [EOL] inputs = [ batch [ k ] for k in input_names ] [EOL] outputs = prediction_net ( * inputs ) [EOL] if output_transform is not None : [EOL] outputs = output_transform ( batch , outputs ) [EOL] if num_samples : [EOL] log_once ( [string] ) [EOL] [EOL] distributions = [ self . distr_output . distribution ( * u ) for u in _extract_instances ( outputs ) ] [EOL] [EOL] i = - [number] [EOL] for i , distr in enumerate ( distributions ) : [EOL] yield DistributionForecast ( distr , start_date = batch [ [string] ] [ i ] , freq = freq , item_id = batch [ FieldName . ITEM_ID ] [ i ] [EOL] if FieldName . ITEM_ID in batch [EOL] else None , info = batch [ [string] ] [ i ] if [string] in batch else None , ) [EOL] assert i + [number] == len ( batch [ [string] ] ) [EOL] [EOL] [EOL] class QuantileForecastGenerator ( ForecastGenerator ) : [EOL] @ validated ( ) def __init__ ( self , quantiles ) : [EOL] self . quantiles = quantiles [EOL] [EOL] def __call__ ( self , inference_data_loader , prediction_net , input_names , freq , output_transform , num_samples , ** kwargs ) : [EOL] for batch in inference_data_loader : [EOL] inputs = [ batch [ k ] for k in input_names ] [EOL] outputs = prediction_net ( * inputs ) . asnumpy ( ) [EOL] if output_transform is not None : [EOL] outputs = output_transform ( batch , outputs ) [EOL] [EOL] if num_samples : [EOL] log_once ( [string] ) [EOL] [EOL] i = - [number] [EOL] for i , output in enumerate ( outputs ) : [EOL] yield QuantileForecast ( output , start_date = batch [ [string] ] [ i ] , freq = freq , item_id = batch [ FieldName . ITEM_ID ] [ i ] [EOL] if FieldName . ITEM_ID in batch [EOL] else None , info = batch [ [string] ] [ i ] if [string] in batch else None , forecast_keys = self . quantiles , ) [EOL] assert i + [number] == len ( batch [ [string] ] ) [EOL] [EOL] [EOL] class SampleForecastGenerator ( ForecastGenerator ) : [EOL] @ validated ( ) def __init__ ( self ) : [EOL] pass [EOL] [EOL] def __call__ ( self , inference_data_loader , prediction_net , input_names , freq , output_transform , num_samples , ** kwargs ) : [EOL] for batch in inference_data_loader : [EOL] inputs = [ batch [ k ] for k in input_names ] [EOL] outputs = prediction_net ( * inputs ) . asnumpy ( ) [EOL] if output_transform is not None : [EOL] outputs = output_transform ( batch , outputs ) [EOL] if num_samples : [EOL] num_collected_samples = outputs [ [number] ] . shape [ [number] ] [EOL] collected_samples = [ outputs ] [EOL] while num_collected_samples < num_samples : [EOL] outputs = prediction_net ( * inputs ) . asnumpy ( ) [EOL] if output_transform is not None : [EOL] outputs = output_transform ( batch , outputs ) [EOL] collected_samples . append ( outputs ) [EOL] num_collected_samples += outputs [ [number] ] . shape [ [number] ] [EOL] outputs = [ np . concatenate ( s ) [ : num_samples ] for s in zip ( * collected_samples ) ] [EOL] assert len ( outputs [ [number] ] ) == num_samples [EOL] i = - [number] [EOL] for i , output in enumerate ( outputs ) : [EOL] yield SampleForecast ( output , start_date = batch [ [string] ] [ i ] , freq = freq , item_id = batch [ FieldName . ITEM_ID ] [ i ] [EOL] if FieldName . ITEM_ID in batch [EOL] else None , info = batch [ [string] ] [ i ] if [string] in batch else None , ) [EOL] assert i + [number] == len ( batch [ [string] ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterator[gluonts.model.forecast.Forecast]$ 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 $builtins.str$ 0 $typing.Optional[OutputTransform]$ 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[OutputTransform]$ 0 0 0 0 0 0 0 $typing.Optional[OutputTransform]$ 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[OutputTransform]$ 0 0 0 0 0 0 0 $typing.Optional[OutputTransform]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [EOL] from pkgutil import extend_path [EOL] [EOL] __path__ = extend_path ( __path__ , __name__ ) [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import types [EOL] import typing [EOL] [EOL] [comment] [EOL] import mxnet as mx [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] Tensor = typing . Union [ mx . nd . NDArray , mx . sym . Symbol ] [EOL] [EOL] [comment] [EOL] TensorTransformer = typing . Callable [ [ types . ModuleType , Tensor ] , Tensor ] [EOL] [EOL] [comment] [EOL] GlobalConfig = typing . Dict [ str , typing . Any ] [EOL] [EOL] [comment] [EOL] NPArrayLike = typing . Union [ int , float , np . ndarray ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Callable , Type , List , Iterator , Optional [EOL] import RepresentableBlockPredictor [EOL] import numpy [EOL] import multiprocessing [EOL] import pathlib [EOL] import mxnet [EOL] import gluonts [EOL] import GluonPredictor [EOL] import typing [EOL] import builtins [EOL] import forecast_generator [EOL] import functools [EOL] import itertools [EOL] import json [EOL] import logging [EOL] import multiprocessing as mp [EOL] import sys [EOL] import traceback [EOL] from pathlib import Path [EOL] from pydoc import locate [EOL] from tempfile import TemporaryDirectory [EOL] from typing import ( TYPE_CHECKING , Any , Callable , Dict , Iterator , List , Optional , Tuple , Type , Union , ) [EOL] [EOL] [comment] [EOL] import mxnet as mx [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] import gluonts [EOL] from gluonts . core . component import ( DType , equals , from_hyperparameters , validated , ) [EOL] from gluonts . core . exception import GluonTSException [EOL] from gluonts . core . serde import dump_json , fqname_for , load_json [EOL] from gluonts . dataset . common import DataEntry , Dataset , ListDataset [EOL] from gluonts . dataset . loader import DataBatch , InferenceDataLoader [EOL] from gluonts . model . forecast import Forecast [EOL] from gluonts . mx . context import get_mxnet_context [EOL] from gluonts . mx . distribution import Distribution , DistributionOutput [EOL] from gluonts . support . util import ( export_repr_block , export_symb_block , get_hybrid_forward_input_names , hybrid_block_to_symbol_block , import_repr_block , import_symb_block , ) [EOL] from gluonts . transform import Transformation [EOL] [EOL] from . forecast_generator import ForecastGenerator , SampleForecastGenerator [EOL] [EOL] if TYPE_CHECKING : [comment] [EOL] from gluonts . model . estimator import Estimator [comment] [EOL] [EOL] [EOL] OutputTransform = Callable [ [ DataEntry , np . ndarray ] , np . ndarray ] [EOL] [EOL] [EOL] class Predictor : [EOL] [docstring] [EOL] [EOL] __version__ = gluonts . __version__ [EOL] [EOL] def __init__ ( self , prediction_length , freq , lead_time = [number] ) : [EOL] assert ( prediction_length > [number] ) , [string] [EOL] assert lead_time >= [number] , [string] [EOL] [EOL] self . prediction_length = prediction_length [EOL] self . freq = freq [EOL] self . lead_time = lead_time [EOL] [EOL] def predict ( self , dataset , ** kwargs ) : [EOL] [docstring] [EOL] raise NotImplementedError [EOL] [EOL] def serialize ( self , path ) : [EOL] [comment] [EOL] with ( path / [string] ) . open ( [string] ) as fp : [EOL] fp . write ( fqname_for ( self . __class__ ) ) [EOL] with ( path / [string] ) . open ( [string] ) as fp : [EOL] json . dump ( { [string] : self . __version__ , [string] : gluonts . __version__ } , fp ) [EOL] [EOL] @ classmethod def deserialize ( cls , path , ctx = None ) : [EOL] [docstring] [EOL] [comment] [EOL] with ( path / [string] ) . open ( [string] ) as fp : [EOL] tpe = locate ( fp . readline ( ) ) [EOL] [EOL] [comment] [EOL] if not issubclass ( tpe , Predictor ) : [EOL] raise IOError ( f" [string] { fqname_for ( tpe ) } [string] " f" [string] { fqname_for ( Predictor ) }" ) [EOL] [EOL] [comment] [EOL] return tpe . deserialize ( path , ctx ) [EOL] [EOL] @ classmethod def from_hyperparameters ( cls , ** hyperparameters ) : [EOL] return from_hyperparameters ( cls , ** hyperparameters ) [EOL] [EOL] @ classmethod def derive_auto_fields ( cls , train_iter ) : [EOL] return { } [EOL] [EOL] @ classmethod def from_inputs ( cls , train_iter , ** params ) : [EOL] [comment] [EOL] auto_params = cls . derive_auto_fields ( train_iter ) [EOL] [comment] [EOL] params = { ** auto_params , ** params } [EOL] return cls . from_hyperparameters ( ** params ) [EOL] [EOL] [EOL] class RepresentablePredictor ( Predictor ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , prediction_length , freq , lead_time = [number] ) : [EOL] super ( ) . __init__ ( freq = freq , lead_time = lead_time , prediction_length = prediction_length ) [EOL] [EOL] def predict ( self , dataset , ** kwargs ) : [EOL] for item in dataset : [EOL] yield self . predict_item ( item ) [EOL] [EOL] def predict_item ( self , item ) : [EOL] raise NotImplementedError [EOL] [EOL] def __eq__ ( self , that ) : [EOL] [docstring] [EOL] return equals ( self , that ) [EOL] [EOL] def serialize ( self , path ) : [EOL] [comment] [EOL] super ( ) . serialize ( path ) [EOL] with ( path / [string] ) . open ( [string] ) as fp : [EOL] print ( dump_json ( self ) , file = fp ) [EOL] [EOL] @ classmethod def deserialize ( cls , path , ctx = None ) : [EOL] with ( path / [string] ) . open ( [string] ) as fp : [EOL] return load_json ( fp . read ( ) ) [EOL] [EOL] [EOL] class GluonPredictor ( Predictor ) : [EOL] [docstring] [EOL] [EOL] BlockType = mx . gluon . Block [EOL] [EOL] def __init__ ( self , input_names , prediction_net , batch_size , prediction_length , freq , ctx , input_transform , lead_time = [number] , forecast_generator = SampleForecastGenerator ( ) , output_transform = None , dtype = np . float32 , ) : [EOL] super ( ) . __init__ ( freq = freq , lead_time = lead_time , prediction_length = prediction_length , ) [EOL] [EOL] self . input_names = input_names [EOL] self . prediction_net = prediction_net [EOL] self . batch_size = batch_size [EOL] self . input_transform = input_transform [EOL] self . forecast_generator = forecast_generator [EOL] self . output_transform = output_transform [EOL] self . ctx = ctx [EOL] self . dtype = dtype [EOL] [EOL] def hybridize ( self , batch ) : [EOL] [docstring] [EOL] self . prediction_net . hybridize ( active = True ) [EOL] self . prediction_net ( * [ batch [ k ] for k in self . input_names ] ) [EOL] [EOL] def as_symbol_block_predictor ( self , batch ) : [EOL] [docstring] [EOL] raise NotImplementedError [EOL] [EOL] def predict ( self , dataset , num_samples = None , num_workers = None , num_prefetch = None , ** kwargs , ) : [EOL] inference_data_loader = InferenceDataLoader ( dataset , transform = self . input_transform , batch_size = self . batch_size , ctx = self . ctx , dtype = self . dtype , num_workers = num_workers , num_prefetch = num_prefetch , ** kwargs , ) [EOL] yield from self . forecast_generator ( inference_data_loader = inference_data_loader , prediction_net = self . prediction_net , input_names = self . input_names , freq = self . freq , output_transform = self . output_transform , num_samples = num_samples , ) [EOL] [EOL] def __eq__ ( self , that ) : [EOL] if type ( self ) != type ( that ) : [EOL] return False [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] return equals ( self . prediction_net . collect_params ( ) , that . prediction_net . collect_params ( ) , ) [EOL] [EOL] def serialize ( self , path ) : [EOL] [comment] [EOL] super ( ) . serialize ( path ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] self . serialize_prediction_net ( path ) [EOL] [EOL] [comment] [EOL] with ( path / [string] ) . open ( [string] ) as fp : [EOL] print ( dump_json ( self . input_transform ) , file = fp ) [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] with ( path / [string] ) . open ( [string] ) as fp : [EOL] parameters = dict ( batch_size = self . batch_size , prediction_length = self . prediction_length , freq = self . freq , ctx = self . ctx , dtype = self . dtype , forecast_generator = self . forecast_generator , input_names = self . input_names , ) [EOL] print ( dump_json ( parameters ) , file = fp ) [EOL] [EOL] def serialize_prediction_net ( self , path ) : [EOL] raise NotImplementedError ( ) [EOL] [EOL] [EOL] class SymbolBlockPredictor ( GluonPredictor ) : [EOL] [docstring] [EOL] [EOL] BlockType = mx . gluon . SymbolBlock [EOL] [EOL] def as_symbol_block_predictor ( self , batch ) : [EOL] return self [EOL] [EOL] def serialize_prediction_net ( self , path ) : [EOL] export_symb_block ( self . prediction_net , path , [string] ) [EOL] [EOL] @ classmethod def deserialize ( cls , path , ctx = None ) : [EOL] ctx = ctx if ctx is not None else get_mxnet_context ( ) [EOL] [EOL] with mx . Context ( ctx ) : [EOL] [comment] [EOL] with ( path / [string] ) . open ( [string] ) as fp : [EOL] parameters = load_json ( fp . read ( ) ) [EOL] [EOL] parameters [ [string] ] = ctx [EOL] [EOL] [comment] [EOL] with ( path / [string] ) . open ( [string] ) as fp : [EOL] transform = load_json ( fp . read ( ) ) [EOL] [EOL] [comment] [EOL] num_inputs = len ( parameters [ [string] ] ) [EOL] prediction_net = import_symb_block ( num_inputs , path , [string] ) [EOL] [EOL] return SymbolBlockPredictor ( input_transform = transform , prediction_net = prediction_net , ** parameters , ) [EOL] [EOL] [EOL] class RepresentableBlockPredictor ( GluonPredictor ) : [EOL] [docstring] [EOL] [EOL] BlockType = mx . gluon . HybridBlock [EOL] [EOL] def __init__ ( self , prediction_net , batch_size , prediction_length , freq , ctx , input_transform , lead_time = [number] , forecast_generator = SampleForecastGenerator ( ) , output_transform = None , dtype = np . float32 , ) : [EOL] super ( ) . __init__ ( input_names = get_hybrid_forward_input_names ( prediction_net ) , prediction_net = prediction_net , batch_size = batch_size , prediction_length = prediction_length , freq = freq , ctx = ctx , input_transform = input_transform , lead_time = lead_time , forecast_generator = forecast_generator , output_transform = output_transform , dtype = dtype , ) [EOL] [EOL] def as_symbol_block_predictor ( self , batch ) : [EOL] with self . ctx : [EOL] symbol_block_net = hybrid_block_to_symbol_block ( hb = self . prediction_net , data_batch = [ batch [ k ] for k in self . input_names ] , ) [EOL] [EOL] return SymbolBlockPredictor ( input_names = self . input_names , prediction_net = symbol_block_net , batch_size = self . batch_size , prediction_length = self . prediction_length , freq = self . freq , ctx = self . ctx , input_transform = self . input_transform , lead_time = self . lead_time , forecast_generator = self . forecast_generator , output_transform = self . output_transform , dtype = self . dtype , ) [EOL] [EOL] def serialize ( self , path ) : [EOL] logging . warning ( [string] [string] [string] ) [EOL] super ( ) . serialize ( path ) [EOL] [EOL] def serialize_prediction_net ( self , path ) : [EOL] export_repr_block ( self . prediction_net , path , [string] ) [EOL] [EOL] @ classmethod def deserialize ( cls , path , ctx = None ) : [EOL] ctx = ctx if ctx is not None else get_mxnet_context ( ) [EOL] [EOL] with mx . Context ( ctx ) : [EOL] [comment] [EOL] with ( path / [string] ) . open ( [string] ) as fp : [EOL] parameters = load_json ( fp . read ( ) ) [EOL] [EOL] [comment] [EOL] with ( path / [string] ) . open ( [string] ) as fp : [EOL] transform = load_json ( fp . read ( ) ) [EOL] [EOL] [comment] [EOL] prediction_net = import_repr_block ( path , [string] ) [EOL] [EOL] [comment] [EOL] if [string] in parameters : [EOL] del parameters [ [string] ] [EOL] [EOL] parameters [ [string] ] = ctx [EOL] [EOL] return RepresentableBlockPredictor ( input_transform = transform , prediction_net = prediction_net , ** parameters , ) [EOL] [EOL] [EOL] class WorkerError : [EOL] def __init__ ( self , msg ) : [EOL] self . msg = msg [EOL] [EOL] [EOL] def _worker_loop ( predictor_path , input_queue , output_queue , worker_id , ** kwargs , ) : [EOL] [docstring] [EOL] [EOL] predictor = Predictor . deserialize ( predictor_path ) [EOL] while True : [EOL] idx , data_chunk = input_queue . get ( ) [EOL] if idx is None : [EOL] output_queue . put ( ( None , None , None ) ) [EOL] break [EOL] try : [EOL] result = list ( predictor . predict ( data_chunk , ** kwargs ) ) [EOL] except Exception : [EOL] we = WorkerError ( [string] . join ( traceback . format_exception ( * sys . exc_info ( ) ) ) ) [EOL] output_queue . put ( ( we , None , None ) ) [EOL] break [EOL] output_queue . put ( ( idx , worker_id , result ) ) [EOL] [EOL] [EOL] class ParallelizedPredictor ( Predictor ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , base_predictor , num_workers = None , chunk_size = [number] , ) : [EOL] super ( ) . __init__ ( freq = base_predictor . freq , lead_time = base_predictor . lead_time , prediction_length = base_predictor . prediction_length , ) [EOL] [EOL] self . _base_predictor = base_predictor [EOL] self . _num_workers = ( num_workers if num_workers is not None else mp . cpu_count ( ) ) [EOL] self . _chunk_size = chunk_size [EOL] self . _num_running_workers = [number] [EOL] self . _input_queues = [ ] [EOL] self . _output_queue = None [EOL] [EOL] def _grouper ( self , iterable , n ) : [EOL] iterator = iter ( iterable ) [EOL] group = tuple ( itertools . islice ( iterator , n ) ) [EOL] while group : [EOL] yield group [EOL] group = tuple ( itertools . islice ( iterator , n ) ) [EOL] [EOL] def terminate ( self ) : [EOL] for q in self . _input_queues : [EOL] q . put ( ( None , None ) ) [EOL] for w in self . _workers : [EOL] w . terminate ( ) [EOL] for i , w in enumerate ( self . _workers ) : [EOL] w . join ( ) [EOL] [EOL] def predict ( self , dataset , ** kwargs ) : [EOL] with TemporaryDirectory ( ) as tempdir : [EOL] predictor_path = Path ( tempdir ) [EOL] self . _base_predictor . serialize ( predictor_path ) [EOL] [EOL] [comment] [EOL] [EOL] self . _input_queues = [ mp . Queue ( ) for _ in range ( self . _num_workers ) ] [EOL] self . _output_queue = mp . Queue ( ) [EOL] [EOL] workers = [ ] [EOL] for worker_id , in_q in enumerate ( self . _input_queues ) : [EOL] worker = mp . Process ( target = _worker_loop , args = ( predictor_path , in_q , self . _output_queue , worker_id ) , kwargs = kwargs , ) [EOL] [EOL] worker . daemon = True [EOL] worker . start ( ) [EOL] workers . append ( worker ) [EOL] self . _num_running_workers += [number] [EOL] [EOL] self . _workers = workers [EOL] [EOL] chunked_data = self . _grouper ( dataset , self . _chunk_size ) [EOL] [EOL] self . _send_idx = [number] [EOL] self . _next_idx = [number] [EOL] [EOL] self . _data_buffer = { } [EOL] [EOL] worker_ids = list ( range ( self . _num_workers ) ) [EOL] [EOL] def receive ( ) : [EOL] idx , worker_id , result = self . _output_queue . get ( ) [EOL] if isinstance ( idx , WorkerError ) : [EOL] self . _num_running_workers -= [number] [EOL] self . terminate ( ) [EOL] raise Exception ( idx . msg ) [EOL] if idx is not None : [EOL] self . _data_buffer [ idx ] = result [EOL] return idx , worker_id , result [EOL] [EOL] def get_next_from_buffer ( ) : [EOL] while self . _next_idx in self . _data_buffer : [EOL] result_batch = self . _data_buffer . pop ( self . _next_idx ) [EOL] self . _next_idx += [number] [EOL] for result in result_batch : [EOL] yield result [EOL] [EOL] def send ( worker_id , chunk ) : [EOL] q = self . _input_queues [ worker_id ] [EOL] q . put ( ( self . _send_idx , chunk ) ) [EOL] self . _send_idx += [number] [EOL] [EOL] try : [EOL] [comment] [EOL] for wid in worker_ids : [EOL] chunk = next ( chunked_data ) [EOL] send ( wid , chunk ) [EOL] [EOL] while True : [EOL] idx , wid , result = receive ( ) [EOL] for res in get_next_from_buffer ( ) : [EOL] yield res [EOL] chunk = next ( chunked_data ) [EOL] send ( wid , chunk ) [EOL] except StopIteration : [EOL] [comment] [EOL] for q in self . _input_queues : [EOL] q . put ( ( None , None ) ) [EOL] [EOL] [comment] [EOL] while self . _num_running_workers > [number] : [EOL] idx , worker_id , result = receive ( ) [EOL] if idx is None : [EOL] self . _num_running_workers -= [number] [EOL] continue [EOL] for res in get_next_from_buffer ( ) : [EOL] yield res [EOL] assert len ( self . _data_buffer ) == [number] [EOL] assert self . _send_idx == self . _next_idx [EOL] [EOL] [EOL] class Localizer ( Predictor ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , estimator ) : [EOL] super ( ) . __init__ ( freq = estimator . freq , lead_time = estimator . lead_time , prediction_length = estimator . prediction_length , ) [EOL] self . estimator = estimator [EOL] [EOL] def predict ( self , dataset , ** kwargs ) : [EOL] logger = logging . getLogger ( __name__ ) [EOL] for i , ts in enumerate ( dataset , start = [number] ) : [EOL] logger . info ( f" [string] { i } [string] { len ( dataset ) }" ) [EOL] local_ds = ListDataset ( [ ts ] , freq = self . freq ) [EOL] trained_pred = self . estimator . train ( local_ds ) [EOL] logger . info ( f" [string] { i } [string] { len ( dataset ) }" ) [EOL] predictions = trained_pred . predict ( local_ds , ** kwargs ) [EOL] for pred in predictions : [EOL] yield pred [EOL] [EOL] [EOL] class FallbackPredictor ( Predictor ) : [EOL] @ classmethod def from_predictor ( cls , base , ** overrides ) : [EOL] [comment] [EOL] [comment] [EOL] return cls . from_hyperparameters ( ** getattr ( base , [string] ) , ** overrides ) [EOL] [EOL] [EOL] def fallback ( fallback_cls ) : [EOL] def decorator ( predict_item ) : [EOL] @ functools . wraps ( predict_item ) def fallback_predict ( self , item ) : [EOL] try : [EOL] return predict_item ( self , item ) [EOL] except GluonTSException : [EOL] raise [EOL] except Exception : [EOL] logging . warning ( f" [string] { traceback . format_exc ( ) }" ) [EOL] fallback_predictor = fallback_cls . from_predictor ( self ) [EOL] return fallback_predictor . predict_item ( item ) [EOL] [EOL] return fallback_predict [EOL] [EOL] return decorator [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterator[gluonts.model.forecast.Forecast]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $Predictor$ 0 0 0 $RepresentablePredictor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $RepresentablePredictor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional [EOL] import gluonts [EOL] import builtins [EOL] import mxnet [EOL] import typing [EOL] from typing import List , Optional [EOL] [EOL] [comment] [EOL] from mxnet . gluon import HybridBlock [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . dataset . field_names import FieldName [EOL] from gluonts . model . estimator import GluonEstimator [EOL] from gluonts . model . predictor import RepresentableBlockPredictor [EOL] from gluonts . mx . distribution import DistributionOutput , StudentTOutput [EOL] from gluonts . mx . trainer import Trainer [EOL] from gluonts . transform import ( Chain , ExpectedNumInstanceSampler , InstanceSplitter , Transformation , AddObservedValuesIndicator , ) [EOL] from gluonts . model . forecast_generator import DistributionForecastGenerator [EOL] from gluonts . transform . feature import ( DummyValueImputation , MissingValueImputation , ) [EOL] [EOL] [EOL] [comment] [EOL] from . _network import ( SimpleFeedForwardSamplingNetwork , SimpleFeedForwardDistributionNetwork , SimpleFeedForwardTrainingNetwork , ) [EOL] [EOL] [EOL] class SimpleFeedForwardEstimator ( GluonEstimator ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] @ validated ( ) def __init__ ( self , freq , prediction_length , sampling = True , trainer = Trainer ( ) , num_hidden_dimensions = None , context_length = None , distr_output = StudentTOutput ( ) , imputation_method = None , batch_normalization = False , mean_scaling = True , num_parallel_samples = [number] , ) : [EOL] [docstring] [EOL] super ( ) . __init__ ( trainer = trainer ) [EOL] [EOL] assert ( prediction_length > [number] ) , [string] [EOL] assert ( context_length is None or context_length > [number] ) , [string] [EOL] assert num_hidden_dimensions is None or ( [ d > [number] for d in num_hidden_dimensions ] ) , [string] [EOL] assert ( num_parallel_samples > [number] ) , [string] [EOL] [EOL] self . num_hidden_dimensions = ( num_hidden_dimensions [EOL] if num_hidden_dimensions is not None [EOL] else list ( [ [number] , [number] ] ) ) [EOL] self . prediction_length = prediction_length [EOL] self . context_length = ( context_length if context_length is not None else prediction_length ) [EOL] self . freq = freq [EOL] self . distr_output = distr_output [EOL] self . batch_normalization = batch_normalization [EOL] self . mean_scaling = mean_scaling [EOL] self . num_parallel_samples = num_parallel_samples [EOL] self . sampling = sampling [EOL] self . imputation_method = ( imputation_method [EOL] if imputation_method is not None [EOL] else DummyValueImputation ( self . distr_output . value_in_support ) ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] def create_transformation ( self ) : [EOL] return Chain ( [ AddObservedValuesIndicator ( target_field = FieldName . TARGET , output_field = FieldName . OBSERVED_VALUES , dtype = self . dtype , imputation_method = self . imputation_method , ) , InstanceSplitter ( target_field = FieldName . TARGET , is_pad_field = FieldName . IS_PAD , start_field = FieldName . START , forecast_start_field = FieldName . FORECAST_START , train_sampler = ExpectedNumInstanceSampler ( num_instances = [number] ) , past_length = self . context_length , future_length = self . prediction_length , time_series_fields = [ FieldName . OBSERVED_VALUES ] , ) , ] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] def create_training_network ( self ) : [EOL] return SimpleFeedForwardTrainingNetwork ( num_hidden_dimensions = self . num_hidden_dimensions , prediction_length = self . prediction_length , context_length = self . context_length , distr_output = self . distr_output , batch_normalization = self . batch_normalization , mean_scaling = self . mean_scaling , ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] def create_predictor ( self , transformation , trained_network ) : [EOL] if self . sampling is True : [EOL] prediction_network = SimpleFeedForwardSamplingNetwork ( num_hidden_dimensions = self . num_hidden_dimensions , prediction_length = self . prediction_length , context_length = self . context_length , distr_output = self . distr_output , batch_normalization = self . batch_normalization , mean_scaling = self . mean_scaling , params = trained_network . collect_params ( ) , num_parallel_samples = self . num_parallel_samples , ) [EOL] [EOL] return RepresentableBlockPredictor ( input_transform = transformation , prediction_net = prediction_network , batch_size = self . trainer . batch_size , freq = self . freq , prediction_length = self . prediction_length , ctx = self . trainer . ctx , ) [EOL] [EOL] else : [EOL] prediction_network = SimpleFeedForwardDistributionNetwork ( num_hidden_dimensions = self . num_hidden_dimensions , prediction_length = self . prediction_length , context_length = self . context_length , distr_output = self . distr_output , batch_normalization = self . batch_normalization , mean_scaling = self . mean_scaling , params = trained_network . collect_params ( ) , num_parallel_samples = self . num_parallel_samples , ) [EOL] return RepresentableBlockPredictor ( input_transform = transformation , prediction_net = prediction_network , batch_size = self . trainer . batch_size , forecast_generator = DistributionForecastGenerator ( self . distr_output ) , freq = self . freq , prediction_length = self . prediction_length , ctx = self . trainer . ctx , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.mx.trainer.Trainer$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.mx.trainer.Trainer$ 0 $gluonts.mx.trainer.Trainer$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.transform.Transformation$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Tuple [EOL] import typing [EOL] import builtins [EOL] import gluonts [EOL] from typing import List [EOL] [EOL] [comment] [EOL] import mxnet as mx [EOL] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] from typing import Tuple [EOL] [EOL] [comment] [EOL] from gluonts . mx . block . scaler import MeanScaler , NOPScaler [EOL] from gluonts . mx . distribution import DistributionOutput [EOL] from gluonts . support . util import weighted_average [EOL] [EOL] [EOL] class SimpleFeedForwardNetworkBase ( mx . gluon . HybridBlock ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] [comment] [EOL] @ validated ( ) def __init__ ( self , num_hidden_dimensions , prediction_length , context_length , batch_normalization , mean_scaling , distr_output , ** kwargs , ) : [EOL] super ( ) . __init__ ( ** kwargs ) [EOL] [EOL] self . num_hidden_dimensions = num_hidden_dimensions [EOL] self . prediction_length = prediction_length [EOL] self . context_length = context_length [EOL] self . batch_normalization = batch_normalization [EOL] self . mean_scaling = mean_scaling [EOL] self . distr_output = distr_output [EOL] [EOL] with self . name_scope ( ) : [EOL] self . distr_args_proj = self . distr_output . get_args_proj ( ) [EOL] self . mlp = mx . gluon . nn . HybridSequential ( ) [EOL] dims = self . num_hidden_dimensions [EOL] for layer_no , units in enumerate ( dims [ : - [number] ] ) : [EOL] self . mlp . add ( mx . gluon . nn . Dense ( units = units , activation = [string] ) ) [EOL] if self . batch_normalization : [EOL] self . mlp . add ( mx . gluon . nn . BatchNorm ( ) ) [EOL] self . mlp . add ( mx . gluon . nn . Dense ( units = prediction_length * dims [ - [number] ] ) ) [EOL] self . mlp . add ( mx . gluon . nn . HybridLambda ( lambda F , o : F . reshape ( o , ( - [number] , prediction_length , dims [ - [number] ] ) ) ) ) [EOL] self . scaler = MeanScaler ( ) if mean_scaling else NOPScaler ( ) [EOL] [EOL] def get_distr_args ( self , F , past_target ) : [EOL] [docstring] [EOL] scaled_target , target_scale = self . scaler ( past_target , F . ones_like ( past_target ) , ) [EOL] mlp_outputs = self . mlp ( scaled_target ) [EOL] distr_args = self . distr_args_proj ( mlp_outputs ) [EOL] scale = target_scale . expand_dims ( axis = [number] ) [EOL] loc = F . zeros_like ( scale ) [EOL] return distr_args , loc , scale [EOL] [EOL] [EOL] class SimpleFeedForwardTrainingNetwork ( SimpleFeedForwardNetworkBase ) : [EOL] [comment] [EOL] def hybrid_forward ( self , F , past_target , future_target , future_observed_values , ) : [EOL] [docstring] [EOL] distr_args , loc , scale = self . get_distr_args ( F , past_target ) [EOL] distr = self . distr_output . distribution ( distr_args , loc = loc , scale = scale ) [EOL] [EOL] [comment] [EOL] loss = distr . loss ( future_target ) [EOL] [EOL] weighted_loss = weighted_average ( F = F , x = loss , weights = future_observed_values , axis = [number] ) [EOL] [EOL] [comment] [EOL] return weighted_loss [EOL] [EOL] [EOL] class SimpleFeedForwardSamplingNetwork ( SimpleFeedForwardNetworkBase ) : [EOL] @ validated ( ) def __init__ ( self , num_parallel_samples = [number] , * args , ** kwargs ) : [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] self . num_parallel_samples = num_parallel_samples [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , past_target ) : [EOL] [docstring] [EOL] [EOL] distr_args , loc , scale = self . get_distr_args ( F , past_target ) [EOL] distr = self . distr_output . distribution ( distr_args , loc = loc , scale = scale ) [EOL] [EOL] [comment] [EOL] samples = distr . sample ( self . num_parallel_samples ) [EOL] [EOL] [comment] [EOL] return samples . swapaxes ( [number] , [number] ) [EOL] [EOL] [EOL] class SimpleFeedForwardDistributionNetwork ( SimpleFeedForwardNetworkBase ) : [EOL] @ validated ( ) def __init__ ( self , num_parallel_samples = [number] , * args , ** kwargs ) : [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] self . num_parallel_samples = num_parallel_samples [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , past_target ) : [EOL] [docstring] [EOL] distr_args , loc , scale = self . get_distr_args ( F , past_target ) [EOL] return distr_args , loc , scale [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor,gluonts.model.common.Tensor]$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from . _estimator import SimpleFeedForwardEstimator [EOL] [EOL] __all__ = [ [string] ] [EOL] [EOL] [comment] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from . _estimator import LSTNetEstimator [EOL] [EOL] __all__ = [ [string] ] [EOL] [EOL] [comment] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Optional [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] from typing import Optional [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . dataset . common import DataEntry [EOL] from gluonts . model . forecast import Forecast , SampleForecast [EOL] from gluonts . model . predictor import RepresentablePredictor [EOL] from gluonts . support . pandas import forecast_start [EOL] from gluonts . time_feature import get_seasonality [EOL] [EOL] [EOL] class SeasonalNaivePredictor ( RepresentablePredictor ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , freq , prediction_length , season_length = None , ) : [EOL] super ( ) . __init__ ( freq = freq , prediction_length = prediction_length ) [EOL] [EOL] assert ( season_length is None or season_length > [number] ) , [string] [EOL] [EOL] self . freq = freq [EOL] self . prediction_length = prediction_length [EOL] self . season_length = ( season_length [EOL] if season_length is not None [EOL] else get_seasonality ( freq ) ) [EOL] [EOL] def predict_item ( self , item ) : [EOL] target = np . asarray ( item [ [string] ] , np . float32 ) [EOL] len_ts = len ( target ) [EOL] forecast_start_time = forecast_start ( item ) [EOL] [EOL] assert ( len_ts >= [number] ) , [string] [EOL] [EOL] if len_ts >= self . season_length : [EOL] indices = [ len_ts - self . season_length + k % self . season_length for k in range ( self . prediction_length ) ] [EOL] samples = target [ indices ] . reshape ( ( [number] , self . prediction_length ) ) [EOL] else : [EOL] samples = np . full ( shape = ( [number] , self . prediction_length ) , fill_value = target . mean ( ) ) [EOL] [EOL] return SampleForecast ( samples , forecast_start_time , self . freq ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.forecast.Forecast$ 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from . _predictor import SeasonalNaivePredictor [EOL] [EOL] __all__ = [ [string] ] [EOL] [EOL] [comment] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Optional [EOL] import gluonts [EOL] import builtins [EOL] import pydantic [EOL] import typing [EOL] from typing import Optional [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] from pydantic import PositiveInt [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . dataset . common import DataEntry , Dataset [EOL] from gluonts . dataset . field_names import FieldName [EOL] from gluonts . model . estimator import Estimator [EOL] from gluonts . model . forecast import SampleForecast [EOL] from gluonts . model . predictor import FallbackPredictor , RepresentablePredictor [EOL] from gluonts . model . trivial . constant import ConstantPredictor [EOL] from gluonts . support . pandas import forecast_start [EOL] [EOL] [EOL] class MeanPredictor ( RepresentablePredictor , FallbackPredictor ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , prediction_length , freq , num_samples = [number] , context_length = None , ) : [EOL] super ( ) . __init__ ( freq = freq , prediction_length = prediction_length ) [EOL] self . context_length = context_length [EOL] self . num_samples = num_samples [EOL] self . shape = ( self . num_samples , self . prediction_length ) [EOL] [EOL] def predict_item ( self , item ) : [EOL] if self . context_length is not None : [EOL] target = item [ [string] ] [ - self . context_length : ] [EOL] else : [EOL] target = item [ [string] ] [EOL] [EOL] mean = np . nanmean ( target ) [EOL] std = np . nanstd ( target ) [EOL] normal = np . random . standard_normal ( self . shape ) [EOL] [EOL] return SampleForecast ( samples = std * normal + mean , start_date = forecast_start ( item ) , freq = self . freq , item_id = item . get ( FieldName . ITEM_ID ) , ) [EOL] [EOL] [EOL] class MovingAveragePredictor ( RepresentablePredictor ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , prediction_length , freq , context_length = None , ) : [EOL] super ( ) . __init__ ( freq = freq , prediction_length = prediction_length ) [EOL] [EOL] if context_length is not None : [EOL] assert ( context_length >= [number] ) , [string] [EOL] [EOL] self . context_length = context_length [EOL] [EOL] def predict_item ( self , item ) : [EOL] target = item [ [string] ] . tolist ( ) [EOL] [EOL] for _ in range ( self . prediction_length ) : [EOL] if self . context_length is not None : [EOL] window = target [ - self . context_length : ] [EOL] else : [EOL] window = target [EOL] [EOL] target . append ( np . nanmean ( window ) ) [EOL] [EOL] return SampleForecast ( samples = np . array ( [ target [ - self . prediction_length : ] ] ) , start_date = forecast_start ( item ) , freq = self . freq , item_id = item . get ( FieldName . ITEM_ID ) , ) [EOL] [EOL] [EOL] class MeanEstimator ( Estimator ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , prediction_length , freq , num_samples , ) : [EOL] super ( ) . __init__ ( ) [EOL] self . prediction_length = prediction_length [EOL] self . freq = freq [EOL] self . num_samples = num_samples [EOL] [EOL] def train ( self , training_data , validation_dataset = None , ) : [EOL] contexts = np . array ( [ item [ [string] ] [ - self . prediction_length : ] for item in training_data ] ) [EOL] [EOL] samples = np . broadcast_to ( array = contexts . mean ( axis = [number] ) , shape = ( self . num_samples , self . prediction_length ) , ) [EOL] [EOL] return ConstantPredictor ( samples = samples , freq = self . freq ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.int$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $gluonts.model.forecast.SampleForecast$ 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.int$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.forecast.SampleForecast$ 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.trivial.constant.ConstantPredictor$ 0 0 0 $gluonts.dataset.common.Dataset$ 0 $typing.Optional[gluonts.dataset.common.Dataset]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.Dataset$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import gluonts [EOL] import builtins [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . dataset . common import DataEntry [EOL] from gluonts . dataset . field_names import FieldName [EOL] from gluonts . model . forecast import Forecast , SampleForecast [EOL] from gluonts . model . predictor import RepresentablePredictor [EOL] from gluonts . support . pandas import forecast_start [EOL] [EOL] [EOL] class IdentityPredictor ( RepresentablePredictor ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , prediction_length , freq , num_samples ) : [EOL] super ( ) . __init__ ( freq = freq , prediction_length = prediction_length ) [EOL] [EOL] assert num_samples > [number] , [string] [EOL] [EOL] self . num_samples = num_samples [EOL] [EOL] def predict_item ( self , item ) : [EOL] prediction = item [ [string] ] [ - self . prediction_length : ] [EOL] samples = np . broadcast_to ( array = np . expand_dims ( prediction , [number] ) , shape = ( self . num_samples , self . prediction_length ) , ) [EOL] [EOL] return SampleForecast ( samples = samples , start_date = forecast_start ( item ) , freq = self . freq , item_id = item . get ( FieldName . ITEM_ID ) , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.int$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.forecast.Forecast$ 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import gluonts [EOL] import builtins [EOL] import numpy [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . dataset . common import DataEntry [EOL] from gluonts . dataset . field_names import FieldName [EOL] from gluonts . model . forecast import SampleForecast [EOL] from gluonts . model . predictor import FallbackPredictor , RepresentablePredictor [EOL] from gluonts . support . pandas import forecast_start [EOL] [EOL] [EOL] class ConstantPredictor ( RepresentablePredictor ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , samples , freq ) : [EOL] super ( ) . __init__ ( samples . shape [ [number] ] , freq ) [EOL] self . samples = samples [EOL] [EOL] def predict_item ( self , item ) : [EOL] return SampleForecast ( samples = self . samples , start_date = item [ [string] ] , freq = self . freq , item_id = item . get ( FieldName . ITEM_ID ) , ) [EOL] [EOL] [EOL] class ConstantValuePredictor ( RepresentablePredictor , FallbackPredictor ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , prediction_length , freq , value = [number] , num_samples = [number] , ) : [EOL] super ( ) . __init__ ( freq = freq , prediction_length = prediction_length ) [EOL] self . value = value [EOL] self . num_samples = num_samples [EOL] [EOL] def predict_item ( self , item ) : [EOL] samples_shape = self . num_samples , self . prediction_length [EOL] samples = np . full ( samples_shape , self . value ) [EOL] return SampleForecast ( samples = samples , start_date = forecast_start ( item ) , freq = self . freq , item_id = item . get ( [string] ) , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.forecast.SampleForecast$ 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.int$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.forecast.SampleForecast$ 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . estimator import DummyEstimator [EOL] [EOL] [comment] [EOL] from . _predictor import NPTSPredictor [EOL] [EOL] [EOL] class NPTSEstimator ( DummyEstimator ) : [EOL] @ validated ( getattr ( NPTSPredictor . __init__ , [string] ) ) def __init__ ( self , ** kwargs ) : [EOL] super ( ) . __init__ ( predictor_cls = NPTSPredictor , ** kwargs ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from . _estimator import NPTSEstimator [EOL] [EOL] [comment] [EOL] from . _predictor import KernelType , NPTSPredictor [EOL] [EOL] __all__ = [ [string] , [string] , [string] ] [EOL] [EOL] [comment] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] [EOL] [EOL] class WeightedSampler : [EOL] [docstring] [EOL] [EOL] @ staticmethod def sample ( weights , num_samples ) : [EOL] [docstring] [EOL] assert all ( weights >= [number] ) , [string] [EOL] [comment] [EOL] [comment] [EOL] weights = np . ones_like ( weights ) if sum ( weights ) == [number] else weights [EOL] [EOL] cumsum_weights = np . cumsum ( weights ) [EOL] [EOL] [comment] [EOL] total_weight = cumsum_weights [ - [number] ] [EOL] [EOL] [comment] [EOL] uniform_samples = total_weight * np . random . random ( num_samples ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] samples_ix = np . searchsorted ( cumsum_weights , uniform_samples , side = [string] ) [EOL] [EOL] return samples_ix [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] from typing import List [EOL] [EOL] [comment] [EOL] import mxnet as mx [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] from gluonts . time_feature import get_seasonality [EOL] [EOL] VALID_N_BEATS_STACK_TYPES = [string] , [string] , [string] [EOL] VALID_LOSS_FUNCTIONS = [string] , [string] , [string] [EOL] [EOL] [EOL] def linear_space ( F , backcast_length , forecast_length , fwd_looking ) : [EOL] if fwd_looking : [EOL] return F . arange ( [number] , forecast_length ) / forecast_length [EOL] else : [EOL] return F . arange ( - backcast_length , [number] ) / backcast_length [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] def seasonality_model ( F , num_coefficients , context_length , prediction_length , is_forecast , ) : [EOL] [docstring] [EOL] t = linear_space ( F , context_length , prediction_length , fwd_looking = is_forecast ) [EOL] cosines = F . stack ( * [ F . cos ( [number] * np . pi * i * t ) for i in range ( num_coefficients ) ] ) [EOL] sines = F . stack ( * [ F . sin ( [number] * np . pi * i * t ) for i in range ( num_coefficients ) ] ) [EOL] S = F . concat ( cosines , sines , dim = [number] ) [EOL] return S [EOL] [EOL] [EOL] def trend_model ( F , num_coefficients , context_length , prediction_length , is_forecast , ) : [EOL] [docstring] [EOL] t = linear_space ( F , context_length , prediction_length , fwd_looking = is_forecast ) [EOL] T = F . stack ( * [ t ** i for i in range ( num_coefficients ) ] ) [EOL] return T [EOL] [EOL] [EOL] class NBEATSBlock ( mx . gluon . HybridBlock ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] [comment] [EOL] @ validated ( ) def __init__ ( self , width , num_block_layers , expansion_coefficient_length , prediction_length , context_length , has_backcast , ** kwargs , ) : [EOL] super ( ) . __init__ ( ** kwargs ) [EOL] [EOL] self . width = width [EOL] self . num_block_layers = num_block_layers [EOL] self . expansion_coefficient_length = expansion_coefficient_length [EOL] self . prediction_length = prediction_length [EOL] self . context_length = context_length [EOL] self . has_backcast = has_backcast [EOL] [EOL] [comment] [EOL] [comment] [EOL] self . basis_initialized = False [EOL] [EOL] [comment] [EOL] with self . name_scope ( ) : [EOL] self . fc_stack = mx . gluon . nn . HybridSequential ( ) [EOL] for i in range ( self . num_block_layers ) : [EOL] self . fc_stack . add ( mx . gluon . nn . Dense ( units = self . width , activation = [string] , prefix = f" [string] { i } [string] " , ) ) [EOL] [EOL] [comment] [EOL] [EOL] self . theta_backcast = None [EOL] self . theta_forecast = None [EOL] [EOL] self . backcast = None [EOL] self . forecast = None [EOL] [EOL] self . backcast_basis = None [EOL] self . forecast_basis = None [EOL] [EOL] [comment] [EOL] def initialize_basis ( self , F ) : [EOL] pass [EOL] [EOL] def hybrid_forward ( self , F , x , * args , ** kwargs ) : [EOL] [comment] [EOL] if not self . basis_initialized : [EOL] self . initialize_basis ( F ) [EOL] self . basis_initialized = True [EOL] [EOL] x = self . fc_stack ( x ) [EOL] theta_f = self . theta_forecast ( x ) [EOL] forecast = self . forecast ( theta_f ) [EOL] [EOL] if self . has_backcast : [EOL] theta_b = self . theta_backcast ( x ) [EOL] backcast = self . backcast ( theta_b ) [EOL] return backcast , forecast [EOL] [EOL] return forecast [EOL] [EOL] [EOL] class NBEATSGenericBlock ( NBEATSBlock ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] [comment] [EOL] @ validated ( ) def __init__ ( self , ** kwargs ) : [EOL] super ( ) . __init__ ( ** kwargs ) [EOL] [EOL] with self . name_scope ( ) : [EOL] if self . has_backcast : [EOL] self . theta_backcast = mx . gluon . nn . Dense ( units = self . expansion_coefficient_length , prefix = f" [string] " , ) [EOL] self . backcast = mx . gluon . nn . Dense ( units = self . context_length , prefix = f" [string] " , ) [EOL] self . theta_forecast = mx . gluon . nn . Dense ( units = self . expansion_coefficient_length , prefix = f" [string] " , ) [EOL] self . forecast = mx . gluon . nn . Dense ( units = self . prediction_length , prefix = f" [string] " , ) [EOL] [EOL] [EOL] class NBEATSSeasonalBlock ( NBEATSBlock ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] [comment] [EOL] @ validated ( ) def __init__ ( self , ** kwargs ) : [EOL] super ( ) . __init__ ( ** kwargs ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] self . num_coefficients = int ( ( self . prediction_length / [number] ) - [number] ) + [number] [EOL] [EOL] with self . name_scope ( ) : [EOL] if self . has_backcast : [EOL] self . theta_backcast = mx . gluon . nn . Dense ( units = [number] * self . num_coefficients , prefix = f" [string] " , ) [EOL] self . backcast = mx . gluon . nn . HybridLambda ( lambda F , thetas : F . dot ( thetas , self . backcast_basis ) , prefix = f" [string] " , ) [EOL] self . theta_forecast = mx . gluon . nn . Dense ( units = [number] * self . num_coefficients , prefix = f" [string] " , ) [EOL] self . forecast = mx . gluon . nn . HybridLambda ( lambda F , thetas : F . dot ( thetas , self . forecast_basis ) , prefix = f" [string] " , ) [EOL] [EOL] def initialize_basis ( self , F ) : [EOL] [comment] [EOL] [comment] [EOL] if self . has_backcast : [EOL] self . backcast_basis = seasonality_model ( F , num_coefficients = self . num_coefficients , context_length = self . context_length , prediction_length = self . prediction_length , is_forecast = False , ) [EOL] self . forecast_basis = seasonality_model ( F , num_coefficients = self . num_coefficients , context_length = self . context_length , prediction_length = self . prediction_length , is_forecast = True , ) [EOL] [EOL] [EOL] class NBEATSTrendBlock ( NBEATSBlock ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] [comment] [EOL] @ validated ( ) def __init__ ( self , ** kwargs ) : [EOL] super ( ) . __init__ ( ** kwargs ) [EOL] [EOL] with self . name_scope ( ) : [EOL] if self . has_backcast : [EOL] self . theta_backcast = mx . gluon . nn . Dense ( units = self . expansion_coefficient_length , prefix = f" [string] " , ) [EOL] self . backcast = mx . gluon . nn . HybridLambda ( lambda F , thetas : F . dot ( thetas , self . backcast_basis ) , prefix = f" [string] " , ) [EOL] self . theta_forecast = mx . gluon . nn . Dense ( units = self . expansion_coefficient_length , prefix = f" [string] " , ) [EOL] self . forecast = mx . gluon . nn . HybridLambda ( lambda F , thetas : F . dot ( thetas , self . forecast_basis ) , prefix = f" [string] " , ) [EOL] [EOL] def initialize_basis ( self , F ) : [EOL] [comment] [EOL] [comment] [EOL] if self . has_backcast : [EOL] self . backcast_basis = trend_model ( F , num_coefficients = self . expansion_coefficient_length , context_length = self . context_length , prediction_length = self . prediction_length , is_forecast = False , ) [EOL] self . forecast_basis = trend_model ( F , num_coefficients = self . expansion_coefficient_length , context_length = self . context_length , prediction_length = self . prediction_length , is_forecast = True , ) [EOL] [EOL] [EOL] class NBEATSNetwork ( mx . gluon . HybridBlock ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] [comment] [EOL] @ validated ( ) def __init__ ( self , prediction_length , context_length , num_stacks , widths , num_blocks , num_block_layers , expansion_coefficient_lengths , sharing , stack_types , ** kwargs , ) : [EOL] super ( ) . __init__ ( ** kwargs ) [EOL] [EOL] self . num_stacks = num_stacks [EOL] self . widths = widths [EOL] self . num_blocks = num_blocks [EOL] self . num_block_layers = num_block_layers [EOL] self . sharing = sharing [EOL] self . expansion_coefficient_lengths = expansion_coefficient_lengths [EOL] self . stack_types = stack_types [EOL] self . prediction_length = prediction_length [EOL] self . context_length = context_length [EOL] [EOL] with self . name_scope ( ) : [EOL] self . net_blocks = [ ] [EOL] [EOL] [comment] [EOL] for stack_id in range ( num_stacks ) : [EOL] for block_id in range ( num_blocks [ stack_id ] ) : [EOL] [comment] [EOL] params = ( self . net_blocks [ - [number] ] . collect_params ( ) [EOL] if ( block_id > [number] and sharing [ stack_id ] ) [EOL] else None ) [EOL] [comment] [EOL] has_backcast = not ( stack_id == num_stacks - [number] [EOL] and block_id == num_blocks [ num_stacks - [number] ] - [number] ) [EOL] if self . stack_types [ stack_id ] == [string] : [EOL] net_block = NBEATSGenericBlock ( width = self . widths [ stack_id ] , num_block_layers = self . num_block_layers [ stack_id ] , expansion_coefficient_length = self . expansion_coefficient_lengths [ stack_id ] , prediction_length = prediction_length , context_length = context_length , has_backcast = has_backcast , params = params , ) [EOL] elif self . stack_types [ stack_id ] == [string] : [EOL] net_block = NBEATSSeasonalBlock ( width = self . widths [ stack_id ] , num_block_layers = self . num_block_layers [ stack_id ] , expansion_coefficient_length = self . expansion_coefficient_lengths [ stack_id ] , prediction_length = prediction_length , context_length = context_length , has_backcast = has_backcast , params = params , ) [EOL] else : [comment] [EOL] net_block = NBEATSTrendBlock ( width = self . widths [ stack_id ] , num_block_layers = self . num_block_layers [ stack_id ] , expansion_coefficient_length = self . expansion_coefficient_lengths [ stack_id ] , prediction_length = prediction_length , context_length = context_length , has_backcast = has_backcast , params = params , ) [EOL] [EOL] self . net_blocks . append ( net_block ) [EOL] self . register_child ( net_block , f" [string] { stack_id } [string] { block_id }" ) [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , past_target , future_target ) : [EOL] if len ( self . net_blocks ) == [number] : [comment] [EOL] return self . net_blocks [ [number] ] ( past_target ) [EOL] else : [EOL] backcast , forecast = self . net_blocks [ [number] ] ( past_target ) [EOL] backcast = past_target - backcast [EOL] [comment] [EOL] for i in range ( [number] , len ( self . net_blocks ) - [number] ) : [EOL] b , f = self . net_blocks [ i ] ( backcast ) [EOL] backcast = backcast - b [EOL] forecast = forecast + f [EOL] [comment] [EOL] return forecast + self . net_blocks [ - [number] ] ( backcast ) [EOL] [EOL] def smape_loss ( self , F , forecast , future_target ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] denominator = F . stop_gradient ( F . abs ( future_target ) + F . abs ( forecast ) ) [EOL] flag = denominator == [number] [EOL] [EOL] smape = ( [number] / self . prediction_length ) * F . mean ( ( F . abs ( future_target - forecast ) * ( [number] - flag ) ) / ( denominator + flag ) , axis = [number] , ) [EOL] [EOL] return smape [EOL] [EOL] def mape_loss ( self , F , forecast , future_target ) : [EOL] [docstring] [EOL] [EOL] denominator = F . abs ( future_target ) [EOL] flag = denominator == [number] [EOL] [EOL] mape = ( [number] / self . prediction_length ) * F . mean ( ( F . abs ( future_target - forecast ) * ( [number] - flag ) ) / ( denominator + flag ) , axis = [number] , ) [EOL] [EOL] return mape [EOL] [EOL] def mase_loss ( self , F , forecast , future_target , past_target , periodicity , ) : [EOL] [docstring] [EOL] factor = [number] / ( self . context_length + self . prediction_length - periodicity ) [EOL] whole_target = F . concat ( past_target , future_target , dim = [number] ) [EOL] seasonal_error = factor * F . mean ( F . abs ( F . slice_axis ( whole_target , axis = [number] , begin = periodicity , end = None ) - F . slice_axis ( whole_target , axis = [number] , begin = [number] , end = - periodicity ) ) , axis = [number] , ) [EOL] flag = seasonal_error == [number] [EOL] [EOL] mase = ( F . mean ( F . abs ( future_target - forecast ) , axis = [number] ) * ( [number] - flag ) ) / ( seasonal_error + flag ) [EOL] [EOL] return mase [EOL] [EOL] [EOL] class NBEATSTrainingNetwork ( NBEATSNetwork ) : [EOL] @ validated ( ) def __init__ ( self , loss_function , freq , * args , ** kwargs ) : [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] self . loss_function = loss_function [EOL] self . freq = freq [EOL] [EOL] [comment] [EOL] [comment] [EOL] self . periodicity = get_seasonality ( self . freq ) [EOL] [EOL] if self . loss_function == [string] : [EOL] assert ( self . periodicity < self . context_length + self . prediction_length ) , ( [string] [string] ) [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , past_target , future_target ) : [EOL] [docstring] [EOL] [comment] [EOL] forecast = super ( ) . hybrid_forward ( F , past_target = past_target , future_target = future_target ) [EOL] [EOL] if self . loss_function == [string] : [EOL] loss = self . smape_loss ( F , forecast , future_target ) [EOL] elif self . loss_function == [string] : [EOL] loss = self . mape_loss ( F , forecast , future_target ) [EOL] elif self . loss_function == [string] : [EOL] loss = self . mase_loss ( F , forecast , future_target , past_target , self . periodicity ) [EOL] else : [EOL] raise ValueError ( f" [string] { self . loss_function } [string] " ) [EOL] [EOL] return loss [EOL] [EOL] [EOL] class NBEATSPredictionNetwork ( NBEATSNetwork ) : [EOL] @ validated ( ) def __init__ ( self , * args , ** kwargs ) : [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , past_target , future_target = None ) : [EOL] [docstring] [EOL] [comment] [EOL] forecasts = super ( ) . hybrid_forward ( F , past_target = past_target , future_target = past_target ) [EOL] [EOL] [comment] [EOL] forecasts = F . expand_dims ( forecasts , axis = [number] ) [EOL] [EOL] [comment] [EOL] return forecasts [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from . _ensemble import NBEATSEnsembleEstimator , NBEATSEnsemblePredictor [EOL] [EOL] [comment] [EOL] from . _estimator import NBEATSEstimator [EOL] [EOL] __all__ = [ [string] , [string] , [string] , ] [EOL] [EOL] [comment] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional [EOL] import gluonts [EOL] import builtins [EOL] import mxnet [EOL] import typing [EOL] from typing import List , Optional [EOL] [EOL] [comment] [EOL] from mxnet . gluon import HybridBlock [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . dataset . field_names import FieldName [EOL] from gluonts . model . estimator import GluonEstimator [EOL] from gluonts . model . predictor import Predictor , RepresentableBlockPredictor [EOL] from gluonts . mx . trainer import Trainer [EOL] from gluonts . transform import ( Chain , ExpectedNumInstanceSampler , InstanceSplitter , Transformation , ) [EOL] [EOL] [comment] [EOL] from . _network import ( VALID_LOSS_FUNCTIONS , VALID_N_BEATS_STACK_TYPES , NBEATSPredictionNetwork , NBEATSTrainingNetwork , ) [EOL] [EOL] [EOL] class NBEATSEstimator ( GluonEstimator ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] @ validated ( ) def __init__ ( self , freq , prediction_length , context_length = None , trainer = Trainer ( ) , num_stacks = [number] , widths = None , num_blocks = None , num_block_layers = None , expansion_coefficient_lengths = None , sharing = None , stack_types = None , loss_function = [string] , ** kwargs , ) : [EOL] [docstring] [EOL] super ( ) . __init__ ( trainer = trainer , ** kwargs ) [EOL] [EOL] assert ( prediction_length > [number] ) , [string] [EOL] assert ( context_length is None or context_length > [number] ) , [string] [EOL] assert ( num_stacks is None or num_stacks > [number] ) , [string] [EOL] assert ( loss_function is None or loss_function in VALID_LOSS_FUNCTIONS ) , f" [string] { VALID_LOSS_FUNCTIONS } [string] " [EOL] [EOL] self . freq = freq [EOL] self . prediction_length = prediction_length [EOL] self . context_length = ( context_length [EOL] if context_length is not None [EOL] else [number] * prediction_length ) [EOL] [comment] [EOL] self . num_stacks = num_stacks [EOL] self . loss_function = loss_function [EOL] [EOL] self . widths = self . _validate_nbeats_argument ( argument_value = widths , argument_name = [string] , default_value = [ [number] ] , validation_condition = lambda val : val > [number] , invalidation_message = [string] , ) [EOL] self . num_blocks = self . _validate_nbeats_argument ( argument_value = num_blocks , argument_name = [string] , default_value = [ [number] ] , validation_condition = lambda val : val > [number] , invalidation_message = [string] , ) [EOL] self . num_block_layers = self . _validate_nbeats_argument ( argument_value = num_block_layers , argument_name = [string] , default_value = [ [number] ] , validation_condition = lambda val : val > [number] , invalidation_message = [string] , ) [EOL] self . sharing = self . _validate_nbeats_argument ( argument_value = sharing , argument_name = [string] , default_value = [ False ] , validation_condition = lambda val : True , invalidation_message = [string] , ) [EOL] self . expansion_coefficient_lengths = self . _validate_nbeats_argument ( argument_value = expansion_coefficient_lengths , argument_name = [string] , default_value = [ [number] ] , validation_condition = lambda val : val > [number] , invalidation_message = [string] , ) [EOL] self . stack_types = self . _validate_nbeats_argument ( argument_value = stack_types , argument_name = [string] , default_value = [ [string] ] , validation_condition = lambda val : val in VALID_N_BEATS_STACK_TYPES , invalidation_message = f" [string] { VALID_N_BEATS_STACK_TYPES }" , ) [EOL] [EOL] def _validate_nbeats_argument ( self , argument_value , argument_name , default_value , validation_condition , invalidation_message , ) : [EOL] [comment] [EOL] new_value = ( argument_value if argument_value is not None else default_value ) [EOL] [EOL] [comment] [EOL] assert len ( new_value ) == [number] or len ( new_value ) == self . num_stacks , ( f" [string] { argument_name } [string] { len ( new_value ) } [string] " f" [string] { self . num_stacks } [string] " ) [EOL] [EOL] [comment] [EOL] assert all ( [ validation_condition ( val ) for val in new_value ] ) , invalidation_message [EOL] [EOL] [comment] [EOL] if len ( new_value ) == [number] : [EOL] return new_value * self . num_stacks [EOL] else : [EOL] return new_value [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] def create_transformation ( self ) : [EOL] return Chain ( [ InstanceSplitter ( target_field = FieldName . TARGET , is_pad_field = FieldName . IS_PAD , start_field = FieldName . START , forecast_start_field = FieldName . FORECAST_START , train_sampler = ExpectedNumInstanceSampler ( num_instances = [number] ) , past_length = self . context_length , future_length = self . prediction_length , time_series_fields = [ ] , ) ] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] def create_training_network ( self ) : [EOL] return NBEATSTrainingNetwork ( prediction_length = self . prediction_length , context_length = self . context_length , num_stacks = self . num_stacks , widths = self . widths , num_blocks = self . num_blocks , num_block_layers = self . num_block_layers , expansion_coefficient_lengths = self . expansion_coefficient_lengths , sharing = self . sharing , stack_types = self . stack_types , loss_function = self . loss_function , freq = self . freq , ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] def create_predictor ( self , transformation , trained_network ) : [EOL] prediction_network = NBEATSPredictionNetwork ( prediction_length = self . prediction_length , context_length = self . context_length , num_stacks = self . num_stacks , widths = self . widths , num_blocks = self . num_blocks , num_block_layers = self . num_block_layers , expansion_coefficient_lengths = self . expansion_coefficient_lengths , sharing = self . sharing , stack_types = self . stack_types , params = trained_network . collect_params ( ) , ) [EOL] [EOL] return RepresentableBlockPredictor ( input_transform = transformation , prediction_net = prediction_network , batch_size = self . trainer . batch_size , freq = self . freq , prediction_length = self . prediction_length , ctx = self . trainer . ctx , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.mx.trainer.Trainer$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.mx.trainer.Trainer$ 0 $gluonts.mx.trainer.Trainer$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.transform.Transformation$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.predictor.Predictor$ 0 0 0 $gluonts.transform.Transformation$ 0 $mxnet.gluon.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.transform.Transformation$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] import logging [EOL] from typing import List , Optional [EOL] from distutils . util import strtobool [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] import mxnet as mx [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . dataset . stat import calculate_dataset_statistics [EOL] from gluonts . model . seq2seq . _forking_estimator import ForkingSeq2SeqEstimator [EOL] [EOL] from gluonts . mx . distribution import DistributionOutput [EOL] [EOL] from gluonts . mx . block . decoder import ForkingMLPDecoder [EOL] from gluonts . mx . block . encoder import ( HierarchicalCausalConv1DEncoder , RNNEncoder , ) [EOL] from gluonts . mx . block . quantile_output import QuantileOutput [EOL] from gluonts . mx . trainer import Trainer [EOL] [EOL] [EOL] class MQCNNEstimator ( ForkingSeq2SeqEstimator ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , freq , prediction_length , context_length = None , use_past_feat_dynamic_real = False , use_feat_dynamic_real = False , use_feat_static_cat = False , cardinality = None , embedding_dimension = None , add_time_feature = True , add_age_feature = False , enable_encoder_dynamic_feature = True , enable_decoder_dynamic_feature = True , seed = None , decoder_mlp_dim_seq = None , channels_seq = None , dilation_seq = None , kernel_size_seq = None , use_residual = True , quantiles = None , distr_output = None , trainer = Trainer ( ) , scaling = False , scaling_decoder_dynamic_feature = False , num_forking = None , ) : [EOL] [EOL] assert ( distr_output is None ) or ( quantiles is None ) [EOL] assert ( prediction_length > [number] ) , f" [string] { prediction_length } [string] " [EOL] assert decoder_mlp_dim_seq is None or all ( d > [number] for d in decoder_mlp_dim_seq ) , [string] [EOL] assert channels_seq is None or all ( d > [number] for d in channels_seq ) , [string] [EOL] assert dilation_seq is None or all ( d > [number] for d in dilation_seq ) , [string] [EOL] [comment] [EOL] assert kernel_size_seq is None or all ( d > [number] for d in kernel_size_seq ) , [string] [EOL] assert quantiles is None or all ( [number] <= d <= [number] for d in quantiles ) , [string] [EOL] [EOL] self . decoder_mlp_dim_seq = ( decoder_mlp_dim_seq if decoder_mlp_dim_seq is not None else [ [number] ] ) [EOL] self . channels_seq = ( channels_seq if channels_seq is not None else [ [number] , [number] , [number] ] ) [EOL] self . dilation_seq = ( dilation_seq if dilation_seq is not None else [ [number] , [number] , [number] ] ) [EOL] self . kernel_size_seq = ( kernel_size_seq if kernel_size_seq is not None else [ [number] , [number] , [number] ] ) [EOL] self . quantiles = ( quantiles [EOL] if ( quantiles is not None ) or ( distr_output is not None ) [EOL] else [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] [EOL] assert ( len ( self . channels_seq ) == len ( self . dilation_seq ) == len ( self . kernel_size_seq ) ) , ( f" [string] { len ( self . channels_seq ) } [string] " f"{ len ( self . dilation_seq ) } [string] { len ( self . kernel_size_seq ) }" ) [EOL] [EOL] if seed : [EOL] np . random . seed ( seed ) [EOL] mx . random . seed ( seed , trainer . ctx ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] encoder = HierarchicalCausalConv1DEncoder ( dilation_seq = self . dilation_seq , kernel_size_seq = self . kernel_size_seq , channels_seq = self . channels_seq , use_residual = use_residual , use_static_feat = True , use_dynamic_feat = True , prefix = [string] , ) [EOL] [EOL] decoder = ForkingMLPDecoder ( dec_len = prediction_length , final_dim = self . decoder_mlp_dim_seq [ - [number] ] , hidden_dimension_sequence = self . decoder_mlp_dim_seq [ : - [number] ] , prefix = [string] , ) [EOL] [EOL] quantile_output = ( QuantileOutput ( self . quantiles ) if self . quantiles else None ) [EOL] [EOL] super ( ) . __init__ ( encoder = encoder , decoder = decoder , quantile_output = quantile_output , distr_output = distr_output , freq = freq , prediction_length = prediction_length , context_length = context_length , use_past_feat_dynamic_real = use_past_feat_dynamic_real , use_feat_dynamic_real = use_feat_dynamic_real , use_feat_static_cat = use_feat_static_cat , enable_encoder_dynamic_feature = enable_encoder_dynamic_feature , enable_decoder_dynamic_feature = enable_decoder_dynamic_feature , cardinality = cardinality , embedding_dimension = embedding_dimension , add_time_feature = add_time_feature , add_age_feature = add_age_feature , trainer = trainer , scaling = scaling , scaling_decoder_dynamic_feature = scaling_decoder_dynamic_feature , num_forking = num_forking , ) [EOL] [EOL] @ classmethod def derive_auto_fields ( cls , train_iter ) : [EOL] stats = calculate_dataset_statistics ( train_iter ) [EOL] [EOL] return { [string] : stats . num_past_feat_dynamic_real > [number] , [string] : stats . num_feat_dynamic_real > [number] , [string] : bool ( stats . feat_static_cat ) , [string] : [ len ( cats ) for cats in stats . feat_static_cat ] , } [EOL] [EOL] @ classmethod def from_inputs ( cls , train_iter , ** params ) : [EOL] logger = logging . getLogger ( __name__ ) [EOL] logger . info ( f" [string] { params }" ) [EOL] [comment] [EOL] [comment] [EOL] auto_params = cls . derive_auto_fields ( train_iter ) [EOL] [EOL] fields = [ [string] , [string] , [string] , ] [EOL] [comment] [EOL] for field in fields : [EOL] if field in params . keys ( ) : [EOL] is_params_field = ( params [ field ] [EOL] if type ( params [ field ] ) == bool [EOL] else strtobool ( params [ field ] ) ) [EOL] if is_params_field and not auto_params [ field ] : [EOL] logger . warning ( f" [string] { field } [string] " ) [EOL] params [ field ] = False [EOL] if field == [string] : [EOL] params [ [string] ] = None [EOL] elif ( field == [string] [EOL] and not is_params_field [EOL] and auto_params [ field ] ) : [EOL] params [ [string] ] = None [EOL] [EOL] [comment] [EOL] params = { ** auto_params , ** params } [EOL] logger . info ( f" [string] " f" [string] { params [ [string] ] } [string] " f" [string] { params [ [string] ] } [string] " f" [string] { params [ [string] ] } [string] { params [ [string] ] } [string] " ) [EOL] return cls . from_hyperparameters ( ** params ) [EOL] [EOL] [EOL] class MQRNNEstimator ( ForkingSeq2SeqEstimator ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , prediction_length , freq , context_length = None , decoder_mlp_dim_seq = None , trainer = Trainer ( ) , quantiles = None , distr_output = None , scaling = False , scaling_decoder_dynamic_feature = False , ) : [EOL] [EOL] assert ( prediction_length > [number] ) , f" [string] { prediction_length } [string] " [EOL] assert decoder_mlp_dim_seq is None or all ( d > [number] for d in decoder_mlp_dim_seq ) , [string] [EOL] assert quantiles is None or all ( [number] <= d <= [number] for d in quantiles ) , [string] [EOL] [EOL] self . decoder_mlp_dim_seq = ( decoder_mlp_dim_seq if decoder_mlp_dim_seq is not None else [ [number] ] ) [EOL] self . quantiles = ( quantiles [EOL] if ( quantiles is not None ) or ( distr_output is not None ) [EOL] else [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] encoder = RNNEncoder ( mode = [string] , hidden_size = [number] , num_layers = [number] , bidirectional = True , prefix = [string] , use_static_feat = True , use_dynamic_feat = True , ) [EOL] [EOL] decoder = ForkingMLPDecoder ( dec_len = prediction_length , final_dim = self . decoder_mlp_dim_seq [ - [number] ] , hidden_dimension_sequence = self . decoder_mlp_dim_seq [ : - [number] ] , prefix = [string] , ) [EOL] [EOL] quantile_output = ( QuantileOutput ( self . quantiles ) if self . quantiles else None ) [EOL] [EOL] super ( ) . __init__ ( encoder = encoder , decoder = decoder , quantile_output = quantile_output , distr_output = distr_output , freq = freq , prediction_length = prediction_length , context_length = context_length , trainer = trainer , scaling = scaling , scaling_decoder_dynamic_feature = scaling_decoder_dynamic_feature , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 $builtins.int$ 0 $typing.Optional[builtins.int]$ 0 0 0 $builtins.bool$ 0 0 0 $builtins.bool$ 0 0 0 $builtins.bool$ 0 0 0 $typing.List[builtins.int]$ 0 0 0 $typing.List[builtins.int]$ 0 0 0 $builtins.bool$ 0 0 0 $builtins.bool$ 0 0 0 $builtins.bool$ 0 0 0 $builtins.bool$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 $typing.Optional[gluonts.mx.distribution.DistributionOutput]$ 0 0 0 $gluonts.mx.trainer.Trainer$ 0 0 0 0 0 $builtins.bool$ 0 0 0 $builtins.bool$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.mx.distribution.DistributionOutput]$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.mx.distribution.DistributionOutput]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 $gluonts.mx.trainer.Trainer$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.mx.distribution.DistributionOutput]$ 0 $typing.Optional[gluonts.mx.distribution.DistributionOutput]$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.int$ 0 $builtins.int$ 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 $builtins.bool$ 0 $builtins.bool$ 0 $builtins.bool$ 0 $builtins.bool$ 0 $builtins.bool$ 0 $builtins.bool$ 0 $builtins.bool$ 0 $builtins.bool$ 0 $builtins.bool$ 0 $builtins.bool$ 0 $typing.List[builtins.int]$ 0 $typing.List[builtins.int]$ 0 $typing.List[builtins.int]$ 0 $typing.List[builtins.int]$ 0 $builtins.bool$ 0 $builtins.bool$ 0 $builtins.bool$ 0 $builtins.bool$ 0 $gluonts.mx.trainer.Trainer$ 0 $gluonts.mx.trainer.Trainer$ 0 $builtins.bool$ 0 $builtins.bool$ 0 $builtins.bool$ 0 $builtins.bool$ 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.int$ 0 $builtins.str$ 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 $gluonts.mx.trainer.Trainer$ 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.mx.distribution.DistributionOutput]$ 0 0 0 $builtins.bool$ 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.mx.distribution.DistributionOutput]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.mx.distribution.DistributionOutput]$ 0 $typing.Optional[gluonts.mx.distribution.DistributionOutput]$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.int$ 0 $builtins.int$ 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 $gluonts.mx.trainer.Trainer$ 0 $gluonts.mx.trainer.Trainer$ 0 $builtins.bool$ 0 $builtins.bool$ 0 $builtins.bool$ 0 $builtins.bool$ 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Iterator , List , Optional [EOL] import numpy [EOL] import builtins [EOL] import gluonts [EOL] import typing [EOL] from collections import Counter [EOL] from typing import Iterator , List , Optional [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] from numpy . lib . stride_tricks import as_strided [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . dataset . common import DataEntry [EOL] from gluonts . dataset . field_names import FieldName [EOL] from gluonts . transform import FlatMapTransformation , shift_timestamp [EOL] [EOL] [EOL] def pad_to_size ( xs , size ) : [EOL] [docstring] [EOL] pad_length = size - xs . shape [ [number] ] [EOL] if pad_length <= [number] : [EOL] return xs [EOL] [EOL] pad_width = [ ( pad_length , [number] ) ] + ( [ ( [number] , [number] ) ] * ( xs . ndim - [number] ) ) [EOL] return np . pad ( xs , mode = [string] , pad_width = pad_width ) [EOL] [EOL] [EOL] class ForkingSequenceSplitter ( FlatMapTransformation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , train_sampler , enc_len , dec_len , num_forking = None , target_field = FieldName . TARGET , encoder_series_fields = None , decoder_series_fields = None , encoder_disabled_fields = None , decoder_disabled_fields = None , prediction_time_decoder_exclude = None , is_pad_out = [string] , start_input_field = [string] , ) : [EOL] [EOL] assert enc_len > [number] , [string] [EOL] assert dec_len > [number] , [string] [EOL] [EOL] self . train_sampler = train_sampler [EOL] self . enc_len = enc_len [EOL] self . dec_len = dec_len [EOL] self . num_forking = ( num_forking if num_forking is not None else self . enc_len ) [EOL] self . target_field = target_field [EOL] [EOL] self . encoder_series_fields = ( encoder_series_fields + [ self . target_field ] [EOL] if encoder_series_fields is not None [EOL] else [ self . target_field ] ) [EOL] self . decoder_series_fields = ( decoder_series_fields + [ self . target_field ] [EOL] if decoder_series_fields is not None [EOL] else [ self . target_field ] ) [EOL] [EOL] self . encoder_disabled_fields = ( encoder_disabled_fields [EOL] if encoder_disabled_fields is not None [EOL] else [ ] ) [EOL] [EOL] self . decoder_disabled_fields = ( decoder_disabled_fields [EOL] if decoder_disabled_fields is not None [EOL] else [ ] ) [EOL] [EOL] [comment] [EOL] self . prediction_time_decoder_exclude = ( prediction_time_decoder_exclude + [ self . target_field ] [EOL] if prediction_time_decoder_exclude is not None [EOL] else [ self . target_field ] ) [EOL] [EOL] self . is_pad_out = is_pad_out [EOL] self . start_in = start_input_field [EOL] [EOL] def _past ( self , col_name ) : [EOL] return f" [string] { col_name }" [EOL] [EOL] def _future ( self , col_name ) : [EOL] return f" [string] { col_name }" [EOL] [EOL] def flatmap_transform ( self , data , is_train ) : [EOL] target = data [ self . target_field ] [EOL] [EOL] if is_train : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] if len ( target ) < self . dec_len : [EOL] return [EOL] [EOL] sampling_indices = self . train_sampler ( target , [number] , len ( target ) - self . dec_len ) [EOL] else : [EOL] sampling_indices = [ len ( target ) ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] ts_fields_counter = Counter ( set ( self . encoder_series_fields + self . decoder_series_fields ) ) [EOL] [EOL] for sampling_idx in sampling_indices : [EOL] [comment] [EOL] start_idx = max ( [number] , sampling_idx - self . enc_len ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] out = data . copy ( ) [EOL] [EOL] for ts_field in list ( ts_fields_counter . keys ( ) ) : [EOL] [EOL] [comment] [EOL] ts = np . atleast_2d ( out [ ts_field ] ) . T [EOL] [EOL] if ts_fields_counter [ ts_field ] == [number] : [EOL] del out [ ts_field ] [EOL] else : [EOL] ts_fields_counter [ ts_field ] -= [number] [EOL] [EOL] [comment] [EOL] slice = ts [ start_idx : sampling_idx , : ] [EOL] [EOL] ts_len = ts . shape [ [number] ] [EOL] past_piece = np . zeros ( shape = ( self . enc_len , ts_len ) , dtype = ts . dtype ) [EOL] [EOL] if ts_field not in self . encoder_disabled_fields : [EOL] [comment] [EOL] past_piece = pad_to_size ( slice , self . enc_len ) [EOL] out [ self . _past ( ts_field ) ] = past_piece [EOL] [EOL] [comment] [EOL] if ( not is_train [EOL] and ts_field in self . prediction_time_decoder_exclude ) : [EOL] continue [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] if ts_field in self . decoder_series_fields : [EOL] [EOL] forking_dec_field = np . zeros ( shape = ( self . num_forking , self . dec_len , ts_len ) , dtype = ts . dtype , ) [EOL] [comment] [EOL] if ts_field not in self . decoder_disabled_fields : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] skip = max ( [number] , self . num_forking - sampling_idx ) [EOL] start_idx = max ( [number] , sampling_idx - self . num_forking ) [EOL] [comment] [EOL] [comment] [EOL] stride = ts . strides [EOL] forking_dec_field [ skip : , : , : ] = as_strided ( ts [ start_idx + [number] : start_idx + [number] + self . num_forking - skip , : , ] , shape = ( self . num_forking - skip , self . dec_len , ts_len , ) , strides = stride [ [number] : [number] ] + stride , ) [EOL] [comment] [EOL] if forking_dec_field . shape [ - [number] ] == [number] : [EOL] out [ self . _future ( ts_field ) ] = np . squeeze ( forking_dec_field , axis = - [number] ) [EOL] else : [EOL] out [ self . _future ( ts_field ) ] = forking_dec_field [EOL] [EOL] [comment] [EOL] pad_indicator = np . zeros ( self . enc_len ) [EOL] pad_length = max ( [number] , self . enc_len - sampling_idx ) [EOL] pad_indicator [ : pad_length ] = True [EOL] out [ self . _past ( self . is_pad_out ) ] = pad_indicator [EOL] [EOL] [comment] [EOL] out [ FieldName . FORECAST_START ] = shift_timestamp ( out [ self . start_in ] , sampling_idx ) [EOL] [EOL] yield out [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterator[gluonts.dataset.common.DataEntry]$ 0 0 0 $gluonts.dataset.common.DataEntry$ 0 $builtins.bool$ 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import gluonts [EOL] import mxnet as mx [EOL] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] [EOL] [comment] [EOL] from gluonts . mx . block . decoder import Seq2SeqDecoder [EOL] from gluonts . mx . block . enc2dec import Seq2SeqEnc2Dec [EOL] from gluonts . mx . block . encoder import Seq2SeqEncoder [EOL] from gluonts . mx . block . feature import FeatureEmbedder [EOL] from gluonts . mx . block . quantile_output import QuantileOutput [EOL] from gluonts . mx . block . scaler import Scaler [EOL] [EOL] [EOL] class Seq2SeqNetworkBase ( mx . gluon . HybridBlock ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , embedder , scaler , encoder , enc2dec , decoder , quantile_output , ** kwargs , ) : [EOL] super ( ) . __init__ ( ** kwargs ) [EOL] [EOL] self . embedder = embedder [EOL] self . scaler = scaler [EOL] self . encoder = encoder [EOL] self . enc2dec = enc2dec [EOL] self . decoder = decoder [EOL] self . quantile_output = quantile_output [EOL] [EOL] with self . name_scope ( ) : [EOL] self . quantile_proj = quantile_output . get_quantile_proj ( ) [EOL] self . loss = quantile_output . get_loss ( ) [EOL] [EOL] def compute_decoder_outputs ( self , F , past_target , feat_static_cat , past_feat_dynamic_real , future_feat_dynamic_real , ) : [EOL] scaled_target , scale = self . scaler ( past_target , F . ones_like ( past_target ) ) [EOL] [EOL] embedded_cat = self . embedder ( feat_static_cat ) [comment] [EOL] [EOL] encoder_output_static , encoder_output_dynamic = self . encoder ( scaled_target , embedded_cat , past_feat_dynamic_real ) [EOL] decoder_input_static , decoder_input_dynamic = self . enc2dec ( encoder_output_static , encoder_output_dynamic , future_feat_dynamic_real , ) [EOL] decoder_output = self . decoder ( decoder_input_static , decoder_input_dynamic ) [EOL] scaled_decoder_output = F . broadcast_mul ( decoder_output , scale . expand_dims ( - [number] ) . expand_dims ( - [number] ) ) [EOL] return scaled_decoder_output [EOL] [EOL] [EOL] class Seq2SeqTrainingNetwork ( Seq2SeqNetworkBase ) : [EOL] [comment] [EOL] def hybrid_forward ( self , F , past_target , future_target , feat_static_cat , past_feat_dynamic_real , future_feat_dynamic_real , ) : [EOL] [docstring] [EOL] scaled_decoder_output = self . compute_decoder_outputs ( F , past_target = past_target , feat_static_cat = feat_static_cat , past_feat_dynamic_real = past_feat_dynamic_real , future_feat_dynamic_real = future_feat_dynamic_real , ) [EOL] projected = self . quantile_proj ( scaled_decoder_output ) [EOL] loss = self . loss ( future_target , projected ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] return loss [EOL] [EOL] [EOL] class Seq2SeqPredictionNetwork ( Seq2SeqNetworkBase ) : [EOL] [comment] [EOL] def hybrid_forward ( self , F , past_target , feat_static_cat , past_feat_dynamic_real , future_feat_dynamic_real , ) : [EOL] [docstring] [EOL] scaled_decoder_output = self . compute_decoder_outputs ( F , past_target = past_target , feat_static_cat = feat_static_cat , past_feat_dynamic_real = past_feat_dynamic_real , future_feat_dynamic_real = future_feat_dynamic_real , ) [EOL] predictions = self . quantile_proj ( scaled_decoder_output ) . swapaxes ( [number] , [number] ) [EOL] [EOL] return predictions [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from . _mq_dnn_estimator import MQCNNEstimator , MQRNNEstimator [EOL] from . _seq2seq_estimator import RNN2QRForecaster , Seq2SeqEstimator [EOL] [EOL] __all__ = [ [string] , [string] , [string] , [string] , ] [EOL] [EOL] [comment] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional [EOL] import _seq2seq_network [EOL] import mxnet [EOL] import gluonts [EOL] import typing [EOL] import builtins [EOL] from typing import List , Optional [EOL] [EOL] [comment] [EOL] import mxnet as mx [EOL] [EOL] [comment] [EOL] from gluonts import transform [EOL] from gluonts . core . component import validated [EOL] from gluonts . dataset . field_names import FieldName [EOL] from gluonts . model . estimator import GluonEstimator [EOL] from gluonts . model . forecast import Quantile [EOL] from gluonts . model . forecast_generator import QuantileForecastGenerator [EOL] from gluonts . model . predictor import Predictor , RepresentableBlockPredictor [EOL] from gluonts . mx . block . decoder import OneShotDecoder [EOL] from gluonts . mx . block . enc2dec import PassThroughEnc2Dec [EOL] from gluonts . mx . block . encoder import ( HierarchicalCausalConv1DEncoder , MLPEncoder , RNNEncoder , Seq2SeqEncoder , ) [EOL] from gluonts . mx . block . feature import FeatureEmbedder [EOL] from gluonts . mx . block . quantile_output import QuantileOutput [EOL] from gluonts . mx . block . scaler import NOPScaler , Scaler [EOL] from gluonts . mx . trainer import Trainer [EOL] from gluonts . support . util import copy_parameters [EOL] from gluonts . time_feature import time_features_from_frequency_str [EOL] from gluonts . transform import ExpectedNumInstanceSampler [EOL] [EOL] [comment] [EOL] from . _seq2seq_network import Seq2SeqPredictionNetwork , Seq2SeqTrainingNetwork [EOL] [EOL] [EOL] class Seq2SeqEstimator ( GluonEstimator ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , freq , prediction_length , cardinality , embedding_dimension , encoder , decoder_mlp_layer , decoder_mlp_static_dim , scaler = NOPScaler ( ) , context_length = None , quantiles = None , trainer = Trainer ( ) , num_parallel_samples = [number] , ) : [EOL] assert ( prediction_length > [number] ) , [string] [EOL] assert ( context_length is None or context_length > [number] ) , [string] [EOL] assert quantiles is None or all ( [number] <= d <= [number] for d in quantiles ) , [string] [EOL] [EOL] super ( ) . __init__ ( trainer = trainer ) [EOL] [EOL] self . context_length = ( context_length if context_length is not None else prediction_length ) [EOL] self . prediction_length = prediction_length [EOL] self . freq = freq [EOL] self . quantiles = ( quantiles if quantiles is not None else [ [number] , [number] , [number] ] ) [EOL] self . encoder = encoder [EOL] self . decoder_mlp_layer = decoder_mlp_layer [EOL] self . decoder_mlp_static_dim = decoder_mlp_static_dim [EOL] self . scaler = scaler [EOL] self . embedder = FeatureEmbedder ( cardinalities = cardinality , embedding_dims = [ embedding_dimension for _ in cardinality ] , ) [EOL] self . num_parallel_samples = num_parallel_samples [EOL] [EOL] def create_transformation ( self ) : [EOL] return transform . Chain ( trans = [ transform . AsNumpyArray ( field = FieldName . TARGET , expected_ndim = [number] ) , transform . AddTimeFeatures ( start_field = FieldName . START , target_field = FieldName . TARGET , output_field = FieldName . FEAT_TIME , time_features = time_features_from_frequency_str ( self . freq ) , pred_length = self . prediction_length , ) , transform . VstackFeatures ( output_field = FieldName . FEAT_DYNAMIC_REAL , input_fields = [ FieldName . FEAT_TIME ] , ) , transform . SetFieldIfNotPresent ( field = FieldName . FEAT_STATIC_CAT , value = [ [number] ] ) , transform . AsNumpyArray ( field = FieldName . FEAT_STATIC_CAT , expected_ndim = [number] ) , transform . InstanceSplitter ( target_field = FieldName . TARGET , is_pad_field = FieldName . IS_PAD , start_field = FieldName . START , forecast_start_field = FieldName . FORECAST_START , train_sampler = ExpectedNumInstanceSampler ( num_instances = [number] ) , past_length = self . context_length , future_length = self . prediction_length , time_series_fields = [ FieldName . FEAT_DYNAMIC_REAL ] , ) , ] ) [EOL] [EOL] def create_training_network ( self ) : [EOL] distribution = QuantileOutput ( self . quantiles ) [EOL] [EOL] enc2dec = PassThroughEnc2Dec ( ) [EOL] decoder = OneShotDecoder ( decoder_length = self . prediction_length , layer_sizes = self . decoder_mlp_layer , static_outputs_per_time_step = self . decoder_mlp_static_dim , ) [EOL] [EOL] training_network = Seq2SeqTrainingNetwork ( embedder = self . embedder , scaler = self . scaler , encoder = self . encoder , enc2dec = enc2dec , decoder = decoder , quantile_output = distribution , ) [EOL] [EOL] return training_network [EOL] [EOL] def create_predictor ( self , transformation , trained_network , ) : [EOL] [comment] [EOL] quantile_strs = [ Quantile . from_float ( quantile ) . name for quantile in self . quantiles ] [EOL] [EOL] prediction_network = Seq2SeqPredictionNetwork ( embedder = trained_network . embedder , scaler = trained_network . scaler , encoder = trained_network . encoder , enc2dec = trained_network . enc2dec , decoder = trained_network . decoder , quantile_output = trained_network . quantile_output , ) [EOL] [EOL] copy_parameters ( trained_network , prediction_network ) [EOL] [EOL] return RepresentableBlockPredictor ( input_transform = transformation , prediction_net = prediction_network , batch_size = self . trainer . batch_size , freq = self . freq , prediction_length = self . prediction_length , ctx = self . trainer . ctx , forecast_generator = QuantileForecastGenerator ( quantile_strs ) , ) [EOL] [EOL] [EOL] [comment] [EOL] class MLP2QRForecaster ( Seq2SeqEstimator ) : [EOL] @ validated ( ) def __init__ ( self , freq , prediction_length , cardinality , embedding_dimension , encoder_mlp_layer , decoder_mlp_layer , decoder_mlp_static_dim , scaler = NOPScaler ( ) , context_length = None , quantiles = None , trainer = Trainer ( ) , num_parallel_samples = [number] , ) : [EOL] encoder = MLPEncoder ( layer_sizes = encoder_mlp_layer ) [EOL] super ( MLP2QRForecaster , self ) . __init__ ( freq = freq , prediction_length = prediction_length , encoder = encoder , cardinality = cardinality , embedding_dimension = embedding_dimension , decoder_mlp_layer = decoder_mlp_layer , decoder_mlp_static_dim = decoder_mlp_static_dim , context_length = context_length , scaler = scaler , quantiles = quantiles , trainer = trainer , num_parallel_samples = num_parallel_samples , ) [EOL] [EOL] [EOL] class RNN2QRForecaster ( Seq2SeqEstimator ) : [EOL] @ validated ( ) def __init__ ( self , freq , prediction_length , cardinality , embedding_dimension , encoder_rnn_layer , encoder_rnn_num_hidden , decoder_mlp_layer , decoder_mlp_static_dim , encoder_rnn_model = [string] , encoder_rnn_bidirectional = True , scaler = NOPScaler ( ) , context_length = None , quantiles = None , trainer = Trainer ( ) , num_parallel_samples = [number] , ) : [EOL] encoder = RNNEncoder ( mode = encoder_rnn_model , hidden_size = encoder_rnn_num_hidden , num_layers = encoder_rnn_layer , bidirectional = encoder_rnn_bidirectional , use_static_feat = True , use_dynamic_feat = True , ) [EOL] super ( RNN2QRForecaster , self ) . __init__ ( freq = freq , prediction_length = prediction_length , encoder = encoder , cardinality = cardinality , embedding_dimension = embedding_dimension , decoder_mlp_layer = decoder_mlp_layer , decoder_mlp_static_dim = decoder_mlp_static_dim , context_length = context_length , scaler = scaler , quantiles = quantiles , trainer = trainer , num_parallel_samples = num_parallel_samples , ) [EOL] [EOL] [EOL] class CNN2QRForecaster ( Seq2SeqEstimator ) : [EOL] @ validated ( ) def __init__ ( self , freq , prediction_length , cardinality , embedding_dimension , decoder_mlp_layer , decoder_mlp_static_dim , scaler = NOPScaler ( ) , context_length = None , quantiles = None , trainer = Trainer ( ) , num_parallel_samples = [number] , ) : [EOL] encoder = HierarchicalCausalConv1DEncoder ( dilation_seq = [ [number] , [number] , [number] ] , kernel_size_seq = ( [ [number] ] * len ( [ [number] , [number] , [number] ] ) ) , channels_seq = [ [number] , [number] , [number] ] , use_residual = True , use_dynamic_feat = True , use_static_feat = True , ) [EOL] [EOL] super ( CNN2QRForecaster , self ) . __init__ ( freq = freq , prediction_length = prediction_length , encoder = encoder , cardinality = cardinality , embedding_dimension = embedding_dimension , decoder_mlp_layer = decoder_mlp_layer , decoder_mlp_static_dim = decoder_mlp_static_dim , context_length = context_length , scaler = scaler , quantiles = quantiles , trainer = trainer , num_parallel_samples = num_parallel_samples , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 $typing.List[builtins.int]$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.mx.trainer.Trainer$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.mx.trainer.Trainer$ 0 $gluonts.mx.trainer.Trainer$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 $builtins.int$ 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.transform.Transformation$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.predictor.Predictor$ 0 0 0 $gluonts.transform.Transformation$ 0 $_seq2seq_network.Seq2SeqTrainingNetwork$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $_seq2seq_network.Seq2SeqTrainingNetwork$ 0 0 0 0 0 $_seq2seq_network.Seq2SeqTrainingNetwork$ 0 0 0 0 0 $_seq2seq_network.Seq2SeqTrainingNetwork$ 0 0 0 0 0 $_seq2seq_network.Seq2SeqTrainingNetwork$ 0 0 0 0 0 $_seq2seq_network.Seq2SeqTrainingNetwork$ 0 0 0 0 0 $_seq2seq_network.Seq2SeqTrainingNetwork$ 0 0 0 0 0 0 0 0 $_seq2seq_network.Seq2SeqTrainingNetwork$ 0 0 0 0 0 0 0 0 0 0 $gluonts.transform.Transformation$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 $builtins.int$ 0 $typing.List[builtins.int]$ 0 $builtins.int$ 0 $typing.List[builtins.int]$ 0 $typing.List[builtins.int]$ 0 $builtins.int$ 0 $gluonts.mx.block.scaler.Scaler$ 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 $typing.Optional[typing.List[builtins.float]]$ 0 0 0 $gluonts.mx.trainer.Trainer$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 $typing.List[builtins.int]$ 0 $typing.List[builtins.int]$ 0 $builtins.int$ 0 $builtins.int$ 0 $typing.List[builtins.int]$ 0 $typing.List[builtins.int]$ 0 $builtins.int$ 0 $builtins.int$ 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 $gluonts.mx.block.scaler.Scaler$ 0 $gluonts.mx.block.scaler.Scaler$ 0 $typing.Optional[typing.List[builtins.float]]$ 0 $typing.Optional[typing.List[builtins.float]]$ 0 $gluonts.mx.trainer.Trainer$ 0 $gluonts.mx.trainer.Trainer$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 $builtins.int$ 0 $typing.List[builtins.int]$ 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.int$ 0 $typing.List[builtins.int]$ 0 $builtins.int$ 0 $builtins.str$ 0 0 0 $builtins.bool$ 0 0 0 $gluonts.mx.block.scaler.Scaler$ 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 $typing.Optional[typing.List[builtins.float]]$ 0 0 0 $gluonts.mx.trainer.Trainer$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 $typing.List[builtins.int]$ 0 $typing.List[builtins.int]$ 0 $builtins.int$ 0 $builtins.int$ 0 $typing.List[builtins.int]$ 0 $typing.List[builtins.int]$ 0 $builtins.int$ 0 $builtins.int$ 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 $gluonts.mx.block.scaler.Scaler$ 0 $gluonts.mx.block.scaler.Scaler$ 0 $typing.Optional[typing.List[builtins.float]]$ 0 $typing.Optional[typing.List[builtins.float]]$ 0 $gluonts.mx.trainer.Trainer$ 0 $gluonts.mx.trainer.Trainer$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 $builtins.int$ 0 $typing.List[builtins.int]$ 0 $builtins.int$ 0 $typing.List[builtins.int]$ 0 $builtins.int$ 0 $gluonts.mx.block.scaler.Scaler$ 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 $typing.Optional[typing.List[builtins.float]]$ 0 0 0 $gluonts.mx.trainer.Trainer$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 $typing.List[builtins.int]$ 0 $typing.List[builtins.int]$ 0 $builtins.int$ 0 $builtins.int$ 0 $typing.List[builtins.int]$ 0 $typing.List[builtins.int]$ 0 $builtins.int$ 0 $builtins.int$ 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 $gluonts.mx.block.scaler.Scaler$ 0 $gluonts.mx.block.scaler.Scaler$ 0 $typing.Optional[typing.List[builtins.float]]$ 0 $typing.Optional[typing.List[builtins.float]]$ 0 $gluonts.mx.trainer.Trainer$ 0 $gluonts.mx.trainer.Trainer$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from . forecast import PointProcessSampleForecast [EOL] from . predictor import PointProcessGluonPredictor [EOL] from . deeptpp import DeepTPPEstimator [EOL] [EOL] __all__ = [ [string] , [string] , [string] , ] [EOL] [EOL] [EOL] [comment] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from . _estimator import DeepTPPEstimator [EOL] from . _network import DeepTPPTrainingNetwork , DeepTPPPredictionNetwork [EOL] [EOL] __all__ = [ [string] , [string] , [string] , ] [EOL] [EOL] [EOL] [comment] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional , Tuple [EOL] import gluonts [EOL] import builtins [EOL] import mxnet [EOL] import typing [EOL] from typing import List , Optional , Tuple [EOL] [EOL] [comment] [EOL] import mxnet as mx [EOL] from mxnet import nd [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] from gluonts . mx . distribution import CategoricalOutput [EOL] [EOL] [comment] [EOL] from gluonts . model . tpp . distribution . base import TPPDistributionOutput [EOL] from gluonts . model . tpp import distribution [EOL] [EOL] [EOL] [comment] [EOL] class DeepTPPNetworkBase ( mx . gluon . HybridBlock ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , num_marks , interval_length , time_distr_output = distribution . WeibullOutput ( ) , embedding_dim = [number] , num_hidden_dimensions = [number] , output_scale = None , apply_log_to_rnn_inputs = True , ** kwargs , ) : [EOL] super ( ) . __init__ ( ** kwargs ) [EOL] [EOL] self . num_marks = num_marks [EOL] self . interval_length = interval_length [EOL] self . rnn_hidden_size = num_hidden_dimensions [EOL] self . output_scale = output_scale [EOL] self . apply_log_to_rnn_inputs = apply_log_to_rnn_inputs [EOL] [EOL] with self . name_scope ( ) : [EOL] self . embedding = mx . gluon . nn . Embedding ( input_dim = num_marks , output_dim = embedding_dim ) [EOL] self . rnn = mx . gluon . rnn . GRU ( num_hidden_dimensions , input_size = embedding_dim + [number] , layout = [string] , ) [EOL] [comment] [EOL] self . time_distr_output = time_distr_output [EOL] self . time_distr_args_proj = self . time_distr_output . get_args_proj ( ) [EOL] [comment] [EOL] if num_marks > [number] : [EOL] self . mark_distr_output = CategoricalOutput ( num_marks ) [EOL] self . mark_distr_args_proj = ( self . mark_distr_output . get_args_proj ( ) ) [EOL] [EOL] def hybridize ( self , active = True , ** kwargs ) : [EOL] if active : [EOL] raise NotImplementedError ( [string] ) [EOL] [EOL] [EOL] class DeepTPPTrainingNetwork ( DeepTPPNetworkBase ) : [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , target , valid_length , ** kwargs , ) : [EOL] [docstring] [EOL] if F is mx . sym : [EOL] raise ValueError ( [string] ) [EOL] [EOL] batch_size = target . shape [ [number] ] [EOL] [comment] [EOL] [comment] [EOL] target = F . concat ( target , F . zeros ( ( batch_size , [number] , [number] ) ) , dim = [number] ) [EOL] [comment] [EOL] [EOL] ia_times , marks = F . split ( target , num_outputs = [number] , axis = - [number] ) [comment] [EOL] marks = marks . squeeze ( axis = - [number] ) [comment] [EOL] [EOL] valid_length = valid_length . reshape ( - [number] ) . astype ( ia_times . dtype ) [comment] [EOL] [EOL] if self . apply_log_to_rnn_inputs : [EOL] ia_times_input = ia_times . clip ( [number] , np . inf ) . log ( ) [EOL] else : [EOL] ia_times_input = ia_times [EOL] rnn_input = F . concat ( ia_times_input , self . embedding ( marks ) , dim = - [number] ) [EOL] rnn_output = self . rnn ( rnn_input ) [comment] [EOL] [EOL] rnn_init_state = F . zeros ( [ batch_size , [number] , self . rnn_hidden_size ] ) [EOL] history_emb = F . slice_axis ( F . concat ( rnn_init_state , rnn_output , dim = [number] ) , axis = [number] , begin = [number] , end = - [number] , ) [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] ia_times = ia_times . squeeze ( axis = - [number] ) [comment] [EOL] time_remaining = self . interval_length - ia_times . sum ( - [number] ) [comment] [EOL] [comment] [EOL] indices = F . stack ( F . arange ( batch_size ) , valid_length ) [EOL] time_remaining_tensor = F . scatter_nd ( time_remaining , indices , ia_times . shape ) [EOL] ia_times_aug = ia_times + time_remaining_tensor [EOL] [EOL] time_distr_args = self . time_distr_args_proj ( history_emb ) [EOL] time_distr = self . time_distr_output . distribution ( time_distr_args , scale = self . output_scale ) [EOL] log_intensity = time_distr . log_intensity ( ia_times_aug ) [comment] [EOL] log_survival = time_distr . log_survival ( ia_times_aug ) [comment] [EOL] [EOL] if self . num_marks > [number] : [EOL] mark_distr_args = self . mark_distr_args_proj ( history_emb ) [EOL] mark_distr = self . mark_distr_output . distribution ( mark_distr_args ) [EOL] log_intensity = log_intensity + mark_distr . log_prob ( marks ) [EOL] [EOL] def _mask ( x , sequence_length ) : [EOL] return F . SequenceMask ( data = x , sequence_length = sequence_length , axis = [number] , use_sequence_length = True , ) [EOL] [EOL] log_likelihood = F . sum ( ( _mask ( log_intensity , valid_length ) + _mask ( log_survival , valid_length + [number] ) ) , axis = - [number] , ) [comment] [EOL] [EOL] return - log_likelihood [EOL] [EOL] [EOL] class DeepTPPPredictionNetwork ( DeepTPPNetworkBase ) : [EOL] @ validated ( ) def __init__ ( self , prediction_interval_length , num_parallel_samples = [number] , * args , ** kwargs , ) : [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] self . num_parallel_samples = num_parallel_samples [EOL] self . prediction_interval_length = prediction_interval_length [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , past_target , past_valid_length , ) : [EOL] [docstring] [EOL] [comment] [EOL] if F is mx . sym : [EOL] raise ValueError ( [string] ) [EOL] [EOL] assert ( past_target . shape [ - [number] ] == [number] ) , [string] [EOL] [EOL] batch_size = past_target . shape [ [number] ] [EOL] [EOL] [comment] [EOL] past_ia_times , past_marks = F . split ( past_target , num_outputs = [number] , axis = - [number] ) [EOL] past_valid_length = past_valid_length . reshape ( - [number] ) . astype ( past_ia_times . dtype ) [EOL] [EOL] if self . apply_log_to_rnn_inputs : [EOL] past_ia_times_input = past_ia_times . clip ( [number] , np . inf ) . log ( ) [EOL] else : [EOL] past_ia_times_input = past_ia_times [EOL] rnn_input = F . concat ( past_ia_times_input , self . embedding ( past_marks . squeeze ( axis = - [number] ) ) , dim = - [number] , ) [EOL] rnn_output = self . rnn ( rnn_input ) [comment] [EOL] rnn_init_state = F . zeros ( [ batch_size , [number] , self . rnn_hidden_size ] ) [EOL] [EOL] past_history_emb = F . concat ( rnn_init_state , rnn_output , dim = [number] ) [comment] [EOL] [EOL] [comment] [EOL] indices = F . stack ( F . arange ( batch_size ) , past_valid_length ) [EOL] history_emb = F . gather_nd ( past_history_emb , indices ) [comment] [EOL] [EOL] num_total_samples = self . num_parallel_samples * batch_size [EOL] history_emb = history_emb . expand_dims ( [number] ) . repeat ( self . num_parallel_samples , axis = [number] ) [comment] [EOL] history_emb = history_emb . reshape ( [ num_total_samples , self . rnn_hidden_size ] ) [comment] [EOL] [EOL] sampled_ia_times_list = [ ] [EOL] sampled_marks_list = [ ] [EOL] arrival_times = F . zeros ( [ num_total_samples ] ) [EOL] [EOL] [comment] [EOL] past_time_elapsed = past_ia_times . squeeze ( - [number] ) . sum ( - [number] ) [EOL] past_time_remaining = self . interval_length - past_time_elapsed [comment] [EOL] past_time_remaining_repeat = ( past_time_remaining . expand_dims ( [number] ) . repeat ( self . num_parallel_samples , axis = [number] ) . reshape ( [ num_total_samples ] ) ) [comment] [EOL] [EOL] first_step = True [EOL] while F . sum ( arrival_times < self . prediction_interval_length ) > [number] : [EOL] [comment] [EOL] time_distr_args = self . time_distr_args_proj ( history_emb ) [EOL] time_distr = self . time_distr_output . distribution ( time_distr_args , scale = self . output_scale , ) [EOL] if first_step : [EOL] [comment] [EOL] next_ia_times = time_distr . sample ( lower_bound = past_time_remaining_repeat ) [EOL] [comment] [EOL] clipped_ia_times = next_ia_times - past_time_remaining_repeat [EOL] sampled_ia_times_list . append ( clipped_ia_times ) [EOL] arrival_times = arrival_times + clipped_ia_times [EOL] first_step = False [EOL] else : [EOL] next_ia_times = time_distr . sample ( ) [EOL] sampled_ia_times_list . append ( next_ia_times ) [EOL] arrival_times = arrival_times + next_ia_times [EOL] [EOL] [comment] [EOL] if self . num_marks > [number] : [EOL] mark_distr_args = self . mark_distr_args_proj ( history_emb ) [EOL] next_marks = self . mark_distr_output . distribution ( mark_distr_args ) . sample ( ) [EOL] else : [EOL] next_marks = F . zeros ( [ num_total_samples ] ) [EOL] [EOL] sampled_marks_list . append ( next_marks ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] if self . apply_log_to_rnn_inputs : [EOL] next_ia_times_input = next_ia_times . clip ( [number] , np . inf ) . log ( ) [EOL] else : [EOL] next_ia_times_input = next_ia_times [EOL] rnn_input = F . concat ( next_ia_times_input . expand_dims ( - [number] ) , self . embedding ( next_marks ) , dim = - [number] , ) . expand_dims ( [number] ) [EOL] [EOL] history_emb = self . rnn ( rnn_input ) . squeeze ( [number] ) [comment] [EOL] [EOL] sampled_ia_times = F . stack ( * sampled_ia_times_list , axis = - [number] ) [EOL] sampled_marks = F . stack ( * sampled_marks_list , axis = - [number] ) . astype ( [string] ) [EOL] [EOL] sampled_valid_length = F . sum ( F . cumsum ( sampled_ia_times , axis = [number] ) < self . prediction_interval_length , axis = - [number] , ) [EOL] [EOL] def _mask ( x , sequence_length ) : [EOL] return F . SequenceMask ( data = x , sequence_length = sequence_length , axis = [number] , use_sequence_length = True , ) [EOL] [EOL] sampled_ia_times = _mask ( sampled_ia_times , sampled_valid_length ) [EOL] sampled_marks = _mask ( sampled_marks , sampled_valid_length ) [EOL] [EOL] sampled_ia_times = sampled_ia_times . reshape ( [ self . num_parallel_samples , batch_size , - [number] ] ) [EOL] sampled_marks = sampled_marks . reshape ( [ self . num_parallel_samples , batch_size , - [number] ] ) [EOL] sampled_valid_length = sampled_valid_length . reshape ( [ self . num_parallel_samples , batch_size ] ) [EOL] sampled_target = F . stack ( sampled_ia_times , sampled_marks , axis = - [number] ) [EOL] return sampled_target , sampled_valid_length [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor]$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[mxnet.nd.NDArray]$ 0 0 0 0 $typing.List[mxnet.nd.NDArray]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[mxnet.nd.NDArray]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[mxnet.nd.NDArray]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[mxnet.nd.NDArray]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[mxnet.nd.NDArray]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[mxnet.nd.NDArray]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] from typing import Optional [EOL] import mxnet [EOL] import gluonts [EOL] import typing [EOL] import builtins [EOL] import _network [EOL] from functools import partial [EOL] from typing import Optional [EOL] [EOL] from gluonts . dataset . parallelized_loader import batchify [EOL] from mxnet . gluon import HybridBlock [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . dataset . common import Dataset [EOL] from gluonts . model . estimator import GluonEstimator , TrainOutput [EOL] from gluonts . model . predictor import Predictor [EOL] from gluonts . model . tpp import PointProcessGluonPredictor [EOL] from gluonts . model . tpp . distribution import TPPDistributionOutput , WeibullOutput [EOL] from gluonts . mx . trainer import Trainer [EOL] from gluonts . transform import ( Chain , ContinuousTimeUniformSampler , ContinuousTimeInstanceSplitter , RenameFields , Transformation , ) [EOL] [EOL] [comment] [EOL] from . _network import DeepTPPTrainingNetwork , DeepTPPPredictionNetwork [EOL] [EOL] [EOL] class DeepTPPEstimator ( GluonEstimator ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , prediction_interval_length , context_interval_length , num_marks , time_distr_output = WeibullOutput ( ) , embedding_dim = [number] , trainer = Trainer ( hybridize = False ) , num_hidden_dimensions = [number] , num_parallel_samples = [number] , num_training_instances = [number] , freq = [string] , ) : [EOL] assert ( not trainer . hybridize ) , [string] [EOL] [EOL] super ( ) . __init__ ( trainer = trainer ) [EOL] [EOL] assert ( prediction_interval_length > [number] ) , [string] [EOL] assert ( context_interval_length is None or context_interval_length > [number] ) , [string] [EOL] assert ( num_hidden_dimensions > [number] ) , [string] [EOL] assert ( num_parallel_samples > [number] ) , [string] [EOL] assert num_marks > [number] , [string] [EOL] assert ( num_training_instances > [number] ) , [string] [EOL] [EOL] self . num_hidden_dimensions = num_hidden_dimensions [EOL] self . prediction_interval_length = prediction_interval_length [EOL] self . context_interval_length = ( context_interval_length [EOL] if context_interval_length is not None [EOL] else prediction_interval_length ) [EOL] self . num_marks = num_marks [EOL] self . time_distr_output = time_distr_output [EOL] self . embedding_dim = embedding_dim [EOL] self . num_parallel_samples = num_parallel_samples [EOL] self . num_training_instances = num_training_instances [EOL] self . freq = freq [EOL] [EOL] def create_training_network ( self ) : [EOL] return DeepTPPTrainingNetwork ( num_marks = self . num_marks , time_distr_output = self . time_distr_output , interval_length = self . prediction_interval_length , embedding_dim = self . embedding_dim , num_hidden_dimensions = self . num_hidden_dimensions , ) [EOL] [EOL] def create_transformation ( self ) : [EOL] return Chain ( [ ContinuousTimeInstanceSplitter ( past_interval_length = self . context_interval_length , future_interval_length = self . prediction_interval_length , train_sampler = ContinuousTimeUniformSampler ( num_instances = self . num_training_instances ) , ) , RenameFields ( { [string] : [string] , [string] : [string] , } ) , ] ) [EOL] [EOL] def create_predictor ( self , transformation , trained_network , ) : [EOL] prediction_network = DeepTPPPredictionNetwork ( num_marks = self . num_marks , prediction_interval_length = self . prediction_interval_length , interval_length = self . context_interval_length , embedding_dim = self . embedding_dim , num_hidden_dimensions = self . num_hidden_dimensions , time_distr_output = trained_network . time_distr_output , params = trained_network . collect_params ( ) , num_parallel_samples = self . num_parallel_samples , ) [EOL] [EOL] return PointProcessGluonPredictor ( input_names = [ [string] , [string] ] , prediction_net = prediction_network , batch_size = self . trainer . batch_size , prediction_interval_length = self . prediction_interval_length , freq = self . freq , ctx = self . trainer . ctx , input_transform = transformation , ) [EOL] [EOL] def train_model ( self , training_data , validation_data = None , num_workers = None , num_prefetch = None , shuffle_buffer_length = None , ** kwargs , ) : [EOL] return super ( ) . train_model ( training_data , validation_data , num_workers , num_prefetch , shuffle_buffer_length , batchify_fn = partial ( batchify , variable_length = True ) , ** kwargs , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.mx.trainer.Trainer$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.mx.trainer.Trainer$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.mx.trainer.Trainer$ 0 $gluonts.mx.trainer.Trainer$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.transform.Transformation$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.predictor.Predictor$ 0 0 0 $gluonts.transform.Transformation$ 0 $_network.DeepTPPTrainingNetwork$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $_network.DeepTPPTrainingNetwork$ 0 0 0 0 0 $_network.DeepTPPTrainingNetwork$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.transform.Transformation$ 0 0 0 0 0 $gluonts.model.estimator.TrainOutput$ 0 0 0 $gluonts.dataset.common.Dataset$ 0 $typing.Optional[gluonts.dataset.common.Dataset]$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.Dataset$ 0 $typing.Optional[gluonts.dataset.common.Dataset]$ 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from . base import ( TPPDistribution , TPPDistributionOutput , TPPTransformedDistribution , ) [EOL] from . loglogistic import Loglogistic , LoglogisticOutput [EOL] from . weibull import Weibull , WeibullOutput [EOL] [EOL] __all__ = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Optional , Tuple , Dict [EOL] import typing [EOL] import builtins [EOL] import gluonts [EOL] from typing import Dict , Optional , Tuple [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] from mxnet import autograd , nd [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] from gluonts . mx . distribution . distribution import getF [EOL] [EOL] [comment] [EOL] from . base import TPPDistribution , TPPDistributionOutput [EOL] [EOL] [EOL] class Loglogistic ( TPPDistribution ) : [EOL] [docstring] [EOL] [EOL] is_reparametrizable = True [EOL] [EOL] @ validated ( ) def __init__ ( self , mu , sigma ) : [EOL] self . mu = mu [EOL] self . sigma = sigma [EOL] [EOL] @ property def batch_shape ( self ) : [EOL] return self . mu . shape [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL] [EOL] @ property def event_dim ( self ) : [EOL] return [number] [EOL] [EOL] @ property def mean ( self ) : [EOL] result = ( self . mu . exp ( ) * self . sigma * np . pi / ( self . sigma * np . pi ) . sin ( ) ) [EOL] [comment] [EOL] return nd . where ( self . sigma > [number] , nd . full ( result . shape , np . inf ) , result ) [EOL] [EOL] def log_intensity ( self , x ) : [EOL] [docstring] [EOL] log_x = x . clip ( [number] , np . inf ) . log ( ) [EOL] z = ( log_x - self . mu ) / self . sigma [EOL] F = getF ( x ) [EOL] return z - self . sigma . log ( ) - F . Activation ( z , [string] ) - log_x [EOL] [EOL] def log_survival ( self , x ) : [EOL] [docstring] [EOL] log_x = x . clip ( [number] , np . inf ) . log ( ) [EOL] z = ( log_x - self . mu ) / self . sigma [EOL] F = getF ( x ) [EOL] return - F . Activation ( z , [string] ) [EOL] [EOL] def log_prob ( self , x ) : [EOL] return self . log_intensity ( x ) + self . log_survival ( x ) [EOL] [EOL] def sample ( self , num_samples = None , dtype = np . float32 , lower_bound = None , ) : [EOL] [docstring] [EOL] F = getF ( self . mu ) [EOL] if num_samples is not None : [EOL] sample_shape = ( num_samples , ) + self . batch_shape [EOL] else : [EOL] sample_shape = self . batch_shape [EOL] u = F . uniform ( [number] , [number] , shape = sample_shape ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] with autograd . pause ( ) : [EOL] if lower_bound is not None : [EOL] survival = self . log_survival ( lower_bound ) . exp ( ) [EOL] u = u * survival [EOL] x = ( self . mu + self . sigma * ( F . log1p ( - u ) - F . log ( u ) ) ) . exp ( ) [EOL] return x [EOL] [EOL] [EOL] class LoglogisticOutput ( TPPDistributionOutput ) : [EOL] args_dim = { [string] : [number] , [string] : [number] } [EOL] distr_cls = Loglogistic [EOL] [EOL] @ classmethod def domain_map ( cls , F , mu , sigma ) : [EOL] [docstring] [EOL] sigma = F . Activation ( sigma , [string] ) [EOL] return mu . squeeze ( axis = - [number] ) , sigma . squeeze ( axis = - [number] ) [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.type$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Union , Tuple , Optional [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] from typing import List , Optional , Tuple , Union [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] from mxnet import autograd [EOL] [EOL] [comment] [EOL] from gluonts . model . common import Tensor [EOL] from gluonts . mx . distribution . distribution import Distribution , getF [EOL] from gluonts . mx . distribution . distribution_output import DistributionOutput [EOL] from gluonts . mx . distribution . bijection import AffineTransformation , Bijection [EOL] from gluonts . mx . distribution . transformed_distribution import ( sum_trailing_axes , TransformedDistribution , ) [EOL] [EOL] [EOL] class TPPDistribution ( Distribution ) : [EOL] [docstring] [EOL] [EOL] def log_intensity ( self , x ) : [EOL] [docstring] [EOL] raise NotImplementedError ( ) [EOL] [EOL] def log_survival ( self , x ) : [EOL] [docstring] [EOL] raise NotImplementedError ( ) [EOL] [EOL] def log_prob ( self , x ) : [EOL] return self . log_intensity ( x ) + self . log_survival ( x ) [EOL] [EOL] def cdf ( self , y ) : [EOL] return [number] - self . log_survival ( y ) . exp ( ) [EOL] [EOL] def sample ( self , num_samples = None , dtype = np . float32 , lower_bound = None , ) : [EOL] raise NotImplementedError ( ) [EOL] [EOL] [EOL] class TPPTransformedDistribution ( TransformedDistribution ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] base_distribution = ... [EOL] [EOL] def __init__ ( self , base_distribution , transforms ) : [EOL] self . base_distribution = base_distribution [EOL] self . transforms = transforms [EOL] self . _check_signs ( transforms ) [EOL] self . is_reparameterizable = self . base_distribution . is_reparameterizable [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] self . _event_dim = None [EOL] self . _event_shape = None [EOL] self . _batch_shape = None [EOL] [EOL] def _check_signs ( self , transforms ) : [EOL] [docstring] [EOL] sign = [number] [EOL] for t in transforms : [EOL] sign = sign * t . sign [EOL] if ( sign != [number] ) . asnumpy ( ) . any ( ) : [EOL] raise ValueError ( [string] ) [EOL] [EOL] def log_intensity ( self , y ) : [EOL] [docstring] [EOL] F = getF ( y ) [EOL] lp = [number] [EOL] x = y [EOL] for t in self . transforms [ : : - [number] ] : [EOL] x = t . f_inv ( y ) [EOL] ladj = t . log_abs_det_jac ( x , y ) [EOL] lp -= sum_trailing_axes ( F , ladj , self . event_dim - t . event_dim ) [EOL] y = x [EOL] return self . base_distribution . log_intensity ( x ) + lp [EOL] [EOL] def log_survival ( self , y ) : [EOL] [docstring] [EOL] x = y [EOL] for t in self . transforms [ : : - [number] ] : [EOL] x = t . f_inv ( x ) [EOL] return self . base_distribution . log_survival ( x ) [EOL] [EOL] def cdf ( self , y ) : [EOL] return [number] - self . log_survival ( y ) . exp ( ) [EOL] [EOL] def sample ( self , num_samples = None , dtype = np . float32 , lower_bound = None , ) : [EOL] [docstring] [EOL] with autograd . pause ( ) : [EOL] if lower_bound is not None : [EOL] z = lower_bound [EOL] for t in self . transforms [ : : - [number] ] : [EOL] z = t . f_inv ( z ) [EOL] lower_bound = z [EOL] x = self . base_distribution . sample ( num_samples = num_samples , lower_bound = lower_bound ) [EOL] [comment] [EOL] for t in self . transforms : [EOL] x = t . f ( x ) [EOL] return x . astype ( dtype ) [EOL] [EOL] [EOL] class TPPDistributionOutput ( DistributionOutput ) : [EOL] [docstring] [EOL] distr_cls = ... [EOL] [EOL] def distribution ( self , distr_args , loc = None , scale = None , ) : [EOL] [docstring] [EOL] if loc is not None : [EOL] raise ValueError ( [string] ) [EOL] if scale is None : [EOL] return self . distr_cls ( * distr_args ) [EOL] else : [EOL] distr = self . distr_cls ( * distr_args ) [EOL] return TPPTransformedDistribution ( distr , [ AffineTransformation ( scale = scale ) ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $TPPDistribution$ 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 $typing.Optional[typing.Tuple]$ 0 0 0 0 0 $typing.Optional[typing.Tuple]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.type$ 0 0 0 0 0 $typing.Union[TPPDistribution,TPPTransformedDistribution]$ 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Optional , Tuple , Dict [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] from typing import Dict , Optional , Tuple [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] from mxnet import autograd , nd [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] from gluonts . mx . distribution . distribution import getF [EOL] [EOL] [comment] [EOL] from . base import TPPDistribution , TPPDistributionOutput [EOL] [EOL] [EOL] class Weibull ( TPPDistribution ) : [EOL] [docstring] [EOL] is_reparametrizable = True [EOL] [EOL] @ validated ( ) def __init__ ( self , rate , shape ) : [EOL] self . rate = rate [EOL] self . shape = shape [EOL] [EOL] @ property def batch_shape ( self ) : [EOL] return self . rate . shape [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL] [EOL] @ property def event_dim ( self ) : [EOL] return [number] [EOL] [EOL] @ property def mean ( self ) : [EOL] return nd . power ( self . rate , - [number] / self . shape ) * nd . gamma ( [number] + [number] / self . shape ) [EOL] [EOL] def log_intensity ( self , x ) : [EOL] [docstring] [EOL] log_x = x . clip ( [number] , np . inf ) . log ( ) [EOL] return self . rate . log ( ) + self . shape . log ( ) + ( self . shape - [number] ) * log_x [EOL] [EOL] def log_survival ( self , x ) : [EOL] [docstring] [EOL] [comment] [EOL] return - self . rate * ( x + [number] ) ** self . shape [EOL] [EOL] def log_prob ( self , x ) : [EOL] return self . log_intensity ( x ) + self . log_survival ( x ) [EOL] [EOL] def sample ( self , num_samples = None , dtype = np . float32 , lower_bound = None , ) : [EOL] [docstring] [EOL] F = getF ( self . rate ) [EOL] if num_samples is not None : [EOL] sample_shape = ( num_samples , ) + self . batch_shape [EOL] else : [EOL] sample_shape = self . batch_shape [EOL] u = F . uniform ( [number] , [number] , shape = sample_shape ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] with autograd . pause ( ) : [EOL] if lower_bound is not None : [EOL] survival = self . log_survival ( lower_bound ) . exp ( ) [EOL] u = u * survival [EOL] x = ( - u . log ( ) / self . rate ) ** ( [number] / self . shape ) [EOL] return x [EOL] [EOL] [EOL] class WeibullOutput ( TPPDistributionOutput ) : [EOL] args_dim = { [string] : [number] , [string] : [number] } [EOL] distr_cls = Weibull [EOL] [EOL] @ classmethod def domain_map ( cls , F , rate , shape ) : [EOL] [docstring] [EOL] rate = F . Activation ( rate , [string] ) [EOL] shape = F . Activation ( shape , [string] ) [EOL] return rate . squeeze ( axis = - [number] ) , shape . squeeze ( axis = - [number] ) [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.type$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Optional [EOL] import numpy [EOL] import builtins [EOL] import gluonts [EOL] import typing [EOL] from typing import Optional [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] import statsmodels . api as sm [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . dataset . common import DataEntry [EOL] from gluonts . model . forecast import Forecast , SampleForecast [EOL] from gluonts . model . predictor import RepresentablePredictor [EOL] from gluonts . support . pandas import forecast_start [EOL] from gluonts . time_feature import get_seasonality [EOL] [EOL] [EOL] def seasonality_test ( past_ts_data , season_length ) : [EOL] [docstring] [EOL] critical_z_score = [number] [comment] [EOL] if len ( past_ts_data ) < [number] * season_length : [EOL] return False [EOL] else : [EOL] [comment] [EOL] auto_correlations = sm . tsa . stattools . acf ( past_ts_data , fft = False , nlags = season_length ) [EOL] auto_correlations [ [number] : ] = [number] * auto_correlations [ [number] : ] ** [number] [EOL] limit = ( critical_z_score / np . sqrt ( len ( past_ts_data ) ) * np . sqrt ( np . cumsum ( auto_correlations ) ) ) [EOL] is_seasonal = ( abs ( auto_correlations [ season_length ] ) > limit [ season_length ] ) [EOL] [EOL] return is_seasonal [EOL] [EOL] [EOL] def naive_2 ( past_ts_data , prediction_length , freq = None , season_length = None , ) : [EOL] [docstring] [EOL] assert freq is not None or season_length is not None , ( [string] [string] ) [EOL] season_length = ( season_length if season_length is not None else get_seasonality ( freq ) ) [EOL] has_seasonality = False [EOL] [EOL] if season_length > [number] : [EOL] has_seasonality = seasonality_test ( past_ts_data , season_length ) [EOL] [EOL] [comment] [EOL] if has_seasonality : [EOL] [comment] [EOL] seasonal_decomposition = sm . tsa . seasonal_decompose ( x = past_ts_data , period = season_length , model = [string] ) . seasonal [EOL] seasonality_normed_context = past_ts_data / seasonal_decomposition [EOL] [EOL] last_period = seasonal_decomposition [ - season_length : ] [EOL] num_required_periods = ( prediction_length // len ( last_period ) ) + [number] [EOL] [EOL] multiplicative_seasonal_component = np . tile ( last_period , num_required_periods ) [ : prediction_length ] [EOL] else : [EOL] seasonality_normed_context = past_ts_data [EOL] multiplicative_seasonal_component = np . ones ( prediction_length ) [comment] [EOL] [EOL] [comment] [EOL] naive_forecast = ( np . ones ( prediction_length ) * seasonality_normed_context [ - [number] ] ) [EOL] [EOL] forecast = np . mean ( naive_forecast ) * multiplicative_seasonal_component [EOL] [EOL] return forecast [EOL] [EOL] [EOL] class Naive2Predictor ( RepresentablePredictor ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , freq , prediction_length , season_length = None , ) : [EOL] super ( ) . __init__ ( freq = freq , prediction_length = prediction_length ) [EOL] [EOL] assert ( season_length is None or season_length > [number] ) , [string] [EOL] [EOL] self . freq = freq [EOL] self . prediction_length = prediction_length [EOL] self . season_length = ( season_length [EOL] if season_length is not None [EOL] else get_seasonality ( freq ) ) [EOL] [EOL] def predict_item ( self , item ) : [EOL] past_ts_data = item [ [string] ] [EOL] forecast_start_time = forecast_start ( item ) [EOL] [EOL] assert ( len ( past_ts_data ) >= [number] ) , [string] [EOL] [EOL] prediction = naive_2 ( past_ts_data , self . prediction_length , self . freq ) [EOL] [EOL] samples = np . array ( [ prediction ] ) [EOL] [EOL] return SampleForecast ( samples , forecast_start_time , self . freq ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.forecast.Forecast$ 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from . _predictor import Naive2Predictor , naive_2 [EOL] [EOL] __all__ = [ [string] , [string] ] [EOL] [EOL] [comment] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import List , Optional [EOL] import mxnet [EOL] import gluonts [EOL] import typing [EOL] import builtins [EOL] import _network [EOL] from typing import List , Optional [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from mxnet . gluon import HybridBlock [EOL] from pandas . tseries . frequencies import to_offset [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . dataset . field_names import FieldName [EOL] from gluonts . model . deepstate . issm import ISSM , CompositeISSM [EOL] from gluonts . model . estimator import GluonEstimator [EOL] from gluonts . model . predictor import Predictor , RepresentableBlockPredictor [EOL] from gluonts . mx . distribution . lds import ParameterBounds [EOL] from gluonts . mx . trainer import Trainer [EOL] from gluonts . support . util import copy_parameters [EOL] from gluonts . time_feature import TimeFeature , time_features_from_frequency_str [EOL] from gluonts . transform import ( AddAgeFeature , AddObservedValuesIndicator , AddTimeFeatures , AsNumpyArray , CanonicalInstanceSplitter , Chain , ExpandDimArray , RemoveFields , SetField , TestSplitSampler , Transformation , VstackFeatures , ) [EOL] [EOL] [comment] [EOL] from . _network import DeepStatePredictionNetwork , DeepStateTrainingNetwork [EOL] [EOL] SEASON_INDICATORS_FIELD = [string] [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] FREQ_LONGEST_PERIOD_DICT = { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , } [EOL] [EOL] [EOL] def longest_period_from_frequency_str ( freq_str ) : [EOL] offset = to_offset ( freq_str ) [EOL] return FREQ_LONGEST_PERIOD_DICT [ offset . name ] // offset . n [EOL] [EOL] [EOL] class DeepStateEstimator ( GluonEstimator ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , freq , prediction_length , cardinality , add_trend = False , past_length = None , num_periods_to_train = [number] , trainer = Trainer ( epochs = [number] , num_batches_per_epoch = [number] , hybridize = False ) , num_layers = [number] , num_cells = [number] , cell_type = [string] , num_parallel_samples = [number] , dropout_rate = [number] , use_feat_dynamic_real = False , use_feat_static_cat = True , embedding_dimension = None , issm = None , scaling = True , time_features = None , noise_std_bounds = ParameterBounds ( [number] , [number] ) , prior_cov_bounds = ParameterBounds ( [number] , [number] ) , innovation_bounds = ParameterBounds ( [number] , [number] ) , ) : [EOL] super ( ) . __init__ ( trainer = trainer ) [EOL] [EOL] assert ( prediction_length > [number] ) , [string] [EOL] assert ( past_length is None or past_length > [number] ) , [string] [EOL] assert num_layers > [number] , [string] [EOL] assert num_cells > [number] , [string] [EOL] assert ( num_parallel_samples > [number] ) , [string] [EOL] assert dropout_rate >= [number] , [string] [EOL] assert not use_feat_static_cat or any ( c > [number] for c in cardinality ) , ( f" [string] " f" [string] { cardinality }" ) [EOL] assert embedding_dimension is None or all ( e > [number] for e in embedding_dimension ) , [string] [EOL] [EOL] assert all ( np . isfinite ( p . lower ) and np . isfinite ( p . upper ) and p . lower > [number] for p in [ noise_std_bounds , prior_cov_bounds , innovation_bounds ] ) , [string] [EOL] [EOL] self . freq = freq [EOL] self . past_length = ( past_length [EOL] if past_length is not None [EOL] else num_periods_to_train * longest_period_from_frequency_str ( freq ) ) [EOL] self . prediction_length = prediction_length [EOL] self . add_trend = add_trend [EOL] self . num_layers = num_layers [EOL] self . num_cells = num_cells [EOL] self . cell_type = cell_type [EOL] self . num_parallel_samples = num_parallel_samples [EOL] self . scaling = scaling [EOL] self . dropout_rate = dropout_rate [EOL] self . use_feat_dynamic_real = use_feat_dynamic_real [EOL] self . use_feat_static_cat = use_feat_static_cat [EOL] self . cardinality = ( cardinality if cardinality and use_feat_static_cat else [ [number] ] ) [EOL] self . embedding_dimension = ( embedding_dimension [EOL] if embedding_dimension is not None [EOL] else [ min ( [number] , ( cat + [number] ) // [number] ) for cat in self . cardinality ] ) [EOL] [EOL] self . issm = ( issm [EOL] if issm is not None [EOL] else CompositeISSM . get_from_freq ( freq , add_trend ) ) [EOL] [EOL] self . time_features = ( time_features [EOL] if time_features is not None [EOL] else time_features_from_frequency_str ( self . freq ) ) [EOL] [EOL] self . noise_std_bounds = noise_std_bounds [EOL] self . prior_cov_bounds = prior_cov_bounds [EOL] self . innovation_bounds = innovation_bounds [EOL] [EOL] def create_transformation ( self ) : [EOL] remove_field_names = [ FieldName . FEAT_DYNAMIC_CAT , FieldName . FEAT_STATIC_REAL , ] [EOL] if not self . use_feat_dynamic_real : [EOL] remove_field_names . append ( FieldName . FEAT_DYNAMIC_REAL ) [EOL] [EOL] return Chain ( [ RemoveFields ( field_names = remove_field_names ) ] + ( [ SetField ( output_field = FieldName . FEAT_STATIC_CAT , value = [ [number] ] ) ] [EOL] if not self . use_feat_static_cat [EOL] else [ ] ) + [ AsNumpyArray ( field = FieldName . FEAT_STATIC_CAT , expected_ndim = [number] ) , AsNumpyArray ( field = FieldName . TARGET , expected_ndim = [number] ) , ExpandDimArray ( field = FieldName . TARGET , axis = [number] ) , AddObservedValuesIndicator ( target_field = FieldName . TARGET , output_field = FieldName . OBSERVED_VALUES , ) , AddTimeFeatures ( time_features = CompositeISSM . seasonal_features ( self . freq ) , pred_length = self . prediction_length , start_field = FieldName . START , target_field = FieldName . TARGET , output_field = SEASON_INDICATORS_FIELD , ) , AddTimeFeatures ( start_field = FieldName . START , target_field = FieldName . TARGET , output_field = FieldName . FEAT_TIME , time_features = self . time_features , pred_length = self . prediction_length , ) , AddAgeFeature ( target_field = FieldName . TARGET , output_field = FieldName . FEAT_AGE , pred_length = self . prediction_length , log_scale = True , ) , VstackFeatures ( output_field = FieldName . FEAT_TIME , input_fields = [ FieldName . FEAT_TIME , FieldName . FEAT_AGE ] + ( [ FieldName . FEAT_DYNAMIC_REAL ] [EOL] if self . use_feat_dynamic_real [EOL] else [ ] ) , ) , CanonicalInstanceSplitter ( target_field = FieldName . TARGET , is_pad_field = FieldName . IS_PAD , start_field = FieldName . START , forecast_start_field = FieldName . FORECAST_START , instance_sampler = TestSplitSampler ( ) , time_series_fields = [ FieldName . FEAT_TIME , SEASON_INDICATORS_FIELD , FieldName . OBSERVED_VALUES , ] , allow_target_padding = True , instance_length = self . past_length , use_prediction_features = True , prediction_length = self . prediction_length , ) , ] ) [EOL] [EOL] def create_training_network ( self ) : [EOL] return DeepStateTrainingNetwork ( num_layers = self . num_layers , num_cells = self . num_cells , cell_type = self . cell_type , past_length = self . past_length , prediction_length = self . prediction_length , issm = self . issm , dropout_rate = self . dropout_rate , cardinality = self . cardinality , embedding_dimension = self . embedding_dimension , scaling = self . scaling , noise_std_bounds = self . noise_std_bounds , prior_cov_bounds = self . prior_cov_bounds , innovation_bounds = self . innovation_bounds , ) [EOL] [EOL] def create_predictor ( self , transformation , trained_network ) : [EOL] prediction_network = DeepStatePredictionNetwork ( num_layers = self . num_layers , num_cells = self . num_cells , cell_type = self . cell_type , past_length = self . past_length , prediction_length = self . prediction_length , issm = self . issm , dropout_rate = self . dropout_rate , cardinality = self . cardinality , embedding_dimension = self . embedding_dimension , scaling = self . scaling , num_parallel_samples = self . num_parallel_samples , noise_std_bounds = self . noise_std_bounds , prior_cov_bounds = self . prior_cov_bounds , innovation_bounds = self . innovation_bounds , params = trained_network . collect_params ( ) , ) [EOL] [EOL] copy_parameters ( trained_network , prediction_network ) [EOL] [EOL] return RepresentableBlockPredictor ( input_transform = transformation , prediction_net = prediction_network , batch_size = self . trainer . batch_size , freq = self . freq , prediction_length = self . prediction_length , ctx = self . trainer . ctx , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $gluonts.mx.trainer.Trainer$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.mx.trainer.Trainer$ 0 $gluonts.mx.trainer.Trainer$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.transform.Transformation$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $_network.DeepStateTrainingNetwork$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.predictor.Predictor$ 0 0 0 $gluonts.transform.Transformation$ 0 $mxnet.gluon.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 $gluonts.transform.Transformation$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Tuple [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] from typing import List , Tuple [EOL] [EOL] [comment] [EOL] from pandas . tseries . frequencies import to_offset [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] from gluonts . mx . distribution . distribution import getF [EOL] from gluonts . support . util import _broadcast_param [EOL] from gluonts . time_feature import ( DayOfWeek , HourOfDay , MinuteOfHour , MonthOfYear , TimeFeature , WeekOfYear , ) [EOL] [EOL] [EOL] def _make_block_diagonal ( blocks ) : [EOL] assert ( len ( blocks ) > [number] ) , [string] [EOL] [EOL] if len ( blocks ) == [number] : [EOL] return blocks [ [number] ] [EOL] [EOL] F = getF ( blocks [ [number] ] ) [EOL] [EOL] [comment] [EOL] block_diagonal = _make_2_block_diagonal ( F , blocks [ [number] ] , blocks [ [number] ] ) [EOL] for i in range ( [number] , len ( blocks ) ) : [EOL] block_diagonal = _make_2_block_diagonal ( F = F , left = block_diagonal , right = blocks [ i ] ) [EOL] [EOL] return block_diagonal [EOL] [EOL] [EOL] def _make_2_block_diagonal ( F , left , right ) : [EOL] [docstring] [EOL] [comment] [EOL] zeros_off_diag = F . broadcast_add ( left . slice_axis ( axis = - [number] , begin = [number] , end = [number] ) . zeros_like ( ) , right . slice_axis ( axis = - [number] , begin = [number] , end = [number] ) . zeros_like ( ) , ) [EOL] [EOL] [comment] [EOL] zeros_off_diag_tr = zeros_off_diag . swapaxes ( [number] , [number] ) [EOL] [EOL] [comment] [EOL] _block_diagonal = F . concat ( F . concat ( left , zeros_off_diag , dim = [number] ) , F . concat ( zeros_off_diag_tr , right , dim = [number] ) , dim = [number] , ) [EOL] [EOL] return _block_diagonal [EOL] [EOL] [EOL] class ISSM : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self ) : [EOL] pass [EOL] [EOL] def latent_dim ( self ) : [EOL] raise NotImplemented ( ) [EOL] [EOL] def output_dim ( self ) : [EOL] raise NotImplemented ( ) [EOL] [EOL] def emission_coeff ( self , seasonal_indicators ) : [EOL] raise NotImplemented ( ) [EOL] [EOL] def transition_coeff ( self , seasonal_indicators ) : [EOL] raise NotImplemented ( ) [EOL] [EOL] def innovation_coeff ( self , seasonal_indicators ) : [EOL] raise NotImplemented ( ) [EOL] [EOL] def get_issm_coeff ( self , seasonal_indicators ) : [EOL] return ( self . emission_coeff ( seasonal_indicators ) , self . transition_coeff ( seasonal_indicators ) , self . innovation_coeff ( seasonal_indicators ) , ) [EOL] [EOL] [EOL] class LevelISSM ( ISSM ) : [EOL] def latent_dim ( self ) : [EOL] return [number] [EOL] [EOL] def output_dim ( self ) : [EOL] return [number] [EOL] [EOL] def emission_coeff ( self , seasonal_indicators ) : [EOL] F = getF ( seasonal_indicators ) [EOL] [EOL] _emission_coeff = F . ones ( shape = ( [number] , [number] , [number] , self . latent_dim ( ) ) ) [EOL] [EOL] [comment] [EOL] zeros = _broadcast_param ( F . zeros_like ( seasonal_indicators . slice_axis ( axis = - [number] , begin = [number] , end = [number] ) . squeeze ( axis = - [number] ) ) , axes = [ [number] , [number] ] , sizes = [ [number] , self . latent_dim ( ) ] , ) [EOL] [EOL] return _emission_coeff . broadcast_like ( zeros ) [EOL] [EOL] def transition_coeff ( self , seasonal_indicators ) : [EOL] F = getF ( seasonal_indicators ) [EOL] [EOL] _transition_coeff = ( F . eye ( self . latent_dim ( ) ) . expand_dims ( axis = [number] ) . expand_dims ( axis = [number] ) ) [EOL] [EOL] [comment] [EOL] zeros = _broadcast_param ( F . zeros_like ( seasonal_indicators . slice_axis ( axis = - [number] , begin = [number] , end = [number] ) . squeeze ( axis = - [number] ) ) , axes = [ [number] , [number] ] , sizes = [ self . latent_dim ( ) , self . latent_dim ( ) ] , ) [EOL] [EOL] return _transition_coeff . broadcast_like ( zeros ) [EOL] [EOL] def innovation_coeff ( self , seasonal_indicators ) : [EOL] return self . emission_coeff ( seasonal_indicators ) . squeeze ( axis = [number] ) [EOL] [EOL] [EOL] class LevelTrendISSM ( LevelISSM ) : [EOL] def latent_dim ( self ) : [EOL] return [number] [EOL] [EOL] def output_dim ( self ) : [EOL] return [number] [EOL] [EOL] def transition_coeff ( self , seasonal_indicators ) : [EOL] F = getF ( seasonal_indicators ) [EOL] [EOL] _transition_coeff = ( ( F . diag ( F . ones ( shape = ( [number] , ) ) , k = [number] ) + F . diag ( F . ones ( shape = ( [number] , ) ) , k = [number] ) ) . expand_dims ( axis = [number] ) . expand_dims ( axis = [number] ) ) [EOL] [EOL] [comment] [EOL] zeros = _broadcast_param ( F . zeros_like ( seasonal_indicators . slice_axis ( axis = - [number] , begin = [number] , end = [number] ) . squeeze ( axis = - [number] ) ) , axes = [ [number] , [number] ] , sizes = [ self . latent_dim ( ) , self . latent_dim ( ) ] , ) [EOL] [EOL] return _transition_coeff . broadcast_like ( zeros ) [EOL] [EOL] [EOL] class SeasonalityISSM ( LevelISSM ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , num_seasons ) : [EOL] super ( SeasonalityISSM , self ) . __init__ ( ) [EOL] self . num_seasons = num_seasons [EOL] [EOL] def latent_dim ( self ) : [EOL] return self . num_seasons [EOL] [EOL] def output_dim ( self ) : [EOL] return [number] [EOL] [EOL] def emission_coeff ( self , seasonal_indicators ) : [EOL] F = getF ( seasonal_indicators ) [EOL] return F . one_hot ( seasonal_indicators , depth = self . latent_dim ( ) ) [EOL] [EOL] def innovation_coeff ( self , seasonal_indicators ) : [EOL] F = getF ( seasonal_indicators ) [EOL] [comment] [EOL] return F . one_hot ( seasonal_indicators , depth = self . latent_dim ( ) ) . squeeze ( axis = [number] ) [EOL] [EOL] [EOL] class CompositeISSM ( ISSM ) : [EOL] DEFAULT_ADD_TREND = True [EOL] [EOL] @ validated ( ) def __init__ ( self , seasonal_issms , add_trend = DEFAULT_ADD_TREND , ) : [EOL] super ( CompositeISSM , self ) . __init__ ( ) [EOL] self . seasonal_issms = seasonal_issms [EOL] self . nonseasonal_issm = ( LevelISSM ( ) if add_trend is False else LevelTrendISSM ( ) ) [EOL] [EOL] def latent_dim ( self ) : [EOL] return ( sum ( [ issm . latent_dim ( ) for issm in self . seasonal_issms ] ) + self . nonseasonal_issm . latent_dim ( ) ) [EOL] [EOL] def output_dim ( self ) : [EOL] return self . nonseasonal_issm . output_dim ( ) [EOL] [EOL] @ classmethod def get_from_freq ( cls , freq , add_trend = DEFAULT_ADD_TREND ) : [EOL] offset = to_offset ( freq ) [EOL] [EOL] seasonal_issms = [ ] [EOL] [EOL] if offset . name == [string] : [EOL] seasonal_issms = [ SeasonalityISSM ( num_seasons = [number] ) ] [EOL] elif offset . name == [string] : [EOL] seasonal_issms = [ SeasonalityISSM ( num_seasons = [number] ) ] [EOL] elif offset . name == [string] : [EOL] seasonal_issms = [ SeasonalityISSM ( num_seasons = [number] ) ] [comment] [EOL] elif offset . name == [string] : [comment] [EOL] seasonal_issms = [ SeasonalityISSM ( num_seasons = [number] ) ] [comment] [EOL] elif offset . name == [string] : [EOL] seasonal_issms = [ SeasonalityISSM ( num_seasons = [number] ) , SeasonalityISSM ( num_seasons = [number] ) , ] [EOL] elif offset . name == [string] : [EOL] seasonal_issms = [ SeasonalityISSM ( num_seasons = [number] ) , SeasonalityISSM ( num_seasons = [number] ) , ] [EOL] else : [EOL] RuntimeError ( f" [string] { offset . name }" ) [EOL] [EOL] return cls ( seasonal_issms = seasonal_issms , add_trend = add_trend ) [EOL] [EOL] @ classmethod def seasonal_features ( cls , freq ) : [EOL] offset = to_offset ( freq ) [EOL] if offset . name == [string] : [EOL] return [ MonthOfYear ( normalized = False ) ] [EOL] elif offset . name == [string] : [EOL] return [ WeekOfYear ( normalized = False ) ] [EOL] elif offset . name == [string] : [EOL] return [ DayOfWeek ( normalized = False ) ] [EOL] elif offset . name == [string] : [comment] [EOL] return [ DayOfWeek ( normalized = False ) ] [EOL] elif offset . name == [string] : [EOL] return [ HourOfDay ( normalized = False ) , DayOfWeek ( normalized = False ) ] [EOL] elif offset . name == [string] : [EOL] return [ MinuteOfHour ( normalized = False ) , HourOfDay ( normalized = False ) , ] [EOL] else : [EOL] RuntimeError ( f" [string] { offset . name }" ) [EOL] [EOL] return [ ] [EOL] [EOL] def get_issm_coeff ( self , seasonal_indicators ) : [EOL] F = getF ( seasonal_indicators ) [EOL] emission_coeff_ls , transition_coeff_ls , innovation_coeff_ls = zip ( self . nonseasonal_issm . get_issm_coeff ( seasonal_indicators ) , * [ issm . get_issm_coeff ( seasonal_indicators . slice_axis ( axis = - [number] , begin = ix , end = ix + [number] ) ) for ix , issm in enumerate ( self . seasonal_issms ) ] , ) [EOL] [EOL] [comment] [EOL] emission_coeff = F . concat ( * emission_coeff_ls , dim = - [number] ) [EOL] [EOL] innovation_coeff = F . concat ( * innovation_coeff_ls , dim = - [number] ) [EOL] [EOL] [comment] [EOL] transition_coeff = _make_block_diagonal ( transition_coeff_ls ) [EOL] [EOL] return emission_coeff , transition_coeff , innovation_coeff [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor,gluonts.model.common.Tensor]$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 $builtins.bool$ 0 0 0 0 0 0 $typing.List[gluonts.time_feature.TimeFeature]$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor,gluonts.model.common.Tensor]$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] from . _estimator import DeepStateEstimator [EOL] [EOL] __all__ = [ [string] ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] from typing import List , Optional [EOL] [EOL] [comment] [EOL] import mxnet as mx [EOL] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] from gluonts . model . deepstate . issm import ISSM [EOL] from gluonts . mx . block . feature import FeatureEmbedder [EOL] from gluonts . mx . block . scaler import MeanScaler , NOPScaler [EOL] from gluonts . mx . distribution . lds import LDS , LDSArgsProj , ParameterBounds [EOL] from gluonts . support . util import make_nd_diag , weighted_average [EOL] [EOL] [EOL] class DeepStateNetwork ( mx . gluon . HybridBlock ) : [EOL] @ validated ( ) def __init__ ( self , num_layers , num_cells , cell_type , past_length , prediction_length , issm , dropout_rate , cardinality , embedding_dimension , scaling = True , noise_std_bounds = ParameterBounds ( [number] , [number] ) , prior_cov_bounds = ParameterBounds ( [number] , [number] ) , innovation_bounds = ParameterBounds ( [number] , [number] ) , ** kwargs , ) : [EOL] super ( ) . __init__ ( ** kwargs ) [EOL] self . num_layers = num_layers [EOL] self . num_cells = num_cells [EOL] self . cell_type = cell_type [EOL] self . past_length = past_length [EOL] self . prediction_length = prediction_length [EOL] self . issm = issm [EOL] self . dropout_rate = dropout_rate [EOL] self . cardinality = cardinality [EOL] self . embedding_dimension = embedding_dimension [EOL] self . num_cat = len ( cardinality ) [EOL] self . scaling = scaling [EOL] [EOL] assert len ( cardinality ) == len ( embedding_dimension ) , [string] [EOL] self . univariate = self . issm . output_dim ( ) == [number] [EOL] [EOL] self . noise_std_bounds = noise_std_bounds [EOL] self . prior_cov_bounds = prior_cov_bounds [EOL] self . innovation_bounds = innovation_bounds [EOL] [EOL] with self . name_scope ( ) : [EOL] self . prior_mean_model = mx . gluon . nn . Dense ( units = self . issm . latent_dim ( ) , flatten = False ) [EOL] self . prior_cov_diag_model = mx . gluon . nn . Dense ( units = self . issm . latent_dim ( ) , activation = [string] , flatten = False , ) [EOL] self . lstm = mx . gluon . rnn . HybridSequentialRNNCell ( ) [EOL] self . lds_proj = LDSArgsProj ( output_dim = self . issm . output_dim ( ) , noise_std_bounds = self . noise_std_bounds , innovation_bounds = self . innovation_bounds , ) [EOL] for k in range ( num_layers ) : [EOL] cell = mx . gluon . rnn . LSTMCell ( hidden_size = num_cells ) [EOL] cell = mx . gluon . rnn . ResidualCell ( cell ) if k > [number] else cell [EOL] cell = ( mx . gluon . rnn . ZoneoutCell ( cell , zoneout_states = dropout_rate ) [EOL] if dropout_rate > [number] [EOL] else cell ) [EOL] self . lstm . add ( cell ) [EOL] self . embedder = FeatureEmbedder ( cardinalities = cardinality , embedding_dims = embedding_dimension ) [EOL] if scaling : [EOL] self . scaler = MeanScaler ( keepdims = False ) [EOL] else : [EOL] self . scaler = NOPScaler ( keepdims = False ) [EOL] [EOL] def compute_lds ( self , F , feat_static_cat , seasonal_indicators , time_feat , length , prior_mean = None , prior_cov = None , lstm_begin_state = None , ) : [EOL] [comment] [EOL] embedded_cat = self . embedder ( feat_static_cat ) [EOL] repeated_static_features = embedded_cat . expand_dims ( axis = [number] ) . repeat ( axis = [number] , repeats = length ) [EOL] [EOL] [comment] [EOL] features = F . concat ( time_feat , repeated_static_features , dim = [number] ) [EOL] [EOL] output , lstm_final_state = self . lstm . unroll ( inputs = features , begin_state = lstm_begin_state , length = length , merge_outputs = True , ) [EOL] [EOL] if prior_mean is None : [EOL] prior_input = F . slice_axis ( output , axis = [number] , begin = [number] , end = [number] ) . squeeze ( axis = [number] ) [EOL] [EOL] prior_mean = self . prior_mean_model ( prior_input ) [EOL] prior_cov_diag = ( self . prior_cov_diag_model ( prior_input ) * ( self . prior_cov_bounds . upper - self . prior_cov_bounds . lower ) + self . prior_cov_bounds . lower ) [EOL] prior_cov = make_nd_diag ( F , prior_cov_diag , self . issm . latent_dim ( ) ) [EOL] [EOL] ( emission_coeff , transition_coeff , innovation_coeff , ) = self . issm . get_issm_coeff ( seasonal_indicators ) [EOL] [EOL] noise_std , innovation , residuals = self . lds_proj ( output ) [EOL] [EOL] lds = LDS ( emission_coeff = emission_coeff , transition_coeff = transition_coeff , innovation_coeff = F . broadcast_mul ( innovation , innovation_coeff ) , noise_std = noise_std , residuals = residuals , prior_mean = prior_mean , prior_cov = prior_cov , latent_dim = self . issm . latent_dim ( ) , output_dim = self . issm . output_dim ( ) , seq_length = length , ) [EOL] [EOL] return lds , lstm_final_state [EOL] [EOL] [EOL] class DeepStateTrainingNetwork ( DeepStateNetwork ) : [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , feat_static_cat , past_observed_values , past_seasonal_indicators , past_time_feat , past_target , ) : [EOL] lds , _ = self . compute_lds ( F , feat_static_cat = feat_static_cat , seasonal_indicators = past_seasonal_indicators . slice_axis ( axis = [number] , begin = - self . past_length , end = None ) , time_feat = past_time_feat . slice_axis ( axis = [number] , begin = - self . past_length , end = None ) , length = self . past_length , ) [EOL] [EOL] _ , scale = self . scaler ( past_target , past_observed_values ) [EOL] [EOL] observed_context = past_observed_values . slice_axis ( axis = [number] , begin = - self . past_length , end = None ) [EOL] [EOL] ll , _ , _ = lds . log_prob ( x = past_target . slice_axis ( axis = [number] , begin = - self . past_length , end = None ) , observed = observed_context . min ( axis = - [number] , keepdims = False ) , scale = scale , ) [EOL] [EOL] return weighted_average ( F = F , x = - ll , axis = [number] , weights = observed_context . squeeze ( axis = - [number] ) ) [EOL] [EOL] [EOL] class DeepStatePredictionNetwork ( DeepStateNetwork ) : [EOL] @ validated ( ) def __init__ ( self , num_parallel_samples , * args , ** kwargs ) : [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] self . num_parallel_samples = num_parallel_samples [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , feat_static_cat , past_observed_values , past_seasonal_indicators , past_time_feat , past_target , future_seasonal_indicators , future_time_feat , ) : [EOL] lds , lstm_state = self . compute_lds ( F , feat_static_cat = feat_static_cat , seasonal_indicators = past_seasonal_indicators . slice_axis ( axis = [number] , begin = - self . past_length , end = None ) , time_feat = past_time_feat . slice_axis ( axis = [number] , begin = - self . past_length , end = None ) , length = self . past_length , ) [EOL] [EOL] _ , scale = self . scaler ( past_target , past_observed_values ) [EOL] [EOL] observed_context = past_observed_values . slice_axis ( axis = [number] , begin = - self . past_length , end = None ) [EOL] [EOL] _ , final_mean , final_cov = lds . log_prob ( x = past_target . slice_axis ( axis = [number] , begin = - self . past_length , end = None ) , observed = observed_context . min ( axis = - [number] , keepdims = False ) , scale = scale , ) [EOL] [EOL] lds_prediction , _ = self . compute_lds ( F , feat_static_cat = feat_static_cat , seasonal_indicators = future_seasonal_indicators , time_feat = future_time_feat , length = self . prediction_length , lstm_begin_state = lstm_state , prior_mean = final_mean , prior_cov = final_cov , ) [EOL] [EOL] samples = lds_prediction . sample ( num_samples = self . num_parallel_samples , scale = scale ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] if self . univariate : [EOL] return samples . transpose ( axes = ( [number] , [number] , [number] , [number] ) ) . squeeze ( axis = [number] ) [EOL] else : [EOL] return samples . transpose ( axes = ( [number] , [number] , [number] , [number] ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.List[gluonts.model.common.Tensor]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.List[gluonts.model.common.Tensor]]$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from . _estimator import TransformerEstimator [EOL] [EOL] __all__ = [ [string] ] [EOL] [EOL] [comment] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Optional , Dict [EOL] import typing [EOL] import builtins [EOL] import gluonts [EOL] from typing import Dict , Optional [EOL] [EOL] [comment] [EOL] from mxnet . gluon import HybridBlock [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] from gluonts . model . transformer . layers import ( InputLayer , MultiHeadAttention , MultiHeadSelfAttention , TransformerFeedForward , TransformerProcessBlock , ) [EOL] [EOL] [EOL] class TransformerDecoder ( HybridBlock ) : [EOL] @ validated ( ) def __init__ ( self , decoder_length , config , ** kwargs ) : [EOL] [EOL] super ( ) . __init__ ( ** kwargs ) [EOL] [EOL] self . decoder_length = decoder_length [EOL] self . cache = { } [EOL] [EOL] with self . name_scope ( ) : [EOL] self . enc_input_layer = InputLayer ( model_size = config [ [string] ] ) [EOL] [EOL] self . dec_pre_self_att = TransformerProcessBlock ( sequence = config [ [string] ] , dropout = config [ [string] ] , prefix = [string] , ) [EOL] self . dec_self_att = MultiHeadSelfAttention ( att_dim_in = config [ [string] ] , heads = config [ [string] ] , att_dim_out = config [ [string] ] , dropout = config [ [string] ] , prefix = [string] , ) [EOL] self . dec_post_self_att = TransformerProcessBlock ( sequence = config [ [string] ] , dropout = config [ [string] ] , prefix = [string] , ) [EOL] self . dec_enc_att = MultiHeadAttention ( att_dim_in = config [ [string] ] , heads = config [ [string] ] , att_dim_out = config [ [string] ] , dropout = config [ [string] ] , prefix = [string] , ) [EOL] self . dec_post_att = TransformerProcessBlock ( sequence = config [ [string] ] , dropout = config [ [string] ] , prefix = [string] , ) [EOL] self . dec_ff = TransformerFeedForward ( inner_dim = config [ [string] ] * config [ [string] ] , out_dim = config [ [string] ] , act_type = config [ [string] ] , dropout = config [ [string] ] , prefix = [string] , ) [EOL] self . dec_post_ff = TransformerProcessBlock ( sequence = config [ [string] ] , dropout = config [ [string] ] , prefix = [string] , ) [EOL] [EOL] def cache_reset ( self ) : [EOL] self . cache = { } [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , data , enc_out , mask = None , is_train = True , ) : [EOL] [EOL] [docstring] [EOL] [EOL] [comment] [EOL] inputs = self . enc_input_layer ( data ) [EOL] [EOL] [comment] [EOL] data_att , cache = self . dec_self_att ( self . dec_pre_self_att ( inputs , None ) , mask , self . cache . copy ( ) if not is_train else None , ) [EOL] data = self . dec_post_self_att ( data_att , inputs ) [EOL] [EOL] [comment] [EOL] data_att = self . dec_enc_att ( data , enc_out ) [EOL] data = self . dec_post_att ( data_att , data ) [EOL] [EOL] [comment] [EOL] data_ff = self . dec_ff ( data ) [EOL] data = self . dec_post_ff ( data_ff , data ) [EOL] [EOL] if not is_train : [EOL] self . cache = cache . copy ( ) [EOL] [EOL] return data [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional [EOL] import gluonts [EOL] import builtins [EOL] import mxnet [EOL] import typing [EOL] from typing import List , Optional [EOL] [EOL] [comment] [EOL] from mxnet . gluon import HybridBlock [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . dataset . field_names import FieldName [EOL] from gluonts . model . estimator import GluonEstimator [EOL] from gluonts . model . predictor import Predictor , RepresentableBlockPredictor [EOL] [EOL] [comment] [EOL] from gluonts . model . transformer . _network import ( TransformerPredictionNetwork , TransformerTrainingNetwork , ) [EOL] from gluonts . model . transformer . trans_decoder import TransformerDecoder [EOL] from gluonts . model . transformer . trans_encoder import TransformerEncoder [EOL] from gluonts . mx . distribution import DistributionOutput , StudentTOutput [EOL] from gluonts . mx . trainer import Trainer [EOL] from gluonts . support . util import copy_parameters [EOL] from gluonts . time_feature import ( TimeFeature , get_lags_for_frequency , time_features_from_frequency_str , ) [EOL] from gluonts . transform import ( AddAgeFeature , AddObservedValuesIndicator , AddTimeFeatures , AsNumpyArray , Chain , ExpectedNumInstanceSampler , InstanceSplitter , RemoveFields , SetField , Transformation , VstackFeatures , ) [EOL] [EOL] [EOL] class TransformerEstimator ( GluonEstimator ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , freq , prediction_length , context_length = None , trainer = Trainer ( ) , dropout_rate = [number] , cardinality = None , embedding_dimension = [number] , distr_output = StudentTOutput ( ) , model_dim = [number] , inner_ff_dim_scale = [number] , pre_seq = [string] , post_seq = [string] , act_type = [string] , num_heads = [number] , scaling = True , lags_seq = None , time_features = None , use_feat_dynamic_real = False , use_feat_static_cat = False , num_parallel_samples = [number] , ) : [EOL] super ( ) . __init__ ( trainer = trainer ) [EOL] [EOL] assert ( prediction_length > [number] ) , [string] [EOL] assert ( context_length is None or context_length > [number] ) , [string] [EOL] assert dropout_rate >= [number] , [string] [EOL] assert ( cardinality is not None or not use_feat_static_cat ) , [string] [EOL] assert cardinality is None or all ( [ c > [number] for c in cardinality ] ) , [string] [EOL] assert ( embedding_dimension > [number] ) , [string] [EOL] assert ( num_parallel_samples > [number] ) , [string] [EOL] [EOL] self . freq = freq [EOL] self . prediction_length = prediction_length [EOL] self . context_length = ( context_length if context_length is not None else prediction_length ) [EOL] self . distr_output = distr_output [EOL] self . dropout_rate = dropout_rate [EOL] self . use_feat_dynamic_real = use_feat_dynamic_real [EOL] self . use_feat_static_cat = use_feat_static_cat [EOL] self . cardinality = cardinality if use_feat_static_cat else [ [number] ] [EOL] self . embedding_dimension = embedding_dimension [EOL] self . num_parallel_samples = num_parallel_samples [EOL] self . lags_seq = ( lags_seq [EOL] if lags_seq is not None [EOL] else get_lags_for_frequency ( freq_str = freq ) ) [EOL] self . time_features = ( time_features [EOL] if time_features is not None [EOL] else time_features_from_frequency_str ( self . freq ) ) [EOL] self . history_length = self . context_length + max ( self . lags_seq ) [EOL] self . scaling = scaling [EOL] [EOL] self . config = { [string] : model_dim , [string] : pre_seq , [string] : post_seq , [string] : dropout_rate , [string] : inner_ff_dim_scale , [string] : act_type , [string] : num_heads , } [EOL] [EOL] self . encoder = TransformerEncoder ( self . context_length , self . config , prefix = [string] ) [EOL] self . decoder = TransformerDecoder ( self . prediction_length , self . config , prefix = [string] ) [EOL] [EOL] def create_transformation ( self ) : [EOL] remove_field_names = [ FieldName . FEAT_DYNAMIC_CAT , FieldName . FEAT_STATIC_REAL , ] [EOL] if not self . use_feat_dynamic_real : [EOL] remove_field_names . append ( FieldName . FEAT_DYNAMIC_REAL ) [EOL] [EOL] return Chain ( [ RemoveFields ( field_names = remove_field_names ) ] + ( [ SetField ( output_field = FieldName . FEAT_STATIC_CAT , value = [ [number] ] ) ] [EOL] if not self . use_feat_static_cat [EOL] else [ ] ) + [ AsNumpyArray ( field = FieldName . FEAT_STATIC_CAT , expected_ndim = [number] ) , AsNumpyArray ( field = FieldName . TARGET , expected_ndim = [number] + len ( self . distr_output . event_shape ) , ) , AddObservedValuesIndicator ( target_field = FieldName . TARGET , output_field = FieldName . OBSERVED_VALUES , ) , AddTimeFeatures ( start_field = FieldName . START , target_field = FieldName . TARGET , output_field = FieldName . FEAT_TIME , time_features = self . time_features , pred_length = self . prediction_length , ) , AddAgeFeature ( target_field = FieldName . TARGET , output_field = FieldName . FEAT_AGE , pred_length = self . prediction_length , log_scale = True , ) , VstackFeatures ( output_field = FieldName . FEAT_TIME , input_fields = [ FieldName . FEAT_TIME , FieldName . FEAT_AGE ] + ( [ FieldName . FEAT_DYNAMIC_REAL ] [EOL] if self . use_feat_dynamic_real [EOL] else [ ] ) , ) , InstanceSplitter ( target_field = FieldName . TARGET , is_pad_field = FieldName . IS_PAD , start_field = FieldName . START , forecast_start_field = FieldName . FORECAST_START , train_sampler = ExpectedNumInstanceSampler ( num_instances = [number] ) , past_length = self . history_length , future_length = self . prediction_length , time_series_fields = [ FieldName . FEAT_TIME , FieldName . OBSERVED_VALUES , ] , ) , ] ) [EOL] [EOL] def create_training_network ( self ) : [EOL] [EOL] training_network = TransformerTrainingNetwork ( encoder = self . encoder , decoder = self . decoder , history_length = self . history_length , context_length = self . context_length , prediction_length = self . prediction_length , distr_output = self . distr_output , cardinality = self . cardinality , embedding_dimension = self . embedding_dimension , lags_seq = self . lags_seq , scaling = True , ) [EOL] [EOL] return training_network [EOL] [EOL] def create_predictor ( self , transformation , trained_network ) : [EOL] [EOL] prediction_network = TransformerPredictionNetwork ( encoder = self . encoder , decoder = self . decoder , history_length = self . history_length , context_length = self . context_length , prediction_length = self . prediction_length , distr_output = self . distr_output , cardinality = self . cardinality , embedding_dimension = self . embedding_dimension , lags_seq = self . lags_seq , scaling = True , num_parallel_samples = self . num_parallel_samples , ) [EOL] [EOL] copy_parameters ( trained_network , prediction_network ) [EOL] [EOL] return RepresentableBlockPredictor ( input_transform = transformation , prediction_net = prediction_network , batch_size = self . trainer . batch_size , freq = self . freq , prediction_length = self . prediction_length , ctx = self . trainer . ctx , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.mx.trainer.Trainer$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.mx.trainer.Trainer$ 0 $gluonts.mx.trainer.Trainer$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.str$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.transform.Transformation$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.transformer._network.TransformerTrainingNetwork$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.predictor.Predictor$ 0 0 0 $gluonts.transform.Transformation$ 0 $mxnet.gluon.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 $gluonts.transform.Transformation$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Dict [EOL] import typing [EOL] import builtins [EOL] import gluonts [EOL] from typing import Dict [EOL] [EOL] [comment] [EOL] from mxnet . gluon import HybridBlock [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] from gluonts . model . transformer . layers import ( InputLayer , MultiHeadSelfAttention , TransformerFeedForward , TransformerProcessBlock , ) [EOL] [EOL] [EOL] class TransformerEncoder ( HybridBlock ) : [EOL] @ validated ( ) def __init__ ( self , encoder_length , config , ** kwargs ) : [EOL] [EOL] super ( ) . __init__ ( ** kwargs ) [EOL] [EOL] self . encoder_length = encoder_length [EOL] [EOL] with self . name_scope ( ) : [EOL] self . enc_input_layer = InputLayer ( model_size = config [ [string] ] ) [EOL] [EOL] self . enc_pre_self_att = TransformerProcessBlock ( sequence = config [ [string] ] , dropout = config [ [string] ] , prefix = [string] , ) [EOL] self . enc_self_att = MultiHeadSelfAttention ( att_dim_in = config [ [string] ] , heads = config [ [string] ] , att_dim_out = config [ [string] ] , dropout = config [ [string] ] , prefix = [string] , ) [EOL] self . enc_post_self_att = TransformerProcessBlock ( sequence = config [ [string] ] , dropout = config [ [string] ] , prefix = [string] , ) [EOL] self . enc_ff = TransformerFeedForward ( inner_dim = config [ [string] ] * config [ [string] ] , out_dim = config [ [string] ] , act_type = config [ [string] ] , dropout = config [ [string] ] , prefix = [string] , ) [EOL] self . enc_post_ff = TransformerProcessBlock ( sequence = config [ [string] ] , dropout = config [ [string] ] , prefix = [string] , ) [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , data ) : [EOL] [EOL] [docstring] [EOL] [EOL] [comment] [EOL] inputs = self . enc_input_layer ( data ) [EOL] [EOL] [comment] [EOL] data_self_att , _ = self . enc_self_att ( self . enc_pre_self_att ( inputs , None ) ) [EOL] data = self . enc_post_self_att ( data_self_att , inputs ) [EOL] [EOL] [comment] [EOL] data_ff = self . enc_ff ( data ) [EOL] data = self . enc_post_ff ( data_ff , data ) [EOL] [EOL] return data [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional , Dict [EOL] import pandas [EOL] import typing [EOL] import builtins [EOL] from typing import List , Optional , Dict [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] import pandas as pd [EOL] import xgboost [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] [EOL] [EOL] class QRF : [EOL] @ validated ( ) def __init__ ( self , params = None ) : [EOL] [docstring] [EOL] from skgarden import RandomForestQuantileRegressor [EOL] [EOL] self . model = RandomForestQuantileRegressor ( ** params ) [EOL] [EOL] def fit ( self , x_train , y_train ) : [EOL] self . model . fit ( np . array ( x_train ) , np . array ( y_train ) ) [EOL] [EOL] def predict ( self , x_test , quantile ) : [EOL] return self . model . predict ( x_test , quantile = [number] * quantile ) [EOL] [EOL] [EOL] class QuantileReg : [EOL] @ validated ( ) def __init__ ( self , quantiles , params = None ) : [EOL] [docstring] [EOL] from lightgbm import LGBMRegressor [EOL] [EOL] self . quantiles = quantiles [EOL] self . models = dict ( ( quantile , LGBMRegressor ( objective = [string] , alpha = quantile , ** params ) , ) for quantile in quantiles ) [EOL] [EOL] def fit ( self , x_train , y_train ) : [EOL] for model in self . models . values ( ) : [EOL] model . fit ( np . array ( x_train ) , np . array ( y_train ) ) [EOL] [EOL] def predict ( self , x_test , quantile ) : [EOL] return self . models [ quantile ] . predict ( x_test ) [EOL] [EOL] [EOL] class QRX : [EOL] @ validated ( ) def __init__ ( self , model = None , xgboost_params = None , clump_size = [number] , ) : [EOL] [docstring] [EOL] if model : [EOL] self . model = model [EOL] else : [EOL] self . model = self . _create_xgboost_model ( xgboost_params ) [EOL] self . clump_size = clump_size [EOL] self . df = None [EOL] self . processed_df = None [EOL] self . cell_values = None [EOL] self . cell_values_dict = None [EOL] self . quantile_dicts = { } [EOL] [EOL] @ staticmethod def _create_xgboost_model ( model_params = None ) : [EOL] [docstring] [EOL] if model_params is None : [EOL] model_params = { [string] : [number] , [string] : - [number] , [string] : [number] , [string] : [string] , } [EOL] return xgboost . sklearn . XGBModel ( ** model_params ) [EOL] [EOL] def fit ( self , x_train , y_train ) : [EOL] [docstring] [EOL] self . quantile_dicts = { } [EOL] x_train , y_train = np . array ( x_train ) , np . array ( y_train ) [comment] [EOL] [comment] [EOL] self . model . fit ( np . array ( x_train ) , np . array ( y_train ) ) [EOL] y_train_pred = self . model . predict ( x_train ) [EOL] self . df = pd . DataFrame ( { [string] : list ( x_train ) , [string] : y_train , [string] : y_train_pred } ) [EOL] self . cell_values_dict = self . preprocess_df ( self . df , clump_size = self . clump_size ) [EOL] self . cell_values = sorted ( self . cell_values_dict . keys ( ) ) [EOL] [EOL] @ staticmethod def clump ( dic , min_num ) : [EOL] [docstring] [EOL] sorted_keys = sorted ( dic ) [EOL] new_dic = { } [EOL] iter_length = [number] [EOL] iter_list = [ ] [EOL] for key in sorted_keys : [EOL] iter_length += len ( dic [ key ] ) [EOL] iter_list . extend ( dic [ key ] ) [EOL] new_dic [ key ] = iter_list [comment] [EOL] [comment] [EOL] [comment] [EOL] if iter_length > min_num : [EOL] iter_length = [number] [EOL] iter_list = [ ] [comment] [EOL] [comment] [EOL] [comment] [EOL] return new_dic [EOL] [EOL] @ classmethod def preprocess_df ( cls , df , clump_size = [number] ) : [EOL] [docstring] [EOL] dic = dict ( df . groupby ( [string] ) [ [string] ] . apply ( list ) ) [EOL] dic = cls . clump ( dic , clump_size ) [EOL] return dic [EOL] [EOL] @ classmethod def get_closest_pt ( cls , sorted_list , num ) : [EOL] [docstring] [EOL] assert sorted_list [EOL] if len ( sorted_list ) == [number] : [EOL] return sorted_list [ [number] ] [EOL] else : [EOL] halfway_indx = ( len ( sorted_list ) - [number] ) // [number] [EOL] if sorted_list [ halfway_indx ] > num : [EOL] return cls . get_closest_pt ( sorted_list [ : halfway_indx + [number] ] , num ) [EOL] elif sorted_list [ halfway_indx + [number] ] < num : [EOL] return cls . get_closest_pt ( sorted_list [ halfway_indx + [number] : ] , num ) [EOL] elif abs ( sorted_list [ halfway_indx ] - num ) < abs ( sorted_list [ halfway_indx + [number] ] - num ) : [EOL] return sorted_list [ halfway_indx ] [EOL] else : [EOL] return sorted_list [ halfway_indx + [number] ] [EOL] [EOL] @ staticmethod def _get_quantiles_from_dic_with_list_values ( dic , quantile ) : [EOL] [docstring] [EOL] df = pd . DataFrame ( dic . items ( ) , columns = [ [string] , [string] ] ) [EOL] df [ [string] ] = df [ [string] ] . apply ( id ) [EOL] df_by_id = df . groupby ( [string] ) [ [string] ] . first ( ) . reset_index ( ) [EOL] df_by_id [ [string] ] = df_by_id [ [string] ] . apply ( lambda l : np . percentile ( l , quantile * [number] ) ) [EOL] df_by_id = df_by_id [ [ [string] , [string] ] ] . merge ( df , on = [string] ) [EOL] return dict ( zip ( df_by_id [ [string] ] , df_by_id [ [string] ] ) ) [EOL] [EOL] def predict ( self , x_test , quantile ) : [EOL] [docstring] [EOL] predicted_values = [ ] [EOL] if quantile in self . quantile_dicts : [EOL] quantile_dic = self . quantile_dicts [ quantile ] [EOL] else : [EOL] quantile_dic = self . _get_quantiles_from_dic_with_list_values ( self . cell_values_dict , quantile ) [EOL] self . quantile_dicts [ quantile ] = quantile_dic [EOL] [comment] [EOL] for pt in x_test : [EOL] pred = self . model . predict ( np . array ( [ pt ] ) ) [ [number] ] [comment] [EOL] [comment] [EOL] closest_pred = self . get_closest_pt ( self . cell_values , pred ) [EOL] predicted_values . append ( quantile_dic [ closest_pred ] ) [EOL] return predicted_values [EOL] [EOL] def estimate_dist ( self , x_test ) : [EOL] [docstring] [EOL] predicted_samples = [ ] [EOL] for pt in x_test : [EOL] pred = self . model . predict ( np . array ( [ pt ] ) ) [ [number] ] [EOL] closest_pred = self . get_closest_pt ( self . cell_values , pred ) [EOL] predicted_samples . append ( self . cell_values_dict [ closest_pred ] ) [EOL] return predicted_samples [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 $typing.Dict$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 $pandas.DataFrame$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $typing.List$ 0 $builtins.int$ 0 0 0 0 0 0 $typing.List$ 0 0 0 0 $typing.List$ 0 0 0 0 0 0 $typing.List$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List$ 0 0 0 0 0 0 0 0 $typing.List$ 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 $typing.List$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $typing.List$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 $typing.List$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $typing.List$ 0 0 0 0 $builtins.int$ 0 0 0 0 $typing.List$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $typing.List$ 0 0 0 0 0 0 0 0 $typing.List$ 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 $typing.Dict$ 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List$ 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List$ 0 0 0 $typing.List[typing.List[builtins.float]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.List[builtins.float]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Iterator , List , Optional [EOL] import pandas [EOL] import _preprocess [EOL] import numpy [EOL] import pathlib [EOL] import mxnet [EOL] import gluonts [EOL] import typing [EOL] import builtins [EOL] from typing import Iterator , List , Optional [EOL] from pathlib import Path [EOL] import json [EOL] [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] import pandas as pd [EOL] from itertools import chain [EOL] import concurrent . futures [EOL] import logging [EOL] import mxnet as mx [EOL] [EOL] [comment] [EOL] import gluonts [EOL] from gluonts . core . component import validated , equals [EOL] from gluonts . core . serde import dump_json , fqname_for , load_json [EOL] from gluonts . dataset . common import Dataset [EOL] from gluonts . model . forecast import Forecast [EOL] from gluonts . model . forecast_generator import log_once [EOL] from gluonts . model . predictor import GluonPredictor [EOL] from gluonts . support . pandas import forecast_start [EOL] from gluonts . dataset . loader import DataBatch [EOL] [EOL] [comment] [EOL] from . _preprocess import PreprocessOnlyLagFeatures , Cardinality [EOL] from . _model import QRX , QuantileReg , QRF [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class RotbaumForecast ( Forecast ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , models , featurized_data , start_date , freq , prediction_length , ) : [EOL] self . models = models [EOL] self . featurized_data = featurized_data [EOL] self . start_date = start_date [EOL] self . freq = freq [EOL] self . prediction_length = prediction_length [EOL] self . item_id = None [EOL] self . lead_time = None [EOL] [EOL] def quantile ( self , q ) : [EOL] [docstring] [EOL] assert [number] <= q <= [number] [EOL] return np . array ( list ( chain . from_iterable ( model . predict ( self . featurized_data , q ) for model in self . models ) ) ) [EOL] [EOL] def estimate_dists ( self ) : [EOL] [docstring] [EOL] return np . array ( list ( chain . from_iterable ( model . estimate_dist ( self . featurized_data ) for model in self . models ) ) ) [EOL] [EOL] [EOL] class TreePredictor ( GluonPredictor ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , freq , prediction_length , n_ignore_last = [number] , lead_time = [number] , max_n_datapts = [number] , clump_size = [number] , context_length = None , use_feat_static_real = False , use_feat_dynamic_real = False , use_feat_dynamic_cat = False , cardinality = [string] , one_hot_encode = False , model_params = None , max_workers = None , method = [string] , quantiles = None , ) : [EOL] assert method in [ [string] , [string] , [string] , ] , [string] [EOL] self . method = method [EOL] self . lead_time = lead_time [EOL] self . context_length = ( context_length if context_length is not None else prediction_length ) [EOL] self . preprocess_object = PreprocessOnlyLagFeatures ( self . context_length , forecast_horizon = prediction_length , stratify_targets = False , n_ignore_last = n_ignore_last , max_n_datapts = max_n_datapts , use_feat_static_real = use_feat_static_real , use_feat_dynamic_real = use_feat_dynamic_real , use_feat_dynamic_cat = use_feat_dynamic_cat , cardinality = cardinality , one_hot_encode = one_hot_encode , ) [EOL] [EOL] assert ( context_length is None or context_length > [number] ) , [string] [EOL] assert ( prediction_length > [number] or use_feat_dynamic_cat or use_feat_dynamic_real or use_feat_static_real or cardinality != [string] ) , ( [string] [string] ) [EOL] [EOL] self . model_params = model_params if model_params else { } [EOL] self . prediction_length = prediction_length [EOL] self . freq = freq [EOL] self . max_workers = max_workers [EOL] self . clump_size = clump_size [EOL] self . quantiles = quantiles [EOL] self . model_list = None [EOL] [EOL] logger . info ( [string] ) [EOL] [EOL] def __call__ ( self , training_data ) : [EOL] assert training_data [EOL] assert self . freq is not None [EOL] if next ( iter ( training_data ) ) [ [string] ] . freq is not None : [EOL] assert self . freq == next ( iter ( training_data ) ) [ [string] ] . freq [EOL] self . preprocess_object . preprocess_from_list ( ts_list = list ( training_data ) , change_internal_variables = True ) [EOL] feature_data , target_data = ( self . preprocess_object . feature_data , self . preprocess_object . target_data , ) [EOL] n_models = self . prediction_length [EOL] logging . info ( f" [string] { n_models }" ) [EOL] if self . method == [string] : [EOL] self . model_list = [ QuantileReg ( params = self . model_params , quantiles = self . quantiles ) for _ in range ( n_models ) ] [EOL] elif self . method == [string] : [EOL] self . model_list = [ QRF ( params = self . model_params ) for _ in range ( n_models ) ] [EOL] elif self . method == [string] : [EOL] self . model_list = [ QRX ( xgboost_params = self . model_params , clump_size = self . clump_size , ) for _ in range ( n_models ) ] [EOL] with concurrent . futures . ThreadPoolExecutor ( max_workers = self . max_workers ) as executor : [EOL] for n_step , model in enumerate ( self . model_list ) : [EOL] logger . info ( f" [string] { n_step + [number] } [string] " f" [string] " ) [EOL] executor . submit ( model . fit , feature_data , np . array ( target_data ) [ : , n_step ] ) [EOL] [EOL] return self [EOL] [EOL] @ validated ( ) def train ( self , training_data ) : [EOL] self . __call__ ( training_data ) [EOL] [EOL] @ validated ( ) def predict ( self , dataset , num_samples = None ) : [EOL] [docstring] [EOL] context_length = self . preprocess_object . context_window_size [EOL] [EOL] if num_samples : [EOL] log_once ( [string] ) [EOL] [EOL] for ts in dataset : [EOL] featurized_data = self . preprocess_object . make_features ( ts , starting_index = len ( ts [ [string] ] ) - context_length ) [EOL] yield RotbaumForecast ( self . model_list , [ featurized_data ] , start_date = forecast_start ( ts ) , prediction_length = self . prediction_length , freq = self . freq , ) [EOL] [EOL] def serialize ( self , path ) : [EOL] [EOL] with ( path / [string] ) . open ( [string] ) as fp : [EOL] fp . write ( fqname_for ( self . __class__ ) ) [EOL] with ( path / [string] ) . open ( [string] ) as fp : [EOL] json . dump ( { [string] : self . __version__ , [string] : gluonts . __version__ } , fp ) [EOL] with ( path / [string] ) . open ( [string] ) as fp : [EOL] print ( dump_json ( self ) , file = fp ) [EOL] [EOL] def serialize_prediction_net ( self , path ) : [EOL] self . serialize ( path ) [EOL] [EOL] @ classmethod def deserialize ( cls , path , ctx = None ) : [EOL] [EOL] with ( path / [string] ) . open ( [string] ) as fp : [EOL] return load_json ( fp . read ( ) ) [EOL] [EOL] def as_symbol_block_predictor ( self , batch ) : [EOL] return None [EOL] [EOL] def __eq__ ( self , that ) : [EOL] [docstring] [EOL] return equals ( self , that ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Tuple , Dict [EOL] import typing [EOL] import builtins [EOL] from typing import List , Tuple , Dict , Union [EOL] from enum import Enum [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] import logging [EOL] from itertools import chain , starmap [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] [EOL] [EOL] class CardinalityLabel ( str , Enum ) : [EOL] auto = [string] [EOL] ignore = [string] [EOL] [EOL] [EOL] Cardinality = Union [ List [ int ] , CardinalityLabel ] [EOL] [EOL] [EOL] class PreprocessGeneric : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , context_window_size , forecast_horizon = [number] , stratify_targets = False , n_ignore_last = [number] , max_n_datapts = [number] , ** kwargs ) : [EOL] [docstring] [EOL] assert not ( stratify_targets and ( forecast_horizon == [number] ) ) [EOL] self . context_window_size = context_window_size [EOL] self . forecast_horizon = forecast_horizon [EOL] self . stratify_targets = stratify_targets [EOL] self . n_ignore_last = n_ignore_last [EOL] self . max_n_datapts = max_n_datapts [EOL] self . kwargs = kwargs [EOL] self . num_samples = None [EOL] self . feature_data = None [EOL] self . target_data = None [EOL] [EOL] def make_features ( self , time_series , starting_index ) : [EOL] [docstring] [EOL] raise NotImplementedError ( ) [EOL] [EOL] def preprocess_from_single_ts ( self , time_series ) : [EOL] [docstring] [EOL] altered_time_series = time_series . copy ( ) [EOL] if self . n_ignore_last > [number] : [EOL] altered_time_series [ [string] ] = altered_time_series [ [string] ] [ : - self . n_ignore_last ] [EOL] feature_data = [ ] [EOL] target_data = [ ] [EOL] max_num_context_windows = ( len ( altered_time_series [ [string] ] ) - self . context_window_size - self . forecast_horizon + [number] ) [EOL] if max_num_context_windows < [number] : [EOL] if not self . use_feat_static_real and not self . cardinality : [EOL] return [ ] , [ ] [EOL] else : [EOL] [comment] [EOL] return ( self . make_features ( altered_time_series , len ( altered_time_series [ [string] ] ) , ) , [ ] , ) [EOL] [EOL] if self . num_samples > [number] : [EOL] locations = [ np . random . randint ( max_num_context_windows ) for _ in range ( self . num_samples ) ] [EOL] else : [EOL] locations = range ( max_num_context_windows ) [EOL] for starting_index in locations : [EOL] if self . stratify_targets : [EOL] featurized_data = self . make_features ( altered_time_series , starting_index ) [EOL] for forecast_horizon_index in range ( self . forecast_horizon ) : [EOL] feature_data . append ( list ( featurized_data ) + [ forecast_horizon_index ] ) [EOL] target_data . append ( [ time_series [ [string] ] [ starting_index + self . context_window_size + forecast_horizon_index ] ] ) [EOL] else : [EOL] featurized_data = self . make_features ( altered_time_series , starting_index ) [EOL] feature_data . append ( featurized_data ) [EOL] target_data . append ( time_series [ [string] ] [ starting_index + self . context_window_size : starting_index + self . context_window_size + self . forecast_horizon ] ) [EOL] return feature_data , target_data [EOL] [EOL] def preprocess_from_list ( self , ts_list , change_internal_variables = True ) : [EOL] [docstring] [EOL] feature_data , target_data = [ ] , [ ] [EOL] self . num_samples = self . get_num_samples ( ts_list ) [EOL] [EOL] if isinstance ( self . cardinality , str ) : [EOL] self . cardinality = ( self . infer_cardinalities ( ts_list ) [EOL] if self . cardinality == [string] [EOL] else [ ] ) [EOL] [EOL] for time_series in ts_list : [EOL] ts_feature_data , ts_target_data = self . preprocess_from_single_ts ( time_series = time_series ) [EOL] feature_data += list ( ts_feature_data ) [EOL] target_data += list ( ts_target_data ) [EOL] logging . info ( [string] . format ( len ( feature_data ) ) ) [EOL] if change_internal_variables : [EOL] self . feature_data , self . target_data = feature_data , target_data [EOL] else : [EOL] return feature_data , target_data [EOL] [EOL] def get_num_samples ( self , ts_list ) : [EOL] [docstring] [EOL] n_time_series = sum ( [ len ( time_series [ [string] ] ) - self . context_window_size - self . forecast_horizon >= [number] for time_series in ts_list ] ) [EOL] max_size_ts = max ( [ len ( time_series [ [string] ] ) for time_series in ts_list ] ) [EOL] n_windows_per_time_series = self . max_n_datapts // n_time_series [EOL] if n_time_series * [number] < n_windows_per_time_series : [EOL] n_windows_per_time_series = n_time_series * [number] [EOL] elif n_windows_per_time_series == [number] : [EOL] n_windows_per_time_series = [number] [EOL] elif n_windows_per_time_series > max_size_ts : [EOL] n_windows_per_time_series = - [number] [EOL] return n_windows_per_time_series [EOL] [EOL] def infer_cardinalities ( self ) : [EOL] raise NotImplementedError [EOL] [EOL] [EOL] class PreprocessOnlyLagFeatures ( PreprocessGeneric ) : [EOL] def __init__ ( self , context_window_size , forecast_horizon = [number] , stratify_targets = False , n_ignore_last = [number] , num_samples = - [number] , use_feat_static_real = False , use_feat_dynamic_real = False , use_feat_dynamic_cat = False , cardinality = CardinalityLabel . auto , one_hot_encode = True , ** kwargs ) : [EOL] [EOL] if one_hot_encode : [EOL] assert cardinality != [string] or ( isinstance ( cardinality , List ) [EOL] and all ( c > [number] for c in cardinality ) ) , [string] [EOL] [EOL] super ( ) . __init__ ( context_window_size = context_window_size , forecast_horizon = forecast_horizon , stratify_targets = stratify_targets , n_ignore_last = n_ignore_last , num_samples = num_samples , ** kwargs ) [EOL] [EOL] self . use_feat_static_real = use_feat_static_real [EOL] self . cardinality = cardinality [EOL] self . use_feat_dynamic_real = use_feat_dynamic_real [EOL] self . use_feat_dynamic_cat = use_feat_dynamic_cat [EOL] self . one_hot_encode = one_hot_encode [EOL] [EOL] @ classmethod def _pre_transform ( cls , time_series_window ) : [EOL] [docstring] [EOL] mean_value = np . mean ( time_series_window ) [EOL] return ( ( time_series_window - mean_value ) , { [string] : mean_value , [string] : np . std ( time_series_window ) , [string] : len ( time_series_window ) , } , ) [EOL] [EOL] def encode_one_hot ( self , feat , cardinality ) : [EOL] result = [ [number] ] * cardinality [EOL] result [ feat ] = [number] [EOL] return result [EOL] [EOL] def encode_one_hot_all ( self , feat_list ) : [EOL] [comment] [EOL] np_feat_list = np . array ( feat_list ) [EOL] assert all ( np . floor ( np_feat_list ) == np_feat_list ) [EOL] [EOL] encoded = starmap ( self . encode_one_hot , zip ( feat_list , self . cardinality ) ) [EOL] encoded_chain = chain . from_iterable ( encoded ) [EOL] return list ( encoded_chain ) [EOL] [EOL] def infer_cardinalities ( self , time_series ) : [EOL] if [string] not in time_series [ [number] ] : [EOL] return [ ] [EOL] mat = np . array ( [ elem [ [string] ] for elem in time_series ] , dtype = int ) [EOL] return [ len ( set ( xs ) ) for xs in mat . T ] [EOL] [EOL] def make_features ( self , time_series , starting_index ) : [EOL] [docstring] [EOL] end_index = starting_index + self . context_window_size [EOL] if starting_index < [number] : [EOL] prefix = [ None ] * abs ( starting_index ) [EOL] else : [EOL] prefix = [ ] [EOL] time_series_window = time_series [ [string] ] [ starting_index : end_index ] [EOL] only_lag_features , transform_dict = self . _pre_transform ( time_series_window ) [EOL] [EOL] feat_static_real = ( list ( time_series [ [string] ] ) [EOL] if self . use_feat_static_real [EOL] else [ ] ) [EOL] if self . cardinality : [EOL] feat_static_cat = ( self . encode_one_hot_all ( time_series [ [string] ] ) [EOL] if self . one_hot_encode [EOL] else list ( time_series [ [string] ] ) ) [EOL] else : [EOL] feat_static_cat = [ ] [EOL] [EOL] feat_dynamic_real = ( [ elem for ent in time_series [ [string] ] for elem in ent ] [EOL] if self . use_feat_dynamic_real [EOL] else [ ] ) [EOL] feat_dynamic_cat = ( [ elem for ent in time_series [ [string] ] for elem in ent ] [EOL] if self . use_feat_dynamic_cat [EOL] else [ ] ) [EOL] [EOL] [comment] [EOL] np_feat_static_cat = np . array ( feat_static_cat ) [EOL] assert ( not feat_static_cat ) or all ( np . floor ( np_feat_static_cat ) == np_feat_static_cat ) [EOL] [EOL] np_feat_dynamic_cat = np . array ( feat_dynamic_cat ) [EOL] assert ( not feat_dynamic_cat ) or all ( np . floor ( np_feat_dynamic_cat ) == np_feat_dynamic_cat ) [EOL] [EOL] feat_dynamics = feat_dynamic_real + feat_dynamic_cat [EOL] feat_statics = feat_static_real + feat_static_cat [EOL] only_lag_features = list ( only_lag_features ) [EOL] return ( prefix + only_lag_features + list ( transform_dict . values ( ) ) + feat_statics + feat_dynamics ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.int]$ 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List$ 0 0 0 $typing.Dict$ 0 $builtins.int$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from . _predictor import TreePredictor [EOL] from . _estimator import TreeEstimator [EOL] [EOL] __all__ = [ [string] , [string] ] [EOL] [EOL] [comment] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import gluonts [EOL] import builtins [EOL] import mxnet [EOL] from mxnet . gluon import HybridBlock [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . dataset . common import Dataset [EOL] from gluonts . model . estimator import GluonEstimator , Predictor , TrainOutput [EOL] from gluonts . transform import FilterTransformation , Transformation [EOL] [EOL] [comment] [EOL] from . _predictor import TreePredictor [EOL] [EOL] [EOL] class ThirdPartyEstimator ( GluonEstimator ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , predictor_cls , ** kwargs ) : [EOL] self . predictor = predictor_cls ( ** kwargs ) [EOL] [EOL] def train ( self , training_data , validation_dataset = None ) : [EOL] return self . predictor ( training_data ) [EOL] [EOL] def train_model ( self ) : [EOL] return TrainOutput ( transformation = self . create_transformation ( ) , trained_net = self . create_training_network ( ) , predictor = self . create_predictor ( ) , ) [EOL] [EOL] def create_predictor ( self ) : [EOL] return self . predictor [EOL] [EOL] def create_transformation ( self ) : [EOL] return FilterTransformation ( lambda x : True ) [EOL] [EOL] def create_training_network ( self ) : [EOL] return HybridBlock ( ) [EOL] [EOL] [EOL] class TreeEstimator ( ThirdPartyEstimator ) : [EOL] @ validated ( getattr ( TreePredictor . __init__ , [string] ) ) def __init__ ( self , ** kwargs ) : [EOL] super ( ) . __init__ ( predictor_cls = TreePredictor , ** kwargs ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.transform.Transformation$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from . _estimator import DeepVAREstimator [EOL] [EOL] __all__ = [ [string] ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional , Tuple [EOL] import gluonts [EOL] import builtins [EOL] import mxnet [EOL] import typing [EOL] from typing import List , Optional , Tuple [EOL] [EOL] [comment] [EOL] import mxnet as mx [EOL] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] [EOL] [comment] [EOL] from gluonts . mx . block . scaler import MeanScaler , NOPScaler [EOL] from gluonts . mx . distribution import DistributionOutput [EOL] from gluonts . support . util import assert_shape , weighted_average [EOL] [EOL] [EOL] def make_rnn_cell ( num_cells , num_layers , cell_type , residual , dropout_rate , ) : [EOL] RnnCell = { [string] : mx . gluon . rnn . LSTMCell , [string] : mx . gluon . rnn . GRUCell } [ cell_type ] [EOL] rnn = mx . gluon . rnn . HybridSequentialRNNCell ( ) [EOL] for k in range ( num_layers ) : [EOL] cell = RnnCell ( hidden_size = num_cells ) [EOL] if residual : [EOL] cell = mx . gluon . rnn . ResidualCell ( cell ) if k > [number] else cell [EOL] cell = ( mx . gluon . rnn . ZoneoutCell ( cell , zoneout_states = dropout_rate ) [EOL] if dropout_rate > [number] [EOL] else cell ) [EOL] rnn . add ( cell ) [EOL] return rnn [EOL] [EOL] [EOL] class DeepVARNetwork ( mx . gluon . HybridBlock ) : [EOL] @ validated ( ) def __init__ ( self , num_layers , num_cells , cell_type , history_length , context_length , prediction_length , distr_output , dropout_rate , lags_seq , target_dim , conditioning_length , cardinality = [ [number] ] , embedding_dimension = [number] , scaling = True , ** kwargs , ) : [EOL] super ( ) . __init__ ( ** kwargs ) [EOL] self . num_layers = num_layers [EOL] self . num_cells = num_cells [EOL] self . cell_type = cell_type [EOL] self . history_length = history_length [EOL] self . context_length = context_length [EOL] self . prediction_length = prediction_length [EOL] self . dropout_rate = dropout_rate [EOL] self . cardinality = cardinality [EOL] self . embedding_dimension = embedding_dimension [EOL] self . num_cat = len ( cardinality ) [EOL] self . target_dim = target_dim [EOL] self . scaling = scaling [EOL] self . target_dim_sample = target_dim [EOL] self . conditioning_length = conditioning_length [EOL] [EOL] assert len ( set ( lags_seq ) ) == len ( lags_seq ) , [string] [EOL] lags_seq . sort ( ) [EOL] [EOL] self . lags_seq = lags_seq [EOL] [EOL] self . distr_output = distr_output [EOL] [EOL] self . target_dim = target_dim [EOL] [EOL] with self . name_scope ( ) : [EOL] self . proj_dist_args = distr_output . get_args_proj ( ) [EOL] [EOL] residual = True [EOL] [EOL] self . rnn = make_rnn_cell ( cell_type = cell_type , num_cells = num_cells , num_layers = num_layers , residual = residual , dropout_rate = dropout_rate , ) [EOL] [EOL] self . embed_dim = [number] [EOL] self . embed = mx . gluon . nn . Embedding ( input_dim = self . target_dim , output_dim = self . embed_dim ) [EOL] [EOL] if scaling : [EOL] self . scaler = MeanScaler ( keepdims = True ) [EOL] else : [EOL] self . scaler = NOPScaler ( keepdims = True ) [EOL] [EOL] @ staticmethod def get_lagged_subsequences ( F , sequence , sequence_length , indices , subsequences_length = [number] , ) : [EOL] [docstring] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] assert max ( indices ) + subsequences_length <= sequence_length , ( f" [string] " f"{ max ( indices ) } [string] { sequence_length }" ) [EOL] assert all ( lag_index >= [number] for lag_index in indices ) [EOL] [EOL] lagged_values = [ ] [EOL] for lag_index in indices : [EOL] begin_index = - lag_index - subsequences_length [EOL] end_index = - lag_index if lag_index > [number] else None [EOL] lagged_values . append ( F . slice_axis ( sequence , axis = [number] , begin = begin_index , end = end_index ) . expand_dims ( axis = [number] ) ) [EOL] return F . concat ( * lagged_values , num_args = len ( indices ) , dim = [number] ) . transpose ( axes = ( [number] , [number] , [number] , [number] ) ) [EOL] [EOL] def unroll ( self , F , lags , scale , time_feat , target_dimension_indicator , unroll_length , begin_state , ) : [EOL] [docstring] [EOL] [comment] [EOL] lags_scaled = F . broadcast_div ( lags , scale . expand_dims ( axis = - [number] ) ) [EOL] [EOL] assert_shape ( lags_scaled , ( - [number] , unroll_length , self . target_dim , len ( self . lags_seq ) ) , ) [EOL] [EOL] input_lags = F . reshape ( data = lags_scaled , shape = ( - [number] , unroll_length , len ( self . lags_seq ) * self . target_dim ) , ) [EOL] [EOL] [comment] [EOL] index_embeddings = self . embed ( target_dimension_indicator ) [EOL] assert_shape ( index_embeddings , ( - [number] , self . target_dim , self . embed_dim ) ) [EOL] [EOL] [comment] [EOL] repeated_index_embeddings = ( index_embeddings . expand_dims ( axis = [number] ) . repeat ( axis = [number] , repeats = unroll_length ) . reshape ( ( - [number] , unroll_length , self . target_dim * self . embed_dim ) ) ) [EOL] [EOL] [comment] [EOL] inputs = F . concat ( input_lags , repeated_index_embeddings , time_feat , dim = - [number] ) [EOL] [EOL] [comment] [EOL] outputs , state = self . rnn . unroll ( inputs = inputs , length = unroll_length , layout = [string] , merge_outputs = True , begin_state = begin_state , ) [EOL] [EOL] assert_shape ( outputs , ( - [number] , unroll_length , self . num_cells ) ) [EOL] for s in state : [EOL] assert_shape ( s , ( - [number] , self . num_cells ) ) [EOL] [EOL] assert_shape ( lags_scaled , ( - [number] , unroll_length , self . target_dim , len ( self . lags_seq ) ) , ) [EOL] [EOL] return outputs , state , lags_scaled , inputs [EOL] [EOL] def unroll_encoder ( self , F , past_time_feat , past_target_cdf , past_observed_values , past_is_pad , future_time_feat , future_target_cdf , target_dimension_indicator , ) : [EOL] [docstring] [EOL] [EOL] past_observed_values = F . broadcast_minimum ( past_observed_values , [number] - past_is_pad . expand_dims ( axis = - [number] ) ) [EOL] [EOL] if future_time_feat is None or future_target_cdf is None : [EOL] time_feat = past_time_feat . slice_axis ( axis = [number] , begin = - self . context_length , end = None ) [EOL] sequence = past_target_cdf [EOL] sequence_length = self . history_length [EOL] subsequences_length = self . context_length [EOL] else : [EOL] time_feat = F . concat ( past_time_feat . slice_axis ( axis = [number] , begin = - self . context_length , end = None ) , future_time_feat , dim = [number] , ) [EOL] sequence = F . concat ( past_target_cdf , future_target_cdf , dim = [number] ) [EOL] sequence_length = self . history_length + self . prediction_length [EOL] subsequences_length = self . context_length + self . prediction_length [EOL] [EOL] [comment] [EOL] lags = self . get_lagged_subsequences ( F = F , sequence = sequence , sequence_length = sequence_length , indices = self . lags_seq , subsequences_length = subsequences_length , ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] _ , scale = self . scaler ( past_target_cdf . slice_axis ( axis = [number] , begin = - self . context_length , end = None ) , past_observed_values . slice_axis ( axis = [number] , begin = - self . context_length , end = None ) , ) [EOL] [EOL] outputs , states , lags_scaled , inputs = self . unroll ( F = F , lags = lags , scale = scale , time_feat = time_feat , target_dimension_indicator = target_dimension_indicator , unroll_length = subsequences_length , begin_state = None , ) [EOL] [EOL] return outputs , states , scale , lags_scaled , inputs [EOL] [EOL] def distr ( self , rnn_outputs , time_features , scale , lags_scaled , target_dimension_indicator , seq_len , ) : [EOL] [docstring] [EOL] distr_args = self . proj_dist_args ( rnn_outputs ) [EOL] [EOL] [comment] [EOL] distr = self . distr_output . distribution ( distr_args , scale = scale ) [EOL] [EOL] return distr , distr_args [EOL] [EOL] def train_hybrid_forward ( self , F , target_dimension_indicator , past_time_feat , past_target_cdf , past_observed_values , past_is_pad , future_time_feat , future_target_cdf , future_observed_values , ) : [EOL] [docstring] [EOL] [EOL] seq_len = self . context_length + self . prediction_length [EOL] [EOL] [comment] [EOL] [comment] [EOL] rnn_outputs , _ , scale , lags_scaled , inputs = self . unroll_encoder ( F = F , past_time_feat = past_time_feat , past_target_cdf = past_target_cdf , past_observed_values = past_observed_values , past_is_pad = past_is_pad , future_time_feat = future_time_feat , future_target_cdf = future_target_cdf , target_dimension_indicator = target_dimension_indicator , ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] target = F . concat ( past_target_cdf . slice_axis ( axis = [number] , begin = - self . context_length , end = None ) , future_target_cdf , dim = [number] , ) [EOL] [EOL] [comment] [EOL] [EOL] distr , distr_args = self . distr ( time_features = inputs , rnn_outputs = rnn_outputs , scale = scale , lags_scaled = lags_scaled , target_dimension_indicator = target_dimension_indicator , seq_len = self . context_length + self . prediction_length , ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] likelihoods = - distr . log_prob ( target ) . expand_dims ( axis = - [number] ) [EOL] [EOL] assert_shape ( likelihoods , ( - [number] , seq_len , [number] ) ) [EOL] [EOL] past_observed_values = F . broadcast_minimum ( past_observed_values , [number] - past_is_pad . expand_dims ( axis = - [number] ) ) [EOL] [EOL] [comment] [EOL] observed_values = F . concat ( past_observed_values . slice_axis ( axis = [number] , begin = - self . context_length , end = None ) , future_observed_values , dim = [number] , ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] loss_weights = observed_values . min ( axis = - [number] , keepdims = True ) [EOL] [EOL] assert_shape ( loss_weights , ( - [number] , seq_len , [number] ) ) [EOL] [EOL] loss = weighted_average ( F = F , x = likelihoods , weights = loss_weights , axis = [number] ) [EOL] [EOL] assert_shape ( loss , ( - [number] , - [number] , [number] ) ) [EOL] [EOL] self . distribution = distr [EOL] [EOL] return ( loss , likelihoods ) + distr_args [EOL] [EOL] def sampling_decoder ( self , F , past_target_cdf , target_dimension_indicator , time_feat , scale , begin_states , ) : [EOL] [docstring] [EOL] [EOL] def repeat ( tensor ) : [EOL] return tensor . repeat ( repeats = self . num_parallel_samples , axis = [number] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] repeated_past_target_cdf = repeat ( past_target_cdf ) [EOL] repeated_time_feat = repeat ( time_feat ) [EOL] repeated_scale = repeat ( scale ) [EOL] repeated_target_dimension_indicator = repeat ( target_dimension_indicator ) [EOL] [EOL] [comment] [EOL] repeated_states = self . make_states ( begin_states ) [EOL] [EOL] future_samples = [ ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] for k in range ( self . prediction_length ) : [EOL] lags = self . get_lagged_subsequences ( F = F , sequence = repeated_past_target_cdf , sequence_length = self . history_length + k , indices = self . shifted_lags , subsequences_length = [number] , ) [EOL] [EOL] rnn_outputs , repeated_states , lags_scaled , inputs = self . unroll ( F = F , begin_state = repeated_states , lags = lags , scale = repeated_scale , time_feat = repeated_time_feat . slice_axis ( axis = [number] , begin = k , end = k + [number] ) , target_dimension_indicator = repeated_target_dimension_indicator , unroll_length = [number] , ) [EOL] [EOL] distr , distr_args = self . distr ( time_features = inputs , rnn_outputs = rnn_outputs , scale = repeated_scale , target_dimension_indicator = repeated_target_dimension_indicator , lags_scaled = lags_scaled , seq_len = [number] , ) [EOL] [EOL] [comment] [EOL] new_samples = distr . sample ( ) [EOL] [EOL] [comment] [EOL] future_samples . append ( new_samples ) [EOL] repeated_past_target_cdf = F . concat ( repeated_past_target_cdf , new_samples , dim = [number] ) [EOL] [EOL] [comment] [EOL] samples = F . concat ( * future_samples , dim = [number] ) [EOL] [EOL] [comment] [EOL] return samples . reshape ( shape = ( - [number] , self . num_parallel_samples , self . prediction_length , self . target_dim , ) ) [EOL] [EOL] def make_states ( self , begin_states ) : [EOL] [docstring] [EOL] [EOL] def repeat ( tensor ) : [EOL] return tensor . repeat ( repeats = self . num_parallel_samples , axis = [number] ) [EOL] [EOL] return [ repeat ( s ) for s in begin_states ] [EOL] [EOL] def predict_hybrid_forward ( self , F , target_dimension_indicator , past_time_feat , past_target_cdf , past_observed_values , past_is_pad , future_time_feat , ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] [comment] [EOL] past_observed_values = F . broadcast_minimum ( past_observed_values , [number] - past_is_pad . expand_dims ( axis = - [number] ) ) [EOL] [EOL] [comment] [EOL] _ , state , scale , _ , inputs = self . unroll_encoder ( F = F , past_time_feat = past_time_feat , past_target_cdf = past_target_cdf , past_observed_values = past_observed_values , past_is_pad = past_is_pad , future_time_feat = None , future_target_cdf = None , target_dimension_indicator = target_dimension_indicator , ) [EOL] [EOL] return self . sampling_decoder ( F = F , past_target_cdf = past_target_cdf , target_dimension_indicator = target_dimension_indicator , time_feat = future_time_feat , scale = scale , begin_states = state , ) [EOL] [EOL] [EOL] class DeepVARTrainingNetwork ( DeepVARNetwork ) : [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , target_dimension_indicator , past_time_feat , past_target_cdf , past_observed_values , past_is_pad , future_time_feat , future_target_cdf , future_observed_values , ) : [EOL] [docstring] [EOL] return self . train_hybrid_forward ( F , target_dimension_indicator , past_time_feat , past_target_cdf , past_observed_values , past_is_pad , future_time_feat , future_target_cdf , future_observed_values , ) [EOL] [EOL] [EOL] class DeepVARPredictionNetwork ( DeepVARNetwork ) : [EOL] @ validated ( ) def __init__ ( self , num_parallel_samples , ** kwargs ) : [EOL] super ( ) . __init__ ( ** kwargs ) [EOL] self . num_parallel_samples = num_parallel_samples [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] self . shifted_lags = [ l - [number] for l in self . lags_seq ] [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , target_dimension_indicator , past_time_feat , past_target_cdf , past_observed_values , past_is_pad , future_time_feat , ) : [EOL] [docstring] [EOL] return self . predict_hybrid_forward ( F = F , target_dimension_indicator = target_dimension_indicator , past_time_feat = past_time_feat , past_target_cdf = past_target_cdf , past_observed_values = past_observed_values , past_is_pad = past_is_pad , future_time_feat = future_time_feat , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 $builtins.int$ 0 $typing.List[builtins.int]$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.int]$ 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor,gluonts.model.common.Tensor,gluonts.model.common.Tensor]$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $builtins.int$ 0 $typing.Optional[typing.List[gluonts.model.common.Tensor]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.List[gluonts.model.common.Tensor]]$ 0 $typing.Optional[typing.List[gluonts.model.common.Tensor]]$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,typing.List[gluonts.model.common.Tensor],gluonts.model.common.Tensor,gluonts.model.common.Tensor,gluonts.model.common.Tensor]$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,...]$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,...]$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List [EOL] import mxnet [EOL] import gluonts [EOL] import typing [EOL] import builtins [EOL] import _network [EOL] from typing import List [EOL] [EOL] [comment] [EOL] from mxnet . gluon import HybridBlock , nn [EOL] [EOL] from gluonts . core . component import validated [EOL] from gluonts . dataset . field_names import FieldName [EOL] from gluonts . model . estimator import GluonEstimator [EOL] from gluonts . model . predictor import Predictor , RepresentableBlockPredictor [EOL] from gluonts . mx . block . feature import FeatureEmbedder [EOL] from gluonts . mx . block . rnn import RNN [EOL] from gluonts . mx . distribution import DistributionOutput , StudentTOutput [EOL] from gluonts . mx . trainer import Trainer [EOL] from gluonts . time_feature import time_features_from_frequency_str [EOL] from gluonts . transform import ( AddTimeFeatures , AsNumpyArray , Chain , InstanceSplitter , SetFieldIfNotPresent , TestSplitSampler , Transformation , ) [EOL] [EOL] [comment] [EOL] from . _network import CanonicalPredictionNetwork , CanonicalTrainingNetwork [EOL] [EOL] [EOL] class CanonicalEstimator ( GluonEstimator ) : [EOL] @ validated ( ) def __init__ ( self , model , is_sequential , freq , context_length , prediction_length , trainer = Trainer ( ) , num_parallel_samples = [number] , cardinality = list ( [ [number] ] ) , embedding_dimension = [number] , distr_output = StudentTOutput ( ) , ) : [EOL] super ( ) . __init__ ( trainer = trainer ) [EOL] [EOL] [comment] [EOL] self . freq = freq [EOL] self . context_length = context_length [EOL] self . prediction_length = prediction_length [EOL] self . distr_output = distr_output [EOL] self . num_parallel_samples = num_parallel_samples [EOL] self . cardinality = cardinality [EOL] self . embedding_dimensions = [ embedding_dimension for _ in cardinality ] [EOL] self . model = model [EOL] self . is_sequential = is_sequential [EOL] [EOL] def create_transformation ( self ) : [EOL] return Chain ( trans = [ AsNumpyArray ( field = FieldName . TARGET , expected_ndim = [number] ) , AddTimeFeatures ( start_field = FieldName . START , target_field = FieldName . TARGET , output_field = FieldName . FEAT_TIME , time_features = time_features_from_frequency_str ( self . freq ) , pred_length = self . prediction_length , ) , SetFieldIfNotPresent ( field = FieldName . FEAT_STATIC_CAT , value = [ [number] ] ) , AsNumpyArray ( field = FieldName . FEAT_STATIC_CAT , expected_ndim = [number] ) , InstanceSplitter ( target_field = FieldName . TARGET , is_pad_field = FieldName . IS_PAD , start_field = FieldName . START , forecast_start_field = FieldName . FORECAST_START , train_sampler = TestSplitSampler ( ) , time_series_fields = [ FieldName . FEAT_TIME ] , past_length = self . context_length , future_length = self . prediction_length , ) , ] ) [EOL] [EOL] def create_training_network ( self ) : [EOL] return CanonicalTrainingNetwork ( embedder = FeatureEmbedder ( cardinalities = self . cardinality , embedding_dims = self . embedding_dimensions , ) , model = self . model , distr_output = self . distr_output , is_sequential = self . is_sequential , ) [EOL] [EOL] def create_predictor ( self , transformation , trained_network , ) : [EOL] prediction_net = CanonicalPredictionNetwork ( embedder = trained_network . embedder , model = trained_network . model , distr_output = trained_network . distr_output , is_sequential = trained_network . is_sequential , prediction_len = self . prediction_length , num_parallel_samples = self . num_parallel_samples , params = trained_network . collect_params ( ) , ) [EOL] [EOL] return RepresentableBlockPredictor ( input_transform = transformation , prediction_net = prediction_net , batch_size = self . trainer . batch_size , freq = self . freq , prediction_length = self . prediction_length , ctx = self . trainer . ctx , ) [EOL] [EOL] [EOL] class CanonicalRNNEstimator ( CanonicalEstimator ) : [EOL] @ validated ( ) def __init__ ( self , freq , context_length , prediction_length , trainer = Trainer ( ) , num_layers = [number] , num_cells = [number] , cell_type = [string] , num_parallel_samples = [number] , cardinality = list ( [ [number] ] ) , embedding_dimension = [number] , distr_output = StudentTOutput ( ) , ) : [EOL] model = RNN ( mode = cell_type , num_layers = num_layers , num_hidden = num_cells ) [EOL] [EOL] super ( CanonicalRNNEstimator , self ) . __init__ ( model = model , is_sequential = True , freq = freq , context_length = context_length , prediction_length = prediction_length , trainer = trainer , num_parallel_samples = num_parallel_samples , cardinality = cardinality , embedding_dimension = embedding_dimension , distr_output = distr_output , ) [EOL] [EOL] [EOL] class MLPForecasterEstimator ( CanonicalEstimator ) : [EOL] @ validated ( ) def __init__ ( self , freq , context_length , prediction_length , trainer = Trainer ( ) , hidden_dim_sequence = list ( [ [number] ] ) , num_parallel_samples = [number] , cardinality = list ( [ [number] ] ) , embedding_dimension = [number] , distr_output = StudentTOutput ( ) , ) : [EOL] model = nn . HybridSequential ( ) [EOL] [EOL] for layer , layer_dim in enumerate ( hidden_dim_sequence ) : [EOL] model . add ( nn . Dense ( layer_dim , flatten = False , activation = [string] , prefix = [string] % layer , ) ) [EOL] [EOL] super ( MLPForecasterEstimator , self ) . __init__ ( model = model , is_sequential = False , freq = freq , context_length = context_length , prediction_length = prediction_length , trainer = trainer , num_parallel_samples = num_parallel_samples , cardinality = cardinality , embedding_dimension = embedding_dimension , distr_output = distr_output , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.mx.trainer.Trainer$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.mx.trainer.Trainer$ 0 $gluonts.mx.trainer.Trainer$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.transform.Transformation$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $_network.CanonicalTrainingNetwork$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.predictor.Predictor$ 0 0 0 $gluonts.transform.Transformation$ 0 $_network.CanonicalTrainingNetwork$ 0 0 0 0 0 0 0 0 0 0 $_network.CanonicalTrainingNetwork$ 0 0 0 0 0 $_network.CanonicalTrainingNetwork$ 0 0 0 0 0 $_network.CanonicalTrainingNetwork$ 0 0 0 0 0 $_network.CanonicalTrainingNetwork$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $_network.CanonicalTrainingNetwork$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.transform.Transformation$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 $builtins.int$ 0 $builtins.int$ 0 $gluonts.mx.trainer.Trainer$ 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.str$ 0 0 0 $builtins.int$ 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $gluonts.mx.distribution.DistributionOutput$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.int$ 0 $gluonts.mx.trainer.Trainer$ 0 $gluonts.mx.trainer.Trainer$ 0 $builtins.int$ 0 $builtins.int$ 0 $typing.List[builtins.int]$ 0 $typing.List[builtins.int]$ 0 $builtins.int$ 0 $builtins.int$ 0 $gluonts.mx.distribution.DistributionOutput$ 0 $gluonts.mx.distribution.DistributionOutput$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 $builtins.int$ 0 $builtins.int$ 0 $gluonts.mx.trainer.Trainer$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $gluonts.mx.distribution.DistributionOutput$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.int$ 0 $gluonts.mx.trainer.Trainer$ 0 $gluonts.mx.trainer.Trainer$ 0 $builtins.int$ 0 $builtins.int$ 0 $typing.List[builtins.int]$ 0 $typing.List[builtins.int]$ 0 $builtins.int$ 0 $builtins.int$ 0 $gluonts.mx.distribution.DistributionOutput$ 0 $gluonts.mx.distribution.DistributionOutput$ 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from . _estimator import CanonicalRNNEstimator [EOL] [EOL] __all__ = [ [string] ] [EOL] [EOL] [comment] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional , Tuple [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] from typing import List , Optional , Tuple [EOL] [EOL] [comment] [EOL] import mxnet as mx [EOL] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] from gluonts . model . deepvar . _network import DeepVARNetwork [EOL] [EOL] [comment] [EOL] from gluonts . mx . distribution . distribution import getF [EOL] [EOL] [EOL] class GPVARNetwork ( DeepVARNetwork ) : [EOL] @ validated ( ) def __init__ ( self , target_dim_sample , ** kwargs ) : [EOL] super ( ) . __init__ ( embedding_dimension = [number] , cardinality = [ [number] ] , ** kwargs ) [EOL] self . target_dim_sample = target_dim_sample [EOL] [EOL] with self . name_scope ( ) : [EOL] self . embed = mx . gluon . nn . Embedding ( input_dim = self . target_dim , output_dim = [number] * self . distr_output . rank , ) [EOL] [EOL] def unroll ( self , F , lags , scale , time_feat , target_dimension_indicator , unroll_length , begin_state , ) : [EOL] [docstring] [EOL] [comment] [EOL] lags_scaled = F . broadcast_div ( lags , scale . expand_dims ( axis = - [number] ) ) [EOL] [EOL] outputs = [ ] [EOL] states = [ ] [EOL] [EOL] [comment] [EOL] index_embeddings = self . embed ( target_dimension_indicator ) [EOL] [EOL] [comment] [EOL] repeated_index_embeddings = index_embeddings . expand_dims ( axis = [number] ) . repeat ( axis = [number] , repeats = unroll_length ) [EOL] [EOL] inputs_seq = [ ] [EOL] [EOL] for i in range ( self . target_dim_sample ) : [EOL] [comment] [EOL] inputs = F . concat ( lags_scaled . slice_axis ( axis = [number] , begin = i , end = i + [number] ) . squeeze ( axis = [number] ) , repeated_index_embeddings . slice_axis ( axis = [number] , begin = i , end = i + [number] ) . squeeze ( axis = [number] ) , time_feat , dim = - [number] , ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] outputs_single_dim , state = self . rnn . unroll ( inputs = inputs , length = unroll_length , layout = [string] , merge_outputs = True , begin_state = begin_state [ i ] [EOL] if begin_state is not None [EOL] else None , ) [EOL] outputs . append ( outputs_single_dim ) [EOL] states . append ( state ) [EOL] inputs_seq . append ( inputs ) [EOL] [EOL] [comment] [EOL] outputs = F . stack ( * outputs , num_args = self . target_dim_sample , axis = [number] ) [EOL] [EOL] return outputs , states , lags_scaled , time_feat [EOL] [EOL] def distr ( self , rnn_outputs , time_features , scale , lags_scaled , target_dimension_indicator , seq_len , ) : [EOL] [docstring] [EOL] F = getF ( rnn_outputs ) [EOL] [EOL] [comment] [EOL] index_embeddings = self . embed ( target_dimension_indicator ) [EOL] [EOL] [comment] [EOL] repeated_index_embeddings = index_embeddings . expand_dims ( axis = [number] ) . repeat ( axis = [number] , repeats = seq_len ) [EOL] [EOL] [comment] [EOL] time_features = time_features . expand_dims ( axis = [number] ) . repeat ( axis = [number] , repeats = self . target_dim_sample ) [EOL] [EOL] [comment] [EOL] distr_input = F . concat ( rnn_outputs , repeated_index_embeddings , time_features , dim = - [number] ) [EOL] [EOL] [comment] [EOL] distr_args = self . proj_dist_args ( distr_input ) [EOL] [EOL] [comment] [EOL] distr = self . distr_output . distribution ( distr_args , scale = scale , dim = self . target_dim_sample ) [EOL] [EOL] return distr , distr_args [EOL] [EOL] [EOL] class GPVARTrainingNetwork ( GPVARNetwork ) : [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , target_dimension_indicator , past_time_feat , past_target_cdf , past_observed_values , past_is_pad , future_time_feat , future_target_cdf , future_observed_values , ) : [EOL] [docstring] [EOL] [EOL] return self . train_hybrid_forward ( F , target_dimension_indicator , past_time_feat , past_target_cdf , past_observed_values , past_is_pad , future_time_feat , future_target_cdf , future_observed_values , ) [EOL] [EOL] [EOL] class GPVARPredictionNetwork ( GPVARNetwork ) : [EOL] @ validated ( ) def __init__ ( self , num_parallel_samples , ** kwargs ) : [EOL] super ( ) . __init__ ( ** kwargs ) [EOL] self . num_parallel_samples = num_parallel_samples [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] self . shifted_lags = [ l - [number] for l in self . lags_seq ] [EOL] [EOL] def make_states ( self , begin_states ) : [EOL] [docstring] [EOL] [EOL] def repeat ( tensor ) : [EOL] return tensor . repeat ( repeats = self . num_parallel_samples , axis = [number] ) [EOL] [EOL] return [ [ repeat ( s ) for s in states ] for states in begin_states ] [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , target_dimension_indicator , past_time_feat , past_target_cdf , past_observed_values , past_is_pad , future_time_feat , ) : [EOL] [docstring] [EOL] [EOL] return self . predict_hybrid_forward ( F = F , target_dimension_indicator = target_dimension_indicator , past_time_feat = past_time_feat , past_target_cdf = past_target_cdf , past_observed_values = past_observed_values , past_is_pad = past_is_pad , future_time_feat = future_time_feat , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,typing.List[gluonts.model.common.Tensor],gluonts.model.common.Tensor,gluonts.model.common.Tensor]$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $builtins.int$ 0 $typing.Optional[typing.List[gluonts.model.common.Tensor]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.List[gluonts.model.common.Tensor]]$ 0 $typing.Optional[typing.List[gluonts.model.common.Tensor]]$ 0 0 0 0 0 $typing.Optional[typing.List[gluonts.model.common.Tensor]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,...]$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.List[gluonts.model.common.Tensor]]$ 0 0 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from . _estimator import GPVAREstimator [EOL] [EOL] __all__ = [ [string] ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from . _predictor import PROPHET_IS_INSTALLED , ProphetPredictor [EOL] [EOL] __all__ = [ [string] , [string] ] [EOL] [EOL] [comment] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from mxnet . gluon import HybridBlock , nn [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . mx . block . rnn import RNN [EOL] [EOL] [EOL] class RNNModel ( HybridBlock ) : [EOL] @ validated ( ) def __init__ ( self , mode , num_hidden , num_layers , num_output , bidirectional = False , ** kwargs , ) : [EOL] super ( RNNModel , self ) . __init__ ( ** kwargs ) [EOL] self . num_output = num_output [EOL] [EOL] with self . name_scope ( ) : [EOL] self . rnn = RNN ( mode = mode , num_hidden = num_hidden , num_layers = num_layers , bidirectional = bidirectional , ) [EOL] [EOL] self . decoder = nn . Dense ( num_output , in_units = num_hidden , flatten = False ) [EOL] [EOL] def hybrid_forward ( self , F , inputs ) : [EOL] return self . decoder ( self . rnn ( inputs ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from . _estimator import DeepFactorEstimator [EOL] [EOL] __all__ = [ [string] ] [EOL] [EOL] [comment] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional [EOL] import typing [EOL] import builtins [EOL] import _network [EOL] import gluonts [EOL] from typing import List , Optional [EOL] [EOL] [comment] [EOL] from gluonts import transform [EOL] from gluonts . core . component import validated [EOL] from gluonts . dataset . field_names import FieldName [EOL] from gluonts . model . estimator import GluonEstimator [EOL] from gluonts . model . predictor import Predictor , RepresentableBlockPredictor [EOL] from gluonts . mx . block . feature import FeatureEmbedder [EOL] from gluonts . mx . distribution import DistributionOutput , StudentTOutput [EOL] from gluonts . mx . trainer import Trainer [EOL] from gluonts . time_feature import time_features_from_frequency_str [EOL] from gluonts . transform import ( AddTimeFeatures , AsNumpyArray , Chain , SetFieldIfNotPresent , TestSplitSampler , Transformation , ) [EOL] [EOL] from . _network import DeepFactorPredictionNetwork , DeepFactorTrainingNetwork [EOL] from . RNNModel import RNNModel [EOL] [EOL] [EOL] class DeepFactorEstimator ( GluonEstimator ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , freq , prediction_length , num_hidden_global = [number] , num_layers_global = [number] , num_factors = [number] , num_hidden_local = [number] , num_layers_local = [number] , cell_type = [string] , trainer = Trainer ( ) , context_length = None , num_parallel_samples = [number] , cardinality = list ( [ [number] ] ) , embedding_dimension = [number] , distr_output = StudentTOutput ( ) , ) : [EOL] super ( ) . __init__ ( trainer = trainer ) [EOL] [EOL] assert ( prediction_length > [number] ) , [string] [EOL] assert ( context_length is None or context_length > [number] ) , [string] [EOL] assert num_layers_global > [number] , [string] [EOL] assert num_hidden_global > [number] , [string] [EOL] assert num_factors > [number] , [string] [EOL] assert ( num_hidden_local > [number] ) , [string] [EOL] assert ( num_layers_local > [number] ) , [string] [EOL] assert all ( [ c > [number] for c in cardinality ] ) , [string] [EOL] assert ( embedding_dimension > [number] ) , [string] [EOL] assert ( num_parallel_samples > [number] ) , [string] [EOL] [EOL] self . freq = freq [EOL] self . context_length = ( context_length if context_length is not None else prediction_length ) [EOL] self . prediction_length = prediction_length [EOL] self . distr_output = distr_output [EOL] self . num_parallel_samples = num_parallel_samples [EOL] self . cardinality = cardinality [EOL] self . embedding_dimensions = [ embedding_dimension for _ in cardinality ] [EOL] [EOL] self . global_model = RNNModel ( mode = cell_type , num_hidden = num_hidden_global , num_layers = num_layers_global , num_output = num_factors , ) [EOL] [EOL] [comment] [EOL] self . local_model = RNNModel ( mode = cell_type , num_hidden = num_hidden_local , num_layers = num_layers_local , num_output = [number] , ) [EOL] [EOL] def create_transformation ( self ) : [EOL] return Chain ( trans = [ AsNumpyArray ( field = FieldName . TARGET , expected_ndim = [number] ) , AddTimeFeatures ( start_field = FieldName . START , target_field = FieldName . TARGET , output_field = FieldName . FEAT_TIME , time_features = time_features_from_frequency_str ( self . freq ) , pred_length = self . prediction_length , ) , SetFieldIfNotPresent ( field = FieldName . FEAT_STATIC_CAT , value = [ [number] ] ) , AsNumpyArray ( field = FieldName . FEAT_STATIC_CAT , expected_ndim = [number] ) , transform . InstanceSplitter ( target_field = FieldName . TARGET , is_pad_field = FieldName . IS_PAD , start_field = FieldName . START , forecast_start_field = FieldName . FORECAST_START , train_sampler = TestSplitSampler ( ) , time_series_fields = [ FieldName . FEAT_TIME ] , past_length = self . context_length , future_length = self . prediction_length , ) , ] ) [EOL] [EOL] def create_training_network ( self ) : [EOL] return DeepFactorTrainingNetwork ( embedder = FeatureEmbedder ( cardinalities = self . cardinality , embedding_dims = self . embedding_dimensions , ) , global_model = self . global_model , local_model = self . local_model , ) [EOL] [EOL] def create_predictor ( self , transformation , trained_network , ) : [EOL] prediction_net = DeepFactorPredictionNetwork ( embedder = trained_network . embedder , global_model = trained_network . global_model , local_model = trained_network . local_model , prediction_len = self . prediction_length , num_parallel_samples = self . num_parallel_samples , params = trained_network . collect_params ( ) , ) [EOL] [EOL] return RepresentableBlockPredictor ( input_transform = transformation , prediction_net = prediction_net , batch_size = self . trainer . batch_size , freq = self . freq , prediction_length = self . prediction_length , ctx = self . trainer . ctx , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.str$ 0 0 0 $gluonts.mx.trainer.Trainer$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.mx.trainer.Trainer$ 0 $gluonts.mx.trainer.Trainer$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 $gluonts.transform.Transformation$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $_network.DeepFactorTrainingNetwork$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.predictor.Predictor$ 0 0 0 $gluonts.transform.Transformation$ 0 $_network.DeepFactorTrainingNetwork$ 0 0 0 0 0 0 0 0 0 0 $_network.DeepFactorTrainingNetwork$ 0 0 0 0 0 $_network.DeepFactorTrainingNetwork$ 0 0 0 0 0 $_network.DeepFactorTrainingNetwork$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $_network.DeepFactorTrainingNetwork$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.transform.Transformation$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from . _estimator import WaveNetEstimator [EOL] from . _network import WaveNet , WaveNetSampler [EOL] [EOL] __all__ = [ [string] , [string] , [string] ] [EOL] [EOL] [comment] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional , Tuple [EOL] import typing [EOL] import builtins [EOL] import gluonts [EOL] import mxnet [EOL] from typing import List , Optional , Tuple [EOL] [EOL] [comment] [EOL] import mxnet as mx [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from gluonts . core . component import DType [EOL] from gluonts . model . common import Tensor [EOL] from gluonts . mx . distribution import MultivariateGaussian [EOL] from gluonts . mx . distribution . distribution import getF [EOL] from gluonts . mx . kernels import Kernel [EOL] from gluonts . support . linalg_util import ( batch_diagonal , jitter_cholesky , jitter_cholesky_eig , ) [EOL] [EOL] [EOL] class GaussianProcess : [EOL] [comment] [EOL] def __init__ ( self , sigma , kernel , prediction_length = None , context_length = None , num_samples = None , ctx = mx . Context ( [string] ) , float_type = np . float64 , jitter_method = [string] , max_iter_jitter = [number] , neg_tol = - [number] , diag_weight = [number] , increase_jitter = [number] , sample_noise = True , F = None , ) : [EOL] [docstring] [EOL] assert ( prediction_length is None or prediction_length > [number] ) , [string] [EOL] assert ( context_length is None or context_length > [number] ) , [string] [EOL] assert ( num_samples is None or num_samples > [number] ) , [string] [EOL] self . sigma = sigma [EOL] self . kernel = kernel [EOL] self . prediction_length = prediction_length [EOL] self . context_length = ( context_length if context_length is not None else prediction_length ) [EOL] self . num_samples = num_samples [EOL] self . F = F if F else getF ( sigma ) [EOL] self . ctx = ctx [EOL] self . float_type = float_type [EOL] self . jitter_method = jitter_method [EOL] self . max_iter_jitter = max_iter_jitter [EOL] self . neg_tol = neg_tol [EOL] self . diag_weight = diag_weight [EOL] self . increase_jitter = increase_jitter [EOL] self . sample_noise = sample_noise [EOL] [EOL] [comment] [EOL] def _compute_cholesky_gp ( self , kernel_matrix , num_data_points = None , noise = True , ) : [EOL] [docstring] [EOL] if noise : [comment] [EOL] kernel_matrix = self . F . broadcast_plus ( kernel_matrix , self . F . broadcast_mul ( self . sigma ** [number] , self . F . eye ( num_data_points , ctx = self . ctx , dtype = self . float_type ) , ) , ) [EOL] [comment] [EOL] [comment] [EOL] if self . jitter_method == [string] : [EOL] return jitter_cholesky_eig ( self . F , kernel_matrix , num_data_points , self . ctx , self . float_type , self . diag_weight , ) [EOL] elif self . jitter_method == [string] and self . F is mx . nd : [EOL] return jitter_cholesky ( self . F , kernel_matrix , num_data_points , self . ctx , self . float_type , self . max_iter_jitter , self . neg_tol , self . diag_weight , self . increase_jitter , ) [EOL] else : [EOL] return self . F . linalg . potrf ( kernel_matrix ) [EOL] [EOL] def log_prob ( self , x_train , y_train ) : [EOL] [docstring] [EOL] assert ( self . context_length is not None ) , [string] [EOL] return - MultivariateGaussian ( self . F . zeros_like ( y_train ) , self . _compute_cholesky_gp ( self . kernel . kernel_matrix ( x_train , x_train ) , self . context_length , ) , ) . log_prob ( y_train ) [EOL] [EOL] def sample ( self , mean , covariance ) : [EOL] [docstring] [EOL] assert ( self . num_samples is not None ) , [string] [EOL] assert ( self . prediction_length is not None ) , [string] [EOL] samples = MultivariateGaussian ( mean , self . _compute_cholesky_gp ( covariance , self . prediction_length , self . sample_noise ) , ) . sample_rep ( self . num_samples , dtype = self . float_type ) [comment] [EOL] return self . F . transpose ( samples , axes = ( [number] , [number] , [number] ) ) [EOL] [EOL] [comment] [EOL] def exact_inference ( self , x_train , y_train , x_test ) : [EOL] [docstring] [EOL] assert ( self . context_length is not None ) , [string] [EOL] assert ( self . prediction_length is not None ) , [string] [EOL] [comment] [EOL] l_train = self . _compute_cholesky_gp ( self . kernel . kernel_matrix ( x_train , x_train ) , self . context_length ) [EOL] [EOL] lower_tri_solve = self . F . linalg . trsm ( l_train , self . kernel . kernel_matrix ( x_train , x_test ) ) [EOL] predictive_mean = self . F . linalg . gemm2 ( lower_tri_solve , self . F . linalg . trsm ( l_train , y_train . expand_dims ( axis = - [number] ) ) , transpose_a = True , ) . squeeze ( axis = - [number] ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] predictive_covariance = self . kernel . kernel_matrix ( x_test , x_test ) - self . F . linalg . gemm2 ( lower_tri_solve , lower_tri_solve , transpose_a = True ) [EOL] [comment] [EOL] predictive_std = batch_diagonal ( self . F , predictive_covariance , self . prediction_length , self . ctx , self . float_type , ) [EOL] [comment] [EOL] if self . sample_noise : [EOL] predictive_std = self . F . broadcast_add ( predictive_std , self . sigma ** [number] ) [EOL] predictive_std = self . F . sqrt ( predictive_std ) . squeeze ( axis = - [number] ) [EOL] [comment] [EOL] return ( self . sample ( predictive_mean , predictive_covariance ) , predictive_mean , predictive_std , ) [EOL] [EOL] @ staticmethod def plot ( ts_idx , x_train = None , y_train = None , x_test = None , mean = None , std = None , samples = None , axis = None , ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] [comment] [EOL] import matplotlib . pyplot as plt [EOL] [EOL] if x_train is not None : [EOL] x_train = x_train [ ts_idx , : , : ] . asnumpy ( ) [EOL] if y_train is not None : [EOL] y_train = y_train [ ts_idx , : ] . asnumpy ( ) [EOL] plt . plot ( x_train , y_train , [string] , ms = [number] ) [EOL] if x_test is not None : [EOL] x_test = x_test [ ts_idx , : , : ] . asnumpy ( ) [EOL] if samples is not None : [EOL] samples = samples [ ts_idx , : , : ] . asnumpy ( ) [EOL] plt . plot ( x_test , samples ) [EOL] if mean is not None : [EOL] mean = mean [ ts_idx , : ] . asnumpy ( ) [EOL] plt . plot ( x_test , mean , [string] , lw = [number] ) [EOL] if std is not None : [EOL] std = std [ ts_idx , : ] . asnumpy ( ) [EOL] plt . gca ( ) . fill_between ( x_test . flat , mean - [number] * std , mean + [number] * std , color = [string] , ) [EOL] if axis is not None : [EOL] plt . axis ( axis ) [EOL] plt . title ( f" [string] { ts_idx }" ) [EOL] plt . show ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor,gluonts.model.common.Tensor]$ 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.List]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.List]$ 0 0 0 0 0 0 0 $typing.Optional[typing.List]$ 0 $typing.Optional[typing.List]$ 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] import mxnet [EOL] from typing import List , Optional [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] from mxnet . gluon import HybridBlock [EOL] [EOL] [comment] [EOL] from gluonts . core . component import DType , validated [EOL] from gluonts . dataset . field_names import FieldName [EOL] from gluonts . model . estimator import GluonEstimator [EOL] from gluonts . model . predictor import Predictor , RepresentableBlockPredictor [EOL] from gluonts . mx . kernels import KernelOutput , RBFKernelOutput [EOL] from gluonts . mx . trainer import Trainer [EOL] from gluonts . support . util import copy_parameters [EOL] from gluonts . time_feature import TimeFeature , time_features_from_frequency_str [EOL] from gluonts . transform import ( AddTimeFeatures , AsNumpyArray , CanonicalInstanceSplitter , Chain , SetFieldIfNotPresent , TestSplitSampler , Transformation , ) [EOL] [EOL] [comment] [EOL] from . _network import ( GaussianProcessPredictionNetwork , GaussianProcessTrainingNetwork , ) [EOL] [EOL] [EOL] class GaussianProcessEstimator ( GluonEstimator ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , freq , prediction_length , cardinality , trainer = Trainer ( ) , context_length = None , kernel_output = RBFKernelOutput ( ) , params_scaling = True , dtype = np . float64 , max_iter_jitter = [number] , jitter_method = [string] , sample_noise = True , time_features = None , num_parallel_samples = [number] , ) : [EOL] self . float_type = dtype [EOL] super ( ) . __init__ ( trainer = trainer , dtype = self . float_type ) [EOL] [EOL] assert ( prediction_length > [number] ) , [string] [EOL] assert cardinality > [number] , [string] [EOL] assert ( context_length is None or context_length > [number] ) , [string] [EOL] assert ( num_parallel_samples > [number] ) , [string] [EOL] [EOL] self . freq = freq [EOL] self . prediction_length = prediction_length [EOL] self . context_length = ( context_length if context_length is not None else prediction_length ) [EOL] self . cardinality = cardinality [EOL] self . kernel_output = kernel_output [EOL] self . params_scaling = params_scaling [EOL] self . max_iter_jitter = max_iter_jitter [EOL] self . jitter_method = jitter_method [EOL] self . sample_noise = sample_noise [EOL] self . time_features = ( time_features [EOL] if time_features is not None [EOL] else time_features_from_frequency_str ( self . freq ) ) [EOL] self . num_parallel_samples = num_parallel_samples [EOL] [EOL] def create_transformation ( self ) : [EOL] return Chain ( [ AsNumpyArray ( field = FieldName . TARGET , expected_ndim = [number] ) , AddTimeFeatures ( start_field = FieldName . START , target_field = FieldName . TARGET , output_field = FieldName . FEAT_TIME , time_features = self . time_features , pred_length = self . prediction_length , ) , SetFieldIfNotPresent ( field = FieldName . FEAT_STATIC_CAT , value = [ [number] ] ) , AsNumpyArray ( field = FieldName . FEAT_STATIC_CAT , expected_ndim = [number] ) , CanonicalInstanceSplitter ( target_field = FieldName . TARGET , is_pad_field = FieldName . IS_PAD , start_field = FieldName . START , forecast_start_field = FieldName . FORECAST_START , instance_sampler = TestSplitSampler ( ) , time_series_fields = [ FieldName . FEAT_TIME ] , instance_length = self . context_length , use_prediction_features = True , prediction_length = self . prediction_length , ) , ] ) [EOL] [EOL] def create_training_network ( self ) : [EOL] return GaussianProcessTrainingNetwork ( prediction_length = self . prediction_length , context_length = self . context_length , cardinality = self . cardinality , kernel_output = self . kernel_output , params_scaling = self . params_scaling , ctx = self . trainer . ctx , float_type = self . float_type , max_iter_jitter = self . max_iter_jitter , jitter_method = self . jitter_method , ) [EOL] [EOL] def create_predictor ( self , transformation , trained_network ) : [EOL] prediction_network = GaussianProcessPredictionNetwork ( prediction_length = self . prediction_length , context_length = self . context_length , cardinality = self . cardinality , num_parallel_samples = self . num_parallel_samples , params = trained_network . collect_params ( ) , kernel_output = self . kernel_output , params_scaling = self . params_scaling , ctx = self . trainer . ctx , float_type = self . float_type , max_iter_jitter = self . max_iter_jitter , jitter_method = self . jitter_method , sample_noise = self . sample_noise , ) [EOL] [EOL] copy_parameters ( net_source = trained_network , net_dest = prediction_network ) [EOL] [EOL] return RepresentableBlockPredictor ( input_transform = transformation , prediction_net = prediction_network , batch_size = self . trainer . batch_size , freq = self . freq , prediction_length = self . prediction_length , ctx = self . trainer . ctx , dtype = self . float_type , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.transform.Transformation$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.predictor.Predictor$ 0 0 0 $gluonts.transform.Transformation$ 0 $mxnet.gluon.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.transform.Transformation$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Tuple [EOL] import gluonts [EOL] import builtins [EOL] import mxnet [EOL] import typing [EOL] from typing import Tuple [EOL] [EOL] [comment] [EOL] import mxnet as mx [EOL] [EOL] [comment] [EOL] from gluonts . core . component import DType , validated [EOL] from gluonts . model . common import Tensor [EOL] from gluonts . mx . distribution . distribution import softplus [EOL] from gluonts . mx . kernels import KernelOutputDict [EOL] [EOL] from . gaussian_process import GaussianProcess [EOL] [EOL] [EOL] class GaussianProcessNetworkBase ( mx . gluon . HybridBlock ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] @ validated ( ) def __init__ ( self , prediction_length , context_length , cardinality , kernel_output , params_scaling , ctx , float_type , max_iter_jitter , jitter_method , ** kwargs , ) : [EOL] [docstring] [EOL] super ( ) . __init__ ( ** kwargs ) [EOL] [EOL] self . prediction_length = prediction_length [EOL] self . context_length = context_length [EOL] self . cardinality = cardinality [EOL] self . kernel_output = kernel_output [EOL] self . params_scaling = params_scaling [EOL] self . float_type = float_type [EOL] self . ctx = ctx [EOL] self . max_iter_jitter = max_iter_jitter [EOL] self . jitter_method = jitter_method [EOL] [EOL] with self . name_scope ( ) : [EOL] self . proj_kernel_args = kernel_output . get_args_proj ( self . float_type ) [EOL] self . num_hyperparams = kernel_output . get_num_args ( ) [EOL] self . embedding = mx . gluon . nn . Embedding ( input_dim = self . cardinality , output_dim = self . num_hyperparams + [number] , dtype = self . float_type , ) [EOL] [EOL] [comment] [EOL] def get_gp_params ( self , F , past_target , past_time_feat , feat_static_cat , ) : [EOL] [docstring] [EOL] output = self . embedding ( feat_static_cat . squeeze ( ) ) [comment] [EOL] kernel_args = self . proj_kernel_args ( output ) [EOL] sigma = softplus ( F , output . slice_axis ( axis = [number] , begin = self . num_hyperparams , end = self . num_hyperparams + [number] , ) , ) [EOL] if self . params_scaling : [EOL] scalings = self . kernel_output . gp_params_scaling ( F , past_target , past_time_feat ) [EOL] sigma = F . broadcast_mul ( sigma , scalings [ self . num_hyperparams ] ) [EOL] kernel_args = ( F . broadcast_mul ( kernel_arg , scaling ) for kernel_arg , scaling in zip ( kernel_args , scalings [ [number] : self . num_hyperparams ] ) ) [EOL] min_value = [number] [EOL] max_value = [number] [EOL] kernel_args = ( kernel_arg . clip ( min_value , max_value ) . expand_dims ( axis = [number] ) for kernel_arg in kernel_args ) [EOL] sigma = sigma . clip ( min_value , max_value ) . expand_dims ( axis = [number] ) [EOL] return kernel_args , sigma [EOL] [EOL] [EOL] class GaussianProcessTrainingNetwork ( GaussianProcessNetworkBase ) : [EOL] [comment] [EOL] @ validated ( ) def __init__ ( self , * args , ** kwargs ) : [EOL] [docstring] [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , past_target , past_time_feat , feat_static_cat , ) : [EOL] [docstring] [EOL] kernel_args , sigma = self . get_gp_params ( F , past_target , past_time_feat , feat_static_cat ) [EOL] kernel = self . kernel_output . kernel ( kernel_args ) [EOL] gp = GaussianProcess ( sigma = sigma , kernel = kernel , context_length = self . context_length , ctx = self . ctx , float_type = self . float_type , max_iter_jitter = self . max_iter_jitter , jitter_method = self . jitter_method , ) [EOL] return gp . log_prob ( past_time_feat , past_target ) [EOL] [EOL] [EOL] class GaussianProcessPredictionNetwork ( GaussianProcessNetworkBase ) : [EOL] @ validated ( ) def __init__ ( self , num_parallel_samples , sample_noise , * args , ** kwargs ) : [EOL] [docstring] [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] self . num_parallel_samples = num_parallel_samples [EOL] self . sample_noise = sample_noise [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , past_target , past_time_feat , future_time_feat , feat_static_cat , ) : [EOL] [docstring] [EOL] kernel_args , sigma = self . get_gp_params ( F , past_target , past_time_feat , feat_static_cat ) [EOL] gp = GaussianProcess ( sigma = sigma , kernel = self . kernel_output . kernel ( kernel_args ) , context_length = self . context_length , prediction_length = self . prediction_length , num_samples = self . num_parallel_samples , ctx = self . ctx , float_type = self . float_type , max_iter_jitter = self . max_iter_jitter , jitter_method = self . jitter_method , sample_noise = self . sample_noise , ) [EOL] samples , _ , _ = gp . exact_inference ( past_time_feat , past_target , future_time_feat ) [comment] [EOL] return samples . swapaxes ( [number] , [number] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from . _estimator import GaussianProcessEstimator [EOL] [EOL] __all__ = [ [string] ] [EOL] [EOL] [comment] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from . _estimator import DeepAREstimator [EOL] [EOL] __all__ = [ [string] ] [EOL] [EOL] [comment] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Iterator , Optional , Dict [EOL] import typing [EOL] import builtins [EOL] import gluonts [EOL] import os [EOL] from pathlib import Path [EOL] from typing import Dict , Iterator , Optional [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . dataset . common import Dataset [EOL] from gluonts . model . forecast import SampleForecast [EOL] from gluonts . model . predictor import RepresentablePredictor [EOL] from gluonts . support . pandas import forecast_start [EOL] from gluonts . time_feature import get_seasonality [EOL] [EOL] USAGE_MESSAGE = [string] [EOL] [EOL] [EOL] class RForecastPredictor ( RepresentablePredictor ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , freq , prediction_length , method_name = [string] , period = None , trunc_length = None , params = None , ) : [EOL] super ( ) . __init__ ( freq = freq , prediction_length = prediction_length ) [EOL] [EOL] try : [EOL] from rpy2 import robjects , rinterface [EOL] import rpy2 . robjects . packages as rpackages [EOL] from rpy2 . rinterface import RRuntimeError [EOL] except ImportError as e : [EOL] raise ImportError ( str ( e ) + USAGE_MESSAGE ) from e [EOL] [EOL] self . _robjects = robjects [EOL] self . _rinterface = rinterface [EOL] self . _rinterface . initr ( ) [EOL] self . _rpackages = rpackages [EOL] [EOL] this_dir = os . path . dirname ( os . path . realpath ( __file__ ) ) [EOL] this_dir = this_dir . replace ( [string] , [string] ) [comment] [EOL] r_files = [ n [ : - [number] ] for n in os . listdir ( f"{ this_dir } [string] " ) if n [ - [number] : ] == [string] ] [EOL] [EOL] for n in r_files : [EOL] try : [EOL] path = Path ( this_dir , [string] , f"{ n } [string] " ) [EOL] robjects . r ( f' [string] { path } [string] ' . replace ( [string] , [string] ) ) [EOL] except RRuntimeError as er : [EOL] raise RRuntimeError ( str ( er ) + USAGE_MESSAGE ) from er [EOL] [EOL] supported_methods = [ [string] , [string] , [string] , [string] , [string] ] [EOL] assert ( method_name in supported_methods ) , f" [string] { method_name } [string] { supported_methods }" [EOL] [EOL] self . method_name = method_name [EOL] [EOL] self . _stats_pkg = rpackages . importr ( [string] ) [EOL] self . _r_method = robjects . r [ method_name ] [EOL] [EOL] self . prediction_length = prediction_length [EOL] self . freq = freq [EOL] self . period = period if period is not None else get_seasonality ( freq ) [EOL] self . trunc_length = trunc_length [EOL] [EOL] self . params = { [string] : self . prediction_length , [string] : [ [string] ] , [string] : self . period , } [EOL] if params is not None : [EOL] self . params . update ( params ) [EOL] [EOL] def _unlist ( self , l ) : [EOL] if type ( l ) . __name__ . endswith ( [string] ) : [EOL] return [ self . _unlist ( x ) for x in l ] [EOL] else : [EOL] return l [EOL] [EOL] def _run_r_forecast ( self , d , params , save_info ) : [EOL] buf = [ ] [EOL] [EOL] def save_to_buf ( x ) : [EOL] buf . append ( x ) [EOL] [EOL] def dont_save ( x ) : [EOL] pass [EOL] [EOL] f = save_to_buf if save_info else dont_save [EOL] [EOL] [comment] [EOL] self . _rinterface . set_writeconsole_regular ( f ) [EOL] self . _rinterface . set_writeconsole_warnerror ( f ) [EOL] [EOL] make_ts = self . _stats_pkg . ts [EOL] r_params = self . _robjects . vectors . ListVector ( params ) [EOL] vec = self . _robjects . FloatVector ( d [ [string] ] ) [EOL] ts = make_ts ( vec , frequency = self . period ) [EOL] forecast = self . _r_method ( ts , r_params ) [EOL] forecast_dict = dict ( zip ( forecast . names , map ( self . _unlist , list ( forecast ) ) ) ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] self . _rinterface . set_writeconsole_regular ( self . _rinterface . consolePrint ) [EOL] self . _rinterface . set_writeconsole_warnerror ( self . _rinterface . consolePrint ) [EOL] return forecast_dict , buf [EOL] [EOL] def predict ( self , dataset , num_samples = [number] , save_info = False , ** kwargs , ) : [EOL] for entry in dataset : [EOL] if isinstance ( entry , dict ) : [EOL] data = entry [EOL] else : [EOL] data = entry . data [EOL] if self . trunc_length : [EOL] data = data [ - self . trunc_length : ] [EOL] [EOL] params = self . params . copy ( ) [EOL] params [ [string] ] = num_samples [EOL] [EOL] forecast_dict , console_output = self . _run_r_forecast ( data , params , save_info = save_info ) [EOL] [EOL] samples = np . array ( forecast_dict [ [string] ] ) [EOL] expected_shape = ( params [ [string] ] , self . prediction_length ) [EOL] assert ( samples . shape == expected_shape ) , f" [string] { expected_shape } [string] { samples . shape }" [EOL] info = ( { [string] : [string] . join ( console_output ) } [EOL] if save_info [EOL] else None ) [EOL] yield SampleForecast ( samples , forecast_start ( data ) , self . freq , info = info ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterator[gluonts.model.forecast.SampleForecast]$ 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from . _predictor import RForecastPredictor [EOL] [EOL] __all__ = [ [string] ] [EOL] [EOL] [comment] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional [EOL] import typing [EOL] import builtins [EOL] import numpy [EOL] from typing import List , Optional [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] from pandas . tseries . frequencies import to_offset [EOL] [EOL] [EOL] def _make_lags ( middle , delta ) : [EOL] [docstring] [EOL] return np . arange ( middle - delta , middle + delta + [number] ) . tolist ( ) [EOL] [EOL] [EOL] def get_lags_for_frequency ( freq_str , lag_ub = [number] , num_lags = None ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] def _make_lags_for_minute ( multiple , num_cycles = [number] ) : [EOL] [comment] [EOL] return [ _make_lags ( k * [number] // multiple , [number] ) for k in range ( [number] , num_cycles + [number] ) ] [EOL] [EOL] def _make_lags_for_hour ( multiple , num_cycles = [number] ) : [EOL] [comment] [EOL] return [ _make_lags ( k * [number] // multiple , [number] ) for k in range ( [number] , num_cycles + [number] ) ] [EOL] [EOL] def _make_lags_for_day ( multiple , num_cycles = [number] ) : [EOL] [comment] [EOL] [comment] [EOL] return [ _make_lags ( k * [number] // multiple , [number] ) for k in range ( [number] , num_cycles + [number] ) ] + [ _make_lags ( [number] // multiple , [number] ) ] [EOL] [EOL] def _make_lags_for_week ( multiple , num_cycles = [number] ) : [EOL] [comment] [EOL] [comment] [EOL] return [ _make_lags ( k * [number] // multiple , [number] ) for k in range ( [number] , num_cycles + [number] ) ] + [ [ [number] // multiple , [number] // multiple , [number] // multiple ] ] [EOL] [EOL] def _make_lags_for_month ( multiple , num_cycles = [number] ) : [EOL] [comment] [EOL] return [ _make_lags ( k * [number] // multiple , [number] ) for k in range ( [number] , num_cycles + [number] ) ] [EOL] [EOL] [comment] [EOL] offset = to_offset ( freq_str ) [EOL] [EOL] if offset . name == [string] : [EOL] lags = _make_lags_for_month ( offset . n ) [EOL] elif offset . name == [string] : [EOL] lags = _make_lags_for_week ( offset . n ) [EOL] elif offset . name == [string] : [EOL] lags = _make_lags_for_day ( offset . n ) + _make_lags_for_week ( offset . n / [number] ) [EOL] elif offset . name == [string] : [EOL] [comment] [EOL] lags = [ ] [EOL] elif offset . name == [string] : [EOL] lags = ( _make_lags_for_hour ( offset . n ) + _make_lags_for_day ( offset . n / [number] ) + _make_lags_for_week ( offset . n / ( [number] * [number] ) ) ) [EOL] [comment] [EOL] elif offset . name == [string] : [EOL] lags = ( _make_lags_for_minute ( offset . n ) + _make_lags_for_hour ( offset . n / [number] ) + _make_lags_for_day ( offset . n / ( [number] * [number] ) ) + _make_lags_for_week ( offset . n / ( [number] * [number] * [number] ) ) ) [EOL] else : [EOL] raise Exception ( [string] ) [EOL] [EOL] [comment] [EOL] lags = [ int ( lag ) for sub_list in lags for lag in sub_list if [number] < lag <= lag_ub ] [EOL] lags = [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] + sorted ( list ( set ( lags ) ) ) [EOL] [EOL] return lags [ : num_lags ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from . _base import ( DayOfMonth , DayOfWeek , DayOfYear , HourOfDay , MinuteOfHour , MonthOfYear , TimeFeature , WeekOfYear , time_features_from_frequency_str , ) [EOL] from . holiday import SPECIAL_DATE_FEATURES , SpecialDateFeatureSet [EOL] from . lag import get_lags_for_frequency [EOL] from . seasonality import get_seasonality [EOL] [EOL] __all__ = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , ] [EOL] [EOL] [comment] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Callable , List [EOL] [EOL] import numpy as np [EOL] import pandas as pd [EOL] from pandas . tseries . holiday import ( SU , TH , EasterMonday , GoodFriday , Holiday , USColumbusDay , USLaborDay , USMartinLutherKingJr , USMemorialDay , USPresidentsDay , USThanksgivingDay , ) [EOL] from pandas . tseries . offsets import DateOffset , Day , Easter [EOL] [EOL] [comment] [EOL] [comment] [EOL] MAX_WINDOW = [number] + [number] [EOL] [EOL] [EOL] def distance_to_holiday ( holiday ) : [EOL] def distance_to_day ( index ) : [EOL] holiday_date = holiday . dates ( index - pd . Timedelta ( days = MAX_WINDOW ) , index + pd . Timedelta ( days = MAX_WINDOW ) , ) [EOL] assert ( len ( holiday_date ) != [number] ) , f" [string] { index } [string] " [EOL] [comment] [EOL] [comment] [EOL] return ( index - holiday_date [ [number] ] ) . days [EOL] [EOL] return distance_to_day [EOL] [EOL] [EOL] EasterSunday = Holiday ( [string] , month = [number] , day = [number] , offset = [ Easter ( ) , Day ( [number] ) ] ) [EOL] NewYearsDay = Holiday ( [string] , month = [number] , day = [number] ) [EOL] SuperBowl = Holiday ( [string] , month = [number] , day = [number] , offset = DateOffset ( weekday = SU ( [number] ) ) ) [EOL] MothersDay = Holiday ( [string] , month = [number] , day = [number] , offset = DateOffset ( weekday = SU ( [number] ) ) ) [EOL] IndependenceDay = Holiday ( [string] , month = [number] , day = [number] ) [EOL] ChristmasEve = Holiday ( [string] , month = [number] , day = [number] ) [EOL] ChristmasDay = Holiday ( [string] , month = [number] , day = [number] ) [EOL] NewYearsEve = Holiday ( [string] , month = [number] , day = [number] ) [EOL] BlackFriday = Holiday ( [string] , month = [number] , day = [number] , offset = [ pd . DateOffset ( weekday = TH ( [number] ) ) , Day ( [number] ) ] , ) [EOL] CyberMonday = Holiday ( [string] , month = [number] , day = [number] , offset = [ pd . DateOffset ( weekday = TH ( [number] ) ) , Day ( [number] ) ] , ) [EOL] [EOL] NEW_YEARS_DAY = [string] [EOL] MARTIN_LUTHER_KING_DAY = [string] [EOL] SUPERBOWL = [string] [EOL] PRESIDENTS_DAY = [string] [EOL] GOOD_FRIDAY = [string] [EOL] EASTER_SUNDAY = [string] [EOL] EASTER_MONDAY = [string] [EOL] MOTHERS_DAY = [string] [EOL] INDEPENDENCE_DAY = [string] [EOL] LABOR_DAY = [string] [EOL] MEMORIAL_DAY = [string] [EOL] COLUMBUS_DAY = [string] [EOL] THANKSGIVING = [string] [EOL] CHRISTMAS_EVE = [string] [EOL] CHRISTMAS_DAY = [string] [EOL] NEW_YEARS_EVE = [string] [EOL] BLACK_FRIDAY = [string] [EOL] CYBER_MONDAY = [string] [EOL] [EOL] SPECIAL_DATE_FEATURES = { NEW_YEARS_DAY : distance_to_holiday ( NewYearsDay ) , MARTIN_LUTHER_KING_DAY : distance_to_holiday ( USMartinLutherKingJr ) , SUPERBOWL : distance_to_holiday ( SuperBowl ) , PRESIDENTS_DAY : distance_to_holiday ( USPresidentsDay ) , GOOD_FRIDAY : distance_to_holiday ( GoodFriday ) , EASTER_SUNDAY : distance_to_holiday ( EasterSunday ) , EASTER_MONDAY : distance_to_holiday ( EasterMonday ) , MOTHERS_DAY : distance_to_holiday ( MothersDay ) , INDEPENDENCE_DAY : distance_to_holiday ( IndependenceDay ) , LABOR_DAY : distance_to_holiday ( USLaborDay ) , MEMORIAL_DAY : distance_to_holiday ( USMemorialDay ) , COLUMBUS_DAY : distance_to_holiday ( USColumbusDay ) , THANKSGIVING : distance_to_holiday ( USThanksgivingDay ) , CHRISTMAS_EVE : distance_to_holiday ( ChristmasEve ) , CHRISTMAS_DAY : distance_to_holiday ( ChristmasDay ) , NEW_YEARS_EVE : distance_to_holiday ( NewYearsEve ) , BLACK_FRIDAY : distance_to_holiday ( BlackFriday ) , CYBER_MONDAY : distance_to_holiday ( CyberMonday ) , } [EOL] [EOL] [EOL] [comment] [EOL] def indicator ( distance ) : [EOL] return float ( distance == [number] ) [EOL] [EOL] [EOL] def exponential_kernel ( alpha = [number] , tol = [number] ) : [EOL] def kernel ( distance ) : [EOL] kernel_value = np . exp ( - alpha * np . abs ( distance ) ) [EOL] if kernel_value > tol : [EOL] return kernel_value [EOL] else : [EOL] return [number] [EOL] [EOL] return kernel [EOL] [EOL] [EOL] def squared_exponential_kernel ( alpha = [number] , tol = [number] ) : [EOL] def kernel ( distance ) : [EOL] kernel_value = np . exp ( - alpha * np . abs ( distance ) ** [number] ) [EOL] if kernel_value > tol : [EOL] return kernel_value [EOL] else : [EOL] return [number] [EOL] [EOL] return kernel [EOL] [EOL] [EOL] class SpecialDateFeatureSet : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , feature_names , kernel_function = indicator , ) : [EOL] [docstring] [EOL] self . feature_names = feature_names [EOL] self . num_features = len ( feature_names ) [EOL] self . kernel_function = kernel_function [EOL] [EOL] def __call__ ( self , dates ) : [EOL] [docstring] [EOL] return np . vstack ( [ np . hstack ( [ self . kernel_function ( SPECIAL_DATE_FEATURES [ feat_name ] ( index ) ) for index in dates ] ) for feat_name in self . feature_names ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import List [EOL] import pandas [EOL] import numpy [EOL] import builtins [EOL] import typing [EOL] from typing import List [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] import pandas as pd [EOL] from pandas . tseries import offsets [EOL] from pandas . tseries . frequencies import to_offset [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] [EOL] [EOL] class TimeFeature : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , normalized = True ) : [EOL] self . normalized = normalized [EOL] [EOL] def __call__ ( self , index ) : [EOL] pass [EOL] [EOL] def __repr__ ( self ) : [EOL] return self . __class__ . __name__ + [string] [EOL] [EOL] [EOL] class MinuteOfHour ( TimeFeature ) : [EOL] [docstring] [EOL] [EOL] def __call__ ( self , index ) : [EOL] if self . normalized : [EOL] return index . minute / [number] - [number] [EOL] else : [EOL] return index . minute . map ( float ) [EOL] [EOL] [EOL] class HourOfDay ( TimeFeature ) : [EOL] [docstring] [EOL] [EOL] def __call__ ( self , index ) : [EOL] if self . normalized : [EOL] return index . hour / [number] - [number] [EOL] else : [EOL] return index . hour . map ( float ) [EOL] [EOL] [EOL] class DayOfWeek ( TimeFeature ) : [EOL] [docstring] [EOL] [EOL] def __call__ ( self , index ) : [EOL] if self . normalized : [EOL] return index . dayofweek / [number] - [number] [EOL] else : [EOL] return index . dayofweek . map ( float ) [EOL] [EOL] [EOL] class DayOfMonth ( TimeFeature ) : [EOL] [docstring] [EOL] [EOL] def __call__ ( self , index ) : [EOL] if self . normalized : [EOL] return index . day / [number] - [number] [EOL] else : [EOL] return index . day . map ( float ) [EOL] [EOL] [EOL] class DayOfYear ( TimeFeature ) : [EOL] [docstring] [EOL] [EOL] def __call__ ( self , index ) : [EOL] if self . normalized : [EOL] return index . dayofyear / [number] - [number] [EOL] else : [EOL] return index . dayofyear . map ( float ) [EOL] [EOL] [EOL] class MonthOfYear ( TimeFeature ) : [EOL] [docstring] [EOL] [EOL] def __call__ ( self , index ) : [EOL] if self . normalized : [EOL] return index . month / [number] - [number] [EOL] else : [EOL] return index . month . map ( float ) [EOL] [EOL] [EOL] class WeekOfYear ( TimeFeature ) : [EOL] [docstring] [EOL] [EOL] def __call__ ( self , index ) : [EOL] if self . normalized : [EOL] return index . weekofyear / [number] - [number] [EOL] else : [EOL] return index . weekofyear . map ( float ) [EOL] [EOL] [EOL] def time_features_from_frequency_str ( freq_str ) : [EOL] [docstring] [EOL] [EOL] features_by_offsets = { offsets . YearOffset : [ ] , offsets . MonthOffset : [ MonthOfYear ] , offsets . Week : [ DayOfMonth , WeekOfYear ] , offsets . Day : [ DayOfWeek , DayOfMonth , DayOfYear ] , offsets . BusinessDay : [ DayOfWeek , DayOfMonth , DayOfYear ] , offsets . Hour : [ HourOfDay , DayOfWeek , DayOfMonth , DayOfYear ] , offsets . Minute : [ MinuteOfHour , HourOfDay , DayOfWeek , DayOfMonth , DayOfYear , ] , } [EOL] [EOL] offset = to_offset ( freq_str ) [EOL] [EOL] for offset_type , feature_classes in features_by_offsets . items ( ) : [EOL] if isinstance ( offset , offset_type ) : [EOL] return [ cls ( ) for cls in feature_classes ] [EOL] [EOL] supported_freq_msg = f""" [string] { freq_str } [string] """ [EOL] raise RuntimeError ( supported_freq_msg ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 $pandas.DatetimeIndex$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 $pandas.DatetimeIndex$ 0 0 0 0 0 0 0 0 0 0 $pandas.DatetimeIndex$ 0 0 0 0 0 0 0 0 0 0 0 $pandas.DatetimeIndex$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 $pandas.DatetimeIndex$ 0 0 0 0 0 0 0 0 0 0 $pandas.DatetimeIndex$ 0 0 0 0 0 0 0 0 0 0 0 $pandas.DatetimeIndex$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 $pandas.DatetimeIndex$ 0 0 0 0 0 0 0 0 0 0 $pandas.DatetimeIndex$ 0 0 0 0 0 0 0 0 0 0 0 $pandas.DatetimeIndex$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 $pandas.DatetimeIndex$ 0 0 0 0 0 0 0 0 0 0 $pandas.DatetimeIndex$ 0 0 0 0 0 0 0 0 0 0 0 $pandas.DatetimeIndex$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 $pandas.DatetimeIndex$ 0 0 0 0 0 0 0 0 0 0 $pandas.DatetimeIndex$ 0 0 0 0 0 0 0 0 0 0 0 $pandas.DatetimeIndex$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 $pandas.DatetimeIndex$ 0 0 0 0 0 0 0 0 0 0 $pandas.DatetimeIndex$ 0 0 0 0 0 0 0 0 0 0 0 $pandas.DatetimeIndex$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 $pandas.DatetimeIndex$ 0 0 0 0 0 0 0 0 0 0 $pandas.DatetimeIndex$ 0 0 0 0 0 0 0 0 0 0 0 $pandas.DatetimeIndex$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[TimeFeature]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import builtins [EOL] import logging [EOL] [EOL] import pandas as pd [EOL] [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] DEFAULT_SEASONALITIES = { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] } [EOL] [EOL] [EOL] def get_seasonality ( freq , seasonalities = DEFAULT_SEASONALITIES ) : [EOL] [docstring] [EOL] offset = pd . tseries . frequencies . to_offset ( freq ) [EOL] [EOL] base_seasonality = seasonalities . get ( offset . name , [number] ) [EOL] [EOL] seasonality , remainder = divmod ( base_seasonality , offset . n ) [EOL] if not remainder : [EOL] return seasonality [EOL] [EOL] logger . warning ( f" [string] { offset . n } [string] " f"{ base_seasonality } [string] " ) [EOL] return [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Any , Type , ContextManager , List , Dict , Iterable , Optional [EOL] import typing [EOL] import builtins [EOL] import gluonts [EOL] import json [EOL] import socket [EOL] import tempfile [EOL] import time [EOL] from contextlib import closing , contextmanager [EOL] from multiprocessing import Process [EOL] from pathlib import Path [EOL] from typing import Any , ContextManager , Dict , Iterable , List , Optional , Type [EOL] [EOL] import requests [EOL] [EOL] [comment] [EOL] from gluonts . dataset . common import DataEntry , serialize_data_entry [EOL] from gluonts . dataset . repository . datasets import materialize_dataset [EOL] from gluonts . model . predictor import Predictor [EOL] from gluonts . shell . sagemaker import ServeEnv , ServePaths , TrainEnv , TrainPaths [EOL] from gluonts . shell . sagemaker . params import encode_sagemaker_parameters [EOL] from gluonts . shell . serve import Settings , make_gunicorn_app [EOL] [EOL] [EOL] class ServerFacade : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , base_address ) : [EOL] self . base_address = base_address [EOL] [EOL] def url ( self , path ) : [EOL] return self . base_address + path [EOL] [EOL] def ping ( self ) : [EOL] try : [EOL] response = requests . get ( url = self . url ( [string] ) ) [EOL] return response . status_code == [number] [EOL] except requests . exceptions . ConnectionError : [EOL] return False [EOL] [EOL] def execution_parameters ( self ) : [EOL] response = requests . get ( url = self . url ( [string] ) , headers = { [string] : [string] } , ) [EOL] [EOL] if response . status_code == [number] : [EOL] return response . json ( ) [EOL] elif response . status_code >= [number] : [EOL] raise RuntimeError ( response . content . decode ( [string] ) ) [EOL] else : [EOL] raise RuntimeError ( f" [string] { response . status_code } [string] " ) [EOL] [EOL] def invocations ( self , data_entries , configuration ) : [EOL] instances = list ( map ( serialize_data_entry , data_entries ) ) [EOL] response = requests . post ( url = self . url ( [string] ) , json = { [string] : instances , [string] : configuration } , headers = { [string] : [string] } , ) [EOL] [EOL] if response . status_code == [number] : [EOL] predictions = response . json ( ) [ [string] ] [EOL] assert len ( predictions ) == len ( instances ) [EOL] return predictions [EOL] elif response . status_code >= [number] : [EOL] raise RuntimeError ( response . content . decode ( [string] ) ) [EOL] else : [EOL] raise RuntimeError ( f" [string] { response . status_code } [string] " ) [EOL] [EOL] def batch_invocations ( self , data_entries ) : [EOL] instances = map ( serialize_data_entry , data_entries ) [EOL] instances = list ( map ( json . dumps , instances ) ) [EOL] [EOL] response = requests . post ( url = self . url ( [string] ) , data = [string] . join ( instances ) ) [EOL] [EOL] if response . status_code != [number] : [EOL] raise RuntimeError ( response . content . decode ( [string] ) ) [EOL] [EOL] predictions = list ( map ( json . loads , response . text . splitlines ( ) ) ) [EOL] assert len ( predictions ) == len ( instances ) [EOL] return predictions [EOL] [EOL] [EOL] def free_port ( ) : [EOL] [docstring] [EOL] with closing ( socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) ) as sock : [EOL] sock . bind ( ( [string] , [number] ) ) [EOL] return sock . getsockname ( ) [ [number] ] [EOL] [EOL] [EOL] @ contextmanager def temporary_server ( env , forecaster_type , settings = Settings ( ) , ) : [EOL] [docstring] [EOL] [EOL] gunicorn_app = make_gunicorn_app ( env , forecaster_type , settings ) [EOL] process = Process ( target = gunicorn_app . run ) [EOL] process . start ( ) [EOL] [EOL] endpoint = ServerFacade ( base_address = [string] . format ( address = settings . sagemaker_server_address , port = settings . sagemaker_server_port , ) ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] n , t = [number] , [number] [EOL] max_time = time . time ( ) + n [EOL] while not endpoint . ping ( ) : [EOL] if time . time ( ) < max_time : [EOL] time . sleep ( t ) [EOL] else : [EOL] msg = f" [string] { n } [string] " [EOL] raise TimeoutError ( msg ) [EOL] [EOL] yield endpoint [EOL] [EOL] process . terminate ( ) [EOL] process . join ( ) [EOL] [EOL] [EOL] @ contextmanager def temporary_train_env ( hyperparameters , dataset_name ) : [EOL] [docstring] [EOL] [EOL] with tempfile . TemporaryDirectory ( prefix = [string] ) as base : [EOL] paths = TrainPaths ( base = Path ( base ) ) [EOL] [EOL] [comment] [EOL] with paths . hyperparameters . open ( mode = [string] ) as fp : [EOL] hps_encoded = encode_sagemaker_parameters ( hyperparameters ) [EOL] json . dump ( hps_encoded , fp , indent = [number] , sort_keys = True ) [EOL] [EOL] [comment] [EOL] ds_path = materialize_dataset ( dataset_name ) [EOL] [EOL] path_metadata = paths . data / [string] / [string] [EOL] path_train = paths . data / [string] [EOL] path_test = paths . data / [string] [EOL] [EOL] path_metadata . parent . mkdir ( exist_ok = True ) [EOL] [EOL] path_metadata . symlink_to ( ds_path / [string] ) [EOL] path_train . symlink_to ( ds_path / [string] , target_is_directory = True ) [EOL] path_test . symlink_to ( ds_path / [string] , target_is_directory = True ) [EOL] [EOL] yield TrainEnv ( path = paths ) [EOL] [EOL] [EOL] @ contextmanager def temporary_serve_env ( predictor ) : [EOL] [docstring] [EOL] [EOL] with tempfile . TemporaryDirectory ( prefix = [string] ) as base : [EOL] paths = ServePaths ( base = Path ( base ) ) [EOL] [EOL] [comment] [EOL] predictor . serialize ( paths . model ) [EOL] [EOL] yield ServeEnv ( path = paths . base ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Tuple [EOL] import typing [EOL] import builtins [EOL] import gluonts [EOL] from random import randint [EOL] from typing import List , Tuple [EOL] [EOL] [comment] [EOL] from gluonts . dataset . common import ListDataset [EOL] from gluonts . dataset . field_names import FieldName [EOL] [EOL] [EOL] def make_dummy_datasets_with_features ( num_ts = [number] , start = [string] , freq = [string] , min_length = [number] , max_length = [number] , prediction_length = [number] , cardinality = [ ] , num_feat_dynamic_real = [number] , num_past_feat_dynamic_real = [number] , ) : [EOL] [EOL] data_iter_train = [ ] [EOL] data_iter_test = [ ] [EOL] [EOL] for k in range ( num_ts ) : [EOL] ts_length = randint ( min_length , max_length ) [EOL] data_entry_train = { FieldName . START : start , FieldName . TARGET : [ [number] ] * ts_length , } [EOL] if len ( cardinality ) > [number] : [EOL] data_entry_train [ FieldName . FEAT_STATIC_CAT ] = [ randint ( [number] , c ) for c in cardinality ] [EOL] if num_past_feat_dynamic_real > [number] : [EOL] data_entry_train [ FieldName . PAST_FEAT_DYNAMIC_REAL ] = [ [ float ( [number] + k ) ] * ts_length for k in range ( num_past_feat_dynamic_real ) ] [EOL] [comment] [EOL] [comment] [EOL] data_entry_test = data_entry_train . copy ( ) [EOL] if num_feat_dynamic_real > [number] : [EOL] data_entry_train [ FieldName . FEAT_DYNAMIC_REAL ] = [ [ float ( [number] + k ) ] * ts_length for k in range ( num_feat_dynamic_real ) ] [EOL] data_entry_test [ FieldName . FEAT_DYNAMIC_REAL ] = [ [ float ( [number] + k ) ] * ( ts_length + prediction_length ) for k in range ( num_feat_dynamic_real ) ] [EOL] data_iter_train . append ( data_entry_train ) [EOL] data_iter_test . append ( data_entry_test ) [EOL] [EOL] return ( ListDataset ( data_iter = data_iter_train , freq = freq ) , ListDataset ( data_iter = data_iter_test , freq = freq ) , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.dataset.common.ListDataset,gluonts.dataset.common.ListDataset]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Tuple [EOL] import typing [EOL] import builtins [EOL] import numpy [EOL] import shutil [EOL] import tempfile [EOL] from contextlib import contextmanager [EOL] from typing import Tuple [EOL] [EOL] import numpy as np [EOL] [EOL] [EOL] @ contextmanager def TemporaryDirectory ( ) : [EOL] name = tempfile . mkdtemp ( ) [EOL] try : [EOL] yield name [EOL] finally : [EOL] shutil . rmtree ( name ) [EOL] [EOL] [EOL] def chunks ( l , n ) : [EOL] [docstring] [EOL] for i in range ( [number] , len ( l ) , n ) : [EOL] yield l [ i : i + n ] [EOL] [EOL] [EOL] def empirical_cdf ( samples , num_bins = [number] ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] cdfs = [ ] [EOL] edges = [ ] [EOL] [EOL] batch_shape = samples . shape [ [number] : ] [EOL] agg_batch_dim = np . prod ( batch_shape ) [EOL] [EOL] samples = samples . reshape ( ( samples . shape [ [number] ] , - [number] ) ) [EOL] [EOL] for i in range ( agg_batch_dim ) : [EOL] s = samples [ : , i ] [EOL] bins = np . linspace ( s . min ( ) , s . max ( ) , num_bins + [number] ) [EOL] hist , edge = np . histogram ( s , bins = bins ) [EOL] cdfs . append ( np . cumsum ( hist / len ( s ) ) ) [EOL] edges . append ( edge ) [EOL] [EOL] empirical_cdf = np . stack ( cdfs , axis = - [number] ) . reshape ( num_bins , * batch_shape ) [EOL] edges = np . stack ( edges , axis = - [number] ) . reshape ( num_bins + [number] , * batch_shape ) [EOL] return empirical_cdf , edges [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Optional [EOL] import typing [EOL] import builtins [EOL] import gluonts [EOL] import mxnet [EOL] from typing import Optional [EOL] [EOL] [comment] [EOL] import mxnet as mx [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from gluonts . core . component import DType [EOL] from gluonts . model . common import Tensor [EOL] [EOL] [EOL] def batch_diagonal ( F , matrix , num_data_points = None , ctx = mx . cpu ( ) , float_type = np . float32 , ) : [EOL] [docstring] [EOL] return F . linalg . gemm2 ( F . broadcast_mul ( F . eye ( num_data_points , ctx = ctx , dtype = float_type ) , matrix ) , F . ones_like ( F . slice_axis ( matrix , axis = [number] , begin = [number] , end = [number] ) ) , ) [EOL] [EOL] [EOL] def lower_triangular_ones ( F , d , offset = [number] ) : [EOL] [docstring] [EOL] mask = F . zeros_like ( F . eye ( d ) ) [EOL] for k in range ( offset , d ) : [EOL] mask = mask + F . eye ( d , d , - k ) [EOL] return mask [EOL] [EOL] [EOL] [comment] [EOL] def jitter_cholesky_eig ( F , matrix , num_data_points = None , ctx = mx . Context ( [string] ) , float_type = np . float64 , diag_weight = [number] , ) : [EOL] [docstring] [EOL] diag = batch_diagonal ( F , matrix , num_data_points , ctx , float_type ) [comment] [EOL] diag_mean = diag . mean ( axis = [number] ) . expand_dims ( axis = [number] ) [comment] [EOL] U , Lambda = F . linalg . syevd ( matrix ) [EOL] jitter = F . broadcast_mul ( diag_mean , F . ones_like ( diag ) ) * diag_weight [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] return F . linalg . potrf ( F . linalg . gemm2 ( U , F . linalg . gemm2 ( F . broadcast_mul ( F . eye ( num_data_points , ctx = ctx , dtype = float_type ) , F . maximum ( jitter , Lambda . expand_dims ( axis = [number] ) ) , ) , U , ) , transpose_a = True , ) ) [EOL] [EOL] [EOL] [comment] [EOL] def jitter_cholesky ( F , matrix , num_data_points = None , ctx = mx . Context ( [string] ) , float_type = np . float64 , max_iter_jitter = [number] , neg_tol = - [number] , diag_weight = [number] , increase_jitter = [number] , ) : [EOL] [docstring] [EOL] num_iter = [number] [EOL] diag = batch_diagonal ( F , matrix , num_data_points , ctx , float_type ) [comment] [EOL] diag_mean = diag . mean ( axis = [number] ) . expand_dims ( axis = [number] ) [comment] [EOL] jitter = F . zeros_like ( diag ) [comment] [EOL] [comment] [EOL] [comment] [EOL] if F . sum ( diag <= neg_tol ) > [number] : [EOL] raise mx . base . MXNetError ( [string] ) [EOL] while num_iter <= max_iter_jitter : [EOL] try : [EOL] L = F . linalg . potrf ( F . broadcast_add ( matrix , F . broadcast_mul ( F . eye ( num_data_points , ctx = ctx , dtype = float_type ) , jitter , ) , ) ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] assert F . abs ( L . nansum ( ) - L . sum ( ) ) <= [number] [EOL] return L [EOL] except : [EOL] if num_iter == [number] : [EOL] [comment] [EOL] jitter = ( F . broadcast_mul ( diag_mean , F . ones_like ( jitter ) ) * diag_weight ) [EOL] else : [EOL] jitter = jitter * increase_jitter [EOL] finally : [EOL] num_iter += [number] [EOL] raise mx . base . MXNetError ( f" [string] { max_iter_jitter } [string] " f" [string] { F . max ( jitter ) }" ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [EOL] from pkgutil import extend_path [EOL] [EOL] __path__ = extend_path ( __path__ , __name__ ) [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] import pandas [EOL] import builtins [EOL] import pandas as pd [EOL] [EOL] [EOL] def frequency_add ( ts , amount ) : [EOL] return ts + ts . freq * amount [EOL] [EOL] [EOL] def forecast_start ( entry ) : [EOL] return frequency_add ( entry [ [string] ] , len ( entry [ [string] ] ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.Timestamp$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [EOL] from pkgutil import extend_path [EOL] [EOL] __path__ = extend_path ( __path__ , __name__ ) [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] import re [EOL] from datetime import datetime [EOL] [EOL] [EOL] def make_metrics ( metrics_names ) : [EOL] avg_epoch_loss_metric = { [string] : [string] , [string] : [string] , } [EOL] final_loss_metric = { [string] : [string] , [string] : [string] } [EOL] other_metrics = [ { [string] : metric , [string] : rf" [string] { re . escape ( metric ) } [string] " , } for metric in metrics_names ] [EOL] [EOL] return [ avg_epoch_loss_metric , final_loss_metric ] + other_metrics [EOL] [EOL] [EOL] def make_job_name ( base_job_name ) : [EOL] now = datetime . utcnow ( ) . strftime ( [string] ) [EOL] return f"{ base_job_name } [string] { now }" [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from pathlib import Path [EOL] [EOL] [comment] [EOL] [comment] [EOL] GLUONTS_VERSION = [string] [EOL] [EOL] [comment] [EOL] FRAMEWORK_NAME = [string] [EOL] LOWEST_MMS_VERSION = [string] [EOL] LOWEST_SCRIPT_MODE_VERSION = [string] , [string] , [string] [EOL] LATEST_GLUONTS_VERSION = [string] [EOL] PYTHON_VERSION = [string] [EOL] [EOL] [comment] [EOL] ENTRY_POINTS_FOLDER = Path ( __file__ ) . parent . resolve ( ) / [string] [EOL] TRAIN_SCRIPT = [string] [EOL] MONITORED_METRICS = [string] , [string] , [string] [EOL] NUM_SAMPLES = [number] [EOL] QUANTILES = [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] [comment] [EOL] from . estimator import GluonTSFramework [EOL] from . model import GluonTSModel , GluonTSPredictor [EOL] [EOL] __all__ = [ [string] , [string] , [string] ] [EOL] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] [comment] [EOL] from typing import Dict [EOL] import typing [EOL] import builtins [EOL] import sagemaker [EOL] import logging [EOL] from typing import Dict [EOL] [EOL] [comment] [EOL] import sagemaker [EOL] from pkg_resources import parse_version [EOL] from sagemaker import session [EOL] from sagemaker . fw_utils import model_code_key_prefix [EOL] from sagemaker . model import MODEL_SERVER_WORKERS_PARAM_NAME , FrameworkModel [EOL] from sagemaker . predictor import ( RealTimePredictor , json_deserializer , json_serializer , ) [EOL] [EOL] [comment] [EOL] from . defaults import FRAMEWORK_NAME , GLUONTS_VERSION , LOWEST_MMS_VERSION [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class GluonTSPredictor ( RealTimePredictor ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , endpoint_name , sagemaker_session = None ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] super ( GluonTSPredictor , self ) . __init__ ( endpoint_name , sagemaker_session , json_serializer , json_deserializer , ) [EOL] [EOL] [EOL] class GluonTSModel ( FrameworkModel ) : [EOL] [docstring] [EOL] [EOL] __framework_name__ = FRAMEWORK_NAME [EOL] _LOWEST_MMS_VERSION = LOWEST_MMS_VERSION [EOL] [EOL] def __init__ ( self , model_data , role , entry_point , image = None , framework_version = GLUONTS_VERSION , predictor_cls = GluonTSPredictor , model_server_workers = None , ** kwargs , ) : [EOL] [docstring] [EOL] [EOL] super ( GluonTSModel , self ) . __init__ ( model_data , image , role , entry_point , predictor_cls = predictor_cls , ** kwargs , ) [EOL] [EOL] self . framework_version = framework_version [EOL] self . model_server_workers = model_server_workers [EOL] [EOL] def prepare_container_def ( self , instance_type , accelerator_type = None ) : [EOL] [docstring] [EOL] [EOL] is_mms_version = parse_version ( self . framework_version ) >= parse_version ( self . _LOWEST_MMS_VERSION ) [EOL] [EOL] deploy_image = self . image [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] logger . info ( f" [string] { deploy_image }" ) [EOL] [EOL] deploy_key_prefix = model_code_key_prefix ( self . key_prefix , self . name , deploy_image ) [EOL] self . _upload_code ( deploy_key_prefix , is_mms_version ) [EOL] deploy_env = dict ( self . env ) [EOL] deploy_env . update ( self . _framework_env_vars ( ) ) [EOL] [EOL] if self . model_server_workers : [EOL] deploy_env [ MODEL_SERVER_WORKERS_PARAM_NAME . upper ( ) ] = str ( self . model_server_workers ) [EOL] return sagemaker . container_def ( deploy_image , self . repacked_model_data or self . model_data , deploy_env , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $sagemaker.session.Session$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $sagemaker.session.Session$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] [comment] [EOL] import argparse [EOL] import json [EOL] import logging [EOL] import os [EOL] [EOL] logging . basicConfig ( level = logging . INFO , format = [string] , datefmt = [string] , ) [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def run ( arguments ) : [EOL] logger . info ( [string] ) [EOL] [EOL] [comment] [EOL] [EOL] return [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( ) [EOL] [EOL] [comment] [EOL] parser . add_argument ( [string] , type = json . loads , default = os . environ [ [string] ] ) [EOL] [EOL] [comment] [EOL] parser . add_argument ( [string] , type = str , default = os . environ [ [string] ] ) [EOL] [comment] [EOL] parser . add_argument ( [string] , type = str , default = os . environ [ [string] ] ) [EOL] [comment] [EOL] parser . add_argument ( [string] , type = str , default = os . environ [ [string] ] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] args , _ = parser . parse_known_args ( ) [EOL] [EOL] run ( args ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] import argparse [EOL] import json [EOL] import logging [EOL] import os [EOL] [EOL] [comment] [EOL] from pathlib import Path [EOL] [EOL] [comment] [EOL] from gluonts . core import serde [EOL] from gluonts . dataset import common [EOL] from gluonts . dataset . repository import datasets [EOL] from gluonts . evaluation import Evaluator , backtest [EOL] [EOL] [comment] [EOL] [EOL] [EOL] logging . basicConfig ( level = logging . INFO , format = [string] , datefmt = [string] , ) [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] def train ( arguments ) : [EOL] [docstring] [EOL] [EOL] logger . info ( [string] ) [EOL] estimator_config = Path ( arguments . estimator ) / [string] [EOL] with estimator_config . open ( ) as config_file : [EOL] estimator = serde . load_json ( config_file . read ( ) ) [EOL] [EOL] logger . info ( [string] ) [EOL] if arguments . s3_dataset is None : [EOL] [comment] [EOL] dataset = datasets . get_dataset ( arguments . dataset ) [EOL] else : [EOL] [comment] [EOL] s3_dataset_dir = Path ( arguments . s3_dataset ) [EOL] dataset = common . load_datasets ( metadata = s3_dataset_dir , train = s3_dataset_dir / [string] , test = s3_dataset_dir / [string] , ) [EOL] [EOL] logger . info ( [string] ) [EOL] predictor = estimator . train ( dataset . train ) [EOL] forecast_it , ts_it = backtest . make_evaluation_predictions ( dataset = dataset . test , predictor = predictor , num_samples = int ( arguments . num_samples ) , ) [EOL] [EOL] logger . info ( [string] ) [EOL] evaluator = Evaluator ( quantiles = eval ( arguments . quantiles ) ) [EOL] [EOL] agg_metrics , item_metrics = evaluator ( ts_it , forecast_it , num_series = len ( list ( dataset . test ) ) ) [EOL] [EOL] [comment] [EOL] for name , value in agg_metrics . items ( ) : [EOL] logger . info ( f" [string] { name } [string] { value }" ) [EOL] [EOL] [comment] [EOL] metrics_output_dir = Path ( arguments . output_data_dir ) [EOL] with open ( metrics_output_dir / [string] , [string] ) as f : [EOL] json . dump ( agg_metrics , f ) [EOL] with open ( metrics_output_dir / [string] , [string] ) as f : [EOL] item_metrics . to_csv ( f , index = False ) [EOL] [EOL] [comment] [EOL] model_output_dir = Path ( arguments . model_dir ) [EOL] predictor . serialize ( model_output_dir ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] [comment] [EOL] parser = argparse . ArgumentParser ( ) [EOL] [EOL] [comment] [EOL] parser . add_argument ( [string] , type = json . loads , default = os . environ [ [string] ] ) [EOL] [EOL] [comment] [EOL] parser . add_argument ( [string] , type = str , default = os . environ [ [string] ] ) [EOL] parser . add_argument ( [string] , type = str , default = os . environ [ [string] ] ) [EOL] [EOL] parser . add_argument ( [string] , type = str , default = os . environ [ [string] ] ) [EOL] [EOL] parser . add_argument ( [string] , type = str , default = os . environ [ [string] ] ) [EOL] [comment] [EOL] parser . add_argument ( [string] , type = str , default = os . environ . get ( [string] ) , ) [EOL] parser . add_argument ( [string] , type = str , default = os . environ [ [string] ] ) [EOL] parser . add_argument ( [string] , type = int , default = os . environ [ [string] ] ) [EOL] parser . add_argument ( [string] , type = str , default = os . environ [ [string] ] ) [EOL] [EOL] args , _ = parser . parse_known_args ( ) [EOL] [EOL] train ( args ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from . _base import fqname_for [EOL] [EOL] __all__ = [ [string] ] [EOL] [EOL] [comment] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] import builtins [EOL] def fqname_for ( cls ) : [EOL] [docstring] [EOL] return f"{ cls . __module__ } [string] { cls . __qualname__ }" [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Callable [EOL] import typing [EOL] import builtins [EOL] import functools [EOL] from typing import Callable [EOL] [EOL] [comment] [EOL] from pydantic . error_wrappers import ValidationError , display_errors [EOL] [EOL] [EOL] class GluonTSException ( Exception ) : [EOL] [docstring] [EOL] [EOL] pass [EOL] [EOL] [EOL] class GluonTSFatalError ( GluonTSException ) : [EOL] [docstring] [EOL] [EOL] pass [EOL] [EOL] [EOL] class GluonTSForecasterNotFoundError ( GluonTSException ) : [EOL] [docstring] [EOL] [EOL] pass [EOL] [EOL] [EOL] class GluonTSHyperparameterParseError ( GluonTSException ) : [EOL] [docstring] [EOL] [EOL] __cause__ = ... [EOL] [EOL] def __init__ ( self , key , value , type ) : [EOL] self . key = key [EOL] self . value = value [EOL] self . type = type [EOL] [EOL] def __str__ ( self , * args , ** kwargs ) : [EOL] return ( f' [string] { self . value } [string] ' f" [string] { self . key } [string] { self . type } [string] " f"{ repr ( self . __cause__ ) }" ) [EOL] [EOL] [EOL] class GluonTSHyperparametersError ( GluonTSException ) : [EOL] [docstring] [EOL] [EOL] __cause__ = ... [EOL] [EOL] def __str__ ( self , * args , ** kwargs ) : [EOL] return ( f" [string] " f" [string] " f"{ display_errors ( self . __cause__ . errors ( ) ) }" ) [EOL] [EOL] [EOL] class GluonTSDataError ( GluonTSException ) : [EOL] [docstring] [EOL] [EOL] pass [EOL] [EOL] [EOL] class GluonTSInvalidRequestException ( GluonTSException ) : [EOL] [docstring] [EOL] [EOL] pass [EOL] [EOL] [EOL] class GluonTSUserError ( GluonTSException ) : [EOL] [docstring] [EOL] [EOL] pass [EOL] [EOL] [EOL] class GluonTSDateBoundsError ( GluonTSException ) : [EOL] [docstring] [EOL] [EOL] pass [EOL] [EOL] [EOL] def assert_gluonts ( exception_class , condition , message , * args , ** kwargs ) : [EOL] [docstring] [EOL] if not condition : [EOL] raise exception_class ( message . format ( * args , ** kwargs ) ) [EOL] [EOL] [EOL] def assert_data_error ( condition , message , * args , ** kwargs ) : [EOL] [docstring] [EOL] assert_gluonts ( GluonTSDataError , condition , message , * args , ** kwargs ) [EOL] [EOL] [EOL] def reraise_error ( origin_class , message = None , target_class = GluonTSUserError , ) : [EOL] [docstring] [EOL] [EOL] def decorator ( fn ) : [EOL] @ functools . wraps ( fn ) def inner ( * args , ** kwargs ) : [EOL] try : [EOL] return fn ( * args , ** kwargs ) [EOL] except origin_class as error : [EOL] import traceback [EOL] [EOL] traceback . print_exc ( ) [EOL] error_message = message or getattr ( error , [string] , None ) [EOL] if error_message is None : [EOL] raise target_class ( message = error ) [EOL] else : [EOL] raise target_class ( message = error_message , caused_by = error ) [EOL] [EOL] return inner [EOL] [EOL] return decorator [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.ValueError$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pydantic.error_wrappers.ValidationError$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Callable$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Any , Optional [EOL] import pandas [EOL] import numpy [EOL] import pathlib [EOL] import pydantic [EOL] import typing [EOL] import builtins [EOL] import importlib [EOL] import itertools [EOL] import json [EOL] import math [EOL] import pickle [EOL] import re [EOL] import textwrap [EOL] from functools import singledispatch [EOL] from pathlib import PurePath [EOL] from pydoc import locate [EOL] from typing import Any , NamedTuple , Optional , cast [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] import pandas as pd [EOL] from pydantic import BaseModel [EOL] [EOL] [comment] [EOL] from gluonts . core import fqname_for [EOL] [EOL] bad_type_msg = textwrap . dedent ( [string] ) . lstrip ( ) [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] def dump_binary ( o ) : [EOL] [docstring] [EOL] return pickle . dumps ( o ) [EOL] [EOL] [EOL] def load_binary ( b ) : [EOL] [docstring] [EOL] return pickle . loads ( b ) [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] def dump_json ( o , indent = None ) : [EOL] [docstring] [EOL] return json . dumps ( encode ( o ) , indent = indent , sort_keys = True ) [EOL] [EOL] [EOL] def load_json ( s ) : [EOL] [docstring] [EOL] return decode ( json . loads ( s ) ) [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] def dump_code ( o ) : [EOL] [docstring] [EOL] [EOL] def _dump_code ( x ) : [EOL] [comment] [EOL] [comment] [EOL] if type ( x ) == dict and x . get ( [string] ) == kind_inst : [EOL] args = x . get ( [string] , [ ] ) [EOL] kwargs = x . get ( [string] , { } ) [EOL] [EOL] fqname = x [ [string] ] [EOL] bindings = [string] . join ( itertools . chain ( map ( _dump_code , args ) , [ f"{ k } [string] { _dump_code ( v ) }" for k , v in kwargs . items ( ) ] , ) ) [EOL] return f"{ fqname } [string] { bindings } [string] " [EOL] [EOL] if type ( x ) == dict and x . get ( [string] ) == kind_type : [EOL] return x [ [string] ] [EOL] [EOL] if isinstance ( x , dict ) : [EOL] inner = [string] . join ( f"{ _dump_code ( k ) } [string] { _dump_code ( v ) }" for k , v in x . items ( ) ) [EOL] return f" [string] { inner } [string] " [EOL] [EOL] if isinstance ( x , list ) : [EOL] inner = [string] . join ( list ( map ( dump_code , x ) ) ) [EOL] return f" [string] { inner } [string] " [EOL] [EOL] if isinstance ( x , tuple ) : [EOL] inner = [string] . join ( list ( map ( dump_code , x ) ) ) [EOL] [comment] [EOL] if len ( x ) == [number] : [EOL] inner += [string] [EOL] return f" [string] { inner } [string] " [EOL] [EOL] if isinstance ( x , str ) : [EOL] [comment] [EOL] return json . dumps ( x ) [EOL] [EOL] if isinstance ( x , float ) or np . issubdtype ( type ( x ) , np . inexact ) : [EOL] if math . isfinite ( x ) : [EOL] return str ( x ) [EOL] else : [EOL] [comment] [EOL] return [string] [EOL] [EOL] if isinstance ( x , int ) or np . issubdtype ( type ( x ) , np . integer ) : [EOL] return str ( x ) [EOL] [EOL] if x is None : [EOL] return str ( x ) [EOL] [EOL] raise RuntimeError ( f" [string] { fqname_for ( x . __class__ ) }" ) [EOL] [EOL] return _dump_code ( encode ( o ) ) [EOL] [EOL] [EOL] def load_code ( c ) : [EOL] [docstring] [EOL] [EOL] def _load_code ( code , modules = None ) : [EOL] if modules is None : [EOL] modules = { } [EOL] try : [EOL] return eval ( code , modules ) [EOL] except NameError as e : [EOL] m = re . match ( [string] , str ( e ) ) [EOL] if m : [EOL] name = m [ [string] ] [EOL] return _load_code ( code , { ** ( modules or { } ) , name : importlib . import_module ( name ) } , ) [EOL] else : [EOL] raise e [EOL] except AttributeError as e : [EOL] m = re . match ( [string] , str ( e ) , ) [EOL] if m : [EOL] module , package = m [ [string] ] , m [ [string] ] [EOL] name = f"{ module } [string] { package }" [EOL] return _load_code ( code , { ** ( modules or { } ) , name : importlib . import_module ( name ) } , ) [EOL] else : [EOL] raise e [EOL] except Exception as e : [EOL] raise e [EOL] [EOL] return _load_code ( c ) [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] kind_type = [string] [EOL] kind_inst = [string] [EOL] [EOL] [EOL] @ singledispatch def encode ( v ) : [EOL] [docstring] [EOL] if isinstance ( v , type ( None ) ) : [EOL] return None [EOL] [EOL] if isinstance ( v , ( float , int , str ) ) : [EOL] return v [EOL] [EOL] if np . issubdtype ( type ( v ) , np . inexact ) : [EOL] return float ( v ) [EOL] [EOL] if np . issubdtype ( type ( v ) , np . integer ) : [EOL] return int ( v ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] if isinstance ( v , tuple ) and hasattr ( v , [string] ) : [EOL] v = cast ( NamedTuple , v ) [EOL] return { [string] : kind_inst , [string] : fqname_for ( v . __class__ ) , [string] : encode ( v . _asdict ( ) ) , } [EOL] [EOL] if isinstance ( v , ( list , set , tuple ) ) : [EOL] return list ( map ( encode , v ) ) [EOL] [EOL] if isinstance ( v , dict ) : [EOL] return { k : encode ( v ) for k , v in v . items ( ) } [EOL] [EOL] if isinstance ( v , type ) : [EOL] return { [string] : kind_type , [string] : fqname_for ( v ) } [EOL] [EOL] if hasattr ( v , [string] ) : [EOL] args , kwargs = v . __getnewargs_ex__ ( ) [comment] [EOL] return { [string] : kind_inst , [string] : fqname_for ( v . __class__ ) , [string] : encode ( args ) , [string] : encode ( kwargs ) , } [EOL] [EOL] raise RuntimeError ( bad_type_msg . format ( fqname_for ( v . __class__ ) ) ) [EOL] [EOL] [EOL] @ encode . register ( PurePath ) def encode_path ( v ) : [EOL] [docstring] [EOL] return { [string] : kind_inst , [string] : fqname_for ( v . __class__ ) , [string] : encode ( [ str ( v ) ] ) , } [EOL] [EOL] [EOL] @ encode . register ( BaseModel ) def encode_pydantic_model ( v ) : [EOL] [docstring] [EOL] return { [string] : kind_inst , [string] : fqname_for ( v . __class__ ) , [string] : encode ( v . __dict__ ) , } [EOL] [EOL] [EOL] @ encode . register ( np . ndarray ) def encode_np_ndarray ( v ) : [EOL] [docstring] [EOL] return { [string] : kind_inst , [string] : [string] , [string] : encode ( [ v . tolist ( ) , v . dtype ] ) , } [EOL] [EOL] [EOL] @ encode . register ( pd . Timestamp ) def encode_pd_timestamp ( v ) : [EOL] [docstring] [EOL] return { [string] : kind_inst , [string] : [string] , [string] : encode ( [ str ( v ) ] ) , [string] : { [string] : v . freqstr if v . freq else None } , } [EOL] [EOL] [EOL] @ encode . register ( np . dtype ) def encode_np_dtype ( v ) : [EOL] [docstring] [EOL] return { [string] : kind_inst , [string] : fqname_for ( v . __class__ ) , [string] : encode ( [ v . name ] ) , } [EOL] [EOL] [EOL] def decode ( r ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] if type ( r ) == dict and r . get ( [string] ) == kind_inst : [EOL] cls = cast ( Any , locate ( r [ [string] ] ) ) [EOL] args = decode ( r [ [string] ] ) if [string] in r else [ ] [EOL] kwargs = decode ( r [ [string] ] ) if [string] in r else { } [EOL] return cls ( * args , ** kwargs ) [EOL] [comment] [EOL] [comment] [EOL] if type ( r ) == dict and r . get ( [string] ) == kind_type : [EOL] return locate ( r [ [string] ] ) [EOL] [comment] [EOL] elif type ( r ) == dict : [EOL] return { k : decode ( v ) for k , v in r . items ( ) } [EOL] [comment] [EOL] elif type ( r ) == tuple : [EOL] return tuple ( [ decode ( y ) for y in r ] ) [EOL] [comment] [EOL] elif type ( r ) == list : [EOL] return [ decode ( y ) for y in r ] [EOL] [comment] [EOL] elif type ( r ) == set : [EOL] return { decode ( y ) for y in r } [EOL] [comment] [EOL] else : [EOL] return r [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bytes$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , Union , Optional , Match [EOL] import logging [EOL] import typing [EOL] import builtins [EOL] import mxnet [EOL] import functools [EOL] import logging [EOL] import re [EOL] from typing import Union [EOL] [EOL] import mxnet as mx [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class MXContext : [EOL] [docstring] [EOL] [EOL] @ classmethod def validate ( cls , v ) : [EOL] if isinstance ( v , mx . Context ) : [EOL] return v [EOL] [EOL] m = re . search ( [string] , v ) [EOL] [EOL] if m : [EOL] return mx . Context ( m [ [string] ] , int ( m [ [string] ] or [number] ) ) [EOL] else : [EOL] raise ValueError ( f" [string] { v } [string] " f" [string] " ) [EOL] [EOL] @ classmethod def __get_validators__ ( cls ) : [EOL] yield cls . validate [EOL] [EOL] [EOL] mx . Context . validate = MXContext . validate [EOL] mx . Context . __get_validators__ = MXContext . __get_validators__ [EOL] [EOL] [EOL] NUM_GPUS = None [EOL] [EOL] [EOL] def num_gpus ( refresh = False ) : [EOL] global NUM_GPUS [EOL] if NUM_GPUS is None or refresh : [EOL] n = [number] [EOL] try : [EOL] n = mx . context . num_gpus ( ) [EOL] except mx . base . MXNetError as e : [EOL] logger . error ( f" [string] { e }" ) [EOL] NUM_GPUS = n [EOL] return NUM_GPUS [EOL] [EOL] [EOL] @ functools . lru_cache ( ) def get_mxnet_context ( gpu_number = [number] ) : [EOL] [docstring] [EOL] if num_gpus ( ) : [EOL] logger . info ( [string] ) [EOL] return mx . context . gpu ( gpu_number ) [EOL] else : [EOL] logger . info ( [string] ) [EOL] return mx . context . cpu ( ) [EOL] [EOL] [EOL] def check_gpu_support ( ) : [EOL] [docstring] [EOL] n = num_gpus ( ) [EOL] logger . info ( f' [string] { [string] if n > [number] else [string] }' ) [EOL] return n != [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.Context$ 0 0 0 $typing.Union[builtins.str,mxnet.Context]$ 0 0 0 0 0 0 $typing.Union[builtins.str,mxnet.Context]$ 0 0 0 0 0 0 0 0 $typing.Union[builtins.str,mxnet.Context]$ 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 $typing.Union[builtins.str,mxnet.Context]$ 0 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Union[builtins.str,mxnet.Context]$ 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.Context$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 $mxnet.Context$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import typing [EOL] import mxnet [EOL] from typing import Any [EOL] [EOL] import mxnet as mx [EOL] [EOL] from gluonts . core import fqname_for [EOL] from gluonts . core . serde import encode , kind_inst [EOL] [EOL] [EOL] @ encode . register ( mx . Context ) def encode_mx_context ( v ) : [EOL] [docstring] [EOL] return { [string] : kind_inst , [string] : fqname_for ( v . __class__ ) , [string] : encode ( [ v . device_type , v . device_id ] ) , } [EOL] [EOL] [EOL] @ encode . register ( mx . nd . NDArray ) def encode_mx_ndarray ( v ) : [EOL] return { [string] : kind_inst , [string] : [string] , [string] : encode ( [ v . asnumpy ( ) . tolist ( ) ] ) , [string] : { [string] : encode ( v . dtype ) } , } [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import List , Any [EOL] import typing [EOL] from . serde import * [EOL] [EOL] __all__ = [ ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [EOL] from typing import Iterable [EOL] import typing [EOL] from pkgutil import extend_path [EOL] [EOL] __path__ = extend_path ( __path__ , __name__ ) [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterable[builtins.str]$ 0 0 0 $typing.Iterable[builtins.str]$ 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional , Tuple [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] from typing import List , Optional , Tuple [EOL] [EOL] from mxnet . gluon import nn [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] [EOL] from . representation import Representation [EOL] [EOL] [comment] [EOL] [EOL] [EOL] class DiscretePIT ( Representation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , num_bins , mlp_transf = False , embedding_size = None , * args , ** kwargs , ) : [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] [EOL] self . num_bins = num_bins [EOL] self . mlp_transf = mlp_transf [EOL] [EOL] if embedding_size is None : [EOL] self . embedding_size = round ( self . num_bins ** ( [number] / [number] ) ) [EOL] else : [EOL] self . embedding_size = embedding_size [EOL] [EOL] if mlp_transf : [EOL] self . mlp = nn . HybridSequential ( ) [EOL] self . mlp . add ( nn . Dense ( units = self . num_bins , activation = [string] , flatten = False ) ) [EOL] self . mlp . add ( nn . Dense ( units = self . embedding_size , flatten = False ) ) [EOL] else : [EOL] self . mlp = None [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , data , observed_indicator , scale , rep_params , ** kwargs , ) : [EOL] data = data / self . num_bins [EOL] if self . mlp_transf : [EOL] data = F . expand_dims ( data , axis = - [number] ) [EOL] data = self . mlp ( data ) [EOL] return data , scale , rep_params [EOL] [EOL] def post_transform ( self , F , samples , scale , rep_params ) : [EOL] samples = samples * F . full ( [number] , self . num_bins ) [EOL] samples = F . Custom ( samples , F . arange ( self . num_bins ) , op_type = [string] ) [EOL] return samples [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor,typing.List[gluonts.model.common.Tensor]]$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import List , Optional , Tuple [EOL] import gluonts [EOL] import numpy [EOL] import typing [EOL] import mxnet [EOL] from typing import List , Optional , Tuple [EOL] [EOL] import mxnet as mx [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . dataset . common import Dataset [EOL] from gluonts . model . common import Tensor [EOL] from gluonts . mx . context import get_mxnet_context [EOL] [EOL] from . representation import Representation [EOL] [EOL] [EOL] class RepresentationChain ( Representation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , chain , * args , ** kwargs ) : [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] self . chain = chain [EOL] for representation in self . chain : [EOL] self . register_child ( representation ) [EOL] [EOL] def initialize_from_dataset ( self , input_dataset , ctx = get_mxnet_context ( ) ) : [EOL] for representation in self . chain : [EOL] representation . initialize_from_dataset ( input_dataset , ctx ) [EOL] [EOL] def initialize_from_array ( self , input_array , ctx = get_mxnet_context ( ) ) : [EOL] for representation in self . chain : [EOL] representation . initialize_from_array ( input_array , ctx ) [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , data , observed_indicator , scale , rep_params , ** kwargs , ) : [EOL] for representation in self . chain : [EOL] data , scale , rep_params = representation ( data , observed_indicator , scale , rep_params , ) [EOL] return data , scale , rep_params [EOL] [EOL] def post_transform ( self , F , samples , scale , rep_params ) : [EOL] for representation in self . chain [ : : - [number] ] : [EOL] samples = representation . post_transform ( F , samples , scale , rep_params , ) [EOL] return samples [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.Dataset$ 0 $mxnet.Context$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.Dataset$ 0 $mxnet.Context$ 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 $mxnet.Context$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 $mxnet.Context$ 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor,typing.List[gluonts.model.common.Tensor]]$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import List , Optional , Tuple [EOL] import gluonts [EOL] import numpy [EOL] import typing [EOL] import mxnet [EOL] from typing import List , Optional , Tuple [EOL] [EOL] import mxnet as mx [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . dataset . common import Dataset [EOL] from gluonts . model . common import Tensor [EOL] from gluonts . mx . context import get_mxnet_context [EOL] [EOL] from . representation import Representation [EOL] [EOL] [EOL] class HybridRepresentation ( Representation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , representations , * args , ** kwargs ) : [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] self . representations = representations [EOL] for representation in self . representations : [EOL] self . register_child ( representation ) [EOL] [EOL] def initialize_from_dataset ( self , input_dataset , ctx = get_mxnet_context ( ) ) : [EOL] for representation in self . representations : [EOL] representation . initialize_from_dataset ( input_dataset , ctx ) [EOL] [EOL] def initialize_from_array ( self , input_array , ctx = get_mxnet_context ( ) ) : [EOL] for representation in self . representations : [EOL] representation . initialize_from_array ( input_array , ctx ) [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , data , observed_indicator , scale , rep_params , ** kwargs , ) : [EOL] representation_list = [ ] [EOL] [EOL] for representation in self . representations : [EOL] representation_data , _ , _ = representation ( data , observed_indicator , scale , rep_params , ) [EOL] representation_list . append ( representation_data ) [EOL] [EOL] representation_agg = F . concat ( * representation_list , dim = - [number] ) [EOL] [EOL] if scale is None : [EOL] scale = F . expand_dims ( F . sum ( data , axis = - [number] ) / F . sum ( observed_indicator , axis = - [number] ) , - [number] ) [EOL] [EOL] return representation_agg , scale , [ ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.Dataset$ 0 $mxnet.Context$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.Dataset$ 0 $mxnet.Context$ 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 $mxnet.Context$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 $mxnet.Context$ 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor,typing.List[gluonts.model.common.Tensor]]$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from . custom_binning import CustomBinning [EOL] from . dim_expansion import DimExpansion [EOL] from . discrete_pit import DiscretePIT [EOL] from . embedding import Embedding [EOL] from . global_relative_binning import GlobalRelativeBinning [EOL] from . hybrid_representation import HybridRepresentation [EOL] from . local_absolute_binning import LocalAbsoluteBinning [EOL] from . mean_scaling import MeanScaling [EOL] [EOL] [comment] [EOL] from . representation import Representation [EOL] from . representation_chain import RepresentationChain [EOL] [EOL] __all__ = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , ] [EOL] [EOL] [comment] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional , Tuple [EOL] import typing [EOL] import numpy [EOL] import gluonts [EOL] import mxnet [EOL] from typing import List , Optional , Tuple [EOL] [EOL] import mxnet as mx [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from mxnet . gluon import nn [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . dataset . common import Dataset [EOL] from gluonts . model . common import Tensor [EOL] from gluonts . mx . context import get_mxnet_context [EOL] [EOL] [EOL] class Representation ( nn . HybridBlock ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self ) : [EOL] super ( ) . __init__ ( ) [EOL] [EOL] def initialize_from_dataset ( self , input_dataset , ctx = get_mxnet_context ( ) ) : [EOL] [docstring] [EOL] pass [EOL] [EOL] def initialize_from_array ( self , input_array , ctx = get_mxnet_context ( ) ) : [EOL] [docstring] [EOL] pass [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , data , observed_indicator , scale , rep_params , ** kwargs , ) : [EOL] [docstring] [EOL] return data , F . ones_like ( data ) , [ ] [EOL] [EOL] def post_transform ( self , F , samples , scale , rep_params ) : [EOL] [docstring] [EOL] return samples [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.Dataset$ 0 $mxnet.Context$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 $mxnet.Context$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor,typing.List[gluonts.model.common.Tensor]]$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional , Tuple [EOL] import typing [EOL] import builtins [EOL] import gluonts [EOL] from typing import List , Optional , Tuple [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] [EOL] from . representation import Representation [EOL] [EOL] [EOL] class DimExpansion ( Representation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , axis = - [number] , * args , ** kwargs ) : [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] self . axis = axis [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , data , observed_indicator , scale , rep_params , ** kwargs , ) : [EOL] data = F . expand_dims ( data , axis = self . axis ) [EOL] return data , scale , rep_params [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor,typing.List[gluonts.model.common.Tensor]]$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 $typing.List[gluonts.model.common.Tensor]$ 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional , Tuple [EOL] import gluonts [EOL] import numpy [EOL] import mxnet [EOL] import typing [EOL] from typing import List , Optional , Tuple [EOL] [EOL] import mxnet as mx [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . dataset . common import Dataset [EOL] from gluonts . model . common import Tensor [EOL] from gluonts . mx . context import get_mxnet_context [EOL] [EOL] from . binning_helpers import bin_edges_from_bin_centers [EOL] from . representation import Representation [EOL] [EOL] [EOL] class CustomBinning ( Representation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , bin_centers , * args , ** kwargs ) : [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] [EOL] self . bin_edges = self . params . get_constant ( [string] , mx . nd . array ( bin_edges_from_bin_centers ( bin_centers ) ) ) [EOL] self . bin_centers = self . params . get_constant ( [string] , mx . nd . array ( bin_centers ) ) [EOL] [EOL] self . num_bins = len ( bin_centers ) [EOL] [EOL] def initialize_from_dataset ( self , input_dataset , ctx = get_mxnet_context ( ) ) : [EOL] self . initialize_from_array ( np . array ( [ ] ) , ctx ) [EOL] [EOL] def initialize_from_array ( self , input_array , ctx = get_mxnet_context ( ) ) : [EOL] with ctx : [EOL] self . bin_edges . initialize ( ) [EOL] self . bin_centers . initialize ( ) [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , data , observed_indicator , scale , rep_params , ** kwargs , ) : [EOL] bin_edges = kwargs [ [string] ] [EOL] bin_centers = kwargs [ [string] ] [EOL] [EOL] [comment] [EOL] if scale is None : [EOL] scale = F . expand_dims ( F . sum ( data * observed_indicator , axis = - [number] ) / F . sum ( observed_indicator , axis = - [number] ) , - [number] , ) [EOL] [comment] [EOL] scale = F . clip ( scale , [number] , np . inf ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] data = F . Custom ( data , bin_edges , op_type = [string] ) [EOL] [EOL] [comment] [EOL] bin_centers_hyb = F . repeat ( F . expand_dims ( bin_centers , axis = [number] ) , len ( data ) , axis = [number] ) [EOL] [EOL] return data , scale , [ bin_centers_hyb , bin_edges ] [EOL] [EOL] def post_transform ( self , F , samples , scale , rep_params ) : [EOL] bin_centers_hyb = rep_params [ [number] ] [EOL] [EOL] transf_samples = F . one_hot ( F . squeeze ( samples ) , self . num_bins ) [EOL] [EOL] [comment] [EOL] transf_samples = F . sum ( bin_centers_hyb * transf_samples , axis = [number] ) . expand_dims ( - [number] ) [EOL] [EOL] return transf_samples [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.Dataset$ 0 $mxnet.Context$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.Context$ 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 $mxnet.Context$ 0 0 0 0 0 0 0 0 $mxnet.Context$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor,typing.List[gluonts.model.common.Tensor]]$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional , Tuple [EOL] import typing [EOL] import builtins [EOL] import gluonts [EOL] from typing import List , Optional , Tuple [EOL] [EOL] import mxnet as mx [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] [EOL] from . binning_helpers import ( bin_edges_from_bin_centers , ensure_binning_monotonicity , ) [EOL] from . representation import Representation [EOL] [EOL] [EOL] class LocalAbsoluteBinning ( Representation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , num_bins = [number] , is_quantile = True , * args , ** kwargs ) : [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] [EOL] self . num_bins = num_bins [EOL] self . is_quantile = is_quantile [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , data , observed_indicator , scale , rep_params , ** kwargs , ) : [EOL] data_np = data . asnumpy ( ) [EOL] observed_indicator_np = observed_indicator . astype ( [string] ) . asnumpy ( ) [EOL] [EOL] if scale is None : [EOL] [comment] [EOL] scale = F . expand_dims ( F . sum ( data * observed_indicator , axis = - [number] ) / F . sum ( observed_indicator , axis = - [number] ) , - [number] , ) [EOL] [EOL] bin_centers_hyb = np . ones ( ( len ( data ) , self . num_bins ) ) * ( - [number] ) [EOL] bin_edges_hyb = np . ones ( ( len ( data ) , self . num_bins + [number] ) ) * ( - [number] ) [EOL] [EOL] [comment] [EOL] for i in range ( len ( data_np ) ) : [EOL] [comment] [EOL] data_loc = data_np [ i ] [EOL] observed_indicator_loc = observed_indicator_np [ i ] [EOL] data_obs_loc = data_loc [ observed_indicator_loc == [number] ] [EOL] [EOL] if data_obs_loc . size > [number] : [EOL] [comment] [EOL] if self . is_quantile : [EOL] bin_centers_loc = np . quantile ( data_obs_loc , np . linspace ( [number] , [number] , self . num_bins ) ) [EOL] else : [EOL] bin_centers_loc = np . linspace ( np . min ( data_obs_loc ) , np . max ( data_obs_loc ) , self . num_bins , ) [EOL] bin_centers_hyb [ i ] = ensure_binning_monotonicity ( bin_centers_loc ) [EOL] bin_edges_hyb [ i ] = bin_edges_from_bin_centers ( bin_centers_hyb [ i ] ) [EOL] [EOL] [comment] [EOL] data_obs_loc_binned = np . digitize ( data_obs_loc , bins = bin_edges_hyb [ i ] , right = False ) [EOL] else : [EOL] data_obs_loc_binned = [ ] [EOL] [EOL] [comment] [EOL] data_loc [ observed_indicator_loc == [number] ] = data_obs_loc_binned [EOL] data_np [ i ] = data_loc [EOL] [EOL] else : [EOL] bin_centers_hyb = rep_params [ [number] ] . asnumpy ( ) [EOL] bin_edges_hyb = rep_params [ [number] ] . asnumpy ( ) [EOL] [EOL] bin_edges_hyb = np . repeat ( bin_edges_hyb , len ( data_np ) / len ( bin_edges_hyb ) , axis = [number] , ) [EOL] bin_centers_hyb = np . repeat ( bin_centers_hyb , len ( data_np ) / len ( bin_centers_hyb ) , axis = [number] , ) [EOL] [EOL] for i in range ( len ( data_np ) ) : [EOL] data_loc = data_np [ i ] [EOL] observed_indicator_loc = observed_indicator_np [ i ] [EOL] data_obs_loc = data_loc [ observed_indicator_loc == [number] ] [EOL] [EOL] [comment] [EOL] data_obs_loc_binned = np . digitize ( data_obs_loc , bins = bin_edges_hyb [ i ] , right = False ) [EOL] [EOL] data_loc [ observed_indicator_loc == [number] ] = data_obs_loc_binned [EOL] data_np [ i ] = data_loc [EOL] [EOL] bin_centers_hyb = F . array ( bin_centers_hyb ) [EOL] bin_edges_hyb = F . array ( bin_edges_hyb ) [EOL] [EOL] data = mx . nd . array ( data_np ) [EOL] [EOL] return data , scale , [ bin_centers_hyb , bin_edges_hyb ] [EOL] [EOL] def post_transform ( self , F , samples , scale , rep_params ) : [EOL] bin_centers_hyb = rep_params [ [number] ] [EOL] [EOL] transf_samples = F . one_hot ( F . squeeze ( samples ) , self . num_bins ) [EOL] [EOL] [comment] [EOL] transf_samples = F . sum ( bin_centers_hyb * transf_samples , axis = [number] ) . expand_dims ( - [number] ) [EOL] [EOL] return transf_samples [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import numpy [EOL] import mxnet as mx [EOL] import numpy as np [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] def ensure_binning_monotonicity ( bin_centers ) : [EOL] for i in range ( [number] , len ( bin_centers ) ) : [EOL] if bin_centers [ i ] < bin_centers [ i - [number] ] : [EOL] bin_centers [ i ] = bin_centers [ i - [number] ] [EOL] return bin_centers [EOL] [EOL] [EOL] def bin_edges_from_bin_centers ( bin_centers ) : [EOL] lower_edge = - np . inf [EOL] upper_edge = np . inf [EOL] bin_edges = np . concatenate ( [ [ lower_edge ] , ( bin_centers [ [number] : ] + bin_centers [ : - [number] ] ) / [number] , [ upper_edge ] , ] ) [EOL] return bin_edges [EOL] [EOL] [EOL] class Digitize ( mx . operator . CustomOp ) : [EOL] def forward ( self , is_train , req , in_data , out_data , aux ) : [EOL] data = in_data [ [number] ] . asnumpy ( ) [EOL] bins = in_data [ [number] ] . asnumpy ( ) [EOL] data_binned = np . digitize ( data , bins = bins , right = False ) [EOL] self . assign ( out_data [ [number] ] , req [ [number] ] , mx . nd . array ( data_binned ) ) [EOL] [EOL] def backward ( self , req , out_grad , in_data , out_data , in_grad , aux ) : [EOL] return [EOL] [EOL] [EOL] @ mx . operator . register ( [string] ) class DigitizeProp ( mx . operator . CustomOpProp ) : [EOL] def __init__ ( self ) : [EOL] super ( DigitizeProp , self ) . __init__ ( True ) [EOL] [EOL] def list_arguments ( self ) : [EOL] return [ [string] , [string] ] [EOL] [EOL] def list_outputs ( self ) : [EOL] return [ [string] ] [EOL] [EOL] def infer_shape ( self , in_shapes ) : [EOL] data_shape = in_shapes [ [number] ] [EOL] bin_shape = in_shapes [ [number] ] [EOL] output_shape = data_shape [EOL] return ( data_shape , bin_shape ) , ( output_shape , ) , ( ) [EOL] [EOL] def create_operator ( self , ctx , in_shapes , in_dtypes ) : [EOL] return Digitize ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional , Tuple [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] from typing import List , Optional , Tuple [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] [EOL] from . representation import Representation [EOL] [EOL] [EOL] class MeanScaling ( Representation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , scale_min = [number] , clip_max = None , * args , ** kwargs , ) : [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] self . scale_min = scale_min [EOL] self . clip_max = clip_max [EOL] [EOL] def compute_scale ( self , F , data , observed_indicator ) : [EOL] [comment] [EOL] num_observed = F . sum ( observed_indicator , axis = [number] ) [EOL] sum_observed = ( data . abs ( ) * observed_indicator ) . sum ( axis = [number] ) [EOL] [EOL] [comment] [EOL] total_observed = num_observed . sum ( axis = [number] ) [EOL] denominator = F . maximum ( total_observed , [number] ) [EOL] default_scale = sum_observed . sum ( axis = [number] ) / denominator [comment] [EOL] [EOL] [comment] [EOL] denominator = F . maximum ( num_observed , [number] ) [EOL] scale = sum_observed / denominator [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] cond = F . broadcast_greater ( sum_observed , F . zeros_like ( sum_observed ) ) [EOL] scale = F . where ( cond , scale , F . broadcast_mul ( default_scale , F . ones_like ( num_observed ) ) , ) [EOL] [EOL] return F . maximum ( scale , self . scale_min ) [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , data , observed_indicator , scale , rep_params , ** kwargs , ) : [EOL] data = F . cast ( data , dtype = [string] ) [EOL] [EOL] if scale is None : [EOL] scale = self . compute_scale ( F , data , observed_indicator ) [EOL] scale = scale . expand_dims ( axis = [number] ) [EOL] [EOL] scaled_data = F . broadcast_div ( data , scale ) [EOL] [EOL] if self . clip_max is not None : [EOL] scaled_data = F . clip ( scaled_data , - self . clip_max , self . clip_max ) [EOL] [EOL] return scaled_data , scale , [ ] [EOL] [EOL] def post_transform ( self , F , samples , scale , rep_params ) : [EOL] transf_samples = F . broadcast_mul ( samples , scale ) [EOL] return transf_samples [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor,typing.List[gluonts.model.common.Tensor]]$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional , Tuple [EOL] import typing [EOL] import builtins [EOL] import gluonts [EOL] from typing import List , Optional , Tuple [EOL] [EOL] from mxnet . gluon import nn [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] [EOL] from . representation import Representation [EOL] [EOL] [EOL] class Embedding ( Representation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , num_bins , size = None , * args , ** kwargs ) : [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] self . num_bins = num_bins [EOL] [EOL] if size is None : [EOL] self . size = round ( self . num_bins ** ( [number] / [number] ) ) [EOL] else : [EOL] self . size = size [EOL] [EOL] self . embedding = nn . Embedding ( input_dim = self . num_bins , output_dim = self . size ) [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , data , observed_indicator , scale , rep_params , ** kwargs , ) : [EOL] data = self . embedding ( data ) [EOL] return data , scale , rep_params [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor,typing.List[gluonts.model.common.Tensor]]$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 $typing.List[gluonts.model.common.Tensor]$ 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional , Tuple [EOL] import numpy [EOL] import mxnet [EOL] import gluonts [EOL] import typing [EOL] import builtins [EOL] from typing import List , Optional , Tuple [EOL] [EOL] import mxnet as mx [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . dataset . common import Dataset [EOL] from gluonts . model . common import Tensor [EOL] from gluonts . mx . context import get_mxnet_context [EOL] [EOL] from . binning_helpers import ( bin_edges_from_bin_centers , ensure_binning_monotonicity , ) [EOL] from . representation import Representation [EOL] [EOL] [EOL] class GlobalRelativeBinning ( Representation ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , num_bins = [number] , is_quantile = True , linear_scaling_limit = [number] , quantile_scaling_limit = [number] , * args , ** kwargs , ) : [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] [EOL] self . num_bins = num_bins [EOL] self . is_quantile = is_quantile [EOL] [EOL] self . linear_scaling_limit = linear_scaling_limit [EOL] self . quantile_scaling_limit = quantile_scaling_limit [EOL] [EOL] self . bin_edges = self . params . get_constant ( [string] , mx . nd . zeros ( self . num_bins + [number] ) ) [EOL] self . bin_centers = self . params . get_constant ( [string] , mx . nd . zeros ( self . num_bins ) ) [EOL] [EOL] def initialize_from_dataset ( self , input_dataset , ctx = get_mxnet_context ( ) ) : [EOL] [comment] [EOL] train_target_sequence = np . array ( [ ] ) [EOL] for train_entry in input_dataset : [EOL] train_entry_target = train_entry [ [string] ] [EOL] train_tar_mean = np . mean ( train_entry_target ) [EOL] train_entry_target /= train_tar_mean [EOL] train_target_sequence = np . concatenate ( [ train_target_sequence , train_entry_target ] ) [EOL] self . initialize_from_array ( train_target_sequence , ctx ) [EOL] [EOL] def initialize_from_array ( self , input_array , ctx = get_mxnet_context ( ) ) : [EOL] [comment] [EOL] if self . is_quantile : [EOL] bin_centers = np . quantile ( input_array , np . linspace ( [number] , self . quantile_scaling_limit , self . num_bins ) , ) [EOL] bin_centers = ensure_binning_monotonicity ( bin_centers ) [EOL] else : [EOL] has_negative_data = np . any ( input_array < [number] ) [EOL] low = - self . linear_scaling_limit if has_negative_data else [number] [EOL] high = self . linear_scaling_limit [EOL] bin_centers = np . linspace ( low , high , self . num_bins ) [EOL] bin_edges = bin_edges_from_bin_centers ( bin_centers ) [EOL] [EOL] [comment] [EOL] with ctx : [EOL] self . bin_edges . initialize ( ) [EOL] self . bin_centers . initialize ( ) [EOL] self . bin_edges . set_data ( mx . nd . array ( bin_edges ) ) [EOL] self . bin_centers . set_data ( mx . nd . array ( bin_centers ) ) [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , data , observed_indicator , scale , rep_params , ** kwargs , ) : [EOL] bin_edges = kwargs [ [string] ] [EOL] bin_centers = kwargs [ [string] ] [EOL] [EOL] [comment] [EOL] if scale is None : [EOL] scale = F . expand_dims ( F . sum ( data * observed_indicator , axis = - [number] ) / F . sum ( observed_indicator , axis = - [number] ) , - [number] , ) [EOL] [comment] [EOL] scale = F . clip ( scale , [number] , np . inf ) [EOL] [EOL] [comment] [EOL] data_rescaled = F . broadcast_div ( data , scale ) [EOL] [EOL] [comment] [EOL] data = F . Custom ( data_rescaled , bin_edges , op_type = [string] ) [EOL] [EOL] [comment] [EOL] bin_centers_hyb = F . repeat ( F . expand_dims ( bin_centers , axis = [number] ) , len ( data ) , axis = [number] ) [EOL] [EOL] return data , scale , [ bin_centers_hyb , bin_edges ] [EOL] [EOL] def post_transform ( self , F , samples , scale , rep_params ) : [EOL] bin_centers_hyb = rep_params [ [number] ] [EOL] [EOL] transf_samples = F . one_hot ( F . squeeze ( samples ) , self . num_bins ) [EOL] [EOL] [comment] [EOL] transf_samples = F . sum ( bin_centers_hyb * transf_samples , axis = [number] ) . expand_dims ( - [number] ) [EOL] [EOL] [comment] [EOL] x = F . broadcast_mul ( scale , transf_samples ) [EOL] [EOL] return x [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.Dataset$ 0 $mxnet.Context$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.Dataset$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.Context$ 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 $mxnet.Context$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.Context$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor,typing.List[gluonts.model.common.Tensor]]$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Any , Optional , Tuple , Type [EOL] import gluonts [EOL] import distribution_output [EOL] import src [EOL] import typing [EOL] import builtins [EOL] from collections import OrderedDict [EOL] from typing import Optional , Tuple [EOL] [EOL] [comment] [EOL] from mxnet import gluon [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] [EOL] from . import LowrankMultivariateGaussian , bijection [EOL] from . distribution_output import ( ArgProj , DistributionOutput , TransformedDistribution , ) [EOL] from . lowrank_multivariate_gaussian import inv_softplus , sigma_minimum [EOL] [EOL] [EOL] class GPArgProj ( gluon . HybridBlock ) : [EOL] @ validated ( ) def __init__ ( self , rank , sigma_init = [number] , sigma_minimum = sigma_minimum , mu_ratio = [number] , dropout_rate = [number] , prefix = None , ) : [EOL] super ( ) . __init__ ( prefix = prefix ) [EOL] self . param_dim_args = OrderedDict ( { [string] : [number] , [string] : [number] , [string] : rank } ) [EOL] self . mu_ratio = mu_ratio [EOL] self . sigma_init = sigma_init [EOL] self . sigma_minimum = sigma_minimum [EOL] self . W_ratio = [number] [EOL] self . rank = rank [EOL] [EOL] def make ( name , param_dim ) : [EOL] net = gluon . nn . HybridSequential ( ) [EOL] net . add ( gluon . nn . Dense ( param_dim , flatten = False , prefix = f" [string] { name } [string] " , weight_initializer = [string] , ) ) [EOL] if dropout_rate > [number] : [EOL] net . add ( gluon . nn . Dropout ( dropout_rate ) ) [EOL] return net [EOL] [EOL] self . proj = [ make ( name , param_dim ) for name , param_dim in self . param_dim_args . items ( ) ] [EOL] for dense in self . proj : [EOL] self . register_child ( dense ) [EOL] [EOL] def hybrid_forward ( self , F , x ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] mu_vector = self . proj [ [number] ] ( x ) . squeeze ( axis = - [number] ) [EOL] [EOL] mu = mu_vector * self . mu_ratio [EOL] [EOL] [comment] [EOL] W_matrix = self . proj [ [number] ] ( x ) * self . W_ratio [EOL] [EOL] [comment] [EOL] x_plus_w = F . concat ( x , W_matrix . square ( ) . sum ( axis = - [number] , keepdims = True ) , dim = - [number] ) [EOL] [EOL] [comment] [EOL] D_vector = self . proj [ [number] ] ( x_plus_w ) . squeeze ( axis = - [number] ) [EOL] [EOL] d_bias = ( [number] [EOL] if self . sigma_init == [number] [EOL] else inv_softplus ( self . sigma_init ** [number] ) ) [EOL] [EOL] D_positive = ( F . Activation ( D_vector + d_bias , act_type = [string] ) + self . sigma_minimum ) [EOL] [EOL] return mu , D_positive , W_matrix [EOL] [EOL] [EOL] class LowrankGPOutput ( DistributionOutput ) : [EOL] @ validated ( ) def __init__ ( self , rank , dim = None , sigma_init = [number] , mu_ratio = [number] , dropout_rate = [number] , ) : [EOL] super ( ) . __init__ ( self ) [EOL] self . dist_cls = LowrankMultivariateGaussian [EOL] self . dim = dim [EOL] self . rank = rank [EOL] self . args_dim = { [string] : [number] , [string] : [number] , [string] : rank } [EOL] self . mu_bias = [number] [EOL] self . sigma_init = sigma_init [EOL] self . mu_ratio = mu_ratio [EOL] self . dropout_rate = dropout_rate [EOL] [EOL] def get_args_proj ( self , prefix = None ) : [EOL] [EOL] return GPArgProj ( rank = self . rank , mu_ratio = self . mu_ratio , sigma_init = self . sigma_init , dropout_rate = self . dropout_rate , prefix = prefix , ) [EOL] [EOL] def distribution ( self , distr_args , loc = None , scale = None , dim = None ) : [EOL] dist = LowrankMultivariateGaussian ( dim , self . rank , * distr_args ) [EOL] if loc is None and scale is None : [EOL] return dist [EOL] else : [EOL] return TransformedDistribution ( dist , [ bijection . AffineTransformation ( loc = loc , scale = scale ) ] ) [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( self . dim , ) [EOL] [EOL] @ property def event_dim ( self ) : [EOL] return [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.int$ 0 $builtins.float$ 0 0 0 $builtins.float$ 0 $builtins.float$ 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.float$ 0 $builtins.float$ 0 0 0 $builtins.float$ 0 $builtins.float$ 0 0 0 $builtins.float$ 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor,gluonts.model.common.Tensor]$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.int$ 0 $typing.Optional[builtins.int]$ 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[src.gluonts.mx.distribution.lowrank_multivariate_gaussian.LowrankMultivariateGaussian]$ 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $builtins.float$ 0 0 0 0 0 $builtins.float$ 0 $builtins.float$ 0 0 0 $builtins.float$ 0 $builtins.float$ 0 0 0 $builtins.float$ 0 $builtins.float$ 0 0 0 $distribution_output.ArgProj$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Any , Optional , Tuple [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] from typing import Any , List , Optional , Tuple [EOL] [EOL] [comment] [EOL] import mxnet as mx [EOL] import numpy as np [EOL] from mxnet import autograd [EOL] [EOL] [comment] [EOL] from gluonts . model . common import Tensor [EOL] [EOL] [EOL] def nans_like ( x ) : [EOL] return x . zeros_like ( ) / [number] [EOL] [EOL] [EOL] def softplus ( F , x ) : [EOL] return F . Activation ( x , act_type = [string] ) [EOL] [EOL] [EOL] def getF ( var ) : [EOL] if isinstance ( var , mx . nd . NDArray ) : [EOL] return mx . nd [EOL] elif isinstance ( var , mx . sym . Symbol ) : [EOL] return mx . sym [EOL] else : [EOL] raise RuntimeError ( [string] ) [EOL] [EOL] [EOL] def _index_tensor ( x , item ) : [EOL] [docstring] [EOL] squeeze = [ ] [EOL] if not isinstance ( item , tuple ) : [EOL] item = ( item , ) [EOL] [EOL] saw_ellipsis = False [EOL] [EOL] for i , item_i in enumerate ( item ) : [EOL] axis = i - len ( item ) if saw_ellipsis else i [EOL] if isinstance ( item_i , int ) : [EOL] if item_i != - [number] : [EOL] x = x . slice_axis ( axis = axis , begin = item_i , end = item_i + [number] ) [EOL] else : [EOL] x = x . slice_axis ( axis = axis , begin = - [number] , end = None ) [EOL] squeeze . append ( axis ) [EOL] elif item_i == slice ( None ) : [EOL] continue [EOL] elif item_i == Ellipsis : [EOL] saw_ellipsis = True [EOL] continue [EOL] elif isinstance ( item_i , slice ) : [EOL] assert item_i . step is None [EOL] start = item_i . start if item_i . start is not None else [number] [EOL] x = x . slice_axis ( axis = axis , begin = start , end = item_i . stop ) [EOL] else : [EOL] raise RuntimeError ( f" [string] { item }" ) [EOL] if len ( squeeze ) : [EOL] x = x . squeeze ( axis = tuple ( squeeze ) ) [EOL] return x [EOL] [EOL] [EOL] class Distribution : [EOL] [docstring] [EOL] [EOL] arg_names = ... [EOL] is_reparameterizable = False [EOL] [EOL] def log_prob ( self , x ) : [EOL] [docstring] [EOL] raise NotImplementedError ( ) [EOL] [EOL] def crps ( self , x ) : [EOL] [docstring] [EOL] raise NotImplementedError ( ) [EOL] [EOL] def loss ( self , x ) : [EOL] [docstring] [EOL] return - self . log_prob ( x ) [EOL] [EOL] def prob ( self , x ) : [EOL] [docstring] [EOL] return self . log_prob ( x ) . exp ( ) [EOL] [EOL] @ property def batch_shape ( self ) : [EOL] [docstring] [EOL] raise NotImplementedError ( ) [EOL] [EOL] @ property def event_shape ( self ) : [EOL] [docstring] [EOL] raise NotImplementedError ( ) [EOL] [EOL] @ property def event_dim ( self ) : [EOL] [docstring] [EOL] raise NotImplementedError ( ) [EOL] [EOL] @ property def batch_dim ( self ) : [EOL] [docstring] [EOL] return len ( self . batch_shape ) [EOL] [EOL] @ property def all_dim ( self ) : [EOL] [docstring] [EOL] return self . batch_dim + self . event_dim [EOL] [EOL] def sample ( self , num_samples = None , dtype = np . float32 ) : [EOL] [docstring] [EOL] with autograd . pause ( ) : [EOL] var = self . sample_rep ( num_samples = num_samples , dtype = dtype ) [EOL] F = getF ( var ) [EOL] return F . BlockGrad ( var ) [EOL] [EOL] def sample_rep ( self , num_samples = None , dtype = np . float32 ) : [EOL] raise NotImplementedError ( ) [EOL] [EOL] @ property def args ( self ) : [EOL] raise NotImplementedError ( ) [EOL] [EOL] @ property def mean ( self ) : [EOL] [docstring] [EOL] raise NotImplementedError ( ) [EOL] [EOL] @ property def stddev ( self ) : [EOL] [docstring] [EOL] raise NotImplementedError ( ) [EOL] [EOL] @ property def variance ( self ) : [EOL] [docstring] [EOL] return self . stddev . square ( ) [EOL] [EOL] def cdf ( self , x ) : [EOL] [docstring] [EOL] raise NotImplementedError ( ) [EOL] [EOL] def quantile ( self , level ) : [EOL] [docstring] [EOL] raise NotImplementedError ( ) [EOL] [EOL] def __getitem__ ( self , item ) : [EOL] sliced_distr = self . __class__ ( * [ _index_tensor ( arg , item ) for arg in self . args ] ) [EOL] assert isinstance ( sliced_distr , type ( self ) ) [EOL] return sliced_distr [EOL] [EOL] def slice_axis ( self , axis , begin , end ) : [EOL] index = ... [EOL] if axis >= [number] : [EOL] index = [ slice ( None ) ] * axis + [ slice ( begin , end ) ] [EOL] else : [EOL] index = [ Ellipsis , slice ( begin , end ) ] + [ slice ( None ) ] * ( - axis - [number] ) [EOL] return self [ tuple ( index ) ] [EOL] [EOL] [EOL] def _expand_param ( p , num_samples = None ) : [EOL] [docstring] [EOL] if num_samples is None : [EOL] return p [EOL] return p . expand_dims ( axis = [number] ) . repeat ( axis = [number] , repeats = num_samples ) [EOL] [EOL] [EOL] def _sample_multiple ( sample_func , * args , num_samples = None , ** kwargs ) : [EOL] [docstring] [EOL] args_expanded = [ _expand_param ( a , num_samples ) for a in args ] [EOL] kwargs_expanded = { k : _expand_param ( v , num_samples ) for k , v in kwargs . items ( ) } [EOL] samples = sample_func ( * args_expanded , ** kwargs_expanded ) [EOL] return samples [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $"Distribution"$ 0 0 0 $builtins.int$ 0 $builtins.int$ 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $builtins.int$ 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List [EOL] import typing [EOL] from . import bijection [EOL] from . beta import Beta , BetaOutput [EOL] from . binned import Binned , BinnedOutput [EOL] from . box_cox_transform import ( BoxCoxTransformOutput , InverseBoxCoxTransformOutput , ) [EOL] from . categorical import Categorical , CategoricalOutput [EOL] from . deterministic import Deterministic , DeterministicOutput [EOL] from . dirichlet import Dirichlet , DirichletOutput [EOL] from . dirichlet_multinomial import ( DirichletMultinomial , DirichletMultinomialOutput , ) [EOL] from . distribution import Distribution [EOL] from . distribution_output import DistributionOutput [EOL] from . gamma import Gamma , GammaOutput [EOL] from . gaussian import Gaussian , GaussianOutput [EOL] from . genpareto import GenPareto , GenParetoOutput [EOL] from . inflated_beta import ( ZeroAndOneInflatedBeta , ZeroAndOneInflatedBetaOutput , ZeroInflatedBeta , ZeroInflatedBetaOutput , OneInflatedBeta , OneInflatedBetaOutput , ) [EOL] from . laplace import Laplace , LaplaceOutput [EOL] from . logit_normal import LogitNormal , LogitNormalOutput [EOL] from . lowrank_multivariate_gaussian import ( LowrankMultivariateGaussian , LowrankMultivariateGaussianOutput , ) [EOL] from . mixture import MixtureDistribution , MixtureDistributionOutput [EOL] from . multivariate_gaussian import ( MultivariateGaussian , MultivariateGaussianOutput , ) [EOL] from . nan_mixture import NanMixture , NanMixtureOutput [EOL] from . neg_binomial import NegativeBinomial , NegativeBinomialOutput [EOL] from . piecewise_linear import ( PiecewiseLinear , PiecewiseLinearOutput , TransformedPiecewiseLinear , ) [EOL] from . poisson import Poisson , PoissonOutput [EOL] from . student_t import StudentT , StudentTOutput [EOL] from . transformed_distribution import TransformedDistribution [EOL] from . transformed_distribution_output import TransformedDistributionOutput [EOL] from . uniform import Uniform , UniformOutput [EOL] [EOL] __all__ = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , ] [EOL] [EOL] [comment] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Any , Tuple , List , Dict , Optional [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] import math [EOL] from functools import partial [EOL] from typing import Dict , List , Optional , Tuple [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] [EOL] from gluonts . core . component import validated [EOL] [EOL] from gluonts . model . common import Tensor [EOL] from . distribution import Distribution [EOL] [EOL] from gluonts . mx . distribution import Distribution [EOL] from gluonts . mx . distribution . distribution import ( getF , softplus , _sample_multiple , ) [EOL] from gluonts . mx . distribution import uniform , box_cox_transform [EOL] from gluonts . mx . distribution . distribution_output import DistributionOutput [EOL] [EOL] [EOL] class GenPareto ( Distribution ) : [EOL] [docstring] [EOL] [EOL] is_reparameterizable = False [EOL] [EOL] @ validated ( ) def __init__ ( self , xi , beta , F = None ) : [EOL] self . xi = xi [EOL] self . beta = beta [EOL] self . F = F if F else getF ( xi ) [comment] [EOL] [EOL] @ property def batch_shape ( self ) : [EOL] return self . xi . shape [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL] [EOL] @ property def event_dim ( self ) : [EOL] return [number] [EOL] [EOL] def log_prob ( self , x ) : [EOL] F = self . F [EOL] xi , beta = self . xi , self . beta [EOL] [EOL] x_shifted = F . broadcast_div ( x , beta ) [EOL] return F . where ( x < [number] , - np . inf * F . ones_like ( x ) , - ( [number] + F . reciprocal ( xi ) ) * F . log1p ( xi * x_shifted ) - F . log ( beta ) , ) [EOL] [EOL] @ property def mean ( self ) : [EOL] F = self . F [EOL] return F . where ( self . xi < [number] , F . broadcast_div ( self . beta , [number] - self . xi ) , np . nan * F . ones_like ( self . xi ) , ) [EOL] [EOL] @ property def variance ( self ) : [EOL] F = self . F [EOL] xi , beta = self . xi , self . beta [EOL] return F . where ( xi < [number] / [number] , F . broadcast_div ( beta ** [number] , F . broadcast_mul ( ( [number] - xi ) ** [number] , ( [number] - [number] * xi ) ) ) , np . nan * F . ones_like ( xi ) , ) [EOL] [EOL] @ property def stddev ( self ) : [EOL] return self . F . sqrt ( self . variance ) [EOL] [EOL] def sample ( self , num_samples = None , dtype = np . float32 ) : [EOL] def s ( xi , beta ) : [EOL] F = getF ( xi ) [EOL] sample_U = uniform . Uniform ( F . zeros_like ( xi ) , F . ones_like ( xi ) ) . sample ( ) [EOL] boxcox = box_cox_transform . BoxCoxTransform ( - xi , F . array ( [ [number] ] ) ) [EOL] sample_X = - [number] * boxcox . f ( [number] - sample_U ) * beta [EOL] return sample_X [EOL] [EOL] samples = _sample_multiple ( s , xi = self . xi , beta = self . beta , num_samples = num_samples , ) [EOL] return self . F . clip ( data = samples , a_min = np . finfo ( dtype ) . eps , a_max = np . finfo ( dtype ) . max ) [EOL] [EOL] @ property def args ( self ) : [EOL] return [ self . xi , self . beta ] [EOL] [EOL] [EOL] class GenParetoOutput ( DistributionOutput ) : [EOL] args_dim = { [string] : [number] , [string] : [number] } [EOL] distr_cls = GenPareto [EOL] [EOL] @ classmethod def domain_map ( cls , F , xi , beta ) : [EOL] [docstring] [EOL] epsilon = np . finfo ( cls . _dtype ) . eps [EOL] xi = softplus ( F , xi ) + epsilon [EOL] beta = softplus ( F , beta ) + epsilon [EOL] return xi . squeeze ( axis = - [number] ) , beta . squeeze ( axis = - [number] ) [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL] [EOL] @ property def value_in_support ( self ) : [EOL] return [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Any$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 $typing.Any$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 $gluonts.model.common.Tensor$ 0 0 $builtins.int$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.type$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional , Tuple , Dict [EOL] import typing [EOL] import builtins [EOL] import gluonts [EOL] from typing import Dict , List , Optional , Tuple [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] [EOL] from gluonts . core . component import validated [EOL] [EOL] [comment] [EOL] from gluonts . model . common import Tensor [EOL] [EOL] [comment] [EOL] from . distribution import Distribution , _sample_multiple , getF , softplus [EOL] from . distribution_output import DistributionOutput [EOL] [EOL] [EOL] class Poisson ( Distribution ) : [EOL] [docstring] [EOL] [EOL] is_reparameterizable = False [EOL] [EOL] @ validated ( ) def __init__ ( self , rate ) : [EOL] self . rate = rate [EOL] [EOL] @ property def F ( self ) : [EOL] return getF ( self . rate ) [EOL] [EOL] @ property def batch_shape ( self ) : [EOL] return self . rate . shape [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL] [EOL] @ property def event_dim ( self ) : [EOL] return [number] [EOL] [EOL] def log_prob ( self , x ) : [EOL] F = self . F [EOL] ll = x * F . log ( self . rate ) - F . gammaln ( x + [number] ) - self . rate [EOL] return ll [EOL] [EOL] @ property def mean ( self ) : [EOL] return self . rate [EOL] [EOL] @ property def stddev ( self ) : [EOL] return self . F . sqrt ( self . rate ) [EOL] [EOL] def sample ( self , num_samples = None , dtype = np . float32 ) : [EOL] def s ( rate ) : [EOL] return self . F . random . poisson ( lam = rate , dtype = dtype ) [EOL] [EOL] return _sample_multiple ( s , rate = self . rate , num_samples = num_samples ) [EOL] [EOL] @ property def args ( self ) : [EOL] return [ self . rate ] [EOL] [EOL] [EOL] class PoissonOutput ( DistributionOutput ) : [EOL] args_dim = { [string] : [number] } [EOL] distr_cls = Poisson [EOL] [EOL] @ classmethod def domain_map ( cls , F , rate ) : [EOL] rate = softplus ( F , rate ) + [number] [EOL] return rate . squeeze ( axis = - [number] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] def distribution ( self , distr_args , loc = None , scale = None , ) : [EOL] rate = distr_args [EOL] if scale is None : [EOL] return Poisson ( rate ) [EOL] else : [EOL] F = getF ( rate ) [EOL] rate = F . broadcast_mul ( rate , scale ) [EOL] return Poisson ( rate , F ) [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 $typing.List$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.int]$ 0 0 0 0 0 0 0 $builtins.type$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $Poisson$ 0 0 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Any , Optional , Tuple [EOL] import bijection [EOL] import typing [EOL] import builtins [EOL] import gluonts [EOL] from typing import Dict , List , Optional , Tuple , cast [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] from gluonts . support import util [EOL] [EOL] from . bijection import AffineTransformation , Bijection [EOL] from . distribution import Distribution , getF [EOL] from . distribution_output import DistributionOutput [EOL] from . transformed_distribution import TransformedDistribution [EOL] [EOL] [EOL] class PiecewiseLinear ( Distribution ) : [EOL] [docstring] [EOL] [EOL] is_reparameterizable = False [EOL] [EOL] @ validated ( ) def __init__ ( self , gamma , slopes , knot_spacings ) : [EOL] self . gamma = gamma [EOL] self . slopes = slopes [EOL] self . knot_spacings = knot_spacings [EOL] [EOL] [comment] [EOL] [comment] [EOL] self . b , self . knot_positions = PiecewiseLinear . _to_orig_params ( self . F , slopes , knot_spacings ) [EOL] [EOL] @ property def F ( self ) : [EOL] return getF ( self . gamma ) [EOL] [EOL] @ property def args ( self ) : [EOL] return [ self . gamma , self . slopes , self . knot_spacings ] [EOL] [EOL] @ staticmethod def _to_orig_params ( F , slopes , knot_spacings ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] [comment] [EOL] b = F . slice_axis ( slopes , axis = - [number] , begin = [number] , end = None ) - F . slice_axis ( slopes , axis = - [number] , begin = [number] , end = - [number] ) [EOL] [EOL] [comment] [EOL] m_0 = F . slice_axis ( slopes , axis = - [number] , begin = [number] , end = [number] ) [EOL] b = F . concat ( m_0 , b , dim = - [number] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] knot_positions = util . cumsum ( F , knot_spacings , exclusive = True ) [EOL] [EOL] return b , knot_positions [EOL] [EOL] def sample ( self , num_samples = None , dtype = np . float32 ) : [EOL] F = self . F [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] u = F . random . uniform_like ( data = ( self . gamma [EOL] if num_samples is None [EOL] else self . gamma . expand_dims ( axis = [number] ) . repeat ( axis = [number] , repeats = num_samples ) ) ) [EOL] [EOL] sample = self . quantile ( u ) [EOL] [EOL] if num_samples is None : [EOL] sample = F . squeeze ( sample , axis = [number] ) [EOL] [EOL] return sample [EOL] [EOL] [comment] [EOL] def loss ( self , x ) : [EOL] return self . crps ( x ) [EOL] [EOL] def crps ( self , x ) : [EOL] [docstring] [EOL] [EOL] F = self . F [EOL] gamma , b , knot_positions = self . gamma , self . b , self . knot_positions [EOL] [EOL] a_tilde = self . cdf ( x ) [EOL] [EOL] max_a_tilde_knots = F . broadcast_maximum ( a_tilde . expand_dims ( axis = - [number] ) , knot_positions ) [EOL] [EOL] knots_cubed = F . broadcast_power ( self . knot_positions , F . ones ( [number] ) * [number] ) [EOL] [EOL] coeff = ( ( [number] - knots_cubed ) / [number] - knot_positions - F . square ( max_a_tilde_knots ) + [number] * max_a_tilde_knots * knot_positions ) [EOL] [EOL] crps = ( ( [number] * a_tilde - [number] ) * x + ( [number] - [number] * a_tilde ) * gamma + F . sum ( b * coeff , axis = - [number] , keepdims = False ) ) [EOL] [EOL] return crps [EOL] [EOL] def cdf ( self , x ) : [EOL] [docstring] [EOL] [EOL] F = self . F [EOL] gamma , b , knot_positions = self . gamma , self . b , self . knot_positions [EOL] [EOL] quantiles_at_knots = self . quantile_internal ( knot_positions , axis = - [number] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] mask = F . broadcast_lesser ( quantiles_at_knots , x . expand_dims ( axis = - [number] ) ) [EOL] [EOL] slope_l0 = F . sum ( b * mask , axis = - [number] , keepdims = False ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] slope_l0_nz = F . where ( slope_l0 == F . zeros_like ( slope_l0 ) , F . ones_like ( x ) , slope_l0 ) [EOL] [EOL] a_tilde = F . where ( slope_l0 == F . zeros_like ( slope_l0 ) , F . zeros_like ( x ) , ( x - gamma + F . sum ( b * knot_positions * mask , axis = - [number] , keepdims = False ) ) / slope_l0_nz , ) [EOL] [EOL] return F . broadcast_minimum ( F . ones_like ( a_tilde ) , a_tilde ) [EOL] [EOL] def quantile ( self , level ) : [EOL] return self . quantile_internal ( level , axis = [number] ) [EOL] [EOL] def quantile_internal ( self , x , axis = None ) : [EOL] [docstring] [EOL] [EOL] F = self . F [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] if axis is not None : [EOL] gamma = self . gamma . expand_dims ( axis = axis if axis == [number] else - [number] ) [EOL] knot_positions = self . knot_positions . expand_dims ( axis = axis ) [EOL] b = self . b . expand_dims ( axis = axis ) [EOL] else : [EOL] gamma , knot_positions , b = self . gamma , self . knot_positions , self . b [EOL] [EOL] x_minus_knots = F . broadcast_minus ( x . expand_dims ( axis = - [number] ) , knot_positions ) [EOL] [EOL] quantile = F . broadcast_add ( gamma , F . sum ( F . broadcast_mul ( b , F . relu ( x_minus_knots ) ) , axis = - [number] ) ) [EOL] [EOL] return quantile [EOL] [EOL] @ property def batch_shape ( self ) : [EOL] return self . gamma . shape [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL] [EOL] @ property def event_dim ( self ) : [EOL] return [number] [EOL] [EOL] [EOL] class PiecewiseLinearOutput ( DistributionOutput ) : [EOL] distr_cls = PiecewiseLinear [EOL] [EOL] @ validated ( ) def __init__ ( self , num_pieces ) : [EOL] super ( ) . __init__ ( self ) [EOL] [EOL] assert ( isinstance ( num_pieces , int ) and num_pieces > [number] ) , [string] [EOL] [EOL] self . num_pieces = num_pieces [EOL] self . args_dim = cast ( Dict [ str , int ] , { [string] : [number] , [string] : num_pieces , [string] : num_pieces } , ) [EOL] [EOL] @ classmethod def domain_map ( cls , F , gamma , slopes , knot_spacings ) : [EOL] [comment] [EOL] slopes_proj = F . Activation ( data = slopes , act_type = [string] ) + [number] [EOL] [EOL] [comment] [EOL] knot_spacings_proj = F . softmax ( knot_spacings ) [EOL] [EOL] return gamma . squeeze ( axis = - [number] ) , slopes_proj , knot_spacings_proj [EOL] [EOL] def distribution ( self , distr_args , loc = None , scale = None , ) : [EOL] if scale is None : [EOL] return self . distr_cls ( * distr_args ) [EOL] else : [EOL] distr = self . distr_cls ( * distr_args ) [EOL] return TransformedPiecewiseLinear ( distr , [ AffineTransformation ( loc = loc , scale = scale ) ] ) [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL] [EOL] [EOL] [comment] [EOL] class TransformedPiecewiseLinear ( TransformedDistribution , PiecewiseLinear ) : [EOL] @ validated ( ) def __init__ ( self , base_distribution , transforms ) : [EOL] super ( ) . __init__ ( base_distribution , transforms ) [EOL] [EOL] def crps ( self , y ) : [EOL] [comment] [EOL] F = getF ( y ) [EOL] x = y [EOL] scale = [number] [EOL] for t in self . transforms [ : : - [number] ] : [EOL] assert isinstance ( t , AffineTransformation ) , [string] [EOL] x = t . f_inv ( x ) [EOL] scale *= t . scale [EOL] p = self . base_distribution . crps ( x ) [EOL] return F . broadcast_mul ( p , scale ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor]$ 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.type$ 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 $PiecewiseLinear$ 0 0 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $PiecewiseLinear$ 0 $typing.List[bijection.Bijection]$ 0 0 0 0 0 0 0 0 0 $PiecewiseLinear$ 0 $typing.List[bijection.Bijection]$ 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $typing.Any$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 $gluonts.model.common.Tensor$ 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $builtins.float$ 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Any , Tuple , Type [EOL] import distribution [EOL] import typing [EOL] import builtins [EOL] import gluonts [EOL] from typing import List , Tuple [EOL] [EOL] import mxnet as mx [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] [EOL] [comment] [EOL] from . distribution import Distribution , _sample_multiple , getF [EOL] from . distribution_output import DistributionOutput [EOL] [EOL] [EOL] class Categorical ( Distribution ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , log_probs ) : [EOL] super ( ) . __init__ ( ) [EOL] self . log_probs = log_probs [EOL] self . num_cats = self . log_probs . shape [ - [number] ] [EOL] self . cats = self . F . arange ( self . num_cats ) [EOL] self . _probs = None [EOL] [EOL] @ property def F ( self ) : [EOL] return getF ( self . log_probs ) [EOL] [EOL] @ property def probs ( self ) : [EOL] if self . _probs is None : [EOL] self . _probs = self . log_probs . exp ( ) [EOL] return self . _probs [EOL] [EOL] @ property def batch_shape ( self ) : [EOL] return self . log_probs . shape [ : - [number] ] [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL] [EOL] @ property def event_dim ( self ) : [EOL] return [number] [EOL] [EOL] @ property def mean ( self ) : [EOL] return ( self . probs * self . cats ) . sum ( axis = - [number] ) [EOL] [EOL] @ property def stddev ( self ) : [EOL] ex2 = ( self . probs * self . cats . square ( ) ) . sum ( axis = - [number] ) [EOL] return ( ex2 - self . mean . square ( ) ) . sqrt ( ) [EOL] [EOL] def log_prob ( self , x ) : [EOL] F = self . F [EOL] mask = F . one_hot ( x , self . num_cats ) [EOL] log_prob = F . broadcast_mul ( self . log_probs , mask ) . sum ( axis = - [number] ) [EOL] return log_prob [EOL] [EOL] def sample ( self , num_samples = None , dtype = np . int32 ) : [EOL] def s ( bin_probs ) : [EOL] F = self . F [EOL] indices = F . sample_multinomial ( bin_probs ) [EOL] return indices [EOL] [EOL] return _sample_multiple ( s , self . probs , num_samples = num_samples ) . astype ( dtype ) [EOL] [EOL] @ property def args ( self ) : [EOL] return [ self . log_probs ] [EOL] [EOL] [EOL] class CategoricalOutput ( DistributionOutput ) : [EOL] distr_cls = Categorical [EOL] [EOL] @ validated ( ) def __init__ ( self , num_cats , temperature = [number] ) : [EOL] super ( ) . __init__ ( ) [EOL] assert num_cats > [number] , [string] [EOL] assert temperature > [number] , [string] [EOL] self . args_dim = { [string] : num_cats } [EOL] self . distr_cls = Categorical [EOL] self . num_cats = num_cats [EOL] self . temperature = temperature [EOL] [EOL] def domain_map ( self , F , probs ) : [EOL] if not mx . autograd . is_training ( ) : [EOL] probs = probs / self . temperature [EOL] log_probs_s = F . log_softmax ( probs ) [EOL] return log_probs_s [EOL] [EOL] def distribution ( self , distr_args , loc = None , scale = None , ** kwargs ) : [EOL] distr = Categorical ( distr_args ) [EOL] return distr [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.type$ 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.int$ 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $typing.Type[typing.Any]$ 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 $builtins.float$ 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 $CategoricalOutput.distribution.Distribution$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Any , Tuple , List , Dict , Optional [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] import math [EOL] from typing import Dict , List , Optional , Tuple [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] [EOL] from gluonts . core . component import validated [EOL] [EOL] [comment] [EOL] from gluonts . model . common import Tensor [EOL] [EOL] [comment] [EOL] from . distribution import ( Distribution , _sample_multiple , getF , nans_like , softplus , ) [EOL] from . distribution_output import DistributionOutput [EOL] [EOL] [EOL] class StudentT ( Distribution ) : [EOL] [docstring] [EOL] [EOL] is_reparameterizable = False [EOL] [EOL] @ validated ( ) def __init__ ( self , mu , sigma , nu , F = None ) : [EOL] self . mu = mu [EOL] self . sigma = sigma [EOL] self . nu = nu [EOL] [EOL] @ property def F ( self ) : [EOL] return getF ( self . mu ) [EOL] [EOL] @ property def batch_shape ( self ) : [EOL] return self . mu . shape [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL] [EOL] @ property def event_dim ( self ) : [EOL] return [number] [EOL] [EOL] @ property def mean ( self ) : [EOL] return self . F . where ( self . nu > [number] , self . mu , nans_like ( self . mu ) ) [EOL] [EOL] @ property def stddev ( self ) : [EOL] F = self . F [EOL] mu , nu , sigma = self . mu , self . nu , self . sigma [EOL] return F . where ( nu > [number] , sigma * F . sqrt ( nu / ( nu - [number] ) ) , nans_like ( mu ) ) [EOL] [EOL] def log_prob ( self , x ) : [EOL] mu , sigma , nu = self . mu , self . sigma , self . nu [EOL] F = self . F [EOL] [EOL] nup1_half = ( nu + [number] ) / [number] [EOL] part1 = [number] / nu * F . square ( ( x - mu ) / sigma ) [EOL] Z = ( F . gammaln ( nup1_half ) - F . gammaln ( nu / [number] ) - [number] * F . log ( math . pi * nu ) - F . log ( sigma ) ) [EOL] [EOL] ll = Z - nup1_half * F . log1p ( part1 ) [EOL] return ll [EOL] [EOL] def sample ( self , num_samples = None , dtype = np . float32 ) : [EOL] def s ( mu , sigma , nu ) : [EOL] F = self . F [EOL] gammas = F . sample_gamma ( alpha = nu / [number] , beta = [number] / ( nu * F . square ( sigma ) ) , dtype = dtype ) [EOL] normal = F . sample_normal ( mu = mu , sigma = [number] / F . sqrt ( gammas ) , dtype = dtype ) [EOL] return normal [EOL] [EOL] return _sample_multiple ( s , mu = self . mu , sigma = self . sigma , nu = self . nu , num_samples = num_samples , ) [EOL] [EOL] @ property def args ( self ) : [EOL] return [ self . mu , self . sigma , self . nu ] [EOL] [EOL] [EOL] class StudentTOutput ( DistributionOutput ) : [EOL] args_dim = { [string] : [number] , [string] : [number] , [string] : [number] } [EOL] distr_cls = StudentT [EOL] [EOL] @ classmethod def domain_map ( cls , F , mu , sigma , nu ) : [EOL] sigma = softplus ( F , sigma ) [EOL] nu = [number] + softplus ( F , nu ) [EOL] return mu . squeeze ( axis = - [number] ) , sigma . squeeze ( axis = - [number] ) , nu . squeeze ( axis = - [number] ) [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $builtins.float$ 0 0 0 0 0 $builtins.float$ 0 0 0 $typing.Any$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 $typing.List$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.type$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Any , Union , Optional [EOL] import gluonts [EOL] import builtins [EOL] import src [EOL] import typing [EOL] from typing import Optional , Union [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] [EOL] from gluonts . core . component import validated [EOL] [EOL] [comment] [EOL] from gluonts . model . common import Tensor [EOL] [EOL] [comment] [EOL] from . distribution import getF [EOL] [EOL] [EOL] class Bijection : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self ) : [EOL] pass [EOL] [EOL] def f ( self , x ) : [EOL] [docstring] [EOL] raise NotImplementedError [EOL] [EOL] def f_inv ( self , y ) : [EOL] [docstring] [EOL] raise NotImplementedError [EOL] [EOL] def log_abs_det_jac ( self , x , y ) : [EOL] [docstring] [EOL] raise NotImplementedError [EOL] [EOL] def inverse_bijection ( self ) : [EOL] [docstring] [EOL] return InverseBijection ( self ) [EOL] [EOL] @ property def event_dim ( self ) : [EOL] raise NotImplementedError ( ) [EOL] [EOL] @ property def sign ( self ) : [EOL] [docstring] [EOL] raise NotImplementedError ( ) [EOL] [EOL] [EOL] class InverseBijection ( Bijection ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , bijection ) : [EOL] super ( ) . __init__ ( self ) [EOL] self . _bijection = bijection [EOL] [EOL] def f ( self , x ) : [EOL] return self . _bijection . f_inv ( x ) [EOL] [EOL] def f_inv ( self , y ) : [EOL] return self . _bijection . f ( y ) [EOL] [EOL] def log_abs_det_jac ( self , x , y ) : [EOL] return - self . _bijection . log_abs_det_jac ( y , x ) [EOL] [EOL] def inverse_bijection ( self ) : [EOL] return self . _bijection [EOL] [EOL] @ property def event_dim ( self ) : [EOL] return self . _bijection . event_dim [EOL] [EOL] @ property def sign ( self ) : [EOL] return self . _bijection . sign [EOL] [EOL] [EOL] class _Exp ( Bijection ) : [EOL] def f ( self , x ) : [EOL] return x . clip ( - np . inf , [number] ) . exp ( ) [EOL] [EOL] def f_inv ( self , y ) : [EOL] return y . clip ( [number] , np . inf ) . log ( ) [EOL] [EOL] def log_abs_det_jac ( self , x , y ) : [EOL] return y . clip ( [number] , np . inf ) . log ( ) [EOL] [EOL] @ property def event_dim ( self ) : [EOL] return [number] [EOL] [EOL] @ property def sign ( self ) : [EOL] return [number] [EOL] [EOL] [EOL] class _Log ( Bijection ) : [EOL] def f ( self , x ) : [EOL] return x . clip ( [number] , np . inf ) . log ( ) [EOL] [EOL] def f_inv ( self , y ) : [EOL] return y . clip ( - np . inf , [number] ) . exp ( ) [EOL] [EOL] def log_abs_det_jac ( self , x , y ) : [EOL] return - y [EOL] [EOL] @ property def event_dim ( self ) : [EOL] return [number] [EOL] [EOL] @ property def sign ( self ) : [EOL] return [number] [EOL] [EOL] [EOL] class _Softrelu ( Bijection ) : [EOL] def _log_expm1 ( self , F , y ) : [EOL] [docstring] [EOL] thresh = F . zeros_like ( y ) + [number] [EOL] x = F . where ( F . broadcast_greater ( y , thresh ) , y , F . log ( F . expm1 ( y ) ) ) [EOL] return x [EOL] [EOL] def f ( self , x ) : [EOL] F = getF ( x ) [EOL] return F . Activation ( x . clip ( - [number] , np . inf ) , act_type = [string] ) [EOL] [EOL] def f_inv ( self , y ) : [EOL] F = getF ( y ) [EOL] return self . _log_expm1 ( F , y ) [EOL] [EOL] def log_abs_det_jac ( self , x , y ) : [EOL] F = getF ( y ) [EOL] return self . _log_expm1 ( F , y ) - y [EOL] [EOL] @ property def event_dim ( self ) : [EOL] return [number] [EOL] [EOL] @ property def sign ( self ) : [EOL] return [number] [EOL] [EOL] [EOL] class AffineTransformation ( Bijection ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , loc = None , scale = None ) : [EOL] super ( ) . __init__ ( self ) [EOL] self . loc = loc [EOL] self . scale = scale [EOL] [EOL] def f ( self , x ) : [EOL] F = getF ( x ) [EOL] if self . scale is not None : [EOL] x = F . broadcast_mul ( x , self . scale ) [EOL] if self . loc is not None : [EOL] x = F . broadcast_add ( x , self . loc ) [EOL] return x [EOL] [EOL] def f_inv ( self , y ) : [EOL] F = getF ( y ) [EOL] if self . loc is not None : [EOL] y = F . broadcast_sub ( y , self . loc ) [EOL] if self . scale is not None : [EOL] y = F . broadcast_div ( y , self . scale ) [EOL] return y [EOL] [EOL] def log_abs_det_jac ( self , x , y ) : [EOL] if self . scale is not None : [EOL] return self . scale . broadcast_like ( x ) . abs ( ) . log ( ) [EOL] F = getF ( x ) [EOL] return F . zeros_like ( x ) [EOL] [EOL] @ property def sign ( self ) : [EOL] return [number] if self . scale is None else self . scale . sign ( ) [EOL] [EOL] @ property def event_dim ( self ) : [EOL] return [number] [EOL] [EOL] [EOL] exp = _Exp ( ) [EOL] log = _Log ( ) [EOL] softrelu = _Softrelu ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 $"Bijection"$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Union[builtins.float,gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $Bijection$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $src.gluonts.mx.distribution.bijection.Bijection$ 0 $Bijection$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 $Bijection$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Union[builtins.float,gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $src.gluonts.mx.distribution.bijection._Exp$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 $src.gluonts.mx.distribution.bijection._Log$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 $src.gluonts.mx.distribution.bijection._Log$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 $src.gluonts.mx.distribution.bijection._Log$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $src.gluonts.mx.distribution.bijection._Exp$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $typing.Any$ 0 0 $gluonts.model.common.Tensor$ 0 0 0 $src.gluonts.mx.distribution.bijection._Log$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $typing.Any$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Any$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Any$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Any$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $typing.Any$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Any$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $typing.Any$ 0 $gluonts.model.common.Tensor$ 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 $src.gluonts.mx.distribution.bijection._Log$ 0 0 0 $typing.Any$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Any$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 $typing.Union[builtins.float,gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $src.gluonts.mx.distribution.bijection._Exp$ 0 0 0 0 0 $src.gluonts.mx.distribution.bijection._Log$ 0 0 0 0 0 $src.gluonts.mx.distribution.bijection._Softrelu$ 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Optional , Tuple [EOL] import distribution [EOL] import gluonts [EOL] import distribution_output [EOL] import typing [EOL] import builtins [EOL] import math [EOL] from typing import Optional , Tuple [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] from mxnet import gluon [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] [EOL] from . import bijection [EOL] from . distribution import Distribution , _sample_multiple , getF [EOL] from . distribution_output import ( ArgProj , DistributionOutput , TransformedDistribution , ) [EOL] [EOL] sigma_minimum = [number] [EOL] [EOL] [EOL] def capacitance_tril ( F , rank , W , D ) : [EOL] [docstring] [EOL] [comment] [EOL] Wt_D_inv_t = F . broadcast_div ( W , D . expand_dims ( axis = - [number] ) ) [EOL] [EOL] [comment] [EOL] K = F . linalg_gemm2 ( Wt_D_inv_t , W , transpose_a = True ) [EOL] [EOL] [comment] [EOL] Id = F . broadcast_mul ( F . ones_like ( K ) , F . eye ( rank ) ) [EOL] [EOL] [comment] [EOL] return F . linalg . potrf ( K + Id ) [EOL] [EOL] [EOL] def log_det ( F , batch_D , batch_capacitance_tril ) : [EOL] [docstring] [EOL] log_D = batch_D . log ( ) . sum ( axis = - [number] ) [EOL] log_C = [number] * F . linalg . sumlogdiag ( batch_capacitance_tril ) [EOL] return log_C + log_D [EOL] [EOL] [EOL] def mahalanobis_distance ( F , W , D , capacitance_tril , x ) : [EOL] [docstring] [EOL] xx = x . expand_dims ( axis = - [number] ) [EOL] [EOL] [comment] [EOL] Wt_Dinv_x = F . linalg_gemm2 ( F . broadcast_div ( W , D . expand_dims ( axis = - [number] ) ) , xx , transpose_a = True ) [EOL] [EOL] [comment] [EOL] maholanobis_D_inv = F . broadcast_div ( x . square ( ) , D ) . sum ( axis = - [number] ) [EOL] [EOL] [comment] [EOL] L_inv_Wt_Dinv_x = F . linalg_trsm ( capacitance_tril , Wt_Dinv_x ) . squeeze ( axis = - [number] ) [EOL] [EOL] maholanobis_L = L_inv_Wt_Dinv_x . square ( ) . sum ( axis = - [number] ) . squeeze ( ) [EOL] [EOL] return F . broadcast_minus ( maholanobis_D_inv , maholanobis_L ) [EOL] [EOL] [EOL] def lowrank_log_likelihood ( rank , mu , D , W , x ) : [EOL] [EOL] F = getF ( mu ) [EOL] [EOL] dim = F . ones_like ( mu ) . sum ( axis = - [number] ) . max ( ) [EOL] [EOL] dim_factor = dim * math . log ( [number] * math . pi ) [EOL] [EOL] batch_capacitance_tril = capacitance_tril ( F = F , rank = rank , W = W , D = D ) [EOL] [EOL] log_det_factor = log_det ( F = F , batch_D = D , batch_capacitance_tril = batch_capacitance_tril ) [EOL] [EOL] mahalanobis_factor = mahalanobis_distance ( F = F , W = W , D = D , capacitance_tril = batch_capacitance_tril , x = x - mu ) [EOL] [EOL] ll = - [number] * ( F . broadcast_add ( dim_factor , log_det_factor ) + mahalanobis_factor ) [EOL] [EOL] return ll [EOL] [EOL] [EOL] class LowrankMultivariateGaussian ( Distribution ) : [EOL] [docstring] [EOL] [EOL] is_reparameterizable = True [EOL] [EOL] @ validated ( ) def __init__ ( self , dim , rank , mu , D , W ) : [EOL] self . dim = dim [EOL] self . rank = rank [EOL] self . mu = mu [EOL] self . D = D [EOL] self . W = W [EOL] self . Cov = None [EOL] [EOL] @ property def F ( self ) : [EOL] return getF ( self . mu ) [EOL] [EOL] @ property def batch_shape ( self ) : [EOL] return self . mu . shape [ : - [number] ] [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return self . mu . shape [ - [number] : ] [EOL] [EOL] @ property def event_dim ( self ) : [EOL] return [number] [EOL] [EOL] def log_prob ( self , x ) : [EOL] return lowrank_log_likelihood ( rank = self . rank , mu = self . mu , D = self . D , W = self . W , x = x ) [EOL] [EOL] @ property def mean ( self ) : [EOL] return self . mu [EOL] [EOL] @ property def variance ( self ) : [EOL] assert self . dim is not None [EOL] F = self . F [EOL] [EOL] if self . Cov is not None : [EOL] return self . Cov [EOL] [comment] [EOL] D_matrix = self . D . expand_dims ( - [number] ) * F . eye ( self . dim ) [EOL] [EOL] W_matrix = F . linalg_gemm2 ( self . W , self . W , transpose_b = True ) [EOL] [EOL] self . Cov = D_matrix + W_matrix [EOL] [EOL] return self . Cov [EOL] [EOL] def sample_rep ( self , num_samples = None , dtype = np . float32 ) : [EOL] [docstring] [EOL] [EOL] def s ( mu , D , W ) : [EOL] F = getF ( mu ) [EOL] [EOL] samples_D = F . sample_normal ( mu = F . zeros_like ( mu ) , sigma = F . ones_like ( mu ) , dtype = dtype ) [EOL] cov_D = D . sqrt ( ) * samples_D [EOL] [EOL] [comment] [EOL] dummy_tensor = F . linalg_gemm2 ( W , mu . expand_dims ( axis = - [number] ) , transpose_a = True ) . squeeze ( axis = - [number] ) [EOL] [EOL] samples_W = F . sample_normal ( mu = F . zeros_like ( dummy_tensor ) , sigma = F . ones_like ( dummy_tensor ) , dtype = dtype , ) [EOL] [EOL] cov_W = F . linalg_gemm2 ( W , samples_W . expand_dims ( axis = - [number] ) ) . squeeze ( axis = - [number] ) [EOL] [EOL] samples = mu + cov_D + cov_W [EOL] [EOL] return samples [EOL] [EOL] return _sample_multiple ( s , mu = self . mu , D = self . D , W = self . W , num_samples = num_samples ) [EOL] [EOL] [EOL] def inv_softplus ( y ) : [EOL] if y < [number] : [EOL] [comment] [EOL] return np . log ( np . exp ( y ) - [number] ) [EOL] else : [EOL] return y [EOL] [EOL] [EOL] class LowrankMultivariateGaussianOutput ( DistributionOutput ) : [EOL] @ validated ( ) def __init__ ( self , dim , rank , sigma_init = [number] , sigma_minimum = sigma_minimum , ) : [EOL] super ( ) . __init__ ( self ) [EOL] self . distr_cls = LowrankMultivariateGaussian [EOL] self . dim = dim [EOL] self . rank = rank [EOL] self . args_dim = { [string] : dim , [string] : dim , [string] : dim * rank } [EOL] self . mu_bias = [number] [EOL] self . sigma_init = sigma_init [EOL] self . sigma_minimum = sigma_minimum [EOL] [EOL] def get_args_proj ( self , prefix = None ) : [EOL] return ArgProj ( args_dim = self . args_dim , domain_map = gluon . nn . HybridLambda ( self . domain_map ) , prefix = prefix , ) [EOL] [EOL] def distribution ( self , distr_args , loc = None , scale = None , ** kwargs ) : [EOL] distr = LowrankMultivariateGaussian ( self . dim , self . rank , * distr_args ) [EOL] if loc is None and scale is None : [EOL] return distr [EOL] else : [EOL] return TransformedDistribution ( distr , [ bijection . AffineTransformation ( loc = loc , scale = scale ) ] ) [EOL] [EOL] def domain_map ( self , F , mu_vector , D_vector , W_vector ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] W_matrix = W_vector . reshape ( ( - [number] , self . dim , self . rank , - [number] ) , reverse = [number] ) [EOL] [EOL] d_bias = ( inv_softplus ( self . sigma_init ** [number] ) [EOL] if self . sigma_init > [number] [EOL] else [number] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] D_diag = ( F . Activation ( D_vector + d_bias , act_type = [string] ) + self . sigma_minimum ** [number] ) [EOL] [EOL] return mu_vector + self . mu_bias , D_diag , W_matrix [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( self . dim , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $distribution_output.ArgProj$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 $LowrankMultivariateGaussianOutput.distribution.Distribution$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Any , Tuple , Dict [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] from typing import Dict , List , Tuple [EOL] [EOL] [comment] [EOL] import mxnet as mx [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] [EOL] [comment] [EOL] from . bijection import Bijection , InverseBijection [EOL] from . bijection_output import BijectionOutput [EOL] from . distribution import getF , softplus [EOL] [EOL] [EOL] class BoxCoxTransform ( Bijection ) : [EOL] [docstring] [EOL] arg_names = [ [string] , [string] ] [EOL] [EOL] @ validated ( ) def __init__ ( self , lambda_1 , lambda_2 , tol_lambda_1 = [number] , F = None , ) : [EOL] self . lambda_1 = lambda_1 [EOL] self . lambda_2 = lambda_2 [EOL] self . tol_lambda_1 = tol_lambda_1 [EOL] self . F = F if F else getF ( lambda_1 ) [EOL] [EOL] [comment] [EOL] self . _power = self . F . power if self . F == mx . nd else self . F . pow [EOL] [EOL] @ property def args ( self ) : [EOL] [docstring] [EOL] return [ self . lambda_1 , self . lambda_2 ] [EOL] [EOL] @ property def event_dim ( self ) : [EOL] return [number] [EOL] [EOL] @ property def sign ( self ) : [EOL] return [number] [EOL] [EOL] def f ( self , z ) : [EOL] [docstring] [EOL] F = self . F [EOL] lambda_1 = self . lambda_1 [EOL] lambda_2 = self . lambda_2 [EOL] tol_lambda_1 = self . tol_lambda_1 [EOL] _power = self . _power [EOL] [EOL] return F . where ( condition = ( F . abs ( lambda_1 ) . __ge__ ( tol_lambda_1 ) . broadcast_like ( z ) ) , x = ( _power ( z + lambda_2 , lambda_1 ) - [number] ) / lambda_1 , y = F . log ( z + lambda_2 ) , name = [string] , ) [EOL] [EOL] def f_inv ( self , y ) : [EOL] [docstring] [EOL] F = self . F [EOL] lambda_1 = self . lambda_1 [EOL] lambda_2 = self . lambda_2 [EOL] tol_lambda_1 = self . tol_lambda_1 [EOL] _power = self . _power [EOL] [EOL] [comment] [EOL] base = F . relu ( y * lambda_1 + [number] ) [EOL] [EOL] return F . where ( condition = ( F . abs ( lambda_1 ) . __ge__ ( tol_lambda_1 ) ) . broadcast_like ( y ) , x = _power ( base , [number] / lambda_1 ) - lambda_2 , y = F . exp ( y ) - lambda_2 , name = [string] , ) [EOL] [EOL] def log_abs_det_jac ( self , z , y = None ) : [EOL] [docstring] [EOL] F = self . F [EOL] lambda_1 = self . lambda_1 [EOL] lambda_2 = self . lambda_2 [EOL] tol_lambda_1 = self . tol_lambda_1 [EOL] [EOL] return F . where ( condition = F . abs ( lambda_1 ) . __ge__ ( tol_lambda_1 ) , x = F . log ( z + lambda_2 ) * ( lambda_1 - [number] ) , y = - F . log ( z + lambda_2 ) , name = [string] , ) [EOL] [EOL] [EOL] class BoxCoxTransformOutput ( BijectionOutput ) : [EOL] bij_cls = BoxCoxTransform [EOL] args_dim = dict ( zip ( BoxCoxTransform . arg_names , [ [number] , [number] ] ) ) [EOL] [EOL] @ validated ( ) def __init__ ( self , lb_obs = [number] , fix_lambda_2 = True ) : [EOL] super ( ) . __init__ ( ) [EOL] self . lb_obs = lb_obs [EOL] self . fix_lambda_2 = fix_lambda_2 [EOL] [EOL] def domain_map ( self , F , * args ) : [EOL] lambda_1 , lambda_2 = args [EOL] if self . fix_lambda_2 : [EOL] lambda_2 = - self . lb_obs * F . ones_like ( lambda_2 ) [EOL] else : [EOL] [comment] [EOL] lambda_2 = softplus ( F , lambda_2 ) - self . lb_obs * F . ones_like ( lambda_2 ) [EOL] [EOL] [comment] [EOL] return lambda_1 . squeeze ( axis = - [number] ) , lambda_2 . squeeze ( axis = - [number] ) [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL] [EOL] [EOL] class InverseBoxCoxTransform ( InverseBijection ) : [EOL] [docstring] [EOL] [EOL] arg_names = [ [string] , [string] ] [EOL] [EOL] @ validated ( ) def __init__ ( self , lambda_1 , lambda_2 , tol_lambda_1 = [number] , F = None , ) : [EOL] super ( ) . __init__ ( BoxCoxTransform ( lambda_1 , lambda_2 , tol_lambda_1 , F ) ) [EOL] [EOL] @ property def event_dim ( self ) : [EOL] return [number] [EOL] [EOL] [EOL] class InverseBoxCoxTransformOutput ( BoxCoxTransformOutput ) : [EOL] bij_cls = InverseBoxCoxTransform [EOL] [EOL] args_dim = dict ( zip ( InverseBoxCoxTransform . arg_names , [ [number] , [number] ] ) ) [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.type$ 0 0 0 $typing.Dict[builtins.str,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.float$ 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 $builtins.float$ 0 0 0 $builtins.bool$ 0 $builtins.bool$ 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,...]$ 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $builtins.float$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.type$ 0 0 0 0 $typing.Dict[builtins.str,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional , Tuple [EOL] import gluonts [EOL] import distribution_output [EOL] import typing [EOL] import builtins [EOL] import bijection_output [EOL] from collections import ChainMap [EOL] from typing import List , Optional , Tuple [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] from mxnet import gluon [EOL] [EOL] from gluonts . core . component import validated [EOL] [EOL] [comment] [EOL] from gluonts . model . common import Tensor [EOL] [EOL] from . import Distribution [EOL] from . bijection import AffineTransformation [EOL] from . bijection_output import BijectionOutput [EOL] from . distribution_output import ArgProj , DistributionOutput [EOL] from . transformed_distribution import TransformedDistribution [EOL] [EOL] [EOL] class TransformedDistributionOutput ( DistributionOutput ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , base_distr_output , transforms_output , ) : [EOL] super ( ) . __init__ ( ) [EOL] self . base_distr_output = base_distr_output [EOL] self . transforms_output = transforms_output [EOL] [EOL] self . base_distr_args_dim = base_distr_output . args_dim [EOL] self . transforms_args_dim = [ transform . args_dim for transform in transforms_output ] [EOL] [EOL] def _fuse ( t1 , t2 ) : [EOL] if len ( t1 ) > len ( t2 ) : [EOL] t1 , t2 = t2 , t1 [EOL] [comment] [EOL] assert t2 [ - len ( t1 ) : ] == t1 [EOL] return t2 [EOL] [EOL] self . _event_shape = ( ) [EOL] for to in self . transforms_output : [EOL] self . _event_shape = _fuse ( self . _event_shape , to . event_shape ) [EOL] [EOL] def get_args_proj ( self , prefix = None ) : [EOL] return ArgProj ( args_dim = dict ( self . base_distr_args_dim , ** dict ( ChainMap ( * self . transforms_args_dim ) ) , ) , domain_map = gluon . nn . HybridLambda ( self . domain_map ) , prefix = prefix , ) [EOL] [EOL] def _split_args ( self , args ) : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] num_distr_args = len ( self . base_distr_args_dim ) [EOL] distr_args = args [ [number] : num_distr_args ] [EOL] [EOL] num_transforms_args = [ len ( transform_dim_args ) for transform_dim_args in self . transforms_args_dim ] [EOL] [comment] [EOL] num_args_cumsum = np . cumsum ( [ num_distr_args ] + num_transforms_args ) [EOL] [EOL] [comment] [EOL] transforms_args = list ( map ( lambda ixs : args [ ixs [ [number] ] : ixs [ [number] ] ] , zip ( num_args_cumsum , num_args_cumsum [ [number] : ] ) , ) ) [EOL] [EOL] return distr_args , transforms_args [EOL] [EOL] def domain_map ( self , F , * args ) : [EOL] distr_args , transforms_args = self . _split_args ( args ) [EOL] [EOL] distr_params = self . base_distr_output . domain_map ( F , * distr_args ) [EOL] transforms_params = [ transform_output . domain_map ( F , * transform_args ) for transform_output , transform_args in zip ( self . transforms_output , transforms_args ) ] [EOL] [EOL] [comment] [EOL] return sum ( tuple ( [ distr_params ] + transforms_params ) , ( ) ) [EOL] [EOL] def distribution ( self , distr_args , loc = None , scale = None , ) : [EOL] distr_args , transforms_args = self . _split_args ( distr_args ) [EOL] distr = self . base_distr_output . distr_cls ( * distr_args ) [EOL] transforms = [ transform_output . bij_cls ( * bij_args ) for transform_output , bij_args in zip ( self . transforms_output , transforms_args ) ] [EOL] [EOL] trans_distr = TransformedDistribution ( distr , transforms ) [EOL] [EOL] [comment] [EOL] if loc is None and scale is None : [EOL] return trans_distr [EOL] else : [EOL] return TransformedDistribution ( trans_distr , [ AffineTransformation ( loc = loc , scale = scale ) ] ) [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return self . _event_shape [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $distribution_output.ArgProj$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $Distribution$ 0 0 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Any , Optional , Tuple [EOL] import distribution [EOL] import gluonts [EOL] import distribution_output [EOL] import mixture [EOL] import typing [EOL] import builtins [EOL] from typing import Tuple , Optional [EOL] [EOL] [comment] [EOL] from mxnet import gluon [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] [EOL] [comment] [EOL] from . distribution import ( Distribution , getF , nans_like , ) [EOL] from . distribution_output import DistributionOutput [EOL] from . mixture import MixtureDistribution [EOL] from . deterministic import Deterministic [EOL] [EOL] [EOL] class NanMixture ( MixtureDistribution ) : [EOL] [docstring] [EOL] [EOL] is_reparameterizable = False [EOL] [EOL] @ validated ( ) def __init__ ( self , nan_prob , distribution , F = None ) : [EOL] [EOL] F = getF ( nan_prob ) [EOL] [EOL] mixture_probs = F . stack ( [number] - nan_prob , nan_prob , axis = - [number] ) [EOL] super ( ) . __init__ ( mixture_probs = mixture_probs , components = [ distribution , Deterministic ( value = nans_like ( nan_prob ) ) , ] , ) [EOL] [EOL] @ property def distribution ( self ) : [EOL] return self . components [ [number] ] [EOL] [EOL] @ property def nan_prob ( self ) : [EOL] return self . mixture_probs . slice_axis ( axis = - [number] , begin = [number] , end = [number] ) . squeeze ( axis = - [number] ) [EOL] [EOL] def log_prob ( self , x ) : [EOL] F = self . F [EOL] [EOL] [comment] [EOL] x_non_nan = F . where ( x != x , F . ones_like ( x ) , x ) [EOL] [EOL] [comment] [EOL] non_nan_dist_log_likelihood = F . where ( x != x , - x . ones_like ( ) / [number] , self . components [ [number] ] . log_prob ( x_non_nan ) , ) [EOL] [EOL] log_mix_weights = F . log ( self . mixture_probs ) [EOL] [EOL] [comment] [EOL] component_log_likelihood = F . stack ( * [ non_nan_dist_log_likelihood , self . components [ [number] ] . log_prob ( x ) ] , axis = - [number] , ) [EOL] [comment] [EOL] summands = log_mix_weights + component_log_likelihood [EOL] max_val = F . max_axis ( summands , axis = - [number] , keepdims = True ) [EOL] [EOL] sum_exp = F . sum ( F . exp ( F . broadcast_minus ( summands , max_val ) ) , axis = - [number] , keepdims = True ) [EOL] [EOL] log_sum_exp = F . log ( sum_exp ) + max_val [EOL] return log_sum_exp . squeeze ( axis = - [number] ) [EOL] [EOL] [EOL] class NanMixtureArgs ( gluon . HybridBlock ) : [EOL] def __init__ ( self , distr_output , prefix = None , ) : [EOL] super ( ) . __init__ ( ) [EOL] self . component_projection = ... [EOL] with self . name_scope ( ) : [EOL] self . proj_nan_prob = gluon . nn . HybridSequential ( ) [EOL] self . proj_nan_prob . add ( gluon . nn . Dense ( [number] , prefix = f"{ prefix } [string] " , flatten = False ) ) [EOL] self . proj_nan_prob . add ( gluon . nn . HybridLambda ( [string] ) ) [EOL] [EOL] self . component_projection = distr_output . get_args_proj ( ) [EOL] [EOL] self . register_child ( self . component_projection ) [EOL] [EOL] def hybrid_forward ( self , F , x ) : [EOL] nan_prob = self . proj_nan_prob ( x ) [EOL] component_args = self . component_projection ( x ) [EOL] return tuple ( [ nan_prob . squeeze ( axis = - [number] ) , component_args ] ) [EOL] [EOL] [EOL] class NanMixtureOutput ( DistributionOutput ) : [EOL] distr_cls = NanMixture [EOL] [EOL] @ validated ( ) def __init__ ( self , distr_output ) : [EOL] self . distr_output = distr_output [EOL] [EOL] def get_args_proj ( self , prefix = None ) : [EOL] return NanMixtureArgs ( self . distr_output , prefix = prefix ) [EOL] [EOL] [comment] [EOL] def distribution ( self , distr_args , loc = None , scale = None , ** kwargs , ) : [EOL] nan_prob = distr_args [ [number] ] [EOL] component_args = distr_args [ [number] ] [EOL] return NanMixture ( nan_prob = nan_prob , distribution = self . distr_output . distribution ( component_args , loc = loc , scale = scale ) , ) [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return self . distr_output . event_shape [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $gluonts.model.common.Tensor$ 0 $NanMixture.distribution.Distribution$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 $NanMixture.distribution.Distribution$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $distribution_output.DistributionOutput$ 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $distribution_output.DistributionOutput$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,...]$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Any$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 $typing.Any$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.type$ 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $NanMixtureArgs$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 $mixture.MixtureDistribution$ 0 0 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 $typing.Optional[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import DirichletOutput [EOL] from typing import List , Optional , Tuple [EOL] import distribution [EOL] import typing [EOL] import builtins [EOL] import gluonts [EOL] from typing import List , Optional , Tuple [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from gluonts . core . component import DType , validated [EOL] from gluonts . model . common import Tensor [EOL] [EOL] from . distribution import Distribution , _sample_multiple , getF [EOL] from . distribution_output import DistributionOutput [EOL] [EOL] [EOL] class Dirichlet ( Distribution ) : [EOL] [docstring] [EOL] [EOL] is_reparameterizable = False [EOL] [EOL] @ validated ( ) def __init__ ( self , alpha , float_type = np . float32 ) : [EOL] self . alpha = alpha [EOL] self . float_type = float_type [EOL] [EOL] @ property def F ( self ) : [EOL] return getF ( self . alpha ) [EOL] [EOL] @ property def args ( self ) : [EOL] return [ self . alpha ] [EOL] [EOL] @ property def batch_shape ( self ) : [EOL] return self . alpha . shape [ : - [number] ] [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return self . alpha . shape [ - [number] : ] [EOL] [EOL] @ property def event_dim ( self ) : [EOL] return [number] [EOL] [EOL] def log_prob ( self , x ) : [EOL] F = self . F [EOL] [EOL] [comment] [EOL] sum_x = F . sum ( x , axis = - [number] ) . expand_dims ( axis = - [number] ) [EOL] x = F . broadcast_div ( x , sum_x ) [EOL] [EOL] alpha = self . alpha [EOL] [EOL] sum_alpha = F . sum ( alpha , axis = - [number] ) [EOL] log_beta = F . sum ( F . gammaln ( alpha ) , axis = - [number] ) - F . gammaln ( sum_alpha ) [EOL] [EOL] l_x = F . sum ( ( alpha - [number] ) * F . log ( x ) , axis = - [number] ) [EOL] ll = l_x - log_beta [EOL] return ll [EOL] [EOL] @ property def mean ( self ) : [EOL] F = self . F [EOL] alpha = self . alpha [EOL] [EOL] sum_alpha = F . sum ( alpha , axis = - [number] ) [EOL] return F . broadcast_div ( alpha , sum_alpha . expand_dims ( axis = - [number] ) ) [EOL] [EOL] @ property def variance ( self ) : [EOL] F = self . F [EOL] alpha = self . alpha [EOL] d = int ( F . ones_like ( self . alpha ) . sum ( axis = - [number] ) . max ( ) . asscalar ( ) ) [EOL] [EOL] scale = F . sqrt ( F . sum ( alpha , axis = - [number] ) + [number] ) . expand_dims ( axis = - [number] ) [EOL] scaled_alpha = F . broadcast_div ( self . mean , scale ) [EOL] [EOL] cross = F . linalg_gemm2 ( scaled_alpha . expand_dims ( axis = - [number] ) , scaled_alpha . expand_dims ( axis = - [number] ) , transpose_b = True , ) [EOL] [EOL] diagonal = F . broadcast_div ( scaled_alpha , scale ) * F . eye ( d ) [EOL] [EOL] return diagonal - cross [EOL] [EOL] def sample ( self , num_samples = None , dtype = np . float32 ) : [EOL] def s ( alpha ) : [EOL] F = getF ( alpha ) [EOL] samples_gamma = F . sample_gamma ( alpha = alpha , beta = F . ones_like ( alpha ) , dtype = dtype ) [EOL] sum_gamma = F . sum ( samples_gamma , axis = - [number] , keepdims = True ) [EOL] samples_s = F . broadcast_div ( samples_gamma , sum_gamma ) [EOL] [EOL] return samples_s [EOL] [EOL] samples = _sample_multiple ( s , alpha = self . alpha , num_samples = num_samples ) [EOL] [EOL] return samples [EOL] [EOL] [EOL] class DirichletOutput ( DistributionOutput ) : [EOL] @ validated ( ) def __init__ ( self , dim ) : [EOL] super ( ) . __init__ ( self ) [EOL] assert dim > [number] , [string] [EOL] self . args_dim = { [string] : dim } [EOL] self . distr_cls = Dirichlet [EOL] self . dim = dim [EOL] self . mask = None [EOL] [EOL] def distribution ( self , distr_args , loc = None , scale = None ) : [EOL] distr = Dirichlet ( distr_args ) [EOL] return distr [EOL] [EOL] def domain_map ( self , F , alpha_vector ) : [EOL] [comment] [EOL] alpha = F . Activation ( alpha_vector , act_type = [string] ) [EOL] return alpha [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( self . dim , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $DirichletOutput.distribution.Distribution$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional , Tuple [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] import mxnet [EOL] from typing import List , Optional , Tuple [EOL] [EOL] [comment] [EOL] import mxnet as mx [EOL] import numpy as np [EOL] from mxnet import gluon [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] [EOL] [comment] [EOL] from . distribution import Distribution , _sample_multiple , getF [EOL] from . distribution_output import DistributionOutput [EOL] [EOL] [EOL] class Binned ( Distribution ) : [EOL] [docstring] [EOL] [EOL] is_reparameterizable = False [EOL] [EOL] @ validated ( ) def __init__ ( self , bin_log_probs , bin_centers , label_smoothing = None , ) : [EOL] self . bin_centers = bin_centers [EOL] self . bin_log_probs = bin_log_probs [EOL] self . _bin_probs = None [EOL] [EOL] self . bin_edges = Binned . _compute_edges ( self . F , bin_centers ) [EOL] self . label_smoothing = label_smoothing [EOL] [EOL] @ property def F ( self ) : [EOL] return getF ( self . bin_log_probs ) [EOL] [EOL] @ staticmethod def _compute_edges ( F , bin_centers ) : [EOL] [docstring] [EOL] [EOL] low = ( F . zeros_like ( bin_centers . slice_axis ( axis = - [number] , begin = [number] , end = [number] ) ) - [number] ) [EOL] high = ( F . zeros_like ( bin_centers . slice_axis ( axis = - [number] , begin = [number] , end = [number] ) ) + [number] ) [EOL] [EOL] means = ( F . broadcast_add ( bin_centers . slice_axis ( axis = - [number] , begin = [number] , end = None ) , bin_centers . slice_axis ( axis = - [number] , begin = [number] , end = - [number] ) , ) / [number] ) [EOL] [EOL] return F . concat ( low , means , high , dim = - [number] ) [EOL] [EOL] @ property def bin_probs ( self ) : [EOL] if self . _bin_probs is None : [EOL] self . _bin_probs = self . bin_log_probs . exp ( ) [EOL] return self . _bin_probs [EOL] [EOL] @ property def batch_shape ( self ) : [EOL] return self . bin_log_probs . shape [ : - [number] ] [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL] [EOL] @ property def event_dim ( self ) : [EOL] return [number] [EOL] [EOL] @ property def mean ( self ) : [EOL] F = self . F [EOL] return F . broadcast_mul ( self . bin_probs , self . bin_centers ) . sum ( axis = - [number] ) [EOL] [EOL] @ property def stddev ( self ) : [EOL] F = self . F [EOL] ex2 = F . broadcast_mul ( self . bin_probs , self . bin_centers . square ( ) ) . sum ( axis = - [number] ) [EOL] return F . broadcast_minus ( ex2 , self . mean . square ( ) ) . sqrt ( ) [EOL] [EOL] def _get_mask ( self , x ) : [EOL] F = self . F [EOL] [comment] [EOL] left_edges = self . bin_edges . slice_axis ( axis = - [number] , begin = [number] , end = - [number] ) [EOL] right_edges = self . bin_edges . slice_axis ( axis = - [number] , begin = [number] , end = None ) [EOL] mask = F . broadcast_mul ( F . broadcast_lesser_equal ( left_edges , x ) , F . broadcast_lesser ( x , right_edges ) , ) [EOL] return mask [EOL] [EOL] @ staticmethod def _smooth_mask ( F , mask , alpha ) : [EOL] return F . broadcast_add ( F . broadcast_mul ( mask , F . broadcast_sub ( F . ones_like ( alpha ) , alpha ) ) , F . broadcast_mul ( F . softmax ( F . ones_like ( mask ) ) , alpha ) , ) [EOL] [EOL] def smooth_ce_loss ( self , x ) : [EOL] [docstring] [EOL] assert self . label_smoothing is not None [EOL] F = self . F [EOL] x = x . expand_dims ( axis = - [number] ) [EOL] mask = self . _get_mask ( x ) [EOL] [EOL] alpha = F . full ( shape = ( [number] , ) , val = self . label_smoothing ) [EOL] smooth_mask = self . _smooth_mask ( F , mask , alpha ) [EOL] [EOL] return - F . broadcast_mul ( self . bin_log_probs , smooth_mask ) . sum ( axis = - [number] ) [EOL] [EOL] def log_prob ( self , x ) : [EOL] F = self . F [EOL] x = x . expand_dims ( axis = - [number] ) [EOL] mask = self . _get_mask ( x ) [EOL] return F . broadcast_mul ( self . bin_log_probs , mask ) . sum ( axis = - [number] ) [EOL] [EOL] def cdf ( self , x ) : [EOL] F = self . F [EOL] x = x . expand_dims ( axis = - [number] ) [EOL] [comment] [EOL] mask = F . broadcast_lesser_equal ( self . bin_centers , x ) [EOL] return F . broadcast_mul ( self . bin_probs , mask ) . sum ( axis = - [number] ) [EOL] [EOL] def loss ( self , x ) : [EOL] return ( self . smooth_ce_loss ( x ) [EOL] if self . label_smoothing [EOL] else - self . log_prob ( x ) ) [EOL] [EOL] def quantile ( self , level ) : [EOL] F = self . F [EOL] [EOL] [comment] [EOL] probs = self . bin_probs . transpose ( ) [comment] [EOL] [EOL] [comment] [EOL] zeros_batch_size = F . zeros_like ( F . slice_axis ( self . bin_probs , axis = - [number] , begin = [number] , end = [number] ) . squeeze ( axis = - [number] ) ) [EOL] [EOL] level = level . expand_dims ( axis = [number] ) [EOL] [EOL] [comment] [EOL] zeros_cdf = F . broadcast_add ( zeros_batch_size . transpose ( ) . expand_dims ( axis = - [number] ) , level . zeros_like ( ) , ) [EOL] start_state = ( zeros_cdf , zeros_cdf . astype ( [string] ) ) [EOL] [EOL] def step ( p , state ) : [EOL] cdf , idx = state [EOL] cdf = F . broadcast_add ( cdf , p . expand_dims ( axis = - [number] ) ) [EOL] idx = F . where ( F . broadcast_greater ( cdf , level ) , idx , idx + [number] ) [EOL] return zeros_batch_size , ( cdf , idx ) [EOL] [EOL] _ , states = F . contrib . foreach ( step , probs , start_state ) [EOL] _ , idx = states [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] centers_expanded = F . broadcast_add ( self . bin_centers . transpose ( ) . expand_dims ( axis = - [number] ) , zeros_cdf . expand_dims ( axis = [number] ) , ) . transpose ( ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] a = centers_expanded . pick ( idx . transpose ( ) , axis = - [number] ) [EOL] return a [EOL] [EOL] def sample ( self , num_samples = None , dtype = np . float32 ) : [EOL] def s ( bin_probs ) : [EOL] F = self . F [EOL] indices = F . sample_multinomial ( bin_probs ) [EOL] if num_samples is None : [EOL] return self . bin_centers . pick ( indices , - [number] ) . reshape_like ( F . zeros_like ( indices . astype ( [string] ) ) ) [EOL] else : [EOL] return F . repeat ( F . expand_dims ( self . bin_centers , axis = [number] ) , repeats = num_samples , axis = [number] , ) . pick ( indices , - [number] ) [EOL] [EOL] return _sample_multiple ( s , self . bin_probs , num_samples = num_samples ) [EOL] [EOL] @ property def args ( self ) : [EOL] return [ self . bin_log_probs , self . bin_centers ] [EOL] [EOL] [EOL] class BinnedArgs ( gluon . HybridBlock ) : [EOL] def __init__ ( self , num_bins , bin_centers , ** kwargs ) : [EOL] super ( ) . __init__ ( ** kwargs ) [EOL] self . num_bins = num_bins [EOL] with self . name_scope ( ) : [EOL] self . bin_centers = self . params . get_constant ( [string] , bin_centers ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] self . proj = gluon . nn . HybridSequential ( ) [EOL] self . proj . add ( gluon . nn . Dense ( self . num_bins , prefix = [string] , flatten = False , weight_initializer = mx . init . Xavier ( ) , ) ) [EOL] self . proj . add ( gluon . nn . HybridLambda ( [string] ) ) [EOL] [EOL] def hybrid_forward ( self , F , x , bin_centers ) : [EOL] ps = self . proj ( x ) [EOL] reshaped_probs = ps . reshape ( shape = ( - [number] , - [number] , self . num_bins ) , reverse = [number] ) [EOL] bin_centers = F . broadcast_add ( bin_centers , ps . zeros_like ( ) ) [EOL] return reshaped_probs , bin_centers [EOL] [EOL] [EOL] class BinnedOutput ( DistributionOutput ) : [EOL] distr_cls = Binned [EOL] [EOL] @ validated ( ) def __init__ ( self , bin_centers , label_smoothing = None , ) : [EOL] assert label_smoothing is None or ( [number] <= label_smoothing < [number] ) , [string] [EOL] super ( ) . __init__ ( self ) [EOL] self . bin_centers = bin_centers [EOL] self . num_bins = self . bin_centers . shape [ [number] ] [EOL] self . label_smoothing = label_smoothing [EOL] assert len ( self . bin_centers . shape ) == [number] [EOL] [EOL] def get_args_proj ( self , * args , ** kwargs ) : [EOL] return BinnedArgs ( self . num_bins , self . bin_centers ) [EOL] [EOL] @ staticmethod def _scale_bin_centers ( F , bin_centers , loc = None , scale = None ) : [EOL] if scale is not None : [EOL] bin_centers = F . broadcast_mul ( bin_centers , scale . expand_dims ( axis = - [number] ) ) [EOL] if loc is not None : [EOL] bin_centers = F . broadcast_add ( bin_centers , loc . expand_dims ( axis = - [number] ) ) [EOL] [EOL] return bin_centers [EOL] [EOL] def distribution ( self , args , loc = None , scale = None ) : [EOL] probs = args [ [number] ] [EOL] bin_centers = args [ [number] ] [EOL] F = getF ( probs ) [EOL] [EOL] bin_centers = F . broadcast_mul ( bin_centers , F . ones_like ( probs ) ) [EOL] bin_centers = self . _scale_bin_centers ( F , bin_centers , loc = loc , scale = scale ) [EOL] [EOL] return Binned ( probs , bin_centers , label_smoothing = self . label_smoothing ) [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor]$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.type$ 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.nn.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $Binned$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Any , Optional , Tuple , Type [EOL] import typing [EOL] import builtins [EOL] import gluonts [EOL] import src [EOL] import math [EOL] from typing import Optional , Tuple [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] from gluonts . support . linalg_util import lower_triangular_ones [EOL] [EOL] from . distribution import Distribution , _sample_multiple , getF [EOL] from . distribution_output import DistributionOutput [EOL] [EOL] [EOL] class MultivariateGaussian ( Distribution ) : [EOL] [docstring] [EOL] [EOL] is_reparameterizable = True [EOL] [EOL] @ validated ( ) def __init__ ( self , mu , L , F = None ) : [EOL] self . mu = mu [EOL] self . L = L [EOL] [EOL] @ property def F ( self ) : [EOL] return getF ( self . mu ) [EOL] [EOL] def __getitem__ ( self , item ) : [EOL] raise NotImplementedError ( ) [EOL] [EOL] @ property def batch_shape ( self ) : [EOL] return self . mu . shape [ : - [number] ] [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return self . mu . shape [ - [number] : ] [EOL] [EOL] @ property def event_dim ( self ) : [EOL] return [number] [EOL] [EOL] def log_prob ( self , x ) : [EOL] [comment] [EOL] F = self . F [EOL] [EOL] [comment] [EOL] d = F . ones_like ( self . mu ) . sum ( axis = - [number] ) . max ( ) [EOL] [EOL] residual = ( x - self . mu ) . expand_dims ( axis = - [number] ) [EOL] [EOL] [comment] [EOL] L_inv_times_residual = F . linalg_trsm ( self . L , residual ) [EOL] [EOL] ll = ( F . broadcast_sub ( - d / [number] * math . log ( [number] * math . pi ) , F . linalg_sumlogdiag ( self . L ) ) - [number] / [number] * F . linalg_syrk ( L_inv_times_residual , transpose = True ) . squeeze ( ) ) [EOL] [EOL] return ll [EOL] [EOL] @ property def mean ( self ) : [EOL] return self . mu [EOL] [EOL] @ property def variance ( self ) : [EOL] return self . F . linalg_gemm2 ( self . L , self . L , transpose_b = True ) [EOL] [EOL] def sample_rep ( self , num_samples = None , dtype = np . float32 ) : [EOL] [docstring] [EOL] [EOL] def s ( mu , L ) : [EOL] F = self . F [EOL] samples_std_normal = F . sample_normal ( mu = F . zeros_like ( mu ) , sigma = F . ones_like ( mu ) , dtype = dtype , ) . expand_dims ( axis = - [number] ) [EOL] samples = ( F . linalg_gemm2 ( L , samples_std_normal ) . squeeze ( axis = - [number] ) + mu ) [EOL] return samples [EOL] [EOL] return _sample_multiple ( s , mu = self . mu , L = self . L , num_samples = num_samples ) [EOL] [EOL] [EOL] class MultivariateGaussianOutput ( DistributionOutput ) : [EOL] @ validated ( ) def __init__ ( self , dim ) : [EOL] self . args_dim = { [string] : dim , [string] : dim * dim } [EOL] self . distr_cls = MultivariateGaussian [EOL] self . dim = dim [EOL] self . mask = None [EOL] [EOL] def domain_map ( self , F , mu_vector , L_vector ) : [EOL] [comment] [EOL] [comment] [EOL] d = self . dim [EOL] [EOL] [comment] [EOL] L_matrix = L_vector . reshape ( ( - [number] , d , d , - [number] ) , reverse = [number] ) [EOL] [EOL] L_diag = F . broadcast_mul ( F . Activation ( F . broadcast_mul ( L_matrix , F . eye ( d ) ) , act_type = [string] ) , F . eye ( d ) , ) [EOL] [EOL] mask = lower_triangular_ones ( F , d , offset = [number] ) [EOL] [EOL] L_low = F . broadcast_mul ( L_matrix , mask ) [EOL] [EOL] return mu_vector , L_diag + L_low [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( self . dim , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 $typing.Type[src.gluonts.mx.distribution.multivariate_gaussian.MultivariateGaussian]$ 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional , Tuple , Dict [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] import math [EOL] from functools import partial [EOL] from typing import Dict , List , Optional , Tuple [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] [EOL] [EOL] [comment] [EOL] from gluonts . model . common import Tensor [EOL] from gluonts . support . util import erf , erfinv [EOL] from gluonts . core . component import validated [EOL] [EOL] [comment] [EOL] from . distribution import Distribution , _sample_multiple , getF , softplus [EOL] from . distribution_output import DistributionOutput [EOL] [EOL] [EOL] class Gaussian ( Distribution ) : [EOL] [docstring] [EOL] [EOL] is_reparameterizable = True [EOL] [EOL] @ validated ( ) def __init__ ( self , mu , sigma ) : [EOL] self . mu = mu [EOL] self . sigma = sigma [EOL] [EOL] @ property def F ( self ) : [EOL] return getF ( self . mu ) [EOL] [EOL] @ property def batch_shape ( self ) : [EOL] return self . mu . shape [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL] [EOL] @ property def event_dim ( self ) : [EOL] return [number] [EOL] [EOL] def log_prob ( self , x ) : [EOL] F = self . F [EOL] mu , sigma = self . mu , self . sigma [EOL] return - [number] * ( F . log ( sigma ) + [number] * math . log ( [number] * math . pi ) + [number] * F . square ( ( x - mu ) / sigma ) ) [EOL] [EOL] @ property def mean ( self ) : [EOL] return self . mu [EOL] [EOL] @ property def stddev ( self ) : [EOL] return self . sigma [EOL] [EOL] def cdf ( self , x ) : [EOL] F = self . F [EOL] u = F . broadcast_div ( F . broadcast_minus ( x , self . mu ) , self . sigma * math . sqrt ( [number] ) ) [EOL] return ( erf ( F , u ) + [number] ) / [number] [EOL] [EOL] def sample ( self , num_samples = None , dtype = np . float32 ) : [EOL] return _sample_multiple ( partial ( self . F . sample_normal , dtype = dtype ) , mu = self . mu , sigma = self . sigma , num_samples = num_samples , ) [EOL] [EOL] def sample_rep ( self , num_samples = None , dtype = np . float32 ) : [EOL] def s ( mu , sigma ) : [EOL] raw_samples = self . F . sample_normal ( mu = mu . zeros_like ( ) , sigma = sigma . ones_like ( ) , dtype = dtype ) [EOL] return sigma * raw_samples + mu [EOL] [EOL] return _sample_multiple ( s , mu = self . mu , sigma = self . sigma , num_samples = num_samples ) [EOL] [EOL] def quantile ( self , level ) : [EOL] F = self . F [EOL] [comment] [EOL] [comment] [EOL] for _ in range ( self . all_dim ) : [EOL] level = level . expand_dims ( axis = - [number] ) [EOL] [EOL] return F . broadcast_add ( self . mu , F . broadcast_mul ( self . sigma , math . sqrt ( [number] ) * erfinv ( F , [number] * level - [number] ) ) , ) [EOL] [EOL] @ property def args ( self ) : [EOL] return [ self . mu , self . sigma ] [EOL] [EOL] [EOL] class GaussianOutput ( DistributionOutput ) : [EOL] args_dim = { [string] : [number] , [string] : [number] } [EOL] distr_cls = Gaussian [EOL] [EOL] @ classmethod def domain_map ( cls , F , mu , sigma ) : [EOL] [docstring] [EOL] sigma = softplus ( F , sigma ) [EOL] return mu . squeeze ( axis = - [number] ) , sigma . squeeze ( axis = - [number] ) [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.type$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Any , Tuple , Dict [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] from typing import Dict , List , Tuple [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] [EOL] from gluonts . core . component import validated [EOL] [EOL] [comment] [EOL] from gluonts . model . common import Tensor [EOL] [EOL] [comment] [EOL] from . distribution import Distribution , _sample_multiple , getF , softplus [EOL] from . distribution_output import DistributionOutput [EOL] [EOL] [EOL] class Laplace ( Distribution ) : [EOL] [docstring] [EOL] [EOL] is_reparameterizable = True [EOL] [EOL] @ validated ( ) def __init__ ( self , mu , b ) : [EOL] self . mu = mu [EOL] self . b = b [EOL] [EOL] @ property def F ( self ) : [EOL] return getF ( self . mu ) [EOL] [EOL] @ property def batch_shape ( self ) : [EOL] return self . mu . shape [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL] [EOL] @ property def event_dim ( self ) : [EOL] return [number] [EOL] [EOL] def log_prob ( self , x ) : [EOL] F = self . F [EOL] return - [number] * ( F . log ( [number] * self . b ) + F . abs ( ( x - self . mu ) / self . b ) ) [EOL] [EOL] @ property def mean ( self ) : [EOL] return self . mu [EOL] [EOL] @ property def stddev ( self ) : [EOL] return [number] ** [number] * self . b [EOL] [EOL] def cdf ( self , x ) : [EOL] y = ( x - self . mu ) / self . b [EOL] return [number] + [number] * y . sign ( ) * ( [number] - self . F . exp ( - y . abs ( ) ) ) [EOL] [EOL] def sample_rep ( self , num_samples = None , dtype = np . float32 ) : [EOL] F = self . F [EOL] [EOL] def s ( mu , b ) : [EOL] ones = mu . ones_like ( ) [EOL] x = F . random . uniform ( - [number] * ones , [number] * ones , dtype = dtype ) [EOL] laplace_samples = mu - b * F . sign ( x ) * F . log ( ( [number] - [number] * F . abs ( x ) ) . clip ( [number] , [number] ) ) [EOL] return laplace_samples [EOL] [EOL] return _sample_multiple ( s , mu = self . mu , b = self . b , num_samples = num_samples ) [EOL] [EOL] def quantile ( self , level ) : [EOL] F = self . F [EOL] for _ in range ( self . all_dim ) : [EOL] level = level . expand_dims ( axis = - [number] ) [EOL] [EOL] condition = F . broadcast_greater ( level , level . zeros_like ( ) + [number] ) [EOL] u = F . where ( condition , F . log ( [number] * level ) , - F . log ( [number] - [number] * level ) ) [EOL] [EOL] return F . broadcast_add ( self . mu , F . broadcast_mul ( self . b , u ) ) [EOL] [EOL] @ property def args ( self ) : [EOL] return [ self . mu , self . b ] [EOL] [EOL] [EOL] class LaplaceOutput ( DistributionOutput ) : [EOL] args_dim = { [string] : [number] , [string] : [number] } [EOL] distr_cls = Laplace [EOL] [EOL] @ classmethod def domain_map ( cls , F , mu , b ) : [EOL] b = softplus ( F , b ) [EOL] return mu . squeeze ( axis = - [number] ) , b . squeeze ( axis = - [number] ) [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Any$ 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Any$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.List$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.type$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import DirichletMultinomialOutput [EOL] from typing import Any , Optional , Tuple , Type [EOL] import distribution [EOL] import gluonts [EOL] import src [EOL] import typing [EOL] import builtins [EOL] from typing import Optional , Tuple [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from gluonts . core . component import DType , validated [EOL] from gluonts . model . common import Tensor [EOL] [EOL] from . distribution import Distribution , _sample_multiple , getF [EOL] from . distribution_output import DistributionOutput [EOL] [EOL] [EOL] class DirichletMultinomial ( Distribution ) : [EOL] [docstring] [EOL] [EOL] is_reparameterizable = False [EOL] [EOL] @ validated ( ) def __init__ ( self , dim , n_trials , alpha , float_type = np . float32 , ) : [EOL] self . dim = dim [EOL] self . n_trials = n_trials [EOL] self . alpha = alpha [EOL] self . float_type = float_type [EOL] [EOL] @ property def F ( self ) : [EOL] return getF ( self . alpha ) [EOL] [EOL] @ property def batch_shape ( self ) : [EOL] return self . alpha . shape [ : - [number] ] [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return self . alpha . shape [ - [number] : ] [EOL] [EOL] @ property def event_dim ( self ) : [EOL] return [number] [EOL] [EOL] def log_prob ( self , x ) : [EOL] F = self . F [EOL] n_trials = self . n_trials [EOL] alpha = self . alpha [EOL] [EOL] sum_alpha = F . sum ( alpha , axis = - [number] ) [EOL] [EOL] ll = ( F . gammaln ( sum_alpha ) + F . gammaln ( F . ones_like ( sum_alpha ) * ( n_trials + [number] ) ) - F . gammaln ( sum_alpha + n_trials ) ) [EOL] [EOL] beta_matrix = ( F . gammaln ( x + alpha ) - F . gammaln ( x + [number] ) - F . gammaln ( alpha ) ) [EOL] [EOL] ll = ll + F . sum ( beta_matrix , axis = - [number] ) [EOL] [EOL] return ll [EOL] [EOL] @ property def mean ( self ) : [EOL] F = self . F [EOL] alpha = self . alpha [EOL] n_trials = self . n_trials [EOL] [EOL] sum_alpha = F . sum ( alpha , axis = - [number] ) [EOL] return ( F . broadcast_div ( alpha , sum_alpha . expand_dims ( axis = - [number] ) ) * n_trials ) [EOL] [EOL] @ property def variance ( self ) : [EOL] F = self . F [EOL] alpha = self . alpha [EOL] d = self . dim [EOL] n_trials = self . n_trials [EOL] [EOL] sum_alpha = F . sum ( alpha , axis = - [number] ) [EOL] scale = F . sqrt ( ( sum_alpha + [number] ) / ( sum_alpha + n_trials ) / n_trials ) . expand_dims ( axis = - [number] ) [EOL] scaled_alpha = F . broadcast_div ( self . mean / n_trials , scale ) [EOL] [EOL] cross = F . linalg_gemm2 ( scaled_alpha . expand_dims ( axis = - [number] ) , scaled_alpha . expand_dims ( axis = - [number] ) , transpose_b = True , ) [EOL] [EOL] diagonal = F . broadcast_div ( scaled_alpha , scale ) * F . eye ( d ) [EOL] [EOL] dir_variance = diagonal - cross [EOL] [EOL] return dir_variance [EOL] [EOL] def sample ( self , num_samples = None , dtype = np . float32 ) : [EOL] dim = self . dim [EOL] n_trials = self . n_trials [EOL] [EOL] def s ( alpha ) : [EOL] F = getF ( alpha ) [EOL] samples_gamma = F . sample_gamma ( alpha = alpha , beta = F . ones_like ( alpha ) , dtype = dtype ) [EOL] sum_gamma = F . sum ( samples_gamma , axis = - [number] , keepdims = True ) [EOL] samples_s = F . broadcast_div ( samples_gamma , sum_gamma ) [EOL] [EOL] cat_samples = F . sample_multinomial ( samples_s , shape = n_trials ) [EOL] return F . sum ( F . one_hot ( cat_samples , dim ) , axis = - [number] ) [EOL] [EOL] samples = _sample_multiple ( s , alpha = self . alpha , num_samples = num_samples ) [EOL] [EOL] return samples [EOL] [EOL] [EOL] class DirichletMultinomialOutput ( DistributionOutput ) : [EOL] @ validated ( ) def __init__ ( self , dim , n_trials ) : [EOL] super ( ) . __init__ ( self ) [EOL] assert dim > [number] , [string] [EOL] self . dim = dim [EOL] self . n_trials = n_trials [EOL] self . args_dim = { [string] : dim } [EOL] self . distr_cls = DirichletMultinomial [EOL] self . dim = dim [EOL] self . mask = None [EOL] [EOL] def distribution ( self , distr_args , loc = None , scale = None ) : [EOL] distr = DirichletMultinomial ( self . dim , self . n_trials , distr_args ) [EOL] return distr [EOL] [EOL] def domain_map ( self , F , alpha_vector ) : [EOL] [comment] [EOL] alpha = F . Activation ( alpha_vector , act_type = [string] ) [EOL] return alpha [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( self . dim , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $builtins.int$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 $builtins.int$ 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Any$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Any$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $typing.Type[src.gluonts.mx.distribution.dirichlet_multinomial.DirichletMultinomial]$ 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 $DirichletMultinomialOutput.distribution.Distribution$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Any , Tuple , Dict [EOL] import distribution [EOL] import typing [EOL] import builtins [EOL] import gluonts [EOL] from typing import Dict , List , Tuple [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] from gluonts . support . util import erfinv [EOL] [EOL] [comment] [EOL] from . distribution import Distribution , _sample_multiple , getF , softplus [EOL] from . distribution_output import DistributionOutput [EOL] [EOL] [EOL] class LogitNormal ( Distribution ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , mu , sigma ) : [EOL] super ( ) . __init__ ( ) [EOL] self . mu = mu [EOL] self . sigma = sigma [EOL] [EOL] @ property def F ( self ) : [EOL] return getF ( self . mu ) [EOL] [EOL] @ property def batch_shape ( self ) : [EOL] return self . mu . shape [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL] [EOL] @ property def event_dim ( self ) : [EOL] return [number] [EOL] [EOL] def log_prob ( self , x ) : [EOL] F = self . F [EOL] x_clip = [number] [EOL] x = F . clip ( x , x_clip , [number] - x_clip ) [EOL] log_prob = - [number] * ( F . log ( self . sigma ) + F . log ( F . sqrt ( [number] * F . full ( [number] , np . pi ) ) ) + F . log ( x ) + F . log ( [number] - x ) + ( ( F . log ( x ) - F . log ( [number] - x ) - self . mu ) ** [number] / ( [number] * ( self . sigma ** [number] ) ) ) ) [EOL] return log_prob [EOL] [EOL] def sample ( self , num_samples = None , dtype = np . float32 ) : [EOL] def s ( mu ) : [EOL] F = self . F [EOL] q_min = [number] [EOL] q_max = [number] - q_min [EOL] sample = F . sample_uniform ( F . ones_like ( mu ) * F . full ( [number] , q_min ) , F . ones_like ( mu ) * F . full ( [number] , q_max ) , ) [EOL] transf_sample = self . quantile ( sample ) [EOL] return transf_sample [EOL] [EOL] mult_samp = _sample_multiple ( s , self . mu , num_samples = num_samples ) [EOL] return mult_samp [EOL] [EOL] def quantile ( self , level ) : [EOL] F = self . F [EOL] exp = F . exp ( self . mu + ( self . sigma * F . sqrt ( F . full ( [number] , [number] ) ) * erfinv ( F , [number] * level - [number] ) ) ) [EOL] return exp / ( [number] + exp ) [EOL] [EOL] @ property def args ( self ) : [EOL] return [ self . mu , self . sigma ] [EOL] [EOL] [EOL] class LogitNormalOutput ( DistributionOutput ) : [EOL] args_dim = { [string] : [number] , [string] : [number] } [EOL] distr_cls = LogitNormal [EOL] [EOL] @ classmethod def domain_map ( cls , F , mu , sigma ) : [EOL] sigma = softplus ( F , sigma ) [EOL] return mu . squeeze ( axis = - [number] ) , sigma . squeeze ( axis = - [number] ) [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL] [EOL] def distribution ( self , distr_args , loc = None , scale = None , ** kwargs ) : [EOL] return self . distr_cls ( * distr_args ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.List$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.type$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 $LogitNormalOutput.distribution.Distribution$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Tuple , Dict [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] from typing import Dict , Tuple [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] from gluonts . core . component import validated [EOL] [EOL] [comment] [EOL] from gluonts . model . common import Tensor [EOL] [EOL] [comment] [EOL] from . distribution import getF , softplus [EOL] from . distribution_output import DistributionOutput [EOL] from . beta import Beta [EOL] from . mixture import MixtureDistribution [EOL] from . deterministic import Deterministic [EOL] [EOL] [EOL] class ZeroAndOneInflatedBeta ( MixtureDistribution ) : [EOL] [docstring] [EOL] [EOL] is_reparameterizable = False [EOL] [EOL] @ validated ( ) def __init__ ( self , alpha , beta , zero_probability , one_probability , ) : [EOL] F = getF ( alpha ) [EOL] self . alpha = alpha [EOL] self . beta = beta [EOL] self . zero_probability = zero_probability [EOL] self . one_probability = one_probability [EOL] self . beta_probability = [number] - zero_probability - one_probability [EOL] self . beta_distribution = Beta ( alpha = alpha , beta = beta ) [EOL] mixture_probs = F . stack ( zero_probability , one_probability , self . beta_probability , axis = - [number] ) [EOL] super ( ) . __init__ ( components = [ Deterministic ( alpha . zeros_like ( ) ) , Deterministic ( alpha . ones_like ( ) ) , self . beta_distribution , ] , mixture_probs = mixture_probs , ) [EOL] [EOL] def log_prob ( self , x ) : [EOL] F = self . F [EOL] [EOL] [comment] [EOL] inputs = F . where ( F . logical_or ( x == [number] , x == [number] ) , x . zeros_like ( ) + [number] , x ) [EOL] [EOL] [comment] [EOL] return F . where ( x == [number] , F . log ( self . one_probability . broadcast_like ( x ) ) , F . where ( x == [number] , F . log ( self . zero_probability . broadcast_like ( x ) ) , F . log ( self . beta_probability ) + self . beta_distribution . log_prob ( inputs ) , ) , ) [EOL] [EOL] [EOL] class ZeroInflatedBeta ( ZeroAndOneInflatedBeta ) : [EOL] [docstring] [EOL] is_reparameterizable = False [EOL] [EOL] @ validated ( ) def __init__ ( self , alpha , beta , zero_probability ) : [EOL] super ( ) . __init__ ( alpha = alpha , beta = beta , zero_probability = zero_probability , one_probability = alpha . zeros_like ( ) , ) [EOL] [EOL] [EOL] class OneInflatedBeta ( ZeroAndOneInflatedBeta ) : [EOL] [docstring] [EOL] is_reparameterizable = False [EOL] [EOL] @ validated ( ) def __init__ ( self , alpha , beta , one_probability ) : [EOL] super ( ) . __init__ ( alpha = alpha , beta = beta , zero_probability = alpha . zeros_like ( ) , one_probability = one_probability , ) [EOL] [EOL] [EOL] class ZeroAndOneInflatedBetaOutput ( DistributionOutput ) : [EOL] args_dim = { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , } [EOL] distr_cls = ZeroAndOneInflatedBeta [EOL] [EOL] @ classmethod def domain_map ( cls , F , alpha , beta , zero_probability , one_probability ) : [EOL] [docstring] [EOL] epsilon = np . finfo ( cls . _dtype ) . eps [comment] [EOL] [EOL] alpha = softplus ( F , alpha ) + epsilon [EOL] beta = softplus ( F , beta ) + epsilon [EOL] zero_probability = F . sigmoid ( zero_probability ) [EOL] one_probability = ( [number] - zero_probability ) * F . sigmoid ( one_probability ) [EOL] return ( alpha . squeeze ( axis = - [number] ) , beta . squeeze ( axis = - [number] ) , zero_probability . squeeze ( axis = - [number] ) , one_probability . squeeze ( axis = - [number] ) , ) [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL] [EOL] @ property def value_in_support ( self ) : [EOL] return [number] [EOL] [EOL] [EOL] class ZeroInflatedBetaOutput ( ZeroAndOneInflatedBetaOutput ) : [EOL] args_dim = { [string] : [number] , [string] : [number] , [string] : [number] } [EOL] distr_cls = ZeroInflatedBeta [EOL] [EOL] @ classmethod def domain_map ( cls , F , alpha , beta , zero_probability ) : [EOL] [docstring] [EOL] epsilon = np . finfo ( cls . _dtype ) . eps [comment] [EOL] [EOL] alpha = softplus ( F , alpha ) + epsilon [EOL] beta = softplus ( F , beta ) + epsilon [EOL] zero_probability = F . sigmoid ( zero_probability ) [EOL] return ( alpha . squeeze ( axis = - [number] ) , beta . squeeze ( axis = - [number] ) , zero_probability . squeeze ( axis = - [number] ) , ) [EOL] [EOL] [EOL] class OneInflatedBetaOutput ( ZeroInflatedBetaOutput ) : [EOL] args_dim = { [string] : [number] , [string] : [number] , [string] : [number] } [EOL] distr_cls = OneInflatedBeta [EOL] [EOL] @ classmethod def domain_map ( cls , F , alpha , beta , one_probability ) : [EOL] return super ( ) . domain_map ( F , alpha , beta , one_probability ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.type$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.type$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.type$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Any , Tuple , List , Dict , Optional [EOL] import typing [EOL] import builtins [EOL] import gluonts [EOL] from functools import partial [EOL] from typing import Dict , List , Optional , Tuple [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] [EOL] from gluonts . core . component import validated [EOL] [EOL] [comment] [EOL] from gluonts . model . common import Tensor [EOL] [EOL] [comment] [EOL] from . distribution import Distribution , _sample_multiple , getF , softplus [EOL] from . distribution_output import DistributionOutput [EOL] [EOL] [EOL] class Uniform ( Distribution ) : [EOL] [docstring] [EOL] [EOL] is_reparameterizable = True [EOL] [EOL] @ validated ( ) def __init__ ( self , low , high ) : [EOL] self . low = low [EOL] self . high = high [EOL] [EOL] @ property def F ( self ) : [EOL] return getF ( self . low ) [EOL] [EOL] @ property def batch_shape ( self ) : [EOL] return self . low . shape [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL] [EOL] @ property def event_dim ( self ) : [EOL] return [number] [EOL] [EOL] def log_prob ( self , x ) : [EOL] F = self . F [EOL] is_in_range = F . broadcast_greater_equal ( x , self . low ) * F . broadcast_lesser ( x , self . high ) [EOL] return F . log ( is_in_range ) - F . log ( self . high - self . low ) [EOL] [EOL] @ property def mean ( self ) : [EOL] return ( self . high + self . low ) / [number] [EOL] [EOL] @ property def stddev ( self ) : [EOL] return ( self . high - self . low ) / ( [number] ** [number] ) [EOL] [EOL] def sample ( self , num_samples = None , dtype = np . float32 ) : [EOL] return _sample_multiple ( partial ( self . F . sample_uniform , dtype = dtype ) , low = self . low , high = self . high , num_samples = num_samples , ) [EOL] [EOL] def sample_rep ( self , num_samples = None , dtype = np . float32 ) : [EOL] def s ( low , high ) : [EOL] raw_samples = self . F . sample_uniform ( low = low . zeros_like ( ) , high = high . ones_like ( ) , dtype = dtype ) [EOL] return low + raw_samples * ( high - low ) [EOL] [EOL] return _sample_multiple ( s , low = self . low , high = self . high , num_samples = num_samples ) [EOL] [EOL] def cdf ( self , x ) : [EOL] return self . F . broadcast_div ( x - self . low , self . high - self . low ) [EOL] [EOL] def quantile ( self , level ) : [EOL] F = self . F [EOL] for _ in range ( self . all_dim ) : [EOL] level = level . expand_dims ( axis = - [number] ) [EOL] return F . broadcast_add ( F . broadcast_mul ( self . high - self . low , level ) , self . low ) [EOL] [EOL] @ property def args ( self ) : [EOL] return [ self . low , self . high ] [EOL] [EOL] [EOL] class UniformOutput ( DistributionOutput ) : [EOL] args_dim = { [string] : [number] , [string] : [number] } [EOL] distr_cls = Uniform [EOL] [EOL] @ classmethod def domain_map ( cls , F , low , width ) : [EOL] high = low + softplus ( F , width ) [EOL] return low . squeeze ( axis = - [number] ) , high . squeeze ( axis = - [number] ) [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $typing.Any$ 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.type$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Tuple [EOL] import typing [EOL] import bijection [EOL] import gluonts [EOL] from typing import Tuple [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] [EOL] from . bijection import Bijection [EOL] from . distribution_output import Output [EOL] [EOL] [EOL] class BijectionOutput ( Output ) : [EOL] [docstring] [EOL] [EOL] bij_cls = ... [EOL] [EOL] @ validated ( ) def __init__ ( self ) : [EOL] pass [EOL] [EOL] def domain_map ( self , F , * args ) : [EOL] raise NotImplementedError ( ) [EOL] [EOL] def bijection ( self , bij_args ) : [EOL] return self . bij_cls ( * bij_args ) [EOL] [EOL] @ property def event_shape ( self ) : [EOL] raise NotImplementedError ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.type$ 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 $BijectionOutput.bijection.Bijection$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional , Tuple , Dict [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] from functools import partial [EOL] from typing import Dict , List , Optional , Tuple [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] [EOL] from gluonts . core . component import validated [EOL] [EOL] [comment] [EOL] from gluonts . model . common import Tensor [EOL] [EOL] [comment] [EOL] from . distribution import Distribution , _sample_multiple , getF , softplus [EOL] from . distribution_output import DistributionOutput [EOL] [EOL] [EOL] class Gamma ( Distribution ) : [EOL] [docstring] [EOL] [EOL] is_reparameterizable = False [EOL] [EOL] @ validated ( ) def __init__ ( self , alpha , beta ) : [EOL] self . alpha = alpha [EOL] self . beta = beta [EOL] [EOL] @ property def F ( self ) : [EOL] return getF ( self . alpha ) [EOL] [EOL] @ property def batch_shape ( self ) : [EOL] return self . alpha . shape [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL] [EOL] @ property def event_dim ( self ) : [EOL] return [number] [EOL] [EOL] def log_prob ( self , x ) : [EOL] F = self . F [EOL] alpha , beta = self . alpha , self . beta [EOL] [EOL] return ( alpha * F . log ( beta ) - F . gammaln ( alpha ) + ( alpha - [number] ) * F . log ( x ) - beta * x ) [EOL] [EOL] @ property def mean ( self ) : [EOL] return self . alpha / self . beta [EOL] [EOL] @ property def stddev ( self ) : [EOL] return self . F . sqrt ( self . alpha ) / self . beta [EOL] [EOL] def sample ( self , num_samples = None , dtype = np . float32 ) : [EOL] epsilon = np . finfo ( dtype ) . eps [comment] [EOL] F = self . F [EOL] [EOL] samples = _sample_multiple ( partial ( F . sample_gamma , dtype = dtype ) , alpha = self . alpha , beta = [number] / self . beta , num_samples = num_samples , ) [EOL] return F . clip ( data = samples , a_min = epsilon , a_max = np . finfo ( dtype ) . max ) [EOL] [EOL] @ property def args ( self ) : [EOL] return [ self . alpha , self . beta ] [EOL] [EOL] [EOL] class GammaOutput ( DistributionOutput ) : [EOL] args_dim = { [string] : [number] , [string] : [number] } [EOL] distr_cls = Gamma [EOL] [EOL] @ classmethod def domain_map ( cls , F , alpha , beta ) : [EOL] [docstring] [EOL] epsilon = np . finfo ( cls . _dtype ) . eps [comment] [EOL] [EOL] alpha = softplus ( F , alpha ) + epsilon [EOL] beta = softplus ( F , beta ) + epsilon [EOL] return alpha . squeeze ( axis = - [number] ) , beta . squeeze ( axis = - [number] ) [EOL] [EOL] @ property def event_shape ( self ) : [EOL] return ( ) [EOL] [EOL] @ property def value_in_support ( self ) : [EOL] return [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.type$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import builtins [EOL] import mxnet as mx [EOL] import numpy as np [EOL] [EOL] [EOL] class MetricAttentiveScheduler ( mx . lr_scheduler . LRScheduler ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , objective , patience , base_lr = [number] , decay_factor = [number] , min_lr = [number] , ) : [EOL] [EOL] assert base_lr > [number] , f" [string] { base_lr }" [EOL] [EOL] assert ( base_lr > min_lr ) , f" [string] { base_lr } [string] { min_lr }" [EOL] [EOL] assert ( [number] < decay_factor < [number] ) , f" [string] { decay_factor }" [EOL] [EOL] assert patience >= [number] , f" [string] { patience }" [EOL] [EOL] assert objective in [ [string] , [string] , ] , f" [string] { objective }" [EOL] [EOL] super ( MetricAttentiveScheduler , self ) . __init__ ( base_lr = base_lr ) [EOL] [EOL] self . decay_factor = decay_factor [EOL] self . patience = patience [EOL] self . objective = objective [EOL] self . min_lr = min_lr [EOL] self . best_metric = np . Inf if objective == [string] else - np . Inf [EOL] self . prev_change = [number] [EOL] self . epoch_no = [number] [EOL] self . curr_lr = None [EOL] [EOL] def __call__ ( self , num_update ) : [EOL] if self . curr_lr is None : [EOL] self . curr_lr = self . base_lr [EOL] assert self . curr_lr is not None [EOL] [EOL] return self . curr_lr [EOL] [EOL] def step ( self , metric_value ) : [EOL] [docstring] [EOL] if self . curr_lr is None : [EOL] self . curr_lr = self . base_lr [EOL] assert self . curr_lr is not None [EOL] [EOL] metric_improved = ( self . objective == [string] and metric_value < self . best_metric ) or ( self . objective == [string] and metric_value > self . best_metric ) [EOL] [EOL] if metric_improved : [EOL] self . best_metric = metric_value [EOL] self . prev_change = self . epoch_no [EOL] [EOL] if ( self . epoch_no - self . prev_change >= self . patience or not np . isfinite ( metric_value ) ) : [EOL] if self . curr_lr == self . min_lr : [EOL] return False [EOL] self . curr_lr = max ( self . min_lr , self . decay_factor * self . curr_lr ) [EOL] self . prev_change = self . epoch_no [EOL] [EOL] self . epoch_no += [number] [EOL] return True [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from . import learning_rate_scheduler as lrs [EOL] from . import model_averaging [EOL] from . import model_iteration_averaging [EOL] from . _base import Trainer [EOL] [EOL] __all__ = [ [string] , [string] , [string] , [string] ] [EOL] [EOL] [comment] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Any , Union , Optional [EOL] import model_iteration_averaging [EOL] import model_averaging [EOL] import mxnet [EOL] import gluonts [EOL] import typing [EOL] import builtins [EOL] import logging [EOL] import os [EOL] import tempfile [EOL] import time [EOL] import uuid [EOL] from typing import Any , List , Optional , Union [EOL] [EOL] [comment] [EOL] import mxnet as mx [EOL] import mxnet . autograd as autograd [EOL] import mxnet . gluon . nn as nn [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . core . exception import GluonTSDataError , GluonTSUserError [EOL] from gluonts . dataset . loader import TrainDataLoader , ValidationDataLoader [EOL] from gluonts . gluonts_tqdm import tqdm [EOL] from gluonts . mx . context import get_mxnet_context [EOL] from gluonts . support . util import HybridContext [EOL] [EOL] [comment] [EOL] from . import learning_rate_scheduler as lrs [EOL] from . model_averaging import ( AveragingStrategy , SelectNBestMean , save_epoch_info , ) [EOL] from . model_iteration_averaging import IterationAveragingStrategy [EOL] [EOL] logger = logging . getLogger ( [string] ) . getChild ( [string] ) [EOL] [EOL] [EOL] MODEL_ARTIFACT_FILE_NAME = [string] [EOL] STATE_ARTIFACT_FILE_NAME = [string] [EOL] [EOL] [comment] [EOL] mx . autograd = autograd [EOL] [EOL] [EOL] def check_loss_finite ( val ) : [EOL] if not np . isfinite ( val ) : [EOL] raise GluonTSDataError ( [string] [string] ) [EOL] [EOL] [EOL] def loss_value ( loss ) : [EOL] return loss . get_name_value ( ) [ [number] ] [ [number] ] [EOL] [EOL] [EOL] class Trainer : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , ctx = None , epochs = [number] , batch_size = [number] , num_batches_per_epoch = [number] , learning_rate = [number] , learning_rate_decay_factor = [number] , patience = [number] , minimum_learning_rate = [number] , clip_gradient = [number] , weight_decay = [number] , init = [string] , hybridize = True , avg_strategy = SelectNBestMean ( num_models = [number] ) , ) : [EOL] [EOL] assert ( [number] <= epochs < float ( [string] ) ) , [string] [EOL] assert [number] < batch_size , [string] [EOL] assert ( [number] < num_batches_per_epoch ) , [string] [EOL] assert ( [number] < learning_rate < float ( [string] ) ) , [string] [EOL] assert ( [number] <= learning_rate_decay_factor < [number] ) , [string] [EOL] assert [number] <= patience , [string] [EOL] assert ( [number] <= minimum_learning_rate ) , [string] [EOL] assert [number] < clip_gradient , [string] [EOL] assert [number] <= weight_decay , [string] [EOL] [EOL] self . epochs = epochs [EOL] self . batch_size = batch_size [EOL] self . num_batches_per_epoch = num_batches_per_epoch [EOL] self . learning_rate = learning_rate [EOL] self . learning_rate_decay_factor = learning_rate_decay_factor [EOL] self . patience = patience [EOL] self . minimum_learning_rate = minimum_learning_rate [EOL] self . clip_gradient = clip_gradient [EOL] self . weight_decay = weight_decay [EOL] self . init = init [EOL] self . hybridize = hybridize [EOL] self . avg_strategy = avg_strategy [EOL] self . ctx = ctx if ctx is not None else get_mxnet_context ( ) [EOL] self . halt = False [EOL] [EOL] def set_halt ( self , signum , stack_frame ) : [EOL] logger . info ( [string] . format ( signum ) ) [EOL] self . halt = True [EOL] [EOL] def count_model_params ( self , net ) : [EOL] params = net . collect_params ( ) [EOL] num_params = [number] [EOL] for p in params : [EOL] v = params [ p ] [EOL] num_params += np . prod ( v . shape ) [EOL] return num_params [EOL] [EOL] def __call__ ( self , net , input_names , train_iter , validation_iter = None , ) : [comment] [EOL] is_validation_available = validation_iter is not None [EOL] self . halt = False [EOL] [EOL] with tempfile . TemporaryDirectory ( prefix = [string] ) as gluonts_temp : [EOL] [EOL] def base_path ( ) : [EOL] return os . path . join ( gluonts_temp , [string] . format ( STATE_ARTIFACT_FILE_NAME , uuid . uuid4 ( ) ) , ) [EOL] [EOL] logger . info ( [string] ) [EOL] [EOL] net . initialize ( ctx = self . ctx , init = self . init ) [EOL] [EOL] with HybridContext ( net = net , hybridize = self . hybridize , static_alloc = True , static_shape = True , ) : [EOL] batch_size = train_iter . batch_size [EOL] [EOL] best_epoch_info = { [string] : [string] % ( base_path ( ) , [string] ) , [string] : - [number] , [string] : np . Inf , } [EOL] [EOL] lr_scheduler = lrs . MetricAttentiveScheduler ( objective = [string] , patience = self . patience , decay_factor = self . learning_rate_decay_factor , min_lr = self . minimum_learning_rate , ) [EOL] [EOL] optimizer = mx . optimizer . Adam ( learning_rate = self . learning_rate , lr_scheduler = lr_scheduler , wd = self . weight_decay , clip_gradient = self . clip_gradient , ) [EOL] [EOL] trainer = mx . gluon . Trainer ( net . collect_params ( ) , optimizer = optimizer , kvstore = [string] , ) [EOL] [EOL] def loop ( epoch_no , batch_iter , is_training = True ) : [EOL] tic = time . time ( ) [EOL] [EOL] epoch_loss = mx . metric . Loss ( ) [EOL] [EOL] [comment] [EOL] if not is_training and isinstance ( self . avg_strategy , IterationAveragingStrategy ) : [EOL] self . avg_strategy . load_averaged_model ( net ) [EOL] [EOL] with tqdm ( batch_iter ) as it : [EOL] for batch_no , data_entry in enumerate ( it , start = [number] ) : [EOL] if self . halt : [EOL] break [EOL] [EOL] inputs = [ data_entry [ k ] for k in input_names ] [EOL] [EOL] with mx . autograd . record ( ) : [EOL] output = net ( * inputs ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] if isinstance ( output , ( list , tuple ) ) : [EOL] loss = output [ [number] ] [EOL] else : [EOL] loss = output [EOL] [EOL] if is_training : [EOL] loss . backward ( ) [EOL] trainer . step ( batch_size ) [EOL] [EOL] [comment] [EOL] if isinstance ( self . avg_strategy , IterationAveragingStrategy , ) : [EOL] self . avg_strategy . apply ( net ) [EOL] [EOL] epoch_loss . update ( None , preds = loss ) [EOL] lv = loss_value ( epoch_loss ) [EOL] [EOL] if not np . isfinite ( lv ) : [EOL] logger . warning ( [string] , epoch_no ) [EOL] return epoch_loss [EOL] [EOL] it . set_postfix ( ordered_dict = { [string] : f"{ epoch_no + [number] } [string] { self . epochs }" , ( [string] if is_training else [string] ) + [string] : lv , } , refresh = False , ) [EOL] [comment] [EOL] if batch_no == [number] and epoch_no == [number] : [EOL] net_name = type ( net ) . __name__ [EOL] num_model_param = self . count_model_params ( net ) [EOL] logger . info ( f" [string] { net_name } [string] { num_model_param }" ) [EOL] [comment] [EOL] toc = time . time ( ) [EOL] logger . info ( [string] , epoch_no , ( toc - tic ) , ) [EOL] [EOL] logger . info ( [string] , epoch_no , ( [string] if is_training else [string] ) + [string] , lv , ) [EOL] [EOL] if not is_training and isinstance ( self . avg_strategy , IterationAveragingStrategy ) : [EOL] [comment] [EOL] self . avg_strategy . load_cached_model ( net ) [EOL] [EOL] return epoch_loss [EOL] [EOL] for epoch_no in range ( self . epochs ) : [EOL] if self . halt : [EOL] logger . info ( f" [string] { epoch_no } [string] " ) [EOL] break [EOL] [EOL] curr_lr = trainer . learning_rate [EOL] logger . info ( f" [string] { epoch_no } [string] { curr_lr }" ) [EOL] [EOL] epoch_loss = loop ( epoch_no , train_iter ) [EOL] if is_validation_available : [EOL] epoch_loss = loop ( epoch_no , validation_iter , is_training = False ) [EOL] [EOL] [comment] [EOL] if isinstance ( self . avg_strategy , IterationAveragingStrategy ) : [EOL] self . avg_strategy . update_average_trigger ( metric = loss_value ( epoch_loss ) , epoch = epoch_no + [number] ) [EOL] [comment] [EOL] self . avg_strategy . apply ( net ) [EOL] [EOL] should_continue = lr_scheduler . step ( loss_value ( epoch_loss ) ) [EOL] if isinstance ( self . avg_strategy , IterationAveragingStrategy ) : [EOL] logging . info ( [string] ) [EOL] should_continue = True [EOL] if not should_continue : [EOL] logger . info ( [string] ) [EOL] break [EOL] [EOL] [comment] [EOL] bp = base_path ( ) [EOL] epoch_info = { [string] : f"{ bp } [string] " , [string] : epoch_no , [string] : loss_value ( epoch_loss ) , } [EOL] [EOL] net . save_parameters ( epoch_info [ [string] ] ) [comment] [EOL] [EOL] save_epoch_info ( bp , epoch_info ) [EOL] [EOL] [comment] [EOL] if loss_value ( epoch_loss ) < best_epoch_info [ [string] ] : [EOL] best_epoch_info = epoch_info . copy ( ) [EOL] [EOL] if not trainer . learning_rate == curr_lr : [EOL] if best_epoch_info [ [string] ] == - [number] : [EOL] raise GluonTSUserError ( [string] ) [EOL] [EOL] logger . info ( f" [string] " f" [string] { best_epoch_info [ [string] ] } [string] " ) [EOL] net . load_parameters ( best_epoch_info [ [string] ] , self . ctx ) [EOL] [EOL] if isinstance ( self . avg_strategy , AveragingStrategy ) : [EOL] logging . info ( [string] ) [EOL] averaged_params_path = self . avg_strategy . apply ( gluonts_temp ) [EOL] [EOL] logging . info ( [string] ) [EOL] net . load_parameters ( averaged_params_path , self . ctx ) [EOL] [EOL] if isinstance ( self . avg_strategy , IterationAveragingStrategy ) : [EOL] logging . info ( [string] ) [EOL] self . avg_strategy . load_averaged_model ( net ) [EOL] [EOL] logger . info ( [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.int$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $mxnet.gluon.nn.HybridBlock$ 0 0 0 0 0 $mxnet.gluon.nn.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $mxnet.gluon.nn.HybridBlock$ 0 $typing.List[builtins.str]$ 0 $gluonts.dataset.loader.TrainDataLoader$ 0 $typing.Optional[gluonts.dataset.loader.ValidationDataLoader]$ 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.dataset.loader.ValidationDataLoader]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.nn.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.nn.HybridBlock$ 0 $mxnet.gluon.nn.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.loader.TrainDataLoader$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.nn.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.metric.Loss$ 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.loader.TrainDataLoader$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[gluonts.dataset.loader.ValidationDataLoader]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.nn.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.nn.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.nn.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.nn.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.nn.HybridBlock$ 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Tuple , Dict [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] import math [EOL] from typing import Dict , Tuple [EOL] [EOL] [comment] [EOL] from gluonts . model . common import Tensor [EOL] from gluonts . mx . distribution . distribution import getF , softplus [EOL] [EOL] [comment] [EOL] from . import Kernel , KernelOutputDict [EOL] [EOL] [EOL] class PeriodicKernel ( Kernel ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] def __init__ ( self , amplitude , length_scale , frequency , F = None , ) : [EOL] [docstring] [EOL] self . F = F if F else getF ( amplitude ) [EOL] self . amplitude = amplitude [EOL] self . length_scale = length_scale [EOL] self . frequency = frequency [EOL] [EOL] [comment] [EOL] def kernel_matrix ( self , x1 , x2 ) : [EOL] [docstring] [EOL] self . _compute_square_dist ( self . F , x1 , x2 ) [EOL] [EOL] return self . F . broadcast_mul ( self . amplitude , self . F . exp ( self . F . broadcast_div ( - [number] * self . F . sin ( self . F . broadcast_mul ( self . frequency , math . pi * self . F . sqrt ( self . F . abs ( self . square_dist ) ) , ) ) ** [number] , self . length_scale ** [number] , ) ) , ) [EOL] [EOL] [EOL] class PeriodicKernelOutput ( KernelOutputDict ) : [EOL] args_dim = { [string] : [number] , [string] : [number] , [string] : [number] , } [EOL] kernel_cls = PeriodicKernel [EOL] [EOL] [comment] [EOL] def gp_params_scaling ( self , F , past_target , past_time_feat ) : [EOL] [docstring] [EOL] axis = [number] [EOL] sigma_scaling = ( self . compute_std ( F , past_target , axis = axis ) / math . sqrt ( [number] ) ) . expand_dims ( axis = axis ) [EOL] amplitude_scaling = sigma_scaling ** [number] [EOL] length_scale_scaling = F . broadcast_mul ( F . mean ( self . compute_std ( F , past_time_feat , axis = axis ) ) , F . ones_like ( amplitude_scaling ) , ) [EOL] [comment] [EOL] frequency_scaling = F . ones_like ( amplitude_scaling ) [EOL] return ( amplitude_scaling , length_scale_scaling , frequency_scaling , sigma_scaling , ) [EOL] [EOL] [comment] [EOL] @ classmethod def domain_map ( cls , F , amplitude , length_scale , frequency ) : [EOL] [docstring] [EOL] amplitude = softplus ( F , amplitude ) [EOL] length_scale = softplus ( F , length_scale ) [EOL] frequency = softplus ( F , frequency ) [EOL] return amplitude , length_scale , frequency [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import gluonts [EOL] from gluonts . model . common import Tensor [EOL] [EOL] [EOL] class Kernel : [EOL] [comment] [EOL] def kernel_matrix ( self , x1 , x2 ) : [EOL] [comment] [EOL] raise NotImplementedError ( ) [EOL] [EOL] [comment] [EOL] def _compute_square_dist ( self , F , x1 , x2 ) : [EOL] [docstring] [EOL] feature_axis = [number] [EOL] [comment] [EOL] x1_norm_square = ( F . norm ( x1 , ord = [number] , axis = feature_axis ) ** [number] ) . expand_dims ( [number] ) [EOL] [comment] [EOL] x2_norm_square = ( F . norm ( x2 , ord = [number] , axis = feature_axis ) ** [number] ) . expand_dims ( [number] ) [EOL] x1x2_trans = F . linalg . gemm2 ( x1 , x2 , transpose_b = True ) [EOL] self . square_dist = F . broadcast_add ( F . broadcast_sub ( x1_norm_square , [number] * x1x2_trans ) , x2_norm_square ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Tuple [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] import mxnet [EOL] from typing import Dict , Tuple [EOL] [EOL] import numpy as np [EOL] from mxnet import gluon [EOL] [EOL] [comment] [EOL] from gluonts . core . component import DType , validated [EOL] from gluonts . model . common import Tensor [EOL] from gluonts . mx . distribution . distribution_output import ArgProj [EOL] [EOL] [comment] [EOL] from . import Kernel [EOL] [EOL] [EOL] class KernelOutput : [EOL] [docstring] [EOL] [EOL] def get_args_proj ( self , float_type ) : [EOL] raise NotImplementedError ( ) [EOL] [EOL] def kernel ( self , args ) : [EOL] raise NotImplementedError ( ) [EOL] [EOL] [comment] [EOL] @ staticmethod def compute_std ( F , data , axis ) : [EOL] [docstring] [EOL] return F . sqrt ( F . mean ( F . broadcast_minus ( data , F . mean ( data , axis = axis ) . expand_dims ( axis = axis ) ) ** [number] , axis = axis , ) ) [EOL] [EOL] [EOL] class KernelOutputDict ( KernelOutput ) : [EOL] args_dim = ... [EOL] kernel_cls = ... [EOL] [EOL] @ validated ( ) def __init__ ( self ) : [EOL] pass [EOL] [EOL] def get_num_args ( self ) : [EOL] return len ( self . args_dim ) [EOL] [EOL] def get_args_proj ( self , float_type = np . float32 ) : [EOL] [docstring] [EOL] return ArgProj ( args_dim = self . args_dim , domain_map = gluon . nn . HybridLambda ( self . domain_map ) , dtype = float_type , ) [EOL] [EOL] [comment] [EOL] def gp_params_scaling ( self , F , past_target , past_time_feat ) : [EOL] raise NotImplementedError ( ) [EOL] [EOL] [comment] [EOL] def domain_map ( self , F , * args ) : [EOL] raise NotImplementedError ( ) [EOL] [EOL] def kernel ( self , kernel_args ) : [EOL] [docstring] [EOL] return self . kernel_cls ( * kernel_args ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.int]$ 0 0 0 $builtins.type$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.mx.distribution.distribution_output.ArgProj$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor,gluonts.model.common.Tensor]$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 $Kernel$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from . _kernel import Kernel [EOL] from . _kernel_output import KernelOutput , KernelOutputDict [EOL] from . _periodic_kernel import PeriodicKernel , PeriodicKernelOutput [EOL] from . _rbf_kernel import RBFKernel , RBFKernelOutput [EOL] [EOL] __all__ = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , ] [EOL] [EOL] for item in __all__ : [EOL] if hasattr ( item , [string] ) : [EOL] setattr ( item , [string] , __name__ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Tuple [EOL] import gluonts [EOL] import typing [EOL] from typing import Tuple [EOL] [EOL] [comment] [EOL] from mxnet . gluon import nn [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] [EOL] [EOL] class Seq2SeqEnc2Dec ( nn . HybridBlock ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , ** kwargs ) : [EOL] super ( ) . __init__ ( ** kwargs ) [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , encoder_output_static , encoder_output_dynamic , future_features_dynamic , ) : [EOL] [docstring] [EOL] pass [EOL] [EOL] [EOL] class PassThroughEnc2Dec ( Seq2SeqEnc2Dec ) : [EOL] [docstring] [EOL] [EOL] def hybrid_forward ( self , F , encoder_output_static , encoder_output_dynamic , future_features_dynamic , ) : [EOL] [docstring] [EOL] return encoder_output_static , encoder_output_dynamic [EOL] [EOL] [EOL] class FutureFeatIntegratorEnc2Dec ( Seq2SeqEnc2Dec ) : [EOL] [docstring] [EOL] [EOL] def hybrid_forward ( self , F , encoder_output_static , encoder_output_dynamic , future_features_dynamic , ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] [comment] [EOL] future_features_dynamic = F . reshape ( future_features_dynamic , shape = ( [number] , [number] , - [number] ) ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] total_dec_input_dynamic = F . concat ( encoder_output_dynamic , future_features_dynamic , dim = [number] ) [EOL] [EOL] return ( encoder_output_static , total_dec_input_dynamic , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor]$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor]$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Tuple [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] from typing import List , Tuple [EOL] [EOL] [comment] [EOL] from mxnet . gluon import nn [EOL] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] [EOL] [comment] [EOL] from gluonts . mx . block . cnn import CausalConv1D [EOL] from gluonts . mx . block . mlp import MLP [EOL] from gluonts . mx . block . rnn import RNN [EOL] [EOL] [EOL] class Seq2SeqEncoder ( nn . HybridBlock ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , target , static_features , dynamic_features , ) : [EOL] [docstring] [EOL] raise NotImplementedError [EOL] [EOL] def _assemble_inputs ( self , F , target , static_features , dynamic_features , ) : [EOL] [docstring] [EOL] [EOL] helper_ones = F . ones_like ( target ) [comment] [EOL] tiled_static_features = F . batch_dot ( helper_ones , static_features . expand_dims ( [number] ) ) [comment] [EOL] inputs = F . concat ( target , tiled_static_features , dynamic_features , dim = [number] ) [comment] [EOL] return inputs [EOL] [EOL] [EOL] [comment] [EOL] class HierarchicalCausalConv1DEncoder ( Seq2SeqEncoder ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , dilation_seq , kernel_size_seq , channels_seq , use_residual = False , use_static_feat = False , use_dynamic_feat = False , ** kwargs , ) : [EOL] assert all ( [ x > [number] for x in dilation_seq ] ) , [string] [EOL] assert all ( [ x > [number] for x in kernel_size_seq ] ) , [string] [EOL] assert all ( [ x > [number] for x in channels_seq ] ) , [string] [EOL] [EOL] super ( ) . __init__ ( ** kwargs ) [EOL] [EOL] self . use_residual = use_residual [EOL] self . use_static_feat = use_static_feat [EOL] self . use_dynamic_feat = use_dynamic_feat [EOL] self . cnn = nn . HybridSequential ( ) [EOL] [EOL] it = zip ( channels_seq , kernel_size_seq , dilation_seq ) [EOL] for layer_no , ( channels , kernel_size , dilation ) in enumerate ( it ) : [EOL] convolution = CausalConv1D ( channels = channels , kernel_size = kernel_size , dilation = dilation , activation = [string] , prefix = f" [string] { layer_no : [string] } [string] " , ) [EOL] self . cnn . add ( convolution ) [EOL] [EOL] def hybrid_forward ( self , F , target , static_features , dynamic_features , ) : [EOL] [docstring] [EOL] [EOL] if self . use_dynamic_feat and self . use_static_feat : [EOL] inputs = self . _assemble_inputs ( F , target = target , static_features = static_features , dynamic_features = dynamic_features , ) [EOL] elif self . use_dynamic_feat : [EOL] inputs = F . concat ( target , dynamic_features , dim = [number] ) [comment] [EOL] else : [EOL] [comment] [EOL] inputs = target [EOL] [EOL] [comment] [EOL] ct = inputs . swapaxes ( [number] , [number] ) [EOL] ct = self . cnn ( ct ) [EOL] ct = ct . swapaxes ( [number] , [number] ) [EOL] [EOL] [comment] [EOL] if self . use_residual : [EOL] ct = F . concat ( ct , target , dim = [number] ) [EOL] [EOL] [comment] [EOL] static_code = F . slice_axis ( ct , axis = [number] , begin = - [number] , end = None ) [EOL] static_code = F . squeeze ( static_code , axis = [number] ) [EOL] [EOL] return static_code , ct [EOL] [EOL] [EOL] class RNNEncoder ( Seq2SeqEncoder ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , mode , hidden_size , num_layers , bidirectional , use_static_feat = False , use_dynamic_feat = False , ** kwargs , ) : [EOL] assert num_layers > [number] , [string] [EOL] assert hidden_size > [number] , [string] [EOL] [EOL] super ( ) . __init__ ( ** kwargs ) [EOL] [EOL] self . mode = mode [EOL] self . hidden_size = hidden_size [EOL] self . num_layers = num_layers [EOL] self . bidirectional = bidirectional [EOL] self . use_static_feat = use_static_feat [EOL] self . use_dynamic_feat = use_dynamic_feat [EOL] [EOL] with self . name_scope ( ) : [EOL] self . rnn = RNN ( mode , hidden_size , num_layers , bidirectional ) [EOL] [EOL] def hybrid_forward ( self , F , target , static_features , dynamic_features , ) : [EOL] [docstring] [EOL] if self . use_dynamic_feat and self . use_static_feat : [EOL] inputs = self . _assemble_inputs ( F , target = target , static_features = static_features , dynamic_features = dynamic_features , ) [EOL] elif self . use_dynamic_feat : [EOL] inputs = F . concat ( target , dynamic_features , dim = [number] ) [comment] [EOL] else : [EOL] inputs = target [EOL] [EOL] dynamic_code = self . rnn ( inputs ) [EOL] static_code = F . slice_axis ( dynamic_code , axis = [number] , begin = - [number] , end = None ) [EOL] return static_code , dynamic_code [EOL] [EOL] [EOL] class MLPEncoder ( Seq2SeqEncoder ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , layer_sizes , ** kwargs ) : [EOL] super ( ) . __init__ ( ** kwargs ) [EOL] self . model = MLP ( layer_sizes , flatten = True ) [EOL] [EOL] def hybrid_forward ( self , F , target , static_features , dynamic_features , ) : [EOL] [docstring] [EOL] [EOL] inputs = self . _assemble_inputs ( F , target , static_features , dynamic_features ) [EOL] static_code = self . model ( inputs ) [EOL] dynamic_code = F . zeros_like ( target ) . expand_dims ( [number] ) [EOL] return static_code , dynamic_code [EOL] [EOL] [EOL] class RNNCovariateEncoder ( RNNEncoder ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , use_static_feat = True , use_dynamic_feat = True , ** kwargs , ) : [EOL] super ( ) . __init__ ( use_static_feat = use_static_feat , use_dynamic_feat = use_dynamic_feat , ** kwargs , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor]$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $typing.List[builtins.int]$ 0 $typing.List[builtins.int]$ 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.int]$ 0 $typing.List[builtins.int]$ 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor]$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor]$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor]$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.bool$ 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 $builtins.bool$ 0 $builtins.bool$ 0 $builtins.bool$ 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Tuple [EOL] import gluonts [EOL] import builtins [EOL] import mxnet [EOL] import typing [EOL] from typing import Tuple [EOL] [EOL] [comment] [EOL] from mxnet . gluon . rnn import ( RecurrentCell , ModifierCell , BidirectionalCell , SequentialRNNCell , ) [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] [EOL] [EOL] class VariationalZoneoutCell ( ModifierCell ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , base_cell , zoneout_outputs = [number] , zoneout_states = [number] , ) : [EOL] assert not isinstance ( base_cell , BidirectionalCell ) , ( [string] [string] ) [EOL] assert ( not isinstance ( base_cell , SequentialRNNCell ) or not base_cell . _bidirectional ) , ( [string] [string] ) [EOL] super ( VariationalZoneoutCell , self ) . __init__ ( base_cell ) [EOL] self . zoneout_outputs = zoneout_outputs [EOL] self . zoneout_states = zoneout_states [EOL] self . _prev_output = None [EOL] [EOL] [comment] [EOL] self . zoneout_states_mask = None [EOL] self . zoneout_outputs_mask = None [EOL] [EOL] def __repr__ ( self ) : [EOL] s = [string] [EOL] return s . format ( name = self . __class__ . __name__ , ** self . __dict__ ) [EOL] [EOL] def _alias ( self ) : [EOL] return [string] [EOL] [EOL] def reset ( self ) : [EOL] super ( VariationalZoneoutCell , self ) . reset ( ) [EOL] self . _prev_output = None [EOL] [EOL] self . zoneout_states_mask = None [EOL] self . zoneout_outputs_mask = None [EOL] [EOL] def _initialize_states_masks ( self , F , states ) : [EOL] if self . zoneout_states and self . zoneout_states_mask is None : [EOL] self . zoneout_states_mask = [ F . Dropout ( F . ones_like ( state ) , p = self . zoneout_states ) for state in states ] [EOL] [EOL] def _initialize_outputs_mask ( self , F , output ) : [EOL] if self . zoneout_outputs and self . zoneout_outputs_mask is None : [EOL] self . zoneout_outputs_mask = F . Dropout ( F . ones_like ( output ) , p = self . zoneout_outputs ) [EOL] [EOL] def hybrid_forward ( self , F , inputs , states ) : [EOL] cell , p_outputs , p_states = ( self . base_cell , self . zoneout_outputs , self . zoneout_states , ) [EOL] next_output , next_states = cell ( inputs , states ) [EOL] [EOL] prev_output = self . _prev_output [EOL] if prev_output is None : [EOL] prev_output = F . zeros_like ( next_output ) [EOL] [EOL] self . _initialize_outputs_mask ( F , next_output ) [EOL] [EOL] output = ( F . where ( self . zoneout_outputs_mask , next_output , prev_output ) [EOL] if p_outputs != [number] [EOL] else next_output ) [EOL] [EOL] self . _initialize_states_masks ( F , next_states ) [EOL] [EOL] new_states = ( [ F . where ( state_mask , new_s , old_s ) for state_mask , new_s , old_s in zip ( self . zoneout_states_mask , next_states , states ) ] [EOL] if p_states != [number] [EOL] else next_states ) [EOL] [EOL] self . _prev_output = output [EOL] [EOL] return output , new_states [EOL] [EOL] [EOL] class RNNZoneoutCell ( ModifierCell ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , base_cell , zoneout_outputs = [number] , zoneout_states = [number] , ) : [EOL] assert not isinstance ( base_cell , BidirectionalCell ) , ( [string] [string] ) [EOL] assert ( not isinstance ( base_cell , SequentialRNNCell ) or not base_cell . _bidirectional ) , ( [string] [string] ) [EOL] super ( RNNZoneoutCell , self ) . __init__ ( base_cell ) [EOL] self . zoneout_outputs = zoneout_outputs [EOL] self . zoneout_states = zoneout_states [EOL] self . _prev_output = None [EOL] [EOL] def __repr__ ( self ) : [EOL] s = [string] [EOL] return s . format ( name = self . __class__ . __name__ , ** self . __dict__ ) [EOL] [EOL] def _alias ( self ) : [EOL] return [string] [EOL] [EOL] def reset ( self ) : [EOL] super ( RNNZoneoutCell , self ) . reset ( ) [EOL] self . _prev_output = None [EOL] [EOL] def hybrid_forward ( self , F , inputs , states ) : [EOL] cell , p_outputs , p_states = ( self . base_cell , self . zoneout_outputs , self . zoneout_states , ) [EOL] next_output , next_states = cell ( inputs , states ) [EOL] mask = lambda p , like : F . Dropout ( F . ones_like ( like ) , p = p ) [EOL] [EOL] prev_output = self . _prev_output [EOL] if prev_output is None : [EOL] prev_output = F . zeros_like ( next_output ) [EOL] [EOL] output_mask = mask ( p_outputs , next_output ) [EOL] output = ( F . where ( output_mask , next_output , prev_output ) [EOL] if p_outputs != [number] [EOL] else next_output ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] new_states = [ F . where ( output_mask , next_states [ [number] ] , states [ [number] ] ) [EOL] if p_outputs != [number] [EOL] else next_states [ [number] ] ] [EOL] new_states . extend ( [ F . where ( mask ( p_states , new_s ) , new_s , old_s ) for new_s , old_s in zip ( next_states [ [number] : ] , states [ [number] : ] ) ] [EOL] if p_states != [number] [EOL] else next_states [ [number] : ] ) [EOL] [EOL] self . _prev_output = output [EOL] [EOL] return output , new_states [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor]$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.rnn.RecurrentCell$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.rnn.RecurrentCell$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.rnn.RecurrentCell$ 0 0 0 0 0 $mxnet.gluon.rnn.RecurrentCell$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.rnn.RecurrentCell$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor]$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] from typing import List [EOL] [EOL] [comment] [EOL] from mxnet . gluon import nn [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] [EOL] [EOL] class MLP ( nn . HybridBlock ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , layer_sizes , flatten , activation = [string] ) : [EOL] super ( ) . __init__ ( ) [EOL] self . layer_sizes = layer_sizes [EOL] with self . name_scope ( ) : [EOL] self . layers = nn . HybridSequential ( ) [EOL] for layer , layer_dim in enumerate ( layer_sizes ) : [EOL] self . layers . add ( nn . Dense ( layer_dim , flatten = flatten , activation = activation ) ) [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , x ) : [EOL] [docstring] [EOL] return self . layers ( x ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Tuple [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] from typing import Tuple [EOL] [EOL] [comment] [EOL] from mxnet . gluon import nn [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] [EOL] [EOL] class Scaler ( nn . HybridBlock ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , keepdims = False , axis = [number] ) : [EOL] [EOL] super ( ) . __init__ ( ) [EOL] self . keepdims = keepdims [EOL] self . axis = axis [EOL] [EOL] def compute_scale ( self , F , data , observed_indicator ) : [EOL] [docstring] [EOL] raise NotImplementedError ( ) [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , data , observed_indicator ) : [EOL] [docstring] [EOL] scale = self . compute_scale ( F , data , observed_indicator ) [EOL] [EOL] if self . keepdims : [EOL] scale = scale . expand_dims ( axis = self . axis ) [EOL] return F . broadcast_div ( data , scale ) , scale [EOL] else : [EOL] return ( F . broadcast_div ( data , scale . expand_dims ( axis = self . axis ) ) , scale , ) [EOL] [EOL] [EOL] class MeanScaler ( Scaler ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , minimum_scale = [number] , * args , ** kwargs ) : [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] self . minimum_scale = minimum_scale [EOL] [EOL] def compute_scale ( self , F , data , observed_indicator , ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] num_observed = F . sum ( observed_indicator , axis = self . axis ) [EOL] sum_observed = ( data . abs ( ) * observed_indicator ) . sum ( axis = self . axis ) [EOL] [EOL] [comment] [EOL] total_observed = num_observed . sum ( axis = [number] ) [EOL] denominator = F . maximum ( total_observed , [number] ) [EOL] default_scale = sum_observed . sum ( axis = [number] ) / denominator [comment] [EOL] [EOL] [comment] [EOL] denominator = F . maximum ( num_observed , [number] ) [EOL] scale = sum_observed / denominator [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] cond = F . broadcast_greater ( sum_observed , F . zeros_like ( sum_observed ) ) [EOL] scale = F . where ( cond , scale , F . broadcast_mul ( default_scale , F . ones_like ( num_observed ) ) , ) [EOL] [EOL] return F . maximum ( scale , self . minimum_scale ) [EOL] [EOL] [EOL] class NOPScaler ( Scaler ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , * args , ** kwargs ) : [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] [EOL] [comment] [EOL] def compute_scale ( self , F , data , observed_indicator ) : [EOL] [docstring] [EOL] return F . ones_like ( data ) . mean ( axis = self . axis ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor]$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] from typing import Optional , List [EOL] [EOL] [comment] [EOL] from mxnet . gluon . loss import Loss [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] [EOL] [EOL] class ActivationRegularizationLoss ( Loss ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , alpha = [number] , weight = None , batch_axis = [number] , time_axis = [number] , ** kwargs ) : [EOL] super ( ActivationRegularizationLoss , self ) . __init__ ( weight , batch_axis , ** kwargs ) [EOL] self . _alpha = alpha [EOL] self . _batch_axis = batch_axis [EOL] self . _time_axis = time_axis [EOL] [EOL] def __repr__ ( self ) : [EOL] s = [string] [EOL] return s . format ( alpha = self . _alpha ) [EOL] [EOL] def hybrid_forward ( self , F , * states ) : [EOL] [docstring] [EOL] if self . _alpha != [number] and states : [EOL] means = [ ] [EOL] for state in states : [EOL] if isinstance ( state , list ) : [EOL] state = F . stack ( * state , axis = self . _time_axis ) [EOL] means . append ( self . _alpha * state . __pow__ ( [number] ) . mean ( axis = self . _batch_axis , exclude = True ) ) [EOL] return F . add_n ( * means ) [EOL] return F . zeros ( [number] ) [EOL] [EOL] [EOL] class TemporalActivationRegularizationLoss ( Loss ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , beta = [number] , weight = None , batch_axis = [number] , time_axis = [number] , ** kwargs ) : [EOL] super ( TemporalActivationRegularizationLoss , self ) . __init__ ( weight , batch_axis , ** kwargs ) [EOL] self . _beta = beta [EOL] self . _batch_axis = batch_axis [EOL] self . _time_axis = time_axis [EOL] [EOL] def __repr__ ( self ) : [EOL] s = [string] [EOL] return s . format ( beta = self . _beta ) [EOL] [EOL] def hybrid_forward ( self , F , * states ) : [EOL] [docstring] [EOL] if self . _beta != [number] and states : [EOL] means = [ ] [EOL] for state in states : [EOL] if isinstance ( state , list ) : [EOL] state = F . stack ( * state , axis = self . _time_axis ) [EOL] sub_state_1 = F . slice_axis ( state , axis = self . _time_axis , begin = [number] , end = None ) [EOL] sub_state_2 = F . slice_axis ( state , axis = self . _time_axis , begin = [number] , end = - [number] ) [EOL] sub_state_diff = F . elemwise_sub ( sub_state_1 , sub_state_2 ) [EOL] means . append ( self . _beta * sub_state_diff . __pow__ ( [number] ) . mean ( axis = self . _batch_axis , exclude = True ) ) [EOL] return F . add_n ( * means ) [EOL] return F . zeros ( [number] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 $typing.Optional[builtins.float]$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.float]$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Callable , List , Optional [EOL] import typing [EOL] import builtins [EOL] import gluonts [EOL] import mxnet [EOL] from typing import Callable , List , Optional [comment] [EOL] [EOL] [comment] [EOL] import mxnet . gluon . nn as nn [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from gluonts . core . component import DType , validated [EOL] from gluonts . model . common import Tensor [EOL] [EOL] [EOL] class FeatureEmbedder ( nn . HybridBlock ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , cardinalities , embedding_dims , dtype = np . float32 , ** kwargs , ) : [EOL] super ( ) . __init__ ( ** kwargs ) [EOL] [EOL] assert ( len ( cardinalities ) > [number] ) , [string] [EOL] assert len ( cardinalities ) == len ( embedding_dims ) , [string] [EOL] assert all ( [ c > [number] for c in cardinalities ] ) , [string] [EOL] assert all ( [ d > [number] for d in embedding_dims ] ) , [string] [EOL] [EOL] self . __num_features = len ( cardinalities ) [EOL] self . dtype = dtype [EOL] [EOL] def create_embedding ( i , c , d ) : [EOL] embedding = nn . Embedding ( c , d , prefix = f" [string] { i } [string] " , dtype = self . dtype ) [EOL] self . register_child ( embedding ) [EOL] return embedding [EOL] [EOL] with self . name_scope ( ) : [EOL] self . __embedders = [ create_embedding ( i , c , d ) for i , ( c , d ) in enumerate ( zip ( cardinalities , embedding_dims ) ) ] [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , features ) : [EOL] [docstring] [EOL] [EOL] if self . __num_features > [number] : [EOL] [comment] [EOL] cat_feature_slices = F . split ( features , axis = - [number] , num_outputs = self . __num_features ) [EOL] else : [EOL] [comment] [EOL] cat_feature_slices = [ features ] [EOL] [EOL] return F . concat ( * [ embed ( F . squeeze ( cat_feature_slice , axis = - [number] ) ) for embed , cat_feature_slice in zip ( self . __embedders , cat_feature_slices ) ] , dim = - [number] , ) [EOL] [EOL] [EOL] class FeatureAssembler ( nn . HybridBlock ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , T , use_static_cat = False , use_static_real = False , use_dynamic_cat = False , use_dynamic_real = False , embed_static = None , embed_dynamic = None , dtype = np . float32 , ** kwargs , ) : [EOL] super ( ) . __init__ ( ** kwargs ) [EOL] [EOL] assert T > [number] , [string] [EOL] [EOL] self . T = T [EOL] self . dtype = dtype [EOL] self . use_static_cat = use_static_cat [EOL] self . use_static_real = use_static_real [EOL] self . use_dynamic_cat = use_dynamic_cat [EOL] self . use_dynamic_real = use_dynamic_real [EOL] self . embed_static = embed_static or ( lambda x : x ) [EOL] self . embed_dynamic = embed_dynamic or ( lambda x : x ) [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , feat_static_cat , feat_static_real , feat_dynamic_cat , feat_dynamic_real , ) : [EOL] processed_features = [ self . process_static_cat ( F , feat_static_cat ) , self . process_static_real ( F , feat_static_real ) , self . process_dynamic_cat ( F , feat_dynamic_cat ) , self . process_dynamic_real ( F , feat_dynamic_real ) , ] [EOL] [EOL] return F . concat ( * processed_features , dim = - [number] ) [EOL] [EOL] def process_static_cat ( self , F , feature ) : [EOL] feature = self . embed_static ( feature . astype ( self . dtype ) ) [EOL] return F . tile ( feature . expand_dims ( axis = [number] ) , reps = ( [number] , self . T , [number] ) ) [EOL] [EOL] def process_dynamic_cat ( self , F , feature ) : [EOL] return self . embed_dynamic ( feature . astype ( self . dtype ) ) [EOL] [EOL] def process_static_real ( self , F , feature ) : [EOL] return F . tile ( feature . expand_dims ( axis = [number] ) , reps = ( [number] , self . T , [number] ) ) [EOL] [EOL] def process_dynamic_real ( self , F , feature ) : [EOL] return feature [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Callable[[gluonts.model.common.Tensor],gluonts.model.common.Tensor]$ 0 0 0 $typing.Callable[[gluonts.model.common.Tensor],gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Callable[[gluonts.model.common.Tensor],gluonts.model.common.Tensor]$ 0 $typing.Callable[[gluonts.model.common.Tensor],gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 $typing.Callable[[gluonts.model.common.Tensor],gluonts.model.common.Tensor]$ 0 $typing.Callable[[gluonts.model.common.Tensor],gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 $gluonts.model.common.Tensor$ 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import gluonts [EOL] import builtins [EOL] from mxnet . gluon import HybridBlock , rnn [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] [EOL] [EOL] class RNN ( HybridBlock ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , mode , num_hidden , num_layers , bidirectional = False , ** kwargs , ) : [EOL] super ( RNN , self ) . __init__ ( ** kwargs ) [EOL] [EOL] with self . name_scope ( ) : [EOL] if mode == [string] : [EOL] self . rnn = rnn . RNN ( num_hidden , num_layers , bidirectional = bidirectional , activation = [string] , layout = [string] , ) [EOL] elif mode == [string] : [EOL] self . rnn = rnn . RNN ( num_hidden , num_layers , bidirectional = bidirectional , layout = [string] , ) [EOL] elif mode == [string] : [EOL] self . rnn = rnn . LSTM ( num_hidden , num_layers , bidirectional = bidirectional , layout = [string] , ) [EOL] elif mode == [string] : [EOL] self . rnn = rnn . GRU ( num_hidden , num_layers , bidirectional = bidirectional , layout = [string] , ) [EOL] else : [EOL] raise ValueError ( [string] % mode ) [EOL] [EOL] def hybrid_forward ( self , F , inputs ) : [comment] [EOL] [docstring] [EOL] return self . rnn ( inputs ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.bool$ 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.bool$ 0 $builtins.bool$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.bool$ 0 $builtins.bool$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.bool$ 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Optional , Tuple [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] import mxnet [EOL] from typing import List , Optional , Tuple [EOL] [EOL] [comment] [EOL] from mxnet import nd [EOL] from mxnet . gluon import nn [EOL] from mxnet . gluon . loss import Loss [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . model . common import Tensor [EOL] [EOL] [EOL] class QuantileLoss ( Loss ) : [EOL] @ validated ( ) def __init__ ( self , quantiles , quantile_weights = None , weight = None , batch_axis = [number] , ** kwargs , ) : [EOL] [docstring] [EOL] super ( ) . __init__ ( weight , batch_axis , ** kwargs ) [EOL] [EOL] self . quantiles = quantiles [EOL] self . num_quantiles = len ( quantiles ) [EOL] self . quantile_weights = ( nd . ones ( self . num_quantiles ) / self . num_quantiles [EOL] if not quantile_weights [EOL] else quantile_weights ) [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , y_true , y_pred , sample_weight = None ) : [EOL] [docstring] [EOL] if self . num_quantiles > [number] : [EOL] y_pred_all = F . split ( y_pred , axis = - [number] , num_outputs = self . num_quantiles , squeeze_axis = [number] ) [EOL] else : [EOL] y_pred_all = [ F . squeeze ( y_pred , axis = - [number] ) ] [EOL] [EOL] qt_loss = [ ] [EOL] for i , y_pred_q in enumerate ( y_pred_all ) : [EOL] q = self . quantiles [ i ] [EOL] weighted_qt = ( self . compute_quantile_loss ( F , y_true , y_pred_q , q ) * self . quantile_weights [ i ] . asscalar ( ) ) [EOL] qt_loss . append ( weighted_qt ) [EOL] stacked_qt_losses = F . stack ( * qt_loss , axis = - [number] ) [EOL] sum_qt_loss = F . mean ( stacked_qt_losses , axis = - [number] ) [comment] [EOL] if sample_weight is not None : [EOL] return sample_weight * sum_qt_loss [EOL] else : [EOL] return sum_qt_loss [EOL] [EOL] @ staticmethod def compute_quantile_loss ( F , y_true , y_pred_p , p ) : [EOL] [docstring] [EOL] [EOL] under_bias = p * F . maximum ( y_true - y_pred_p , [number] ) [EOL] over_bias = ( [number] - p ) * F . maximum ( y_pred_p - y_true , [number] ) [EOL] [EOL] qt_loss = [number] * ( under_bias + over_bias ) [EOL] [EOL] return qt_loss [EOL] [EOL] [EOL] class ProjectParams ( nn . HybridBlock ) : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , num_quantiles , ** kwargs ) : [EOL] super ( ) . __init__ ( ** kwargs ) [EOL] [EOL] with self . name_scope ( ) : [EOL] self . projection = nn . Dense ( units = num_quantiles , flatten = False ) [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , x ) : [EOL] [docstring] [EOL] return self . projection ( x ) [EOL] [EOL] [EOL] class QuantileOutput : [EOL] [docstring] [EOL] [EOL] @ validated ( ) def __init__ ( self , quantiles , quantile_weights = None , ) : [EOL] self . quantiles = quantiles [EOL] self . quantile_weights = quantile_weights [EOL] [EOL] def get_loss ( self ) : [EOL] [docstring] [EOL] return QuantileLoss ( quantiles = self . quantiles , quantile_weights = self . quantile_weights ) [EOL] [EOL] def get_quantile_proj ( self , ** kwargs ) : [EOL] [docstring] [EOL] return ProjectParams ( len ( self . quantiles ) , ** kwargs ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 $builtins.float$ 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor,gluonts.model.common.Tensor]$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.nn.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.nn.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Union , Tuple , Optional [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] from typing import List , Optional , Tuple , Union [EOL] [EOL] [comment] [EOL] from mxnet import gluon [EOL] from mxnet . gluon import nn [EOL] [EOL] [comment] [EOL] from gluonts . model . common import Tensor [EOL] [EOL] [EOL] class CausalConv1D ( gluon . HybridBlock ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , channels , kernel_size , dilation = [number] , activation = None , ** kwargs , ) : [EOL] super ( CausalConv1D , self ) . __init__ ( ** kwargs ) [EOL] [EOL] self . dilation = dilation [EOL] self . kernel_size = kernel_size [EOL] self . padding = dilation * ( kernel_size - [number] ) [EOL] self . conv1d = nn . Conv1D ( channels = channels , kernel_size = kernel_size , dilation = dilation , padding = self . padding , activation = activation , ** kwargs , ) [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , data ) : [EOL] [docstring] [EOL] ct = self . conv1d ( data ) [EOL] if self . kernel_size > [number] : [EOL] ct = F . slice_axis ( ct , axis = [number] , begin = [number] , end = - self . padding ) [EOL] return ct [EOL] [EOL] [EOL] class DilatedCausalGated ( gluon . HybridBlock ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , inner_channels , out_channels , kernel_size , dilation , ** kwargs , ) : [EOL] super ( DilatedCausalGated , self ) . __init__ ( ** kwargs ) [EOL] with self . name_scope ( ) : [EOL] self . conv1 = CausalConv1D ( channels = inner_channels , kernel_size = kernel_size , dilation = dilation , activation = [string] , ) [EOL] self . conv2 = CausalConv1D ( channels = inner_channels , kernel_size = kernel_size , dilation = dilation , activation = [string] , ) [EOL] self . output_conv = gluon . nn . Conv1D ( channels = out_channels , kernel_size = [number] ) [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , x ) : [EOL] [docstring] [EOL] x1 = self . conv1 ( x ) [EOL] x2 = self . conv2 ( x ) [EOL] return self . output_conv ( x1 * x2 ) [EOL] [EOL] [EOL] class ResidualSequential ( gluon . nn . HybridSequential ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , ** kwargs ) : [EOL] super ( ResidualSequential , self ) . __init__ ( ** kwargs ) [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , x ) : [EOL] [docstring] [EOL] outs = [ ] [EOL] for i , block in enumerate ( self . _children . values ( ) ) : [EOL] out = block ( x ) [EOL] outs . append ( out ) [EOL] if i == [number] : [EOL] x = out [EOL] else : [EOL] x = x + out [EOL] [EOL] return sum ( outs ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.int$ 0 $builtins.int$ 0 $typing.Union[builtins.int,typing.Tuple[builtins.int],typing.List[builtins.int]]$ 0 $typing.Union[builtins.int,typing.Tuple[builtins.int],typing.List[builtins.int]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $typing.Union[builtins.int,typing.Tuple[builtins.int],typing.List[builtins.int]]$ 0 $typing.Union[builtins.int,typing.Tuple[builtins.int],typing.List[builtins.int]]$ 0 $typing.Union[builtins.int,typing.Tuple[builtins.int],typing.List[builtins.int]]$ 0 $typing.Union[builtins.int,typing.Tuple[builtins.int],typing.List[builtins.int]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $typing.Union[builtins.int,typing.Tuple[builtins.int],typing.List[builtins.int]]$ 0 $typing.Union[builtins.int,typing.Tuple[builtins.int],typing.List[builtins.int]]$ 0 $typing.Union[builtins.int,typing.Tuple[builtins.int],typing.List[builtins.int]]$ 0 $typing.Union[builtins.int,typing.Tuple[builtins.int],typing.List[builtins.int]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $typing.Union[builtins.int,typing.Tuple[builtins.int],typing.List[builtins.int]]$ 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [EOL] from pkgutil import extend_path [EOL] [EOL] __path__ = extend_path ( __path__ , __name__ ) [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
import pandas [EOL] import builtins [EOL] import pandas as pd [EOL] import json [EOL] from pathlib import Path [EOL] import os [EOL] [EOL] from generate_evaluations import metrics_persisted [EOL] [EOL] dir_path = Path ( os . path . dirname ( os . path . realpath ( __file__ ) ) ) [EOL] [EOL] [EOL] def collect_results ( ) : [EOL] evals = [ ] [EOL] for evaluation_file in dir_path . glob ( [string] ) : [EOL] with open ( evaluation_file , [string] ) as f : [EOL] evals . append ( json . load ( f ) ) [EOL] return pd . DataFrame ( evals ) [EOL] [EOL] [EOL] def to_markdown ( df , float_format = [string] ) : [EOL] [comment] [EOL] [comment] [EOL] return os . linesep . join ( [ [string] . join ( df . columns ) , [string] . join ( [number] * [string] for _ in df . columns ) , df . to_csv ( sep = [string] , index = False , header = False , float_format = float_format ) , ] ) . replace ( [string] , [string] ) [EOL] [EOL] [EOL] results_df = collect_results ( ) [EOL] [EOL] [comment] [EOL] for metric in metrics_persisted : [EOL] print ( f" [string] { metric } [string] " ) [EOL] [EOL] pivot_df = results_df . pivot_table ( index = [string] , columns = [string] , values = metric ) [EOL] print ( to_markdown ( pivot_df . reset_index ( level = [number] ) ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Dict [EOL] import typing [EOL] import builtins [EOL] [docstring] [EOL] import json [EOL] import os [EOL] from pathlib import Path [EOL] from typing import Dict [EOL] [EOL] from gluonts . dataset . repository . datasets import get_dataset , dataset_names [EOL] from gluonts . evaluation . backtest import backtest_metrics [EOL] from gluonts . model . seasonal_naive import SeasonalNaivePredictor [EOL] [EOL] metrics_persisted = [ [string] , [string] , [string] ] [EOL] datasets = dataset_names [EOL] [EOL] Estimators = [ SeasonalNaivePredictor , ] [EOL] [EOL] dir_path = Path ( os . path . dirname ( os . path . realpath ( __file__ ) ) ) [EOL] [EOL] [EOL] def persist_evaluation ( estimator_name , dataset , evaluation , evaluation_path = [string] , ) : [EOL] [docstring] [EOL] path = Path ( evaluation_path ) / dataset / f"{ estimator_name } [string] " [EOL] [EOL] os . makedirs ( path . parent , exist_ok = True ) [EOL] [EOL] evaluation = { m : v for m , v in evaluation . items ( ) if m in metrics_persisted } [EOL] evaluation [ [string] ] = dataset [EOL] evaluation [ [string] ] = estimator_name [EOL] [EOL] with open ( path , [string] ) as f : [EOL] f . write ( json . dumps ( evaluation , indent = [number] , sort_keys = True ) ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] [EOL] for dataset_name in datasets : [EOL] for Estimator in Estimators : [EOL] dataset = get_dataset ( dataset_name = dataset_name , regenerate = False , path = Path ( [string] ) , ) [EOL] [EOL] estimator = Estimator ( prediction_length = dataset . metadata . prediction_length , freq = dataset . metadata . freq , ) [EOL] [EOL] estimator_name = type ( estimator ) . __name__ [EOL] [EOL] print ( f" [string] { estimator_name } [string] { dataset_name }" ) [EOL] [EOL] agg_metrics , item_metrics = backtest_metrics ( train_dataset = dataset . train , test_dataset = dataset . test , forecaster = estimator , ) [EOL] [EOL] persist_evaluation ( estimator_name = estimator_name , dataset = dataset_name , evaluation = agg_metrics , evaluation_path = dir_path , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Tuple [EOL] import gluonts [EOL] import builtins [EOL] import numpy [EOL] import typing [EOL] from typing import Tuple [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] import pandas as pd [EOL] import mxnet as mx [EOL] import pytest [EOL] [EOL] [comment] [EOL] import gluonts [EOL] from gluonts import time_feature , transform [EOL] from gluonts . core import fqname_for [EOL] from gluonts . core . serde import dump_code , dump_json , load_code , load_json [EOL] from gluonts . dataset . common import ProcessStartField , DataEntry , ListDataset [EOL] from gluonts . dataset . field_names import FieldName [EOL] from gluonts . dataset . stat import ScaleHistogram , calculate_dataset_statistics [EOL] [EOL] from gluonts . transform import ( MissingValueImputation , LeavesMissingValues , DummyValueImputation , MeanValueImputation , LastValueImputation , CausalMeanValueImputation , RollingMeanValueImputation , ) [EOL] [EOL] FREQ = [string] [EOL] [EOL] TEST_VALUES = { [string] : [ True , False ] , [string] : [ np . zeros ( [number] ) , np . random . rand ( [number] ) , np . random . rand ( [number] ) ] , [string] : [ ProcessStartField . process ( [string] , freq = [string] ) , ProcessStartField . process ( [string] , freq = [string] ) , ] , [string] : [ True , False ] , [string] : [ True , False ] , [string] : [ [number] , [number] , [number] , [number] ] , } [EOL] [EOL] [EOL] def test_align_timestamp ( ) : [EOL] def aligned_with ( date_str , freq ) : [EOL] return str ( ProcessStartField . process ( date_str , freq = freq ) ) [EOL] [EOL] for _ in range ( [number] ) : [EOL] assert ( aligned_with ( [string] , [string] ) == [string] ) [EOL] assert ( aligned_with ( [string] , [string] ) == [string] ) [EOL] assert ( aligned_with ( [string] , [string] ) == [string] ) [EOL] assert ( aligned_with ( [string] , [string] ) == [string] ) [EOL] assert ( aligned_with ( [string] , [string] ) == [string] ) [EOL] assert ( aligned_with ( [string] , [string] ) == [string] ) [EOL] assert ( aligned_with ( [string] , [string] ) == [string] ) [EOL] assert ( aligned_with ( [string] , [string] ) == [string] ) [EOL] assert ( aligned_with ( [string] , [string] ) == [string] ) [EOL] assert ( aligned_with ( [string] , [string] ) == [string] ) [EOL] assert ( aligned_with ( [string] , [string] ) == [string] ) [EOL] assert ( aligned_with ( [string] , [string] ) == [string] ) [EOL] assert ( aligned_with ( [string] , [string] ) == [string] ) [EOL] assert ( aligned_with ( [string] , [string] ) == [string] ) [EOL] assert ( aligned_with ( [string] , [string] ) == [string] ) [EOL] assert ( aligned_with ( [string] , [string] ) == [string] ) [EOL] assert ( aligned_with ( [string] , [string] ) == [string] ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , TEST_VALUES [ [string] ] ) @ pytest . mark . parametrize ( [string] , TEST_VALUES [ [string] ] ) @ pytest . mark . parametrize ( [string] , TEST_VALUES [ [string] ] ) def test_AddTimeFeatures ( start , target , is_train ) : [EOL] pred_length = [number] [EOL] t = transform . AddTimeFeatures ( start_field = FieldName . START , target_field = FieldName . TARGET , output_field = [string] , pred_length = pred_length , time_features = [ time_feature . DayOfWeek ( ) , time_feature . DayOfMonth ( ) ] , dtype = np . float64 , ) [EOL] [EOL] assert_serializable ( t ) [EOL] [EOL] data = { [string] : start , [string] : target } [EOL] res = t . map_transform ( data , is_train = is_train ) [EOL] mat = res [ [string] ] [EOL] expected_length = len ( target ) + ( [number] if is_train else pred_length ) [EOL] assert mat . shape == ( [number] , expected_length ) [EOL] tmp_idx = pd . date_range ( start = start , freq = start . freq , periods = expected_length ) [EOL] assert np . alltrue ( mat [ [number] ] == time_feature . DayOfWeek ( ) ( tmp_idx ) ) [EOL] assert np . alltrue ( mat [ [number] ] == time_feature . DayOfMonth ( ) ( tmp_idx ) ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , TEST_VALUES [ [string] ] ) @ pytest . mark . parametrize ( [string] , TEST_VALUES [ [string] ] ) @ pytest . mark . parametrize ( [string] , TEST_VALUES [ [string] ] ) def test_AddTimeFeatures_empty_time_features ( start , target , is_train ) : [EOL] pred_length = [number] [EOL] t = transform . AddTimeFeatures ( start_field = FieldName . START , target_field = FieldName . TARGET , output_field = [string] , pred_length = pred_length , time_features = [ ] , ) [EOL] [EOL] assert_serializable ( t ) [EOL] [EOL] data = { [string] : start , [string] : target } [EOL] res = t . map_transform ( data , is_train = is_train ) [EOL] assert res [ [string] ] is None [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , TEST_VALUES [ [string] ] ) @ pytest . mark . parametrize ( [string] , TEST_VALUES [ [string] ] ) @ pytest . mark . parametrize ( [string] , TEST_VALUES [ [string] ] ) def test_AddAgeFeatures ( start , target , is_train ) : [EOL] pred_length = [number] [EOL] t = transform . AddAgeFeature ( pred_length = pred_length , target_field = FieldName . TARGET , output_field = [string] , log_scale = True , ) [EOL] [EOL] assert_serializable ( t ) [EOL] [EOL] data = { [string] : start , [string] : target } [EOL] out = t . map_transform ( data , is_train = is_train ) [EOL] expected_length = len ( target ) + ( [number] if is_train else pred_length ) [EOL] assert out [ [string] ] . shape [ - [number] ] == expected_length [EOL] assert np . allclose ( out [ [string] ] , np . log10 ( [number] + np . arange ( expected_length ) ) . reshape ( ( [number] , expected_length ) ) , ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , TEST_VALUES [ [string] ] ) @ pytest . mark . parametrize ( [string] , TEST_VALUES [ [string] ] ) @ pytest . mark . parametrize ( [string] , TEST_VALUES [ [string] ] ) @ pytest . mark . parametrize ( [string] , TEST_VALUES [ [string] ] ) @ pytest . mark . parametrize ( [string] , TEST_VALUES [ [string] ] ) def test_InstanceSplitter ( start , target , lead_time , is_train , pick_incomplete ) : [EOL] train_length = [number] [EOL] pred_length = [number] [EOL] t = transform . InstanceSplitter ( target_field = FieldName . TARGET , is_pad_field = FieldName . IS_PAD , start_field = FieldName . START , forecast_start_field = FieldName . FORECAST_START , train_sampler = transform . UniformSplitSampler ( p = [number] ) , past_length = train_length , future_length = pred_length , lead_time = lead_time , time_series_fields = [ [string] ] , pick_incomplete = pick_incomplete , ) [EOL] [EOL] assert_serializable ( t ) [EOL] [EOL] other_feat = np . arange ( len ( target ) + [number] ) [EOL] data = { [string] : start , [string] : target , [string] : other_feat , [string] : [string] , } [EOL] [EOL] if not is_train and not pick_incomplete and len ( target ) < train_length : [EOL] with pytest . raises ( AssertionError ) : [EOL] out = list ( t . flatmap_transform ( data , is_train = is_train ) ) [EOL] return [EOL] else : [EOL] out = list ( t . flatmap_transform ( data , is_train = is_train ) ) [EOL] [EOL] if is_train : [EOL] assert len ( out ) == max ( [number] , len ( target ) - pred_length - lead_time + [number] - ( [number] if pick_incomplete else train_length ) , ) [EOL] else : [EOL] assert len ( out ) == [number] [EOL] [EOL] for o in out : [EOL] assert [string] not in o [EOL] assert [string] not in o [EOL] assert [string] in o [EOL] [EOL] assert len ( o [ [string] ] ) == train_length [EOL] assert len ( o [ [string] ] ) == train_length [EOL] [EOL] if is_train : [EOL] assert len ( o [ [string] ] ) == pred_length [EOL] assert len ( o [ [string] ] ) == pred_length [EOL] else : [EOL] assert len ( o [ [string] ] ) == [number] [EOL] assert len ( o [ [string] ] ) == pred_length [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , TEST_VALUES [ [string] ] ) @ pytest . mark . parametrize ( [string] , TEST_VALUES [ [string] ] ) @ pytest . mark . parametrize ( [string] , TEST_VALUES [ [string] ] ) @ pytest . mark . parametrize ( [string] , TEST_VALUES [ [string] ] ) @ pytest . mark . parametrize ( [string] , TEST_VALUES [ [string] ] ) def test_CanonicalInstanceSplitter ( start , target , is_train , use_prediction_features , allow_target_padding , ) : [EOL] train_length = [number] [EOL] pred_length = [number] [EOL] t = transform . CanonicalInstanceSplitter ( target_field = FieldName . TARGET , is_pad_field = FieldName . IS_PAD , start_field = FieldName . START , forecast_start_field = FieldName . FORECAST_START , instance_sampler = transform . UniformSplitSampler ( p = [number] ) , instance_length = train_length , prediction_length = pred_length , time_series_fields = [ [string] ] , allow_target_padding = allow_target_padding , use_prediction_features = use_prediction_features , ) [EOL] [EOL] assert_serializable ( t ) [EOL] [EOL] other_feat = np . arange ( len ( target ) + [number] ) [EOL] data = { [string] : start , [string] : target , [string] : other_feat , [string] : [string] , } [EOL] [EOL] out = list ( t . flatmap_transform ( data , is_train = is_train ) ) [EOL] [EOL] min_num_instances = [number] if allow_target_padding else [number] [EOL] if is_train : [EOL] assert len ( out ) == max ( min_num_instances , len ( target ) - train_length + [number] ) [EOL] else : [EOL] assert len ( out ) == [number] [EOL] [EOL] for o in out : [EOL] assert [string] not in o [EOL] assert [string] not in o [EOL] assert [string] not in o [EOL] assert [string] in o [EOL] [EOL] assert len ( o [ [string] ] ) == train_length [EOL] assert len ( o [ [string] ] ) == train_length [EOL] [EOL] if use_prediction_features and not is_train : [EOL] assert len ( o [ [string] ] ) == pred_length [EOL] [EOL] [EOL] def test_Transformation ( ) : [EOL] train_length = [number] [EOL] ds = gluonts . dataset . common . ListDataset ( [ { [string] : [string] , [string] : [ [number] ] * train_length } ] , freq = [string] ) [EOL] [EOL] pred_length = [number] [EOL] [EOL] t = transform . Chain ( trans = [ transform . AddTimeFeatures ( start_field = FieldName . START , target_field = FieldName . TARGET , output_field = [string] , time_features = [ time_feature . DayOfWeek ( ) , time_feature . DayOfMonth ( ) , time_feature . MonthOfYear ( ) , ] , pred_length = pred_length , ) , transform . AddAgeFeature ( target_field = FieldName . TARGET , output_field = [string] , pred_length = pred_length , log_scale = True , ) , transform . AddObservedValuesIndicator ( target_field = FieldName . TARGET , output_field = [string] ) , transform . VstackFeatures ( output_field = [string] , input_fields = [ [string] , [string] ] , drop_inputs = True , ) , transform . InstanceSplitter ( target_field = FieldName . TARGET , is_pad_field = FieldName . IS_PAD , start_field = FieldName . START , forecast_start_field = FieldName . FORECAST_START , train_sampler = transform . ExpectedNumInstanceSampler ( num_instances = [number] ) , past_length = train_length , future_length = pred_length , time_series_fields = [ [string] , [string] ] , ) , ] ) [EOL] [EOL] assert_serializable ( t ) [EOL] [EOL] for u in t ( iter ( ds ) , is_train = True ) : [EOL] print ( u ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , TEST_VALUES [ [string] ] ) def test_multi_dim_transformation ( is_train ) : [EOL] train_length = [number] [EOL] [EOL] first_dim = list ( np . arange ( [number] , [number] , [number] ) ) [EOL] first_dim [ - [number] ] = [string] [EOL] [EOL] second_dim = list ( np . arange ( [number] , [number] , [number] ) ) [EOL] second_dim [ [number] ] = [string] [EOL] [EOL] ds = gluonts . dataset . common . ListDataset ( data_iter = [ { [string] : [string] , [string] : [ first_dim , second_dim ] } ] , freq = [string] , one_dim_target = False , ) [EOL] pred_length = [number] [EOL] [EOL] [comment] [EOL] first_dim [ - [number] ] = np . nan [EOL] second_dim [ [number] ] = np . nan [EOL] [EOL] t = transform . Chain ( trans = [ transform . AddTimeFeatures ( start_field = FieldName . START , target_field = FieldName . TARGET , output_field = [string] , time_features = [ time_feature . DayOfWeek ( ) , time_feature . DayOfMonth ( ) , time_feature . MonthOfYear ( ) , ] , pred_length = pred_length , ) , transform . AddAgeFeature ( target_field = FieldName . TARGET , output_field = [string] , pred_length = pred_length , log_scale = True , ) , transform . AddObservedValuesIndicator ( target_field = FieldName . TARGET , output_field = [string] , imputation_method = None , ) , transform . VstackFeatures ( output_field = [string] , input_fields = [ [string] , [string] ] , drop_inputs = True , ) , transform . InstanceSplitter ( target_field = FieldName . TARGET , is_pad_field = FieldName . IS_PAD , start_field = FieldName . START , forecast_start_field = FieldName . FORECAST_START , train_sampler = transform . ExpectedNumInstanceSampler ( num_instances = [number] ) , past_length = train_length , future_length = pred_length , time_series_fields = [ [string] , [string] ] , output_NTC = False , ) , ] ) [EOL] [EOL] assert_serializable ( t ) [EOL] [EOL] if is_train : [EOL] for u in t ( iter ( ds ) , is_train = True ) : [EOL] assert_shape ( u [ [string] ] , ( [number] , [number] ) ) [EOL] assert_shape ( u [ [string] ] , ( [number] , [number] ) ) [EOL] assert_shape ( u [ [string] ] , ( [number] , [number] ) ) [EOL] assert_shape ( u [ [string] ] , ( [number] , [number] ) ) [EOL] [EOL] assert_padded_array ( u [ [string] ] , np . array ( [ [ [number] ] * [number] + [ [number] ] , [ [number] ] + [ [number] ] * [number] ] ) , u [ [string] ] , ) [EOL] assert_padded_array ( u [ [string] ] , np . array ( [ first_dim , second_dim ] ) , u [ [string] ] , ) [EOL] else : [EOL] for u in t ( iter ( ds ) , is_train = False ) : [EOL] assert_shape ( u [ [string] ] , ( [number] , [number] ) ) [EOL] assert_shape ( u [ [string] ] , ( [number] , [number] ) ) [EOL] assert_shape ( u [ [string] ] , ( [number] , [number] ) ) [EOL] assert_shape ( u [ [string] ] , ( [number] , [number] ) ) [EOL] [EOL] assert_padded_array ( u [ [string] ] , np . array ( [ [ [number] ] * [number] + [ [number] ] , [ [number] ] + [ [number] ] * [number] ] ) , u [ [string] ] , ) [EOL] assert_padded_array ( u [ [string] ] , np . array ( [ first_dim , second_dim ] ) , u [ [string] ] , ) [EOL] [EOL] [EOL] def test_ExpectedNumInstanceSampler ( ) : [EOL] N = [number] [EOL] train_length = [number] [EOL] pred_length = [number] [EOL] ds = make_dataset ( N , train_length ) [EOL] [EOL] t = transform . Chain ( trans = [ transform . InstanceSplitter ( target_field = FieldName . TARGET , is_pad_field = FieldName . IS_PAD , start_field = FieldName . START , forecast_start_field = FieldName . FORECAST_START , train_sampler = transform . ExpectedNumInstanceSampler ( num_instances = [number] ) , past_length = train_length , future_length = pred_length , pick_incomplete = True , ) ] ) [EOL] [EOL] assert_serializable ( t ) [EOL] [EOL] scale_hist = ScaleHistogram ( ) [EOL] [EOL] repetition = [number] [EOL] for i in range ( repetition ) : [EOL] for data in t ( iter ( ds ) , is_train = True ) : [EOL] target_values = data [ [string] ] [EOL] [comment] [EOL] target_values = target_values [ target_values > [number] ] [EOL] scale_hist . add ( target_values ) [EOL] [EOL] expected_values = { i : [number] ** i * repetition for i in range ( [number] , N ) } [EOL] [EOL] assert expected_values == scale_hist . bin_counts [EOL] [EOL] [EOL] def test_BucketInstanceSampler ( ) : [EOL] N = [number] [EOL] train_length = [number] [EOL] pred_length = [number] [EOL] ds = make_dataset ( N , train_length ) [EOL] [EOL] dataset_stats = calculate_dataset_statistics ( ds ) [EOL] [EOL] t = transform . Chain ( trans = [ transform . InstanceSplitter ( target_field = FieldName . TARGET , is_pad_field = FieldName . IS_PAD , start_field = FieldName . START , forecast_start_field = FieldName . FORECAST_START , train_sampler = transform . BucketInstanceSampler ( dataset_stats . scale_histogram ) , past_length = train_length , future_length = pred_length , pick_incomplete = True , ) ] ) [EOL] [EOL] assert_serializable ( t ) [EOL] [EOL] scale_hist = ScaleHistogram ( ) [EOL] [EOL] repetition = [number] [EOL] for i in range ( repetition ) : [EOL] for data in t ( iter ( ds ) , is_train = True ) : [EOL] target_values = data [ [string] ] [EOL] [comment] [EOL] target_values = target_values [ target_values > [number] ] [EOL] scale_hist . add ( target_values ) [EOL] [EOL] expected_values = { i : repetition for i in range ( [number] , N ) } [EOL] found_values = scale_hist . bin_counts [EOL] [EOL] for i in range ( [number] , N ) : [EOL] assert abs ( expected_values [ i ] - found_values [ i ] < expected_values [ i ] * [number] ) [EOL] [EOL] [EOL] def test_cdf_to_gaussian_transformation ( ) : [EOL] def make_test_data ( ) : [EOL] target = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] ) . tolist ( ) [EOL] [EOL] np . random . shuffle ( target ) [EOL] [EOL] multi_dim_target = np . array ( [ target , target ] ) . transpose ( ) [EOL] [EOL] past_is_pad = np . array ( [ [ [number] ] * len ( target ) ] ) . transpose ( ) [EOL] [EOL] past_observed_target = np . array ( [ [ [number] ] * len ( target ) , [ [number] ] * len ( target ) ] ) . transpose ( ) [EOL] [EOL] ds = gluonts . dataset . common . ListDataset ( data_iter = [ { [string] : [string] , [string] : multi_dim_target , [string] : multi_dim_target , [string] : multi_dim_target , [string] : past_is_pad , f" [string] { FieldName . OBSERVED_VALUES }" : past_observed_target , } ] , freq = [string] , one_dim_target = False , ) [EOL] return ds [EOL] [EOL] def make_fake_output ( u ) : [EOL] fake_output = np . expand_dims ( np . expand_dims ( u [ [string] ] , axis = [number] ) , axis = [number] ) [EOL] return fake_output [EOL] [EOL] ds = make_test_data ( ) [EOL] [EOL] t = transform . Chain ( trans = [ transform . CDFtoGaussianTransform ( target_field = FieldName . TARGET , observed_values_field = FieldName . OBSERVED_VALUES , max_context_length = [number] , target_dim = [number] , ) ] ) [EOL] [EOL] for u in t ( iter ( ds ) , is_train = False ) : [EOL] [EOL] fake_output = make_fake_output ( u ) [EOL] [EOL] [comment] [EOL] u [ [string] ] = mx . nd . array ( np . expand_dims ( u [ [string] ] , axis = [number] ) ) [EOL] [EOL] u [ [string] ] = mx . nd . array ( np . expand_dims ( u [ [string] ] , axis = [number] ) ) [EOL] [EOL] u [ [string] ] = mx . nd . array ( np . expand_dims ( u [ [string] ] , axis = [number] ) ) [EOL] [EOL] back_transformed = transform . cdf_to_gaussian_forward_transform ( u , fake_output ) [EOL] [EOL] [comment] [EOL] back_transformed = back_transformed [ [number] ] [ [number] ] [EOL] [EOL] original_target = u [ [string] ] [EOL] [EOL] [comment] [EOL] assert np . allclose ( original_target , back_transformed ) [EOL] [EOL] [EOL] def test_gaussian_cdf ( ) : [EOL] try : [EOL] from scipy . stats import norm [EOL] except : [EOL] pytest . skip ( [string] ) [EOL] [EOL] x = np . array ( [ - [number] , - [number] , - [number] ] + np . linspace ( - [number] , [number] , [number] ) . tolist ( ) + [ [number] , [number] , [number] ] ) [EOL] y_gluonts = transform . CDFtoGaussianTransform . standard_gaussian_cdf ( x ) [EOL] y_scipy = norm . cdf ( x ) [EOL] [EOL] assert np . allclose ( y_gluonts , y_scipy , atol = [number] ) [EOL] [EOL] [EOL] def test_gaussian_ppf ( ) : [EOL] try : [EOL] from scipy . stats import norm [EOL] except : [EOL] pytest . skip ( [string] ) [EOL] [EOL] x = np . linspace ( [number] , [number] , [number] ) [EOL] y_gluonts = transform . CDFtoGaussianTransform . standard_gaussian_ppf ( x ) [EOL] y_scipy = norm . ppf ( x ) [EOL] [EOL] assert np . allclose ( y_gluonts , y_scipy , atol = [number] ) [EOL] [EOL] [EOL] def test_target_dim_indicator ( ) : [EOL] target = np . array ( [ [number] , [number] , [number] , [number] ] ) . tolist ( ) [EOL] [EOL] multi_dim_target = np . array ( [ target , target , target , target ] ) [EOL] dataset = gluonts . dataset . common . ListDataset ( data_iter = [ { [string] : [string] , [string] : multi_dim_target } ] , freq = [string] , one_dim_target = False , ) [EOL] [EOL] t = transform . Chain ( trans = [ transform . TargetDimIndicator ( target_field = FieldName . TARGET , field_name = [string] ) ] ) [EOL] [EOL] for data_entry in t ( dataset , is_train = True ) : [EOL] assert ( data_entry [ [string] ] == np . array ( [ [number] , [number] , [number] , [number] ] ) ) . all ( ) [EOL] [EOL] [EOL] @ pytest . fixture def point_process_dataset ( ) : [EOL] [EOL] ia_times = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] marks = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] [EOL] lds = ListDataset ( [ { [string] : np . c_ [ ia_times , marks ] . T , [string] : pd . Timestamp ( [string] , freq = [string] ) , [string] : pd . Timestamp ( [string] , freq = [string] ) , } ] , freq = [string] , one_dim_target = False , ) [EOL] [EOL] return lds [EOL] [EOL] [EOL] class MockContinuousTimeSampler ( transform . ContinuousTimePointSampler ) : [EOL] [comment] [EOL] def __init__ ( self , ret_values , * args , ** kwargs ) : [EOL] self . _ret_values = ret_values [EOL] [EOL] def __call__ ( self , * args , ** kwargs ) : [EOL] return np . array ( self . _ret_values ) [EOL] [EOL] [EOL] def test_ctsplitter_mask_sorted ( point_process_dataset ) : [EOL] d = next ( iter ( point_process_dataset ) ) [EOL] [EOL] ia_times = d [ [string] ] [ [number] , : ] [EOL] [EOL] ts = np . cumsum ( ia_times ) [EOL] [EOL] splitter = transform . ContinuousTimeInstanceSplitter ( [number] , [number] , train_sampler = transform . ContinuousTimeUniformSampler ( num_instances = [number] ) , ) [EOL] [EOL] [comment] [EOL] res = splitter . _mask_sorted ( ts , [number] , [number] ) [EOL] assert all ( [ a == b for a , b in zip ( [ [number] , [number] , [number] ] , res ) ] ) [EOL] [EOL] [comment] [EOL] res = splitter . _mask_sorted ( np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] ] ) , [number] , [number] ) [EOL] assert all ( [ a == b for a , b in zip ( [ [number] ] , res ) ] ) [EOL] [EOL] [EOL] def test_ctsplitter_no_train_last_point ( point_process_dataset ) : [EOL] splitter = transform . ContinuousTimeInstanceSplitter ( [number] , [number] , train_sampler = transform . ContinuousTimeUniformSampler ( num_instances = [number] ) , ) [EOL] [EOL] iter_de = splitter ( point_process_dataset , is_train = False ) [EOL] [EOL] d_out = next ( iter ( iter_de ) ) [EOL] [EOL] assert [string] not in d_out [EOL] assert [string] not in d_out [EOL] assert [string] in d_out [EOL] assert [string] in d_out [EOL] [EOL] assert d_out [ [string] ] == [number] [EOL] assert np . allclose ( [ [number] , [number] , [number] , [number] , [number] , [number] ] , d_out [ [string] ] [ ... , [number] ] , atol = [number] ) [EOL] [EOL] [EOL] def test_ctsplitter_train_correct ( point_process_dataset ) : [EOL] splitter = transform . ContinuousTimeInstanceSplitter ( [number] , [number] , train_sampler = MockContinuousTimeSampler ( ret_values = [ [number] , [number] , [number] ] , num_instances = [number] ) , ) [EOL] [EOL] iter_de = splitter ( point_process_dataset , is_train = True ) [EOL] [EOL] outputs = list ( iter_de ) [EOL] [EOL] assert outputs [ [number] ] [ [string] ] == [number] [EOL] assert outputs [ [number] ] [ [string] ] == [number] [EOL] [EOL] assert np . allclose ( outputs [ [number] ] [ [string] ] , np . array ( [ [ [number] , [number] ] , [ [number] , [number] ] ] ) . T ) [EOL] assert np . allclose ( outputs [ [number] ] [ [string] ] , np . array ( [ [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] ] ) . T ) [EOL] [EOL] assert outputs [ [number] ] [ [string] ] == [number] [EOL] assert outputs [ [number] ] [ [string] ] == [number] [EOL] [EOL] assert outputs [ [number] ] [ [string] ] == [number] [EOL] assert outputs [ [number] ] [ [string] ] == [number] [EOL] [EOL] [EOL] def test_ctsplitter_train_correct_out_count ( point_process_dataset ) : [EOL] [EOL] [comment] [EOL] def shuffle_iterator ( num_duplications = [number] ) : [EOL] for entry in point_process_dataset : [EOL] for i in range ( num_duplications ) : [EOL] d = dict . copy ( entry ) [EOL] d [ [string] ] = np . random . permutation ( d [ [string] ] . T ) . T [EOL] yield d [EOL] [EOL] splitter = transform . ContinuousTimeInstanceSplitter ( [number] , [number] , train_sampler = MockContinuousTimeSampler ( ret_values = [ [number] , [number] , [number] ] , num_instances = [number] ) , ) [EOL] [EOL] iter_de = splitter ( shuffle_iterator ( ) , is_train = True ) [EOL] [EOL] outputs = list ( iter_de ) [EOL] [EOL] assert len ( outputs ) == [number] * [number] [EOL] [EOL] [EOL] def test_ctsplitter_train_samples_correct_times ( point_process_dataset ) : [EOL] [EOL] splitter = transform . ContinuousTimeInstanceSplitter ( [number] , [number] , train_sampler = transform . ContinuousTimeUniformSampler ( [number] ) ) [EOL] [EOL] iter_de = splitter ( point_process_dataset , is_train = True ) [EOL] [EOL] assert all ( [ ( pd . Timestamp ( [string] ) <= d [ [string] ] <= pd . Timestamp ( [string] ) ) for d in iter_de ] ) [EOL] [EOL] [EOL] def test_ctsplitter_train_short_intervals ( point_process_dataset ) : [EOL] splitter = transform . ContinuousTimeInstanceSplitter ( [number] , [number] , train_sampler = MockContinuousTimeSampler ( ret_values = [ [number] , [number] , [number] ] , num_instances = [number] ) , ) [EOL] [EOL] iter_de = splitter ( point_process_dataset , is_train = True ) [EOL] [EOL] for d in iter_de : [EOL] assert d [ [string] ] == d [ [string] ] == [number] [EOL] assert np . prod ( np . shape ( d [ [string] ] ) ) == [number] [EOL] assert np . prod ( np . shape ( d [ [string] ] ) ) == [number] [EOL] [EOL] [EOL] def test_AddObservedIndicator ( ) : [EOL] [docstring] [EOL] [EOL] array_values = [ np . array ( [ np . nan , [number] , [number] , np . nan , [number] , np . nan , [number] , np . nan ] ) , np . array ( [ np . nan ] ) , np . array ( [ [number] ] ) , ] [EOL] [EOL] l_methods = [ [string] , [string] , [string] , [string] , [string] , [string] , ] [EOL] [EOL] d_method_instances = { [string] : DummyValueImputation ( ) , [string] : MeanValueImputation ( ) , [string] : CausalMeanValueImputation ( ) , [string] : LastValueImputation ( ) , [string] : RollingMeanValueImputation ( [number] ) , [string] : RollingMeanValueImputation ( [number] ) , } [EOL] [EOL] d_expected_results = { [string] : [ np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) , np . array ( [ [number] ] ) , np . array ( [ [number] ] ) , ] , [string] : [ np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) , np . array ( [ [number] ] ) , np . array ( [ [number] ] ) , ] , [string] : [ np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] / [number] ] ) , np . array ( [ [number] ] ) , np . array ( [ [number] ] ) , ] , [string] : [ np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) , np . array ( [ [number] ] ) , np . array ( [ [number] ] ) , ] , [string] : [ np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) , np . array ( [ [number] ] ) , np . array ( [ [number] ] ) , ] , [string] : [ np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) , np . array ( [ [number] ] ) , np . array ( [ [number] ] ) , ] , } [EOL] [EOL] expected_missindicators = [ np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) , np . array ( [ [number] ] ) , np . array ( [ [number] ] ) , ] [EOL] [EOL] for i , array_value in enumerate ( array_values ) : [EOL] for method in l_methods : [EOL] transfo = transform . AddObservedValuesIndicator ( target_field = FieldName . TARGET , output_field = FieldName . OBSERVED_VALUES , imputation_method = d_method_instances [ method ] , ) [EOL] [EOL] d = { [string] : array_value . copy ( ) } [EOL] [EOL] res = transfo . transform ( d ) [EOL] [EOL] assert np . array_equal ( d_expected_results [ method ] [ i ] , res [ [string] ] ) [EOL] assert np . array_equal ( expected_missindicators [ i ] , res [ FieldName . OBSERVED_VALUES ] ) [EOL] [EOL] [EOL] def make_dataset ( N , train_length ) : [EOL] [comment] [EOL] n = [number] ** N - [number] [EOL] targets = np . ones ( ( n , train_length ) ) [EOL] for i in range ( [number] , n ) : [EOL] targets [ i , : ] = targets [ i , : ] * i [EOL] [EOL] ds = gluonts . dataset . common . ListDataset ( data_iter = [ { [string] : [string] , [string] : targets [ i , : ] } for i in range ( n ) ] , freq = [string] , ) [EOL] [EOL] return ds [EOL] [EOL] [EOL] def assert_serializable ( x ) : [EOL] t = fqname_for ( x . __class__ ) [EOL] y = load_json ( dump_json ( x ) ) [EOL] z = load_code ( dump_code ( x ) ) [EOL] assert dump_json ( x ) == dump_json ( y ) , f" [string] { t } [string] " [EOL] assert dump_code ( x ) == dump_code ( z ) , f" [string] { t } [string] " [EOL] [EOL] [EOL] def assert_shape ( array , reference_shape ) : [EOL] assert ( array . shape == reference_shape ) , f" [string] { reference_shape } [string] { array . shape } [string] " [EOL] [EOL] [EOL] def assert_padded_array ( sampled_array , reference_array , padding_array ) : [EOL] num_padded = int ( np . sum ( padding_array ) ) [EOL] sampled_no_padding = sampled_array [ : , num_padded : ] [EOL] [EOL] reference_array = np . roll ( reference_array , num_padded , axis = [number] ) [EOL] reference_no_padding = reference_array [ : , num_padded : ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] reference_no_padding [ np . isnan ( reference_no_padding ) ] = [number] [EOL] sampled_no_padding [ np . isnan ( sampled_no_padding ) ] = [number] [EOL] [EOL] reference_no_padding = np . array ( reference_no_padding , dtype = np . float32 ) [EOL] [EOL] assert ( sampled_no_padding == reference_no_padding ) . all ( ) , ( f" [string] " f" [string] { sampled_no_padding } [string] { reference_no_padding } [string] " ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import pytest [EOL] [EOL] [EOL] def test_sanity ( ) : [EOL] [comment] [EOL] [comment] [EOL] import gluonts as ts [EOL] [EOL] [EOL] @ pytest . mark . gpu def test_sanity_gpu ( ) : [EOL] [comment] [EOL] [comment] [EOL] import gluonts as ts [EOL] [EOL] [EOL] @ pytest . mark . serial def test_sanity_serial ( ) : [EOL] [comment] [EOL] [comment] [EOL] import gluonts as ts [EOL] [EOL] [EOL] @ pytest . mark . gpu @ pytest . mark . serial def test_sanity_gpu_serial ( ) : [EOL] [comment] [EOL] [comment] [EOL] import gluonts as ts [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import ContextManager [EOL] import gluonts [EOL] import typing [EOL] import json [EOL] from typing import ContextManager [EOL] import sys [EOL] from distutils . util import strtobool [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] import pytest [EOL] [EOL] [comment] [EOL] from gluonts . core . component import equals [EOL] from gluonts . dataset . common import FileDataset , ListDataset [EOL] from gluonts . model . trivial . mean import MeanPredictor [EOL] from gluonts . model . seq2seq import MQCNNEstimator [EOL] from gluonts . shell . sagemaker import ServeEnv , TrainEnv [EOL] from gluonts . shell . train import run_train_and_test [EOL] [EOL] try : [EOL] from gluonts . shell . serve import Settings [EOL] from gluonts . shell . serve . util import jsonify_floats [EOL] from gluonts . testutil import shell as testutil [EOL] except ImportError : [EOL] if sys . platform != [string] : [EOL] raise [EOL] [EOL] [comment] [EOL] pytestmark = pytest . mark . skip [EOL] [EOL] [EOL] context_length = [number] [EOL] prediction_length = [number] [EOL] num_samples = [number] [EOL] [EOL] [EOL] @ pytest . fixture ( scope = [string] ) def train_env ( listify_dataset ) : [EOL] hyperparameters = { [string] : context_length , [string] : prediction_length , [string] : num_samples , [string] : listify_dataset , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , } [EOL] with testutil . temporary_train_env ( hyperparameters , [string] ) as env : [EOL] yield env [EOL] [EOL] [EOL] @ pytest . fixture ( scope = [string] ) def static_server ( train_env , ) : [EOL] predictor = MeanPredictor . from_hyperparameters ( ** train_env . hyperparameters ) [EOL] predictor . serialize ( train_env . path . model ) [EOL] [EOL] serve_env = ServeEnv ( train_env . path . base ) [EOL] settings = Settings ( sagemaker_server_port = testutil . free_port ( ) ) [EOL] with testutil . temporary_server ( serve_env , None , settings ) as server : [EOL] yield server [EOL] [EOL] [EOL] @ pytest . fixture ( scope = [string] ) def dynamic_server ( train_env , ) : [EOL] serve_env = ServeEnv ( train_env . path . base ) [EOL] settings = Settings ( sagemaker_server_port = testutil . free_port ( ) ) [EOL] with testutil . temporary_server ( serve_env , MeanPredictor , settings ) as server : [EOL] yield server [EOL] [EOL] [EOL] @ pytest . fixture def batch_transform ( monkeypatch , train_env ) : [EOL] monkeypatch . setenv ( [string] , [string] ) [EOL] [EOL] inference_config = { [string] : context_length , [string] : prediction_length , [string] : num_samples , [string] : [ [string] , [string] ] , [string] : [ ] , ** train_env . hyperparameters , } [EOL] [EOL] monkeypatch . setenv ( [string] , json . dumps ( inference_config ) ) [EOL] return inference_config [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ [string] , [string] ] ) def test_listify_dataset ( train_env , listify_dataset ) : [EOL] for dataset_name in train_env . datasets . keys ( ) : [EOL] assert ( isinstance ( train_env . datasets [ dataset_name ] , ListDataset ) [EOL] if strtobool ( listify_dataset ) [EOL] else isinstance ( train_env . datasets [ dataset_name ] , FileDataset ) ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ [string] , [string] ] ) @ pytest . mark . parametrize ( [string] , [ MeanPredictor , MQCNNEstimator ] ) def test_train_shell ( train_env , caplog , forecaster_type ) : [EOL] run_train_and_test ( env = train_env , forecaster_type = forecaster_type ) [EOL] [EOL] if forecaster_type == MeanPredictor : [EOL] for _ , _ , line in caplog . record_tuples : [EOL] if [string] in line : [EOL] assert line . endswith ( [string] ) [EOL] if [string] in line : [EOL] assert line . endswith ( [string] ) [EOL] if [string] in line : [EOL] assert line . endswith ( [string] ) [EOL] if [string] in line or [string] in line : [EOL] assert line . endswith ( [string] ) [EOL] if [string] in line : [EOL] assert line . endswith ( [string] ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ [string] , [string] ] ) def test_server_shell ( train_env , static_server , caplog ) : [EOL] execution_parameters = static_server . execution_parameters ( ) [EOL] [EOL] assert [string] in execution_parameters [EOL] assert [string] in execution_parameters [EOL] assert [string] in execution_parameters [EOL] [EOL] assert execution_parameters [ [string] ] == [string] [EOL] assert execution_parameters [ [string] ] == [number] [EOL] [EOL] configuration = { [string] : [number] , [string] : [ [string] , [string] ] , [string] : [ ] , } [EOL] [EOL] for entry in train_env . datasets [ [string] ] : [EOL] forecast = static_server . invocations ( [ entry ] , configuration ) [ [number] ] [EOL] [EOL] for output_type in configuration [ [string] ] : [EOL] assert output_type in forecast [EOL] [EOL] act_mean = np . array ( forecast [ [string] ] ) [EOL] act_samples = np . array ( forecast [ [string] ] ) [EOL] [EOL] mean = np . mean ( entry [ [string] ] ) [EOL] [EOL] exp_mean_shape = ( prediction_length , ) [EOL] exp_samples_shape = ( num_samples , prediction_length ) [EOL] [EOL] exp_mean = mean * np . ones ( shape = ( prediction_length , ) ) [EOL] exp_samples = mean * np . ones ( shape = exp_samples_shape ) [EOL] [EOL] assert exp_mean_shape == act_mean . shape [EOL] assert exp_samples_shape == act_samples . shape [EOL] assert equals ( exp_mean , act_mean ) [EOL] assert equals ( exp_samples , act_samples ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ [string] , [string] ] ) def test_dynamic_shell ( train_env , dynamic_server , caplog ) : [EOL] execution_parameters = dynamic_server . execution_parameters ( ) [EOL] [EOL] assert [string] in execution_parameters [EOL] assert [string] in execution_parameters [EOL] assert [string] in execution_parameters [EOL] [EOL] assert execution_parameters [ [string] ] == [string] [EOL] assert execution_parameters [ [string] ] == [number] [EOL] [EOL] configuration = { [string] : [number] , [string] : [ [string] , [string] ] , [string] : [ ] , ** train_env . hyperparameters , } [EOL] [EOL] for entry in train_env . datasets [ [string] ] : [EOL] forecast = dynamic_server . invocations ( [ entry ] , configuration ) [ [number] ] [EOL] [EOL] for output_type in configuration [ [string] ] : [EOL] assert output_type in forecast [EOL] [EOL] act_mean = np . array ( forecast [ [string] ] ) [EOL] act_samples = np . array ( forecast [ [string] ] ) [EOL] [EOL] mean = np . mean ( entry [ [string] ] ) [EOL] [EOL] exp_mean_shape = ( prediction_length , ) [EOL] exp_samples_shape = ( num_samples , prediction_length ) [EOL] [EOL] exp_mean = mean * np . ones ( shape = ( prediction_length , ) ) [EOL] exp_samples = mean * np . ones ( shape = exp_samples_shape ) [EOL] [EOL] assert exp_mean_shape == act_mean . shape [EOL] assert exp_samples_shape == act_samples . shape [EOL] assert equals ( exp_mean , act_mean ) [EOL] assert equals ( exp_samples , act_samples ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ [string] , [string] ] ) def test_dynamic_batch_shell ( batch_transform , train_env , dynamic_server , caplog , ) : [EOL] execution_parameters = dynamic_server . execution_parameters ( ) [EOL] [EOL] assert [string] in execution_parameters [EOL] assert [string] in execution_parameters [EOL] assert [string] in execution_parameters [EOL] [EOL] assert execution_parameters [ [string] ] == [string] [EOL] assert execution_parameters [ [string] ] == [number] [EOL] [EOL] for entry in train_env . datasets [ [string] ] : [EOL] forecast = dynamic_server . batch_invocations ( [ entry ] ) [ [number] ] [EOL] [EOL] for output_type in batch_transform [ [string] ] : [EOL] assert output_type in forecast [EOL] [EOL] act_mean = np . array ( forecast [ [string] ] ) [EOL] act_samples = np . array ( forecast [ [string] ] ) [EOL] [EOL] mean = np . mean ( entry [ [string] ] ) [EOL] [EOL] exp_mean_shape = ( prediction_length , ) [EOL] exp_samples_shape = ( num_samples , prediction_length ) [EOL] [EOL] exp_mean = mean * np . ones ( shape = ( prediction_length , ) ) [EOL] exp_samples = mean * np . ones ( shape = exp_samples_shape ) [EOL] [EOL] assert exp_mean_shape == act_mean . shape [EOL] assert exp_samples_shape == act_samples . shape [EOL] assert equals ( exp_mean , act_mean ) [EOL] assert equals ( exp_samples , act_samples ) [EOL] [EOL] [EOL] def test_as_json_dict_outputs_valid_json ( ) : [EOL] non_compliant_json = { [string] : float ( [string] ) , [string] : float ( [string] ) , [string] : { [string] : float ( [string] ) , [string] : [string] , [string] : float ( [string] ) , [string] : float ( [string] ) , [string] : { [string] : float ( [string] ) } , } , } [EOL] [EOL] with pytest . raises ( ValueError ) : [EOL] json . dumps ( non_compliant_json , allow_nan = False ) [EOL] [EOL] output_json = jsonify_floats ( non_compliant_json ) [EOL] json . dumps ( output_json , allow_nan = False ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] [comment] [EOL] import tempfile [EOL] from pathlib import Path [EOL] import argparse [EOL] [EOL] [comment] [EOL] import pytest [EOL] [EOL] [comment] [EOL] from gluonts . core import serde [EOL] from gluonts . dataset . repository . datasets import get_dataset [EOL] from gluonts . model . simple_feedforward import SimpleFeedForwardEstimator [EOL] from gluonts . nursery . sagemaker_sdk . entry_point_scripts . train_entry_point import ( train , ) [EOL] from gluonts . nursery . sagemaker_sdk . defaults import QUANTILES , NUM_SAMPLES [EOL] [EOL] [EOL] def create_arguments ( temp_dir_abs_path , dataset_name , s3_dataset_path = None ) : [EOL] parser = argparse . ArgumentParser ( ) [EOL] [EOL] parser . add_argument ( [string] , type = str , default = temp_dir_abs_path ) [EOL] parser . add_argument ( [string] , type = str , default = temp_dir_abs_path ) [EOL] parser . add_argument ( [string] , type = str , default = temp_dir_abs_path ) [EOL] parser . add_argument ( [string] , type = str , default = s3_dataset_path ) [EOL] parser . add_argument ( [string] , type = str , default = dataset_name ) [EOL] parser . add_argument ( [string] , type = int , default = str ( NUM_SAMPLES ) ) [EOL] parser . add_argument ( [string] , type = str , default = str ( QUANTILES ) ) [EOL] [EOL] args , _ = parser . parse_known_args ( ) [EOL] [EOL] return args [EOL] [EOL] [EOL] def simple_feedforward_estimator ( ) : [EOL] return ( SimpleFeedForwardEstimator , dict ( ctx = [string] , epochs = [number] , learning_rate = [number] , hybridize = True , num_hidden_dimensions = [ [number] ] , num_batches_per_epoch = [number] , use_symbol_block_predictor = True , num_parallel_samples = [number] , ) , ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [string] , False ) , ( [string] , True ) ] ) def test_train_script ( dataset_name , custom_dataset ) : [EOL] [comment] [EOL] with tempfile . TemporaryDirectory ( ) as temp_dir : [EOL] temp_dir_path = Path ( temp_dir ) [EOL] dataset = get_dataset ( dataset_name , path = temp_dir_path , regenerate = True ) [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] if custom_dataset : [EOL] args = create_arguments ( str ( temp_dir_path ) , dataset_name , s3_dataset_path = str ( temp_dir_path / dataset_name ) , ) [EOL] else : [EOL] args = create_arguments ( str ( temp_dir_path ) , dataset_name ) [EOL] [EOL] [comment] [EOL] estimator_cls , hyperparameters = simple_feedforward_estimator ( ) [EOL] estimator = estimator_cls . from_hyperparameters ( prediction_length = dataset . metadata . prediction_length , freq = dataset . metadata . freq , ** hyperparameters ) [EOL] serialized = serde . dump_json ( estimator ) [EOL] with open ( temp_dir_path / [string] , [string] ) as estimator_file : [EOL] estimator_file . write ( serialized ) [EOL] [EOL] [comment] [EOL] train ( args ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] from typing import List [EOL] import typing [EOL] import gluonts [EOL] import itertools [EOL] import tempfile [EOL] from pathlib import Path [EOL] from typing import List [EOL] [EOL] [comment] [EOL] import mxnet as mx [EOL] import numpy as np [EOL] import pytest [EOL] [EOL] [comment] [EOL] from gluonts . support import util [EOL] from gluonts . model . common import Tensor [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ [ [ [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] ] ] ] ) def test_cumsum ( vec ) : [EOL] [EOL] forward_cumsum = util . cumsum ( mx . nd , mx . nd . array ( vec ) ) . asnumpy ( ) [EOL] np_forward_cumsum = np . cumsum ( vec , axis = - [number] ) [EOL] assert np . all ( forward_cumsum == np_forward_cumsum ) , ( f" [string] " f" [string] { np_forward_cumsum } [string] { forward_cumsum }" ) [EOL] [EOL] reverse_cumsum = util . cumsum ( mx . nd , mx . nd . array ( vec ) , reverse = True ) . asnumpy ( ) [EOL] np_reverse_cumsum = np . flip ( np . cumsum ( np . flip ( vec , axis = - [number] ) , axis = - [number] ) , axis = - [number] ) [EOL] assert np . all ( reverse_cumsum == np_reverse_cumsum ) , ( f" [string] " f" [string] { np_reverse_cumsum } [string] { reverse_cumsum }" ) [EOL] [EOL] forward_cumsum_excl = util . cumsum ( mx . nd , mx . nd . array ( vec ) , exclusive = True ) . asnumpy ( ) [EOL] np_forward_cumsum_excl = np . insert ( np_forward_cumsum [ ... , : - [number] ] , [number] , [number] , axis = - [number] ) [EOL] assert np . all ( forward_cumsum_excl == np_forward_cumsum_excl ) , ( f" [string] " f" [string] { np_forward_cumsum_excl } [string] { forward_cumsum_excl }" ) [EOL] [EOL] reverse_cumsum_excl = util . cumsum ( mx . nd , mx . nd . array ( vec ) , exclusive = True , reverse = True ) . asnumpy ( ) [EOL] np_reverse_cumsum_excl = np . insert ( np_reverse_cumsum [ ... , [number] : ] , np . shape ( vec ) [ - [number] ] - [number] , [number] , axis = - [number] ) [EOL] assert np . all ( reverse_cumsum_excl == np_reverse_cumsum_excl ) , ( f" [string] " f" [string] { np_reverse_cumsum_excl } [string] { reverse_cumsum_excl }" ) [EOL] [EOL] [EOL] def test_erf ( ) : [EOL] try : [EOL] from scipy . special import erf as scipy_erf [EOL] except : [EOL] pytest . skip ( [string] ) [EOL] [EOL] x = np . array ( [ - [number] , - [number] , - [number] ] + np . linspace ( - [number] , [number] , [number] ) . tolist ( ) + [ [number] , [number] , [number] ] ) [EOL] y_scipy = scipy_erf ( x ) [EOL] [EOL] [comment] [EOL] y_mxnet = util . erf ( mx . nd , mx . nd . array ( x ) ) . asnumpy ( ) [EOL] assert np . allclose ( y_mxnet , y_scipy , rtol = [number] ) [EOL] [EOL] [comment] [EOL] X = mx . symbol . Variable ( [string] ) [EOL] func = util . erf ( mx . sym , X ) [EOL] func_exec = func . bind ( ctx = mx . cpu ( ) , args = { [string] : mx . nd . array ( x ) } ) [EOL] func_exec . forward ( ) [EOL] y_mxnet_sym = func_exec . outputs [ [number] ] . asnumpy ( ) [EOL] assert np . allclose ( y_mxnet_sym , y_scipy , rtol = [number] ) [EOL] [EOL] [comment] [EOL] y_np = util . erf ( np , x ) [EOL] assert np . allclose ( y_np , y_scipy , atol = [number] ) [EOL] [EOL] [EOL] def test_erfinv ( ) : [EOL] try : [EOL] from scipy . special import erfinv as scipy_erfinv [EOL] except : [EOL] pytest . skip ( [string] ) [EOL] [EOL] x = np . linspace ( - [number] + [number] , [number] - [number] , [number] ) [EOL] y_scipy = scipy_erfinv ( x ) [EOL] [EOL] [comment] [EOL] y_mxnet = util . erfinv ( mx . nd , mx . nd . array ( x ) ) . asnumpy ( ) [EOL] assert np . allclose ( y_mxnet , y_scipy , rtol = [number] ) [EOL] [EOL] [comment] [EOL] X = mx . symbol . Variable ( [string] ) [EOL] func = util . erfinv ( mx . sym , X ) [EOL] func_exec = func . bind ( ctx = mx . cpu ( ) , args = { [string] : mx . nd . array ( x ) } ) [EOL] func_exec . forward ( ) [EOL] y_mxnet_sym = func_exec . outputs [ [number] ] . asnumpy ( ) [EOL] assert np . allclose ( y_mxnet_sym , y_scipy , rtol = [number] ) [EOL] [EOL] [comment] [EOL] y_np = util . erfinv ( np , x ) [EOL] assert np . allclose ( y_np , y_scipy , rtol = [number] ) [EOL] [EOL] [EOL] def sym_block_import_export_test_cases ( ) : [EOL] [comment] [EOL] class TestBlock1 ( mx . gluon . HybridBlock ) : [EOL] def hybrid_forward ( self , F , x1 , x2 ) : [EOL] return F . broadcast_mul ( x1 , x2 [ [number] ] ) [EOL] [EOL] [comment] [EOL] class TestBlock2 ( mx . gluon . HybridBlock ) : [EOL] def hybrid_forward ( self , F , x1 , x2 ) : [EOL] return F . broadcast_add ( F . broadcast_mul ( x1 , x2 [ [number] ] ) , F . broadcast_mul ( x1 , x2 [ [number] ] ) ) [EOL] [EOL] [comment] [EOL] class TestBlock3 ( mx . gluon . HybridBlock ) : [EOL] def __init__ ( self , ** kwargs ) : [EOL] super ( ) . __init__ ( ** kwargs ) [EOL] [EOL] with self . name_scope ( ) : [EOL] self . my_param = self . params . get ( [string] , shape = ( [number] , ) , init = mx . init . Constant ( [number] ) , allow_deferred_init = True , ) [EOL] [EOL] def hybrid_forward ( self , F , x1 , x2 , my_param ) : [EOL] y = F . broadcast_mul ( x2 [ [number] ] , my_param ) [EOL] return F . broadcast_add ( F . broadcast_mul ( x1 , x2 [ [number] ] ) , y ) [EOL] [EOL] [comment] [EOL] class TestBlock4 ( mx . gluon . HybridBlock ) : [EOL] def __init__ ( self , ** kwargs ) : [EOL] super ( ) . __init__ ( ** kwargs ) [EOL] [EOL] with self . name_scope ( ) : [EOL] self . my_param = self . params . get ( [string] , shape = ( [number] , ) , init = mx . init . Constant ( [number] ) , allow_deferred_init = True , ) [EOL] self . dense_layer = mx . gluon . nn . Dense ( [number] ) [EOL] [EOL] def hybrid_forward ( self , F , x1 , x2 , my_param ) : [EOL] y = self . dense_layer ( F . broadcast_mul ( x2 [ [number] ] , my_param ) ) [EOL] return F . broadcast_add ( F . broadcast_mul ( x1 , x2 [ [number] ] ) , y ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] return [ TestBlock2 , TestBlock3 , TestBlock4 ] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [ [string] , [string] ] , itertools . product ( sym_block_import_export_test_cases ( ) , [ True , False ] ) , ) def test_symb_block_export_import_nested_array ( block_type , hybridize ) : [EOL] x1 = mx . nd . array ( [ [number] , [number] , [number] ] ) [EOL] x2 = [ mx . nd . array ( [ [number] , [number] , [number] ] ) , mx . nd . array ( [ [number] , [number] , [number] ] ) ] [EOL] [EOL] my_block = block_type ( ) [EOL] my_block . collect_params ( ) . initialize ( ) [EOL] if hybridize : [EOL] my_block . hybridize ( ) [EOL] my_block ( x1 , x2 ) [EOL] [EOL] sb = util . hybrid_block_to_symbol_block ( my_block , [ x1 , x2 ] ) [EOL] [EOL] assert np . allclose ( sb ( x1 , x2 ) . asnumpy ( ) , my_block ( x1 , x2 ) . asnumpy ( ) ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , sym_block_import_export_test_cases ( ) ) def test_symb_block_import_backward_compatible ( block_type ) : [EOL] x1 = mx . nd . array ( [ [number] , [number] , [number] ] ) [EOL] x2 = [ mx . nd . array ( [ [number] , [number] , [number] ] ) , mx . nd . array ( [ [number] , [number] , [number] ] ) ] [EOL] [EOL] my_block = block_type ( ) [EOL] my_block . collect_params ( ) . initialize ( ) [EOL] my_block . hybridize ( ) [EOL] my_block ( x1 , x2 ) [EOL] [EOL] with tempfile . TemporaryDirectory ( prefix = [string] ) as temp_dir : [EOL] temp_path = Path ( temp_dir ) [EOL] [EOL] util . export_symb_block ( my_block , temp_path , [string] ) [EOL] [EOL] format_json_path = temp_path / [string] [EOL] [EOL] assert format_json_path . exists ( ) [EOL] try : [EOL] format_json_path . unlink ( ) [EOL] util . import_symb_block ( [number] , temp_path , [string] ) [EOL] except FileNotFoundError : [EOL] pytest . fail ( [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[gluonts.model.common.Tensor]$ 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 $typing.List[gluonts.model.common.Tensor]$ 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[gluonts.model.common.Tensor]$ 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[gluonts.model.common.Tensor]$ 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 $typing.List[gluonts.model.common.Tensor]$ 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[gluonts.model.common.Tensor]$ 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[gluonts.model.common.Tensor]$ 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[gluonts.model.common.Tensor]$ 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[gluonts.model.common.Tensor]$ 0 $typing.List[gluonts.model.common.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import math [EOL] import sys [EOL] [EOL] [comment] [EOL] from gluonts . mx . context import check_gpu_support [EOL] from gluonts . mx . kernels import RBFKernel [EOL] from gluonts . model . gp_forecaster . gaussian_process import GaussianProcess [EOL] from gluonts . support . linalg_util import jitter_cholesky , jitter_cholesky_eig [EOL] [EOL] [comment] [EOL] import mxnet . ndarray as nd [EOL] import mxnet as mx [EOL] import numpy as np [EOL] import pytest [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] @ pytest . mark . skipif ( sys . platform == [string] , reason = f" [string] " , ) @ pytest . mark . parametrize ( [string] , [ mx . Context ( [string] ) , mx . Context ( [string] ) ] ) @ pytest . mark . parametrize ( [string] , [ [string] , [string] ] ) @ pytest . mark . parametrize ( [string] , [ np . float32 , np . float64 ] ) def test_jitter_unit ( jitter_method , float_type , ctx ) : [EOL] [comment] [EOL] if ctx == mx . Context ( [string] ) and not check_gpu_support ( ) : [EOL] return [EOL] matrix = nd . array ( [ [ [ [number] , [number] ] , [ [number] , [number] ] ] , [ [ [number] , [number] ] , [ - [number] , [number] ] ] ] , ctx = ctx , dtype = float_type ) [EOL] F = mx . nd [EOL] num_data_points = matrix . shape [ [number] ] [EOL] if jitter_method == [string] : [EOL] L = jitter_cholesky_eig ( F , matrix , num_data_points , ctx , float_type ) [EOL] elif jitter_method == [string] : [EOL] L = jitter_cholesky ( F , matrix , num_data_points , ctx , float_type ) [EOL] assert np . sum ( np . isnan ( L . asnumpy ( ) ) ) == [number] , [string] [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] @ pytest . mark . skipif ( sys . platform == [string] , reason = f" [string] " , ) @ pytest . mark . parametrize ( [string] , [ mx . Context ( [string] ) , mx . Context ( [string] ) ] ) @ pytest . mark . parametrize ( [string] , [ [string] , [string] ] ) @ pytest . mark . parametrize ( [string] , [ np . float32 , np . float64 ] ) def test_jitter_synthetic_gp ( jitter_method , float_type , ctx ) : [EOL] [comment] [EOL] if ctx == mx . Context ( [string] ) and not check_gpu_support ( ) : [EOL] return [EOL] [comment] [EOL] batch_size = [number] [EOL] prediction_length = [number] [EOL] context_length = [number] [EOL] num_samples = [number] [EOL] [EOL] [comment] [EOL] lb = - [number] [EOL] ub = [number] [EOL] dx = ( ub - lb ) / ( prediction_length - [number] ) [EOL] x_test = nd . arange ( lb , ub + dx , dx , ctx = ctx , dtype = float_type ) . reshape ( - [number] , [number] ) [EOL] x_test = nd . tile ( x_test , reps = ( batch_size , [number] , [number] ) ) [EOL] [EOL] [comment] [EOL] amplitude = nd . ones ( ( batch_size , [number] , [number] ) , ctx = ctx , dtype = float_type ) [EOL] length_scale = math . sqrt ( [number] ) * nd . ones_like ( amplitude ) [EOL] sigma = math . sqrt ( [number] ) * nd . ones_like ( amplitude ) [EOL] [EOL] [comment] [EOL] rbf_kernel = RBFKernel ( amplitude , length_scale ) [EOL] [EOL] [comment] [EOL] gp = GaussianProcess ( sigma = sigma , kernel = rbf_kernel , prediction_length = prediction_length , context_length = context_length , num_samples = num_samples , ctx = ctx , float_type = float_type , jitter_method = jitter_method , sample_noise = False , ) [EOL] [EOL] [comment] [EOL] x_train = nd . array ( [ - [number] , - [number] , - [number] , - [number] , [number] ] , ctx = ctx , dtype = float_type ) . reshape ( context_length , [number] ) [EOL] x_train = nd . tile ( x_train , reps = ( batch_size , [number] , [number] ) ) [EOL] y_train = nd . sin ( x_train . squeeze ( axis = [number] ) ) [EOL] [EOL] [comment] [EOL] samples , predictive_mean , predictive_std = gp . exact_inference ( x_train , y_train , x_test ) [EOL] [EOL] assert ( np . sum ( np . isnan ( samples . asnumpy ( ) ) ) == [number] ) , [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] import pandas as pd [EOL] import pytest [EOL] [EOL] [comment] [EOL] from gluonts . evaluation import Evaluator , MultivariateEvaluator [EOL] from gluonts . model . forecast import QuantileForecast , SampleForecast [EOL] [EOL] QUANTILES = [ str ( q / [number] ) for q in range ( [number] , [number] ) ] [EOL] [EOL] [EOL] def data_iterator ( ts ) : [EOL] [docstring] [EOL] for i in range ( len ( ts ) ) : [EOL] yield ts [ i ] [EOL] [EOL] [EOL] def fcst_iterator ( fcst , start_dates , freq ) : [EOL] [docstring] [EOL] for i in range ( len ( fcst ) ) : [EOL] yield SampleForecast ( samples = fcst [ i ] , start_date = start_dates [ i ] , freq = freq ) [EOL] [EOL] [EOL] def iterator ( it ) : [EOL] [docstring] [EOL] return iter ( it ) [EOL] [EOL] [EOL] def iterable ( it ) : [EOL] [docstring] [EOL] return list ( it ) [EOL] [EOL] [EOL] def naive_forecaster ( ts , prediction_length , num_samples = [number] , target_dim = [number] ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] naive_pred = ts . values [ - prediction_length - [number] ] [EOL] assert len ( naive_pred . shape ) == target_dim [EOL] return np . tile ( naive_pred , ( num_samples , prediction_length ) + tuple ( [number] for _ in range ( target_dim ) ) , ) [EOL] [EOL] [EOL] def naive_multivariate_forecaster ( ts , prediction_length , num_samples = [number] ) : [EOL] return naive_forecaster ( ts , prediction_length , num_samples , target_dim = [number] ) [EOL] [EOL] [EOL] def calculate_metrics ( timeseries , evaluator , ts_datastructure , has_nans = False , forecaster = naive_forecaster , input_type = iterator , ) : [EOL] num_timeseries = timeseries . shape [ [number] ] [EOL] num_timestamps = timeseries . shape [ [number] ] [EOL] [EOL] if has_nans : [EOL] timeseries [ [number] , [number] ] = np . nan [EOL] timeseries [ [number] , [number] ] = np . nan [EOL] [EOL] num_samples = [number] [EOL] prediction_length = [number] [EOL] freq = [string] [EOL] [EOL] ts_start_dates = ( [ ] ) [comment] [EOL] pd_timeseries = [ ] [comment] [EOL] samples = [ ] [comment] [EOL] start_dates = [ ] [comment] [EOL] for i in range ( num_timeseries ) : [EOL] ts_start_dates . append ( pd . Timestamp ( year = [number] , month = [number] , day = [number] , hour = [number] ) ) [EOL] index = pd . date_range ( ts_start_dates [ i ] , periods = num_timestamps , freq = freq ) [EOL] [EOL] pd_timeseries . append ( ts_datastructure ( timeseries [ i ] , index = index ) ) [EOL] samples . append ( forecaster ( pd_timeseries [ i ] , prediction_length , num_samples ) ) [EOL] start_dates . append ( pd . date_range ( ts_start_dates [ i ] , periods = num_timestamps , freq = freq ) [ - prediction_length ] ) [EOL] [EOL] [comment] [EOL] data_iter = input_type ( data_iterator ( pd_timeseries ) ) [EOL] fcst_iter = input_type ( fcst_iterator ( samples , start_dates , freq ) ) [EOL] [EOL] [comment] [EOL] agg_df , item_df = evaluator ( data_iter , fcst_iter ) [EOL] return agg_df , item_df [EOL] [EOL] [EOL] TIMESERIES_M4 = [ np . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ - [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , ] ) , np . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , ] ) , ] [EOL] [EOL] RES_M4 = [ { [string] : [number] , [string] : [number] , [string] : [number] , [string] : np . array ( [ [number] , [number] , [number] , [number] , [number] ] ) , } , { [string] : [number] , [string] : [number] , [string] : [number] , [string] : np . array ( [ [number] , [number] , [number] , [number] , [number] ] ) , } , ] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , zip ( TIMESERIES_M4 , RES_M4 ) ) def test_MASE_sMAPE_M4 ( timeseries , res ) : [EOL] ts_datastructure = pd . Series [EOL] evaluator = Evaluator ( quantiles = QUANTILES ) [EOL] agg_df , item_df = calculate_metrics ( timeseries , evaluator , ts_datastructure ) [EOL] [EOL] assert abs ( ( agg_df [ [string] ] - res [ [string] ] ) / res [ [string] ] ) < [number] , ( [string] [string] . format ( res [ [string] ] , agg_df [ [string] ] ) ) [EOL] assert abs ( ( agg_df [ [string] ] - res [ [string] ] ) / res [ [string] ] ) < [number] , ( [string] [string] . format ( res [ [string] ] , agg_df [ [string] ] ) ) [EOL] assert abs ( ( agg_df [ [string] ] - res [ [string] ] ) / res [ [string] ] ) < [number] , ( [string] [string] . format ( res [ [string] ] , agg_df [ [string] ] ) ) [EOL] assert ( sum ( abs ( item_df [ [string] ] . values - res [ [string] ] ) ) < [number] ) , ( [string] [string] . format ( res [ [string] ] , item_df [ [string] ] . values ) ) [EOL] [EOL] [EOL] TIMESERIES = [ np . zeros ( ( [number] , [number] ) , dtype = np . float64 ) , np . ones ( ( [number] , [number] ) , dtype = np . float64 ) , np . ones ( ( [number] , [number] ) , dtype = np . float64 ) , np . arange ( [number] , [number] , dtype = np . float64 ) . reshape ( [number] , [number] ) , np . arange ( [number] , [number] , dtype = np . float64 ) . reshape ( [number] , [number] ) , np . array ( [ [ np . nan ] * [number] , [ [number] ] * [number] ] ) , ] [EOL] [EOL] RES = [ { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , } , { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , } , { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , } , { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , } , { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , } , { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , } , ] [EOL] [EOL] HAS_NANS = [ False , False , True , False , True , True ] [EOL] [EOL] [EOL] INPUT_TYPE = [ iterable , iterable , iterable , iterator , iterator , iterable ] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , zip ( TIMESERIES , RES , HAS_NANS , INPUT_TYPE ) , ) def test_metrics ( timeseries , res , has_nans , input_type ) : [EOL] ts_datastructure = pd . Series [EOL] evaluator = Evaluator ( quantiles = QUANTILES , num_workers = [number] ) [EOL] agg_metrics , item_metrics = calculate_metrics ( timeseries , evaluator , ts_datastructure , has_nans = has_nans , input_type = input_type , ) [EOL] [EOL] for metric , score in agg_metrics . items ( ) : [EOL] if metric in res . keys ( ) : [EOL] assert abs ( score - res [ metric ] ) < [number] , ( [string] [string] . format ( metric , res [ metric ] , score ) ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , zip ( TIMESERIES , RES , HAS_NANS , INPUT_TYPE ) , ) def test_metrics_mp ( timeseries , res , has_nans , input_type ) : [EOL] ts_datastructure = pd . Series [EOL] [comment] [EOL] evaluator = Evaluator ( quantiles = QUANTILES , num_workers = [number] ) [EOL] agg_metrics , item_metrics = calculate_metrics ( timeseries , evaluator , ts_datastructure , has_nans = has_nans , input_type = input_type , ) [EOL] [EOL] for metric , score in agg_metrics . items ( ) : [EOL] if metric in res . keys ( ) : [EOL] assert abs ( score - res [ metric ] ) < [number] , ( [string] [string] . format ( metric , res [ metric ] , score ) ) [EOL] [EOL] [EOL] TIMESERIES_MULTIVARIATE = [ np . ones ( ( [number] , [number] , [number] ) , dtype = np . float64 ) , np . ones ( ( [number] , [number] , [number] ) , dtype = np . float64 ) , np . ones ( ( [number] , [number] , [number] ) , dtype = np . float64 ) , np . stack ( ( np . arange ( [number] , [number] , dtype = np . float64 ) . reshape ( [number] , [number] ) , np . arange ( [number] , [number] , dtype = np . float64 ) . reshape ( [number] , [number] ) , ) , axis = [number] , ) , np . stack ( ( np . arange ( [number] , [number] , dtype = np . float64 ) . reshape ( [number] , [number] ) , np . arange ( [number] , [number] , dtype = np . float64 ) . reshape ( [number] , [number] ) , ) , axis = [number] , ) , np . stack ( ( np . arange ( [number] , [number] , dtype = np . float64 ) . reshape ( [number] , [number] ) , np . arange ( [number] , [number] , dtype = np . float64 ) . reshape ( [number] , [number] ) , ) , axis = [number] , ) , ] [EOL] [EOL] RES_MULTIVARIATE = [ { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , } , { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , } , { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , } , { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , } , { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , } , { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , } , ] [EOL] [EOL] HAS_NANS_MULTIVARIATE = [ False , False , False , False , False , False ] [EOL] [EOL] EVAL_DIMS = [ [ [number] ] , [ [number] ] , [ [number] , [number] ] , [ [number] ] , [ [number] ] , None ] [EOL] [EOL] INPUT_TYPE = [ iterable , iterable , iterator , iterator , iterable , iterator ] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , zip ( TIMESERIES_MULTIVARIATE , RES_MULTIVARIATE , HAS_NANS_MULTIVARIATE , EVAL_DIMS , INPUT_TYPE , ) , ) def test_metrics_multivariate ( timeseries , res , has_nans , eval_dims , input_type ) : [EOL] ts_datastructure = pd . DataFrame [EOL] evaluator = MultivariateEvaluator ( quantiles = QUANTILES , eval_dims = eval_dims , target_agg_funcs = { [string] : np . sum } , ) [EOL] [EOL] agg_metrics , item_metrics = calculate_metrics ( timeseries , evaluator , ts_datastructure , has_nans = has_nans , forecaster = naive_multivariate_forecaster , input_type = input_type , ) [EOL] [EOL] for metric , score in agg_metrics . items ( ) : [EOL] if metric in res . keys ( ) : [EOL] assert abs ( score - res [ metric ] ) < [number] , ( [string] [string] . format ( metric , res [ metric ] , score ) ) [EOL] [EOL] [EOL] def test_evaluation_with_QuantileForecast ( ) : [EOL] start = [string] [EOL] target = [ [number] , [number] , [number] , [number] , [number] , [number] ] * [number] [EOL] index = pd . date_range ( start = start , freq = [string] , periods = len ( target ) ) [EOL] ts = pd . Series ( index = index , data = target ) [EOL] [EOL] ev = Evaluator ( quantiles = ( [string] , [string] , [string] ) ) [EOL] [EOL] fcst = [ QuantileForecast ( start_date = pd . Timestamp ( [string] ) , freq = [string] , forecast_arrays = np . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] ] * [number] ] ) , forecast_keys = [ [string] ] , ) ] [EOL] [EOL] agg_metric , _ = ev ( iter ( [ ts ] ) , iter ( fcst ) ) [EOL] [EOL] assert np . isfinite ( agg_metric [ [string] ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] import math [EOL] [EOL] import pytest [EOL] from mxnet import nd [EOL] [EOL] [comment] [EOL] from gluonts . mx . kernels import PeriodicKernel [EOL] [EOL] test_cases = [ ( nd . array ( [ [number] , [number] , [number] ] ) . expand_dims ( [number] ) , nd . array ( [ [number] , [number] , [number] ] ) . expand_dims ( [number] ) , nd . array ( [ [number] ] ) , nd . array ( [ [number] ] ) , nd . array ( [ [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] ] ) , ) , ( nd . array ( [ [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] ] ) , nd . array ( [ [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] ] ) , nd . array ( [ [number] ] ) , nd . array ( [ [number] ] ) , nd . array ( [ [ [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] ] ] ) , ) , ( nd . array ( [ [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] ] ) , nd . array ( [ [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] ] ) , nd . array ( [ [number] ] ) , nd . array ( [ [number] ] ) , nd . array ( [ [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] ] ) , ) , ( nd . array ( [ [ [number] , - [number] , [number] ] , [ [number] , [number] , - [number] ] ] ) , nd . array ( [ [ [number] , [number] , [number] ] , [ [number] , - [number] , [number] ] , [ [number] , [number] , - [number] ] , [ - [number] , - [number] , [number] ] ] ) , nd . array ( [ [number] , [number] , [number] ] ) , nd . array ( [ [number] , [number] , [number] ] ) , nd . array ( [ [ [ [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] ] ] , [ [ [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] ] ] , [ [ [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] ] ] , ] ) , ) , ] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , test_cases ) def test_periodic_kernel ( x1 , x2 , amplitude , length_scale , exact ) : [EOL] tol = [number] [EOL] batch_size = amplitude . shape [ [number] ] [EOL] history_length_1 = x1 . shape [ [number] ] [EOL] history_length_2 = x2 . shape [ [number] ] [EOL] num_features = x1 . shape [ [number] ] [EOL] if batch_size > [number] : [EOL] x1 = nd . tile ( x1 , reps = ( batch_size , [number] , [number] ) ) [EOL] x2 = nd . tile ( x2 , reps = ( batch_size , [number] , [number] ) ) [EOL] for i in range ( [number] , batch_size ) : [EOL] x1 [ i , : , : ] = ( i + [number] ) * x1 [ i , : , : ] [EOL] x2 [ i , : , : ] = ( i - [number] ) * x2 [ i , : , : ] [EOL] else : [EOL] x1 = x1 . reshape ( batch_size , history_length_1 , num_features ) [EOL] x2 = x2 . reshape ( batch_size , history_length_2 , num_features ) [EOL] amplitude = amplitude . reshape ( batch_size , [number] , [number] ) [EOL] length_scale = length_scale . reshape ( batch_size , [number] , [number] ) [EOL] frequency = [number] / [number] * nd . ones_like ( length_scale ) [EOL] periodic = PeriodicKernel ( amplitude , length_scale , frequency ) [EOL] [EOL] exact = amplitude * nd . exp ( - [number] * nd . sin ( frequency * math . pi * nd . sqrt ( exact ) ) ** [number] / length_scale ** [number] ) [EOL] [EOL] res = periodic . kernel_matrix ( x1 , x2 ) [EOL] assert nd . norm ( exact - res ) < tol [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] @ pytest . mark . parametrize ( [string] , [ nd . array ( [ [number] , [number] , [number] ] ) . expand_dims ( [number] ) ] ) @ pytest . mark . parametrize ( [string] , [ nd . array ( [ [number] , [number] ] ) . expand_dims ( [number] ) ] ) @ pytest . mark . parametrize ( [string] , [ nd . array ( [ [number] ] ) ] ) @ pytest . mark . parametrize ( [string] , [ nd . array ( [ [number] ] ) ] ) @ pytest . mark . parametrize ( [string] , [ nd . array ( [ [number] / [number] ] ) ] ) def test_periodic_kernel_compute ( x1 , x2 , amplitude , length_scale , frequency ) : [EOL] tol = [number] [EOL] batch_size = amplitude . shape [ [number] ] [EOL] history_length_1 = x1 . shape [ [number] ] [EOL] history_length_2 = x2 . shape [ [number] ] [EOL] num_features = x1 . shape [ [number] ] [EOL] x1 = x1 . reshape ( batch_size , history_length_1 , num_features ) [EOL] x2 = x2 . reshape ( batch_size , history_length_2 , num_features ) [EOL] amplitude = amplitude . reshape ( batch_size , [number] , [number] ) [EOL] length_scale = length_scale . reshape ( batch_size , [number] , [number] ) [EOL] frequency = frequency . reshape ( batch_size , [number] , [number] ) [EOL] periodic = PeriodicKernel ( amplitude , length_scale , frequency ) [EOL] [EOL] exact = nd . zeros ( ( batch_size , history_length_1 , history_length_2 ) ) [EOL] for i in range ( history_length_1 ) : [EOL] for j in range ( history_length_2 ) : [EOL] val = ( [number] * ( nd . sin ( frequency * math . pi * ( x1 [ : , i , : ] - x2 [ : , j , : ] ) ) / length_scale ) ** [number] ) [EOL] exact [ : , i , j ] = ( amplitude * nd . exp ( - val ) ) . reshape ( - [number] ) [EOL] res = periodic . kernel_matrix ( x1 , x2 ) [EOL] assert nd . norm ( res - exact ) < tol [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import pytest [EOL] [EOL] from gluonts . time_feature import get_seasonality [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [string] , [number] ) , ( [string] , [number] ) , ( [string] , [number] ) , ( [string] , [number] ) , ( [string] , [number] ) , ( [string] , [number] ) , ( [string] , [number] ) , ( [string] , [number] ) , ( [string] , [number] ) , ( [string] , [number] ) , ( [string] , [number] ) , ( [string] , [number] ) , ( [string] , [number] ) , ] , ) def test_get_seasonality ( freq , expected_seasonality ) : [EOL] assert get_seasonality ( freq ) == expected_seasonality [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] import pandas as pd [EOL] import pytest [EOL] [EOL] [comment] [EOL] from gluonts . dataset . field_names import FieldName [EOL] from gluonts . dataset . common import ListDataset [EOL] from gluonts . transform import AddAggregateLags [EOL] [EOL] [EOL] expected_lags_rolling = { [string] : { [string] : np . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , ] ) , [string] : np . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , ] ) , } , [string] : { [string] : np . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , ] ) , [string] : np . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , ] ) , } , } [EOL] [EOL] [EOL] valid_lags_rolling = { [string] : [ [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] ] , } [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ [number] , [number] ] ) def test_agg_lags ( pred_length ) : [EOL] [comment] [EOL] target = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] start = pd . Timestamp ( [string] , freq = [string] ) [EOL] freq = [string] [EOL] ds = ListDataset ( [ { FieldName . TARGET : target , FieldName . START : start } ] , freq = freq ) [EOL] [EOL] [comment] [EOL] lags_2H = [ [number] , [number] , [number] , [number] , [number] ] [EOL] [EOL] add_agg_lags = AddAggregateLags ( target_field = FieldName . TARGET , output_field = [string] , pred_length = pred_length , base_freq = freq , agg_freq = [string] , agg_lags = lags_2H , ) [EOL] [EOL] assert add_agg_lags . ratio == [number] [EOL] [EOL] train_entry = next ( add_agg_lags ( iter ( ds ) , is_train = True ) ) [EOL] test_entry = next ( add_agg_lags ( iter ( ds ) , is_train = False ) ) [EOL] [EOL] assert ( add_agg_lags . valid_lags == valid_lags_rolling [ f" [string] { pred_length }" ] ) [EOL] [EOL] assert np . allclose ( train_entry [ [string] ] , expected_lags_rolling [ f" [string] { pred_length }" ] [ [string] ] , ) [EOL] [EOL] assert np . allclose ( test_entry [ [string] ] , expected_lags_rolling [ f" [string] { pred_length }" ] [ [string] ] , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [docstring] [EOL] [EOL] [comment] [EOL] import gluonts . time_feature . lag as date_feature_set [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] expected_lags = { [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] + [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] + [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] + [ [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] + [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] + [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] + [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] + [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] + [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] + [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] + [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] + [ [number] , [number] , [number] ] + [ [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] + [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] + [ [number] , [number] , [number] ] + [ [number] , [number] ] + [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] + [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] + [ [number] , [number] , [number] ] + [ [number] , [number] ] + [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] + [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] + [ [number] , [number] ] + [ [number] , [number] ] + [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] + [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] + [ [number] , [number] ] + [ [number] , [number] ] + [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] ] + [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] + [ [number] ] + [ [number] , [number] ] + [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] + [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] + [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] + [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , } [EOL] [EOL] [comment] [EOL] for freq in [ [string] , [string] , [string] , [string] , [string] ] : [EOL] expected_lags [ [string] + freq ] = expected_lags [ freq ] [EOL] [EOL] [comment] [EOL] expected_lags [ [string] ] = expected_lags [ [string] ] [EOL] expected_lags [ [string] ] = expected_lags [ [string] ] [EOL] expected_lags [ [string] ] = expected_lags [ [string] ] [EOL] [EOL] [EOL] def test_lags ( ) : [EOL] [EOL] freq_strs = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , ] [EOL] [EOL] for freq_str in freq_strs : [EOL] lags = date_feature_set . get_lags_for_frequency ( freq_str ) [EOL] [EOL] assert ( lags == expected_lags [ freq_str ] ) , [string] . format ( freq_str , expected_lags [ freq_str ] , lags ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] test_lags ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] import pandas as pd [EOL] import pytest [EOL] [EOL] [comment] [EOL] from gluonts . time_feature . holiday import ( CHRISTMAS_DAY , CHRISTMAS_EVE , COLUMBUS_DAY , EASTER_MONDAY , EASTER_SUNDAY , GOOD_FRIDAY , INDEPENDENCE_DAY , LABOR_DAY , MARTIN_LUTHER_KING_DAY , MEMORIAL_DAY , MOTHERS_DAY , NEW_YEARS_DAY , NEW_YEARS_EVE , PRESIDENTS_DAY , SPECIAL_DATE_FEATURES , SUPERBOWL , THANKSGIVING , BLACK_FRIDAY , CYBER_MONDAY , SpecialDateFeatureSet , squared_exponential_kernel , ) [EOL] [EOL] test_dates = { NEW_YEARS_DAY : [ [string] , [string] , [string] , [string] , [string] , ] , MARTIN_LUTHER_KING_DAY : [ [string] , [string] , [string] , [string] , [string] , ] , SUPERBOWL : [ [string] , [string] , [string] , [string] ] , PRESIDENTS_DAY : [ [string] , [string] , [string] , [string] ] , MEMORIAL_DAY : [ [string] , [string] , [string] , [string] , [string] , ] , GOOD_FRIDAY : [ [string] , [string] , [string] , [string] , [string] , ] , EASTER_SUNDAY : [ [string] , [string] , [string] , [string] , [string] , ] , EASTER_MONDAY : [ [string] , [string] , [string] , [string] , [string] , ] , MOTHERS_DAY : [ [string] , [string] , [string] , [string] ] , INDEPENDENCE_DAY : [ [string] , [string] , [string] , [string] ] , LABOR_DAY : [ [string] , [string] , [string] , [string] ] , COLUMBUS_DAY : [ [string] , [string] , [string] , [string] ] , THANKSGIVING : [ [string] , [string] , [string] , [string] , [string] , ] , CHRISTMAS_EVE : [ [string] , [string] , [string] , [string] ] , CHRISTMAS_DAY : [ [string] , [string] , [string] , [string] ] , NEW_YEARS_EVE : [ [string] , [string] , [string] , [string] ] , BLACK_FRIDAY : [ [string] , [string] , [string] , [string] , [string] , ] , CYBER_MONDAY : [ [string] , [string] , [string] , [string] , [string] , ] , } [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , test_dates . keys ( ) ) def test_holidays ( holiday ) : [EOL] for test_date in test_dates [ holiday ] : [EOL] test_date = pd . to_datetime ( test_date ) [EOL] distance_function = SPECIAL_DATE_FEATURES [ holiday ] [EOL] assert ( distance_function ( test_date ) == [number] ) , [string] . format ( holiday ) [EOL] [EOL] [EOL] def test_special_date_feature_set_daily ( ) : [EOL] date_indices = pd . date_range ( start = [string] , end = [string] , freq = [string] ) [EOL] [EOL] reference_features = np . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , ] ) [EOL] sfs = SpecialDateFeatureSet ( [ CHRISTMAS_EVE , CHRISTMAS_DAY , NEW_YEARS_EVE ] ) [EOL] computed_features = sfs ( date_indices ) [EOL] [EOL] assert ( computed_features == reference_features ) . all ( ) , [string] [EOL] [EOL] [EOL] def test_special_date_feature_set_hourly ( ) : [EOL] date_indices = pd . date_range ( start = [string] , end = [string] , freq = [string] ) [EOL] [EOL] reference_features = np . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , ] ) [EOL] sfs = SpecialDateFeatureSet ( [ CHRISTMAS_EVE , CHRISTMAS_DAY , NEW_YEARS_EVE ] ) [EOL] computed_features = sfs ( date_indices ) [EOL] [EOL] assert ( computed_features == reference_features ) . all ( ) , [string] [EOL] [EOL] [EOL] def test_special_date_feature_set_daily_squared_exponential ( ) : [EOL] date_indices = pd . date_range ( start = [string] , end = [string] , freq = [string] ) [EOL] reference_features = np . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , ] , ] , dtype = float , ) [EOL] [EOL] squared_exp_kernel = squared_exponential_kernel ( alpha = [number] ) [EOL] sfs = SpecialDateFeatureSet ( [ CHRISTMAS_EVE , CHRISTMAS_DAY ] , squared_exp_kernel ) [EOL] computed_features = sfs ( date_indices ) [EOL] np . testing . assert_almost_equal ( computed_features , reference_features , decimal = [number] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Dict [EOL] import typing [EOL] import builtins [EOL] import random [EOL] from textwrap import dedent [EOL] from typing import Dict , List [EOL] [EOL] [comment] [EOL] from gluonts . core . component import validated [EOL] from gluonts . core . serde import dump_code , dump_json , load_code , load_json [EOL] [EOL] [EOL] class Complex : [EOL] @ validated ( ) def __init__ ( self , x , y ) : [EOL] self . x = x [EOL] self . y = y [EOL] [EOL] assert type ( self . x ) == float [EOL] assert type ( self . y ) == float [EOL] [EOL] def __eq__ ( self , that ) : [EOL] return self . x == that . x and self . y == that . y [EOL] [EOL] def __hash__ ( self ) : [EOL] return hash ( ( self . x , self . y ) ) [EOL] [EOL] [EOL] class Foo : [EOL] @ validated ( ) def __init__ ( self , a , c , ** kwargs ) : [EOL] self . a = a [EOL] self . b = kwargs [ [string] ] [EOL] self . c = c [EOL] [EOL] assert type ( self . a ) == int [EOL] assert type ( self . b ) == float [EOL] assert type ( self . c ) == Complex [EOL] [EOL] def __eq__ ( self , that ) : [EOL] return self . a == that . a and self . b == that . b and self . c == that . c [EOL] [EOL] def __hash__ ( self ) : [EOL] return hash ( ( self . a , self . b , self . c ) ) [EOL] [EOL] [EOL] class Baz ( Foo ) : [EOL] @ validated ( ) def __init__ ( self , a , b , c , d ) : [EOL] super ( ) . __init__ ( a = a , c = c , b = b ) [EOL] self . d = d [EOL] [EOL] [EOL] class Bar : [EOL] @ validated ( ) def __init__ ( self , x_list , x_dict , input_fields , ) : [EOL] self . x_list = x_list [EOL] self . x_dict = x_dict [EOL] self . input_fields = input_fields [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] class test : [EOL] class test_components : [EOL] Complex = Complex [EOL] Bar = Bar [EOL] Foo = Foo [EOL] [EOL] [EOL] [comment] [EOL] def test_component_ctor ( ) : [EOL] random . seed ( [number] ) [EOL] [EOL] A = [number] [EOL] B = [number] [EOL] C = [number] [EOL] [EOL] x_list = [ Foo ( str ( random . randint ( [number] , A ) ) , Complex ( x = random . uniform ( [number] , C ) , y = str ( random . uniform ( [number] , C ) ) ) , b = random . uniform ( [number] , B ) , ) for i in range ( [number] ) ] [EOL] fields = [ Foo ( a = str ( random . randint ( [number] , A ) ) , b = random . uniform ( [number] , B ) , c = Complex ( x = str ( random . uniform ( [number] , C ) ) , y = random . uniform ( [number] , C ) ) , ) for i in range ( [number] ) ] [EOL] x_dict = { i : Foo ( b = random . uniform ( [number] , B ) , a = str ( random . randint ( [number] , A ) ) , c = Complex ( x = str ( random . uniform ( [number] , C ) ) , y = str ( random . uniform ( [number] , C ) ) ) , ) for i in range ( [number] ) } [EOL] [EOL] bar01 = Bar ( x_list , input_fields = fields , x_dict = x_dict ) [EOL] bar02 = load_code ( dump_code ( bar01 ) ) [EOL] bar03 = load_json ( dump_json ( bar02 ) ) [EOL] [EOL] def compare_tpes ( x , y , z , tpe ) : [EOL] assert tpe == type ( x ) == type ( y ) == type ( z ) [EOL] [EOL] def compare_vals ( x , y , z ) : [EOL] assert x == y == z [EOL] [EOL] compare_tpes ( bar02 . x_list , bar02 . x_list , bar03 . x_list , tpe = list ) [EOL] compare_tpes ( bar02 . x_dict , bar02 . x_dict , bar03 . x_dict , tpe = dict ) [EOL] compare_tpes ( bar02 . input_fields , bar02 . input_fields , bar03 . input_fields , tpe = list ) [EOL] [EOL] compare_vals ( len ( bar02 . x_list ) , len ( bar02 . x_list ) , len ( bar03 . x_list ) ) [EOL] compare_vals ( len ( bar02 . x_dict ) , len ( bar02 . x_dict ) , len ( bar03 . x_dict ) ) [EOL] compare_vals ( len ( bar02 . input_fields ) , len ( bar02 . input_fields ) , len ( bar03 . input_fields ) , ) [EOL] [EOL] compare_vals ( bar02 . x_list , bar02 . x_list , bar03 . x_list ) [EOL] compare_vals ( bar02 . x_dict , bar02 . x_dict , bar03 . x_dict ) [EOL] compare_vals ( bar02 . input_fields , bar02 . input_fields , bar03 . input_fields ) [EOL] [EOL] baz01 = Baz ( a = [string] , b = [string] , c = Complex ( x = [string] , y = [string] ) , d = [string] ) [EOL] baz02 = load_json ( dump_json ( baz01 ) ) [EOL] [EOL] assert type ( baz01 ) == type ( baz02 ) [EOL] assert baz01 == baz02 [EOL] [EOL] [EOL] def test_dynamic_loading ( ) : [EOL] code = dedent ( [string] ) [EOL] [EOL] load_code ( code ) [EOL] [EOL] [EOL] def test_to_code ( ) : [EOL] c1 = Complex ( x = [number] , y = [number] ) [EOL] c2 = Complex ( y = [number] , x = [number] ) [EOL] [EOL] assert repr ( c1 ) == repr ( c2 ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.int$ 0 $builtins.float$ 0 $Complex$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 $Complex$ 0 $Complex$ 0 $builtins.float$ 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List [EOL] import typing [EOL] import builtins [EOL] from pathlib import Path [EOL] from typing import List , NamedTuple [EOL] [EOL] [comment] [EOL] import mxnet as mx [EOL] import numpy as np [EOL] import pandas as pd [EOL] import pytest [EOL] from pydantic import BaseModel [EOL] [EOL] [comment] [EOL] from gluonts . core import serde [EOL] [EOL] [comment] [EOL] [comment] [EOL] from gluonts . core . component import equals , equals_list [EOL] [EOL] [EOL] class Span ( NamedTuple ) : [EOL] path = ... [EOL] line = ... [EOL] [EOL] [EOL] class BestEpochInfo ( NamedTuple ) : [EOL] params_path = ... [EOL] epoch_no = ... [EOL] metric_value = ... [EOL] [EOL] [EOL] class CategoricalFeatureInfo ( BaseModel ) : [EOL] name = ... [EOL] cardinality = ... [EOL] [EOL] [EOL] class MyGluonBlock ( mx . gluon . HybridBlock ) : [EOL] def __init__ ( self , feature_infos , feature_dims , ) : [EOL] super ( ) . __init__ ( ) [EOL] self . feature_infos = feature_infos [EOL] self . feature_dims = feature_dims [EOL] [EOL] def hybrid_forward ( self , F , x , * args , ** kwargs ) : [EOL] raise NotImplementedError [EOL] [EOL] [comment] [EOL] def __getnewargs_ex__ ( self ) : [EOL] return ( self . feature_infos , self . feature_dims ) , dict ( ) [EOL] [EOL] def __eq__ ( self , that ) : [EOL] if isinstance ( that , MyGluonBlock ) : [EOL] return self . __getnewargs_ex__ ( ) == that . __getnewargs_ex__ ( ) [EOL] else : [EOL] return False [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] best_epoch_info = BestEpochInfo ( params_path = Path ( [string] ) , epoch_no = [number] , metric_value = [number] ) [EOL] [EOL] feature_info = CategoricalFeatureInfo ( name = [string] , cardinality = [number] ) [EOL] [EOL] custom_type = MyGluonBlock ( feature_infos = [ feature_info ] , feature_dims = [ [number] ] ) [EOL] [EOL] numpy_array = np . array ( [ [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] ] , dtype = np . float64 ) [EOL] [EOL] list_container = [ best_epoch_info , feature_info , custom_type , [number] , [number] , [string] , numpy_array , ] [EOL] [EOL] set_container = { best_epoch_info , [number] , [number] , [string] } [EOL] [EOL] dict_container = dict ( best_epoch_info = best_epoch_info , feature_info = feature_info , custom_type = custom_type , ) [EOL] [EOL] simple_types = [ [number] , [number] , [string] , np . int32 ( [number] ) , np . float64 ( [number] ) , ] [comment] [EOL] [EOL] complex_types = [ Path ( [string] ) , best_epoch_info , feature_info , custom_type , numpy_array , ] [EOL] [EOL] container_types = [ list_container , dict_container , set_container ] [EOL] [EOL] examples = simple_types + complex_types + container_types [comment] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , examples ) def test_binary_serialization ( e ) : [EOL] assert equals ( e , serde . load_binary ( serde . dump_binary ( e ) ) ) [EOL] [EOL] [EOL] def check_equality ( expected , actual ) : [EOL] if isinstance ( expected , set ) : [EOL] [comment] [EOL] return equals_list ( sorted ( expected , key = hash ) , sorted ( actual , key = hash ) ) [EOL] elif np . issubdtype ( type ( expected ) , np . integer ) : [EOL] [comment] [EOL] return np . equal ( expected , actual ) [EOL] elif np . issubdtype ( type ( expected ) , np . inexact ) : [EOL] [comment] [EOL] return np . allclose ( expected , actual ) [EOL] else : [EOL] return equals ( expected , actual ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , examples ) def test_json_serialization ( e ) : [EOL] expected , actual = e , serde . load_json ( serde . dump_json ( e ) ) [EOL] assert check_equality ( expected , actual ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , examples ) def test_code_serialization ( e ) : [EOL] expected , actual = e , serde . load_code ( serde . dump_code ( e ) ) [EOL] assert check_equality ( expected , actual ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ mx . nd . random . uniform ( shape = ( [number] , [number] , [number] ) , dtype = [string] ) , mx . nd . random . uniform ( shape = ( [number] , [number] , [number] ) , dtype = [string] ) , mx . nd . random . uniform ( shape = ( [number] , [number] , [number] ) , dtype = [string] ) , mx . nd . array ( [ [ [number] , [number] , [number] ] , [ - [number] , - [number] , [number] ] ] , dtype = np . uint8 ) , mx . nd . array ( [ [ [number] , [number] , [number] ] , [ - [number] , - [number] , [number] ] ] , dtype = np . int32 ) , mx . nd . array ( [ [ [number] , [number] , [number] ] , [ - [number] , - [number] , [number] ] ] , dtype = np . int64 ) , mx . nd . array ( [ [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] ] , dtype = np . uint8 ) , ] , ) @ pytest . mark . parametrize ( [string] , [ lambda x : serde . load_json ( serde . dump_json ( x ) ) , lambda x : serde . load_binary ( serde . dump_binary ( x ) ) , lambda x : serde . load_code ( serde . dump_code ( x ) ) , ] , ) def test_ndarray_serialization ( a , serialize_fn ) : [EOL] b = serialize_fn ( a ) [EOL] assert type ( a ) == type ( b ) [EOL] assert a . dtype == b . dtype [EOL] assert a . shape == b . shape [EOL] assert np . all ( ( a == b ) . asnumpy ( ) ) [EOL] [EOL] [EOL] def test_timestamp_encode_decode ( ) : [EOL] now = pd . Timestamp . now ( ) [EOL] assert now == serde . decode ( serde . encode ( now ) ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ lambda x : serde . load_json ( serde . dump_json ( x ) ) , lambda x : serde . load_binary ( serde . dump_binary ( x ) ) , lambda x : serde . load_code ( serde . dump_code ( x ) ) , ] , ) def test_string_escape ( serialize_fn ) : [EOL] assert serialize_fn ( [string] ) == [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pathlib.Path$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $pathlib.Path$ 0 0 0 $builtins.int$ 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import logging [EOL] import math [EOL] import pytest [EOL] from pathlib import Path [EOL] [EOL] [comment] [EOL] import gluonts [EOL] from gluonts . core . component import equals [EOL] from gluonts . core . serde import load_code , dump_code [EOL] from gluonts . dataset . artificial import constant_dataset [EOL] from gluonts . dataset . stat import ( DatasetStatistics , ScaleHistogram , calculate_dataset_statistics , ) [EOL] from gluonts . evaluation import Evaluator [EOL] from gluonts . evaluation . backtest import BacktestInformation , backtest_metrics [EOL] from gluonts . model . trivial . mean import MeanEstimator [EOL] [EOL] root = logging . getLogger ( ) [EOL] root . setLevel ( logging . DEBUG ) [EOL] [EOL] [EOL] def make_estimator ( freq , prediction_length ) : [EOL] [comment] [EOL] return MeanEstimator ( prediction_length = prediction_length , freq = freq , num_samples = [number] ) [EOL] [EOL] [EOL] def test_forecast_parser ( ) : [EOL] [comment] [EOL] [comment] [EOL] [EOL] dataset_info , train_ds , test_ds = constant_dataset ( ) [EOL] [EOL] estimator = make_estimator ( dataset_info . metadata . freq , dataset_info . prediction_length ) [EOL] assert repr ( estimator ) == repr ( load_code ( repr ( estimator ) ) ) [EOL] [EOL] predictor = estimator . train ( training_data = train_ds ) [EOL] [EOL] stats = calculate_dataset_statistics ( train_ds ) [EOL] assert stats == eval ( repr ( stats ) , globals ( ) , { [string] : gluonts } ) [comment] [EOL] [EOL] evaluator = Evaluator ( quantiles = [ [number] , [number] , [number] ] ) [EOL] agg_metrics , _ = backtest_metrics ( test_ds , predictor , evaluator ) [EOL] [EOL] [comment] [EOL] for key , val in agg_metrics . items ( ) : [EOL] if not math . isfinite ( val ) : [EOL] agg_metrics [ key ] = [number] [EOL] [EOL] assert agg_metrics == load_code ( dump_code ( agg_metrics ) ) [EOL] [EOL] [EOL] @ pytest . mark . skip ( ) def test_benchmark ( caplog ) : [EOL] [comment] [EOL] [comment] [EOL] [EOL] with caplog . at_level ( logging . DEBUG ) : [EOL] dataset_info , train_ds , test_ds = constant_dataset ( ) [EOL] [EOL] estimator = make_estimator ( dataset_info . metadata . freq , dataset_info . prediction_length ) [EOL] predictor = estimator . train ( training_data = train_ds ) [EOL] evaluator = Evaluator ( quantiles = [ [number] , [number] , [number] ] ) [EOL] backtest_metrics ( test_ds , predictor , evaluator ) [EOL] train_stats = calculate_dataset_statistics ( train_ds ) [EOL] test_stats = calculate_dataset_statistics ( test_ds ) [EOL] [EOL] log_info = BacktestInformation . make_from_log_contents ( caplog . text ) [EOL] [EOL] assert train_stats == log_info . train_dataset_stats [EOL] assert test_stats == log_info . test_dataset_stats [EOL] assert equals ( estimator , log_info . estimator ) [EOL] [EOL] print ( log_info ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import gluonts [EOL] import pytest [EOL] [EOL] import numpy as np [EOL] [EOL] from gluonts . model . estimator import Estimator [EOL] from gluonts . model . simple_feedforward import SimpleFeedForwardEstimator [EOL] from gluonts . dataset . common import Dataset , ListDataset [EOL] from gluonts . mx . trainer import Trainer [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( ListDataset ( data_iter = [ { [string] : [string] , [string] : np . random . normal ( loc = [number] , scale = [number] , size = [number] ) , [string] : [string] , [string] : { [string] : [ [number] , [number] , [number] ] } , } , { [string] : [string] , [string] : np . random . normal ( loc = [number] , scale = [number] , size = [number] ) , [string] : [string] , [string] : { [string] : [ [number] , [number] , [number] ] } , } , { [string] : [string] , [string] : np . random . normal ( loc = [number] , scale = [number] , size = [number] ) , [string] : [string] , [string] : { [string] : [ [number] , [number] , [number] ] } , } , ] , freq = [string] , ) , SimpleFeedForwardEstimator ( freq = [string] , prediction_length = [number] , context_length = [number] , trainer = Trainer ( epochs = [number] , num_batches_per_epoch = [number] , batch_size = [number] , hybridize = False , ) , ) , ) , ] , ) def test_item_id_info ( dataset , estimator ) : [EOL] predictor = estimator . train ( dataset ) [EOL] forecasts = predictor . predict ( dataset ) [EOL] for data_entry , forecast in zip ( dataset , forecasts ) : [EOL] assert ( not [string] in data_entry ) or data_entry [ [string] ] == forecast . item_id [EOL] assert ( not [string] in data_entry ) or data_entry [ [string] ] == forecast . info [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from gluonts . dataset . common import ListDataset [EOL] from gluonts . evaluation . backtest import backtest_metrics [EOL] from gluonts . model . predictor import ParallelizedPredictor , Localizer [EOL] from gluonts . model . trivial . identity import IdentityPredictor [EOL] from gluonts . model . trivial . mean import MeanEstimator [EOL] [EOL] [EOL] def test_parallelized_predictor ( ) : [EOL] dataset = ListDataset ( data_iter = [ { [string] : [string] , [string] : ( np . zeros ( [number] ) + i ) . tolist ( ) } for i in range ( [number] ) ] , freq = [string] , ) [EOL] [EOL] base_predictor = IdentityPredictor ( freq = [string] , prediction_length = [number] , num_samples = [number] ) [EOL] [EOL] predictor = ParallelizedPredictor ( base_predictor = base_predictor , num_workers = [number] , chunk_size = [number] ) [EOL] [EOL] predictions = list ( base_predictor . predict ( dataset ) ) [EOL] parallel_predictions = list ( predictor . predict ( dataset ) ) [EOL] [EOL] assert len ( predictions ) == len ( parallel_predictions ) [EOL] [EOL] for p , pp in zip ( predictions , parallel_predictions ) : [EOL] assert np . all ( p . samples == pp . samples ) [EOL] assert np . all ( p . index == pp . index ) [EOL] [EOL] [EOL] def test_localizer ( ) : [EOL] dataset = ListDataset ( data_iter = [ { [string] : [string] , [string] : ( np . zeros ( [number] ) + i * [number] + [number] ) , [string] : f"{ i }" , } for i in range ( [number] ) ] , freq = [string] , ) [EOL] [EOL] estimator = MeanEstimator ( prediction_length = [number] , freq = [string] , num_samples = [number] ) [EOL] [EOL] local_pred = Localizer ( estimator = estimator ) [EOL] agg_metrics , _ = backtest_metrics ( test_dataset = dataset , predictor = local_pred ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] import pandas as pd [EOL] import pytest [EOL] import mxnet as mx [EOL] [EOL] [comment] [EOL] from gluonts . model . forecast import ( QuantileForecast , SampleForecast , DistributionForecast , ) [EOL] [EOL] from gluonts . mx . distribution import Uniform [EOL] [EOL] QUANTILES = np . arange ( [number] , [number] ) / [number] [EOL] SAMPLES = np . arange ( [number] ) . reshape ( [number] , [number] ) / [number] [EOL] START_DATE = pd . Timestamp ( [number] , [number] , [number] , [number] ) [EOL] FREQ = [string] [EOL] [EOL] FORECASTS = { [string] : QuantileForecast ( forecast_arrays = QUANTILES . reshape ( - [number] , [number] ) , start_date = START_DATE , forecast_keys = np . array ( QUANTILES , str ) , freq = FREQ , ) , [string] : SampleForecast ( samples = SAMPLES , start_date = START_DATE , freq = FREQ ) , [string] : DistributionForecast ( distribution = Uniform ( low = mx . nd . zeros ( [number] ) , high = mx . nd . ones ( [number] ) ) , start_date = START_DATE , freq = FREQ , ) , } [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , FORECASTS . keys ( ) ) def test_Forecast ( name ) : [EOL] forecast = FORECASTS [ name ] [EOL] [EOL] def percentile ( value ) : [EOL] return f" [string] { int ( round ( value * [number] ) ) : [string] }" [EOL] [EOL] num_samples , pred_length = SAMPLES . shape [EOL] [EOL] for quantile in QUANTILES : [EOL] test_cases = [ quantile , str ( quantile ) , percentile ( quantile ) ] [EOL] for quant_pred in map ( forecast . quantile , test_cases ) : [EOL] assert np . isclose ( quant_pred [ [number] ] , quantile ) , f" [string] { percentile ( quantile ) } [string] { quantile } [string] { quant_pred } [string] " [EOL] [EOL] assert forecast . prediction_length == [number] [EOL] assert len ( forecast . index ) == pred_length [EOL] assert forecast . index [ [number] ] == pd . Timestamp ( START_DATE ) [EOL] [EOL] [EOL] def test_DistributionForecast ( ) : [EOL] forecast = DistributionForecast ( distribution = Uniform ( low = mx . nd . array ( [ [number] , [number] ] ) , high = mx . nd . array ( [ [number] , [number] ] ) ) , start_date = START_DATE , freq = FREQ , ) [EOL] [EOL] def percentile ( value ) : [EOL] return f" [string] { int ( round ( value * [number] ) ) : [string] }" [EOL] [EOL] for quantile in QUANTILES : [EOL] test_cases = [ quantile , str ( quantile ) , percentile ( quantile ) ] [EOL] for quant_pred in map ( forecast . quantile , test_cases ) : [EOL] expected = quantile * np . array ( [ [number] , [number] ] ) [EOL] assert np . allclose ( quant_pred , expected ) , f" [string] { percentile ( quantile ) } [string] { quantile } [string] { quant_pred } [string] " [EOL] [EOL] pred_length = [number] [EOL] assert forecast . prediction_length == pred_length [EOL] assert len ( forecast . index ) == pred_length [EOL] assert forecast . index [ [number] ] == pd . Timestamp ( START_DATE ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( SampleForecast ( samples = np . random . normal ( size = ( [number] , [number] , [number] ) ) , start_date = pd . Timestamp ( [string] ) , freq = [string] , ) , pd . date_range ( start = pd . Timestamp ( [string] ) , freq = [string] , periods = [number] , ) , ) , ( DistributionForecast ( Uniform ( low = mx . nd . zeros ( shape = ( [number] , [number] ) ) , high = mx . nd . ones ( shape = ( [number] , [number] ) ) , ) , start_date = pd . Timestamp ( [string] ) , freq = [string] , ) , pd . date_range ( start = pd . Timestamp ( [string] ) , freq = [string] , periods = [number] , ) , ) , ] , ) def test_forecast_multivariate ( forecast , exp_index ) : [EOL] assert forecast . prediction_length == len ( exp_index ) [EOL] assert np . all ( forecast . index == exp_index ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import tempfile [EOL] from pathlib import Path [EOL] [EOL] import pytest [EOL] [EOL] try : [EOL] import statsmodels [EOL] except ImportError : [EOL] statsmodels = None [EOL] [EOL] [EOL] class AttrDict ( dict ) : [EOL] def __init__ ( self , * args , ** kwargs ) : [EOL] super ( AttrDict , self ) . __init__ ( * args , ** kwargs ) [EOL] self . __dict__ = self [EOL] [EOL] [EOL] def pytest_runtest_setup ( item ) : [EOL] skip_datasets = [ mark . args [ [number] ] for mark in item . iter_markers ( name = [string] ) ] [EOL] [EOL] if skip_datasets : [EOL] ds_name = item . _request . getfixturevalue ( [string] ) [ [string] ] [EOL] if ds_name in skip_datasets : [EOL] pytest . skip ( f" [string] { ds_name }" ) [EOL] [EOL] [EOL] @ pytest . fixture ( scope = [string] , params = [ [string] , [string] ] ) def dsinfo ( request ) : [EOL] from gluonts import time_feature [EOL] from gluonts . dataset . artificial import constant_dataset , default_synthetic [EOL] [EOL] if request . param == [string] : [EOL] ds_info , train_ds , test_ds = constant_dataset ( ) [EOL] [EOL] return AttrDict ( name = [string] , cardinality = int ( ds_info . metadata . feat_static_cat [ [number] ] . cardinality ) , freq = ds_info . metadata . freq , num_parallel_samples = [number] , prediction_length = ds_info . prediction_length , time_features = [ time_feature . DayOfWeek ( ) , time_feature . HourOfDay ( ) ] , train_ds = train_ds , test_ds = test_ds , ) [EOL] elif request . param == [string] : [EOL] ds_info , train_ds , test_ds = default_synthetic ( ) [EOL] [EOL] return AttrDict ( name = [string] , batch_size = [number] , cardinality = int ( ds_info . metadata . feat_static_cat [ [number] ] . cardinality ) , context_length = [number] , freq = ds_info . metadata . freq , prediction_length = ds_info . prediction_length , num_parallel_samples = [number] , train_ds = train_ds , test_ds = test_ds , time_features = None , ) [EOL] [EOL] [EOL] def from_hyperparameters ( Estimator , hyperparameters , dsinfo ) : [EOL] return Estimator . from_hyperparameters ( freq = dsinfo . freq , ** { [string] : dsinfo . prediction_length , [string] : dsinfo . num_parallel_samples , } , ** hyperparameters , ) [EOL] [EOL] [EOL] @ pytest . fixture ( ) def accuracy_test ( dsinfo ) : [EOL] from gluonts . evaluation import Evaluator [EOL] from gluonts . evaluation . backtest import backtest_metrics [EOL] [EOL] def test_accuracy ( Estimator , hyperparameters , accuracy ) : [EOL] estimator = from_hyperparameters ( Estimator , hyperparameters , dsinfo ) [EOL] predictor = estimator . train ( training_data = dsinfo . train_ds ) [EOL] agg_metrics , item_metrics = backtest_metrics ( test_dataset = dsinfo . test_ds , predictor = predictor , evaluator = Evaluator ( calculate_owa = statsmodels is not None , num_workers = [number] ) , ) [EOL] [EOL] if dsinfo . name == [string] : [EOL] accuracy = [number] [EOL] [EOL] assert agg_metrics [ [string] ] <= accuracy [EOL] [EOL] return test_accuracy [EOL] [EOL] [EOL] @ pytest . fixture ( ) def serialize_test ( dsinfo ) : [EOL] from gluonts . model . predictor import Predictor [EOL] [EOL] def test_serialize ( Estimator , hyperparameters ) : [EOL] estimator = from_hyperparameters ( Estimator , hyperparameters , dsinfo ) [EOL] [EOL] with tempfile . TemporaryDirectory ( ) as temp_dir : [EOL] predictor_act = estimator . train ( dsinfo . train_ds ) [EOL] predictor_act . serialize ( Path ( temp_dir ) ) [EOL] predictor_exp = Predictor . deserialize ( Path ( temp_dir ) ) [EOL] [comment] [EOL] assert predictor_act == predictor_exp [EOL] [EOL] return test_serialize [EOL] [EOL] [EOL] @ pytest . fixture ( ) def repr_test ( dsinfo ) : [EOL] from gluonts . core . serde import load_code [EOL] [EOL] def test_repr ( Estimator , hyperparameters ) : [EOL] estimator = from_hyperparameters ( Estimator , hyperparameters , dsinfo ) [EOL] assert repr ( estimator ) == repr ( load_code ( repr ( estimator ) ) ) [EOL] [EOL] return test_repr [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import itertools [EOL] [EOL] [comment] [EOL] import mxnet as mx [EOL] [EOL] [comment] [EOL] from gluonts . model . deepar . _network import DeepARTrainingNetwork [EOL] [EOL] [EOL] def test_lagged_subsequences ( ) : [EOL] N = [number] [EOL] T = [number] [EOL] C = [number] [EOL] lags = [ [number] , [number] , [number] , [number] , [number] ] [EOL] I = len ( lags ) [EOL] sequence = mx . nd . random . normal ( shape = ( N , T , C ) ) [EOL] S = [number] [EOL] [EOL] [comment] [EOL] lagged_subsequences = DeepARTrainingNetwork . get_lagged_subsequences ( F = mx . nd , sequence = sequence , sequence_length = sequence . shape [ [number] ] , indices = lags , subsequences_length = S , ) [EOL] [EOL] assert ( N , S , C , I ) == lagged_subsequences . shape [EOL] [EOL] [comment] [EOL] for i , j , k in itertools . product ( range ( N ) , range ( S ) , range ( I ) ) : [EOL] assert ( ( lagged_subsequences [ i , j , : , k ] == sequence [ i , - lags [ k ] - S + j , : ] ) . asnumpy ( ) . all ( ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from functools import partial [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] import pytest [EOL] [EOL] [comment] [EOL] from gluonts . testutil . dummy_datasets import make_dummy_datasets_with_features [EOL] from gluonts . model . deepar import DeepAREstimator [EOL] from gluonts . mx . trainer import Trainer [EOL] [EOL] [EOL] common_estimator_hps = dict ( freq = [string] , prediction_length = [number] , trainer = Trainer ( epochs = [number] , num_batches_per_epoch = [number] , batch_size = [number] ) , ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( partial ( DeepAREstimator , ** common_estimator_hps ) , make_dummy_datasets_with_features ( ) , ) , ( partial ( DeepAREstimator , ** common_estimator_hps , use_feat_static_cat = True , cardinality = [ [number] ] , ) , make_dummy_datasets_with_features ( cardinality = [ [number] ] ) , ) , ( partial ( DeepAREstimator , ** common_estimator_hps , use_feat_static_cat = True , cardinality = [ [number] , [number] , [number] ] , ) , make_dummy_datasets_with_features ( cardinality = [ [number] , [number] , [number] ] ) , ) , ( partial ( DeepAREstimator , ** common_estimator_hps ) , make_dummy_datasets_with_features ( cardinality = [ [number] , [number] , [number] ] ) , ) , ( partial ( DeepAREstimator , ** common_estimator_hps , use_feat_dynamic_real = True , ) , make_dummy_datasets_with_features ( num_feat_dynamic_real = [number] ) , ) , ( partial ( DeepAREstimator , ** common_estimator_hps , use_feat_dynamic_real = True , ) , make_dummy_datasets_with_features ( num_feat_dynamic_real = [number] ) , ) , ( partial ( DeepAREstimator , ** common_estimator_hps ) , make_dummy_datasets_with_features ( num_feat_dynamic_real = [number] ) , ) , ( partial ( DeepAREstimator , ** common_estimator_hps , use_feat_dynamic_real = True , use_feat_static_cat = True , cardinality = [ [number] , [number] , [number] ] , ) , make_dummy_datasets_with_features ( cardinality = [ [number] , [number] , [number] ] , num_feat_dynamic_real = [number] ) , ) , ( partial ( DeepAREstimator , ** common_estimator_hps ) , make_dummy_datasets_with_features ( cardinality = [ [number] , [number] , [number] ] , num_feat_dynamic_real = [number] ) , ) , ] , ) @ pytest . mark . parametrize ( [string] , [ np . float32 , np . float64 ] ) def test_deepar_smoke ( estimator , datasets , dtype ) : [EOL] estimator = estimator ( dtype = dtype ) [EOL] dataset_train , dataset_test = datasets [EOL] predictor = estimator . train ( dataset_train ) [EOL] forecasts = list ( predictor . predict ( dataset_test ) ) [EOL] assert all ( [ forecast . samples . dtype == dtype for forecast in forecasts ] ) [EOL] assert len ( forecasts ) == len ( dataset_test ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from itertools import islice [EOL] [EOL] import mxnet as mx [EOL] [EOL] from gluonts . mx . distribution import StudentTOutput , StudentT [EOL] from gluonts . dataset . artificial import constant_dataset [EOL] from gluonts . dataset . loader import TrainDataLoader [EOL] from gluonts . support . util import get_hybrid_forward_input_names [EOL] from gluonts . model . deepar import DeepAREstimator [EOL] from gluonts . mx . trainer import Trainer [EOL] [EOL] [EOL] ds_info , train_ds , test_ds = constant_dataset ( ) [EOL] freq = ds_info . metadata . freq [EOL] prediction_length = ds_info . prediction_length [EOL] [EOL] [EOL] def test_distribution ( ) : [EOL] [docstring] [EOL] prediction_length = ds_info . prediction_length [EOL] estimator = DeepAREstimator ( freq = freq , prediction_length = prediction_length , trainer = Trainer ( epochs = [number] , num_batches_per_epoch = [number] ) , distr_output = StudentTOutput ( ) , ) [EOL] [EOL] train_output = estimator . train_model ( train_ds , test_ds ) [EOL] [EOL] [comment] [EOL] batch_size = [number] [EOL] num_samples = [number] [EOL] [EOL] training_data_loader = TrainDataLoader ( dataset = train_ds , transform = train_output . transformation , batch_size = batch_size , num_batches_per_epoch = estimator . trainer . num_batches_per_epoch , ctx = mx . cpu ( ) , ) [EOL] [EOL] seq_len = [number] * ds_info . prediction_length [EOL] [EOL] for data_entry in islice ( training_data_loader , [number] ) : [EOL] input_names = get_hybrid_forward_input_names ( train_output . trained_net ) [EOL] [EOL] distr = train_output . trained_net . distribution ( * [ data_entry [ k ] for k in input_names ] ) [EOL] [EOL] assert distr . sample ( num_samples ) . shape == ( num_samples , batch_size , seq_len , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import builtins [EOL] import pytest [EOL] from flaky import flaky [EOL] import mxnet as mx [EOL] [EOL] [comment] [EOL] from gluonts . dataset . artificial import constant_dataset [EOL] from gluonts . mx . distribution import LowrankMultivariateGaussian [EOL] from gluonts . mx . distribution . lowrank_gp import LowrankGPOutput , GPArgProj [EOL] from gluonts . evaluation . backtest import backtest_metrics [EOL] from gluonts . evaluation import MultivariateEvaluator [EOL] from gluonts . model . gpvar import GPVAREstimator [EOL] from gluonts . mx . trainer import Trainer [EOL] from gluonts . dataset . multivariate_grouper import MultivariateGrouper [EOL] from gluonts . dataset . common import TrainDatasets [EOL] [EOL] [EOL] def load_multivariate_constant_dataset ( ) : [EOL] dataset_info , train_ds , test_ds = constant_dataset ( ) [EOL] grouper_train = MultivariateGrouper ( max_target_dim = [number] ) [EOL] grouper_test = MultivariateGrouper ( num_test_dates = [number] , max_target_dim = [number] ) [EOL] metadata = dataset_info . metadata [EOL] metadata . prediction_length = dataset_info . prediction_length [EOL] return TrainDatasets ( metadata = dataset_info . metadata , train = grouper_train ( train_ds ) , test = grouper_test ( test_ds ) , ) [EOL] [EOL] [EOL] dataset = load_multivariate_constant_dataset ( ) [EOL] target_dim = int ( dataset . metadata . feat_static_cat [ [number] ] . cardinality ) [EOL] metadata = dataset . metadata [EOL] [EOL] [EOL] def test_gp_output ( ) : [EOL] [comment] [EOL] batch = [number] [EOL] hidden_size = [number] [EOL] dim = [number] [EOL] rank = [number] [EOL] [EOL] states = mx . ndarray . ones ( shape = ( batch , dim , hidden_size ) ) [EOL] [EOL] lowrank_gp_output = LowrankGPOutput ( dim = dim , rank = rank ) [EOL] [EOL] proj = lowrank_gp_output . get_args_proj ( ) [EOL] [EOL] proj . initialize ( ) [EOL] [EOL] distr_args = proj ( states ) [EOL] [EOL] mu , D , W = distr_args [EOL] [EOL] assert mu . shape == ( batch , dim ) [EOL] assert D . shape == ( batch , dim ) [EOL] assert W . shape == ( batch , dim , rank ) [EOL] [EOL] [EOL] def test_gpvar_proj ( ) : [EOL] [comment] [EOL] batch = [number] [EOL] hidden_size = [number] [EOL] dim = [number] [EOL] rank = [number] [EOL] [EOL] states = mx . ndarray . ones ( shape = ( batch , dim , hidden_size ) ) [EOL] [EOL] gp_proj = GPArgProj ( rank = rank ) [EOL] gp_proj . initialize ( ) [EOL] [EOL] distr_args = gp_proj ( states ) [EOL] [EOL] mu , D , W = distr_args [EOL] [EOL] assert mu . shape == ( batch , dim ) [EOL] assert D . shape == ( batch , dim ) [EOL] assert W . shape == ( batch , dim , rank ) [EOL] [EOL] distr = LowrankMultivariateGaussian ( dim , rank , * distr_args ) [EOL] [EOL] assert distr . mean . shape == ( batch , dim ) [EOL] [EOL] [EOL] @ flaky ( max_runs = [number] , min_passes = [number] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) @ pytest . mark . parametrize ( [string] , [ None , [number] ] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_smoke ( hybridize , target_dim_sample , use_marginal_transformation ) : [EOL] num_batches_per_epoch = [number] [EOL] estimator = GPVAREstimator ( distr_output = LowrankGPOutput ( rank = [number] ) , num_cells = [number] , num_layers = [number] , pick_incomplete = True , prediction_length = metadata . prediction_length , target_dim = target_dim , target_dim_sample = target_dim_sample , freq = metadata . freq , use_marginal_transformation = use_marginal_transformation , trainer = Trainer ( epochs = [number] , batch_size = [number] , learning_rate = [number] , num_batches_per_epoch = num_batches_per_epoch , hybridize = hybridize , ) , ) [EOL] [EOL] predictor = estimator . train ( training_data = dataset . train ) [EOL] [EOL] agg_metrics , _ = backtest_metrics ( test_dataset = dataset . test , predictor = predictor , num_samples = [number] , evaluator = MultivariateEvaluator ( quantiles = ( [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ) ) , ) [EOL] assert agg_metrics [ [string] ] < [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import pytest [EOL] [EOL] from gluonts . model . seq2seq import ( MQCNNEstimator , MQRNNEstimator , ) [EOL] from gluonts . testutil . dummy_datasets import make_dummy_datasets_with_features [EOL] [EOL] from gluonts . mx . distribution import GaussianOutput [EOL] [EOL] [EOL] @ pytest . fixture ( ) def hyperparameters ( dsinfo ) : [EOL] return dict ( ctx = [string] , epochs = [number] , learning_rate = [number] , hybridize = True , context_length = dsinfo . prediction_length , num_forking = [number] , num_batches_per_epoch = [number] , use_symbol_block_predictor = True , ) [EOL] [EOL] [EOL] @ pytest . fixture ( params = [ MQCNNEstimator , MQRNNEstimator ] , ids = [ [string] , [string] ] ) def Estimator ( request ) : [EOL] return request . param [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ True , False ] ) @ pytest . mark . parametrize ( [string] , [ ( [ [number] , [number] , [number] ] , None ) , ( None , GaussianOutput ( ) ) ] , ) def test_accuracy ( Estimator , accuracy_test , hyperparameters , hybridize , quantiles , distr_output , ) : [EOL] hyperparameters . update ( num_batches_per_epoch = [number] , hybridize = hybridize , quantiles = quantiles , distr_output = distr_output , ) [EOL] [EOL] accuracy_test ( Estimator , hyperparameters , accuracy = [number] if quantiles else [number] ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ True , False ] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) @ pytest . mark . parametrize ( [string] , [ ( [ [number] , [number] ] , None ) , ( None , GaussianOutput ( ) ) , ] ) def test_mqcnn_covariate_smoke_test ( use_past_feat_dynamic_real , use_feat_dynamic_real , add_time_feature , add_age_feature , enable_encoder_dynamic_feature , enable_decoder_dynamic_feature , hybridize , quantiles , distr_output , ) : [EOL] hps = { [string] : [number] , [string] : [string] , [string] : [number] , [string] : [number] , [string] : quantiles , [string] : distr_output , [string] : [number] , [string] : [number] , [string] : use_past_feat_dynamic_real , [string] : use_feat_dynamic_real , [string] : add_time_feature , [string] : add_age_feature , [string] : enable_encoder_dynamic_feature , [string] : enable_decoder_dynamic_feature , [string] : hybridize , } [EOL] [EOL] dataset_train , dataset_test = make_dummy_datasets_with_features ( cardinality = [ [number] , [number] ] , num_feat_dynamic_real = [number] , num_past_feat_dynamic_real = [number] , freq = hps [ [string] ] , prediction_length = hps [ [string] ] , ) [EOL] [EOL] estimator = MQCNNEstimator . from_hyperparameters ( ** hps ) [EOL] [EOL] predictor = estimator . train ( dataset_train , num_workers = [number] ) [EOL] forecasts = list ( predictor . predict ( dataset_test ) ) [EOL] assert len ( forecasts ) == len ( dataset_test ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ True , False ] ) @ pytest . mark . parametrize ( [string] , [ [ ] , [ [number] , [number] ] ] ) def test_feat_static_cat_smoke_test ( use_feat_static_cat , cardinality ) : [EOL] hps = { [string] : [number] , [string] : [string] , [string] : [number] , [string] : [ [number] , [number] ] , [string] : [number] , [string] : [number] , [string] : use_feat_static_cat , } [EOL] [EOL] dataset_train , dataset_test = make_dummy_datasets_with_features ( cardinality = cardinality , num_feat_dynamic_real = [number] , freq = hps [ [string] ] , prediction_length = hps [ [string] ] , ) [EOL] estimator = MQCNNEstimator . from_inputs ( dataset_train , ** hps ) [EOL] [EOL] predictor = estimator . train ( dataset_train , num_workers = [number] ) [EOL] forecasts = list ( predictor . predict ( dataset_test ) ) [EOL] assert len ( forecasts ) == len ( dataset_test ) [EOL] [EOL] [EOL] [comment] [EOL] @ pytest . mark . parametrize ( [string] , [ True , False ] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_mqcnn_scaling_smoke_test ( scaling , scaling_decoder_dynamic_feature ) : [EOL] hps = { [string] : [number] , [string] : [string] , [string] : [number] , [string] : [ [number] , [number] ] , [string] : [number] , [string] : [number] , [string] : scaling , [string] : scaling_decoder_dynamic_feature , } [EOL] [EOL] dataset_train , dataset_test = make_dummy_datasets_with_features ( cardinality = [ [number] , [number] ] , num_feat_dynamic_real = [number] , freq = hps [ [string] ] , prediction_length = hps [ [string] ] , ) [EOL] [EOL] estimator = MQCNNEstimator . from_inputs ( dataset_train , ** hps ) [EOL] [EOL] predictor = estimator . train ( dataset_train , num_workers = [number] ) [EOL] forecasts = list ( predictor . predict ( dataset_test ) ) [EOL] assert len ( forecasts ) == len ( dataset_test ) [EOL] [EOL] [EOL] def test_repr ( Estimator , repr_test , hyperparameters ) : [EOL] repr_test ( Estimator , hyperparameters ) [EOL] [EOL] [EOL] def test_serialize ( Estimator , serialize_test , hyperparameters ) : [EOL] serialize_test ( Estimator , hyperparameters ) [EOL] [EOL] [EOL] def test_backwards_compatibility ( ) : [EOL] hps = { [string] : [string] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [ [number] , [number] ] , [string] : [number] , [string] : [number] , [string] : True , [string] : True , [string] : True , [string] : True , [string] : True , [string] : True , } [EOL] [EOL] dataset_train , dataset_test = make_dummy_datasets_with_features ( cardinality = [ [number] , [number] ] , num_feat_dynamic_real = [number] , num_past_feat_dynamic_real = [number] , freq = hps [ [string] ] , prediction_length = hps [ [string] ] , ) [EOL] [EOL] for i in range ( len ( dataset_train ) ) : [EOL] dataset_train . list_data [ i ] [ [string] ] = dataset_train . list_data [ i ] [ [string] ] [EOL] del dataset_train . list_data [ i ] [ [string] ] [EOL] [EOL] for i in range ( len ( dataset_test ) ) : [EOL] dataset_test . list_data [ i ] [ [string] ] = dataset_test . list_data [ i ] [ [string] ] [EOL] del dataset_test . list_data [ i ] [ [string] ] [EOL] [EOL] estimator = MQCNNEstimator . from_inputs ( dataset_train , ** hps ) [EOL] [EOL] predictor = estimator . train ( dataset_train , num_workers = [number] ) [EOL] forecasts = list ( predictor . predict ( dataset_test ) ) [EOL] assert len ( forecasts ) == len ( dataset_test ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from mxnet import nd [EOL] [EOL] [comment] [EOL] from gluonts . mx . block . quantile_output import QuantileLoss [EOL] [EOL] [EOL] def test_compute_quantile_loss ( ) : [EOL] y_true = nd . ones ( shape = ( [number] , [number] , [number] ) ) [EOL] y_pred = nd . zeros ( shape = ( [number] , [number] , [number] , [number] ) ) [EOL] [EOL] quantiles = [ [number] , [number] ] [EOL] [EOL] loss = QuantileLoss ( quantiles ) [EOL] [EOL] correct_qt_loss = [ [number] , [number] ] [EOL] [EOL] for idx , q in enumerate ( quantiles ) : [EOL] assert ( nd . mean ( loss . compute_quantile_loss ( nd . ndarray , y_true , y_pred [ : , : , : , idx ] , q ) ) - correct_qt_loss [ idx ] < [number] ) , f" [string] { q } [string] " [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import numpy [EOL] import builtins [EOL] import mxnet as mx [EOL] import numpy as np [EOL] from mxnet import nd [EOL] [EOL] [comment] [EOL] from gluonts . mx . block . cnn import CausalConv1D [EOL] [EOL] [EOL] def compute_causalconv1d ( x , kernels , dilation ) : [EOL] [docstring] [EOL] [EOL] conv_x = np . zeros_like ( x ) [EOL] [comment] [EOL] for ( t , xt ) in enumerate ( x ) : [EOL] dial_offset = [number] [EOL] for i in reversed ( range ( len ( kernels ) ) ) : [EOL] xt_lag = x [ t - dial_offset ] if t - dial_offset >= [number] else [number] [EOL] dial_offset += dilation [EOL] conv_x [ t ] += kernels [ i ] * xt_lag [EOL] [EOL] return conv_x [EOL] [EOL] [EOL] def test_causal_conv_1d ( ) : [EOL] [docstring] [EOL] x = nd . random . normal ( [number] , [number] , shape = ( [number] , [number] , [number] ) ) [EOL] [EOL] conv1d = CausalConv1D ( channels = [number] , kernel_size = [number] , dilation = [number] , activation = None ) [EOL] conv1d . collect_params ( ) . initialize ( mx . init . One ( ) , ctx = mx . cpu ( ) , force_reinit = True ) [EOL] [EOL] y1 = conv1d ( x ) . reshape ( shape = ( - [number] , ) ) . asnumpy ( ) [EOL] y2 = compute_causalconv1d ( x = x . reshape ( shape = ( - [number] , ) ) . asnumpy ( ) , kernels = np . asarray ( [ [number] ] * [number] ) , dilation = [number] , ) [EOL] [EOL] assert ( np . max ( np . abs ( y1 - y2 ) ) < [number] ) , [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import pytest [EOL] from mxnet import nd [EOL] [EOL] [comment] [EOL] from gluonts . mx . block . encoder import HierarchicalCausalConv1DEncoder [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ True , False ] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_hierarchical_cnn_encoders ( use_residual , hybridize ) : [EOL] num_ts = [number] [EOL] ts_len = [number] [EOL] num_static_feat = [number] [EOL] num_dynamic_feat = [number] [EOL] [EOL] test_data = nd . arange ( num_ts * ts_len ) . reshape ( shape = ( num_ts , ts_len , [number] ) ) [EOL] test_static_feat = nd . random . randn ( num_ts , num_static_feat ) [EOL] test_dynamic_feat = nd . random . randn ( num_ts , ts_len , num_dynamic_feat ) [EOL] [EOL] chl_dim = [ [number] , [number] , [number] ] [EOL] ks_seq = [ [number] ] * len ( chl_dim ) [EOL] dial_seq = [ [number] , [number] , [number] ] [EOL] [EOL] cnn = HierarchicalCausalConv1DEncoder ( dial_seq , ks_seq , chl_dim , use_residual , use_dynamic_feat = True , use_static_feat = True , ) [EOL] cnn . collect_params ( ) . initialize ( ) [EOL] [EOL] if hybridize : [EOL] cnn . hybridize ( ) [EOL] [EOL] true_shape = ( num_ts , ts_len , [number] ) if use_residual else ( num_ts , ts_len , [number] ) [EOL] [EOL] assert ( cnn ( test_data , test_static_feat , test_dynamic_feat ) [ [number] ] . shape == true_shape ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] import pytest [EOL] [EOL] from gluonts import transform [EOL] from gluonts . dataset . common import ListDataset [EOL] from gluonts . dataset . field_names import FieldName [EOL] from gluonts . model . seq2seq . _transform import ForkingSequenceSplitter [EOL] [EOL] [comment] [EOL] from gluonts . transform import TestSplitSampler as TSplitSampler [EOL] from gluonts . time_feature import time_features_from_frequency_str [EOL] [EOL] [EOL] def make_dataset ( N , train_length ) : [EOL] [comment] [EOL] n = [number] ** N - [number] [EOL] [EOL] targets = np . arange ( n * train_length ) . reshape ( ( n , train_length ) ) [EOL] [EOL] return ListDataset ( [ { [string] : [string] , [string] : targets [ i , : ] } for i in range ( n ) ] , freq = [string] , ) [EOL] [EOL] [EOL] def test_forking_sequence_splitter ( ) : [EOL] len_ts = [number] [EOL] ds = make_dataset ( [number] , len_ts ) [EOL] enc_len = [number] [EOL] dec_len = [number] [EOL] [EOL] trans = transform . Chain ( [ transform . AddAgeFeature ( target_field = FieldName . TARGET , output_field = [string] , pred_length = dec_len , ) , ForkingSequenceSplitter ( train_sampler = TSplitSampler ( ) , enc_len = enc_len , dec_len = dec_len , encoder_series_fields = [ [string] ] , ) , ] ) [EOL] [EOL] out = trans ( ds , is_train = True ) [EOL] transformed_data = next ( iter ( out ) ) [EOL] [EOL] future_target = np . array ( [ [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] , ] ) [EOL] assert ( np . linalg . norm ( future_target - transformed_data [ [string] ] ) < [number] ) , [string] [EOL] [EOL] age = np . log10 ( [number] + np . arange ( len_ts ) ) [EOL] assert ( np . linalg . norm ( age [ - ( enc_len + dec_len ) : - dec_len ] - transformed_data [ [string] ] . flatten ( ) ) < [number] ) , [string] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_forking_sequence_with_features ( is_train ) : [EOL] def make_dataset ( N , train_length ) : [EOL] [comment] [EOL] n = [number] ** N - [number] [EOL] [EOL] targets = np . arange ( n * train_length ) . reshape ( ( n , train_length ) ) [EOL] [EOL] return ListDataset ( [ { [string] : [string] , [string] : targets [ i , : ] } for i in range ( n ) ] , freq = [string] , ) [EOL] [EOL] ds = make_dataset ( [number] , [number] ) [EOL] enc_len = [number] [EOL] dec_len = [number] [EOL] num_forking = [number] [EOL] num_time_feat_daily_freq = [number] [EOL] num_age_feat = [number] [EOL] [EOL] trans = transform . Chain ( trans = [ transform . AddAgeFeature ( target_field = FieldName . TARGET , output_field = FieldName . FEAT_AGE , pred_length = [number] , ) , transform . AddTimeFeatures ( start_field = FieldName . START , target_field = FieldName . TARGET , output_field = FieldName . FEAT_TIME , time_features = time_features_from_frequency_str ( [string] ) , pred_length = [number] , ) , ForkingSequenceSplitter ( train_sampler = TSplitSampler ( ) , enc_len = enc_len , dec_len = dec_len , num_forking = num_forking , encoder_series_fields = [ FieldName . FEAT_AGE , FieldName . FEAT_TIME , ] , decoder_series_fields = [ FieldName . FEAT_TIME ] , ) , ] ) [EOL] [EOL] out = trans ( iter ( ds ) , is_train = is_train ) [EOL] transformed_data = next ( iter ( out ) ) [EOL] [EOL] assert transformed_data [ [string] ] . shape == ( enc_len , [number] ) [EOL] assert transformed_data [ [string] ] . shape == ( enc_len , num_age_feat , ) [EOL] assert transformed_data [ [string] ] . shape == ( enc_len , num_time_feat_daily_freq , ) [EOL] assert transformed_data [ [string] ] . shape == ( num_forking , dec_len , num_time_feat_daily_freq , ) [EOL] [EOL] if is_train : [EOL] assert transformed_data [ [string] ] . shape == ( num_forking , dec_len , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import pytest [EOL] [EOL] from gluonts . model . n_beats import NBEATSEnsembleEstimator , NBEATSEstimator [EOL] [EOL] [EOL] @ pytest . fixture ( ) def args ( dsinfo ) : [EOL] common_hp = dict ( ctx = [string] , epochs = [number] , hybridize = True , num_batches_per_epoch = [number] , ) [EOL] return { [string] : { [string] : NBEATSEstimator , [string] : { [string] : [number] } , ** common_hp , } , [string] : { [string] : NBEATSEstimator , [string] : { [string] : [number] , [string] : [ [number] ] , [string] : [ [number] , [number] ] , [string] : [ True ] , [string] : [ [string] , [string] ] , ** common_hp , } , } , [string] : { [string] : NBEATSEnsembleEstimator , [string] : { [string] : [ [number] * dsinfo . prediction_length ] , [string] : [ [string] ] , [string] : [number] , [string] : [number] , ** common_hp , } , } , } [EOL] [EOL] [EOL] @ pytest . fixture ( params = [ [string] , [string] , [string] ] ) def name ( request ) : [EOL] return request . param [EOL] [EOL] [EOL] @ pytest . fixture ( ) def estimator_config ( args , name ) : [EOL] config = args [ name ] [EOL] return name , config [ [string] ] , config [ [string] ] [EOL] [EOL] [EOL] [comment] [EOL] @ pytest . mark . skip ( [string] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_accuracy ( accuracy_test , estimator_config , hybridize ) : [EOL] Estimator , hyperparameters = estimator_config [ [number] : ] [EOL] hyperparameters . update ( num_batches_per_epoch = [number] , hybridize = hybridize ) [EOL] [EOL] accuracy_test ( Estimator , hyperparameters , accuracy = [number] ) [EOL] [EOL] [EOL] def test_repr ( repr_test , estimator_config ) : [EOL] repr_test ( * estimator_config [ [number] : ] ) [EOL] [EOL] [EOL] def test_serialize ( serialize_test , estimator_config ) : [EOL] if estimator_config [ [number] ] == [string] : [EOL] pytest . skip ( [string] ) [EOL] serialize_test ( * estimator_config [ [number] : ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import pytest [EOL] [EOL] from gluonts . model . simple_feedforward import SimpleFeedForwardEstimator [EOL] from gluonts . mx . distribution import GaussianOutput [EOL] [EOL] [EOL] @ pytest . fixture ( ) def hyperparameters ( ) : [EOL] return dict ( ctx = [string] , epochs = [number] , learning_rate = [number] , hybridize = True , num_hidden_dimensions = [ [number] ] , num_batches_per_epoch = [number] , use_symbol_block_predictor = True , distr_output = GaussianOutput ( ) , ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ True , False ] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_accuracy ( accuracy_test , hyperparameters , hybridize , sampling ) : [EOL] hyperparameters . update ( num_batches_per_epoch = [number] , hybridize = hybridize , sampling = sampling ) [EOL] [EOL] accuracy_test ( SimpleFeedForwardEstimator , hyperparameters , accuracy = [number] ) [EOL] [EOL] [EOL] def test_repr ( repr_test , hyperparameters ) : [EOL] repr_test ( SimpleFeedForwardEstimator , hyperparameters ) [EOL] [EOL] [EOL] def test_serialize ( serialize_test , hyperparameters ) : [EOL] serialize_test ( SimpleFeedForwardEstimator , hyperparameters ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from gluonts . dataset . common import ListDataset [EOL] from gluonts . model . trivial . mean import MovingAveragePredictor [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] import pytest [EOL] [EOL] [EOL] def get_predictions ( target , prediction_length = [number] , context_length = [number] , freq = [string] , start = [string] ) : [EOL] mp = MovingAveragePredictor ( prediction_length = prediction_length , context_length = context_length , freq = freq , ) [EOL] [EOL] ds = ListDataset ( [ { [string] : target , [string] : start } ] , freq = freq ) [EOL] item = next ( iter ( ds ) ) [EOL] predictions = mp . predict_item ( item ) . mean [EOL] [EOL] return predictions [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [ [number] , [number] , [number] ] , [ [number] ] , [number] , [number] ) , ( [ [number] , [number] , [number] ] , [ [number] , [number] ] , [number] , [number] ) , ( [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] , [number] , [number] ) , ( [ [number] , [number] , [number] ] , [ [number] ] , [number] , [number] ) , ( [ [number] , [number] , [number] ] , [ [number] , [number] ] , [number] , [number] ) , ( [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] , [number] , [number] ) , ( [ [number] , [number] , [number] ] , [ [number] ] , [number] , [number] ) , ( [ [number] , [number] , [number] ] , [ [number] , [number] ] , [number] , [number] ) , ( [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] , [number] , [number] ) , ( [ ] , [ np . nan ] * [number] , [number] , [number] ) , ( [ ] , [ np . nan ] * [number] , [number] , [number] ) , ( [ ] , [ np . nan ] * [number] , [number] , [number] ) , ( [ np . nan ] , [ np . nan ] * [number] , [number] , [number] ) , ( [ [number] , [number] , np . nan ] , [ [number] ] , [number] , [number] ) , ( [ [number] , [number] , np . nan ] , [ [number] , [number] ] , [number] , [number] ) , ( [ [number] , [number] , np . nan ] , [ [number] , [number] , [number] ] , [number] , [number] ) , ( [ [number] , [number] , [number] ] , [ [number] ] , [number] , [number] ) , ( [ [number] , [number] , [number] ] , [ [number] , [number] ] , [number] , [number] ) , ( [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] , [number] , [number] ) , ( [ [number] , [number] , [number] ] , [ [number] ] , [number] , [number] ) , ( [ [number] , [number] , [number] ] , [ [number] , [number] ] , [number] , [number] ) , ( [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] , [number] , [number] ) , ( [ [number] , [number] , [number] ] , [ [number] ] , [number] , [number] ) , ( [ [number] , [number] , [number] ] , [ [number] , [number] / [number] ] , [number] , [number] ) , ( [ [number] , [number] , [number] ] , [ [number] , [number] / [number] , [number] / [number] ] , [number] , [number] ) , ( [ [number] , [number] , [number] ] , [ [number] ] , [number] , None ) , ( [ [number] , [number] , [number] ] , [ [number] , [number] ] , [number] , None ) , ( [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] , [number] , None ) , ( [ [number] , [number] , np . nan ] , [ [number] ] , [number] , None ) , ( [ [number] , [number] , np . nan ] , [ [number] , [number] ] , [number] , None ) , ( [ [number] , [number] , np . nan ] , [ [number] , [number] , [number] ] , [number] , None ) , ] , ) def testing ( data , expected_output , prediction_length , context_length ) : [EOL] [EOL] predictions = get_predictions ( data , prediction_length = prediction_length , context_length = context_length , ) [EOL] [EOL] np . testing . assert_equal ( predictions , expected_output ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import pytest [EOL] [EOL] from gluonts . model . canonical . _estimator import ( CanonicalRNNEstimator , MLPForecasterEstimator , ) [EOL] [EOL] [EOL] @ pytest . fixture ( ) def hyperparameters ( dsinfo ) : [EOL] return dict ( ctx = [string] , epochs = [number] , learning_rate = [number] , hybridize = True , num_cells = [number] , num_layers = [number] , context_length = [number] , use_symbol_block_predictor = False , ) [EOL] [EOL] [EOL] @ pytest . fixture ( params = [ MLPForecasterEstimator , CanonicalRNNEstimator ] , ids = [ [string] , [string] ] ) def Estimator ( request ) : [EOL] return request . param [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_accuracy ( Estimator , accuracy_test , hyperparameters , hybridize ) : [EOL] hyperparameters . update ( hybridize = hybridize ) [EOL] [EOL] accuracy_test ( Estimator , hyperparameters , accuracy = [number] ) [EOL] [EOL] [EOL] def test_repr ( Estimator , repr_test , hyperparameters ) : [EOL] repr_test ( Estimator , hyperparameters ) [EOL] [EOL] [EOL] @ pytest . mark . xfail def test_serialize ( Estimator , serialize_test , hyperparameters ) : [EOL] serialize_test ( Estimator , hyperparameters ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import pytest [EOL] [EOL] from gluonts . model . transformer import TransformerEstimator [EOL] [EOL] [EOL] @ pytest . fixture ( ) def hyperparameters ( ) : [EOL] return dict ( ctx = [string] , epochs = [number] , learning_rate = [number] , hybridize = True , model_dim = [number] , inner_ff_dim_scale = [number] , num_heads = [number] , context_length = [number] , num_batches_per_epoch = [number] , use_symbol_block_predictor = False , ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_accuracy ( accuracy_test , hyperparameters , hybridize ) : [EOL] hyperparameters . update ( num_batches_per_epoch = [number] , hybridize = hybridize ) [EOL] [EOL] accuracy_test ( TransformerEstimator , hyperparameters , accuracy = [number] ) [EOL] [EOL] [EOL] def test_repr ( repr_test , hyperparameters ) : [EOL] repr_test ( TransformerEstimator , hyperparameters ) [EOL] [EOL] [EOL] def test_serialize ( serialize_test , hyperparameters ) : [EOL] serialize_test ( TransformerEstimator , hyperparameters ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from functools import partial [EOL] [EOL] [comment] [EOL] import pytest [EOL] [EOL] [comment] [EOL] from gluonts . model . deepstate import DeepStateEstimator [EOL] from gluonts . testutil . dummy_datasets import make_dummy_datasets_with_features [EOL] from gluonts . mx . trainer import Trainer [EOL] [EOL] [EOL] common_estimator_hps = dict ( freq = [string] , prediction_length = [number] , trainer = Trainer ( epochs = [number] , num_batches_per_epoch = [number] , batch_size = [number] , hybridize = True ) , past_length = [number] , add_trend = True , ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( partial ( DeepStateEstimator , ** common_estimator_hps , cardinality = [ [number] ] , use_feat_static_cat = False , ) , make_dummy_datasets_with_features ( ) , ) , ( partial ( DeepStateEstimator , ** common_estimator_hps , cardinality = [ [number] ] ) , make_dummy_datasets_with_features ( cardinality = [ [number] ] ) , ) , ( partial ( DeepStateEstimator , ** common_estimator_hps , cardinality = [ [number] , [number] , [number] ] , ) , make_dummy_datasets_with_features ( cardinality = [ [number] , [number] , [number] ] ) , ) , ( partial ( DeepStateEstimator , ** common_estimator_hps , cardinality = [ [number] , [number] , [number] ] , ) , make_dummy_datasets_with_features ( cardinality = [ [number] , [number] , [number] ] ) , ) , ( partial ( DeepStateEstimator , ** common_estimator_hps , cardinality = [ [number] ] , use_feat_static_cat = False , use_feat_dynamic_real = True , ) , make_dummy_datasets_with_features ( num_feat_dynamic_real = [number] ) , ) , ( partial ( DeepStateEstimator , ** common_estimator_hps , cardinality = [ [number] ] , use_feat_static_cat = False , use_feat_dynamic_real = True , ) , make_dummy_datasets_with_features ( num_feat_dynamic_real = [number] ) , ) , ( partial ( DeepStateEstimator , ** common_estimator_hps , cardinality = [ [number] ] , use_feat_static_cat = False , ) , make_dummy_datasets_with_features ( num_feat_dynamic_real = [number] ) , ) , ( partial ( DeepStateEstimator , ** common_estimator_hps , use_feat_dynamic_real = True , use_feat_static_cat = True , cardinality = [ [number] , [number] , [number] ] , ) , make_dummy_datasets_with_features ( cardinality = [ [number] , [number] , [number] ] , num_feat_dynamic_real = [number] ) , ) , ] , ) def test_deepstate_smoke ( estimator , datasets ) : [EOL] [comment] [EOL] estimator = estimator ( ) [EOL] dataset_train , dataset_test = datasets [EOL] predictor = estimator . train ( dataset_train ) [EOL] forecasts = list ( predictor . predict ( dataset_test ) ) [EOL] assert len ( forecasts ) == len ( dataset_test ) [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] @ pytest . mark . parametrize ( [string] , [ ( partial ( DeepStateEstimator , ** common_estimator_hps ) , make_dummy_datasets_with_features ( cardinality = [ [number] ] ) , ) , ( partial ( DeepStateEstimator , ** common_estimator_hps , cardinality = [ [number] , [number] , [number] ] , ) , make_dummy_datasets_with_features ( cardinality = [ [number] , [number] , [number] ] ) , ) , ] , ) def test_deepstate_exceptions_with_feat_static_cat ( estimator , datasets ) : [EOL] with pytest . raises ( Exception ) : [EOL] estimator ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import pytest [EOL] [EOL] from gluonts . model . deepstate import DeepStateEstimator [EOL] [EOL] [EOL] @ pytest . fixture ( ) def hyperparameters ( dsinfo ) : [EOL] return dict ( ctx = [string] , epochs = [number] , learning_rate = [number] , hybridize = False , num_cells = [number] , num_layers = [number] , context_length = [number] , past_length = dsinfo . prediction_length , cardinality = [ [number] ] , use_feat_static_cat = False , num_batches_per_epoch = [number] , use_symbol_block_predictor = False , ) [EOL] [EOL] [EOL] def test_accuracy ( accuracy_test , hyperparameters ) : [EOL] hyperparameters . update ( num_batches_per_epoch = [number] ) [EOL] [EOL] accuracy_test ( DeepStateEstimator , hyperparameters , accuracy = [number] ) [EOL] [EOL] [EOL] def test_repr ( repr_test , hyperparameters ) : [EOL] repr_test ( DeepStateEstimator , hyperparameters ) [EOL] [EOL] [EOL] def test_serialize ( serialize_test , hyperparameters ) : [EOL] serialize_test ( DeepStateEstimator , hyperparameters ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] import pytest [EOL] [EOL] [comment] [EOL] from gluonts . dataset . common import ListDataset [EOL] from gluonts . model . prophet import ProphetPredictor , PROPHET_IS_INSTALLED [EOL] [EOL] [comment] [EOL] [comment] [EOL] if not PROPHET_IS_INSTALLED : [EOL] skip_message = [string] [EOL] pytest . skip ( msg = skip_message , allow_module_level = True ) [EOL] [EOL] [EOL] def test_feat_dynamic_real_success ( ) : [EOL] params = dict ( freq = [string] , prediction_length = [number] , prophet_params = dict ( n_changepoints = [number] ) ) [EOL] [EOL] dataset = ListDataset ( data_iter = [ { [string] : [string] , [string] : np . array ( [ [number] , [number] , [number] , [number] ] ) , [string] : np . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , ] ) , } ] , freq = params [ [string] ] , ) [EOL] [EOL] predictor = ProphetPredictor ( ** params ) [EOL] [EOL] act_fcst = next ( predictor . predict ( dataset ) ) [EOL] exp_fcst = np . arange ( [number] , [number] + params [ [string] ] ) [EOL] [EOL] assert np . all ( np . isclose ( act_fcst . quantile ( [number] ) , exp_fcst , atol = [number] ) ) [EOL] assert np . all ( np . isclose ( act_fcst . quantile ( [number] ) , exp_fcst , atol = [number] ) ) [EOL] assert np . all ( np . isclose ( act_fcst . quantile ( [number] ) , exp_fcst , atol = [number] ) ) [EOL] [EOL] [EOL] def test_feat_dynamic_real_bad_size ( ) : [EOL] params = dict ( freq = [string] , prediction_length = [number] , prophet_params = { } ) [EOL] [EOL] dataset = ListDataset ( data_iter = [ { [string] : [string] , [string] : np . array ( [ [number] , [number] , [number] , [number] ] ) , [string] : np . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] ] , ] ) , } ] , freq = params [ [string] ] , ) [EOL] [EOL] with pytest . raises ( AssertionError ) as excinfo : [EOL] predictor = ProphetPredictor ( ** params ) [EOL] list ( predictor . predict ( dataset ) ) [EOL] [EOL] assert str ( excinfo . value ) == ( [string] [string] ) [EOL] [EOL] [EOL] def test_min_obs_error ( ) : [EOL] params = dict ( freq = [string] , prediction_length = [number] , prophet_params = { } ) [EOL] [EOL] dataset = ListDataset ( data_iter = [ { [string] : [string] , [string] : np . array ( [ [number] ] ) } ] , freq = params [ [string] ] , ) [EOL] [EOL] with pytest . raises ( ValueError ) as excinfo : [EOL] predictor = ProphetPredictor ( ** params ) [EOL] list ( predictor . predict ( dataset ) ) [EOL] [EOL] act_error_msg = str ( excinfo . value ) [EOL] exp_error_msg = [string] [EOL] [EOL] assert act_error_msg == exp_error_msg [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import pytest [EOL] [EOL] from gluonts . model . deep_factor import DeepFactorEstimator [EOL] [EOL] [EOL] @ pytest . fixture ( ) def hyperparameters ( dsinfo ) : [EOL] return dict ( ctx = [string] , epochs = [number] , learning_rate = [number] , hybridize = True , cardinality = [ dsinfo . cardinality ] , num_batches_per_epoch = [number] , use_symbol_block_predictor = False , ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_accuracy ( accuracy_test , hyperparameters , hybridize ) : [EOL] hyperparameters . update ( num_batches_per_epoch = [number] , hybridize = hybridize ) [EOL] [EOL] accuracy_test ( DeepFactorEstimator , hyperparameters , accuracy = [number] ) [EOL] [EOL] [EOL] def test_repr ( repr_test , hyperparameters ) : [EOL] repr_test ( DeepFactorEstimator , hyperparameters ) [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] @ pytest . mark . xfail def test_serialize ( serialize_test , hyperparameters ) : [EOL] serialize_test ( DeepFactorEstimator , hyperparameters ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] from itertools import chain [EOL] import pytest [EOL] [EOL] [comment] [EOL] from gluonts . model . rotbaum import TreeEstimator [EOL] [EOL] [EOL] @ pytest . fixture ( ) def hyperparameters ( dsinfo ) : [EOL] return dict ( context_length = [number] , quantiles = [ [number] , [number] , [number] ] , num_workers = [number] , ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ [ [number] , [number] , [number] ] , [ [number] ] ] ) def test_accuracy ( accuracy_test , hyperparameters , quantiles ) : [EOL] hyperparameters . update ( quantiles = quantiles , max_workers = [number] ) [EOL] [EOL] accuracy_test ( TreeEstimator , hyperparameters , accuracy = [number] ) [EOL] [EOL] [EOL] def test_repr ( repr_test , hyperparameters ) : [EOL] repr_test ( TreeEstimator , hyperparameters ) [EOL] [EOL] [EOL] def test_serialize ( serialize_test , hyperparameters ) : [EOL] serialize_test ( TreeEstimator , hyperparameters ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import pytest [EOL] [EOL] [comment] [EOL] from gluonts . testutil . dummy_datasets import make_dummy_datasets_with_features [EOL] from gluonts . model . rotbaum import TreeEstimator [EOL] [EOL] [comment] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ make_dummy_datasets_with_features ( ) , make_dummy_datasets_with_features ( cardinality = [ [number] ] ) , make_dummy_datasets_with_features ( cardinality = [ [number] , [number] , [number] ] ) , make_dummy_datasets_with_features ( cardinality = [ [number] , [number] , [number] ] ) , make_dummy_datasets_with_features ( num_feat_dynamic_real = [number] ) , make_dummy_datasets_with_features ( num_feat_dynamic_real = [number] ) , make_dummy_datasets_with_features ( num_feat_dynamic_real = [number] ) , make_dummy_datasets_with_features ( cardinality = [ [number] , [number] , [number] ] , num_feat_dynamic_real = [number] ) , make_dummy_datasets_with_features ( cardinality = [ [number] , [number] , [number] ] , num_feat_dynamic_real = [number] ) , ] , ) def test_rotbaum_smoke ( datasets ) : [EOL] dataset_train , dataset_test = datasets [EOL] hps = { [string] : [string] , [string] : [number] , [string] : [number] , } [EOL] estimator = TreeEstimator . from_inputs ( dataset_train , ** hps ) [EOL] [EOL] predictor = estimator . train ( dataset_train ) [EOL] forecasts = list ( predictor . predict ( dataset_test ) ) [EOL] assert len ( forecasts ) == len ( dataset_test ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from gluonts . model . npts import NPTSEstimator [EOL] [EOL] hyperparameters = dict ( kernel_type = [string] , use_default_features = True , ) [EOL] [EOL] [EOL] def test_accuracy ( accuracy_test ) : [EOL] accuracy_test ( NPTSEstimator , hyperparameters , accuracy = [number] ) [EOL] [EOL] [EOL] def test_repr ( repr_test ) : [EOL] repr_test ( NPTSEstimator , hyperparameters ) [EOL] [EOL] [EOL] def test_serialize ( serialize_test ) : [EOL] serialize_test ( NPTSEstimator , hyperparameters ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import pytest [EOL] [EOL] from gluonts . dataset . artificial import constant_dataset [EOL] from gluonts . mx . distribution import ( MultivariateGaussianOutput , LowrankMultivariateGaussianOutput , ) [EOL] from gluonts . evaluation . backtest import backtest_metrics [EOL] from gluonts . model . deepvar import DeepVAREstimator [EOL] from gluonts . dataset . common import TrainDatasets [EOL] from gluonts . mx . trainer import Trainer [EOL] from gluonts . dataset . multivariate_grouper import MultivariateGrouper [EOL] from gluonts . evaluation import MultivariateEvaluator [EOL] [EOL] [EOL] def load_multivariate_constant_dataset ( ) : [EOL] dataset_info , train_ds , test_ds = constant_dataset ( ) [EOL] grouper_train = MultivariateGrouper ( max_target_dim = [number] ) [EOL] grouper_test = MultivariateGrouper ( num_test_dates = [number] , max_target_dim = [number] ) [EOL] metadata = dataset_info . metadata [EOL] metadata . prediction_length = dataset_info . prediction_length [EOL] return TrainDatasets ( metadata = dataset_info . metadata , train = grouper_train ( train_ds ) , test = grouper_test ( test_ds ) , ) [EOL] [EOL] [EOL] dataset = load_multivariate_constant_dataset ( ) [EOL] target_dim = int ( dataset . metadata . feat_static_cat [ [number] ] . cardinality ) [EOL] metadata = dataset . metadata [EOL] estimator = DeepVAREstimator [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] [string] , [ ( LowrankMultivariateGaussianOutput ( dim = target_dim , rank = [number] ) , [number] , estimator , True , True , ) , ( LowrankMultivariateGaussianOutput ( dim = target_dim , rank = [number] ) , [number] , estimator , False , False , ) , ( LowrankMultivariateGaussianOutput ( dim = target_dim , rank = [number] ) , [number] , estimator , True , False , ) , ( None , [number] , estimator , True , True ) , ( MultivariateGaussianOutput ( dim = target_dim ) , [number] , estimator , False , True , ) , ( MultivariateGaussianOutput ( dim = target_dim ) , [number] , estimator , True , True , ) , ] , ) def test_deepvar ( distr_output , num_batches_per_epoch , Estimator , hybridize , use_marginal_transformation , ) : [EOL] [EOL] estimator = Estimator ( num_cells = [number] , num_layers = [number] , pick_incomplete = True , target_dim = target_dim , prediction_length = metadata . prediction_length , freq = metadata . freq , distr_output = distr_output , scaling = False , use_marginal_transformation = use_marginal_transformation , trainer = Trainer ( epochs = [number] , batch_size = [number] , learning_rate = [number] , num_batches_per_epoch = num_batches_per_epoch , hybridize = hybridize , ) , ) [EOL] [EOL] predictor = estimator . train ( training_data = dataset . train ) [EOL] [EOL] agg_metrics , _ = backtest_metrics ( test_dataset = dataset . test , predictor = predictor , evaluator = MultivariateEvaluator ( quantiles = ( [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ) ) , ) [EOL] [EOL] assert agg_metrics [ [string] ] < [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import pytest [EOL] import numpy as np [EOL] import pandas as pd [EOL] [EOL] [comment] [EOL] from gluonts . dataset . artificial import constant_dataset [EOL] from gluonts . dataset . common import TrainDatasets [EOL] from gluonts . model . lstnet import LSTNetEstimator [EOL] from gluonts . mx . trainer import Trainer [EOL] from gluonts . dataset . multivariate_grouper import MultivariateGrouper [EOL] from gluonts . evaluation import MultivariateEvaluator [EOL] from gluonts . evaluation . backtest import make_evaluation_predictions [EOL] [EOL] [EOL] NUM_SERIES = [number] [EOL] NUM_SAMPLES = [number] [EOL] [EOL] [EOL] def load_multivariate_constant_dataset ( ) : [EOL] metadata , train_ds , test_ds = constant_dataset ( ) [EOL] grouper_train = MultivariateGrouper ( max_target_dim = NUM_SERIES ) [EOL] grouper_test = MultivariateGrouper ( max_target_dim = NUM_SERIES ) [EOL] return TrainDatasets ( metadata = metadata , train = grouper_train ( train_ds ) , test = grouper_test ( test_ds ) , ) [EOL] [EOL] [EOL] dataset = load_multivariate_constant_dataset ( ) [EOL] freq = dataset . metadata . metadata . freq [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ [number] ] ) @ pytest . mark . parametrize ( [string] , [ [number] ] ) @ pytest . mark . parametrize ( [string] , [ ( dataset . metadata . prediction_length - [number] , [number] ) , ( [number] , dataset . metadata . prediction_length ) , ] , ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) @ pytest . mark . parametrize ( [string] , [ np . float32 , np . float64 ] ) def test_lstnet ( skip_size , ar_window , lead_time , prediction_length , hybridize , scaling , dtype , ) : [EOL] estimator = LSTNetEstimator ( skip_size = skip_size , ar_window = ar_window , num_series = NUM_SERIES , channels = [number] , kernel_size = [number] , context_length = [number] , freq = freq , lead_time = lead_time , prediction_length = prediction_length , trainer = Trainer ( epochs = [number] , batch_size = [number] , learning_rate = [number] , hybridize = hybridize ) , scaling = scaling , dtype = dtype , ) [EOL] [EOL] predictor = estimator . train ( dataset . train ) [EOL] forecast_it , ts_it = make_evaluation_predictions ( dataset = dataset . test , predictor = predictor , num_samples = NUM_SAMPLES ) [EOL] forecasts = list ( forecast_it ) [EOL] tss = list ( ts_it ) [EOL] assert len ( forecasts ) == len ( tss ) == len ( dataset . test ) [EOL] test_ds = dataset . test . list_data [ [number] ] [EOL] for fct in forecasts : [EOL] assert fct . freq == freq [EOL] assert fct . samples . shape == ( NUM_SAMPLES , prediction_length , NUM_SERIES , ) [EOL] assert ( fct . start_date == pd . date_range ( start = str ( test_ds [ [string] ] ) , periods = test_ds [ [string] ] . shape [ [number] ] , freq = freq , ) [ - prediction_length ] ) [EOL] [EOL] evaluator = MultivariateEvaluator ( quantiles = [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] agg_metrics , item_metrics = evaluator ( iter ( tss ) , iter ( forecasts ) , num_series = len ( dataset . test ) ) [EOL] assert agg_metrics [ [string] ] < [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from mxnet import nd [EOL] [EOL] [EOL] def load_gp_params ( ) : [EOL] return nd . array ( [ [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] , ] ) . expand_dims ( axis = [number] ) [EOL] [EOL] [EOL] def load_exact_mean ( ) : [EOL] return nd . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , ] ) [EOL] [EOL] [EOL] def load_exact_std ( ) : [EOL] return nd . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , ] ) [EOL] [EOL] [EOL] def load_xfull ( ) : [EOL] return nd . array ( [ [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , ] ) . expand_dims ( axis = [number] ) [EOL] [EOL] [EOL] def load_ytrain ( ) : [EOL] return nd . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from gluonts . mx . kernels import RBFKernel [EOL] from gluonts . model . gp_forecaster . gaussian_process import GaussianProcess [EOL] [EOL] [comment] [EOL] from . data import ( load_gp_params , load_exact_mean , load_exact_std , load_xfull , load_ytrain , ) [EOL] [EOL] [comment] [EOL] from mxnet import nd [EOL] import pytest [EOL] [EOL] [EOL] def relative_error ( y_hat , y_exact ) : [EOL] return nd . max ( nd . max ( nd . abs ( y_exact - y_hat ) , axis = [number] ) / nd . max ( nd . abs ( y_exact ) , axis = [number] ) ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( load_gp_params ( ) , load_exact_mean ( ) , load_exact_std ( ) , load_xfull ( ) , load_ytrain ( ) , ) , ( load_gp_params ( ) , load_exact_mean ( ) [ : , : [number] ] , load_exact_std ( ) [ : , : [number] ] , load_xfull ( ) , load_ytrain ( ) , ) , ] , ) def test_inference ( gp_params , mean_exact , std_exact , x_full , y_train ) : [EOL] [comment] [EOL] tol = [number] [EOL] num_samples = [number] [EOL] context_length = y_train . shape [ [number] ] [EOL] prediction_length = mean_exact . shape [ [number] ] [EOL] [EOL] [comment] [EOL] x_train = x_full [ : , : context_length , : ] [EOL] x_test = x_full [ : , context_length : context_length + prediction_length , : ] [EOL] [EOL] amplitude = gp_params [ : , [number] , : ] . expand_dims ( axis = [number] ) [EOL] length_scale = gp_params [ : , [number] , : ] . expand_dims ( axis = [number] ) [EOL] sigma = gp_params [ : , [number] , : ] . expand_dims ( axis = [number] ) [EOL] [EOL] [comment] [EOL] kernel = RBFKernel ( amplitude , length_scale ) [EOL] [EOL] [comment] [EOL] gp = GaussianProcess ( sigma = sigma , kernel = kernel , context_length = context_length , prediction_length = prediction_length , num_samples = num_samples , float_type = np . float32 , ) [EOL] [EOL] [comment] [EOL] _ , mean , std = gp . exact_inference ( x_train , y_train , x_test ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] assert relative_error ( mean , mean_exact ) <= tol [EOL] assert relative_error ( std , std_exact ) <= tol [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import pytest [EOL] [EOL] from gluonts . model . gp_forecaster import GaussianProcessEstimator [EOL] [EOL] [EOL] @ pytest . fixture ( ) def hyperparameters ( dsinfo ) : [EOL] return dict ( ctx = [string] , epochs = [number] , learning_rate = [number] , hybridize = True , cardinality = dsinfo . cardinality , num_batches_per_epoch = [number] , time_features = dsinfo . time_features , use_symbol_block_predictor = False , ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_accuracy ( accuracy_test , hyperparameters , hybridize ) : [EOL] hyperparameters . update ( num_batches_per_epoch = [number] , hybridize = hybridize ) [EOL] [EOL] accuracy_test ( GaussianProcessEstimator , hyperparameters , accuracy = [number] ) [EOL] [EOL] [EOL] def test_repr ( repr_test , hyperparameters ) : [EOL] repr_test ( GaussianProcessEstimator , hyperparameters ) [EOL] [EOL] [EOL] def test_serialize ( serialize_test , hyperparameters ) : [EOL] serialize_test ( GaussianProcessEstimator , hyperparameters ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import mxnet [EOL] import pytest [EOL] import mxnet as mx [EOL] import numpy as np [EOL] from mxnet import nd [EOL] [EOL] [comment] [EOL] from gluonts . model . tpp . deeptpp . _network import ( DeepTPPTrainingNetwork , DeepTPPPredictionNetwork , ) [EOL] from gluonts . model . tpp . distribution import WeibullOutput [EOL] [EOL] [EOL] def _allclose ( a , b ) : [EOL] return np . allclose ( a . asnumpy ( ) , b . asnumpy ( ) , atol = [number] ) [EOL] [EOL] [EOL] TEST_CASES = [ ( nd . array ( [ [ [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] ] ] ) , nd . array ( [ [ [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] ] ] ) , nd . array ( [ [number] , [number] ] ) , [number] , nd . array ( [ [number] , [number] ] ) , ) , ( nd . array ( [ [ [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] ] ] ) , nd . array ( [ [ [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] ] ] ) , nd . array ( [ [number] , [number] ] ) , [number] , nd . array ( [ [number] , [number] ] ) , ) , ( nd . array ( [ [ [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] ] ] ) , nd . array ( [ [ [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] ] ] ) , nd . array ( [ [number] , [number] ] ) , [number] , nd . array ( [ [number] , [number] ] ) , ) , ( nd . array ( [ [ [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] ] ] ) , nd . array ( [ [ [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] ] ] ) , nd . array ( [ [number] , [number] ] ) , [number] , nd . array ( [ [number] , [number] ] ) , ) , ] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , TEST_CASES ) def test_log_likelihood ( ia_times , marks , valid_length , num_marks , loglike ) : [EOL] mx . rnd . seed ( seed_state = [number] ) [EOL] [EOL] model = DeepTPPTrainingNetwork ( num_marks = num_marks , interval_length = [number] , time_distr_output = WeibullOutput ( ) , ) [EOL] model . initialize ( ) [EOL] [EOL] loglike_pred = model ( nd . stack ( ia_times , marks , axis = - [number] ) , valid_length ) [EOL] [EOL] assert loglike_pred . shape == ( ia_times . shape [ [number] ] , ) [EOL] assert _allclose ( loglike , loglike_pred ) [EOL] [EOL] [EOL] def test_trainining_network_disallows_hybrid ( ) : [EOL] mx . rnd . seed ( seed_state = [number] ) [EOL] [EOL] with pytest . raises ( NotImplementedError ) : [EOL] smodel = DeepTPPTrainingNetwork ( num_marks = [number] , interval_length = [number] ) [EOL] smodel . hybridize ( ) [EOL] [EOL] [EOL] def test_prediction_network_disallows_hybrid ( ) : [EOL] mx . rnd . seed ( seed_state = [number] ) [EOL] [EOL] with pytest . raises ( NotImplementedError ) : [EOL] smodel = DeepTPPPredictionNetwork ( num_marks = [number] , interval_length = [number] , prediction_interval_length = [number] ) [EOL] smodel . hybridize ( ) [EOL] [EOL] [EOL] def test_prediction_network_output ( ) : [EOL] mx . rnd . seed ( seed_state = [number] ) [EOL] model = DeepTPPPredictionNetwork ( num_marks = [number] , time_distr_output = WeibullOutput ( ) , interval_length = [number] , prediction_interval_length = [number] , ) [EOL] model . initialize ( ) [EOL] past_ia_times = nd . array ( [ [ [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] ] ] ) [EOL] past_marks = nd . array ( [ [ [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] ] ] ) [EOL] past_valid_length = nd . array ( [ [number] , [number] ] ) [EOL] past_target = nd . stack ( past_ia_times , past_marks , axis = - [number] ) [EOL] [EOL] pred_target , pred_valid_length = model ( past_target , past_valid_length ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] assert pred_target . ndim == [number] [EOL] assert pred_target . shape [ [number] ] == model . num_parallel_samples [EOL] assert pred_target . shape [ [number] ] == past_ia_times . shape [ [number] ] [EOL] assert pred_target . shape [ [number] ] == [number] [comment] [EOL] [comment] [EOL] assert pred_valid_length . ndim == [number] [EOL] assert pred_valid_length . shape [ [number] ] == model . num_parallel_samples [EOL] assert pred_valid_length . shape [ [number] ] == past_ia_times . shape [ [number] ] [EOL] [EOL] pred_ia_times = pred_target [ ... , [number] ] . asnumpy ( ) [EOL] pred_marks = pred_target [ ... , [number] ] . asnumpy ( ) [EOL] [EOL] assert pred_marks . min ( ) >= [number] [EOL] assert pred_marks . max ( ) < model . num_marks [EOL] assert ( pred_ia_times >= [number] ) . all ( ) [EOL] [comment] [EOL] assert ( pred_ia_times . sum ( - [number] ) < model . prediction_interval_length ) . all ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Tuple [EOL] import typing [EOL] import builtins [EOL] import gluonts [EOL] from typing import Tuple [EOL] [EOL] [comment] [EOL] import mxnet as mx [EOL] import numpy as np [EOL] import pandas as pd [EOL] import pytest [EOL] from mxnet import nd [EOL] [EOL] [comment] [EOL] from gluonts . model . common import Tensor [EOL] from gluonts . model . tpp import ( PointProcessGluonPredictor , PointProcessSampleForecast , ) [EOL] from gluonts . transform import ( ContinuousTimeInstanceSplitter , ContinuousTimeUniformSampler , ) [EOL] [EOL] [comment] [EOL] from . common import point_process_dataset , point_process_dataset_2 [EOL] [EOL] [EOL] class MockTPPPredictionNet ( mx . gluon . HybridBlock ) : [EOL] def __init__ ( self , num_parallel_samples = [number] , prediction_interval_length = [number] , context_interval_length = [number] , ) : [EOL] super ( ) . __init__ ( ) [EOL] self . num_parallel_samples = num_parallel_samples [EOL] self . prediction_interval_length = prediction_interval_length [EOL] self . context_interval_length = context_interval_length [EOL] [EOL] def hybridize ( self , active = True , ** kwargs ) : [EOL] if active : [EOL] raise NotImplementedError ( ) [EOL] [EOL] [comment] [EOL] def hybrid_forward ( self , F , past_target , past_valid_length ) : [EOL] [docstring] [EOL] batch_size = past_target . shape [ [number] ] [EOL] assert past_valid_length . shape [ [number] ] == batch_size [EOL] [EOL] target_shape = ( self . num_parallel_samples , batch_size , [number] ) [EOL] pred_target = nd . stack ( nd . random . uniform ( shape = target_shape ) , nd . random . randint ( [number] , [number] , shape = target_shape ) . astype ( np . float32 ) , axis = - [number] , ) [EOL] pred_valid_length = nd . random . randint ( [number] , [number] + [number] , shape = target_shape [ : [number] ] ) [EOL] [EOL] return pred_target , pred_valid_length [EOL] [EOL] [EOL] @ pytest . fixture def predictor_factory ( ) : [EOL] def get_predictor ( ** kwargs ) : [EOL] default_kwargs = dict ( input_names = [ [string] , [string] ] , prediction_net = MockTPPPredictionNet ( prediction_interval_length = [number] ) , batch_size = [number] , prediction_interval_length = [number] , freq = [string] , ctx = mx . cpu ( ) , input_transform = ContinuousTimeInstanceSplitter ( [number] , [number] , ContinuousTimeUniformSampler ( num_instances = [number] ) ) , ) [EOL] [EOL] default_kwargs . update ( ** kwargs ) [EOL] [EOL] return PointProcessGluonPredictor ( ** default_kwargs ) [EOL] [EOL] return get_predictor [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( point_process_dataset , [number] ) , ( point_process_dataset_2 , [number] ) ] ) def test_tpp_pred_dataset_2_shapes_ok ( dataset_tuple , predictor_factory ) : [EOL] [EOL] dataset , ds_length = dataset_tuple [EOL] [EOL] predictor = predictor_factory ( ) [EOL] forecasts = [ fc for fc in predictor . predict ( dataset ( ) , [number] ) ] [EOL] [EOL] assert len ( forecasts ) == ds_length [EOL] [EOL] for forecast in forecasts : [EOL] [comment] [EOL] assert isinstance ( forecast , PointProcessSampleForecast ) [EOL] [EOL] assert forecast . samples . shape == ( [number] , [number] , [number] ) [EOL] assert forecast . valid_length . shape == ( [number] , ) [EOL] [EOL] assert ( forecast . prediction_interval_length == predictor . prediction_interval_length ) [EOL] [EOL] assert forecast . start_date == pd . Timestamp ( [string] ) [EOL] assert forecast . end_date == pd . Timestamp ( [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[gluonts.model.common.Tensor,gluonts.model.common.Tensor]$ 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 $gluonts.model.common.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.tpp.PointProcessGluonPredictor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] import pandas as pd [EOL] import pytest [EOL] [EOL] [comment] [EOL] from gluonts . dataset . common import ListDataset [EOL] [EOL] [EOL] @ pytest . fixture def point_process_dataset ( ) : [EOL] [EOL] ia_times = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] marks = np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] [EOL] lds = ListDataset ( [ { [string] : np . c_ [ ia_times , marks ] . T , [string] : pd . Timestamp ( [string] , freq = [string] ) , [string] : pd . Timestamp ( [string] , freq = [string] ) , } ] , freq = [string] , one_dim_target = False , ) [EOL] [EOL] return lds [EOL] [EOL] [EOL] @ pytest . fixture def point_process_dataset_2 ( ) : [EOL] [EOL] lds = ListDataset ( [ { [string] : np . c_ [ np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) , np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) , ] . T , [string] : pd . Timestamp ( [string] , freq = [string] ) , [string] : pd . Timestamp ( [string] , freq = [string] ) , } , { [string] : np . c_ [ np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) , np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) , ] . T , [string] : pd . Timestamp ( [string] , freq = [string] ) , [string] : pd . Timestamp ( [string] , freq = [string] ) , } , { [string] : np . c_ [ np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) , np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) , ] . T , [string] : pd . Timestamp ( [string] , freq = [string] ) , [string] : pd . Timestamp ( [string] , freq = [string] ) , } , ] , freq = [string] , one_dim_target = False , ) [EOL] [EOL] return lds [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import gluonts [EOL] import builtins [EOL] import tempfile [EOL] from pathlib import Path [EOL] [EOL] [comment] [EOL] import pytest [EOL] from flaky import flaky [EOL] import pandas as pd [EOL] import numpy as np [EOL] from pydantic import PositiveInt [EOL] [EOL] [comment] [EOL] from gluonts . dataset . artificial import constant_dataset [EOL] from gluonts . evaluation . backtest import backtest_metrics [EOL] from gluonts . evaluation import Evaluator [EOL] from gluonts . model . predictor import Predictor [EOL] from gluonts . model . naive_2 import Naive2Predictor [EOL] from gluonts . model . seasonal_naive import SeasonalNaivePredictor [EOL] from gluonts . dataset . common import Dataset [EOL] from gluonts . support . pandas import forecast_start [EOL] [EOL] [EOL] def generate_random_dataset ( num_ts , start_time , freq , min_length , max_length ) : [EOL] start_timestamp = pd . Timestamp ( start_time , freq = freq ) [EOL] for _ in range ( num_ts ) : [EOL] ts_length = np . random . randint ( low = min_length , high = max_length ) [EOL] target = np . random . uniform ( size = ( ts_length , ) ) [EOL] data = { [string] : target , [string] : start_timestamp } [EOL] yield data [EOL] [EOL] [EOL] PREDICTION_LENGTH = PositiveInt ( [number] ) [EOL] SEASON_LENGTH = PositiveInt ( [number] ) [EOL] START_TIME = [string] [comment] [EOL] MIN_LENGTH = [number] [EOL] MAX_LENGTH = [number] [EOL] NUM_TS = [number] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ SeasonalNaivePredictor , Naive2Predictor ] ) @ pytest . mark . parametrize ( [string] , [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] ] ) def test_predictor ( predictor_cls , freq ) : [EOL] predictor = predictor_cls ( freq = freq , prediction_length = PREDICTION_LENGTH , season_length = SEASON_LENGTH , ) [EOL] dataset = list ( generate_random_dataset ( num_ts = NUM_TS , start_time = START_TIME , freq = freq , min_length = MIN_LENGTH , max_length = MAX_LENGTH , ) ) [EOL] [EOL] [comment] [EOL] forecasts = list ( predictor . predict ( dataset ) ) [EOL] [EOL] assert len ( dataset ) == NUM_TS [EOL] assert len ( forecasts ) == NUM_TS [EOL] [EOL] [comment] [EOL] for data , forecast in zip ( dataset , forecasts ) : [EOL] assert forecast . samples . shape == ( [number] , PREDICTION_LENGTH ) [EOL] [EOL] ref = data [ [string] ] [ - SEASON_LENGTH : - SEASON_LENGTH + PREDICTION_LENGTH ] [EOL] [EOL] assert forecast . start_date == forecast_start ( data ) [EOL] [EOL] [comment] [EOL] if predictor_cls == SeasonalNaivePredictor : [EOL] assert np . allclose ( forecast . samples [ [number] ] , ref ) [EOL] [EOL] [EOL] [comment] [EOL] [EOL] [EOL] dataset_info , constant_train_ds , constant_test_ds = constant_dataset ( ) [EOL] CONSTANT_DATASET_FREQ = dataset_info . metadata . freq [EOL] CONSTANT_DATASET_PREDICTION_LENGTH = dataset_info . prediction_length [EOL] [EOL] [EOL] def seasonal_naive_predictor ( ) : [EOL] return ( SeasonalNaivePredictor , dict ( prediction_length = CONSTANT_DATASET_PREDICTION_LENGTH ) , ) [EOL] [EOL] [EOL] def naive_2_predictor ( ) : [EOL] return ( Naive2Predictor , dict ( prediction_length = CONSTANT_DATASET_PREDICTION_LENGTH ) , ) [EOL] [EOL] [EOL] @ flaky ( max_runs = [number] , min_passes = [number] ) @ pytest . mark . parametrize ( [string] , [ seasonal_naive_predictor ( ) + ( [number] , ) , naive_2_predictor ( ) + ( [number] , ) ] , ) def test_accuracy ( predictor_cls , parameters , accuracy ) : [EOL] predictor = predictor_cls ( freq = CONSTANT_DATASET_FREQ , ** parameters ) [EOL] agg_metrics , item_metrics = backtest_metrics ( test_dataset = constant_test_ds , predictor = predictor , evaluator = Evaluator ( calculate_owa = True ) , ) [EOL] [EOL] assert agg_metrics [ [string] ] <= accuracy [EOL] [EOL] [EOL] [comment] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ seasonal_naive_predictor ( ) , naive_2_predictor ( ) ] , ) def test_seriali_predictors ( predictor_cls , parameters ) : [EOL] predictor = predictor_cls ( freq = CONSTANT_DATASET_FREQ , ** parameters ) [EOL] with tempfile . TemporaryDirectory ( ) as temp_dir : [EOL] predictor . serialize ( Path ( temp_dir ) ) [EOL] predictor_exp = Predictor . deserialize ( Path ( temp_dir ) ) [EOL] assert predictor == predictor_exp [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.Dataset$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] import pandas as pd [EOL] import os [EOL] from pathlib import Path [EOL] [EOL] [comment] [EOL] from gluonts . model . naive_2 import naive_2 [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] R_INPUT_FILE = [string] [EOL] R_OUTPUT_FILE = [string] [EOL] [EOL] [EOL] def load_naive_2_data ( ) : [EOL] test_directory_path = Path ( os . getenv ( [string] ) ) . parents [ [number] ] [EOL] r_naive_2_inputs = pd . read_csv ( test_directory_path / R_INPUT_FILE ) . values [EOL] r_naive_2_outputs = pd . read_csv ( test_directory_path / R_OUTPUT_FILE ) . values [EOL] return r_naive_2_inputs , r_naive_2_outputs [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [docstring] [EOL] [comment] [EOL] [docstring] [EOL] [EOL] [comment] [EOL] FH = [number] [comment] [EOL] FRQ = [number] [comment] [EOL] [EOL] [EOL] def test_naive_2 ( prediction_length = FH , season_length = FRQ ) : [EOL] r_naive_2_inputs , r_naive_2_outputs = load_naive_2_data ( ) [EOL] predictions = [ ] [EOL] for i in range ( len ( r_naive_2_inputs ) ) : [EOL] predictions . append ( naive_2 ( r_naive_2_inputs [ i ] , prediction_length = prediction_length , season_length = season_length , ) ) [EOL] predictions = np . array ( predictions ) [EOL] [EOL] assert np . allclose ( r_naive_2_outputs , predictions ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List , Any [EOL] import typing [EOL] import builtins [EOL] from typing import Any , List [EOL] [EOL] [comment] [EOL] import pytest [EOL] [EOL] [comment] [EOL] from gluonts . mx . trainer import Trainer [EOL] [EOL] [EOL] def test_epochs ( ) : [EOL] assert_valid_param ( param_name = [string] , param_values = [ [number] , [number] , [number] , [number] , [number] ] ) [EOL] assert_invalid_param ( param_name = [string] , param_values = [ - [number] , - [number] ] , exp_msg = [string] , ) [EOL] [EOL] [EOL] def test_patience ( ) : [EOL] assert_valid_param ( param_name = [string] , param_values = [ [number] , [number] , [number] , [number] ] ) [EOL] assert_invalid_param ( param_name = [string] , param_values = [ - [number] , - [number] ] , exp_msg = [string] , ) [EOL] [EOL] [EOL] def test_learning_rate ( ) : [EOL] assert_valid_param ( param_name = [string] , param_values = [ [number] , [number] , [number] ] ) [EOL] assert_invalid_param ( param_name = [string] , param_values = [ - [number] , - [number] , [number] , float ( [string] ) , float ( [string] ) ] , exp_msg = [string] , ) [EOL] [EOL] [EOL] def test_learning_rate_decay_factor ( ) : [EOL] assert_valid_param ( param_name = [string] , param_values = [ [number] , [number] , [number] , [number] - [number] ] , ) [EOL] assert_invalid_param ( param_name = [string] , param_values = [ - [number] , - [number] , + [number] , + [number] , float ( [string] ) , float ( [string] ) ] , exp_msg = [string] , ) [EOL] [EOL] [EOL] def assert_valid_param ( param_name , param_values ) : [EOL] try : [EOL] for x in param_values : [EOL] Trainer ( ** { param_name : x } ) [EOL] except Exception as e : [EOL] pytest . fail ( f' [string] { e } [string] ' ) [EOL] raise e [EOL] [EOL] [EOL] def assert_invalid_param ( param_name , param_values , exp_msg ) : [EOL] for x in param_values : [EOL] with pytest . raises ( AssertionError ) as excinfo : [EOL] Trainer ( ** { param_name : x } ) [EOL] assert exp_msg in str ( excinfo . value ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import mxnet as mx [EOL] import numpy as np [EOL] import pytest [EOL] [EOL] [comment] [EOL] from gluonts . mx . trainer import learning_rate_scheduler as lrs [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [number] , [number] , [number] , [number] , [ ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ] , ) , ( [number] , [number] , [number] , [number] , [ ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ] , ) , ( [number] , [number] , [number] , [number] , [ ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ] , ) , ] , ) def test_PatientMetricAttentiveScheduler ( base_lr , decay_factor , patience , minimum_lr , seq_loss_lr ) : [EOL] lr_scheduler = lrs . MetricAttentiveScheduler ( base_lr = [number] * base_lr , decay_factor = decay_factor , patience = patience , objective = [string] , min_lr = minimum_lr , ) [EOL] [EOL] opt = mx . optimizer . Adam ( learning_rate = base_lr , lr_scheduler = lr_scheduler ) [EOL] [EOL] for loss , lr_exp in seq_loss_lr : [EOL] lr_scheduler . step ( loss ) [EOL] [EOL] [comment] [EOL] for _ in range ( [number] ) : [EOL] assert np . isclose ( opt . learning_rate , lr_exp ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import builtins [EOL] import mxnet [EOL] import mxnet as mx [EOL] import mxnet . gluon . nn as nn [EOL] import numpy as np [EOL] import pytest [EOL] import pandas as pd [EOL] import math [EOL] [EOL] [comment] [EOL] from gluonts . dataset . common import ListDataset [EOL] from gluonts . model . simple_feedforward import SimpleFeedForwardEstimator [EOL] from gluonts . mx . trainer import Trainer [EOL] from gluonts . mx . trainer . model_iteration_averaging import ( IterationAveragingStrategy , NTA , Alpha_Suffix , ) [EOL] [EOL] [EOL] def initialize_model ( ) : [EOL] [comment] [EOL] N = [number] [comment] [EOL] T = [number] [comment] [EOL] prediction_length = [number] [EOL] freq = [string] [EOL] custom_dataset = np . zeros ( shape = ( N , T ) ) [EOL] start = pd . Timestamp ( [string] , freq = freq ) [comment] [EOL] train_ds = ListDataset ( [ { [string] : x , [string] : start } for x in custom_dataset [ : , : - prediction_length ] ] , freq = freq , ) [EOL] [comment] [EOL] estimator = SimpleFeedForwardEstimator ( num_hidden_dimensions = [ [number] ] , prediction_length = prediction_length , context_length = T , freq = freq , trainer = Trainer ( ctx = [string] , epochs = [number] , learning_rate = [number] , num_batches_per_epoch = [number] , ) , ) [EOL] [EOL] [comment] [EOL] predictor = estimator . train ( train_ds ) [EOL] [EOL] return predictor . prediction_net [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ - [number] , - [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_NTA_V1 ( n , last_n_trigger ) : [EOL] model = initialize_model ( ) [EOL] params = model . collect_params ( ) [EOL] avg_strategy = NTA ( n = n , last_n_trigger = last_n_trigger ) [EOL] loss_list = [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] [EOL] for i , loss in enumerate ( loss_list ) : [EOL] for k , v in params . items ( ) : [EOL] for arr in v . list_data ( ) : [EOL] arr [ : ] = i [EOL] avg_strategy . update_average_trigger ( metric = loss ) [EOL] avg_strategy . apply ( model ) [EOL] [comment] [EOL] [comment] [EOL] avg_strategy . load_cached_model ( model ) [EOL] for k , v in params . items ( ) : [EOL] for arr in v . list_data ( ) : [EOL] [comment] [EOL] assert mx . nd . norm ( arr - [number] ) . asscalar ( ) < [number] [EOL] [comment] [EOL] avg_strategy . load_averaged_model ( model ) [EOL] len_limit = ( len ( loss_list ) - [number] ) if last_n_trigger else [number] [EOL] if n <= [number] or n > len_limit : [EOL] [comment] [EOL] for k , v in params . items ( ) : [EOL] for arr in v . list_data ( ) : [EOL] [comment] [EOL] assert mx . nd . norm ( arr - [number] ) . asscalar ( ) < [number] [EOL] else : [EOL] for k , v in params . items ( ) : [EOL] for arr in v . list_data ( ) : [EOL] if last_n_trigger : [EOL] [comment] [EOL] [comment] [EOL] val = [number] if n <= [number] else ( ( n + [number] ) / [number] ) [EOL] else : [EOL] [comment] [EOL] val = ( [number] + n + [number] ) / [number] [EOL] assert mx . nd . norm ( arr - val ) . asscalar ( ) < [number] [EOL] [comment] [EOL] avg_strategy . load_cached_model ( model ) [EOL] for k , v in params . items ( ) : [EOL] for arr in v . list_data ( ) : [EOL] [comment] [EOL] assert mx . nd . norm ( arr - [number] ) . asscalar ( ) < [number] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) def test_Alpha_Suffix ( alpha ) : [EOL] model = initialize_model ( ) [EOL] params = model . collect_params ( ) [EOL] loss_list = [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] [EOL] avg_strategy = Alpha_Suffix ( epochs = len ( loss_list ) , alpha = alpha ) [EOL] for i , loss in enumerate ( loss_list ) : [EOL] for k , v in params . items ( ) : [EOL] for arr in v . list_data ( ) : [EOL] arr [ : ] = i [EOL] avg_strategy . update_average_trigger ( epoch = i + [number] ) [EOL] avg_strategy . apply ( model ) [EOL] [comment] [EOL] [comment] [EOL] avg_strategy . load_cached_model ( model ) [EOL] for k , v in params . items ( ) : [EOL] for arr in v . list_data ( ) : [EOL] [comment] [EOL] assert mx . nd . norm ( arr - [number] ) . asscalar ( ) < [number] [EOL] [comment] [EOL] avg_strategy . load_averaged_model ( model ) [EOL] n = max ( int ( math . ceil ( len ( loss_list ) * ( [number] - alpha ) ) ) , [number] ) [EOL] if n > len ( loss_list ) : [EOL] [comment] [EOL] for k , v in params . items ( ) : [EOL] for arr in v . list_data ( ) : [EOL] [comment] [EOL] assert mx . nd . norm ( arr - [number] ) . asscalar ( ) < [number] [EOL] else : [EOL] for k , v in params . items ( ) : [EOL] for arr in v . list_data ( ) : [EOL] val = ( n + [number] ) / [number] [EOL] assert mx . nd . norm ( arr - val ) . asscalar ( ) < [number] [EOL] [comment] [EOL] avg_strategy . load_cached_model ( model ) [EOL] for k , v in params . items ( ) : [EOL] for arr in v . list_data ( ) : [EOL] [comment] [EOL] assert mx . nd . norm ( arr - [number] ) . asscalar ( ) < [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.nn.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import mxnet as mx [EOL] import numpy as np [EOL] import pytest [EOL] [EOL] [comment] [EOL] from gluonts . mx . trainer . model_averaging import ( SelectNBestMean , SelectNBestSoftmax , ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ SelectNBestMean , SelectNBestSoftmax ] ) @ pytest . mark . parametrize ( [string] , [ [number] , [number] ] ) def test_model_averaging ( strategy , num_models ) : [EOL] total_models = [number] [EOL] [EOL] [comment] [EOL] param_1 = { [string] : mx . nd . array ( [ [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] ] ) , [string] : mx . nd . array ( [ [ [number] , [number] ] , [ [number] , [number] ] ] ) , } [EOL] loss_1 = [number] [EOL] [EOL] [comment] [EOL] param_2 = { [string] : mx . nd . array ( [ [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] ] ) , [string] : mx . nd . array ( [ [ [number] , [number] ] , [ [number] , [number] ] ] ) , } [EOL] loss_2 = [number] [EOL] assert ( loss_1 < loss_2 ) [comment] [EOL] [EOL] [comment] [EOL] all_arg_params = [ param_1 , param_2 ] [EOL] dummy_checkpoints = [ { [string] : [string] , [string] : [number] , [string] : loss_1 , } , { [string] : [string] , [string] : [number] , [string] : loss_2 , } , ] [EOL] [EOL] [comment] [EOL] avg = strategy ( num_models = num_models ) [EOL] _ , weights = avg . select_checkpoints ( dummy_checkpoints ) [EOL] assert len ( weights ) == num_models [EOL] [EOL] if isinstance ( avg , SelectNBestMean ) : [EOL] exp_weights = [ [number] / num_models for _ in range ( num_models ) ] [EOL] assert weights == exp_weights [EOL] elif isinstance ( avg , SelectNBestSoftmax ) : [EOL] losses = [ c [ [string] ] for c in dummy_checkpoints ] [EOL] losses = sorted ( losses ) [ : num_models ] [EOL] exp_weights = [ np . exp ( - l ) for l in losses ] [EOL] exp_weights = [ x / sum ( exp_weights ) for x in exp_weights ] [EOL] assert weights == exp_weights [EOL] [EOL] [comment] [EOL] weights = weights + [ [number] ] * ( total_models - num_models ) [comment] [EOL] exp_output = { [string] : weights [ [number] ] * mx . nd . array ( [ [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] ] ) + weights [ [number] ] * mx . nd . array ( [ [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] ] ) , [string] : weights [ [number] ] * mx . nd . array ( [ [ [number] , [number] ] , [ [number] , [number] ] ] ) + weights [ [number] ] * mx . nd . array ( [ [ [number] , [number] ] , [ [number] , [number] ] ] ) , } [EOL] [EOL] avg_params = { } [EOL] for k in all_arg_params [ [number] ] : [EOL] arrays = [ p [ k ] for p in all_arg_params ] [EOL] avg_params [ k ] = avg . average_arrays ( arrays , weights ) [EOL] [EOL] for k in all_arg_params [ [number] ] : [EOL] assert all_arg_params [ [number] ] [ k ] . shape == exp_output [ k ] . shape [EOL] assert mx . nd . sum ( avg_params [ k ] - exp_output [ k ] ) < [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from itertools import chain , combinations [EOL] [EOL] [comment] [EOL] import mxnet as mx [EOL] import pytest [EOL] [EOL] [comment] [EOL] from gluonts . mx . block . feature import FeatureAssembler , FeatureEmbedder [EOL] [EOL] [comment] [EOL] mx . random . seed ( [number] ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ False , True ] ) @ pytest . mark . parametrize ( [string] , ( lambda N , T : [ dict ( shape = ( N , [number] ) , kwargs = dict ( cardinalities = [ [number] ] , embedding_dims = [ [number] ] ) , ) , dict ( shape = ( N , T , [number] ) , kwargs = dict ( cardinalities = [ [number] ] , embedding_dims = [ [number] ] ) , ) , dict ( shape = ( N , [number] ) , kwargs = dict ( cardinalities = [ [number] , [number] , [number] , [number] ] , embedding_dims = [ [number] , [number] , [number] , [number] ] , ) , ) , dict ( shape = ( N , T , [number] ) , kwargs = dict ( cardinalities = [ [number] , [number] , [number] ] , embedding_dims = [ [number] , [number] , [number] ] ) , ) , ] ) ( [number] , [number] ) , ) def test_feature_embedder ( config , hybridize ) : [EOL] out_shape = config [ [string] ] [ : - [number] ] + ( sum ( config [ [string] ] [ [string] ] ) , ) [EOL] [EOL] embed_feature = FeatureEmbedder ( prefix = [string] , ** config [ [string] ] ) [EOL] embed_feature . collect_params ( ) . initialize ( mx . initializer . One ( ) ) [EOL] [EOL] if hybridize : [EOL] embed_feature . hybridize ( ) [EOL] [EOL] def test_parameters_length ( ) : [EOL] exp_params_len = len ( embed_feature . collect_params ( ) . keys ( ) ) [EOL] act_params_len = len ( config [ [string] ] [ [string] ] ) [EOL] assert exp_params_len == act_params_len [EOL] [EOL] def test_parameter_names ( ) : [EOL] for param in embed_feature . collect_params ( ) : [EOL] assert param . startswith ( [string] ) [EOL] [EOL] def test_forward_pass ( ) : [EOL] act_output = embed_feature ( mx . nd . ones ( shape = config [ [string] ] ) ) [EOL] exp_output = mx . nd . ones ( shape = out_shape ) [EOL] [EOL] assert act_output . shape == exp_output . shape [EOL] assert mx . nd . sum ( act_output - exp_output ) < [number] [EOL] [EOL] test_parameters_length ( ) [EOL] test_parameter_names ( ) [EOL] test_forward_pass ( ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ False , True ] ) @ pytest . mark . parametrize ( [string] , ( lambda N , T : [ dict ( N = N , T = T , static_cat = dict ( C = [number] ) , static_real = dict ( C = [number] ) , dynamic_cat = dict ( C = [number] ) , dynamic_real = dict ( C = [number] ) , embed_static = dict ( cardinalities = [ [number] , [number] ] , embedding_dims = [ [number] , [number] ] , prefix = [string] , ) , embed_dynamic = dict ( cardinalities = [ [number] , [number] , [number] ] , embedding_dims = [ [number] , [number] , [number] ] , prefix = [string] , ) , ) ] ) ( [number] , [number] ) , ) def test_feature_assembler ( config , hybridize ) : [EOL] [comment] [EOL] feature_types = { [string] , [string] , [string] , [string] , } [EOL] feature_combs = chain . from_iterable ( combinations ( feature_types , r ) for r in range ( [number] , len ( feature_types ) + [number] ) ) [EOL] [EOL] [comment] [EOL] embedder_types = { [string] , [string] } [EOL] embedder_combs = chain . from_iterable ( combinations ( embedder_types , r ) for r in range ( [number] , len ( embedder_types ) + [number] ) ) [EOL] [EOL] for enabled_embedders in embedder_combs : [EOL] embed_static = ( FeatureEmbedder ( ** config [ [string] ] ) [EOL] if [string] in enabled_embedders [EOL] else None ) [EOL] embed_dynamic = ( FeatureEmbedder ( ** config [ [string] ] ) [EOL] if [string] in enabled_embedders [EOL] else None ) [EOL] [EOL] for enabled_features in feature_combs : [EOL] assemble_feature = FeatureAssembler ( T = config [ [string] ] , embed_static = embed_static , embed_dynamic = embed_dynamic , ) [EOL] [EOL] assemble_feature . collect_params ( ) . initialize ( mx . initializer . One ( ) ) [EOL] [EOL] if hybridize : [EOL] assemble_feature . hybridize ( ) [EOL] [EOL] def test_parameters_length ( ) : [EOL] exp_params_len = sum ( [ len ( config [ k ] [ [string] ] ) for k in [ [string] , [string] ] if k in enabled_embedders ] ) [EOL] act_params_len = len ( assemble_feature . collect_params ( ) . keys ( ) ) [EOL] assert exp_params_len == act_params_len [EOL] [EOL] def test_parameter_names ( ) : [EOL] if embed_static : [EOL] for param in embed_static . collect_params ( ) : [EOL] assert param . startswith ( [string] ) [EOL] if embed_dynamic : [EOL] for param in embed_dynamic . collect_params ( ) : [EOL] assert param . startswith ( [string] ) [EOL] [EOL] def test_forward_pass ( ) : [EOL] N , T = config [ [string] ] , config [ [string] ] [EOL] [EOL] inp_features = [ ] [EOL] out_features = [ ] [EOL] [EOL] if [string] not in enabled_features : [EOL] inp_features . append ( mx . nd . zeros ( shape = ( N , [number] ) ) ) [EOL] out_features . append ( mx . nd . zeros ( shape = ( N , T , [number] ) ) ) [EOL] elif embed_static : [comment] [EOL] C = config [ [string] ] [ [string] ] [EOL] inp_features . append ( mx . nd . concat ( * [ mx . nd . random . uniform ( [number] , config [ [string] ] [ [string] ] [ c ] , shape = ( N , [number] ) , ) . floor ( ) for c in range ( C ) ] , dim = [number] , ) ) [EOL] out_features . append ( mx . nd . ones ( shape = ( N , T , sum ( config [ [string] ] [ [string] ] ) , ) ) ) [EOL] else : [comment] [EOL] C = config [ [string] ] [ [string] ] [EOL] inp_features . append ( mx . nd . concat ( * [ mx . nd . random . uniform ( [number] , config [ [string] ] [ [string] ] [ c ] , shape = ( N , [number] ) , ) . floor ( ) for c in range ( C ) ] , dim = [number] , ) ) [EOL] out_features . append ( mx . nd . tile ( mx . nd . expand_dims ( inp_features [ - [number] ] , axis = [number] ) , reps = ( [number] , T , [number] ) , ) ) [EOL] [EOL] if [string] not in enabled_features : [EOL] inp_features . append ( mx . nd . zeros ( shape = ( N , [number] ) ) ) [EOL] out_features . append ( mx . nd . zeros ( shape = ( N , T , [number] ) ) ) [EOL] else : [EOL] C = config [ [string] ] [ [string] ] [EOL] static_real = mx . nd . random . uniform ( [number] , [number] , shape = ( N , C ) ) [EOL] inp_features . append ( static_real ) [EOL] out_features . append ( mx . nd . tile ( static_real . expand_dims ( axis = - [number] ) , reps = ( [number] , T , [number] ) ) ) [EOL] [EOL] if [string] not in enabled_features : [EOL] inp_features . append ( mx . nd . zeros ( shape = ( N , T , [number] ) ) ) [EOL] out_features . append ( mx . nd . zeros ( shape = ( N , T , [number] ) ) ) [EOL] elif embed_dynamic : [comment] [EOL] C = config [ [string] ] [ [string] ] [EOL] inp_features . append ( mx . nd . concat ( * [ mx . nd . random . uniform ( [number] , config [ [string] ] [ [string] ] [ c ] , shape = ( N , T , [number] ) , ) . floor ( ) for c in range ( C ) ] , dim = [number] , ) ) [EOL] out_features . append ( mx . nd . ones ( shape = ( N , T , sum ( config [ [string] ] [ [string] ] ) , ) ) ) [EOL] else : [comment] [EOL] C = config [ [string] ] [ [string] ] [EOL] inp_features . append ( mx . nd . concat ( * [ mx . nd . random . uniform ( [number] , config [ [string] ] [ [string] ] [ c ] , shape = ( N , T , [number] ) , ) . floor ( ) for c in range ( C ) ] , dim = [number] , ) ) [EOL] out_features . append ( inp_features [ - [number] ] ) [EOL] [EOL] if [string] not in enabled_features : [EOL] inp_features . append ( mx . nd . zeros ( shape = ( N , T , [number] ) ) ) [EOL] out_features . append ( mx . nd . zeros ( shape = ( N , T , [number] ) ) ) [EOL] else : [EOL] C = config [ [string] ] [ [string] ] [EOL] dynamic_real = mx . nd . random . uniform ( [number] , [number] , shape = ( N , T , C ) ) [EOL] inp_features . append ( dynamic_real ) [EOL] out_features . append ( dynamic_real ) [EOL] [EOL] exp_output = mx . nd . concat ( * out_features , dim = [number] ) [EOL] act_output = assemble_feature ( * inp_features ) [EOL] [EOL] assert exp_output . shape == act_output . shape [EOL] assert mx . nd . sum ( exp_output - act_output ) < [number] [EOL] [EOL] test_parameters_length ( ) [EOL] test_parameter_names ( ) [EOL] test_forward_pass ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import pytest [EOL] import mxnet as mx [EOL] import numpy as np [EOL] [EOL] from gluonts . mx . block import scaler [EOL] [EOL] [EOL] test_cases = [ ( scaler . MeanScaler ( ) , mx . nd . array ( [ [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] , ] ) , mx . nd . array ( [ [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] , ] ) , mx . nd . array ( [ [number] , [number] , [number] , [number] , [number] ] ) , ) , ( scaler . MeanScaler ( keepdims = True ) , mx . nd . array ( [ [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] , ] ) , mx . nd . array ( [ [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] , ] ) , mx . nd . array ( [ [number] , [number] , [number] , [number] , [number] ] ) . expand_dims ( axis = [number] ) , ) , ( scaler . MeanScaler ( ) , mx . nd . array ( [ [ [ [number] ] ] * [number] , [ [ [number] ] ] * [number] + [ [ [number] ] ] * [number] , [ [ [number] ] ] * [number] + [ [ [number] ] ] * [number] , [ [ [number] ] ] * [number] , [ [ [number] ] ] * [number] , ] ) , mx . nd . array ( [ [ [ [number] ] ] * [number] , [ [ [number] ] ] * [number] + [ [ [number] ] ] * [number] , [ [ [number] ] ] * [number] + [ [ [number] ] ] * [number] , [ [ [number] ] ] * [number] , [ [ [number] ] ] * [number] , ] ) , mx . nd . array ( [ [number] , [number] , [number] , [number] , [number] ] ) . expand_dims ( axis = [number] ) , ) , ( scaler . MeanScaler ( minimum_scale = [number] ) , mx . nd . array ( [ [ [ [number] , [number] ] ] * [number] , [ [ [number] , [number] ] ] * [number] + [ [ [number] , [number] ] ] * [number] , [ [ [number] , [number] ] ] * [number] + [ [ [number] , [number] ] ] * [number] , [ [ [number] , [number] ] ] * [number] , [ [ [number] , [number] ] ] * [number] , ] ) , mx . nd . array ( [ [ [ [number] , [number] ] ] * [number] , [ [ [number] , [number] ] ] * [number] + [ [ [number] , [number] ] ] * [number] , [ [ [number] , [number] ] ] * [number] + [ [ [number] , [number] ] ] * [number] , [ [ [number] , [number] ] ] * [number] , [ [ [number] , [number] ] ] * [number] , ] ) , mx . nd . array ( [ [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , ] ) , ) , ( scaler . MeanScaler ( ) , mx . nd . array ( [ [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] + [ [number] ] * [number] , ] ) , mx . nd . array ( [ [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] + [ [number] ] * [number] , ] ) , mx . nd . array ( [ [number] , [number] , [number] , [number] ] ) , ) , ( scaler . MeanScaler ( ) , mx . nd . random . normal ( shape = ( [number] , [number] ) ) , mx . nd . zeros ( shape = ( [number] , [number] ) ) , [number] * mx . nd . ones ( shape = ( [number] , ) ) , ) , ( scaler . MeanScaler ( axis = [number] , minimum_scale = [number] ) , mx . nd . random . normal ( shape = ( [number] , [number] , [number] ) ) , mx . nd . zeros ( shape = ( [number] , [number] , [number] ) ) , [number] * mx . nd . ones ( shape = ( [number] , [number] ) ) , ) , ( scaler . MeanScaler ( minimum_scale = [number] ) , mx . nd . random . normal ( shape = ( [number] , [number] , [number] ) ) , mx . nd . zeros ( shape = ( [number] , [number] , [number] ) ) , [number] * mx . nd . ones ( shape = ( [number] , [number] ) ) , ) , ( scaler . MeanScaler ( minimum_scale = [number] ) , mx . nd . random . normal ( shape = ( [number] , [number] , [number] ) ) , mx . nd . zeros ( shape = ( [number] , [number] , [number] ) ) , [number] * mx . nd . ones ( shape = ( [number] , [number] ) ) , ) , ( scaler . NOPScaler ( ) , mx . nd . random . normal ( shape = ( [number] , [number] , [number] ) ) , mx . nd . random . normal ( shape = ( [number] , [number] , [number] ) ) > [number] , mx . nd . ones ( shape = ( [number] , [number] ) ) , ) , ( scaler . NOPScaler ( ) , mx . nd . random . normal ( shape = ( [number] , [number] , [number] ) ) , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) , mx . nd . ones ( shape = ( [number] , [number] ) ) , ) , ( scaler . NOPScaler ( ) , mx . nd . random . normal ( shape = ( [number] , [number] , [number] ) ) , mx . nd . zeros ( shape = ( [number] , [number] , [number] ) ) , mx . nd . ones ( shape = ( [number] , [number] ) ) , ) , ] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , test_cases ) def test_scaler ( s , target , observed , expected_scale ) : [EOL] target_scaled , scale = s ( target , observed ) [EOL] [EOL] assert np . allclose ( expected_scale . asnumpy ( ) , scale . asnumpy ( ) ) , [string] [EOL] [EOL] if s . keepdims : [EOL] expected_target_scaled = mx . nd . broadcast_div ( target , expected_scale ) [EOL] else : [EOL] expected_target_scaled = mx . nd . broadcast_div ( target , expected_scale . expand_dims ( axis = s . axis ) ) [EOL] [EOL] assert np . allclose ( expected_target_scaled . asnumpy ( ) , target_scaled . asnumpy ( ) ) , [string] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ] ) def test_nopscaler ( target , observed ) : [EOL] s = scaler . NOPScaler ( ) [EOL] target_scaled , scale = s ( target , observed ) [EOL] [EOL] assert mx . nd . norm ( target - target_scaled ) == [number] [EOL] assert mx . nd . norm ( mx . nd . ones_like ( target ) . mean ( axis = s . axis ) - scale ) == [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import builtins [EOL] from mxnet import nd [EOL] import pytest [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from gluonts . mx . block . regularization import ( ActivationRegularizationLoss , TemporalActivationRegularizationLoss , ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) def test_ActivationRegularizationLoss ( alpha ) : [EOL] ar = ActivationRegularizationLoss ( alpha , batch_axis = [number] ) [EOL] inputs = [ nd . arange ( [number] ) . reshape ( [number] , [number] , [number] ) , nd . arange ( [number] ) . reshape ( [number] , [number] , [number] ) , nd . arange ( [number] ) . reshape ( [number] , [number] , [number] ) , ] [EOL] ar_result = ar ( * inputs ) [EOL] outputs = [ alpha * nd . mean ( ( array * array ) , axis = [number] , exclude = True ) for array in inputs ] [EOL] assert np . isclose ( nd . add_n ( * outputs ) . asnumpy ( ) , ar_result . asnumpy ( ) ) . all ( ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) def test_TemporalActivationRegularizationLoss ( beta ) : [EOL] tar = TemporalActivationRegularizationLoss ( beta , time_axis = [number] , batch_axis = [number] ) [EOL] inputs = [ nd . arange ( [number] ) . reshape ( [number] , [number] , [number] ) , nd . arange ( [number] ) . reshape ( [number] , [number] , [number] ) , nd . arange ( [number] ) . reshape ( [number] , [number] , [number] ) , ] [EOL] tar_result = tar ( * inputs ) [EOL] outputs = [ beta * nd . mean ( ( array [ : , [number] : , : ] - array [ : , : - [number] , : ] ) . __pow__ ( [number] ) , axis = [number] , exclude = True , ) for array in inputs ] [EOL] assert np . isclose ( nd . add_n ( * outputs ) . asnumpy ( ) , tar_result . asnumpy ( ) ) . all ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import List , Tuple [EOL] import numpy [EOL] import mxnet [EOL] import gluonts [EOL] import pydantic [EOL] import typing [EOL] import builtins [EOL] [docstring] [EOL] [comment] [EOL] from typing import Iterable , List , Tuple [EOL] [EOL] [comment] [EOL] import mxnet as mx [EOL] import numpy as np [EOL] import pytest [EOL] from pydantic import PositiveFloat , PositiveInt [EOL] [EOL] [comment] [EOL] from gluonts . model . common import NPArrayLike [EOL] from gluonts . mx . distribution . box_cox_transform import ( InverseBoxCoxTransform , InverseBoxCoxTransformOutput , ) [EOL] from gluonts . mx . distribution import ( DistributionOutput , StudentT , StudentTOutput , Gamma , GammaOutput , Beta , BetaOutput , MultivariateGaussian , MultivariateGaussianOutput , LowrankMultivariateGaussian , LowrankMultivariateGaussianOutput , Dirichlet , DirichletOutput , DirichletMultinomial , DirichletMultinomialOutput , NegativeBinomial , NegativeBinomialOutput , Laplace , LaplaceOutput , Gaussian , GaussianOutput , GenPareto , GenParetoOutput , Poisson , PoissonOutput , PiecewiseLinear , PiecewiseLinearOutput , Binned , BinnedOutput , Categorical , CategoricalOutput , LogitNormal , LogitNormalOutput , ZeroInflatedBeta , OneInflatedBeta , ZeroAndOneInflatedBeta , ZeroInflatedBetaOutput , ZeroAndOneInflatedBetaOutput , OneInflatedBetaOutput , ) [EOL] from gluonts . mx . distribution . transformed_distribution_output import ( TransformedDistributionOutput , ) [EOL] from gluonts . mx . distribution . transformed_distribution import ( TransformedDistribution , ) [EOL] from gluonts . model . tpp . distribution import ( Loglogistic , LoglogisticOutput , Weibull , WeibullOutput , ) [EOL] [EOL] [EOL] NUM_SAMPLES = [number] [EOL] BATCH_SIZE = [number] [EOL] TOL = [number] [EOL] START_TOL_MULTIPLE = [number] [EOL] [EOL] np . random . seed ( [number] ) [EOL] mx . random . seed ( [number] ) [EOL] [EOL] [EOL] def inv_softplus ( y ) : [EOL] [comment] [EOL] return np . log ( np . exp ( y ) - [number] ) [EOL] [EOL] [EOL] def maximum_likelihood_estimate_sgd ( distr_output , samples , init_biases = None , num_epochs = PositiveInt ( [number] ) , learning_rate = PositiveFloat ( [number] ) , hybridize = True , ) : [EOL] model_ctx = mx . cpu ( ) [EOL] [EOL] arg_proj = distr_output . get_args_proj ( ) [EOL] arg_proj . initialize ( ) [EOL] [EOL] if hybridize : [EOL] arg_proj . hybridize ( ) [EOL] [EOL] if init_biases is not None : [EOL] for param , bias in zip ( arg_proj . proj , init_biases ) : [EOL] param . params [ param . prefix + [string] ] . initialize ( mx . initializer . Constant ( bias ) , force_reinit = True ) [EOL] [EOL] trainer = mx . gluon . Trainer ( arg_proj . collect_params ( ) , [string] , { [string] : learning_rate , [string] : [number] } , ) [EOL] [EOL] [comment] [EOL] dummy_data = mx . nd . array ( np . ones ( ( len ( samples ) , [number] ) ) ) [EOL] [EOL] train_data = mx . gluon . data . DataLoader ( mx . gluon . data . ArrayDataset ( dummy_data , samples ) , batch_size = BATCH_SIZE , shuffle = True , ) [EOL] [EOL] for e in range ( num_epochs ) : [EOL] cumulative_loss = [number] [EOL] num_batches = [number] [EOL] [comment] [EOL] for i , ( data , sample_label ) in enumerate ( train_data ) : [EOL] data = data . as_in_context ( model_ctx ) [EOL] sample_label = sample_label . as_in_context ( model_ctx ) [EOL] with mx . autograd . record ( ) : [EOL] distr_args = arg_proj ( data ) [EOL] distr = distr_output . distribution ( distr_args ) [EOL] loss = distr . loss ( sample_label ) [EOL] if not hybridize : [EOL] assert loss . shape == distr . batch_shape [EOL] loss . backward ( ) [EOL] trainer . step ( BATCH_SIZE ) [EOL] num_batches += [number] [EOL] [EOL] cumulative_loss += mx . nd . mean ( loss ) . asscalar ( ) [EOL] [EOL] assert not np . isnan ( cumulative_loss ) [EOL] print ( [string] % ( e , cumulative_loss / num_batches ) ) [EOL] [EOL] if len ( distr_args [ [number] ] . shape ) == [number] : [EOL] return [ param . asnumpy ( ) for param in arg_proj ( mx . nd . array ( np . ones ( ( [number] , [number] ) ) ) ) ] [EOL] [EOL] return [ param [ [number] ] . asnumpy ( ) for param in arg_proj ( mx . nd . array ( np . ones ( ( [number] , [number] ) ) ) ) ] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [number] , [number] ) ] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_beta_likelihood ( alpha , beta , hybridize ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] alphas = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + alpha [EOL] betas = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + beta [EOL] [EOL] distr = Beta ( alphas , betas ) [EOL] samples = distr . sample ( ) [EOL] [EOL] init_biases = [ inv_softplus ( alpha - START_TOL_MULTIPLE * TOL * alpha ) , inv_softplus ( beta - START_TOL_MULTIPLE * TOL * beta ) , ] [EOL] [EOL] alpha_hat , beta_hat = maximum_likelihood_estimate_sgd ( BetaOutput ( ) , samples , init_biases = init_biases , hybridize = hybridize , learning_rate = PositiveFloat ( [number] ) , num_epochs = PositiveInt ( [number] ) , ) [EOL] [EOL] print ( [string] , alpha_hat , [string] , beta_hat ) [EOL] assert ( np . abs ( alpha_hat - alpha ) < TOL * alpha ) , f" [string] { alpha } [string] { alpha_hat }" [EOL] assert ( np . abs ( beta_hat - beta ) < TOL * beta ) , f" [string] { beta } [string] { beta_hat }" [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [number] , [number] ) ] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) @ pytest . mark . parametrize ( [string] , [ [string] , [string] , [string] ] ) @ pytest . mark . parametrize ( [string] , [ [number] ] ) @ pytest . mark . parametrize ( [string] , [ [number] ] ) def test_inflated_beta_likelihood ( alpha , beta , hybridize , inflated_at , zero_probability , one_probability , ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] alphas = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + alpha [EOL] betas = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + beta [EOL] [EOL] zero_probabilities = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + zero_probability [EOL] one_probabilities = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + one_probability [EOL] if inflated_at == [string] : [EOL] distr = ZeroInflatedBeta ( alphas , betas , zero_probability = zero_probabilities ) [EOL] distr_output = ZeroInflatedBetaOutput ( ) [EOL] elif inflated_at == [string] : [EOL] distr = OneInflatedBeta ( alphas , betas , one_probability = one_probabilities ) [EOL] distr_output = OneInflatedBetaOutput ( ) [EOL] [EOL] else : [EOL] distr = ZeroAndOneInflatedBeta ( alphas , betas , zero_probability = zero_probabilities , one_probability = one_probabilities , ) [EOL] distr_output = ZeroAndOneInflatedBetaOutput ( ) [EOL] [EOL] samples = distr . sample ( ) [EOL] [EOL] init_biases = [ inv_softplus ( alpha - START_TOL_MULTIPLE * TOL * alpha ) , inv_softplus ( beta - START_TOL_MULTIPLE * TOL * beta ) , ] [EOL] [EOL] parameters = maximum_likelihood_estimate_sgd ( distr_output , samples , init_biases = init_biases , hybridize = hybridize , learning_rate = PositiveFloat ( [number] ) , num_epochs = PositiveInt ( [number] ) , ) [EOL] [EOL] if inflated_at == [string] : [EOL] alpha_hat , beta_hat , zero_probability_hat = parameters [EOL] [EOL] assert ( np . abs ( zero_probability_hat [ [number] ] - zero_probability ) < TOL * zero_probability ) , f" [string] { alpha } [string] { zero_probability_hat }" [EOL] [EOL] elif inflated_at == [string] : [EOL] alpha_hat , beta_hat , one_probability_hat = parameters [EOL] [EOL] assert ( np . abs ( one_probability_hat - one_probability ) < TOL * one_probability ) , f" [string] { one_probability } [string] { one_probability_hat }" [EOL] else : [EOL] ( alpha_hat , beta_hat , zero_probability_hat , one_probability_hat , ) = parameters [EOL] [EOL] assert ( np . abs ( zero_probability_hat - zero_probability ) < TOL * zero_probability ) , f" [string] { alpha } [string] { zero_probability_hat }" [EOL] assert ( np . abs ( one_probability_hat - one_probability ) < TOL * one_probability ) , f" [string] { one_probability } [string] { one_probability_hat }" [EOL] [EOL] assert ( np . abs ( alpha_hat - alpha ) < TOL * alpha ) , f" [string] { alpha } [string] { alpha_hat }" [EOL] assert ( np . abs ( beta_hat - beta ) < TOL * beta ) , f" [string] { beta } [string] { beta_hat }" [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [number] , [number] , [number] ) ] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_studentT_likelihood ( mu , sigma , nu , hybridize ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] mus = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + mu [EOL] sigmas = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + sigma [EOL] nus = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + nu [EOL] [EOL] distr = StudentT ( mus , sigmas , nus ) [EOL] samples = distr . sample ( ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] init_bias = [ mu - START_TOL_MULTIPLE * TOL * mu , inv_softplus ( sigma - START_TOL_MULTIPLE * TOL * sigma ) , inv_softplus ( nu - [number] ) , ] [EOL] [EOL] mu_hat , sigma_hat , nu_hat = maximum_likelihood_estimate_sgd ( StudentTOutput ( ) , samples , init_biases = init_bias , hybridize = hybridize , num_epochs = PositiveInt ( [number] ) , learning_rate = PositiveFloat ( [number] ) , ) [EOL] [EOL] assert ( np . abs ( mu_hat - mu ) < TOL * mu ) , f" [string] { mu } [string] { mu_hat }" [EOL] assert ( np . abs ( sigma_hat - sigma ) < TOL * sigma ) , f" [string] { sigma } [string] { sigma_hat }" [EOL] assert ( np . abs ( nu_hat - nu ) < TOL * nu ) , [string] % ( nu , nu_hat ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [number] , [number] ) ] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_gamma_likelihood ( alpha , beta , hybridize ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] alphas = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + alpha [EOL] betas = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + beta [EOL] [EOL] distr = Gamma ( alphas , betas ) [EOL] samples = distr . sample ( ) [EOL] [EOL] init_biases = [ inv_softplus ( alpha - START_TOL_MULTIPLE * TOL * alpha ) , inv_softplus ( beta - START_TOL_MULTIPLE * TOL * beta ) , ] [EOL] [EOL] alpha_hat , beta_hat = maximum_likelihood_estimate_sgd ( GammaOutput ( ) , samples , init_biases = init_biases , hybridize = hybridize , learning_rate = PositiveFloat ( [number] ) , num_epochs = PositiveInt ( [number] ) , ) [EOL] [EOL] assert ( np . abs ( alpha_hat - alpha ) < TOL * alpha ) , f" [string] { alpha } [string] { alpha_hat }" [EOL] assert ( np . abs ( beta_hat - beta ) < TOL * beta ) , f" [string] { beta } [string] { beta_hat }" [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [number] , [number] ) ] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_gaussian_likelihood ( mu , sigma , hybridize ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] mus = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + mu [EOL] sigmas = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + sigma [EOL] [EOL] distr = Gaussian ( mus , sigmas ) [EOL] samples = distr . sample ( ) [EOL] [EOL] init_biases = [ mu - START_TOL_MULTIPLE * TOL * mu , inv_softplus ( sigma - START_TOL_MULTIPLE * TOL * sigma ) , ] [EOL] [EOL] mu_hat , sigma_hat = maximum_likelihood_estimate_sgd ( GaussianOutput ( ) , samples , init_biases = init_biases , hybridize = hybridize , learning_rate = PositiveFloat ( [number] ) , num_epochs = PositiveInt ( [number] ) , ) [EOL] [EOL] assert ( np . abs ( mu_hat - mu ) < TOL * mu ) , f" [string] { mu } [string] { mu_hat }" [EOL] assert ( np . abs ( sigma_hat - sigma ) < TOL * sigma ) , f" [string] { sigma } [string] { sigma_hat }" [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_multivariate_gaussian ( hybridize ) : [EOL] num_samples = [number] [EOL] dim = [number] [EOL] [EOL] mu = np . arange ( [number] , dim ) / float ( dim ) [EOL] [EOL] L_diag = np . ones ( ( dim , ) ) [EOL] L_low = [number] * np . ones ( ( dim , dim ) ) * np . tri ( dim , k = - [number] ) [EOL] L = np . diag ( L_diag ) + L_low [EOL] Sigma = L . dot ( L . transpose ( ) ) [EOL] [EOL] distr = MultivariateGaussian ( mu = mx . nd . array ( mu ) , L = mx . nd . array ( L ) ) [EOL] [EOL] samples = distr . sample ( num_samples ) [EOL] [EOL] mu_hat , L_hat = maximum_likelihood_estimate_sgd ( MultivariateGaussianOutput ( dim = dim ) , samples , init_biases = None , hybridize = hybridize , learning_rate = PositiveFloat ( [number] ) , num_epochs = PositiveInt ( [number] ) , ) [EOL] [EOL] distr = MultivariateGaussian ( mu = mx . nd . array ( [ mu_hat ] ) , L = mx . nd . array ( [ L_hat ] ) ) [EOL] [EOL] Sigma_hat = distr . variance [ [number] ] . asnumpy ( ) [EOL] [EOL] assert np . allclose ( mu_hat , mu , atol = [number] , rtol = [number] ) , f" [string] { mu } [string] { mu_hat }" [EOL] assert np . allclose ( Sigma_hat , Sigma , atol = [number] , rtol = [number] ) , f" [string] { Sigma } [string] { Sigma_hat }" [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_dirichlet ( hybridize ) : [EOL] num_samples = [number] [EOL] dim = [number] [EOL] [EOL] alpha = np . array ( [ [number] , [number] , [number] ] ) [EOL] [EOL] distr = Dirichlet ( alpha = mx . nd . array ( alpha ) ) [EOL] cov = distr . variance . asnumpy ( ) [EOL] [EOL] samples = distr . sample ( num_samples ) [EOL] [EOL] alpha_hat = maximum_likelihood_estimate_sgd ( DirichletOutput ( dim = dim ) , samples , init_biases = None , hybridize = hybridize , learning_rate = PositiveFloat ( [number] ) , num_epochs = PositiveInt ( [number] ) , ) [EOL] [EOL] distr = Dirichlet ( alpha = mx . nd . array ( alpha_hat ) ) [EOL] [EOL] cov_hat = distr . variance . asnumpy ( ) [EOL] [EOL] assert np . allclose ( alpha_hat , alpha , atol = [number] , rtol = [number] ) , f" [string] { alpha } [string] { alpha_hat }" [EOL] assert np . allclose ( cov_hat , cov , atol = [number] , rtol = [number] ) , f" [string] { cov } [string] { cov_hat }" [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_dirichlet_multinomial ( hybridize ) : [EOL] num_samples = [number] [EOL] dim = [number] [EOL] n_trials = [number] [EOL] [EOL] alpha = np . array ( [ [number] , [number] , [number] ] ) [EOL] [EOL] distr = DirichletMultinomial ( dim = [number] , n_trials = n_trials , alpha = mx . nd . array ( alpha ) ) [EOL] cov = distr . variance . asnumpy ( ) [EOL] [EOL] samples = distr . sample ( num_samples ) [EOL] [EOL] alpha_hat = maximum_likelihood_estimate_sgd ( DirichletMultinomialOutput ( dim = dim , n_trials = n_trials ) , samples , init_biases = None , hybridize = hybridize , learning_rate = PositiveFloat ( [number] ) , num_epochs = PositiveInt ( [number] ) , ) [EOL] [EOL] distr = DirichletMultinomial ( dim = [number] , n_trials = n_trials , alpha = mx . nd . array ( alpha_hat ) ) [EOL] [EOL] cov_hat = distr . variance . asnumpy ( ) [EOL] [EOL] assert np . allclose ( alpha_hat , alpha , atol = [number] , rtol = [number] ) , f" [string] { alpha } [string] { alpha_hat }" [EOL] assert np . allclose ( cov_hat , cov , atol = [number] , rtol = [number] ) , f" [string] { cov } [string] { cov_hat }" [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_lowrank_multivariate_gaussian ( hybridize ) : [EOL] num_samples = [number] [EOL] dim = [number] [EOL] rank = [number] [EOL] [EOL] mu = np . arange ( [number] , dim ) / float ( dim ) [EOL] D = np . eye ( dim ) * ( np . arange ( dim ) / dim + [number] ) [EOL] W = np . sqrt ( np . ones ( ( dim , rank ) ) * [number] ) [EOL] Sigma = D + W . dot ( W . transpose ( ) ) [EOL] [EOL] distr = LowrankMultivariateGaussian ( mu = mx . nd . array ( [ mu ] ) , D = mx . nd . array ( [ np . diag ( D ) ] ) , W = mx . nd . array ( [ W ] ) , dim = dim , rank = rank , ) [EOL] [EOL] assert np . allclose ( distr . variance [ [number] ] . asnumpy ( ) , Sigma , atol = [number] , rtol = [number] ) , f" [string] { Sigma } [string] { distr . variance [ [number] ] }" [EOL] [EOL] samples = distr . sample ( num_samples ) . squeeze ( ) . asnumpy ( ) [EOL] [EOL] mu_hat , D_hat , W_hat = maximum_likelihood_estimate_sgd ( LowrankMultivariateGaussianOutput ( dim = dim , rank = rank , sigma_init = [number] , sigma_minimum = [number] ) , samples , learning_rate = PositiveFloat ( [number] ) , num_epochs = PositiveInt ( [number] ) , init_biases = None , hybridize = hybridize , ) [EOL] [EOL] distr = LowrankMultivariateGaussian ( dim = dim , rank = rank , mu = mx . nd . array ( [ mu_hat ] ) , D = mx . nd . array ( [ D_hat ] ) , W = mx . nd . array ( [ W_hat ] ) , ) [EOL] [EOL] Sigma_hat = distr . variance . asnumpy ( ) [EOL] [EOL] assert np . allclose ( mu_hat , mu , atol = [number] , rtol = [number] ) , f" [string] { mu } [string] { mu_hat }" [EOL] [EOL] assert np . allclose ( Sigma_hat , Sigma , atol = [number] , rtol = [number] ) , f" [string] { Sigma } [string] { Sigma_hat }" [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ [number] ] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_deterministic_l2 ( mu , hybridize ) : [EOL] [docstring] [EOL] [comment] [EOL] mu = mu [EOL] mus = mx . nd . zeros ( NUM_SAMPLES ) + mu [EOL] [EOL] deterministic_distr = Gaussian ( mu = mus , sigma = [number] * mx . nd . ones_like ( mus ) ) [EOL] samples = deterministic_distr . sample ( ) [EOL] [EOL] class GaussianFixedVarianceOutput ( GaussianOutput ) : [EOL] @ classmethod def domain_map ( cls , F , mu , sigma ) : [EOL] sigma = [number] * F . ones_like ( sigma ) [EOL] return mu . squeeze ( axis = - [number] ) , sigma . squeeze ( axis = - [number] ) [EOL] [EOL] mu_hat , _ = maximum_likelihood_estimate_sgd ( GaussianFixedVarianceOutput ( ) , samples , init_biases = [ [number] * mu , [number] ] , hybridize = hybridize , num_epochs = PositiveInt ( [number] ) , ) [EOL] [EOL] assert ( np . abs ( mu_hat - mu ) < TOL * mu ) , f" [string] { mu } [string] { mu_hat }" [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ [number] ] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_deterministic_l1 ( mu , hybridize ) : [EOL] [docstring] [EOL] [comment] [EOL] mu = mu [EOL] mus = mx . nd . zeros ( NUM_SAMPLES ) + mu [EOL] [EOL] class LaplaceFixedVarianceOutput ( LaplaceOutput ) : [EOL] @ classmethod def domain_map ( cls , F , mu , b ) : [EOL] b = [number] * F . ones_like ( b ) [EOL] return mu . squeeze ( axis = - [number] ) , b . squeeze ( axis = - [number] ) [EOL] [EOL] deterministic_distr = Laplace ( mu = mus , b = [number] * mx . nd . ones_like ( mus ) ) [EOL] samples = deterministic_distr . sample ( ) [EOL] [EOL] mu_hat , _ = maximum_likelihood_estimate_sgd ( LaplaceFixedVarianceOutput ( ) , samples , init_biases = [ [number] * mu , [number] ] , learning_rate = PositiveFloat ( [number] ) , hybridize = hybridize , ) [EOL] [EOL] assert ( np . abs ( mu_hat - mu ) < TOL * mu ) , f" [string] { mu } [string] { mu_hat }" [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [number] , [number] ) ] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_neg_binomial ( mu_alpha , hybridize ) : [EOL] [docstring] [EOL] [comment] [EOL] mu , alpha = mu_alpha [EOL] [EOL] [comment] [EOL] mus = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + mu [EOL] alphas = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + alpha [EOL] [EOL] neg_bin_distr = NegativeBinomial ( mu = mus , alpha = alphas ) [EOL] samples = neg_bin_distr . sample ( ) [EOL] [EOL] init_biases = [ inv_softplus ( mu - START_TOL_MULTIPLE * TOL * mu ) , inv_softplus ( alpha + START_TOL_MULTIPLE * TOL * alpha ) , ] [EOL] [EOL] mu_hat , alpha_hat = maximum_likelihood_estimate_sgd ( NegativeBinomialOutput ( ) , samples , hybridize = hybridize , init_biases = init_biases , num_epochs = PositiveInt ( [number] ) , ) [EOL] [EOL] assert ( np . abs ( mu_hat - mu ) < TOL * mu ) , f" [string] { mu } [string] { mu_hat }" [EOL] assert ( np . abs ( alpha_hat - alpha ) < TOL * alpha ) , f" [string] { alpha } [string] { alpha_hat }" [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [number] , [number] ) ] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_laplace ( mu_b , hybridize ) : [EOL] [docstring] [EOL] [comment] [EOL] mu , b = mu_b [EOL] [EOL] [comment] [EOL] mus = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + mu [EOL] bs = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + b [EOL] [EOL] laplace_distr = Laplace ( mu = mus , b = bs ) [EOL] samples = laplace_distr . sample ( ) [EOL] [EOL] init_biases = [ mu - START_TOL_MULTIPLE * TOL * mu , inv_softplus ( b + START_TOL_MULTIPLE * TOL * b ) , ] [EOL] [EOL] mu_hat , b_hat = maximum_likelihood_estimate_sgd ( LaplaceOutput ( ) , samples , hybridize = hybridize , init_biases = init_biases ) [EOL] [EOL] assert ( np . abs ( mu_hat - mu ) < TOL * mu ) , f" [string] { mu } [string] { mu_hat }" [EOL] assert ( np . abs ( b_hat - b ) < TOL * b ) , f" [string] { b } [string] { b_hat }" [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [number] , np . array ( [ [number] , [number] , [number] , [number] ] ) , np . array ( [ [number] , [number] , [number] , [number] ] ) ) ] , ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_piecewise_linear ( gamma , slopes , knot_spacings , hybridize , ) : [EOL] [docstring] [EOL] num_samples = [number] [comment] [EOL] [EOL] gammas = mx . nd . zeros ( ( num_samples , ) ) + gamma [EOL] slopess = mx . nd . zeros ( ( num_samples , len ( slopes ) ) ) + mx . nd . array ( slopes ) [EOL] knot_spacingss = mx . nd . zeros ( ( num_samples , len ( knot_spacings ) ) ) + mx . nd . array ( knot_spacings ) [EOL] [EOL] pwl_sqf = PiecewiseLinear ( gammas , slopess , knot_spacingss ) [EOL] [EOL] samples = pwl_sqf . sample ( ) [EOL] [EOL] [comment] [EOL] gamma_init = gamma - START_TOL_MULTIPLE * TOL * gamma [EOL] slopes_init = slopes - START_TOL_MULTIPLE * TOL * slopes [EOL] knot_spacings_init = knot_spacings [EOL] [comment] [EOL] mid = len ( slopes ) // [number] [EOL] knot_spacings_init [ : mid ] = ( knot_spacings [ : mid ] - START_TOL_MULTIPLE * TOL * knot_spacings [ : mid ] ) [EOL] knot_spacings_init [ mid : ] = ( knot_spacings [ mid : ] + START_TOL_MULTIPLE * TOL * knot_spacings [ mid : ] ) [EOL] [EOL] init_biases = [ gamma_init , slopes_init , knot_spacings_init ] [EOL] [EOL] [comment] [EOL] gamma_hat , slopes_hat , knot_spacings_hat = maximum_likelihood_estimate_sgd ( PiecewiseLinearOutput ( len ( slopes ) ) , samples , init_biases = init_biases , hybridize = hybridize , learning_rate = PositiveFloat ( [number] ) , num_epochs = PositiveInt ( [number] ) , ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] quantile_levels = np . arange ( [number] , [number] , [number] ) [EOL] [EOL] [comment] [EOL] pwl_sqf_hat = PiecewiseLinear ( mx . nd . array ( gamma_hat ) , mx . nd . array ( slopes_hat ) . expand_dims ( axis = [number] ) , mx . nd . array ( knot_spacings_hat ) . expand_dims ( axis = [number] ) , ) [EOL] [EOL] [comment] [EOL] quantiles_hat = np . squeeze ( pwl_sqf_hat . quantile_internal ( mx . nd . array ( quantile_levels ) . expand_dims ( axis = [number] ) , axis = [number] ) . asnumpy ( ) ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] quantiles = np . squeeze ( pwl_sqf . quantile_internal ( mx . nd . array ( quantile_levels ) . expand_dims ( axis = [number] ) . repeat ( axis = [number] , repeats = num_samples ) , axis = [number] , ) . asnumpy ( ) [ [number] , : ] ) [EOL] [EOL] for ix , ( quantile , quantile_hat ) in enumerate ( zip ( quantiles , quantiles_hat ) ) : [EOL] assert np . abs ( quantile_hat - quantile ) < TOL * quantile , ( f" [string] { quantile_levels [ ix ] } [string] " f" [string] " f" [string] { quantile } [string] { quantile_hat }" ) [EOL] [EOL] [EOL] @ pytest . mark . skip ( [string] ) @ pytest . mark . parametrize ( [string] , [ ( [number] , [number] ) ] ) @ pytest . mark . parametrize ( [string] , [ ( - [number] , [number] ) ] ) @ pytest . mark . parametrize ( [string] , [ True ] ) def test_box_cox_tranform ( lam_1 , lam_2 , mu , sigma , hybridize ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] lamdas_1 = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + lam_1 [EOL] lamdas_2 = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + lam_2 [EOL] transform = InverseBoxCoxTransform ( lamdas_1 , lamdas_2 ) [EOL] [EOL] mus = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + mu [EOL] sigmas = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + sigma [EOL] gausian_distr = Gaussian ( mus , sigmas ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] trans_distr = TransformedDistribution ( gausian_distr , [ transform ] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] samples = trans_distr . sample ( ) [EOL] [EOL] init_biases = [ mu - START_TOL_MULTIPLE * TOL * mu , inv_softplus ( sigma - START_TOL_MULTIPLE * TOL * sigma ) , lam_1 - START_TOL_MULTIPLE * TOL * lam_1 , inv_softplus ( lam_2 - START_TOL_MULTIPLE * TOL * lam_2 ) , ] [EOL] [EOL] mu_hat , sigma_hat , lam_1_hat , lam_2_hat = maximum_likelihood_estimate_sgd ( TransformedDistributionOutput ( GaussianOutput ( ) , InverseBoxCoxTransformOutput ( lb_obs = lam_2 , fix_lambda_2 = True ) , ) , samples , init_biases = init_biases , hybridize = hybridize , learning_rate = PositiveFloat ( [number] ) , num_epochs = PositiveInt ( [number] ) , ) [EOL] [EOL] assert ( np . abs ( lam_1_hat - lam_1 ) < TOL * lam_1 ) , f" [string] { lam_1 } [string] { lam_1_hat }" [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] assert np . abs ( mu_hat - mu ) < TOL * np . abs ( mu ) , f" [string] { mu } [string] { mu_hat }" [EOL] assert ( np . abs ( sigma_hat - sigma ) < TOL * sigma ) , f" [string] { sigma } [string] { sigma_hat }" [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ [number] ] ) @ pytest . mark . parametrize ( [string] , [ np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] ] ) ] ) [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] @ pytest . mark . parametrize ( [string] , [ False ] ) def test_binned_likelihood ( num_bins , bin_probabilites , hybridize ) : [EOL] [docstring] [EOL] [EOL] bin_prob = mx . nd . array ( bin_probabilites ) [EOL] bin_center = mx . nd . array ( np . logspace ( - [number] , [number] , num_bins ) ) [EOL] [EOL] [comment] [EOL] bin_probs = mx . nd . zeros ( ( NUM_SAMPLES , num_bins ) ) + bin_prob [EOL] bin_centers = mx . nd . zeros ( ( NUM_SAMPLES , num_bins ) ) + bin_center [EOL] [EOL] distr = Binned ( bin_probs . log ( ) , bin_centers ) [EOL] samples = distr . sample ( ) [EOL] [EOL] [comment] [EOL] bin_prob_init = mx . nd . random_uniform ( [number] - TOL , [number] + TOL , num_bins ) * bin_prob [EOL] bin_prob_init = bin_prob_init / bin_prob_init . sum ( ) [EOL] [EOL] init_biases = [ bin_prob_init ] [EOL] [EOL] bin_log_prob_hat , _ = maximum_likelihood_estimate_sgd ( BinnedOutput ( bin_center ) , samples , init_biases = init_biases , hybridize = hybridize , learning_rate = PositiveFloat ( [number] ) , num_epochs = PositiveInt ( [number] ) , ) [EOL] [EOL] bin_prob_hat = np . exp ( bin_log_prob_hat ) [EOL] [EOL] assert all ( mx . nd . abs ( mx . nd . array ( bin_prob_hat ) - bin_prob ) < TOL * bin_prob ) , f" [string] { bin_prob } [string] { bin_prob_hat }" [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ [number] ] ) @ pytest . mark . parametrize ( [string] , [ np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] ] ) ] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_categorical_likelihood ( num_cats , cat_probs , hybridize ) : [EOL] [docstring] [EOL] cat_prob = mx . nd . array ( cat_probs ) [EOL] cat_probs = mx . nd . zeros ( ( NUM_SAMPLES , num_cats ) ) + cat_prob [EOL] [EOL] distr = Categorical ( cat_probs . log ( ) ) [EOL] samples = distr . sample ( ) [EOL] [EOL] cat_prob_init = mx . nd . random_uniform ( [number] - TOL , [number] + TOL , num_cats ) * cat_prob [EOL] cat_prob_init = cat_prob_init / cat_prob_init . sum ( ) [EOL] [EOL] init_biases = [ cat_prob_init ] [EOL] [EOL] cat_log_prob_hat = maximum_likelihood_estimate_sgd ( CategoricalOutput ( num_cats ) , samples , init_biases = init_biases , hybridize = hybridize , learning_rate = PositiveFloat ( [number] ) , num_epochs = PositiveInt ( [number] ) , ) [EOL] cat_prob_hat = np . exp ( cat_log_prob_hat ) [EOL] [EOL] prob_deviation = np . abs ( cat_prob_hat - cat_prob . asnumpy ( ) ) . flatten ( ) [EOL] tolerance = ( TOL * cat_prob . asnumpy ( ) ) . flatten ( ) [EOL] [EOL] assert np . all ( np . less ( prob_deviation , tolerance ) ) , f" [string] { cat_prob } [string] { cat_prob_hat }" [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ [number] ] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_poisson_likelihood ( rate , hybridize ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] rates = mx . nd . zeros ( NUM_SAMPLES ) + rate [EOL] [EOL] distr = Poisson ( rates ) [EOL] samples = distr . sample ( ) [EOL] [EOL] init_biases = [ inv_softplus ( rate - START_TOL_MULTIPLE * TOL * rate ) ] [EOL] [EOL] rate_hat = maximum_likelihood_estimate_sgd ( PoissonOutput ( ) , samples , init_biases = init_biases , hybridize = hybridize , learning_rate = PositiveFloat ( [number] ) , num_epochs = PositiveInt ( [number] ) , ) [EOL] [EOL] print ( [string] , rate_hat ) [EOL] assert ( np . abs ( rate_hat [ [number] ] - rate ) < TOL * rate ) , f" [string] { rate } [string] { rate_hat }" [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [number] , [number] ) ] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_logit_normal_likelihood ( mu , sigma , hybridize ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] mus = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + mu [EOL] sigmas = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + sigma [EOL] [EOL] distr = LogitNormal ( mus , sigmas ) [EOL] samples = distr . sample ( ) [EOL] [EOL] init_biases = [ mu - START_TOL_MULTIPLE * TOL * mu , inv_softplus ( sigma - START_TOL_MULTIPLE * TOL * sigma ) , ] [EOL] [EOL] mu_hat , sigma_hat = maximum_likelihood_estimate_sgd ( LogitNormalOutput ( ) , samples , init_biases = init_biases , hybridize = hybridize , learning_rate = PositiveFloat ( [number] ) , num_epochs = PositiveInt ( [number] ) , ) [EOL] [EOL] assert ( np . abs ( mu_hat - mu ) < TOL * mu ) , f" [string] { mu } [string] { mu_hat }" [EOL] assert ( np . abs ( sigma_hat - sigma ) < TOL * sigma ) , f" [string] { sigma } [string] { sigma_hat }" [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [number] , [number] ) ] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_loglogistic_likelihood ( mu , sigma , hybridize ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] mus = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + mu [EOL] sigmas = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + sigma [EOL] [EOL] distr = Loglogistic ( mus , sigmas ) [EOL] samples = distr . sample ( ) [EOL] [EOL] init_biases = [ mu - START_TOL_MULTIPLE * TOL * mu , inv_softplus ( sigma - START_TOL_MULTIPLE * TOL * sigma ) , ] [EOL] [EOL] mu_hat , sigma_hat = maximum_likelihood_estimate_sgd ( LoglogisticOutput ( ) , samples , init_biases = init_biases , hybridize = hybridize , learning_rate = PositiveFloat ( [number] ) , num_epochs = PositiveInt ( [number] ) , ) [EOL] [EOL] print ( [string] , mu_hat , [string] , sigma_hat ) [EOL] assert ( np . abs ( mu_hat - mu ) < TOL * mu ) , f" [string] { mu } [string] { mu_hat }" [EOL] assert ( np . abs ( sigma_hat - sigma ) < TOL * sigma ) , f" [string] { sigma } [string] { sigma_hat }" [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [number] , [number] ) ] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_weibull_likelihood ( rate , shape , hybridize ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] rates = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + rate [EOL] shapes = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + shape [EOL] [EOL] distr = Weibull ( rates , shapes ) [EOL] samples = distr . sample ( ) [EOL] [EOL] init_biases = [ inv_softplus ( rate - START_TOL_MULTIPLE * TOL * rate ) , inv_softplus ( shape - START_TOL_MULTIPLE * TOL * shape ) , ] [EOL] [EOL] rate_hat , shape_hat = maximum_likelihood_estimate_sgd ( WeibullOutput ( ) , samples , init_biases = init_biases , hybridize = hybridize , learning_rate = PositiveFloat ( [number] ) , num_epochs = PositiveInt ( [number] ) , ) [EOL] [EOL] print ( [string] , rate_hat , [string] , shape_hat ) [EOL] assert ( np . abs ( rate_hat - rate ) < TOL * rate ) , f" [string] { rate } [string] { rate_hat }" [EOL] assert ( np . abs ( shape_hat - shape ) < TOL * shape ) , f" [string] { shape } [string] { shape_hat }" [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [number] / [number] , [number] ) ] ) @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_genpareto_likelihood ( xi , beta , hybridize ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] xis = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + xi [EOL] betas = mx . nd . zeros ( ( NUM_SAMPLES , ) ) + beta [EOL] [EOL] distr = GenPareto ( xis , betas ) [EOL] samples = distr . sample ( ) [EOL] [EOL] init_biases = [ inv_softplus ( xi - START_TOL_MULTIPLE * TOL * xi ) , inv_softplus ( beta - START_TOL_MULTIPLE * TOL * beta ) , ] [EOL] [EOL] xi_hat , beta_hat = maximum_likelihood_estimate_sgd ( GenParetoOutput ( ) , samples , init_biases = init_biases , hybridize = hybridize , learning_rate = PositiveFloat ( [number] ) , num_epochs = PositiveInt ( [number] ) , ) [EOL] [EOL] print ( [string] , xi_hat , [string] , beta_hat ) [EOL] assert ( np . abs ( xi_hat - xi ) < TOL * xi ) , f" [string] { xi } [string] { xi_hat }" [EOL] assert ( np . abs ( beta_hat - beta ) < TOL * beta ) , f" [string] { beta } [string] { beta_hat }" [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import builtins [EOL] import mxnet as mx [EOL] import numpy as np [EOL] import pytest [EOL] from flaky import flaky [EOL] [EOL] [comment] [EOL] from gluonts . mx . distribution import ( Uniform , StudentT , NegativeBinomial , Laplace , Gaussian , Gamma , GenPareto , Beta , MultivariateGaussian , Poisson , PiecewiseLinear , Binned , TransformedDistribution , Dirichlet , DirichletMultinomial , Categorical , ZeroAndOneInflatedBeta , ) [EOL] from gluonts . core . serde import dump_json , load_json , dump_code , load_code [EOL] from gluonts . model . tpp . distribution import Loglogistic , Weibull [EOL] [EOL] from gluonts . testutil import empirical_cdf [EOL] [EOL] [EOL] test_cases = [ ( Gaussian , { [string] : mx . nd . array ( [ [number] , - [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , } , ) , ( Gamma , { [string] : mx . nd . array ( [ [number] , [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) } , ) , ( Beta , { [string] : mx . nd . array ( [ [number] , [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) } , ) , ( Laplace , { [string] : mx . nd . array ( [ [number] , - [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) } , ) , ( StudentT , { [string] : mx . nd . array ( [ [number] , - [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , } , ) , ( NegativeBinomial , { [string] : mx . nd . array ( [ [number] , [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) } , ) , ( Uniform , { [string] : mx . nd . array ( [ [number] , - [number] ] ) , [string] : mx . nd . array ( [ [number] , - [number] ] ) , } , ) , ( Binned , { [string] : mx . nd . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ] ) . log ( ) . repeat ( axis = [number] , repeats = [number] ) , [string] : mx . nd . array ( [ [ - [number] , - [number] , - [number] , - [number] , [number] , [number] , [number] ] ] ) . repeat ( axis = [number] , repeats = [number] ) , } , ) , ( Binned , { [string] : mx . nd . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ] ) . log ( ) . repeat ( axis = [number] , repeats = [number] ) , [string] : mx . nd . array ( [ [ - [number] , - [number] , - [number] , - [number] , [number] , [number] , [number] ] ] ) . repeat ( axis = [number] , repeats = [number] ) , [string] : [number] , } , ) , ( Categorical , { [string] : mx . nd . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ] ) . log ( ) . repeat ( axis = [number] , repeats = [number] ) , } , ) , ( Poisson , { [string] : mx . nd . array ( [ [number] , [number] ] ) } ) , ( Loglogistic , { [string] : mx . nd . array ( [ - [number] , [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) } , ) , ( Weibull , { [string] : mx . nd . array ( [ [number] , [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) } , ) , ( GenPareto , { [string] : mx . nd . array ( [ [number] / [number] , [number] / [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] / [number] ] ) , } , ) , ] [EOL] [EOL] [EOL] serialize_fn_list = [ lambda x : x , lambda x : load_json ( dump_json ( x ) ) ] [EOL] [EOL] [EOL] DISTRIBUTIONS_WITH_CDF = [ Gaussian , Uniform , Laplace , Binned , Loglogistic , Weibull , ] [EOL] DISTRIBUTIONS_WITH_QUANTILE_FUNCTION = [ Gaussian , Uniform , Laplace , Binned ] [EOL] DISTRIBUTIONS_WITHOUT_STDDEV = [ Loglogistic , Weibull ] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , test_cases ) @ pytest . mark . parametrize ( [string] , serialize_fn_list ) def test_sampling ( distr_class , params , serialize_fn ) : [EOL] distr = distr_class ( ** params ) [EOL] distr = serialize_fn ( distr ) [EOL] samples = distr . sample ( ) [EOL] assert samples . shape == ( [number] , ) [EOL] num_samples = [number] [EOL] samples = distr . sample ( num_samples ) [EOL] assert samples . shape == ( num_samples , [number] ) [EOL] [EOL] np_samples = samples . asnumpy ( ) [EOL] [comment] [EOL] [comment] [EOL] np_samples = np_samples . astype ( np . float64 ) [EOL] [EOL] assert np . isfinite ( np_samples ) . all ( ) [EOL] assert np . allclose ( np_samples . mean ( axis = [number] ) , distr . mean . asnumpy ( ) , atol = [number] , rtol = [number] ) [EOL] [EOL] if distr_class not in DISTRIBUTIONS_WITHOUT_STDDEV : [EOL] emp_std = np_samples . std ( axis = [number] ) [EOL] assert np . allclose ( emp_std , distr . stddev . asnumpy ( ) , atol = [number] , rtol = [number] ) [EOL] [EOL] if distr_class in DISTRIBUTIONS_WITH_CDF : [EOL] emp_cdf , edges = empirical_cdf ( np_samples ) [EOL] calc_cdf = distr . cdf ( mx . nd . array ( edges ) ) . asnumpy ( ) [EOL] assert np . allclose ( calc_cdf [ [number] : , : ] , emp_cdf , atol = [number] ) [EOL] [EOL] if distr_class in DISTRIBUTIONS_WITH_QUANTILE_FUNCTION : [EOL] levels = np . linspace ( [number] , [number] - [number] , [number] ) [EOL] emp_qfunc = np . percentile ( np_samples , levels * [number] , axis = [number] ) [EOL] calc_qfunc = distr . quantile ( mx . nd . array ( levels ) ) . asnumpy ( ) [EOL] assert np . allclose ( calc_qfunc , emp_qfunc , rtol = [number] ) [EOL] [EOL] [EOL] test_cases_multivariate = [ ( MultivariateGaussian , { [string] : mx . nd . array ( [ [number] , - [number] ] ) , [string] : mx . nd . array ( [ [ [number] , [number] ] , [ [number] , [number] ] ] ) , } , [number] , ) , ( Dirichlet , { [string] : mx . nd . array ( [ [number] , [number] , [number] ] ) } , [number] ) , ( DirichletMultinomial , { [string] : [number] , [string] : [number] , [string] : mx . nd . array ( [ [number] , [number] , [number] ] ) } , [number] , ) , ] [EOL] [EOL] [EOL] @ flaky ( min_passes = [number] , max_runs = [number] ) @ pytest . mark . parametrize ( [string] , test_cases_multivariate ) @ pytest . mark . parametrize ( [string] , serialize_fn_list ) def test_multivariate_sampling ( distr , params , dim , serialize_fn ) : [EOL] distr = distr ( ** params ) [EOL] distr = serialize_fn ( distr ) [EOL] samples = distr . sample ( ) [EOL] assert samples . shape == ( dim , ) [EOL] samples = distr . sample ( num_samples = [number] ) [EOL] assert samples . shape == ( [number] , dim ) [EOL] num_samples = [number] [EOL] samples = distr . sample ( num_samples ) [EOL] assert samples . shape == ( num_samples , dim ) [EOL] [EOL] np_samples = samples . asnumpy ( ) [EOL] [EOL] assert np . allclose ( np_samples . mean ( axis = [number] ) , distr . mean . asnumpy ( ) , atol = [number] , rtol = [number] ) [EOL] [EOL] assert np . allclose ( np . cov ( np_samples . transpose ( ) ) , distr . variance . asnumpy ( ) , atol = [number] , rtol = [number] , ) [EOL] [EOL] [EOL] test_cases_pwl_sqf = [ ( PiecewiseLinear , { [string] : mx . nd . array ( [ [number] ] ) . repeat ( axis = [number] , repeats = [number] ) , [string] : mx . nd . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] ] ] ) . repeat ( axis = [number] , repeats = [number] ) , [string] : mx . nd . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] ] ] ) . repeat ( axis = [number] , repeats = [number] ) , } , ) ] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , test_cases_pwl_sqf ) @ pytest . mark . parametrize ( [string] , serialize_fn_list ) def test_piecewise_linear_sampling ( distr , params , serialize_fn ) : [EOL] distr = distr ( ** params ) [EOL] distr = serialize_fn ( distr ) [EOL] samples = distr . sample ( ) [EOL] assert samples . shape == ( [number] , ) [EOL] num_samples = [number] [EOL] samples = distr . sample ( num_samples ) [EOL] assert samples . shape == ( num_samples , [number] ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [number] , [number] ) , ( [number] , [number] ) ] ) @ pytest . mark . parametrize ( [string] , [ ( [number] , [number] ) ] ) def test_inflated_beta_sampling ( alpha , beta , zero_probability , one_probability ) : [EOL] distr = ZeroAndOneInflatedBeta ( alpha = mx . nd . array ( [ alpha ] ) , beta = mx . nd . array ( [ beta ] ) , zero_probability = mx . nd . array ( [ zero_probability ] ) , one_probability = mx . nd . array ( [ one_probability ] ) , ) [EOL] samples = distr . sample ( ) [EOL] assert samples . shape == ( [number] , ) [EOL] num_samples = [number] [EOL] samples = distr . sample ( num_samples ) [EOL] assert samples . shape == ( num_samples , [number] ) [EOL] [EOL] category = np . random . choice ( [ [number] , [number] , [number] ] , p = [ zero_probability , one_probability , [number] - zero_probability - one_probability , ] , size = num_samples , ) [EOL] samples_numpy = np . random . beta ( a = alpha , b = beta , size = num_samples ) [EOL] samples_numpy [ category == [number] ] = [number] [EOL] samples_numpy [ category == [number] ] = [number] [EOL] assert np . allclose ( np . histogram ( samples_numpy ) [ [number] ] , np . histogram ( samples . asnumpy ( ) ) [ [number] ] , rtol = [number] , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import numpy [EOL] import mxnet . ndarray as nd [EOL] import numpy as np [EOL] import pytest [EOL] [EOL] [comment] [EOL] from gluonts . mx . distribution import Uniform [EOL] from gluonts . mx . distribution . transformed_distribution import ( TransformedDistribution , ) [EOL] from gluonts . mx . distribution import bijection [EOL] from gluonts . core . serde import dump_json , load_json [EOL] [EOL] [EOL] serialize_fn_list = [ lambda x : x , lambda x : load_json ( dump_json ( x ) ) ] [EOL] [EOL] [EOL] def exp_cdf ( x ) : [EOL] return [number] - np . exp ( - x ) [EOL] [EOL] [EOL] def exp_quantile ( level ) : [EOL] return - np . log ( [number] - level ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , serialize_fn_list ) def test_transformed_distribution ( serialize_fn ) : [EOL] zero = nd . zeros ( [number] ) [EOL] one = nd . ones ( [number] ) [EOL] [EOL] [comment] [EOL] exponential = TransformedDistribution ( Uniform ( zero , one ) , [ bijection . log , bijection . AffineTransformation ( scale = - [number] * one ) ] , ) [EOL] exponential = serialize_fn ( exponential ) [EOL] [EOL] [comment] [EOL] assert exponential . log_prob ( [number] * one ) . asscalar ( ) == - [number] [EOL] assert exponential . log_prob ( [number] * one ) . asscalar ( ) == - [number] [EOL] [EOL] v = np . linspace ( [number] , [number] , [number] ) [EOL] assert np . allclose ( exponential . cdf ( nd . array ( v ) ) . asnumpy ( ) , exp_cdf ( v ) ) [EOL] [EOL] level = np . linspace ( [number] , [number] - [number] , [number] ) [EOL] [EOL] qs_calc = exponential . quantile ( nd . array ( level ) ) . asnumpy ( ) [ : , [number] ] [EOL] qs_theo = exp_quantile ( level ) [EOL] assert np . allclose ( qs_calc , qs_theo , atol = [number] ) [EOL] [EOL] [comment] [EOL] uniform = TransformedDistribution ( exponential , [ bijection . AffineTransformation ( scale = - [number] * one ) , bijection . log . inverse_bijection ( ) , bijection . AffineTransformation ( loc = one , scale = - [number] * one ) , ] , ) [EOL] uniform = serialize_fn ( uniform ) [EOL] [comment] [EOL] assert uniform . log_prob ( [number] * one ) . asscalar ( ) == [number] [EOL] assert uniform . log_prob ( [number] * one ) . asscalar ( ) == [number] [EOL] [EOL] v = np . linspace ( [number] , [number] , [number] ) [EOL] assert np . allclose ( uniform . cdf ( nd . array ( v ) ) . asnumpy ( ) , v ) [EOL] [EOL] qs_calc = uniform . quantile ( nd . array ( level ) ) . asnumpy ( ) [ : , [number] ] [EOL] assert np . allclose ( qs_calc , level , atol = [number] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import mxnet as mx [EOL] import numpy as np [EOL] import pytest [EOL] [EOL] [comment] [EOL] from gluonts . mx . distribution import ( Uniform , StudentT , NegativeBinomial , Laplace , Gaussian , Gamma , GenPareto , Beta , MultivariateGaussian , PiecewiseLinear , Poisson , Binned , TransformedDistribution , Categorical , ZeroInflatedBeta , OneInflatedBeta , ZeroAndOneInflatedBeta , ) [EOL] [EOL] from gluonts . core . serde import load_json , dump_json [EOL] [EOL] test_cases = [ ( Gaussian , { [string] : mx . nd . array ( [ [number] , - [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , } , ) , ( Gamma , { [string] : mx . nd . array ( [ [number] , [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) } , ) , ( GenPareto , { [string] : mx . nd . array ( [ [number] / [number] , [number] / [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , } , ) , ( Beta , { [string] : mx . nd . array ( [ [number] , [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) } , ) , ( Laplace , { [string] : mx . nd . array ( [ [number] , - [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) } , ) , ( StudentT , { [string] : mx . nd . array ( [ [number] , - [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , } , ) , ( NegativeBinomial , { [string] : mx . nd . array ( [ [number] , [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) } , ) , ( Uniform , { [string] : mx . nd . array ( [ [number] , - [number] ] ) , [string] : mx . nd . array ( [ [number] , - [number] ] ) , } , ) , ( Binned , { [string] : mx . nd . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ] ) . log ( ) . repeat ( axis = [number] , repeats = [number] ) , [string] : mx . nd . array ( [ [ - [number] , - [number] , - [number] , - [number] , [number] , [number] , [number] ] ] ) . repeat ( axis = [number] , repeats = [number] ) , } , ) , ( Binned , { [string] : mx . nd . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ] ) . log ( ) . repeat ( axis = [number] , repeats = [number] ) , [string] : mx . nd . array ( [ [ - [number] , - [number] , - [number] , - [number] , [number] , [number] , [number] ] ] ) . repeat ( axis = [number] , repeats = [number] ) , [string] : [number] , } , ) , ( Categorical , { [string] : mx . nd . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ] ) . log ( ) . repeat ( axis = [number] , repeats = [number] ) , } , ) , ( Poisson , { [string] : mx . nd . array ( [ [number] , [number] ] ) } ) , ( ZeroInflatedBeta , { [string] : mx . nd . array ( [ [number] ] ) , [string] : mx . nd . array ( [ [number] ] ) , [string] : mx . nd . array ( [ [number] ] ) , } , ) , ( OneInflatedBeta , { [string] : mx . nd . array ( [ [number] ] ) , [string] : mx . nd . array ( [ [number] ] ) , [string] : mx . nd . array ( [ [number] ] ) , } , ) , ( ZeroAndOneInflatedBeta , { [string] : mx . nd . array ( [ [number] ] ) , [string] : mx . nd . array ( [ [number] ] ) , [string] : mx . nd . array ( [ [number] ] ) , [string] : mx . nd . array ( [ [number] ] ) , } , ) , ] [EOL] [EOL] test_output = { [string] : { [string] : mx . nd . array ( [ [number] , - [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , } , [string] : { [string] : mx . nd . array ( [ [number] , [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , } , [string] : { [string] : mx . nd . array ( [ [number] , [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , } , [string] : { [string] : mx . nd . array ( [ [number] , [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , } , [string] : { [string] : mx . nd . array ( [ [number] , - [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , } , [string] : { [string] : mx . nd . array ( [ [number] , - [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , } , [string] : { [string] : mx . nd . array ( [ [number] , [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , } , [string] : { [string] : mx . nd . array ( [ [number] , - [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , } , [string] : { [string] : mx . nd . array ( [ - [number] , - [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , } , [string] : { [string] : mx . nd . array ( [ [number] , [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , } , [string] : { [string] : mx . nd . array ( [ [number] , [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , [string] : mx . nd . array ( [ [number] , [number] ] ) , } , [string] : { [string] : mx . nd . array ( [ [number] ] ) , [string] : mx . nd . array ( [ [number] ] ) , [string] : mx . nd . array ( [ [number] ] ) , } , [string] : { [string] : mx . nd . array ( [ [number] ] ) , [string] : mx . nd . array ( [ [number] ] ) , [string] : mx . nd . array ( [ [number] ] ) , } , [string] : { [string] : mx . nd . array ( [ [number] ] ) , [string] : mx . nd . array ( [ [number] ] ) , [string] : mx . nd . array ( [ [number] ] ) , } , } [EOL] [EOL] [comment] [EOL] DISTRIBUTIONS = [ Gaussian , Laplace , StudentT , Gamma , NegativeBinomial , Uniform , Binned , Poisson , ZeroInflatedBeta , OneInflatedBeta , ZeroAndOneInflatedBeta , ] [EOL] [EOL] [EOL] serialize_fn_list = [ lambda x : x , lambda x : load_json ( dump_json ( x ) ) ] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , test_cases ) @ pytest . mark . parametrize ( [string] , serialize_fn_list ) def test_means ( distr_class , params , serialize_fn ) : [EOL] distr = distr_class ( ** params ) [EOL] distr = serialize_fn ( distr ) [EOL] means = distr . mean [EOL] distr_name = distr . __class__ . __name__ [EOL] assert means . shape == test_output [ distr_name ] [ [string] ] . shape [EOL] [comment] [EOL] assert np . allclose ( means . asnumpy ( ) , test_output [ distr_name ] [ [string] ] . asnumpy ( ) , atol = [number] ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , test_cases ) @ pytest . mark . parametrize ( [string] , serialize_fn_list ) def test_stdevs ( distr_class , params , serialize_fn ) : [EOL] distr = distr_class ( ** params ) [EOL] distr = serialize_fn ( distr ) [EOL] stddevs = distr . stddev [EOL] distr_name = distr . __class__ . __name__ [EOL] assert stddevs . shape == test_output [ distr_name ] [ [string] ] . shape [EOL] assert np . allclose ( stddevs . asnumpy ( ) , test_output [ distr_name ] [ [string] ] . asnumpy ( ) , atol = [number] , ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , test_cases ) @ pytest . mark . parametrize ( [string] , serialize_fn_list ) def test_variances ( distr_class , params , serialize_fn ) : [EOL] distr = distr_class ( ** params ) [EOL] distr = serialize_fn ( distr ) [EOL] variances = distr . variance [EOL] distr_name = distr . __class__ . __name__ [EOL] assert variances . shape == test_output [ distr_name ] [ [string] ] . shape [EOL] assert np . allclose ( variances . asnumpy ( ) , test_output [ distr_name ] [ [string] ] . asnumpy ( ) , atol = [number] , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] from typing import NamedTuple , Optional [EOL] [EOL] import pytest [EOL] [EOL] import mxnet as mx [EOL] import numpy as np [EOL] [EOL] from gluonts . mx . distribution import ( TransformedDistribution , StudentT , Gamma , Beta , Dirichlet , Laplace , NegativeBinomial , Poisson , Uniform , PiecewiseLinear , MixtureDistribution , Binned , ) [EOL] import gluonts . mx . distribution . bijection as bij [EOL] from gluonts . mx . distribution . box_cox_transform import BoxCoxTransform [EOL] from gluonts . mx . distribution . gaussian import Gaussian [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ [ ( [number] , [number] , None ) , [number] ] , [ ( [number] , [number] , [number] ) , [number] ] , [ ( [number] , - [number] , None ) , [number] ] ] , ) @ pytest . mark . parametrize ( [string] , [ Gaussian ( mu = mx . nd . random . normal ( shape = ( [number] , [number] ) ) , sigma = mx . nd . random . uniform ( shape = ( [number] , [number] ) ) , ) ] , ) def test_distr_slice_axis ( distr , slice_axis_args , expected_axis_length ) : [EOL] axis , begin , end = slice_axis_args [EOL] distr_sliced = distr . slice_axis ( axis , begin , end ) [EOL] [EOL] assert distr_sliced . batch_shape [ axis ] == expected_axis_length [EOL] [EOL] [EOL] class SliceHelper : [EOL] def __getitem__ ( self , item ) : [EOL] return item [EOL] [EOL] [EOL] sh = SliceHelper ( ) [EOL] [EOL] BATCH_SHAPE = ( [number] , [number] , [number] ) [EOL] [EOL] [EOL] DISTRIBUTIONS_WITH_QUANTILE_FUNCTION = ( Gaussian , Uniform , Laplace , Binned ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ TransformedDistribution ( Gaussian ( mu = mx . nd . random . uniform ( shape = BATCH_SHAPE ) , sigma = mx . nd . ones ( shape = BATCH_SHAPE ) , ) , [ bij . AffineTransformation ( scale = [number] + mx . nd . random . uniform ( shape = BATCH_SHAPE ) ) , bij . softrelu , ] , ) , Binned ( bin_log_probs = mx . nd . uniform ( shape = BATCH_SHAPE + ( [number] , ) ) , bin_centers = mx . nd . array ( np . logspace ( - [number] , [number] , [number] ) ) + mx . nd . zeros ( BATCH_SHAPE + ( [number] , ) ) , ) , TransformedDistribution ( Binned ( bin_log_probs = mx . nd . uniform ( shape = BATCH_SHAPE + ( [number] , ) ) , bin_centers = mx . nd . array ( np . logspace ( - [number] , [number] , [number] ) ) + mx . nd . zeros ( BATCH_SHAPE + ( [number] , ) ) , ) , [ bij . AffineTransformation ( scale = [number] + mx . nd . random . uniform ( shape = BATCH_SHAPE ) ) , bij . softrelu , ] , ) , Gaussian ( mu = mx . nd . zeros ( shape = BATCH_SHAPE ) , sigma = mx . nd . ones ( shape = BATCH_SHAPE ) , ) , Gamma ( alpha = mx . nd . ones ( shape = BATCH_SHAPE ) , beta = mx . nd . ones ( shape = BATCH_SHAPE ) , ) , Beta ( alpha = [number] * mx . nd . ones ( shape = BATCH_SHAPE ) , beta = [number] * mx . nd . ones ( shape = BATCH_SHAPE ) , ) , StudentT ( mu = mx . nd . zeros ( shape = BATCH_SHAPE ) , sigma = mx . nd . ones ( shape = BATCH_SHAPE ) , nu = mx . nd . ones ( shape = BATCH_SHAPE ) , ) , Dirichlet ( alpha = mx . nd . ones ( shape = BATCH_SHAPE ) ) , Laplace ( mu = mx . nd . zeros ( shape = BATCH_SHAPE ) , b = mx . nd . ones ( shape = BATCH_SHAPE ) ) , NegativeBinomial ( mu = mx . nd . zeros ( shape = BATCH_SHAPE ) , alpha = mx . nd . ones ( shape = BATCH_SHAPE ) , ) , Poisson ( rate = mx . nd . ones ( shape = BATCH_SHAPE ) ) , Uniform ( low = - mx . nd . ones ( shape = BATCH_SHAPE ) , high = mx . nd . ones ( shape = BATCH_SHAPE ) , ) , PiecewiseLinear ( gamma = mx . nd . ones ( shape = BATCH_SHAPE ) , slopes = mx . nd . ones ( shape = ( [number] , [number] , [number] , [number] ) ) , knot_spacings = mx . nd . ones ( shape = ( [number] , [number] , [number] , [number] ) ) / [number] , ) , MixtureDistribution ( mixture_probs = mx . nd . stack ( [number] * mx . nd . ones ( shape = BATCH_SHAPE ) , [number] * mx . nd . ones ( shape = BATCH_SHAPE ) , axis = - [number] , ) , components = [ Gaussian ( mu = mx . nd . zeros ( shape = BATCH_SHAPE ) , sigma = mx . nd . ones ( shape = BATCH_SHAPE ) , ) , StudentT ( mu = mx . nd . zeros ( shape = BATCH_SHAPE ) , sigma = mx . nd . ones ( shape = BATCH_SHAPE ) , nu = mx . nd . ones ( shape = BATCH_SHAPE ) , ) , ] , ) , TransformedDistribution ( StudentT ( mu = mx . nd . zeros ( shape = BATCH_SHAPE ) , sigma = mx . nd . ones ( shape = BATCH_SHAPE ) , nu = mx . nd . ones ( shape = BATCH_SHAPE ) , ) , [ bij . AffineTransformation ( scale = [number] + mx . nd . random . uniform ( shape = BATCH_SHAPE ) ) ] , ) , TransformedDistribution ( Uniform ( low = mx . nd . zeros ( shape = BATCH_SHAPE ) , high = mx . nd . ones ( shape = BATCH_SHAPE ) , ) , [ BoxCoxTransform ( lambda_1 = mx . nd . ones ( shape = BATCH_SHAPE ) , lambda_2 = mx . nd . zeros ( shape = BATCH_SHAPE ) , ) ] , ) , ] , ) @ pytest . mark . parametrize ( [string] , [ sh [ [number] : [number] ] , sh [ [number] , : ] , sh [ : , [number] ] , sh [ [number] , - [number] ] ] ) def test_slice_axis_results ( distr , slice_item ) : [EOL] s = distr . sample ( ) . asnumpy ( ) [EOL] sliced = distr [ slice_item ] [EOL] s_sliced = sliced . sample ( ) . asnumpy ( ) [EOL] assert s_sliced . shape == s [ slice_item ] . shape [EOL] [EOL] y = np . random . uniform ( size = BATCH_SHAPE ) [EOL] lp_expected = distr . loss ( mx . nd . array ( y ) ) . asnumpy ( ) [ slice_item ] [EOL] lp_actual = sliced . loss ( mx . nd . array ( y [ slice_item ] ) ) . asnumpy ( ) [EOL] assert np . allclose ( lp_actual , lp_expected ) [EOL] [EOL] tmp = ( distr . base_distribution [EOL] if isinstance ( distr , TransformedDistribution ) [EOL] else distr ) [EOL] has_quantile_fn = isinstance ( tmp , DISTRIBUTIONS_WITH_QUANTILE_FUNCTION ) [EOL] [EOL] if has_quantile_fn : [EOL] for ql in [ [number] , [number] , [number] , [number] , [number] ] : [EOL] qs_actual = sliced . quantile ( mx . nd . array ( [ ql ] ) ) . asnumpy ( ) [ [number] ] [EOL] qs_expected = distr . quantile ( mx . nd . array ( [ ql ] ) ) . asnumpy ( ) [ [number] ] [ slice_item ] [EOL] assert np . allclose ( qs_actual , qs_expected ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import gluonts [EOL] import builtins [EOL] import numpy [EOL] import mxnet as mx [EOL] import numpy as np [EOL] import pytest [EOL] [EOL] [comment] [EOL] from gluonts . gluonts_tqdm import tqdm [EOL] from gluonts . model . common import Tensor , NPArrayLike [EOL] from gluonts . mx . distribution . distribution import Distribution [EOL] from gluonts . mx . distribution import ( Gaussian , StudentT , MixtureDistribution , GaussianOutput , StudentTOutput , LaplaceOutput , MultivariateGaussianOutput , MixtureDistributionOutput , ) [EOL] from gluonts . testutil import empirical_cdf [EOL] from gluonts . core . serde import dump_json , load_json [EOL] [EOL] serialize_fn_list = [ lambda x : x , lambda x : load_json ( dump_json ( x ) ) ] [EOL] [EOL] [EOL] def plot_samples ( s , bins = [number] ) : [EOL] from matplotlib import pyplot as plt [EOL] [EOL] s = s . asnumpy ( ) [EOL] plt . hist ( s , bins = bins ) [EOL] plt . show ( ) [EOL] [EOL] [EOL] BINS = np . linspace ( - [number] , [number] , [number] ) [EOL] [EOL] [EOL] def histogram ( samples ) : [EOL] h , _ = np . histogram ( samples , bins = BINS , density = True ) [EOL] return h [EOL] [EOL] [EOL] def diff ( x , y ) : [EOL] return np . mean ( np . abs ( x - y ) ) [EOL] [EOL] [EOL] NUM_SAMPLES = [number] [EOL] NUM_SAMPLES_LARGE = [number] [EOL] [EOL] [EOL] SHAPE = ( [number] , [number] , [number] ) [EOL] [EOL] np . random . seed ( [number] ) [EOL] mx . random . seed ( [number] ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( Gaussian ( mu = mx . nd . zeros ( shape = SHAPE ) , sigma = [number] + [number] * mx . nd . ones ( shape = SHAPE ) , ) , Gaussian ( mu = mx . nd . ones ( shape = SHAPE ) , sigma = [number] + [number] * mx . nd . ones ( shape = SHAPE ) , ) , [number] * mx . nd . ones ( shape = SHAPE ) , ) , ( StudentT ( mu = mx . nd . ones ( shape = SHAPE ) , sigma = [number] + mx . nd . zeros ( shape = SHAPE ) , nu = mx . nd . zeros ( shape = SHAPE ) + [number] , ) , Gaussian ( mu = - mx . nd . ones ( shape = SHAPE ) , sigma = [number] + mx . nd . zeros ( shape = SHAPE ) , ) , mx . nd . random_uniform ( shape = SHAPE ) , ) , ] , ) @ pytest . mark . parametrize ( [string] , serialize_fn_list ) def test_mixture ( distr1 , distr2 , p , serialize_fn ) : [EOL] [comment] [EOL] samples1 = distr1 . sample ( num_samples = NUM_SAMPLES_LARGE ) [EOL] samples2 = distr2 . sample ( num_samples = NUM_SAMPLES_LARGE ) [EOL] [EOL] rand = mx . nd . random . uniform ( shape = ( NUM_SAMPLES_LARGE , * p . shape ) ) [EOL] choice = ( rand < p . expand_dims ( axis = [number] ) ) . broadcast_like ( samples1 ) [EOL] samples_ref = mx . nd . where ( choice , samples1 , samples2 ) [EOL] [EOL] [comment] [EOL] [EOL] mixture_probs = mx . nd . stack ( p , [number] - p , axis = - [number] ) [EOL] [EOL] mixture = MixtureDistribution ( mixture_probs = mixture_probs , components = [ distr1 , distr2 ] ) [EOL] mixture = serialize_fn ( mixture ) [EOL] [EOL] samples_mix = mixture . sample ( num_samples = NUM_SAMPLES_LARGE ) [EOL] [EOL] [comment] [EOL] [EOL] assert ( samples1 . shape == samples2 . shape == samples_mix . shape == samples_ref . shape ) [EOL] [EOL] [comment] [EOL] calc_mean = mixture . mean . asnumpy ( ) [EOL] calc_std = mixture . stddev . asnumpy ( ) [EOL] sample_mean = samples_mix . asnumpy ( ) . mean ( axis = [number] ) [EOL] sample_std = samples_mix . asnumpy ( ) . std ( axis = [number] ) [EOL] [EOL] assert np . allclose ( calc_mean , sample_mean , atol = [number] ) [EOL] assert np . allclose ( calc_std , sample_std , atol = [number] ) [EOL] [EOL] [comment] [EOL] assert ( diff ( histogram ( samples_mix . asnumpy ( ) ) , histogram ( samples_ref . asnumpy ( ) ) ) < [number] ) [EOL] [EOL] [comment] [EOL] if isinstance ( distr1 , Gaussian ) and isinstance ( distr2 , Gaussian ) : [EOL] emp_cdf , edges = empirical_cdf ( samples_mix . asnumpy ( ) ) [EOL] calc_cdf = mixture . cdf ( mx . nd . array ( edges ) ) . asnumpy ( ) [EOL] assert np . allclose ( calc_cdf [ [number] : , : ] , emp_cdf , atol = [number] ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( ( GaussianOutput ( ) , GaussianOutput ( ) ) , ) , ( ( GaussianOutput ( ) , StudentTOutput ( ) , LaplaceOutput ( ) ) , ) , ( ( MultivariateGaussianOutput ( [number] ) , MultivariateGaussianOutput ( [number] ) ) , ) , ] , ) @ pytest . mark . parametrize ( [string] , serialize_fn_list ) def test_mixture_output ( distribution_outputs , serialize_fn ) : [EOL] mdo = MixtureDistributionOutput ( * distribution_outputs ) [EOL] [EOL] args_proj = mdo . get_args_proj ( ) [EOL] args_proj . initialize ( ) [EOL] [EOL] input = mx . nd . ones ( shape = ( [number] , [number] ) ) [EOL] [EOL] distr_args = args_proj ( input ) [EOL] d = mdo . distribution ( distr_args ) [EOL] d = serialize_fn ( d ) [EOL] [EOL] samples = d . sample ( num_samples = NUM_SAMPLES ) [EOL] [EOL] sample = d . sample ( ) [EOL] [EOL] assert samples . shape == ( NUM_SAMPLES , * sample . shape ) [EOL] [EOL] log_prob = d . log_prob ( sample ) [EOL] [EOL] assert log_prob . shape == d . batch_shape [EOL] [EOL] [EOL] BATCH_SIZE = [number] [EOL] [EOL] zeros = mx . nd . zeros ( ( BATCH_SIZE , [number] ) ) [EOL] ones = mx . nd . ones ( ( BATCH_SIZE , [number] ) ) [EOL] [EOL] mu1 = [number] [EOL] mu2 = [number] [EOL] sigma1 = [number] [EOL] sigma2 = [number] [EOL] [EOL] p1 = [number] [EOL] p2 = [number] - p1 [EOL] [EOL] samples1 = np . random . normal ( mu1 , scale = sigma1 , size = ( BATCH_SIZE , [number] ) ) [EOL] samples2 = np . random . normal ( mu2 , scale = sigma2 , size = ( BATCH_SIZE , [number] ) ) [EOL] np_samples = np . where ( np . random . uniform ( size = ( BATCH_SIZE , [number] ) ) > p1 , samples2 , samples1 ) [EOL] [EOL] EXPECTED_HIST = histogram ( np_samples ) [EOL] [EOL] [EOL] @ pytest . mark . skip ( [string] ) def test_mixture_inference ( ) : [EOL] mdo = MixtureDistributionOutput ( [ GaussianOutput ( ) , GaussianOutput ( ) ] ) [EOL] [EOL] args_proj = mdo . get_args_proj ( ) [EOL] args_proj . initialize ( ) [EOL] args_proj . hybridize ( ) [EOL] [EOL] input = mx . nd . ones ( ( BATCH_SIZE , [number] ) ) [EOL] [EOL] distr_args = args_proj ( input ) [EOL] d = mdo . distribution ( distr_args ) [EOL] [EOL] [comment] [EOL] [EOL] trainer = mx . gluon . Trainer ( args_proj . collect_params ( ) , [string] , { [string] : [number] } ) [EOL] [EOL] mixture_samples = mx . nd . array ( np_samples ) [EOL] [EOL] N = [number] [EOL] t = tqdm ( list ( range ( N ) ) ) [EOL] for i in t : [EOL] with mx . autograd . record ( ) : [EOL] distr_args = args_proj ( input ) [EOL] d = mdo . distribution ( distr_args ) [EOL] loss = d . loss ( mixture_samples ) [EOL] loss . backward ( ) [EOL] loss_value = loss . mean ( ) . asnumpy ( ) [EOL] t . set_postfix ( { [string] : loss_value } ) [EOL] trainer . step ( BATCH_SIZE ) [EOL] [EOL] distr_args = args_proj ( input ) [EOL] d = mdo . distribution ( distr_args ) [EOL] [EOL] obtained_hist = histogram ( d . sample ( ) . asnumpy ( ) ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] assert diff ( obtained_hist , EXPECTED_HIST ) < [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import List , Tuple [EOL] import typing [EOL] import builtins [EOL] import gluonts [EOL] from typing import Tuple , List [EOL] import pytest [EOL] [EOL] import mxnet as mx [EOL] import numpy as np [EOL] [EOL] from gluonts . mx . distribution import PiecewiseLinear , PiecewiseLinearOutput [EOL] from gluonts . testutil import empirical_cdf [EOL] from gluonts . core . serde import dump_json , load_json [EOL] [EOL] serialize_fn_list = [ lambda x : x , lambda x : load_json ( dump_json ( x ) ) ] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( PiecewiseLinear ( gamma = mx . nd . ones ( shape = ( [number] , ) ) , slopes = mx . nd . array ( [ [number] , [number] , [number] ] ) . reshape ( shape = ( [number] , [number] ) ) , knot_spacings = mx . nd . array ( [ [number] , [number] , [number] ] ) . reshape ( shape = ( [number] , [number] ) ) , ) , [ [number] ] , [ [number] ] , [ [number] ] , ) , ( PiecewiseLinear ( gamma = mx . nd . ones ( shape = ( [number] , ) ) , slopes = mx . nd . array ( [ [ [number] , [number] ] , [ [number] , [number] ] ] ) . reshape ( shape = ( [number] , [number] ) ) , knot_spacings = mx . nd . array ( [ [ [number] , [number] ] , [ [number] , [number] ] ] ) . reshape ( shape = ( [number] , [number] ) ) , ) , [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] , ) , ] , ) @ pytest . mark . parametrize ( [string] , serialize_fn_list ) def test_values ( distr , target , expected_target_cdf , expected_target_crps , serialize_fn , ) : [EOL] distr = serialize_fn ( distr ) [EOL] target = mx . nd . array ( target ) . reshape ( shape = ( len ( target ) , ) ) [EOL] expected_target_cdf = np . array ( expected_target_cdf ) . reshape ( ( len ( expected_target_cdf ) , ) ) [EOL] expected_target_crps = np . array ( expected_target_crps ) . reshape ( ( len ( expected_target_crps ) , ) ) [EOL] [EOL] assert all ( np . isclose ( distr . cdf ( target ) . asnumpy ( ) , expected_target_cdf ) ) [EOL] assert all ( np . isclose ( distr . crps ( target ) . asnumpy ( ) , expected_target_crps ) ) [EOL] [EOL] [comment] [EOL] num_samples = [number] [EOL] samples = distr . sample ( num_samples ) . asnumpy ( ) [EOL] assert np . isfinite ( samples ) . all ( ) [EOL] [EOL] emp_cdf , edges = empirical_cdf ( samples ) [EOL] calc_cdf = distr . cdf ( mx . nd . array ( edges ) ) . asnumpy ( ) [EOL] assert np . allclose ( calc_cdf [ [number] : , : ] , emp_cdf , atol = [number] ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( ( [number] , [number] , [number] ) , [number] , [number] ) , ( ( [number] , ) , [number] , [number] ) , ( ( [number] , ) , [number] , [number] ) , ( ( [number] , [number] ) , [number] , [number] ) ] , ) @ pytest . mark . parametrize ( [string] , serialize_fn_list ) def test_shapes ( batch_shape , num_pieces , num_samples , serialize_fn ) : [EOL] gamma = mx . nd . ones ( shape = ( * batch_shape , ) ) [EOL] slopes = mx . nd . ones ( shape = ( * batch_shape , num_pieces ) ) [comment] [EOL] knot_spacings = ( mx . nd . ones ( shape = ( * batch_shape , num_pieces ) ) / num_pieces ) [comment] [EOL] target = mx . nd . ones ( shape = batch_shape ) [comment] [EOL] [EOL] distr = PiecewiseLinear ( gamma = gamma , slopes = slopes , knot_spacings = knot_spacings ) [EOL] distr = serialize_fn ( distr ) [EOL] [EOL] [comment] [EOL] assert gamma . shape == target . shape [EOL] assert knot_spacings . shape == slopes . shape [EOL] assert len ( gamma . shape ) + [number] == len ( knot_spacings . shape ) [EOL] [EOL] [comment] [EOL] assert distr . batch_shape == batch_shape [EOL] [EOL] [comment] [EOL] assert distr . b . shape == slopes . shape [EOL] assert distr . knot_positions . shape == knot_spacings . shape [EOL] [EOL] [comment] [EOL] assert distr . crps ( target ) . shape == batch_shape [EOL] [EOL] [comment] [EOL] assert distr . quantile_internal ( knot_spacings , axis = - [number] ) . shape == ( * batch_shape , num_pieces , ) [EOL] [EOL] [comment] [EOL] samples = distr . sample ( ) [EOL] assert samples . shape == batch_shape [EOL] assert distr . quantile_internal ( samples ) . shape == batch_shape [EOL] [EOL] [comment] [EOL] samples = distr . sample ( num_samples ) [EOL] assert samples . shape == ( num_samples , * batch_shape ) [EOL] assert distr . quantile_internal ( samples , axis = [number] ) . shape == ( num_samples , * batch_shape , ) [EOL] [EOL] [EOL] def test_simple_symmetric ( ) : [EOL] gamma = mx . nd . array ( [ - [number] ] ) [EOL] slopes = mx . nd . array ( [ [ [number] , [number] ] ] ) [EOL] knot_spacings = mx . nd . array ( [ [ [number] , [number] ] ] ) [EOL] [EOL] distr = PiecewiseLinear ( gamma = gamma , slopes = slopes , knot_spacings = knot_spacings ) [EOL] [EOL] assert distr . cdf ( mx . nd . array ( [ - [number] ] ) ) . asnumpy ( ) . item ( ) == [number] [EOL] assert distr . cdf ( mx . nd . array ( [ + [number] ] ) ) . asnumpy ( ) . item ( ) == [number] [EOL] [EOL] expected_crps = np . array ( [ [number] + [number] / [number] ] ) [EOL] [EOL] assert np . allclose ( distr . crps ( mx . nd . array ( [ - [number] ] ) ) . asnumpy ( ) , expected_crps ) [EOL] [EOL] assert np . allclose ( distr . crps ( mx . nd . array ( [ [number] ] ) ) . asnumpy ( ) , expected_crps ) [EOL] [EOL] [EOL] def test_robustness ( ) : [EOL] distr_out = PiecewiseLinearOutput ( num_pieces = [number] ) [EOL] args_proj = distr_out . get_args_proj ( ) [EOL] args_proj . initialize ( ) [EOL] [EOL] net_out = mx . nd . random . normal ( shape = ( [number] , [number] ) , scale = [number] ) [EOL] gamma , slopes , knot_spacings = args_proj ( net_out ) [EOL] distr = distr_out . distribution ( ( gamma , slopes , knot_spacings ) ) [EOL] [EOL] [comment] [EOL] sup_support = gamma + mx . nd . sum ( slopes * knot_spacings , axis = - [number] ) [EOL] [EOL] assert mx . nd . broadcast_lesser_equal ( gamma , sup_support ) . asnumpy ( ) . all ( ) [EOL] [EOL] width = sup_support - gamma [EOL] x = mx . random . uniform ( low = gamma - width , high = sup_support + width ) [EOL] [EOL] [comment] [EOL] cdf_x = distr . cdf ( x ) [EOL] assert ( mx . nd . min ( cdf_x ) . asscalar ( ) >= [number] [EOL] and mx . nd . max ( cdf_x ) . asscalar ( ) <= [number] ) [EOL] [EOL] [comment] [EOL] crps_x = distr . crps ( x ) [EOL] assert mx . nd . min ( crps_x ) . asscalar ( ) >= [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Tuple [EOL] import gluonts [EOL] import typing [EOL] from typing import Tuple [EOL] import pytest [EOL] [EOL] import mxnet as mx [EOL] [EOL] from gluonts . support . util import make_nd_diag [EOL] from gluonts . mx . distribution import ( Distribution , Gaussian , Gamma , Beta , Laplace , MixtureDistribution , MultivariateGaussian , NegativeBinomial , PiecewiseLinear , Poisson , StudentT , Uniform , TransformedDistribution , Dirichlet , DirichletMultinomial , ) [EOL] from gluonts . mx . distribution . bijection import AffineTransformation [EOL] from gluonts . mx . distribution . box_cox_transform import BoxCoxTransform [EOL] from gluonts . model . tpp . distribution import Loglogistic , Weibull [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( Gaussian ( mu = mx . nd . zeros ( shape = ( [number] , [number] , [number] ) ) , sigma = mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) , ) , ( [number] , [number] , [number] ) , ( ) , ) , ( Gamma ( alpha = mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) , beta = mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) , ) , ( [number] , [number] , [number] ) , ( ) , ) , ( Beta ( alpha = mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) , beta = mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) , ) , ( [number] , [number] , [number] ) , ( ) , ) , ( StudentT ( mu = mx . nd . zeros ( shape = ( [number] , [number] , [number] ) ) , sigma = mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) , nu = mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) , ) , ( [number] , [number] , [number] ) , ( ) , ) , ( MultivariateGaussian ( mu = mx . nd . zeros ( shape = ( [number] , [number] , [number] ) ) , L = make_nd_diag ( F = mx . nd , x = mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) , d = [number] ) , ) , ( [number] , [number] ) , ( [number] , ) , ) , ( Dirichlet ( alpha = mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ) , ( [number] , [number] ) , ( [number] , ) ) , ( DirichletMultinomial ( dim = [number] , n_trials = [number] , alpha = mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ) , ( [number] , [number] ) , ( [number] , ) , ) , ( Laplace ( mu = mx . nd . zeros ( shape = ( [number] , [number] , [number] ) ) , b = mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ) , ( [number] , [number] , [number] ) , ( ) , ) , ( NegativeBinomial ( mu = mx . nd . zeros ( shape = ( [number] , [number] , [number] ) ) , alpha = mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) , ) , ( [number] , [number] , [number] ) , ( ) , ) , ( Poisson ( rate = mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ) , ( [number] , [number] , [number] ) , ( ) ) , ( Uniform ( low = - mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) , high = mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) , ) , ( [number] , [number] , [number] ) , ( ) , ) , ( PiecewiseLinear ( gamma = mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) , slopes = mx . nd . ones ( shape = ( [number] , [number] , [number] , [number] ) ) , knot_spacings = mx . nd . ones ( shape = ( [number] , [number] , [number] , [number] ) ) / [number] , ) , ( [number] , [number] , [number] ) , ( ) , ) , ( MixtureDistribution ( mixture_probs = mx . nd . stack ( [number] * mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) , [number] * mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) , axis = - [number] , ) , components = [ Gaussian ( mu = mx . nd . zeros ( shape = ( [number] , [number] , [number] ) ) , sigma = mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) , ) , StudentT ( mu = mx . nd . zeros ( shape = ( [number] , [number] , [number] ) ) , sigma = mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) , nu = mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) , ) , ] , ) , ( [number] , [number] , [number] ) , ( ) , ) , ( MixtureDistribution ( mixture_probs = mx . nd . stack ( [number] * mx . nd . ones ( shape = ( [number] , [number] ) ) , [number] * mx . nd . ones ( shape = ( [number] , [number] ) ) , axis = - [number] , ) , components = [ MultivariateGaussian ( mu = mx . nd . zeros ( shape = ( [number] , [number] , [number] ) ) , L = make_nd_diag ( F = mx . nd , x = mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) , d = [number] ) , ) , MultivariateGaussian ( mu = mx . nd . zeros ( shape = ( [number] , [number] , [number] ) ) , L = make_nd_diag ( F = mx . nd , x = mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) , d = [number] ) , ) , ] , ) , ( [number] , [number] ) , ( [number] , ) , ) , ( TransformedDistribution ( StudentT ( mu = mx . nd . zeros ( shape = ( [number] , [number] , [number] ) ) , sigma = mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) , nu = mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) , ) , [ AffineTransformation ( scale = [number] + mx . nd . random . uniform ( shape = ( [number] , [number] , [number] ) ) ) ] , ) , ( [number] , [number] , [number] ) , ( ) , ) , ( TransformedDistribution ( MultivariateGaussian ( mu = mx . nd . zeros ( shape = ( [number] , [number] , [number] ) ) , L = make_nd_diag ( F = mx . nd , x = mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) , d = [number] ) , ) , [ AffineTransformation ( scale = [number] + mx . nd . random . uniform ( shape = ( [number] , [number] , [number] ) ) ) ] , ) , ( [number] , [number] ) , ( [number] , ) , ) , ( TransformedDistribution ( Uniform ( low = mx . nd . zeros ( shape = ( [number] , [number] , [number] ) ) , high = mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) , ) , [ BoxCoxTransform ( lambda_1 = mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) , lambda_2 = mx . nd . zeros ( shape = ( [number] , [number] , [number] ) ) , ) ] , ) , ( [number] , [number] , [number] ) , ( ) , ) , ( Loglogistic ( mx . nd . zeros ( shape = ( [number] , [number] , [number] ) ) , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) , ) , ( [number] , [number] , [number] ) , ( ) , ) , ( Weibull ( mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) , ) , ( [number] , [number] , [number] ) , ( ) , ) , ] , ) def test_distribution_shapes ( distr , expected_batch_shape , expected_event_shape , ) : [EOL] assert distr . batch_shape == expected_batch_shape [EOL] assert distr . event_shape == expected_event_shape [EOL] [EOL] x = distr . sample ( ) [EOL] [EOL] assert x . shape == distr . batch_shape + distr . event_shape [EOL] [EOL] loss = distr . loss ( x ) [EOL] [EOL] assert loss . shape == distr . batch_shape [EOL] [EOL] x1 = distr . sample ( num_samples = [number] ) [EOL] [EOL] assert x1 . shape == ( [number] , ) + distr . batch_shape + distr . event_shape [EOL] [EOL] x3 = distr . sample ( num_samples = [number] ) [EOL] [EOL] assert x3 . shape == ( [number] , ) + distr . batch_shape + distr . event_shape [EOL] [EOL] def has_quantile ( d ) : [EOL] return isinstance ( d , ( Uniform , Gaussian , Laplace ) ) [EOL] [EOL] if ( has_quantile ( distr ) or isinstance ( distr , TransformedDistribution ) [EOL] and has_quantile ( distr . base_distribution ) ) : [EOL] qs1 = distr . quantile ( mx . nd . array ( [ [number] ] ) ) [EOL] assert qs1 . shape == ( [number] , ) + distr . batch_shape + distr . event_shape [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import pytest [EOL] import json [EOL] import gzip [EOL] import os [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] import mxnet as mx [EOL] [EOL] [comment] [EOL] from gluonts . mx . distribution . lds import LDS [EOL] [EOL] [EOL] def assert_shape_and_finite ( x , shape ) : [EOL] assert x . shape == shape [EOL] assert not np . isnan ( x . asnumpy ( ) ) . any ( ) [EOL] assert not np . isinf ( x . asnumpy ( ) ) . any ( ) [EOL] [EOL] [EOL] current_path = os . path . dirname ( os . path . abspath ( __file__ ) ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] @ pytest . mark . parametrize ( [string] , [ os . path . join ( current_path , [string] ) , os . path . join ( current_path , [string] ) , os . path . join ( current_path , [string] , ) , ] , ) def test_lds_likelihood ( data_filename ) : [EOL] [docstring] [EOL] with gzip . GzipFile ( data_filename , [string] ) as fp : [EOL] data = json . load ( fp = fp ) [EOL] [EOL] lds = LDS ( mx . nd . array ( data [ [string] ] ) , mx . nd . array ( data [ [string] ] ) , mx . nd . array ( data [ [string] ] ) , mx . nd . array ( data [ [string] ] ) , mx . nd . array ( data [ [string] ] ) , mx . nd . array ( data [ [string] ] ) , mx . nd . array ( data [ [string] ] ) , data [ [string] ] , data [ [string] ] , data [ [string] ] , ) [EOL] [EOL] targets = mx . nd . array ( data [ [string] ] ) [EOL] true_likelihood = mx . nd . array ( data [ [string] ] ) [EOL] [EOL] batch_size = lds . emission_coeff [ [number] ] . shape [ [number] ] [EOL] time_length = len ( lds . emission_coeff ) [EOL] output_dim = lds . emission_coeff [ [number] ] . shape [ [number] ] [EOL] latent_dim = lds . emission_coeff [ [number] ] . shape [ [number] ] [EOL] [EOL] assert lds . batch_shape == ( batch_size , time_length ) [EOL] assert lds . event_shape == ( output_dim , ) [EOL] [EOL] likelihood , final_mean , final_cov = lds . log_prob ( targets ) [EOL] [EOL] assert_shape_and_finite ( likelihood , shape = lds . batch_shape ) [EOL] assert_shape_and_finite ( final_mean , shape = ( batch_size , latent_dim ) ) [EOL] assert_shape_and_finite ( final_cov , shape = ( batch_size , latent_dim , latent_dim ) ) [EOL] [EOL] likelihood_per_item = likelihood . sum ( axis = [number] ) [EOL] [EOL] np . testing . assert_almost_equal ( likelihood_per_item . asnumpy ( ) , true_likelihood . asnumpy ( ) , decimal = [number] , err_msg = f" [string] " f" [string] { true_likelihood } [string] " f" [string] { likelihood_per_item }" , ) [EOL] [EOL] samples = lds . sample_marginals ( num_samples = [number] ) [EOL] [EOL] assert_shape_and_finite ( samples , shape = ( [number] , ) + lds . batch_shape + lds . event_shape ) [EOL] [EOL] sample = lds . sample_marginals ( ) [EOL] [EOL] assert_shape_and_finite ( sample , shape = lds . batch_shape + lds . event_shape ) [EOL] [EOL] samples = lds . sample ( num_samples = [number] ) [EOL] [EOL] assert_shape_and_finite ( samples , shape = ( [number] , ) + lds . batch_shape + lds . event_shape ) [EOL] [EOL] sample = lds . sample ( ) [EOL] [EOL] assert_shape_and_finite ( sample , shape = lds . batch_shape + lds . event_shape ) [EOL] [EOL] ll , _ , _ = lds . log_prob ( sample ) [EOL] [EOL] assert_shape_and_finite ( ll , shape = lds . batch_shape ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import List , Union , Tuple [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] from typing import Tuple , List , Union [EOL] import pytest [EOL] from itertools import product [EOL] [EOL] import mxnet as mx [EOL] [EOL] from gluonts . model . common import Tensor [EOL] from gluonts . mx . distribution import ( DistributionOutput , GaussianOutput , GammaOutput , BetaOutput , LaplaceOutput , MixtureDistributionOutput , MultivariateGaussianOutput , LowrankMultivariateGaussianOutput , NegativeBinomialOutput , PiecewiseLinearOutput , PoissonOutput , StudentTOutput , UniformOutput , DirichletOutput , DirichletMultinomialOutput , DeterministicOutput , ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( GaussianOutput ( ) , mx . nd . random . normal ( shape = ( [number] , [number] , [number] , [number] ) ) , [ None , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ] , [ None , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ] , ( [number] , [number] , [number] ) , ( ) , ) , ( StudentTOutput ( ) , mx . nd . random . normal ( shape = ( [number] , [number] , [number] , [number] ) ) , [ None , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ] , [ None , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ] , ( [number] , [number] , [number] ) , ( ) , ) , ( GammaOutput ( ) , mx . nd . random . gamma ( shape = ( [number] , [number] , [number] , [number] ) ) , [ None , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ] , [ None , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ] , ( [number] , [number] , [number] ) , ( ) , ) , ( BetaOutput ( ) , mx . nd . random . gamma ( shape = ( [number] , [number] , [number] , [number] ) ) , [ None , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ] , [ None , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ] , ( [number] , [number] , [number] ) , ( ) , ) , ( MultivariateGaussianOutput ( dim = [number] ) , mx . nd . random . normal ( shape = ( [number] , [number] , [number] ) ) , [ None , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ] , [ None , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ] , ( [number] , [number] ) , ( [number] , ) , ) , ( LowrankMultivariateGaussianOutput ( dim = [number] , rank = [number] ) , mx . nd . random . normal ( shape = ( [number] , [number] , [number] ) ) , [ None , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ] , [ None , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ] , ( [number] , [number] ) , ( [number] , ) , ) , ( DirichletOutput ( dim = [number] ) , mx . nd . random . gamma ( shape = ( [number] , [number] , [number] ) ) , [ None ] , [ None ] , ( [number] , [number] ) , ( [number] , ) , ) , ( DirichletMultinomialOutput ( dim = [number] , n_trials = [number] ) , mx . nd . random . gamma ( shape = ( [number] , [number] , [number] ) ) , [ None ] , [ None ] , ( [number] , [number] ) , ( [number] , ) , ) , ( LaplaceOutput ( ) , mx . nd . random . normal ( shape = ( [number] , [number] , [number] , [number] ) ) , [ None , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ] , [ None , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ] , ( [number] , [number] , [number] ) , ( ) , ) , ( NegativeBinomialOutput ( ) , mx . nd . random . normal ( shape = ( [number] , [number] , [number] , [number] ) ) , [ None ] , [ None , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ] , ( [number] , [number] , [number] ) , ( ) , ) , ( UniformOutput ( ) , mx . nd . random . normal ( shape = ( [number] , [number] , [number] , [number] ) ) , [ None , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ] , [ None , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ] , ( [number] , [number] , [number] ) , ( ) , ) , ( PiecewiseLinearOutput ( num_pieces = [number] ) , mx . nd . random . normal ( shape = ( [number] , [number] , [number] , [number] ) ) , [ None , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ] , [ None , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ] , ( [number] , [number] , [number] ) , ( ) , ) , ( MixtureDistributionOutput ( [ GaussianOutput ( ) , StudentTOutput ( ) ] ) , mx . nd . random . normal ( shape = ( [number] , [number] , [number] , [number] ) ) , [ None , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ] , [ None , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ] , ( [number] , [number] , [number] ) , ( ) , ) , ( MixtureDistributionOutput ( [ MultivariateGaussianOutput ( dim = [number] ) , MultivariateGaussianOutput ( dim = [number] ) , ] ) , mx . nd . random . normal ( shape = ( [number] , [number] , [number] ) ) , [ None , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ] , [ None , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ] , ( [number] , [number] ) , ( [number] , ) , ) , ( PoissonOutput ( ) , mx . nd . random . normal ( shape = ( [number] , [number] , [number] , [number] ) ) , [ None ] , [ None , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ] , ( [number] , [number] , [number] ) , ( ) , ) , ( DeterministicOutput ( [number] ) , mx . nd . random . normal ( shape = ( [number] , [number] , [number] , [number] ) ) , [ None , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ] , [ None , mx . nd . ones ( shape = ( [number] , [number] , [number] ) ) ] , ( [number] , [number] , [number] ) , ( ) , ) , ] , ) def test_distribution_output_shapes ( distr_out , data , loc , scale , expected_batch_shape , expected_event_shape , ) : [EOL] args_proj = distr_out . get_args_proj ( ) [EOL] args_proj . initialize ( ) [EOL] [EOL] args = args_proj ( data ) [EOL] [EOL] assert distr_out . event_shape == expected_event_shape [EOL] [EOL] for l , s in product ( loc , scale ) : [EOL] [EOL] distr = distr_out . distribution ( args , loc = l , scale = s ) [EOL] [EOL] assert distr . batch_shape == expected_batch_shape [EOL] assert distr . event_shape == expected_event_shape [EOL] [EOL] x = distr . sample ( ) [EOL] [EOL] assert x . shape == distr . batch_shape + distr . event_shape [EOL] [EOL] loss = distr . loss ( x ) [EOL] [EOL] assert loss . shape == distr . batch_shape [EOL] [EOL] x1 = distr . sample ( num_samples = [number] ) [EOL] [EOL] assert x1 . shape == ( [number] , ) + distr . batch_shape + distr . event_shape [EOL] [EOL] x3 = distr . sample ( num_samples = [number] ) [EOL] [EOL] assert x3 . shape == ( [number] , ) + distr . batch_shape + distr . event_shape [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [number] , ( [number] , [number] , [number] ) ) ] ) def test_deterministic_output ( value , model_output_shape ) : [EOL] do = DeterministicOutput ( value ) [EOL] x = mx . nd . ones ( model_output_shape ) [EOL] [EOL] args_proj = do . get_args_proj ( ) [EOL] args_proj . initialize ( ) [EOL] args = args_proj ( x ) [EOL] distr = do . distribution ( args ) [EOL] [EOL] s = distr . sample ( ) [EOL] [EOL] assert ( ( s == value * mx . nd . ones ( shape = model_output_shape [ : - [number] ] ) ) . asnumpy ( ) . all ( ) ) [EOL] [EOL] assert ( distr . prob ( s ) == [number] ) . asnumpy ( ) . all ( ) [EOL] [EOL] s10 = distr . sample ( [number] ) [EOL] [EOL] assert ( ( s10 == value * mx . nd . ones ( shape = ( [number] , ) + model_output_shape [ : - [number] ] ) ) . asnumpy ( ) . all ( ) ) [EOL] [EOL] assert ( distr . prob ( s10 ) == [number] ) . asnumpy ( ) . all ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import mxnet as mx [EOL] import numpy as np [EOL] import pytest [EOL] from gluonts . mx . distribution import DistributionOutput [EOL] from gluonts . mx . distribution . neg_binomial import NegativeBinomialOutput [EOL] from gluonts . mx . distribution . gamma import GammaOutput [EOL] from gluonts . mx . distribution . beta import BetaOutput [EOL] [EOL] test_cases = [ NegativeBinomialOutput , GammaOutput , BetaOutput ] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , test_cases ) def test_issue_287 ( distr_out_class ) : [EOL] network_output = mx . nd . ones ( shape = ( [number] , ) ) [EOL] distr_output = distr_out_class ( ) [EOL] args_proj = distr_output . get_args_proj ( ) [EOL] args_proj . initialize ( init = mx . init . Constant ( - [number] ) ) [EOL] distr_args = args_proj ( network_output ) [EOL] distr = distr_output . distribution ( distr_args ) [EOL] x = mx . nd . array ( [ [number] ] ) [EOL] ll = distr . log_prob ( x ) [EOL] assert np . isfinite ( ll . asnumpy ( ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] import itertools [EOL] [EOL] import pytest [EOL] import mxnet as mx [EOL] import numpy as np [EOL] [EOL] from gluonts . mx . distribution import Binned , BinnedOutput [EOL] [EOL] [EOL] COMMON_KWARGS = { [string] : mx . nd . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ] ) . log ( ) . repeat ( axis = [number] , repeats = [number] ) , [string] : mx . nd . array ( [ [ - [number] , - [number] , - [number] , - [number] , [number] , [number] , [number] ] ] ) . repeat ( axis = [number] , repeats = [number] ) , } [EOL] [EOL] [EOL] @ pytest . fixture def labels ( ) : [EOL] return mx . random . uniform ( low = - [number] , high = [number] , shape = ( [number] , ) ) [comment] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , itertools . product ( [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] ) ) def test_smooth_mask_adds_to_one ( K , alpha ) : [EOL] bin_log_probs = mx . nd . log_softmax ( mx . nd . ones ( K ) ) [EOL] bin_centers = mx . nd . arange ( K ) [EOL] [EOL] dist = Binned ( bin_log_probs = bin_log_probs , bin_centers = bin_centers , label_smoothing = [number] , ) [EOL] [EOL] labels = mx . random . uniform ( low = [number] , high = K , shape = ( [number] , ) ) . expand_dims ( - [number] ) [EOL] mask = dist . _get_mask ( labels ) [EOL] smooth_mask = dist . _smooth_mask ( mx . nd , mask , alpha = mx . nd . array ( [ alpha ] ) ) [EOL] [EOL] [comment] [EOL] assert np . allclose ( smooth_mask . asnumpy ( ) . sum ( axis = - [number] ) , np . ones ( [number] ) , atol = [number] ) [EOL] [EOL] [EOL] def test_get_smooth_mask_correct ( labels ) : [EOL] dist = Binned ( ** COMMON_KWARGS , label_smoothing = [number] ) [EOL] binned = Binned ( ** COMMON_KWARGS ) [EOL] [EOL] labels = labels . expand_dims ( - [number] ) [EOL] [EOL] mask = dist . _get_mask ( labels ) [EOL] [EOL] assert np . allclose ( mask . asnumpy ( ) , binned . _get_mask ( labels ) . asnumpy ( ) ) [EOL] [EOL] smooth_mask = dist . _smooth_mask ( mx . nd , mask , alpha = mx . nd . array ( [ [number] ] ) ) [EOL] [EOL] [comment] [EOL] assert np . allclose ( smooth_mask . asnumpy ( ) . sum ( axis = - [number] ) , np . ones ( [number] ) ) [EOL] [EOL] [comment] [EOL] assert np . allclose ( np . argmax ( smooth_mask . asnumpy ( ) , axis = - [number] ) , np . argmax ( mask . asnumpy ( ) , axis = - [number] ) , ) [EOL] [EOL] [comment] [EOL] assert np . allclose ( smooth_mask . asnumpy ( ) . min ( axis = - [number] ) , np . ones ( [number] ) * [number] / [number] ) [EOL] [EOL] [EOL] def test_loss_correct ( labels ) : [EOL] smooth_alpha = Binned ( ** COMMON_KWARGS , label_smoothing = [number] ) [EOL] smooth_noalpha = Binned ( ** COMMON_KWARGS , label_smoothing = [number] ) [EOL] binned = Binned ( ** COMMON_KWARGS ) [EOL] [EOL] assert np . allclose ( binned . loss ( labels ) . asnumpy ( ) , smooth_noalpha . loss ( labels ) . asnumpy ( ) ) [EOL] [EOL] assert not np . allclose ( binned . loss ( labels ) . asnumpy ( ) , smooth_alpha . loss ( labels ) . asnumpy ( ) ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ True , False ] ) def test_output_sets_alpha ( labels , hybridize ) : [EOL] binned_output = BinnedOutput ( bin_centers = COMMON_KWARGS [ [string] ] [ [number] ] , label_smoothing = [number] ) [EOL] [EOL] arg_proj = binned_output . get_args_proj ( ) [EOL] if hybridize : [EOL] arg_proj . hybridize ( ) [EOL] arg_proj . initialize ( ) [EOL] [EOL] assert ( binned_output . distribution ( arg_proj ( mx . nd . random . uniform ( [number] , [number] ) ) ) . label_smoothing == [number] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import pytest [EOL] import mxnet as mx [EOL] import numpy as np [EOL] [EOL] from gluonts . mx . representation import Representation [EOL] [EOL] [EOL] cases = [ ( mx . nd . array ( [ [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] , ] ) , mx . nd . array ( [ [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] , ] ) , ) , ( mx . nd . array ( [ [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] + [ [number] ] * [number] , ] ) , mx . nd . array ( [ [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] + [ [number] ] * [number] , ] ) , ) , ( mx . nd . random . normal ( shape = ( [number] , [number] ) ) , mx . nd . zeros ( shape = ( [number] , [number] ) ) , ) , ] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , cases ) def test_rep ( target , observed ) : [EOL] s = Representation ( ) [EOL] target_scaled , scale , _ = s ( target , observed , None , [ ] ) [EOL] [EOL] assert mx . nd . norm ( target - target_scaled ) == [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import pytest [EOL] import mxnet as mx [EOL] import numpy as np [EOL] [EOL] from gluonts . mx . representation import CustomBinning [EOL] [EOL] [EOL] binning_cases = [ ( CustomBinning ( bin_centers = np . linspace ( - [number] , [number] , [number] ) ) , mx . nd . array ( [ [ - [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] , ] ) , mx . nd . array ( [ [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] , ] ) , mx . nd . array ( [ - np . inf , [number] , [number] , [number] , [number] , np . inf ] ) , mx . nd . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , ] ) , ) , ( CustomBinning ( bin_centers = np . linspace ( - [number] , [number] , [number] ) ) , mx . nd . array ( [ [ - [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] , ] ) , mx . nd . array ( [ [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] , ] ) , mx . nd . array ( [ - np . inf , - [number] , - [number] , - [number] , [number] , [number] , [number] , [number] , np . inf , ] ) , mx . nd . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , ] ) , ) , ] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , binning_cases , ) def test_binning ( r , target , observed , exp_bin_edges , expected_repr ) : [EOL] r . initialize_from_array ( np . array ( [ ] ) , mx . context . cpu ( ) ) [EOL] target_transf , _ , rep_params = r ( target , observed , None , [ ] ) [EOL] bin_edges = rep_params [ [number] ] [EOL] [EOL] assert np . allclose ( exp_bin_edges . asnumpy ( ) , bin_edges . asnumpy ( ) ) , f" [string] { exp_bin_edges } [string] { bin_edges . asnumpy ( ) } [string] " [EOL] assert np . allclose ( expected_repr . asnumpy ( ) , target_transf . asnumpy ( ) ) , f" [string] { expected_repr } [string] { target_transf } [string] " [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import pytest [EOL] import mxnet as mx [EOL] import numpy as np [EOL] [EOL] from gluonts . mx . representation import LocalAbsoluteBinning [EOL] [EOL] [EOL] la_binning_cases = [ ( LocalAbsoluteBinning ( num_bins = [number] , is_quantile = True ) , mx . nd . array ( [ [ - [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] , ] ) , mx . nd . array ( [ [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] , ] ) , mx . nd . array ( [ [ - np . inf , [number] , [number] , [number] , [number] , [number] , np . inf , ] , [ - np . inf , [number] , [number] , [number] , [number] , [number] , np . inf , ] , [ - np . inf , [number] , [number] , [number] , [number] , [number] , np . inf , ] , [ - np . inf , [number] , [number] , [number] , [number] , [number] , np . inf , ] , [ - [number] , - [number] , - [number] , - [number] , - [number] , - [number] , - [number] , ] , [ - np . inf , [number] , [number] , [number] , [number] , [number] , np . inf , ] , ] ) , mx . nd . array ( [ [ - [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , ] , [ - [number] , - [number] , - [number] , - [number] , - [number] , - [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , ] , ] ) , mx . nd . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , ] ) , ) , ( LocalAbsoluteBinning ( num_bins = [number] , is_quantile = False ) , mx . nd . array ( [ [ - [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] , ] ) , mx . nd . array ( [ [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] , ] ) , mx . nd . array ( [ [ - np . inf , [number] , [number] , [number] , [number] , [number] , np . inf , ] , [ - np . inf , [number] , [number] , [number] , [number] , [number] , np . inf , ] , [ - np . inf , [number] , [number] , [number] , [number] , [number] , np . inf , ] , [ - np . inf , [number] , [number] , [number] , [number] , [number] , np . inf , ] , [ - [number] , - [number] , - [number] , - [number] , - [number] , - [number] , - [number] , ] , [ - np . inf , [number] , [number] , [number] , [number] , [number] , np . inf , ] , ] ) , mx . nd . array ( [ [ - [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , ] , [ - [number] , - [number] , - [number] , - [number] , - [number] , - [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , ] , ] ) , mx . nd . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , ] ) , ) , ] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , la_binning_cases , ) def test_la_binning ( r , target , observed , exp_bin_edges , exp_bin_centers , expected_repr ) : [EOL] target_transf , _ , rep_params = r ( target , observed , None , [ ] ) [EOL] bin_centers_hyb = rep_params [ [number] ] . asnumpy ( ) [EOL] bin_edges_hyb = rep_params [ [number] ] . asnumpy ( ) [EOL] [EOL] assert np . allclose ( exp_bin_edges . asnumpy ( ) , bin_edges_hyb ) , f" [string] { exp_bin_edges } [string] { bin_edges_hyb } [string] " [EOL] assert np . allclose ( exp_bin_centers . asnumpy ( ) , bin_centers_hyb ) , f" [string] { exp_bin_centers } [string] { bin_centers_hyb } [string] " [EOL] assert np . allclose ( expected_repr . asnumpy ( ) , target_transf . asnumpy ( ) ) , f" [string] { expected_repr } [string] { target_transf } [string] " [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import pytest [EOL] import mxnet as mx [EOL] import numpy as np [EOL] [EOL] from gluonts . mx . representation import ( HybridRepresentation , CustomBinning , LocalAbsoluteBinning , DimExpansion , RepresentationChain , ) [EOL] [EOL] [EOL] hyb_cases = [ ( HybridRepresentation ( representations = [ RepresentationChain ( chain = [ CustomBinning ( bin_centers = np . linspace ( - [number] , [number] , [number] ) ) , DimExpansion ( ) , ] ) , RepresentationChain ( chain = [ CustomBinning ( bin_centers = np . linspace ( - [number] , [number] , [number] ) ) , DimExpansion ( ) , ] ) , ] ) , mx . nd . array ( [ [ - [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] , ] ) , mx . nd . array ( [ [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] , ] ) , [ mx . nd . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , ] ) , mx . nd . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , ] ) , ] , ) , ( HybridRepresentation ( representations = [ RepresentationChain ( chain = [ CustomBinning ( bin_centers = np . linspace ( - [number] , [number] , [number] ) ) , DimExpansion ( ) , ] ) , RepresentationChain ( chain = [ LocalAbsoluteBinning ( num_bins = [number] , is_quantile = True ) , DimExpansion ( ) , ] ) , ] ) , mx . nd . array ( [ [ - [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] , ] ) , mx . nd . array ( [ [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] , ] ) , [ mx . nd . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , ] ) , mx . nd . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , ] ) , ] , ) , ( HybridRepresentation ( representations = [ RepresentationChain ( chain = [ LocalAbsoluteBinning ( num_bins = [number] , is_quantile = True ) , DimExpansion ( ) , ] ) , ] ) , mx . nd . array ( [ [ - [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] , ] ) , mx . nd . array ( [ [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] , ] ) , [ mx . nd . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , ] ) , ] , ) , ] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , hyb_cases , ) def test_hyb ( r , target , observed , expected_repr ) : [EOL] r . initialize_from_array ( np . array ( [ ] ) , mx . context . cpu ( ) ) [EOL] target_transf , _ , _ = r ( target , observed , None , [ ] ) [EOL] [EOL] for i in range ( len ( expected_repr ) ) : [EOL] exp_loc = expected_repr [ i ] . asnumpy ( ) [EOL] target_loc = target_transf [ : , : , i ] . asnumpy ( ) [EOL] print ( target_loc ) [EOL] assert np . allclose ( exp_loc , target_loc ) , f" [string] { exp_loc } [string] { target_loc } [string] " [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import pytest [EOL] import mxnet as mx [EOL] import numpy as np [EOL] [EOL] from gluonts . mx . representation import GlobalRelativeBinning [EOL] [EOL] [EOL] gr_binning_cases = [ ( GlobalRelativeBinning ( num_bins = [number] , is_quantile = True , quantile_scaling_limit = [number] , ) , mx . nd . array ( [ [ - [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , ] ) , mx . nd . array ( [ [ - [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] , ] ) , mx . nd . array ( [ [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] , ] ) , mx . nd . array ( [ - np . inf , [number] , [number] , [number] , [number] , [number] , np . inf , ] ) , mx . nd . array ( [ - [number] , [number] , [number] , [number] , [number] , [number] ] ) , mx . nd . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , ] ) , ) , ( GlobalRelativeBinning ( num_bins = [number] , is_quantile = True , quantile_scaling_limit = [number] , ) , mx . nd . array ( [ [ - [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , ] ) , mx . nd . array ( [ [ - [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] , ] ) , mx . nd . array ( [ [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] , ] ) , mx . nd . array ( [ - np . inf , [number] , [number] , [number] , [number] , [number] , [number] , [number] , np . inf , ] ) , mx . nd . array ( [ - [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] ) , mx . nd . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , ] ) , ) , ( GlobalRelativeBinning ( num_bins = [number] , is_quantile = False , quantile_scaling_limit = [number] , ) , mx . nd . array ( [ [ - [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , ] ) , mx . nd . array ( [ [ - [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] , ] ) , mx . nd . array ( [ [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] , ] ) , mx . nd . array ( [ - np . inf , - [number] , - [number] , [number] , [number] , [number] , np . inf ] ) , mx . nd . array ( [ - [number] , - [number] , - [number] , [number] , [number] , [number] ] ) , mx . nd . array ( [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , ] , ] ) , ) , ] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , gr_binning_cases , ) def test_gr_binning ( r , dataset , target , observed , exp_bin_edges , exp_bin_centers , expected_repr ) : [EOL] r . initialize_from_array ( dataset . asnumpy ( ) , mx . context . cpu ( ) ) [EOL] target_transf , _ , rep_params = r ( target , observed , None , [ ] ) [EOL] bin_centers_hyb = rep_params [ [number] ] [EOL] bin_edges = rep_params [ [number] ] [EOL] [EOL] exp_bin_centers = mx . nd . repeat ( mx . nd . expand_dims ( exp_bin_centers , axis = [number] ) , len ( bin_centers_hyb ) , axis = [number] , ) [EOL] [EOL] assert np . allclose ( exp_bin_edges . asnumpy ( ) , bin_edges . asnumpy ( ) ) , f" [string] { exp_bin_edges } [string] { bin_edges . asnumpy ( ) } [string] " [EOL] assert np . allclose ( exp_bin_centers . asnumpy ( ) , bin_centers_hyb . asnumpy ( ) ) , f" [string] { exp_bin_centers } [string] { bin_centers_hyb . asnumpy ( ) } [string] " [EOL] assert np . allclose ( expected_repr . asnumpy ( ) , target_transf . asnumpy ( ) ) , f" [string] { expected_repr } [string] { target_transf } [string] " [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import pytest [EOL] import mxnet as mx [EOL] import numpy as np [EOL] [EOL] from gluonts . mx . representation import MeanScaling [EOL] [EOL] [EOL] mean_cases = [ ( MeanScaling ( ) , mx . nd . array ( [ [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] , ] ) , mx . nd . array ( [ [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] , ] ) , mx . nd . array ( [ [number] , [number] , [number] , [number] , [number] ] ) , ) , ( MeanScaling ( ) , mx . nd . array ( [ [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] + [ [number] ] * [number] , ] ) , mx . nd . array ( [ [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] + [ [number] ] * [number] , [ [number] ] * [number] , [ [number] ] * [number] + [ [number] ] * [number] + [ [number] ] * [number] , ] ) , mx . nd . array ( [ [number] , [number] , [number] , [number] ] ) , ) , ( MeanScaling ( ) , mx . nd . random . normal ( shape = ( [number] , [number] ) ) , mx . nd . zeros ( shape = ( [number] , [number] ) ) , [number] * mx . nd . ones ( shape = ( [number] , ) ) , ) , ] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , mean_cases ) def test_mean ( s , target , observed , expected_scale ) : [EOL] target_scaled , scale , _ = s ( target , observed , None , [ ] ) [EOL] scale = mx . nd . reshape ( scale , shape = ( len ( scale ) , ) ) [EOL] [EOL] assert np . allclose ( expected_scale . asnumpy ( ) , scale . asnumpy ( ) ) , [string] [EOL] [EOL] expected_target_scaled = mx . nd . broadcast_div ( target , expected_scale . expand_dims ( axis = [number] ) ) [EOL] [EOL] assert np . allclose ( expected_target_scaled . asnumpy ( ) , target_scaled . asnumpy ( ) ) , [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from gluonts . dataset . artificial import constant_dataset [EOL] from gluonts . dataset . parallelized_loader import ShuffleIter [EOL] import itertools [EOL] [EOL] [EOL] [comment] [EOL] def test_shuffle_iter ( ) : [EOL] [comment] [EOL] data = [ { str ( i ) : str ( i ) } for i in range ( [number] ) ] [EOL] shuffled_data = ShuffleIter ( base_iterator = iter ( data ) , shuffle_buffer_length = [number] ) [EOL] assert len ( list ( shuffled_data ) ) == [number] [EOL] [EOL] [comment] [EOL] ds_info , train_ds , test_ds = constant_dataset ( ) [EOL] base_iter , base_iter_backup = itertools . tee ( iter ( train_ds ) , [number] ) [EOL] shuffled_data = ShuffleIter ( base_iterator = base_iter , shuffle_buffer_length = [number] ) [EOL] assert len ( list ( shuffled_data ) ) == len ( list ( base_iter_backup ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import pytest [EOL] import numpy as np [EOL] [EOL] [comment] [EOL] from gluonts . dataset . common import ListDataset [EOL] from gluonts . dataset . multivariate_grouper import MultivariateGrouper [EOL] [EOL] UNIVARIATE_TS = [ [ { [string] : [string] , [string] : [ [number] , [number] , [number] , [number] ] } , { [string] : [string] , [string] : [ [number] , [number] , [number] , [number] ] } , ] , [ { [string] : [string] , [string] : [ [number] , [number] , [number] , [number] ] } , { [string] : [string] , [string] : [ [number] , [number] , [number] , [number] ] } , ] , [ { [string] : [string] , [string] : [ [number] , [number] , [number] , [number] ] } , { [string] : [string] , [string] : [ [number] ] } , ] , [ { [string] : [string] , [string] : [ [number] , [number] , [number] , [number] ] } , { [string] : [string] , [string] : [ [number] ] } , ] , [ { [string] : [string] , [string] : [ [number] , [number] , [number] , [number] ] } , { [string] : [string] , [string] : [ [number] , [number] , [number] , [number] ] } , ] , ] [EOL] [EOL] MULTIVARIATE_TS = [ [ { [string] : [string] , [string] : [ [ [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] ] ] } ] , [ { [string] : [string] , [string] : [ [ [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] ] ] , } ] , [ { [string] : [string] , [string] : [ [ [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] ] ] } ] , [ { [string] : [string] , [string] : [ [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , ] , } ] , [ { [string] : [string] , [string] : [ [ [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] ] ] } ] , ] [EOL] [EOL] TRAIN_FILL_RULE = [ np . mean , np . mean , np . mean , np . mean , lambda x : [number] ] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , zip ( UNIVARIATE_TS , MULTIVARIATE_TS , TRAIN_FILL_RULE ) , ) def test_multivariate_grouper_train ( univariate_ts , multivariate_ts , train_fill_rule ) : [EOL] univariate_ds = ListDataset ( univariate_ts , freq = [string] ) [EOL] multivariate_ds = ListDataset ( multivariate_ts , freq = [string] , one_dim_target = False ) [EOL] [EOL] grouper = MultivariateGrouper ( train_fill_rule = train_fill_rule ) [EOL] assert ( list ( grouper ( univariate_ds ) ) [ [number] ] [ [string] ] == list ( multivariate_ds ) [ [number] ] [ [string] ] ) . all ( ) [EOL] [EOL] assert ( list ( grouper ( univariate_ds ) ) [ [number] ] [ [string] ] == list ( multivariate_ds ) [ [number] ] [ [string] ] ) [EOL] [EOL] [EOL] UNIVARIATE_TS_TEST = [ [ { [string] : [string] , [string] : [ [number] , [number] , [number] , [number] ] } , { [string] : [string] , [string] : [ [number] , [number] , [number] , [number] ] } , { [string] : [string] , [string] : [ [number] , [number] , [number] , [number] ] } , { [string] : [string] , [string] : [ [number] , [number] , [number] , [number] ] } , ] , [ { [string] : [string] , [string] : [ [number] , [number] , [number] , [number] ] } , { [string] : [string] , [string] : [ [number] , [number] , [number] , [number] ] } , { [string] : [string] , [string] : [ [number] , [number] , [number] , [number] ] } , { [string] : [string] , [string] : [ [number] , [number] , [number] , [number] ] } , ] , ] [EOL] [EOL] MULTIVARIATE_TS_TEST = [ [ { [string] : [string] , [string] : [ [ [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] ] ] } , { [string] : [string] , [string] : [ [ [number] , [number] , [number] , [number] , [number] ] , [ [number] , [number] , [number] , [number] , [number] ] ] } , ] , [ { [string] : [string] , [string] : [ [ [number] , [number] , [number] , [number] ] ] } , { [string] : [string] , [string] : [ [ [number] , [number] , [number] , [number] , [number] ] ] } , ] , ] [EOL] [EOL] TEST_FILL_RULE = [ lambda x : [number] , lambda x : [number] ] [EOL] MAX_TARGET_DIM = [ [number] , [number] ] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , zip ( UNIVARIATE_TS_TEST , MULTIVARIATE_TS_TEST , TEST_FILL_RULE , MAX_TARGET_DIM , ) , ) def test_multivariate_grouper_test ( univariate_ts , multivariate_ts , test_fill_rule , max_target_dim ) : [EOL] univariate_ds = ListDataset ( univariate_ts , freq = [string] ) [EOL] multivariate_ds = ListDataset ( multivariate_ts , freq = [string] , one_dim_target = False ) [EOL] [EOL] grouper = MultivariateGrouper ( test_fill_rule = test_fill_rule , num_test_dates = [number] , max_target_dim = max_target_dim , ) [EOL] [EOL] for grouped_data , multivariate_data in zip ( grouper ( univariate_ds ) , multivariate_ds ) : [EOL] assert ( grouped_data [ [string] ] == multivariate_data [ [string] ] ) . all ( ) [EOL] [EOL] assert grouped_data [ [string] ] == multivariate_data [ [string] ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import gzip [EOL] import tempfile [EOL] from pathlib import Path [EOL] [EOL] import pytest [EOL] [EOL] from gluonts . dataset . common import FileDataset [EOL] [EOL] N = [number] [EOL] [EOL] data = [ [string] , ] * N [EOL] [EOL] [EOL] def test_jsonl ( ) : [EOL] with tempfile . TemporaryDirectory ( ) as path : [EOL] with Path ( path , [string] ) . open ( [string] ) as out_file : [EOL] for line in data : [EOL] out_file . write ( line + [string] ) [EOL] [EOL] assert len ( FileDataset ( path , freq = [string] ) ) == N [EOL] assert len ( list ( FileDataset ( path , freq = [string] ) ) ) == N [EOL] [EOL] [EOL] def test_jsonlgz ( ) : [EOL] with tempfile . TemporaryDirectory ( ) as path : [EOL] with gzip . open ( Path ( path , [string] ) , [string] ) as out_file : [EOL] for line in data : [EOL] out_file . write ( line + [string] ) [EOL] [EOL] assert len ( FileDataset ( path , freq = [string] ) ) == N [EOL] assert len ( list ( FileDataset ( path , freq = [string] ) ) ) == N [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import pytest [EOL] import pandas as pd [EOL] [EOL] from gluonts . dataset . common import ProcessStartField , ListDataset [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ] , ) def test_process_start_field ( freq , expected ) : [EOL] process = ProcessStartField . process [EOL] given = [string] [EOL] [EOL] assert process ( given , freq ) == pd . Timestamp ( expected , freq ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import numpy [EOL] import builtins [EOL] import json [EOL] import random [EOL] import tempfile [EOL] import time [EOL] import multiprocessing as mp [EOL] [EOL] [comment] [EOL] from collections import defaultdict [EOL] from pathlib import Path [EOL] [EOL] import numpy as np [EOL] import pandas as pd [EOL] from mxnet . context import current_context [EOL] from flaky import flaky [EOL] import pytest [EOL] [EOL] [comment] [EOL] from gluonts . dataset . field_names import FieldName [EOL] from gluonts . dataset . loader import ( TrainDataLoader , ValidationDataLoader , InferenceDataLoader , ) [EOL] from gluonts . dataset . common import ListDataset , FileDataset [EOL] from gluonts . transform import ( Chain , UniformSplitSampler , InstanceSplitter , InstanceSampler , ) [EOL] from gluonts . dataset . artificial import ConstantDataset [EOL] [EOL] from gluonts . model . deepar import DeepAREstimator [EOL] from gluonts . evaluation . backtest import backtest_metrics [EOL] from gluonts . mx . trainer import Trainer [EOL] from gluonts . dataset . artificial import constant_dataset [EOL] from gluonts . evaluation import Evaluator [EOL] [EOL] [comment] [EOL] [EOL] BATCH_SIZE = [number] [EOL] NUM_WORKERS_MP = [number] [EOL] CONTEXT_LEN = [number] [EOL] SPLITTING_SAMPLE_PROBABILITY = [number] [comment] [EOL] CD_NUM_STEPS = [number] [EOL] CD_NUM_TIME_SERIES = [number] [comment] [EOL] CD_MAX_LEN_MULTIPLICATION_FACTOR = [number] [EOL] [EOL] [comment] [EOL] assert CD_NUM_TIME_SERIES % NUM_WORKERS_MP != [number] [EOL] [EOL] [comment] [EOL] [EOL] _data_cache = None [EOL] [EOL] [comment] [EOL] def delete_cache ( ) : [EOL] global _data_cache [EOL] if _data_cache is not None : [EOL] del _data_cache [EOL] [EOL] [EOL] [comment] [EOL] def get_dataset_and_transformation ( ) : [EOL] [comment] [EOL] global _data_cache [EOL] if _data_cache is not None : [EOL] return _data_cache [EOL] [EOL] [comment] [EOL] [comment] [EOL] dataset = ConstantDataset ( num_steps = CD_NUM_STEPS , num_timeseries = CD_NUM_TIME_SERIES ) [EOL] list_dataset = list ( dataset . train ) [EOL] for i , ts in enumerate ( list_dataset ) : [EOL] ts [ [string] ] = pd . Timestamp ( ts_input = ts [ [string] ] , freq = dataset . freq ) [EOL] [comment] [EOL] ts [ [string] ] = np . array ( ts [ [string] ] * random . randint ( [number] , CD_MAX_LEN_MULTIPLICATION_FACTOR ) ) [EOL] list_dataset = ListDataset ( data_iter = list_dataset , freq = dataset . freq ) [EOL] list_dataset_pred_length = dataset . prediction_length [EOL] [EOL] [comment] [EOL] transformation = Chain ( [ InstanceSplitter ( target_field = FieldName . TARGET , is_pad_field = FieldName . IS_PAD , start_field = FieldName . START , forecast_start_field = FieldName . FORECAST_START , train_sampler = UniformSplitSampler ( p = SPLITTING_SAMPLE_PROBABILITY ) , past_length = CONTEXT_LEN , future_length = list_dataset_pred_length , dummy_value = [number] , ) , ] ) [EOL] [EOL] [comment] [EOL] train_data_transformed_original = list ( ValidationDataLoader ( dataset = list_dataset , transform = transformation , batch_size = BATCH_SIZE , num_workers = [number] , ctx = current_context ( ) , ) ) [EOL] [EOL] _data_cache = ( list_dataset , transformation , list_dataset_pred_length , train_data_transformed_original , ) [EOL] [EOL] return _data_cache [EOL] [EOL] [EOL] [comment] [EOL] def get_transformation_counts ( dataset ) : [EOL] transformation_counts = { } [EOL] for batch in dataset : [EOL] for ts_id in batch [ [string] ] : [EOL] ts_id = int ( ts_id ) [EOL] if not ts_id in transformation_counts : [EOL] transformation_counts [ ts_id ] = [number] [EOL] else : [EOL] transformation_counts [ ts_id ] += [number] [EOL] return transformation_counts [EOL] [EOL] [EOL] [comment] [EOL] def test_validation_loader_equivalence ( ) : [EOL] ( list_dataset , transformation , list_dataset_pred_length , train_data_transformed_original , ) = get_dataset_and_transformation ( ) [EOL] current_desired_context = current_context ( ) [EOL] [EOL] validation_dataset_loader = ValidationDataLoader ( dataset = list_dataset , transform = transformation , batch_size = BATCH_SIZE , num_workers = NUM_WORKERS_MP , ctx = current_desired_context , ) [EOL] [EOL] [comment] [EOL] mp_val_data_loader_result_01 = list ( validation_dataset_loader ) [EOL] [EOL] [comment] [EOL] mp_val_data_loader_result_02 = list ( validation_dataset_loader ) [EOL] [EOL] [comment] [EOL] [EOL] assert len ( list_dataset . list_data ) == len ( get_transformation_counts ( mp_val_data_loader_result_01 ) ) , [string] [EOL] [EOL] assert get_transformation_counts ( mp_val_data_loader_result_01 ) == get_transformation_counts ( train_data_transformed_original ) , [string] [EOL] [EOL] assert get_transformation_counts ( mp_val_data_loader_result_02 ) == get_transformation_counts ( train_data_transformed_original ) , [string] [EOL] [EOL] assert ( mp_val_data_loader_result_02 [ [number] ] [ [string] ] . context == current_desired_context ) , [string] [EOL] [EOL] [EOL] @ flaky ( max_runs = [number] , min_passes = [number] ) @ pytest . mark . parametrize ( [string] , [ i for i in [ None , [number] , [number] , ] if i is None or i <= mp . cpu_count ( ) ] , ) def test_train_loader_goes_over_all_data ( num_workers ) : [EOL] batch_size = [number] [EOL] num_batches_per_epoch = [number] [EOL] [EOL] X = [number] [EOL] [EOL] simple_data = [ { [string] : [string] , [string] : np . random . uniform ( size = [number] ) . astype ( float ) . tolist ( ) , [string] : i , } for i in range ( batch_size * num_batches_per_epoch * X ) ] [EOL] [EOL] num_passes = [number] [EOL] num_epochs = X * num_passes [EOL] [EOL] def test_dataset ( dataset ) : [EOL] class ExactlyOneSampler ( InstanceSampler ) : [EOL] def __call__ ( self , ts , a , b ) : [EOL] window_size = b - a + [number] [EOL] assert window_size > [number] [EOL] return np . array ( [ a ] ) [EOL] [EOL] transformation = InstanceSplitter ( target_field = FieldName . TARGET , is_pad_field = FieldName . IS_PAD , start_field = FieldName . START , forecast_start_field = FieldName . FORECAST_START , train_sampler = ExactlyOneSampler ( ) , past_length = [number] , future_length = [number] , dummy_value = [number] , ) [EOL] [EOL] dl = TrainDataLoader ( dataset = dataset , transform = transformation , batch_size = batch_size , num_workers = num_workers , num_batches_per_epoch = num_batches_per_epoch , ctx = current_context ( ) , ) [EOL] [EOL] item_ids = defaultdict ( int ) [EOL] [EOL] for epoch in range ( num_epochs ) : [EOL] for batch in dl : [EOL] for item_id in batch [ [string] ] : [EOL] item_ids [ item_id ] += [number] [EOL] [EOL] for i in range ( len ( dataset ) ) : [EOL] assert num_passes - [number] <= item_ids [ i ] <= num_passes + [number] [EOL] [EOL] test_dataset ( ListDataset ( simple_data , freq = [string] ) ) [EOL] [EOL] with tempfile . TemporaryDirectory ( ) as tmpdir : [EOL] with open ( tmpdir + [string] , [string] ) as f : [EOL] for data in simple_data : [EOL] json . dump ( data , f ) [EOL] f . write ( [string] ) [EOL] [EOL] test_dataset ( FileDataset ( Path ( tmpdir ) , freq = [string] ) ) [EOL] test_dataset ( FileDataset ( Path ( tmpdir ) , freq = [string] , cache = True ) ) [EOL] [EOL] [EOL] [comment] [EOL] def test_inference_loader_equivalence ( ) : [EOL] ( list_dataset , transformation , list_dataset_pred_length , train_data_transformed_original , ) = get_dataset_and_transformation ( ) [EOL] current_desired_context = current_context ( ) [EOL] [EOL] [comment] [EOL] inference_loader_data_transformed_original = list ( InferenceDataLoader ( dataset = list_dataset , transform = transformation , batch_size = BATCH_SIZE , num_workers = [number] , ctx = current_context ( ) , ) ) [EOL] [EOL] inference_loader = InferenceDataLoader ( dataset = list_dataset , transform = transformation , batch_size = BATCH_SIZE , num_workers = NUM_WORKERS_MP , ctx = current_context ( ) , ) [EOL] [EOL] [comment] [EOL] mp_inf_data_loader_result_01 = list ( inference_loader ) [EOL] [EOL] [comment] [EOL] mp_inf_data_loader_result_02 = list ( inference_loader ) [EOL] [EOL] [comment] [EOL] [EOL] assert get_transformation_counts ( mp_inf_data_loader_result_01 ) == get_transformation_counts ( inference_loader_data_transformed_original ) , [string] [EOL] [EOL] assert get_transformation_counts ( mp_inf_data_loader_result_02 ) == get_transformation_counts ( inference_loader_data_transformed_original ) , [string] [EOL] [EOL] assert ( mp_inf_data_loader_result_02 [ [number] ] [ [string] ] . context == current_desired_context ) , [string] [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] def test_training_loader_batch_size_hard_constraint ( ) : [EOL] ( list_dataset , transformation , list_dataset_pred_length , train_data_transformed_original , ) = get_dataset_and_transformation ( ) [EOL] [EOL] train_dataset_loader_01 = TrainDataLoader ( dataset = list_dataset , transform = transformation , batch_size = BATCH_SIZE , num_workers = NUM_WORKERS_MP , ctx = current_context ( ) , num_batches_per_epoch = [number] , ) [EOL] [EOL] train_dataset_loader_02 = TrainDataLoader ( dataset = list_dataset , transform = transformation , batch_size = BATCH_SIZE , num_workers = NUM_WORKERS_MP , ctx = current_context ( ) , num_batches_per_epoch = [number] , shuffle_buffer_length = [number] * BATCH_SIZE , ) [EOL] [EOL] [comment] [EOL] mp_training_data_loader_result_01 = list ( train_dataset_loader_01 ) [EOL] [EOL] [comment] [EOL] mp_training_data_loader_result_02 = list ( train_dataset_loader_02 ) [EOL] [EOL] assert all ( [ len ( batch [ [string] ] ) == BATCH_SIZE for batch in mp_training_data_loader_result_01 ] ) , [string] [EOL] [EOL] assert all ( [ len ( batch [ [string] ] ) == BATCH_SIZE for batch in mp_training_data_loader_result_02 ] ) , [string] [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] @ pytest . mark . xfail ( reason = [string] ) @ flaky ( max_runs = [number] , min_passes = [number] ) def test_training_loader_soft_constraint_01 ( ) : [EOL] ( list_dataset , transformation , list_dataset_pred_length , train_data_transformed_original , ) = get_dataset_and_transformation ( ) [EOL] [EOL] [comment] [EOL] exp_num_batches = len ( train_data_transformed_original ) [EOL] [EOL] [comment] [EOL] [EOL] train_dataset_loader_01 = TrainDataLoader ( dataset = list_dataset , transform = transformation , batch_size = BATCH_SIZE , num_workers = NUM_WORKERS_MP , ctx = current_context ( ) , num_batches_per_epoch = int ( [number] * exp_num_batches ) , ) [EOL] [EOL] [comment] [EOL] time . sleep ( [number] ) [EOL] [EOL] [comment] [EOL] mp_training_data_loader_result_01 = list ( train_dataset_loader_01 ) [EOL] [EOL] [comment] [EOL] transformation_counts_01 = get_transformation_counts ( mp_training_data_loader_result_01 ) [EOL] [EOL] assert all ( [ k in transformation_counts_01 for k in range ( CD_NUM_TIME_SERIES ) ] ) , [string] [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] @ flaky ( max_runs = [number] , min_passes = [number] ) def test_training_loader_soft_constraint_02 ( ) : [EOL] ( list_dataset , transformation , list_dataset_pred_length , train_data_transformed_original , ) = get_dataset_and_transformation ( ) [EOL] [EOL] [comment] [EOL] exp_num_batches = len ( train_data_transformed_original ) [EOL] [EOL] [comment] [EOL] [EOL] train_dataset_loader_02 = TrainDataLoader ( dataset = list_dataset , transform = transformation , batch_size = BATCH_SIZE , num_workers = NUM_WORKERS_MP , ctx = current_context ( ) , num_batches_per_epoch = int ( [number] * exp_num_batches ) , ) [EOL] [EOL] [comment] [EOL] mp_training_data_loader_result_02 = list ( train_dataset_loader_02 ) [EOL] [EOL] [comment] [EOL] transformation_counts_02 = get_transformation_counts ( mp_training_data_loader_result_02 ) [EOL] [EOL] assert not all ( [ k in transformation_counts_02 for k in range ( CD_NUM_TIME_SERIES ) ] ) , [string] [EOL] [EOL] [EOL] [comment] [EOL] def test_training_loader_soft_constraint_03 ( ) : [EOL] ( list_dataset , transformation , list_dataset_pred_length , train_data_transformed_original , ) = get_dataset_and_transformation ( ) [EOL] [EOL] [comment] [EOL] exp_num_batches = len ( train_data_transformed_original ) [EOL] [EOL] [comment] [EOL] [EOL] train_dataset_loader_03 = TrainDataLoader ( dataset = list_dataset , transform = transformation , batch_size = BATCH_SIZE , num_workers = [number] , ctx = current_context ( ) , num_batches_per_epoch = int ( [number] * exp_num_batches ) , ) [EOL] [EOL] [comment] [EOL] mp_training_data_loader_result_03 = list ( train_dataset_loader_03 ) [EOL] [EOL] [comment] [EOL] transformation_counts_03 = get_transformation_counts ( mp_training_data_loader_result_03 ) [EOL] [EOL] assert all ( k in transformation_counts_03 for k in range ( CD_NUM_TIME_SERIES ) ) , [string] [EOL] [EOL] [EOL] [comment] [EOL] def test_general_functionality ( ) : [EOL] ds_info , train_ds , test_ds = constant_dataset ( ) [EOL] freq = ds_info . metadata . freq [EOL] prediction_length = ds_info . prediction_length [EOL] [EOL] ctx = [string] [EOL] trainer = Trainer ( ctx = ctx , epochs = [number] , num_batches_per_epoch = [number] ) [EOL] [EOL] estimator = DeepAREstimator ( prediction_length = prediction_length , freq = freq , trainer = trainer ) [EOL] [EOL] predictor = estimator . train ( training_data = train_ds ) [EOL] [EOL] agg_metrics , item_metrics = backtest_metrics ( test_dataset = test_ds , predictor = predictor , evaluator = Evaluator ( calculate_owa = False ) , ) [EOL] [EOL] [comment] [EOL] assert ( agg_metrics is not None and item_metrics is not None ) , [string] [EOL] [EOL] [EOL] [comment] [EOL] delete_cache ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 $numpy.ndarray$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] import gluonts [EOL] import builtins [EOL] import itertools [EOL] from functools import partial [EOL] [EOL] [comment] [EOL] import mxnet as mx [EOL] import numpy as np [EOL] import pandas as pd [EOL] import pytest [EOL] [EOL] [comment] [EOL] from gluonts . dataset . common import ListDataset [EOL] from gluonts . dataset . loader import ( DataLoader , TrainDataLoader , InferenceDataLoader , ) [EOL] from gluonts . dataset . parallelized_loader import batchify , stack , _pad_arrays [EOL] from gluonts . transform import ( ContinuousTimeInstanceSplitter , ContinuousTimeUniformSampler , ) [EOL] [EOL] [EOL] @ pytest . fixture def pp_dataset ( ) : [EOL] def get_dataset ( ) : [EOL] [EOL] data_entry_list = [ { [string] : np . c_ [ np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) , np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) , ] . T , [string] : pd . Timestamp ( [string] , freq = [string] ) , [string] : pd . Timestamp ( [string] , freq = [string] ) , } , { [string] : np . c_ [ np . array ( [ [number] , [number] , [number] , [number] , [number] ] ) , np . array ( [ [number] , [number] , [number] , [number] , [number] ] ) , ] . T , [string] : pd . Timestamp ( [string] , freq = [string] ) , [string] : pd . Timestamp ( [string] , freq = [string] ) , } , { [string] : np . c_ [ np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) , np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) , ] . T , [string] : pd . Timestamp ( [string] , freq = [string] ) , [string] : pd . Timestamp ( [string] , freq = [string] ) , } , ] [EOL] [EOL] return ListDataset ( data_entry_list , freq = [string] , one_dim_target = False , ) [EOL] [EOL] return get_dataset [EOL] [EOL] [EOL] @ pytest . fixture def loader_factory ( ) : [EOL] [comment] [EOL] def train_loader ( dataset , prediction_interval_length , context_interval_length , is_train = True , override_args = None , ) : [EOL] [EOL] if override_args is None : [EOL] override_args = { } [EOL] [EOL] splitter = ContinuousTimeInstanceSplitter ( future_interval_length = prediction_interval_length , past_interval_length = context_interval_length , train_sampler = ContinuousTimeUniformSampler ( num_instances = [number] ) , ) [EOL] [EOL] kwargs = dict ( dataset = dataset , transform = splitter , batch_size = [number] , ctx = mx . cpu ( ) , dtype = np . float32 , batchify_fn = partial ( batchify , variable_length = True ) , ) [EOL] kwargs . update ( override_args ) [EOL] [EOL] if is_train : [EOL] return TrainDataLoader ( num_batches_per_epoch = [number] , num_workers = [number] , ** kwargs ) [EOL] else : [EOL] return InferenceDataLoader ( num_workers = [number] , ** kwargs ) [EOL] [EOL] return train_loader [EOL] [EOL] [EOL] def test_train_loader_shapes ( loader_factory , pp_dataset ) : [EOL] dataset = pp_dataset ( ) [EOL] loader = loader_factory ( dataset , [number] , [number] ) [EOL] [EOL] d = next ( iter ( loader ) ) [EOL] [EOL] field_names = [ [string] , [string] , [string] , [string] , ] [EOL] [EOL] assert all ( [ key in d for key in field_names ] ) [EOL] [EOL] assert d [ [string] ] . shape [ [number] ] == d [ [string] ] . shape [ [number] ] == [number] [EOL] assert d [ [string] ] . shape [ [number] ] == d [ [string] ] . shape [ [number] ] == [number] [EOL] assert ( d [ [string] ] . shape [ [number] ] == d [ [string] ] . shape [ [number] ] == [number] ) [EOL] [EOL] [EOL] def test_train_loader_length ( loader_factory , pp_dataset ) : [EOL] dataset = pp_dataset ( ) [EOL] loader = loader_factory ( dataset , [number] , [number] ) [EOL] [EOL] batches = list ( iter ( loader ) ) [EOL] [EOL] assert len ( batches ) == [number] [EOL] [EOL] [EOL] def test_inference_loader_shapes ( loader_factory , pp_dataset ) : [EOL] loader = loader_factory ( dataset = pp_dataset ( ) , prediction_interval_length = [number] , context_interval_length = [number] , is_train = False , override_args = { [string] : [number] } , ) [EOL] [EOL] batches = list ( iter ( loader ) ) [EOL] [EOL] assert len ( batches ) == [number] [EOL] [EOL] d = batches [ [number] ] [EOL] [EOL] assert d [ [string] ] . shape [ [number] ] == [number] [EOL] assert d [ [string] ] . shape [ [number] ] == [number] [EOL] assert d [ [string] ] . shape [ [number] ] == [number] [EOL] [EOL] [EOL] def test_inference_loader_shapes_small_batch ( loader_factory , pp_dataset ) : [EOL] loader = loader_factory ( dataset = pp_dataset ( ) , prediction_interval_length = [number] , context_interval_length = [number] , is_train = False , override_args = { [string] : [number] } , ) [EOL] [EOL] batches = list ( iter ( loader ) ) [EOL] [EOL] assert len ( batches ) == [number] [EOL] [EOL] d = batches [ [number] ] [EOL] [EOL] assert d [ [string] ] . shape [ [number] ] == [number] [EOL] assert d [ [string] ] . shape [ [number] ] == [number] [EOL] assert d [ [string] ] . shape [ [number] ] == [number] [EOL] [EOL] [EOL] def test_train_loader_short_intervals ( loader_factory , pp_dataset ) : [EOL] loader = loader_factory ( dataset = pp_dataset ( ) , prediction_interval_length = [number] , context_interval_length = [number] , is_train = True , override_args = { [string] : [number] } , ) [EOL] [EOL] batches = list ( iter ( loader ) ) [EOL] [EOL] d = batches [ [number] ] [EOL] [EOL] assert d [ [string] ] . shape [ [number] ] == d [ [string] ] . shape [ [number] ] == [number] [EOL] assert d [ [string] ] . shape [ [number] ] == d [ [string] ] . shape [ [number] ] == [number] [EOL] [EOL] [EOL] def test_inference_loader_short_intervals ( loader_factory , pp_dataset ) : [EOL] loader = loader_factory ( dataset = pp_dataset ( ) , prediction_interval_length = [number] , context_interval_length = [number] , is_train = False , override_args = { [string] : [number] } , ) [EOL] [EOL] batches = list ( iter ( loader ) ) [EOL] [EOL] d = batches [ [number] ] [EOL] [EOL] assert d [ [string] ] . shape [ [number] ] == [number] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , itertools . product ( [ [string] , [string] ] , [ True , False ] ) , ) def test_variable_length_stack ( pp_dataset , array_type , multi_processing ) : [EOL] arrays = [ d [ [string] ] . T if array_type == [string] else mx . nd . array ( d [ [string] ] . T ) for d in list ( iter ( pp_dataset ( ) ) ) ] [EOL] [EOL] assert isinstance ( multi_processing , bool ) [EOL] stacked = stack ( arrays , multi_processing = multi_processing , dtype = arrays [ [number] ] . dtype , variable_length = True , ) [EOL] [EOL] assert stacked . shape [ [number] ] == [number] [EOL] assert stacked . shape [ [number] ] > [number] [EOL] assert stacked . shape [ [number] ] == [number] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , itertools . product ( [ [string] , [string] ] , [ True , False ] ) , ) def test_variable_length_stack_zerosize ( pp_dataset , array_type , multi_processing ) : [EOL] arrays = [ np . zeros ( shape = ( [number] , [number] ) ) [EOL] if array_type == [string] [EOL] else mx . nd . array ( np . zeros ( shape = ( [number] , [number] ) ) ) for _ in range ( [number] ) ] [EOL] [EOL] assert isinstance ( multi_processing , bool ) [EOL] stacked = stack ( arrays , multi_processing = multi_processing , dtype = arrays [ [number] ] . dtype , variable_length = True , ) [EOL] [EOL] assert stacked . shape [ [number] ] == [number] [EOL] assert stacked . shape [ [number] ] == [number] [EOL] assert stacked . shape [ [number] ] == [number] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , itertools . product ( [ [string] , [string] ] , [ True , False ] , [ [number] , [number] ] ) , ) def test_pad_arrays_axis ( pp_dataset , array_type , multi_processing , axis ) : [EOL] arrays = [ d [ [string] ] if array_type == [string] else mx . nd . array ( d [ [string] ] ) for d in list ( iter ( pp_dataset ( ) ) ) ] [EOL] if axis == [number] : [EOL] arrays = [ x . T for x in arrays ] [EOL] [EOL] padded_arrays = _pad_arrays ( arrays , axis ) [EOL] [EOL] assert all ( a . shape [ axis ] == [number] for a in padded_arrays ) [EOL] assert all ( a . shape [ [number] - axis ] == [number] for a in padded_arrays ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.loader.DataLoader$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Iterator , Any [EOL] import typing [EOL] import builtins [EOL] import pathlib [EOL] import json [EOL] import tempfile [EOL] from pathlib import Path [EOL] from typing import Any , Iterator [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] import pandas as pd [EOL] import pytest [EOL] import ujson [EOL] from pandas import Timestamp [EOL] [EOL] [comment] [EOL] from gluonts . dataset . common import ( FileDataset , ListDataset , MetaData , serialize_data_entry , ) [EOL] from gluonts . dataset . common import ProcessDataEntry [EOL] from gluonts . dataset . artificial import ComplexSeasonalTimeSeries [EOL] from gluonts . dataset . jsonl import JsonLinesFile [EOL] from gluonts . dataset . util import find_files [EOL] from gluonts . support . util import Timer [EOL] [EOL] [EOL] def baseline ( path , freq ) : [EOL] for file in find_files ( path , FileDataset . is_valid ) : [EOL] for line in open ( file ) : [EOL] yield line [EOL] [EOL] [EOL] def load_json ( path , freq ) : [EOL] for file in find_files ( path , FileDataset . is_valid ) : [EOL] for line in open ( file ) : [EOL] yield json . loads ( line ) [EOL] [EOL] [EOL] def load_ujson ( path , freq ) : [EOL] for file in find_files ( path , FileDataset . is_valid ) : [EOL] for line in open ( file ) : [EOL] yield ujson . loads ( line ) [EOL] [EOL] [EOL] def load_json_lines_file ( path , freq ) : [EOL] for file in find_files ( path , FileDataset . is_valid ) : [EOL] yield from JsonLinesFile ( file ) [EOL] [EOL] [EOL] def load_file_dataset ( path , freq ) : [EOL] return iter ( FileDataset ( path , freq ) ) [EOL] [EOL] [EOL] def load_file_dataset_cached ( path , freq ) : [EOL] return iter ( FileDataset ( path , freq , cache = True ) ) [EOL] [EOL] [EOL] def load_file_dataset_numpy ( path , freq ) : [EOL] for item in FileDataset ( path , freq ) : [EOL] item [ [string] ] = pd . Timestamp ( item [ [string] ] ) [EOL] item [ [string] ] = np . array ( item [ [string] ] ) [EOL] yield item [EOL] [EOL] [EOL] def load_parsed_dataset ( path , freq ) : [EOL] yield from FileDataset ( path , freq ) [EOL] [EOL] [EOL] def load_list_dataset ( path , freq ) : [EOL] lines = ( line . content for line in load_json_lines_file ( path , freq ) ) [EOL] return iter ( ListDataset ( lines , freq ) ) [EOL] [EOL] [EOL] [comment] [EOL] def test_io_speed ( ) : [EOL] exp_size = [number] [EOL] act_size = [number] [EOL] [EOL] with Timer ( ) as timer : [EOL] dataset = ComplexSeasonalTimeSeries ( num_series = exp_size , freq_str = [string] , length_low = [number] , length_high = [number] , min_val = [number] , max_val = [number] , proportion_missing_values = [number] , ) . generate ( ) [EOL] print ( f" [string] { timer . interval } [string] " ) [EOL] [EOL] [comment] [EOL] fixtures = [ ( [string] , baseline , [number] ) , ( [string] , load_ujson , [number] ) , ( [string] , load_json_lines_file , [number] ) , ( [string] , load_list_dataset , [number] ) , ( [string] , load_file_dataset , [number] ) , ( [string] , load_file_dataset_cached , [number] ) , ( [string] , load_file_dataset_numpy , [number] ) , ( [string] , load_parsed_dataset , [number] ) , ] [EOL] [EOL] with tempfile . TemporaryDirectory ( ) as path : [EOL] [comment] [EOL] with Timer ( ) as timer : [EOL] dataset . save ( path ) [EOL] print ( f" [string] { timer . interval } [string] " ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] rates = { } [EOL] for name , get_loader , _ in fixtures : [EOL] with Timer ( ) as timer : [EOL] loader = get_loader ( Path ( path ) / [string] , dataset . metadata . freq ) [EOL] for act_size , _ in enumerate ( loader , start = [number] ) : [EOL] pass [EOL] rates [ name ] = int ( act_size / max ( timer . interval , [number] ) ) [EOL] print ( f" [string] { name : [string] } [string] { rates [ name ] : [string] } [string] " f" [string] " ) [EOL] assert exp_size == act_size , ( f" [string] { name } [string] " f"{ exp_size } [string] " ) [EOL] [EOL] [comment] [EOL] for name , _ , min_rate in fixtures : [EOL] assert min_rate <= rates [ name ] , ( f" [string] { name } [string] { rates [ name ] } [string] " f" [string] { min_rate } [string] " ) [EOL] [EOL] [EOL] def test_loader_multivariate ( ) : [EOL] with tempfile . TemporaryDirectory ( ) as tmp_folder : [EOL] tmp_path = Path ( tmp_folder ) [EOL] [EOL] lines = [ [string] , ] [EOL] with open ( tmp_path / [string] , [string] ) as f : [EOL] f . write ( [string] . join ( lines ) ) [EOL] [EOL] ds = list ( FileDataset ( tmp_path , freq = [string] , one_dim_target = False ) ) [EOL] [EOL] assert ( ds [ [number] ] [ [string] ] == [ [ [number] , [number] , [number] ] ] ) . all ( ) [EOL] assert ds [ [number] ] [ [string] ] == Timestamp ( [string] , freq = [string] ) [EOL] [EOL] assert ( ds [ [number] ] [ [string] ] == [ [ - [number] , - [number] , [number] ] , [ [number] , [number] , [number] ] ] ) . all ( ) [EOL] assert ds [ [number] ] [ [string] ] == Timestamp ( [string] , freq = [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterator[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterator[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterator[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterator[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterator[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterator[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterator[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterator[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterator[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from gluonts . dataset . field_names import FieldName [EOL] [EOL] [EOL] def test_dataset_fields ( ) : [EOL] assert ( [string] == FieldName . FEAT_STATIC_CAT ) , [string] [EOL] assert ( [string] == FieldName . FEAT_STATIC_REAL ) , [string] [EOL] assert ( [string] == FieldName . FEAT_DYNAMIC_CAT ) , [string] [EOL] assert ( [string] == FieldName . FEAT_DYNAMIC_REAL ) , [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import numpy [EOL] import gluonts [EOL] import unittest [EOL] from typing import cast [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] import pandas as pd [EOL] [EOL] [comment] [EOL] from gluonts . core . exception import GluonTSDataError [EOL] from gluonts . dataset . common import DataEntry , Dataset [EOL] from gluonts . dataset . stat import ( DatasetStatistics , ScaleHistogram , calculate_dataset_statistics , ) [EOL] [EOL] [EOL] def make_dummy_dynamic_feat ( target , num_features ) : [EOL] [comment] [EOL] return np . vstack ( [ target * ( i + [number] ) for i in range ( num_features ) ] ) [EOL] [EOL] [EOL] [comment] [EOL] start = pd . Timestamp ( [string] , freq = [string] ) [EOL] target = np . random . randint ( [number] , [number] , [number] ) [EOL] fsc = [ [number] , [number] ] [EOL] fsr = [ [number] , [number] ] [EOL] [EOL] [EOL] def make_time_series ( start = start , target = target , feat_static_cat = fsc , feat_static_real = fsr , num_feat_dynamic_cat = [number] , num_feat_dynamic_real = [number] , num_past_feat_dynamic_real = [number] , ) : [EOL] feat_dynamic_cat = ( make_dummy_dynamic_feat ( target , num_feat_dynamic_cat ) . astype ( [string] ) [EOL] if num_feat_dynamic_cat > [number] [EOL] else None ) [EOL] feat_dynamic_real = ( make_dummy_dynamic_feat ( target , num_feat_dynamic_real ) . astype ( [string] ) [EOL] if num_feat_dynamic_real > [number] [EOL] else None ) [EOL] past_feat_dynamic_real = ( make_dummy_dynamic_feat ( target , num_past_feat_dynamic_real ) . astype ( [string] ) [EOL] if num_past_feat_dynamic_real > [number] [EOL] else None ) [EOL] data = { [string] : start , [string] : target , [string] : feat_static_cat , [string] : feat_static_real , [string] : feat_dynamic_cat , [string] : feat_dynamic_real , [string] : past_feat_dynamic_real , } [EOL] return data [EOL] [EOL] [EOL] def ts ( start , target , feat_static_cat = None , feat_static_real = None , feat_dynamic_cat = None , feat_dynamic_real = None , ) : [EOL] d = { [string] : start , [string] : target } [EOL] if feat_static_cat is not None : [EOL] d [ [string] ] = feat_static_cat [EOL] if feat_static_real is not None : [EOL] d [ [string] ] = feat_static_real [EOL] if feat_dynamic_cat is not None : [EOL] d [ [string] ] = feat_dynamic_cat [EOL] if feat_dynamic_real is not None : [EOL] d [ [string] ] = feat_dynamic_real [EOL] return d [EOL] [EOL] [EOL] class DatasetStatisticsTest ( unittest . TestCase ) : [EOL] def test_dataset_statistics ( self ) : [EOL] [EOL] n = [number] [EOL] T = [number] [EOL] [EOL] [comment] [EOL] np . random . seed ( [number] ) [EOL] targets = np . random . randint ( [number] , [number] , ( n , T ) ) [EOL] [EOL] scale_histogram = ScaleHistogram ( ) [EOL] for i in range ( n ) : [EOL] scale_histogram . add ( targets [ i , : ] ) [EOL] [EOL] scale_histogram . add ( [ ] ) [EOL] [EOL] expected = DatasetStatistics ( integer_dataset = True , num_time_series = n + [number] , num_time_observations = targets . size , mean_target_length = T * [number] / [number] , min_target = targets . min ( ) , mean_target = targets . mean ( ) , mean_abs_target = targets . mean ( ) , max_target = targets . max ( ) , feat_static_real = [ { [number] } , { [number] , [number] } ] , feat_static_cat = [ { [number] } , { [number] , [number] } ] , num_feat_dynamic_real = [number] , num_past_feat_dynamic_real = [number] , num_feat_dynamic_cat = [number] , num_missing_values = [number] , scale_histogram = scale_histogram , ) [EOL] [EOL] [comment] [EOL] timeseries = cast ( Dataset , [ make_time_series ( target = targets [ [number] , : ] , feat_static_cat = [ [number] , [number] ] , feat_static_real = [ [number] , [number] ] , num_feat_dynamic_cat = [number] , num_feat_dynamic_real = [number] , num_past_feat_dynamic_real = [number] , ) , make_time_series ( target = targets [ [number] , : ] , feat_static_cat = [ [number] , [number] ] , feat_static_real = [ [number] , [number] ] , num_feat_dynamic_cat = [number] , num_feat_dynamic_real = [number] , num_past_feat_dynamic_real = [number] , ) , make_time_series ( target = np . array ( [ ] ) , feat_static_cat = [ [number] , [number] ] , feat_static_real = [ [number] , [number] ] , num_feat_dynamic_cat = [number] , num_feat_dynamic_real = [number] , num_past_feat_dynamic_real = [number] , ) , ] , ) [EOL] [EOL] found = calculate_dataset_statistics ( timeseries ) [EOL] [EOL] assert expected == found [EOL] [EOL] def test_dataset_histogram ( self ) : [EOL] [EOL] [comment] [EOL] N = [number] [EOL] n = [number] ** N - [number] [EOL] T = [number] [EOL] targets = np . ones ( ( n , T ) ) [EOL] for i in range ( [number] , n ) : [EOL] targets [ i , : ] = targets [ i , : ] * i [EOL] [EOL] [comment] [EOL] timeseries = cast ( Dataset , [ make_time_series ( target = targets [ i , : ] ) for i in range ( n ) ] ) [EOL] [EOL] found = calculate_dataset_statistics ( timeseries ) [EOL] [EOL] hist = found . scale_histogram . bin_counts [EOL] for i in range ( [number] , N ) : [EOL] assert i in hist [EOL] assert hist [ i ] == [number] ** i [EOL] [EOL] [EOL] class DatasetStatisticsExceptions ( unittest . TestCase ) : [EOL] def test_dataset_statistics_exceptions ( self ) : [EOL] def check_error_message ( expected_regex , dataset ) : [EOL] with self . assertRaisesRegex ( GluonTSDataError , expected_regex ) : [EOL] calculate_dataset_statistics ( dataset ) [EOL] [EOL] check_error_message ( [string] , [ ] ) [EOL] [EOL] check_error_message ( [string] , [ make_time_series ( target = np . random . randint ( [number] , [number] , [number] ) ) ] , ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] check_error_message ( [string] [string] , [ make_time_series ( num_feat_dynamic_cat = [number] ) , make_time_series ( num_feat_dynamic_cat = [number] ) , ] , ) [EOL] check_error_message ( [string] [string] , [ make_time_series ( num_feat_dynamic_cat = [number] ) , make_time_series ( num_feat_dynamic_cat = [number] ) , ] , ) [EOL] check_error_message ( [string] , [ make_time_series ( num_feat_dynamic_cat = [number] ) , make_time_series ( num_feat_dynamic_cat = [number] ) , ] , ) [EOL] check_error_message ( [string] [string] , [ make_time_series ( num_feat_dynamic_real = [number] ) , make_time_series ( num_feat_dynamic_real = [number] ) , ] , ) [EOL] check_error_message ( [string] [string] , [ make_time_series ( num_feat_dynamic_real = [number] ) , make_time_series ( num_feat_dynamic_real = [number] ) , ] , ) [EOL] check_error_message ( [string] , [ make_time_series ( num_feat_dynamic_real = [number] ) , make_time_series ( num_feat_dynamic_real = [number] ) , ] , ) [EOL] [EOL] [comment] [EOL] inf_dynamic_feat = np . full ( ( [number] , len ( target ) ) , np . inf ) [EOL] check_error_message ( [string] [string] , [ ts ( start , target , feat_dynamic_cat = inf_dynamic_feat , feat_static_cat = [ [number] , [number] ] , ) ] , ) [EOL] check_error_message ( [string] [string] , [ ts ( start , target , feat_dynamic_real = inf_dynamic_feat , feat_static_cat = [ [number] , [number] ] , ) ] , ) [EOL] [EOL] [comment] [EOL] check_error_message ( [string] [string] [string] , [ ts ( start = start , target = target , feat_static_cat = [ [number] , [number] ] , feat_dynamic_cat = np . ones ( ( [number] , [number] ) ) , ) ] , ) [EOL] check_error_message ( [string] [string] [string] , [ ts ( start = start , target = target , feat_static_cat = [ [number] , [number] ] , feat_dynamic_real = np . ones ( ( [number] , [number] ) ) , ) ] , ) [EOL] [EOL] [comment] [EOL] check_error_message ( [string] , [ ts ( start = start , target = target , feat_static_cat = [ [number] , [number] ] ) , ts ( start = start , target = target , feat_static_cat = [ [number] ] ) , ] , ) [EOL] check_error_message ( [string] , [ ts ( start = start , target = target , feat_static_real = [ [number] , [number] ] ) , ts ( start = start , target = target , feat_static_real = [ [number] ] ) , ] , ) [EOL] [EOL] calculate_dataset_statistics ( cast ( Dataset , [ make_time_series ( num_feat_dynamic_cat = [number] ) , make_time_series ( num_feat_dynamic_cat = [number] ) , ] , ) ) [EOL] [EOL] calculate_dataset_statistics ( cast ( Dataset , [ make_time_series ( num_feat_dynamic_cat = [number] ) , make_time_series ( num_feat_dynamic_cat = [number] ) , ] , ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.dataset.common.DataEntry$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import pandas as pd [EOL] [EOL] from gluonts . dataset . split . splitter import TimeSeriesSlice [EOL] [EOL] [EOL] def make_series ( data , start = [string] , freq = [string] ) : [EOL] index = pd . date_range ( start = start , freq = freq , periods = len ( data ) ) [EOL] return pd . Series ( data , index = index ) [EOL] [EOL] [EOL] def test_ts_slice_to_item ( ) : [EOL] [EOL] sl = TimeSeriesSlice ( target = make_series ( range ( [number] ) ) , item = [string] , feat_static_cat = [ [number] , [number] , [number] ] , feat_static_real = [ [number] , [number] , [number] ] , feat_dynamic_cat = [ make_series ( range ( [number] ) ) ] , feat_dynamic_real = [ make_series ( range ( [number] ) ) ] , ) [EOL] [EOL] sl . to_data_entry ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import numpy as np [EOL] import pandas as pd [EOL] import pytest [EOL] [EOL] [comment] [EOL] from gluonts . core . serde import dump_code , load_code [EOL] from gluonts . dataset . common import ( BasicFeatureInfo , CategoricalFeatureInfo , MetaData , ) [EOL] from gluonts . dataset . artificial import RecipeDataset [EOL] from gluonts . dataset . artificial . recipe import ( Add , BinaryMarkovChain , Constant , ConstantVec , Debug , Eval , ForEachCat , Lag , LinearTrend , Mul , NanWhere , RandomBinary , RandomCat , RandomGaussian , RandomSymmetricDirichlet , Ref , SmoothSeasonality , Stack , evaluate , generate , take_as_list , ) [EOL] [EOL] BASE_RECIPE = [ ( [string] , ConstantVec ( [number] ) ) , ( [string] , RandomCat ( [ [number] ] ) ) ] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ Debug ( ) , RandomGaussian ( ) , RandomBinary ( ) , RandomSymmetricDirichlet ( ) , BinaryMarkovChain ( [number] , [number] ) , Constant ( [number] ) , LinearTrend ( ) , RandomCat ( [ [number] ] ) , Lag ( [string] , [number] ) , ForEachCat ( RandomGaussian ( ) ) , Eval ( [string] ) , SmoothSeasonality ( Constant ( [number] ) , Constant ( [number] ) ) , Add ( [ [string] , [string] ] ) , Mul ( [ [string] , [string] ] ) , NanWhere ( [string] , [string] ) , Stack ( [ Ref ( [string] ) , Ref ( [string] ) ] ) , RandomGaussian ( ) + RandomGaussian ( ) , RandomGaussian ( ) * RandomGaussian ( ) , RandomGaussian ( ) / RandomGaussian ( ) , ] , ) def test_call_and_repr ( func ) : [EOL] global_state = { } [EOL] x = evaluate ( BASE_RECIPE , length = [number] , global_state = global_state ) [EOL] kwargs = dict ( foo = [number] , bar = [number] ) [EOL] np . random . seed ( [number] ) [EOL] ret = func ( x , field_name = [string] , length = [number] , global_state = global_state . copy ( ) , ** kwargs , ) [EOL] [EOL] func_reconstructed = load_code ( dump_code ( func ) ) [EOL] [EOL] np . random . seed ( [number] ) [EOL] ret2 = func_reconstructed ( x , field_name = [string] , length = [number] , global_state = global_state . copy ( ) , ** kwargs , ) [EOL] print ( ret ) [EOL] np . testing . assert_allclose ( ret2 , ret ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ [ ( [string] , LinearTrend ( ) + RandomGaussian ( ) ) , ( [string] , BinaryMarkovChain ( [number] , [number] ) ) , ( [string] , Stack ( [ Ref ( [string] ) ] ) ) , ( [string] , RandomCat ( [ [number] ] ) ) , ( [string] , ForEachCat ( RandomGaussian ( [number] , ( [number] , ) ) , [string] ) + RandomGaussian ( [number] , ( [number] , ) ) , ) , ] , lambda ** kwargs : dict ( target = np . random . rand ( kwargs [ [string] ] ) , feat_dynamic_real = np . random . rand ( [number] , kwargs [ [string] ] ) , feat_static_cat = [ [number] ] , feat_static_real = [ [number] , [number] ] , ) , ] , ) def test_recipe_dataset ( recipe ) : [EOL] data = RecipeDataset ( recipe = recipe , metadata = MetaData ( freq = [string] , feat_static_real = [ BasicFeatureInfo ( name = [string] ) ] , feat_static_cat = [ CategoricalFeatureInfo ( name = [string] , cardinality = [number] ) ] , feat_dynamic_real = [ BasicFeatureInfo ( name = [string] ) ] , ) , max_train_length = [number] , prediction_length = [number] , num_timeseries = [number] , trim_length_fun = lambda x , ** kwargs : np . minimum ( int ( np . random . geometric ( [number] / ( kwargs [ [string] ] / [number] ) ) ) , kwargs [ [string] ] , ) , ) [EOL] [EOL] generated = data . generate ( ) [EOL] generated_train = list ( generated . train ) [EOL] generated_test = list ( generated . test ) [EOL] train_lengths = np . array ( [ len ( x [ [string] ] ) for x in generated_train ] ) [EOL] test_lengths = np . array ( [ len ( x [ [string] ] ) for x in generated_test ] ) [EOL] assert np . all ( test_lengths >= [number] ) [EOL] assert np . all ( test_lengths - train_lengths >= [number] ) [EOL] [EOL] assert len ( list ( generated . train ) ) == [number] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ BASE_RECIPE , lambda ** kwargs : dict ( ) ] ) def test_generate ( recipe ) : [EOL] start = pd . Timestamp ( [string] , freq = [string] ) [EOL] result = take_as_list ( iterator = generate ( length = [number] , recipe = BASE_RECIPE , start = start ) , num = [number] ) [EOL] assert len ( result ) == [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import List [EOL] import gluonts [EOL] import builtins [EOL] import typing [EOL] import mxnet [EOL] from gluonts . dataset . artificial import constant_dataset [EOL] from gluonts . dataset . field_names import FieldName [EOL] [EOL] [EOL] def test_listing_1 ( ) : [EOL] [docstring] [EOL] from gluonts . dataset . repository . datasets import get_dataset [EOL] from gluonts . model . deepar import DeepAREstimator [EOL] from gluonts . mx . trainer import Trainer [EOL] from gluonts . evaluation import Evaluator [EOL] from gluonts . evaluation . backtest import backtest_metrics [EOL] [EOL] [comment] [EOL] [comment] [EOL] dataset_info , train_ds , test_ds = constant_dataset ( ) [EOL] [EOL] meta = dataset_info . metadata [EOL] [EOL] estimator = DeepAREstimator ( freq = meta . freq , prediction_length = [number] , trainer = Trainer ( epochs = [number] , batch_size = [number] ) , ) [EOL] predictor = estimator . train ( train_ds ) [EOL] [EOL] evaluator = Evaluator ( quantiles = ( [number] , [number] , [number] ) ) [EOL] agg_metrics , item_metrics = backtest_metrics ( test_dataset = test_ds , predictor = predictor , evaluator = evaluator , ) [EOL] [EOL] [EOL] def test_appendix_c ( ) : [EOL] [docstring] [EOL] from typing import List [EOL] from mxnet import gluon [EOL] from gluonts . model . estimator import GluonEstimator [EOL] from gluonts . model . predictor import Predictor , RepresentableBlockPredictor [EOL] from gluonts . mx . trainer import Trainer [EOL] from gluonts . transform import ( InstanceSplitter , Transformation , ExpectedNumInstanceSampler , ) [EOL] from gluonts . core . component import validated [EOL] from gluonts . support . util import copy_parameters [EOL] [EOL] class MyTrainNetwork ( gluon . HybridBlock ) : [EOL] def __init__ ( self , prediction_length , cells , act_type , ** kwargs ) : [EOL] super ( ) . __init__ ( ** kwargs ) [EOL] self . prediction_length = prediction_length [EOL] with self . name_scope ( ) : [EOL] [comment] [EOL] self . nn = gluon . nn . HybridSequential ( ) [EOL] for c in cells : [EOL] self . nn . add ( gluon . nn . Dense ( units = c , activation = act_type ) ) [EOL] self . nn . add ( gluon . nn . Dense ( units = self . prediction_length , activation = act_type ) ) [EOL] [EOL] def hybrid_forward ( self , F , past_target , future_target ) : [EOL] prediction = self . nn ( past_target ) [EOL] [comment] [EOL] return ( prediction - future_target ) . abs ( ) . mean ( axis = - [number] ) [EOL] [EOL] class MyPredNetwork ( MyTrainNetwork ) : [EOL] [comment] [EOL] [comment] [EOL] def hybrid_forward ( self , F , past_target ) : [EOL] prediction = self . nn ( past_target ) [EOL] return prediction . expand_dims ( axis = [number] ) [EOL] [EOL] class MyEstimator ( GluonEstimator ) : [EOL] @ validated ( ) def __init__ ( self , freq , prediction_length , act_type = [string] , context_length = [number] , cells = [ [number] , [number] , [number] ] , trainer = Trainer ( epochs = [number] ) , ) : [EOL] super ( ) . __init__ ( trainer = trainer ) [EOL] self . freq = freq [EOL] self . prediction_length = prediction_length [EOL] self . act_type = act_type [EOL] self . context_length = context_length [EOL] self . cells = cells [EOL] [EOL] def create_training_network ( self ) : [EOL] return MyTrainNetwork ( prediction_length = self . prediction_length , cells = self . cells , act_type = self . act_type , ) [EOL] [EOL] def create_predictor ( self , transformation , trained_network , ) : [EOL] prediction_network = MyPredNetwork ( prediction_length = self . prediction_length , cells = self . cells , act_type = self . act_type , ) [EOL] [EOL] copy_parameters ( trained_network , prediction_network ) [EOL] [EOL] return RepresentableBlockPredictor ( input_transform = transformation , prediction_net = prediction_network , batch_size = self . trainer . batch_size , freq = self . freq , prediction_length = self . prediction_length , ctx = self . trainer . ctx , ) [EOL] [EOL] def create_transformation ( self ) : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] return InstanceSplitter ( target_field = FieldName . TARGET , is_pad_field = FieldName . IS_PAD , start_field = FieldName . START , forecast_start_field = FieldName . FORECAST_START , train_sampler = ExpectedNumInstanceSampler ( num_instances = [number] ) , past_length = self . context_length , future_length = self . prediction_length , ) [EOL] [EOL] from gluonts . mx . trainer import Trainer [EOL] from gluonts . evaluation import Evaluator [EOL] from gluonts . evaluation . backtest import backtest_metrics [EOL] [EOL] dataset_info , train_ds , test_ds = constant_dataset ( ) [EOL] [EOL] meta = dataset_info . metadata [EOL] estimator = MyEstimator ( freq = meta . freq , prediction_length = [number] , trainer = Trainer ( epochs = [number] , batch_size = [number] ) , ) [EOL] predictor = estimator . train ( train_ds ) [EOL] [EOL] evaluator = Evaluator ( quantiles = ( [number] , [number] , [number] ) ) [EOL] agg_metrics , item_metrics = backtest_metrics ( test_dataset = test_ds , predictor = predictor , evaluator = evaluator , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.mx.trainer.Trainer$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.mx.trainer.Trainer$ 0 $gluonts.mx.trainer.Trainer$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $MyTrainNetwork$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $gluonts.model.predictor.Predictor$ 0 0 0 $gluonts.transform.Transformation$ 0 $mxnet.gluon.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mxnet.gluon.HybridBlock$ 0 0 0 0 0 0 0 0 0 0 $gluonts.transform.Transformation$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] import sys [EOL] import os , subprocess [EOL] import shlex [EOL] import recommonmark [EOL] import sphinx_gallery [EOL] from recommonmark . parser import CommonMarkParser [EOL] from recommonmark . transform import AutoStructify [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] curr_path = os . path . dirname ( os . path . abspath ( os . path . expanduser ( __file__ ) ) ) [EOL] sys . path . insert ( [number] , os . path . join ( curr_path , [string] ) ) [EOL] [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from pkg_resources import get_distribution [EOL] [EOL] release = get_distribution ( [string] ) . version [EOL] version = [string] . join ( release . split ( [string] ) [ : [number] ] ) [comment] [EOL] [EOL] [comment] [EOL] project = [string] [EOL] copyright = [string] [EOL] author = [string] [EOL] github_doc_root = [string] . format ( str ( version ) ) [EOL] [EOL] [comment] [EOL] CommonMarkParser . github_doc_root = github_doc_root [EOL] source_parsers = { [string] : CommonMarkParser } [EOL] [EOL] [comment] [EOL] [comment] [EOL] extensions = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , ] [EOL] [EOL] [comment] [EOL] templates_path = [ [string] ] [EOL] [EOL] nbsphinx_kernel_name = [string] [EOL] nbsphinx_allow_errors = True [EOL] nbsphinx_timeout = [number] [EOL] html_sourcelink_suffix = [string] [EOL] [EOL] html_context = { [string] : True , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : False , [string] : True , } [EOL] [EOL] nbsphinx_prolog = [string] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] source_suffix = [ [string] , [string] , [string] ] [EOL] [EOL] [comment] [EOL] autosummary_generate = True [EOL] [EOL] [comment] [EOL] master_doc = [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] version = [string] [EOL] [comment] [EOL] release = [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] language = None [EOL] [EOL] [comment] [EOL] [comment] [EOL] html_logo = [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] html_favicon = [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] exclude_patterns = [ [string] , [string] , [string] ] [EOL] [EOL] [comment] [EOL] pygments_style = [string] [EOL] [EOL] [comment] [EOL] todo_include_todos = True [EOL] [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] html_theme = [string] [EOL] html_theme_path = [ [string] ] [EOL] html_theme_options = { [string] : [string] , [string] : [string] , [string] : [ ( [string] , [string] , False , [string] ) , ( [string] , [string] , False , [string] ) , ( [string] , [string] , False , [string] ) , ( [string] , [string] , False , [string] ) , ( [string] , [string] , True , [string] , ) , ] , [string] : True , [string] : True , [string] : True , [string] : True , [string] : False , } [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] html_static_path = [ [string] ] [EOL] [EOL] [comment] [EOL] htmlhelp_basename = [string] [EOL] [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] intersphinx_mapping = { [string] : ( [string] . format ( sys . version_info ) , None , ) , [string] : ( [string] , None ) , [string] : ( [string] , None ) , [string] : ( [string] , None ) , [string] : ( [string] , None ) , } [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] man_pages = [ ( master_doc , [string] , [string] , [ author ] , [number] ) ] [EOL] [EOL] from sphinx_gallery . sorting import ExplicitOrder [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] texinfo_documents = [ ( master_doc , [string] , [string] , author , [string] , [string] , [string] , ) ] [EOL] [EOL] [EOL] def setup ( app ) : [EOL] import mxtheme [EOL] [EOL] app . add_directive ( [string] , mxtheme . CardDirective ) [EOL] [EOL] app . add_config_value ( [string] , { [string] : lambda url : github_doc_root + url , [string] : True , } , True , ) [EOL] app . add_transform ( AutoStructify ) [EOL] app . add_javascript ( [string] ) [EOL] [EOL] [EOL] sphinx_gallery_conf = { [string] : [string] , [string] : ( [string] , [string] , [string] ) , [string] : { [string] : None , [string] : [string] , } , [string] : [ ] , [string] : [ ] , [string] : ExplicitOrder ( [ ] ) , [string] : False , [string] : [string] , [string] : [ ] , } [EOL] [EOL] [comment] [EOL] napoleon_use_ivar = True [EOL] [EOL] [comment] [EOL] import multiprocessing [EOL] [EOL] linkcheck_ignore = [ [string] ] [EOL] linkcheck_retries = [number] [EOL] linkcheck_workers = int ( multiprocessing . cpu_count ( ) / [number] ) [EOL] [EOL] intersphinx_mapping = { [string] : ( [string] , None ) } [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
import sys [EOL] import time [EOL] import notedown [EOL] import nbformat [EOL] [EOL] assert len ( sys . argv ) == [number] , [string] [EOL] [EOL] [comment] [EOL] timeout = [number] * [number] [EOL] [EOL] [comment] [EOL] ignore_execution = [ ] [EOL] [EOL] input_fn = sys . argv [ [number] ] [EOL] output_fn = [string] . join ( input_fn . split ( [string] ) [ : - [number] ] + [ [string] ] ) [EOL] [EOL] reader = notedown . MarkdownReader ( ) [EOL] [EOL] [comment] [EOL] with open ( input_fn , [string] ) as f : [EOL] notebook = reader . read ( f ) [EOL] [EOL] if not any ( [ i in input_fn for i in ignore_execution ] ) : [EOL] tic = time . time ( ) [EOL] notedown . run ( notebook , timeout ) [EOL] print ( [string] % ( time . time ( ) - tic ) ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] notebook [ [string] ] . update ( { [string] : { [string] : [string] } } ) [EOL] [EOL] with open ( output_fn , [string] ) as f : [EOL] f . write ( nbformat . writes ( notebook ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] import math [EOL] [EOL] [comment] [EOL] from gluonts . mx . kernels import RBFKernel [EOL] from gluonts . model . gp_forecaster . gaussian_process import GaussianProcess [EOL] [EOL] [comment] [EOL] import mxnet . ndarray as nd [EOL] import mxnet as mx [EOL] import numpy as np [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] def main ( ) : [EOL] [comment] [EOL] batch_size = [number] [EOL] prediction_length = [number] [EOL] context_length = [number] [EOL] axis = [ - [number] , [number] , - [number] , [number] ] [EOL] float_type = np . float64 [EOL] ctx = mx . Context ( [string] ) [EOL] [EOL] num_samples = [number] [EOL] ts_idx = [number] [EOL] [EOL] [comment] [EOL] lb = - [number] [EOL] ub = [number] [EOL] dx = ( ub - lb ) / ( prediction_length - [number] ) [EOL] x_test = nd . arange ( lb , ub + dx , dx , ctx = ctx , dtype = float_type ) . reshape ( - [number] , [number] ) [EOL] x_test = nd . tile ( x_test , reps = ( batch_size , [number] , [number] ) ) [EOL] [EOL] [comment] [EOL] amplitude = nd . ones ( ( batch_size , [number] , [number] ) , ctx = ctx , dtype = float_type ) [EOL] length_scale = math . sqrt ( [number] ) * nd . ones_like ( amplitude ) [EOL] sigma = math . sqrt ( [number] ) * nd . ones_like ( amplitude ) [EOL] [EOL] [comment] [EOL] rbf_kernel = RBFKernel ( amplitude , length_scale ) [EOL] [EOL] [comment] [EOL] gp = GaussianProcess ( sigma = sigma , kernel = rbf_kernel , prediction_length = prediction_length , context_length = context_length , num_samples = num_samples , ctx = ctx , float_type = float_type , sample_noise = False , ) [EOL] mean = nd . zeros ( ( batch_size , prediction_length ) , ctx = ctx , dtype = float_type ) [EOL] covariance = rbf_kernel . kernel_matrix ( x_test , x_test ) [EOL] gp . plot ( x_test = x_test , samples = gp . sample ( mean , covariance ) , ts_idx = ts_idx ) [EOL] [EOL] [comment] [EOL] x_train = nd . array ( [ - [number] , - [number] , - [number] , - [number] , [number] ] , ctx = ctx , dtype = float_type ) . reshape ( context_length , [number] ) [EOL] x_train = nd . tile ( x_train , reps = ( batch_size , [number] , [number] ) ) [EOL] y_train = nd . sin ( x_train . squeeze ( axis = [number] ) ) [EOL] [EOL] [comment] [EOL] samples , predictive_mean , predictive_std = gp . exact_inference ( x_train , y_train , x_test ) [EOL] [EOL] assert ( np . sum ( np . isnan ( samples . asnumpy ( ) ) ) == [number] ) , [string] [EOL] [EOL] gp . plot ( x_train = x_train , y_train = y_train , x_test = x_test , ts_idx = ts_idx , mean = predictive_mean , std = predictive_std , samples = samples , axis = axis , ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [docstring] [EOL] import numpy as np [EOL] from itertools import islice [EOL] import mxnet as mx [EOL] import matplotlib . pyplot as plt [EOL] import pandas as pd [EOL] from pandas . plotting import register_matplotlib_converters [EOL] [EOL] register_matplotlib_converters ( ) [EOL] [EOL] from gluonts . dataset . loader import TrainDataLoader [EOL] from gluonts . model . deepar import DeepAREstimator [EOL] from gluonts . support . util import get_hybrid_forward_input_names [EOL] from gluonts . mx . trainer import Trainer [EOL] from gluonts . dataset . repository . datasets import get_dataset [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] [EOL] dataset = get_dataset ( dataset_name = [string] ) [EOL] [EOL] estimator = DeepAREstimator ( prediction_length = dataset . metadata . prediction_length , freq = dataset . metadata . freq , trainer = Trainer ( learning_rate = [number] , epochs = [number] , num_batches_per_epoch = [number] ) , ) [EOL] [EOL] [comment] [EOL] train_output = estimator . train_model ( dataset . train ) [EOL] [EOL] [comment] [EOL] batch_size = [number] [EOL] num_samples = [number] [EOL] training_data_loader = TrainDataLoader ( dataset = dataset . train , transform = train_output . transformation , batch_size = batch_size , num_batches_per_epoch = estimator . trainer . num_batches_per_epoch , ctx = mx . cpu ( ) , ) [EOL] [EOL] for data_entry in islice ( training_data_loader , [number] ) : [EOL] pass [EOL] [EOL] [comment] [EOL] [comment] [EOL] context_length = train_output . trained_net . context_length [EOL] prediction_length = train_output . trained_net . prediction_length [EOL] [EOL] input_names = get_hybrid_forward_input_names ( train_output . trained_net ) [EOL] [EOL] distr = train_output . trained_net . distribution ( * [ data_entry [ k ] for k in input_names ] ) [EOL] [EOL] [comment] [EOL] samples = distr . sample ( num_samples ) . asnumpy ( ) [EOL] percentiles = np . percentile ( samples , axis = [number] , q = [ [number] , [number] ] ) [EOL] target = mx . ndarray . concat ( data_entry [ [string] ] , data_entry [ [string] ] , dim = [number] ) [EOL] target = target [ : , - ( context_length + prediction_length ) : ] [EOL] nll = - distr . log_prob ( target ) . asnumpy ( ) [EOL] target = target . asnumpy ( ) [EOL] mean = samples . mean ( axis = [number] ) [EOL] percentiles = np . percentile ( samples , axis = [number] , q = [ [number] , [number] ] ) [EOL] [EOL] [comment] [EOL] sorted_indices = np . argsort ( nll . reshape ( - [number] ) ) [ : : - [number] ] [EOL] [EOL] [comment] [EOL] for k in sorted_indices [ : [number] ] : [EOL] i = k // nll . shape [ [number] ] [EOL] t = k % nll . shape [ [number] ] [EOL] [EOL] time_index = pd . date_range ( pd . Timestamp ( data_entry [ [string] ] [ i ] ) , periods = context_length + prediction_length , ) [EOL] time_index -= context_length * time_index . freq [EOL] [EOL] plt . figure ( figsize = ( [number] , [number] ) ) [EOL] plt . fill_between ( time_index , percentiles [ [number] , i ] , percentiles [ - [number] , i ] , alpha = [number] , label = [string] , ) [EOL] plt . plot ( time_index , target [ i ] , label = [string] ) [EOL] plt . axvline ( time_index [ t ] , alpha = [number] , color = [string] ) [EOL] plt . title ( f" [string] { nll [ i , t ] }" ) [EOL] plt . legend ( ) [EOL] plt . show ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [docstring] [EOL] import pprint [EOL] [EOL] from gluonts . dataset . repository . datasets import get_dataset , dataset_recipes [EOL] from gluonts . evaluation import Evaluator [EOL] from gluonts . evaluation . backtest import make_evaluation_predictions [EOL] from gluonts . model . simple_feedforward import SimpleFeedForwardEstimator [EOL] from gluonts . mx . trainer import Trainer [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] [EOL] print ( f" [string] { dataset_recipes . keys ( ) }" ) [EOL] [EOL] [comment] [EOL] dataset = get_dataset ( [string] , regenerate = False ) [EOL] [EOL] estimator = SimpleFeedForwardEstimator ( prediction_length = dataset . metadata . prediction_length , freq = dataset . metadata . freq , trainer = Trainer ( epochs = [number] , num_batches_per_epoch = [number] ) , ) [EOL] [EOL] predictor = estimator . train ( dataset . train ) [EOL] [EOL] forecast_it , ts_it = make_evaluation_predictions ( dataset . test , predictor = predictor , num_samples = [number] ) [EOL] [EOL] agg_metrics , item_metrics = Evaluator ( ) ( ts_it , forecast_it , num_series = len ( dataset . test ) ) [EOL] [EOL] pprint . pprint ( agg_metrics ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [docstring] [EOL] import pprint [EOL] from functools import partial [EOL] [EOL] import pandas as pd [EOL] [EOL] from gluonts . dataset . repository . datasets import get_dataset [EOL] from gluonts . distribution . piecewise_linear import PiecewiseLinearOutput [EOL] from gluonts . evaluation import Evaluator [EOL] from gluonts . evaluation . backtest import make_evaluation_predictions [EOL] from gluonts . model . deepar import DeepAREstimator [EOL] from gluonts . model . seq2seq import MQCNNEstimator [EOL] from gluonts . model . simple_feedforward import SimpleFeedForwardEstimator [EOL] from gluonts . mx . trainer import Trainer [EOL] [EOL] datasets = [ [string] , [string] , [string] , [string] , [string] , [string] , ] [EOL] [EOL] epochs = [number] [EOL] num_batches_per_epoch = [number] [EOL] [EOL] estimators = [ partial ( SimpleFeedForwardEstimator , trainer = Trainer ( epochs = epochs , num_batches_per_epoch = num_batches_per_epoch ) , ) , partial ( DeepAREstimator , trainer = Trainer ( epochs = epochs , num_batches_per_epoch = num_batches_per_epoch ) , ) , partial ( DeepAREstimator , distr_output = PiecewiseLinearOutput ( [number] ) , trainer = Trainer ( epochs = epochs , num_batches_per_epoch = num_batches_per_epoch ) , ) , partial ( MQCNNEstimator , trainer = Trainer ( epochs = epochs , num_batches_per_epoch = num_batches_per_epoch ) , ) , ] [EOL] [EOL] [EOL] def evaluate ( dataset_name , estimator ) : [EOL] dataset = get_dataset ( dataset_name ) [EOL] estimator = estimator ( prediction_length = dataset . metadata . prediction_length , freq = dataset . metadata . freq , use_feat_static_cat = True , cardinality = [ feat_static_cat . cardinality for feat_static_cat in dataset . metadata . feat_static_cat ] , ) [EOL] [EOL] print ( f" [string] { estimator } [string] { dataset }" ) [EOL] [EOL] predictor = estimator . train ( dataset . train ) [EOL] [EOL] forecast_it , ts_it = make_evaluation_predictions ( dataset . test , predictor = predictor , num_samples = [number] ) [EOL] [EOL] agg_metrics , item_metrics = Evaluator ( ) ( ts_it , forecast_it , num_series = len ( dataset . test ) ) [EOL] [EOL] pprint . pprint ( agg_metrics ) [EOL] [EOL] eval_dict = agg_metrics [EOL] eval_dict [ [string] ] = dataset_name [EOL] eval_dict [ [string] ] = type ( estimator ) . __name__ [EOL] return eval_dict [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] [EOL] results = [ ] [EOL] for dataset_name in datasets : [EOL] for estimator in estimators : [EOL] [comment] [EOL] try : [EOL] results . append ( evaluate ( dataset_name , estimator ) ) [EOL] except Exception as e : [EOL] print ( str ( e ) ) [EOL] [EOL] df = pd . DataFrame ( results ) [EOL] [EOL] sub_df = df [ [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , ] ] [EOL] [EOL] print ( sub_df . to_string ( ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [docstring] [EOL] import os [EOL] import pprint [EOL] [EOL] from gluonts . dataset . repository . datasets import get_dataset [EOL] from gluonts . evaluation import Evaluator [EOL] from gluonts . evaluation . backtest import make_evaluation_predictions [EOL] from gluonts . model . simple_feedforward import SimpleFeedForwardEstimator [EOL] from gluonts . support . util import get_download_path [EOL] from gluonts . mx . trainer import Trainer [EOL] from gluonts . model . predictor import Predictor [EOL] [EOL] if __name__ == [string] : [EOL] [EOL] dataset = get_dataset ( [string] ) [EOL] [EOL] estimator = SimpleFeedForwardEstimator ( prediction_length = dataset . metadata . prediction_length , freq = dataset . metadata . freq , trainer = Trainer ( epochs = [number] , num_batches_per_epoch = [number] ) , ) [EOL] [EOL] predictor = estimator . train ( dataset . train ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] model_path = get_download_path ( ) / [string] [EOL] os . makedirs ( model_path , exist_ok = True ) [EOL] [EOL] predictor . serialize ( model_path ) [EOL] [EOL] [comment] [EOL] predictor_deserialized = Predictor . deserialize ( model_path ) [EOL] [EOL] forecast_it , ts_it = make_evaluation_predictions ( dataset . test , predictor = predictor_deserialized , num_samples = [number] ) [EOL] [EOL] agg_metrics , item_metrics = Evaluator ( ) ( ts_it , forecast_it , num_series = len ( dataset . test ) ) [EOL] [EOL] pprint . pprint ( agg_metrics ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0