[comment] [EOL] from typing import Any [EOL] import typing [EOL] from os . path import join [EOL] [EOL] from setuptools import setup , find_packages [EOL] [EOL] MODULE_NAME = [string] [comment] [EOL] MODULE_NAME_IMPORT = [string] [comment] [EOL] REPO_NAME = [string] [comment] [EOL] [EOL] [EOL] def requirements_from_pip ( filename = [string] ) : [EOL] with open ( filename , [string] ) as pip : [EOL] return [ l . strip ( ) for l in pip if not l . startswith ( [string] ) and l . strip ( ) ] [EOL] [EOL] core_deps = requirements_from_pip ( ) [EOL] demos_deps = requirements_from_pip ( [string] ) [EOL] test_deps = requirements_from_pip ( [string] ) [EOL] [EOL] tools_deps = requirements_from_pip ( [string] ) [EOL] [EOL] lgbm_deps = requirements_from_pip ( [string] ) [EOL] xgboost_deps = requirements_from_pip ( [string] ) [EOL] catboost_deps = requirements_from_pip ( [string] ) [EOL] [EOL] all_models_deps = lgbm_deps + xgboost_deps + catboost_deps [EOL] all_deps = all_models_deps + tools_deps [EOL] devel_deps = test_deps + all_deps [EOL] [EOL] setup ( name = MODULE_NAME , description = [string] , url = [string] . format ( REPO_NAME ) , author = [string] , package_dir = { [string] : [string] } , packages = find_packages ( [string] ) , version = ( open ( join ( [string] , MODULE_NAME , [string] , [string] ) ) . read ( ) . strip ( ) ) , install_requires = core_deps , extras_require = { [string] : test_deps , [string] : lgbm_deps , [string] : xgboost_deps , [string] : catboost_deps , [string] : tools_deps , [string] : devel_deps , [string] : all_models_deps , [string] : devel_deps , [string] : all_deps } , include_package_data = True , zip_safe = False , classifiers = [ [string] ] ) [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
import builtins [EOL] from os . path import dirname , join [EOL] [EOL] [EOL] def version ( ) : [EOL] [docstring] [EOL] with open ( join ( dirname ( __file__ ) , [string] , [string] ) ) as f : [EOL] return f . read ( ) . strip ( ) [EOL] [EOL] [EOL] __version__ = version ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0
from . version import __version__ [EOL]	0 0 0 0 0 0
[EOL] from typing import Union , Literal [EOL] import typing [EOL] import typing_extensions [EOL] import builtins [EOL] def learner_pred_fn_docstring ( f_name , shap = False ) : [EOL] shap_docstring = [string] if shap else [string] [EOL] [EOL] docstring = [string] % ( f_name , shap_docstring ) [EOL] [EOL] return docstring [EOL] [EOL] [EOL] def learner_return_docstring ( model_name ) : [EOL] docstring = [string] % model_name [EOL] [EOL] return docstring [EOL] [EOL] [EOL] splitter_return_docstring = [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Any , List , Tuple [EOL] import builtins [EOL] import typing [EOL] import pandas [EOL] import numpy [EOL] from typing import Tuple [EOL] [EOL] import numpy as np [EOL] from numpy import nan [EOL] import pandas as pd [EOL] [EOL] [EOL] def make_tutorial_data ( n ) : [EOL] [docstring] [EOL] np . random . seed ( [number] ) [EOL] [EOL] dataset = pd . DataFrame ( { [string] : list ( map ( lambda x : [string] % x , np . random . randint ( [number] , [number] , n ) ) ) , [string] : np . random . choice ( pd . date_range ( [string] , periods = [number] ) , n ) , [string] : np . random . gamma ( [number] , size = n ) , [string] : np . random . normal ( [number] , size = n ) , [string] : np . random . choice ( [ [string] , [string] , [string] ] , size = n ) } ) [EOL] [EOL] dataset [ [string] ] = ( dataset [ [string] ] + dataset [ [string] ] + dataset [ [string] ] . apply ( lambda x : [number] if x == [string] else [number] if x == [string] else [number] ) + np . random . normal ( [number] , [number] , size = n ) ) [EOL] [EOL] [comment] [EOL] dataset . loc [ np . random . randint ( [number] , n , [number] ) , [string] ] = nan [EOL] dataset . loc [ np . random . randint ( [number] , n , [number] ) , [string] ] = nan [EOL] [EOL] return dataset [EOL] [EOL] [EOL] def make_confounded_data ( n ) : [EOL] [docstring] [EOL] [EOL] def get_severity ( df ) : [EOL] return ( ( np . random . beta ( [number] , [number] , size = df . shape [ [number] ] ) * ( df [ [string] ] < [number] ) ) + ( np . random . beta ( [number] , [number] , size = df . shape [ [number] ] ) * ( df [ [string] ] >= [number] ) ) ) [EOL] [EOL] def get_treatment ( df ) : [EOL] return ( [number] * df [ [string] ] + [number] * df [ [string] ] + [number] * np . random . normal ( size = df . shape [ [number] ] ) > [number] ) . astype ( float ) [EOL] [EOL] def get_recovery ( df ) : [EOL] return np . random . poisson ( np . exp ( [number] + [number] * df [ [string] ] + [number] * df [ [string] ] + df [ [string] ] - df [ [string] ] ) ) [EOL] [EOL] np . random . seed ( [number] ) [EOL] sexes = np . random . randint ( [number] , [number] , size = n ) [EOL] ages = np . random . gamma ( [number] , scale = [number] , size = n ) [EOL] meds = np . random . randint ( [number] , [number] , size = n ) [EOL] [EOL] [comment] [EOL] df_rnd = pd . DataFrame ( dict ( sex = sexes , age = ages , medication = meds ) ) [EOL] df_rnd [ [string] ] = get_severity ( df_rnd ) [EOL] df_rnd [ [string] ] = get_recovery ( df_rnd ) [EOL] [EOL] features = [ [string] , [string] , [string] , [string] , [string] ] [EOL] df_rnd = df_rnd [ features ] [comment] [EOL] [EOL] [comment] [EOL] df_obs = df_rnd . copy ( ) [EOL] df_obs [ [string] ] = get_treatment ( df_obs ) [EOL] df_obs [ [string] ] = get_recovery ( df_obs ) [EOL] [EOL] [comment] [EOL] df_ctf = df_obs . copy ( ) [EOL] df_ctf [ [string] ] = ( ( df_ctf [ [string] ] == [number] ) ^ [number] ) . astype ( float ) [EOL] df_ctf [ [string] ] = get_recovery ( df_ctf ) [EOL] [EOL] return df_rnd , df_obs , df_ctf [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[pandas.DataFrame,pandas.DataFrame,pandas.DataFrame]$ 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.Series$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Iterable , Union , Dict , Any , List , Callable , Tuple [EOL] import typing [EOL] import pandas [EOL] import fklearn [EOL] import datetime [EOL] import builtins [EOL] import operator [EOL] from datetime import datetime , timedelta [EOL] from itertools import chain , repeat , starmap [EOL] from typing import Callable , Iterable , List , Tuple , Union [EOL] [EOL] import numpy as np [EOL] import pandas as pd [EOL] from sklearn . model_selection import GroupKFold , KFold , StratifiedKFold [EOL] from sklearn . utils import check_random_state [EOL] from toolz . curried import curry , partial , pipe , assoc , accumulate , map , filter [EOL] [EOL] from fklearn . common_docstrings import splitter_return_docstring [EOL] from fklearn . types import DateType , LogType , SplitterReturnType [EOL] [EOL] [EOL] def _log_time_fold ( time_fold ) : [EOL] train_time , test_time = time_fold [EOL] return { [string] : train_time . min ( ) , [string] : train_time . max ( ) , [string] : train_time . shape [ [number] ] , [string] : test_time . min ( ) , [string] : test_time . max ( ) , [string] : test_time . shape [ [number] ] } [EOL] [EOL] [EOL] def _get_lc_folds ( date_range , date_fold_filter_fn , test_time , time_column , min_samples ) : [EOL] return pipe ( date_range , map ( date_fold_filter_fn ) , map ( lambda df : df [ time_column ] ) , filter ( lambda s : len ( s . index ) > min_samples ) , lambda train : zip ( train , repeat ( test_time ) ) , list ) [EOL] [EOL] [EOL] def _get_sc_folds ( date_range , date_fold_filter_fn , time_column , min_samples ) : [EOL] return pipe ( date_range , map ( date_fold_filter_fn ) , map ( lambda df : df [ time_column ] ) , filter ( lambda s : len ( s . index ) > min_samples ) , list ) [EOL] [EOL] [EOL] def _get_sc_test_fold_idx_and_logs ( test_data , train_time , time_column , first_test_moment , last_test_moment , min_samples , freq ) : [EOL] periods_range = pd . period_range ( start = first_test_moment , end = last_test_moment , freq = freq ) [EOL] [EOL] def date_filter_fn ( period ) : [EOL] return test_data [ test_data [ time_column ] . dt . to_period ( freq ) == period ] [EOL] [EOL] folds = _get_sc_folds ( periods_range , date_filter_fn , time_column , min_samples ) [EOL] [EOL] logs = list ( map ( _log_time_fold , zip ( repeat ( train_time ) , folds ) ) ) [comment] [EOL] test_indexes = list ( map ( lambda test : [ test . index ] , folds ) ) [comment] [EOL] return logs , test_indexes [EOL] [EOL] [EOL] def _lc_fold_to_indexes ( folds ) : [EOL] return list ( starmap ( lambda train , test : ( train . index , [ test . index ] ) , folds ) ) [EOL] [EOL] [EOL] @ curry def k_fold_splitter ( train_data , n_splits , random_state = None , stratify_column = None ) : [EOL] [docstring] [EOL] [EOL] if stratify_column is not None : [EOL] folds = StratifiedKFold ( n_splits = n_splits , shuffle = True , random_state = random_state ) . split ( train_data , train_data [ stratify_column ] ) [EOL] else : [EOL] folds = KFold ( n_splits , shuffle = True , random_state = random_state ) . split ( train_data ) [EOL] result = list ( map ( lambda f : ( f [ [number] ] , [ f [ [number] ] ] ) , folds ) ) [EOL] [EOL] logs = [ { [string] : len ( fold [ [number] ] ) , [string] : train_data . shape [ [number] ] - len ( fold [ [number] ] ) } for fold in result ] [EOL] [EOL] return result , logs [EOL] [EOL] [EOL] k_fold_splitter . __doc__ += splitter_return_docstring [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] @ curry def out_of_time_and_space_splitter ( train_data , n_splits , in_time_limit , time_column , space_column , holdout_gap = timedelta ( days = [number] ) ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] [comment] [EOL] train_data = train_data . reset_index ( ) [EOL] space_folds = GroupKFold ( n_splits ) . split ( train_data , groups = train_data [ space_column ] ) [EOL] [EOL] if isinstance ( in_time_limit , str ) : [EOL] in_time_limit = datetime . strptime ( in_time_limit , [string] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] folds = pipe ( space_folds , partial ( starmap , lambda f_train , f_test : [ train_data . iloc [ f_train ] [ time_column ] , train_data . iloc [ f_test ] [ time_column ] ] ) , partial ( starmap , lambda train , test : ( train [ train <= in_time_limit ] , test [ test > ( in_time_limit + holdout_gap ) ] ) ) , list ) [EOL] [EOL] logs = list ( map ( _log_time_fold , folds ) ) [comment] [EOL] folds_indexes = _lc_fold_to_indexes ( folds ) [comment] [EOL] return folds_indexes , logs [EOL] [EOL] [EOL] out_of_time_and_space_splitter . __doc__ += splitter_return_docstring [EOL] [EOL] [EOL] @ curry def time_and_space_learning_curve_splitter ( train_data , training_time_limit , space_column , time_column , freq = [string] , space_hold_percentage = [number] , holdout_gap = timedelta ( days = [number] ) , random_state = None , min_samples = [number] ) : [EOL] [docstring] [EOL] [EOL] train_data = train_data . reset_index ( ) [EOL] first_moment = train_data [ time_column ] . min ( ) [EOL] date_range = pd . date_range ( start = first_moment , end = training_time_limit , freq = freq ) [EOL] [EOL] [comment] [EOL] rng = check_random_state ( random_state ) [EOL] out_of_space_mask = pipe ( train_data , lambda df : df [ df [ time_column ] > date_range [ - [number] ] ] , lambda df : df [ space_column ] . unique ( ) , lambda array : rng . choice ( array , int ( len ( array ) * space_hold_percentage ) , replace = False ) , lambda held_space : train_data [ space_column ] . isin ( held_space ) ) [comment] [EOL] [EOL] training_time_limit_dt = datetime . strptime ( training_time_limit , [string] ) + holdout_gap [EOL] test_time = train_data [ ( train_data [ time_column ] > training_time_limit_dt ) & out_of_space_mask ] [ time_column ] [EOL] [EOL] def date_filter_fn ( date ) : [EOL] return train_data [ ( train_data [ time_column ] <= date ) & ~ out_of_space_mask ] [EOL] [EOL] folds = _get_lc_folds ( date_range , date_filter_fn , test_time , time_column , min_samples ) [EOL] [EOL] logs = list ( map ( _log_time_fold , folds ) ) [comment] [EOL] folds_indexes = _lc_fold_to_indexes ( folds ) [comment] [EOL] [EOL] return folds_indexes , logs [EOL] [EOL] [EOL] time_and_space_learning_curve_splitter . __doc__ += splitter_return_docstring [EOL] [EOL] [EOL] @ curry def time_learning_curve_splitter ( train_data , training_time_limit , time_column , freq = [string] , holdout_gap = timedelta ( days = [number] ) , min_samples = [number] ) : [EOL] [docstring] [EOL] [EOL] train_data = train_data . reset_index ( ) [EOL] first_moment = train_data [ time_column ] . min ( ) [EOL] date_range = pd . date_range ( start = first_moment , end = training_time_limit , freq = freq ) [EOL] [EOL] [comment] [EOL] effective_training_time_end = date_range [ - [number] ] [EOL] [EOL] test_time = train_data [ train_data [ time_column ] > ( effective_training_time_end + holdout_gap ) ] [ time_column ] [EOL] [EOL] def date_filter_fn ( date ) : [EOL] return train_data [ train_data [ time_column ] <= date ] [EOL] [EOL] folds = _get_lc_folds ( date_range , date_filter_fn , test_time , time_column , min_samples ) [EOL] [EOL] logs = list ( map ( _log_time_fold , folds ) ) [comment] [EOL] folds_indexes = _lc_fold_to_indexes ( folds ) [comment] [EOL] return folds_indexes , logs [EOL] [EOL] [EOL] time_learning_curve_splitter . __doc__ += splitter_return_docstring [EOL] [EOL] [EOL] @ curry def reverse_time_learning_curve_splitter ( train_data , time_column , training_time_limit , lower_time_limit = None , freq = [string] , holdout_gap = timedelta ( days = [number] ) , min_samples = [number] ) : [EOL] [docstring] [EOL] [EOL] train_data = train_data . reset_index ( ) [EOL] first_moment = lower_time_limit if lower_time_limit else train_data [ time_column ] . min ( ) [EOL] date_range = pd . date_range ( start = first_moment , end = training_time_limit , freq = freq ) [EOL] [EOL] [comment] [EOL] effective_training_time_end = date_range [ - [number] ] [EOL] [EOL] train_range = train_data [ train_data [ time_column ] <= effective_training_time_end ] [EOL] test_time = train_data [ train_data [ time_column ] > ( effective_training_time_end + holdout_gap ) ] [ time_column ] [EOL] [EOL] def date_filter_fn ( date ) : [EOL] return train_range . loc [ train_data [ time_column ] >= date ] [EOL] [EOL] folds = _get_lc_folds ( date_range [ : : - [number] ] , date_filter_fn , test_time , time_column , min_samples ) [EOL] [EOL] logs = list ( map ( _log_time_fold , folds ) ) [comment] [EOL] folds_indexes = _lc_fold_to_indexes ( folds ) [comment] [EOL] [EOL] return folds_indexes , logs [EOL] [EOL] [EOL] reverse_time_learning_curve_splitter . __doc__ += splitter_return_docstring [EOL] [EOL] [EOL] @ curry def spatial_learning_curve_splitter ( train_data , space_column , time_column , training_limit , holdout_gap = timedelta ( days = [number] ) , train_percentages = ( [number] , [number] , [number] , [number] ) , random_state = None ) : [EOL] [docstring] [EOL] if np . min ( train_percentages ) < [number] or np . min ( train_percentages ) > [number] : [EOL] raise ValueError ( [string] ) [EOL] [EOL] if isinstance ( training_limit , str ) : [EOL] training_limit = datetime . strptime ( training_limit , [string] ) [EOL] [EOL] if training_limit < train_data [ time_column ] . min ( ) or training_limit > train_data [ time_column ] . max ( ) : [EOL] raise ValueError ( [string] ) [EOL] if timedelta ( days = [number] ) > holdout_gap : [EOL] raise ValueError ( [string] ) [EOL] if holdout_gap >= ( train_data [ time_column ] . max ( ) - training_limit ) : [EOL] raise ValueError ( [string] ) [EOL] [EOL] train_data = train_data . reset_index ( ) [EOL] [EOL] [comment] [EOL] spatial_ids = train_data [ space_column ] . sample ( frac = [number] , random_state = random_state ) . unique ( ) [EOL] [EOL] cumulative_ids = pipe ( spatial_ids , lambda ids : ( np . array ( train_percentages ) * len ( ids ) ) . astype ( int ) , lambda idx : np . split ( spatial_ids , idx ) [ : - [number] ] , lambda l : map ( lambda x : x . tolist ( ) , l ) , lambda l : filter ( None , l ) , accumulate ( operator . add ) ) [EOL] [EOL] validation_set = train_data [ train_data [ time_column ] > ( training_limit + holdout_gap ) ] [EOL] train_data = train_data [ train_data [ time_column ] <= training_limit ] [EOL] [EOL] folds = [ ( train_data [ train_data [ space_column ] . isin ( ids ) ] [ time_column ] , validation_set [ time_column ] ) for ids in cumulative_ids ] [EOL] [EOL] folds_indices = _lc_fold_to_indexes ( folds ) [comment] [EOL] [EOL] logs = [ assoc ( learner , [string] , p ) for learner , p in zip ( map ( _log_time_fold , folds ) , train_percentages ) ] [EOL] [EOL] return folds_indices , logs [EOL] [EOL] [EOL] spatial_learning_curve_splitter . __doc__ += splitter_return_docstring [EOL] [EOL] [EOL] @ curry def stability_curve_time_splitter ( train_data , training_time_limit , time_column , freq = [string] , min_samples = [number] ) : [EOL] [docstring] [EOL] [EOL] train_data = train_data . reset_index ( ) [EOL] [EOL] train_time = train_data [ train_data [ time_column ] <= training_time_limit ] [ time_column ] [EOL] test_data = train_data [ train_data [ time_column ] > training_time_limit ] [EOL] [EOL] first_test_moment = test_data [ time_column ] . min ( ) [EOL] last_test_moment = test_data [ time_column ] . max ( ) [EOL] [EOL] logs , test_indexes = _get_sc_test_fold_idx_and_logs ( test_data , train_time , time_column , first_test_moment , last_test_moment , min_samples , freq ) [EOL] [EOL] [comment] [EOL] logs = [ { k : [ dic [ k ] for dic in logs ] for k in logs [ [number] ] } ] [EOL] [EOL] [comment] [EOL] flattened_test_indices = list ( chain . from_iterable ( test_indexes ) ) [EOL] [EOL] return [ ( train_time . index , flattened_test_indices ) ] , logs [EOL] [EOL] [EOL] stability_curve_time_splitter . __doc__ += splitter_return_docstring [EOL] [EOL] [EOL] @ curry def stability_curve_time_in_space_splitter ( train_data , training_time_limit , space_column , time_column , freq = [string] , space_hold_percentage = [number] , random_state = None , min_samples = [number] ) : [EOL] [docstring] [EOL] [EOL] train_data = train_data . reset_index ( ) [EOL] [EOL] rng = check_random_state ( random_state ) [EOL] [EOL] train_time = train_data [ train_data [ time_column ] <= training_time_limit ] [ time_column ] [EOL] [EOL] test_data = pipe ( train_data , lambda trand_df : trand_df . iloc [ train_time . index ] [ space_column ] . unique ( ) , lambda space : rng . choice ( space , int ( len ( space ) * space_hold_percentage ) , replace = False ) , lambda held_space : train_data [ ( train_data [ time_column ] > training_time_limit ) & ( train_data [ space_column ] . isin ( held_space ) ) ] ) [EOL] [EOL] first_test_moment = test_data [ time_column ] . min ( ) [EOL] last_test_moment = test_data [ time_column ] . max ( ) [EOL] [EOL] logs , test_indexes = _get_sc_test_fold_idx_and_logs ( test_data , train_time , time_column , first_test_moment , last_test_moment , min_samples , freq ) [EOL] [EOL] [comment] [EOL] logs = [ { k : [ dic [ k ] for dic in logs ] for k in logs [ [number] ] } ] [EOL] [EOL] [comment] [EOL] flattened_test_indices = list ( chain . from_iterable ( test_indexes ) ) [EOL] [EOL] return [ ( train_time . index , flattened_test_indices ) ] , logs [EOL] [EOL] [EOL] stability_curve_time_in_space_splitter . __doc__ += splitter_return_docstring [EOL] [EOL] [EOL] @ curry def stability_curve_time_space_splitter ( train_data , training_time_limit , space_column , time_column , freq = [string] , space_hold_percentage = [number] , random_state = None , min_samples = [number] ) : [EOL] [docstring] [EOL] train_data = train_data . reset_index ( ) [EOL] [EOL] rng = check_random_state ( random_state ) [EOL] [EOL] train_time = train_data [ train_data [ time_column ] <= training_time_limit ] [ time_column ] [EOL] train_index = train_time . index . values [EOL] train_space = train_data . iloc [ train_index ] [ space_column ] . unique ( ) [EOL] [EOL] held_space = rng . choice ( train_space , int ( len ( train_space ) * space_hold_percentage ) , replace = False ) [EOL] [EOL] test_data = train_data [ ( train_data [ time_column ] > training_time_limit ) & ( ~ train_data [ space_column ] . isin ( held_space ) ) ] [EOL] train_index = train_data [ ( train_data [ time_column ] <= training_time_limit ) & ( train_data [ space_column ] . isin ( held_space ) ) ] . index . values [EOL] [EOL] first_test_moment = test_data [ time_column ] . min ( ) [EOL] last_test_moment = test_data [ time_column ] . max ( ) [EOL] [EOL] logs , test_indexes = _get_sc_test_fold_idx_and_logs ( test_data , train_time , time_column , first_test_moment , last_test_moment , min_samples , freq ) [EOL] [EOL] [comment] [EOL] logs = [ { k : [ dic [ k ] for dic in logs ] for k in logs [ [number] ] } ] [EOL] [EOL] [comment] [EOL] flattened_test_indices = list ( chain . from_iterable ( test_indexes ) ) [EOL] [EOL] return [ ( train_index , flattened_test_indices ) ] , logs [EOL] [EOL] [EOL] stability_curve_time_space_splitter . __doc__ += splitter_return_docstring [EOL] [EOL] [EOL] @ curry def forward_stability_curve_time_splitter ( train_data , training_time_start , training_time_end , time_column , holdout_gap = timedelta ( days = [number] ) , holdout_size = timedelta ( days = [number] ) , step = timedelta ( days = [number] ) , move_training_start_with_steps = True ) : [EOL] [docstring] [EOL] [EOL] if isinstance ( training_time_start , str ) : [EOL] training_time_start = datetime . strptime ( training_time_start , [string] ) [EOL] [EOL] if isinstance ( training_time_end , str ) : [EOL] training_time_end = datetime . strptime ( training_time_end , [string] ) [EOL] [EOL] train_data = train_data . reset_index ( ) [EOL] [EOL] max_date = train_data [ time_column ] . max ( ) [EOL] [EOL] if not ( train_data [ time_column ] . min ( ) <= training_time_start < training_time_end <= max_date ) : [EOL] raise ValueError ( [string] ) [EOL] if timedelta ( days = [number] ) > holdout_gap : [EOL] raise ValueError ( [string] ) [EOL] if timedelta ( days = [number] ) > holdout_size : [EOL] raise ValueError ( [string] ) [EOL] [EOL] n_folds = int ( np . ceil ( ( max_date - holdout_size - holdout_gap - training_time_end ) / step ) ) [EOL] [EOL] if n_folds <= [number] : [EOL] raise ValueError ( [string] ) [EOL] [EOL] train_ranges = [ ( training_time_start + i * step * move_training_start_with_steps , training_time_end + i * step ) for i in range ( n_folds ) ] [EOL] [EOL] test_ranges = [ ( training_time_end + holdout_gap + i * step , training_time_end + holdout_gap + holdout_size + i * step ) for i in range ( n_folds ) ] [EOL] [EOL] train_idx = [ train_data [ ( train_data [ time_column ] >= start ) & ( train_data [ time_column ] < end ) ] . index for start , end in train_ranges ] [EOL] test_idx = [ [ train_data [ ( train_data [ time_column ] >= start ) & ( train_data [ time_column ] < end ) ] . index ] for start , end in test_ranges ] [EOL] [EOL] logs = [ _log_time_fold ( ( train_data . iloc [ i ] [ time_column ] , train_data . iloc [ j [ [number] ] ] [ time_column ] ) ) for i , j in zip ( train_idx , test_idx ) ] [EOL] [EOL] return list ( zip ( train_idx , test_idx ) ) , logs [EOL] [EOL] [EOL] forward_stability_curve_time_splitter . __doc__ += splitter_return_docstring [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Iterable , Dict , Any , List , Callable [EOL] import typing [EOL] import pandas [EOL] import fklearn [EOL] import numpy [EOL] import builtins [EOL] import warnings [EOL] from typing import Any , Callable , Iterable , List [EOL] [EOL] import numpy as np [EOL] import pandas as pd [EOL] import toolz as fp [EOL] from pandas . util import hash_pandas_object [EOL] from sklearn . metrics import ( average_precision_score , brier_score_loss , fbeta_score , log_loss , mean_absolute_error , mean_squared_error , precision_score , r2_score , recall_score , roc_auc_score ) [EOL] from toolz import curry [EOL] [EOL] from fklearn . types import ( EvalFnType , EvalReturnType , PredictFnType , UncurriedEvalFnType ) [EOL] [EOL] [EOL] def generic_sklearn_evaluator ( name_prefix , sklearn_metric ) : [EOL] [docstring] [EOL] [EOL] def p ( test_data , prediction_column = [string] , target_column = [string] , eval_name = None , ** kwargs ) : [EOL] try : [EOL] score = sklearn_metric ( test_data [ target_column ] , test_data [ prediction_column ] , ** kwargs ) [EOL] except ValueError : [EOL] [comment] [EOL] score = np . nan [EOL] [EOL] if eval_name is None : [EOL] eval_name = name_prefix + target_column [EOL] [EOL] return { eval_name : score } [EOL] [EOL] return p [EOL] [EOL] [EOL] @ curry def auc_evaluator ( test_data , prediction_column = [string] , target_column = [string] , eval_name = None ) : [EOL] [docstring] [EOL] [EOL] warnings . warn ( [string] [string] [string] ) [EOL] [EOL] return roc_auc_evaluator ( test_data , prediction_column , target_column , eval_name ) [EOL] [EOL] [EOL] @ curry def roc_auc_evaluator ( test_data , prediction_column = [string] , target_column = [string] , eval_name = None ) : [EOL] [docstring] [EOL] [EOL] eval_fn = generic_sklearn_evaluator ( [string] , roc_auc_score ) [EOL] eval_data = test_data . assign ( ** { target_column : lambda df : df [ target_column ] . astype ( int ) } ) [EOL] [EOL] return eval_fn ( eval_data , prediction_column , target_column , eval_name ) [EOL] [EOL] [EOL] @ curry def pr_auc_evaluator ( test_data , prediction_column = [string] , target_column = [string] , eval_name = None ) : [EOL] [docstring] [EOL] [EOL] eval_fn = generic_sklearn_evaluator ( [string] , average_precision_score ) [EOL] eval_data = test_data . assign ( ** { target_column : lambda df : df [ target_column ] . astype ( int ) } ) [EOL] [EOL] return eval_fn ( eval_data , prediction_column , target_column , eval_name ) [EOL] [EOL] [EOL] @ curry def precision_evaluator ( test_data , threshold = [number] , prediction_column = [string] , target_column = [string] , eval_name = None ) : [EOL] [docstring] [EOL] eval_fn = generic_sklearn_evaluator ( [string] , precision_score ) [EOL] eval_data = test_data . assign ( ** { prediction_column : ( test_data [ prediction_column ] > threshold ) . astype ( int ) } ) [EOL] [EOL] return eval_fn ( eval_data , prediction_column , target_column , eval_name ) [EOL] [EOL] [EOL] @ curry def recall_evaluator ( test_data , threshold = [number] , prediction_column = [string] , target_column = [string] , eval_name = None ) : [EOL] [docstring] [EOL] [EOL] eval_data = test_data . assign ( ** { prediction_column : ( test_data [ prediction_column ] > threshold ) . astype ( int ) } ) [EOL] eval_fn = generic_sklearn_evaluator ( [string] , recall_score ) [EOL] [EOL] return eval_fn ( eval_data , prediction_column , target_column , eval_name ) [EOL] [EOL] [EOL] @ curry def fbeta_score_evaluator ( test_data , threshold = [number] , beta = [number] , prediction_column = [string] , target_column = [string] , eval_name = None ) : [EOL] [docstring] [EOL] [EOL] eval_data = test_data . assign ( ** { prediction_column : ( test_data [ prediction_column ] > threshold ) . astype ( int ) } ) [EOL] eval_fn = generic_sklearn_evaluator ( [string] , fbeta_score ) [EOL] [EOL] return eval_fn ( eval_data , prediction_column , target_column , eval_name , beta = beta ) [EOL] [EOL] [EOL] @ curry def logloss_evaluator ( test_data , prediction_column = [string] , target_column = [string] , eval_name = None ) : [EOL] [docstring] [EOL] [EOL] eval_fn = generic_sklearn_evaluator ( [string] , log_loss ) [EOL] eval_data = test_data . assign ( ** { target_column : lambda df : df [ target_column ] . astype ( int ) } ) [EOL] [EOL] return eval_fn ( eval_data , prediction_column , target_column , eval_name ) [EOL] [EOL] [EOL] @ curry def brier_score_evaluator ( test_data , prediction_column = [string] , target_column = [string] , eval_name = None ) : [EOL] [docstring] [EOL] [EOL] eval_fn = generic_sklearn_evaluator ( [string] , brier_score_loss ) [EOL] eval_data = test_data . assign ( ** { target_column : lambda df : df [ target_column ] . astype ( int ) } ) [EOL] [EOL] return eval_fn ( eval_data , prediction_column , target_column , eval_name ) [EOL] [EOL] [EOL] @ curry def expected_calibration_error_evaluator ( test_data , prediction_column = [string] , target_column = [string] , eval_name = None , n_bins = [number] , bin_choice = [string] ) : [EOL] [docstring] [EOL] [EOL] if eval_name is None : [EOL] eval_name = [string] + target_column [EOL] [EOL] if bin_choice == [string] : [EOL] bins = pd . qcut ( test_data [ prediction_column ] , q = n_bins ) [EOL] elif bin_choice == [string] : [EOL] bins = pd . cut ( test_data [ prediction_column ] , bins = n_bins ) [EOL] else : [EOL] raise AttributeError ( [string] ) [EOL] [EOL] metric_df = pd . DataFrame ( { [string] : bins , [string] : test_data [ prediction_column ] , [string] : test_data [ target_column ] } ) [EOL] [EOL] agg_df = metric_df . groupby ( [string] ) . agg ( { [string] : [string] , [string] : [string] , [string] : [string] } ) [EOL] [EOL] sample_weight = None [EOL] if bin_choice == [string] : [EOL] sample_weight = agg_df [ [string] ] . values [EOL] [EOL] distance = mean_absolute_error ( agg_df [ [string] ] . values , agg_df [ [string] ] . values , sample_weight = sample_weight ) [EOL] [EOL] return { eval_name : distance } [EOL] [EOL] [EOL] @ curry def r2_evaluator ( test_data , prediction_column = [string] , target_column = [string] , eval_name = None ) : [EOL] [docstring] [EOL] [EOL] eval_fn = generic_sklearn_evaluator ( [string] , r2_score ) [EOL] [EOL] return eval_fn ( test_data , prediction_column , target_column , eval_name ) [EOL] [EOL] [EOL] @ curry def mse_evaluator ( test_data , prediction_column = [string] , target_column = [string] , eval_name = None ) : [EOL] [docstring] [EOL] eval_fn = generic_sklearn_evaluator ( [string] , mean_squared_error ) [EOL] [EOL] return eval_fn ( test_data , prediction_column , target_column , eval_name ) [EOL] [EOL] [EOL] @ curry def mean_prediction_evaluator ( test_data , prediction_column = [string] , eval_name = None ) : [EOL] [docstring] [EOL] [EOL] if eval_name is None : [EOL] eval_name = [string] + prediction_column [EOL] [EOL] return { eval_name : test_data [ prediction_column ] . mean ( ) } [EOL] [EOL] [EOL] @ curry def correlation_evaluator ( test_data , prediction_column = [string] , target_column = [string] , eval_name = None ) : [EOL] [docstring] [EOL] [EOL] if eval_name is None : [EOL] eval_name = [string] + target_column [EOL] [EOL] score = test_data [ [ prediction_column , target_column ] ] . corr ( method = [string] ) . iloc [ [number] , [number] ] [EOL] return { eval_name : score } [EOL] [EOL] [EOL] @ curry def spearman_evaluator ( test_data , prediction_column = [string] , target_column = [string] , eval_name = None ) : [EOL] [docstring] [EOL] [EOL] if eval_name is None : [EOL] eval_name = [string] + target_column [EOL] [EOL] score = test_data [ [ prediction_column , target_column ] ] . corr ( method = [string] ) . iloc [ [number] , [number] ] [EOL] return { eval_name : score } [EOL] [EOL] [EOL] @ curry def ndcg_evaluator ( test_data , prediction_column = [string] , target_column = [string] , k = None , exponential_gain = True , eval_name = None ) : [EOL] [docstring] [EOL] [EOL] if isinstance ( k , ( int , float ) ) and not [number] < k <= len ( test_data [ prediction_column ] ) : [EOL] raise ValueError ( [string] ) [EOL] [EOL] if eval_name is None : [EOL] eval_name = f" [string] { target_column }" [EOL] [EOL] rel = np . argsort ( test_data [ prediction_column ] ) [ : : - [number] ] [ : k ] [EOL] cum_gain = test_data [ target_column ] [ rel ] [EOL] [EOL] ideal_cum_gain = np . sort ( test_data [ target_column ] ) [ : : - [number] ] [ : k ] [EOL] [EOL] if exponential_gain : [EOL] cum_gain = ( [number] ** cum_gain ) - [number] [EOL] ideal_cum_gain = ( [number] ** ideal_cum_gain ) - [number] [EOL] [EOL] discount = np . log2 ( np . arange ( len ( cum_gain ) ) + [number] ) [EOL] [EOL] dcg = np . sum ( cum_gain / discount ) [EOL] idcg = np . sum ( ideal_cum_gain / discount ) [EOL] [EOL] ndcg_score = dcg / idcg [EOL] [EOL] return { eval_name : ndcg_score } [EOL] [EOL] [EOL] @ curry def combined_evaluators ( test_data , evaluators ) : [EOL] [docstring] [EOL] return fp . merge ( e ( test_data ) for e in evaluators ) [EOL] [EOL] [EOL] @ curry def split_evaluator ( test_data , eval_fn , split_col , split_values = None , eval_name = None ) : [EOL] [docstring] [EOL] if split_values is None : [EOL] split_values = test_data [ split_col ] . unique ( ) [EOL] [EOL] if eval_name is None : [EOL] eval_name = [string] + split_col [EOL] [EOL] return { eval_name + [string] + str ( value ) : eval_fn ( test_data . loc [ lambda df : df [ split_col ] == value ] ) for value in split_values } [EOL] [EOL] [EOL] @ curry def temporal_split_evaluator ( test_data , eval_fn , time_col , time_format = [string] , split_values = None , eval_name = None ) : [EOL] [docstring] [EOL] [EOL] formatted_time_col = test_data [ time_col ] . dt . strftime ( time_format ) [EOL] unique_values = formatted_time_col . unique ( ) [EOL] [EOL] if eval_name is None : [EOL] eval_name = [string] + time_col [EOL] [EOL] if split_values is None : [EOL] split_values = unique_values [EOL] else : [EOL] if not ( all ( sv in unique_values for sv in split_values ) ) : [EOL] raise ValueError ( [string] ) [EOL] [EOL] return { eval_name + [string] + str ( value ) : eval_fn ( test_data . loc [ lambda df : formatted_time_col == value ] ) for value in split_values } [EOL] [EOL] [EOL] @ curry def permutation_evaluator ( test_data , predict_fn , eval_fn , baseline = True , features = None , shuffle_all_at_once = False , random_state = None ) : [EOL] [docstring] [EOL] [EOL] if features is None : [EOL] features = list ( test_data . columns ) [EOL] [EOL] def col_shuffler ( f ) : [EOL] return test_data [ f ] . sample ( frac = [number] , random_state = random_state ) . values [EOL] [EOL] def permutation_eval ( features_to_shuffle ) : [EOL] shuffled_cols = { f : col_shuffler ( f ) for f in features_to_shuffle } [EOL] return eval_fn ( predict_fn ( test_data . assign ( ** shuffled_cols ) ) ) [EOL] [EOL] if shuffle_all_at_once : [EOL] permutation_results = { [string] . join ( features ) : permutation_eval ( features ) } [EOL] else : [EOL] permutation_results = { f : permutation_eval ( [ f ] ) for f in features } [EOL] [EOL] feature_importance = { [string] : permutation_results } [EOL] [EOL] if baseline : [EOL] baseline_results = { [string] : eval_fn ( predict_fn ( test_data ) ) } [EOL] else : [EOL] baseline_results = { } [EOL] [EOL] return fp . merge ( feature_importance , baseline_results ) [EOL] [EOL] [EOL] @ curry def hash_evaluator ( test_data , hash_columns = None , eval_name = None , consider_index = False ) : [EOL] [docstring] [EOL] if hash_columns is None : [EOL] hash_columns = test_data . columns [EOL] [EOL] def calculate_dataframe_hash ( df , eval_name ) : [EOL] [comment] [EOL] return { eval_name : hash_pandas_object ( df ) . sum ( ) } [EOL] [EOL] if eval_name is None : [EOL] eval_name = [string] + [string] . join ( sorted ( hash_columns ) ) [EOL] eval_data = test_data [ hash_columns ] [EOL] [EOL] if not consider_index : [comment] [EOL] return calculate_dataframe_hash ( eval_data . set_index ( np . zeros ( len ( eval_data ) , dtype = [string] ) ) , eval_name ) [EOL] [EOL] return calculate_dataframe_hash ( eval_data , eval_name ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $fklearn.types.EvalReturnType$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Any , List [EOL] import builtins [EOL] import typing [EOL] import fklearn [EOL] import pandas [EOL] import random [EOL] from typing import List [EOL] [EOL] import numpy as np [EOL] from toolz import curry [EOL] import pandas as pd [EOL] [EOL] from fklearn . types import ColumnWisePerturbFnType [EOL] [EOL] [EOL] @ curry def shift_mu ( col , perc ) : [EOL] [docstring] [EOL] mu = np . mean ( col ) [EOL] col = col + mu * perc [EOL] return col [EOL] [EOL] [EOL] @ curry def random_noise ( col , mag ) : [EOL] [docstring] [EOL] mu = np . mean ( col ) [EOL] std = np . std ( col ) [EOL] noise = np . random . normal ( mu , std , len ( col ) ) * mag [EOL] return col + noise [EOL] [EOL] [EOL] @ curry def nullify ( col , perc = [number] ) : [EOL] [docstring] [EOL] [comment] [EOL] n = len ( col ) [EOL] ix_to_nan = random . sample ( range ( n ) , int ( n * perc ) ) [EOL] ret = col . copy ( deep = True ) [EOL] ret . iloc [ ix_to_nan ] = np . nan [EOL] return ret [EOL] [EOL] [EOL] @ curry def sample_columns ( data , perc ) : [EOL] [docstring] [EOL] return random . sample ( list ( data . columns ) , int ( len ( data . columns ) * perc ) ) [EOL] [EOL] [EOL] @ curry def perturbator ( data , cols , corruption_fn ) : [EOL] [docstring] [EOL] return data . assign ( ** { col : corruption_fn ( data [ col ] ) for col in cols } ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.Series$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.Series$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Optional , Any , Tuple [EOL] import typing [EOL] import pandas [EOL] import fklearn [EOL] import numpy [EOL] import builtins [EOL] from typing import Optional , Tuple [EOL] [EOL] import numpy as np [EOL] from numpy . random import RandomState [EOL] import pandas as pd [EOL] from sklearn . model_selection import StratifiedShuffleSplit [EOL] from toolz import curry [EOL] [EOL] from fklearn . types import DateType [EOL] [EOL] [EOL] @ curry def time_split_dataset ( dataset , train_start_date , train_end_date , holdout_end_date , time_column , holdout_start_date = None ) : [EOL] [docstring] [EOL] [EOL] holdout_start_date = holdout_start_date if holdout_start_date else train_end_date [EOL] [EOL] train_set = dataset [ ( dataset [ time_column ] >= train_start_date ) & ( dataset [ time_column ] < train_end_date ) ] [EOL] [EOL] test_set = dataset [ ( dataset [ time_column ] >= holdout_start_date ) & ( dataset [ time_column ] < holdout_end_date ) ] [EOL] [EOL] return train_set , test_set [EOL] [EOL] [EOL] @ curry def space_time_split_dataset ( dataset , train_start_date , train_end_date , holdout_end_date , split_seed , space_holdout_percentage , space_column , time_column , holdout_space = None , holdout_start_date = None ) : [EOL] [docstring] [EOL] holdout_start_date = holdout_start_date if holdout_start_date else train_end_date [EOL] [EOL] in_time_mask = ( dataset [ time_column ] >= train_start_date ) & ( dataset [ time_column ] < train_end_date ) [EOL] out_time_mask = ( dataset [ time_column ] >= holdout_start_date ) & ( dataset [ time_column ] < holdout_end_date ) [EOL] [EOL] all_space_in_time = dataset [ in_time_mask ] [ space_column ] . unique ( ) [EOL] [EOL] if holdout_space is None : [EOL] [comment] [EOL] state = RandomState ( split_seed ) [EOL] train_period_space = np . sort ( all_space_in_time ) [EOL] [EOL] [comment] [EOL] partial_holdout_space = state . choice ( train_period_space , int ( space_holdout_percentage * len ( train_period_space ) ) , replace = False ) [EOL] [EOL] in_space = pd . Index ( all_space_in_time ) . difference ( pd . Index ( partial_holdout_space ) ) . values [EOL] [EOL] else : [EOL] in_space = pd . Index ( all_space_in_time ) . difference ( pd . Index ( holdout_space ) ) . values [EOL] [EOL] in_space_mask = dataset [ space_column ] . isin ( in_space ) [EOL] [EOL] train_set = dataset [ in_space_mask & in_time_mask ] [EOL] intime_outspace_hdout = dataset [ ~ in_space_mask & in_time_mask ] [EOL] outtime_outspace_hdout = dataset [ ~ in_space_mask & out_time_mask ] [EOL] outtime_inspace_hdout = dataset [ in_space_mask & out_time_mask ] [EOL] [EOL] return train_set , intime_outspace_hdout , outtime_inspace_hdout , outtime_outspace_hdout [EOL] [EOL] [EOL] @ curry def stratified_split_dataset ( dataset , target_column , test_size , random_state = None ) : [EOL] [docstring] [EOL] train_placeholder = np . zeros ( len ( dataset ) ) [EOL] target = dataset [ target_column ] [EOL] [EOL] splitter = StratifiedShuffleSplit ( n_splits = [number] , test_size = test_size , random_state = random_state ) [EOL] [EOL] train_indices , test_indices = next ( splitter . split ( train_placeholder , target ) ) [EOL] train_set = dataset . iloc [ train_indices ] [EOL] test_set = dataset . iloc [ test_indices ] [EOL] [EOL] return train_set , test_set [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[pandas.DataFrame,pandas.DataFrame]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[pandas.DataFrame,...]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[pandas.DataFrame,pandas.DataFrame]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] import builtins [EOL] import pandas [EOL] import pandas as pd [EOL] from toolz import curry , partial [EOL] [EOL] [EOL] @ curry def rebalance_by_categorical ( dataset , categ_column , max_lines_by_categ = None , seed = [number] ) : [EOL] [docstring] [EOL] [EOL] categs = dataset [ categ_column ] . value_counts ( ) . to_dict ( ) [EOL] max_lines_by_categ = max_lines_by_categ if max_lines_by_categ else min ( categs . values ( ) ) [EOL] [EOL] return pd . concat ( [ ( dataset . loc [ dataset [ categ_column ] == categ , : ] . sample ( max_lines_by_categ , random_state = seed ) ) for categ in list ( categs . keys ( ) ) ] ) [EOL] [EOL] [EOL] @ curry def rebalance_by_continuous ( dataset , continuous_column , buckets , max_lines_by_categ = None , by_quantile = False , seed = [number] ) : [EOL] [docstring] [EOL] [EOL] bin_fn = partial ( pd . qcut , q = buckets , duplicates = [string] ) if by_quantile else partial ( pd . cut , bins = buckets ) [EOL] [EOL] return ( dataset . assign ( bins = bin_fn ( dataset [ continuous_column ] ) ) . pipe ( rebalance_by_categorical ( categ_column = [string] , max_lines_by_categ = max_lines_by_categ , seed = seed ) ) . drop ( columns = [ [string] ] ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Generator , Dict , Any , List [EOL] import typing [EOL] import fklearn [EOL] import builtins [EOL] from typing import Any , Dict , Generator , List [EOL] [EOL] from toolz . curried import reduce , partial , pipe , first , curry [EOL] [EOL] from fklearn . metrics . pd_extractors import extract [EOL] from fklearn . types import LogListType , LogType , ExtractorFnType , ValidatorReturnType , EvalReturnType [EOL] [EOL] [EOL] @ curry def get_avg_metric_from_extractor ( logs , extractor , metric_name ) : [EOL] metric_folds = extract ( logs [ [string] ] , extractor ) [EOL] return metric_folds [ metric_name ] . mean ( ) [EOL] [EOL] [EOL] def get_best_performing_log ( log_list , extractor , metric_name ) : [EOL] logs_eval = [ get_avg_metric_from_extractor ( log , extractor , metric_name ) for log in log_list ] [EOL] return pipe ( logs_eval , partial ( zip , log_list ) , partial ( sorted , reverse = True , key = lambda x : x [ [number] ] ) ) [ [number] ] [ [number] ] [EOL] [EOL] [EOL] def get_used_features ( log ) : [EOL] return first ( ( gen_dict_extract ( [string] , log ) ) ) [EOL] [EOL] [EOL] def order_feature_importance_avg_from_logs ( log ) : [EOL] d = first ( gen_dict_extract ( [string] , log ) ) [EOL] return sorted ( d , key = d . get , reverse = True ) [EOL] [EOL] [EOL] def gen_key_avgs_from_logs ( key , logs ) : [EOL] return gen_key_avgs_from_dicts ( [ gen_key_avgs_from_iteration ( key , log ) for log in logs ] ) [EOL] [EOL] [EOL] def gen_key_avgs_from_iteration ( key , log ) : [EOL] return first ( gen_dict_extract ( key , log ) ) [EOL] [EOL] [EOL] def gen_key_avgs_from_dicts ( obj ) : [EOL] sum_values_by_key = reduce ( lambda x , y : dict ( ( k , v + y . get ( k , [number] ) ) for k , v in x . items ( ) ) , obj ) [EOL] return { k : float ( v ) / len ( obj ) for k , v in sum_values_by_key . items ( ) } [EOL] [EOL] [EOL] def gen_dict_extract ( key , obj ) : [EOL] if hasattr ( obj , [string] ) : [EOL] for k , v in obj . items ( ) : [EOL] if k == key : [EOL] yield v [EOL] if isinstance ( v , dict ) : [EOL] for result in gen_dict_extract ( key , v ) : [EOL] yield result [EOL] elif isinstance ( v , list ) : [EOL] for d in v : [EOL] for result in gen_dict_extract ( key , d ) : [EOL] yield result [EOL] [EOL] [EOL] @ curry def gen_validator_log ( eval_log , fold_num , test_size ) : [EOL] return { [string] : [ { [string] : fold_num , [string] : { [string] : test_size } , [string] : [ eval_log ] } ] } [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.float]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.float]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Generator[typing.Any,None,None]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $fklearn.types.ValidatorReturnType$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Callable , Any , Type , List [EOL] import typing [EOL] import fklearn [EOL] import builtins [EOL] from typing import Callable [EOL] [EOL] from toolz . curried import curry , take , first [EOL] [EOL] from fklearn . tuning . utils import get_best_performing_log , get_avg_metric_from_extractor , get_used_features [EOL] from fklearn . types import ExtractorFnType , ListLogListType [EOL] [EOL] [EOL] StopFnType = Callable [ [ ListLogListType ] , bool ] [EOL] [EOL] [EOL] def aggregate_stop_funcs ( * stop_funcs ) : [EOL] [docstring] [EOL] [EOL] def p ( logs ) : [EOL] return any ( [ stop_fn ( logs ) for stop_fn in stop_funcs ] ) [EOL] [EOL] return p [EOL] [EOL] [EOL] @ curry def stop_by_iter_num ( logs , iter_limit = [number] ) : [EOL] [docstring] [EOL] [EOL] return len ( logs ) >= iter_limit [EOL] [EOL] [EOL] @ curry def stop_by_no_improvement ( logs , extractor , metric_name , early_stop = [number] , threshold = [number] ) : [EOL] [docstring] [EOL] [EOL] if len ( logs ) < early_stop : [EOL] return False [EOL] [EOL] limited_logs = list ( take ( early_stop , logs ) ) [EOL] curr_auc = get_avg_metric_from_extractor ( limited_logs [ - [number] ] , extractor , metric_name ) [EOL] [EOL] return all ( [ ( curr_auc - get_avg_metric_from_extractor ( log , extractor , metric_name ) ) <= threshold for log in limited_logs [ : - [number] ] ] ) [EOL] [EOL] [EOL] @ curry def stop_by_no_improvement_parallel ( logs , extractor , metric_name , early_stop = [number] , threshold = [number] ) : [EOL] [docstring] [EOL] [EOL] if len ( logs ) < early_stop : [EOL] return False [EOL] [EOL] log_list = [ get_best_performing_log ( log , extractor , metric_name ) for log in logs ] [EOL] [EOL] limited_logs = list ( take ( early_stop , log_list ) ) [EOL] curr_auc = get_avg_metric_from_extractor ( limited_logs [ - [number] ] , extractor , metric_name ) [EOL] [EOL] return all ( [ ( curr_auc - get_avg_metric_from_extractor ( log , extractor , metric_name ) ) <= threshold for log in limited_logs [ : - [number] ] ] ) [EOL] [EOL] [EOL] @ curry def stop_by_num_features ( logs , min_num_features = [number] ) : [EOL] [docstring] [EOL] [EOL] return len ( get_used_features ( first ( logs ) ) ) <= min_num_features [EOL] [EOL] [EOL] @ curry def stop_by_num_features_parallel ( logs , extractor , metric_name , min_num_features = [number] ) : [EOL] [docstring] [EOL] [EOL] best_log = get_best_performing_log ( first ( logs ) , extractor , metric_name ) [EOL] [EOL] return stop_by_num_features ( [ best_log ] , min_num_features ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Dict , Any , Tuple , List [EOL] import typing [EOL] import fklearn [EOL] import builtins [EOL] import pandas [EOL] import gc [EOL] from itertools import combinations [EOL] from typing import List , Tuple [EOL] [EOL] import pandas as pd [EOL] from joblib import Parallel , delayed [EOL] from numpy import random [EOL] from toolz . curried import curry , first , compose , valfilter , sorted , pipe , take [EOL] [EOL] from fklearn . tuning . utils import order_feature_importance_avg_from_logs , get_best_performing_log , gen_dict_extract , get_avg_metric_from_extractor , get_used_features , gen_validator_log [EOL] from fklearn . types import EvalFnType , ExtractorFnType , LogListType , LogType , PredictFnType [EOL] [EOL] [EOL] @ curry def remove_by_feature_importance ( log , num_removed_by_step = [number] ) : [EOL] [docstring] [EOL] return order_feature_importance_avg_from_logs ( log ) [ : - num_removed_by_step ] [EOL] [EOL] [EOL] @ curry def remove_features_subsets ( log_list , extractor , metric_name , num_removed_by_step = [number] ) : [EOL] [docstring] [EOL] [EOL] best_log = get_best_performing_log ( log_list , extractor , metric_name ) [EOL] best_subset = first ( gen_dict_extract ( [string] , best_log ) ) [EOL] [EOL] return list ( combinations ( best_subset , len ( best_subset ) - num_removed_by_step ) ) [EOL] [EOL] [EOL] @ curry def remove_by_feature_shuffling ( log , predict_fn , eval_fn , eval_data , extractor , metric_name , max_removed_by_step = [number] , threshold = [number] , speed_up_by_importance = False , parallel = False , nthread = [number] , seed = [number] ) : [EOL] [EOL] [docstring] [EOL] random . seed ( seed ) [EOL] [EOL] curr_metric = get_avg_metric_from_extractor ( log , extractor , metric_name ) [EOL] eval_size = eval_data . shape [ [number] ] [EOL] [EOL] features_to_shuffle = order_feature_importance_avg_from_logs ( log ) [ - max_removed_by_step : ] \ [EOL] if speed_up_by_importance else get_used_features ( log ) [EOL] [EOL] def shuffle ( feature ) : [EOL] return eval_data . assign ( ** { feature : eval_data [ feature ] . sample ( frac = [number] ) } ) [EOL] [EOL] feature_to_delta_metric = compose ( lambda m : curr_metric - m , get_avg_metric_from_extractor ( extractor = extractor , metric_name = metric_name ) , gen_validator_log ( fold_num = [number] , test_size = eval_size ) , eval_fn , predict_fn , shuffle ) [EOL] [EOL] if parallel : [EOL] metrics = Parallel ( n_jobs = nthread , backend = [string] ) ( delayed ( feature_to_delta_metric ) ( feature ) for feature in features_to_shuffle ) [EOL] feature_to_delta_metric = dict ( zip ( features_to_shuffle , metrics ) ) [EOL] gc . collect ( ) [EOL] [EOL] else : [EOL] feature_to_delta_metric = { feature : feature_to_delta_metric ( feature ) for feature in features_to_shuffle } [EOL] [EOL] return pipe ( feature_to_delta_metric , valfilter ( lambda delta_metric : delta_metric < threshold ) , sorted ( key = lambda f : feature_to_delta_metric . get ( f ) ) , take ( max_removed_by_step ) , list ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,...]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List [EOL] import builtins [EOL] import typing [EOL] import fklearn [EOL] import pandas [EOL] from typing import List [EOL] [EOL] import pandas as pd [EOL] from numpy import tril [EOL] from toolz import curry [EOL] [EOL] from fklearn . types import LogType [EOL] [EOL] [EOL] @ curry def correlation_feature_selection ( train_set , features , threshold = [number] ) : [EOL] [docstring] [EOL] [EOL] correlogram = train_set [ features ] . corr ( ) [EOL] correlogram_diag = pd . DataFrame ( tril ( correlogram . values ) , columns = correlogram . columns , index = correlogram . index ) [EOL] [EOL] features_to_drop = pd . melt ( correlogram_diag . reset_index ( ) , id_vars = [string] ) . query ( [string] ) . query ( [string] ) . query ( [string] % threshold ) [ [string] ] . tolist ( ) [EOL] [EOL] final_features = list ( set ( features ) - set ( features_to_drop ) ) [EOL] [EOL] return { [string] : correlogram . to_dict ( ) , [string] : features_to_drop , [string] : final_features } [EOL] [EOL] [EOL] @ curry def variance_feature_selection ( train_set , features , threshold = [number] ) : [EOL] [docstring] [EOL] [EOL] feature_var = train_set [ features ] . var ( ) [EOL] [EOL] features_to_drop = feature_var [ feature_var <= threshold ] . index . tolist ( ) [EOL] [EOL] final_features = list ( set ( features ) - set ( features_to_drop ) ) [EOL] [EOL] return { [string] : feature_var . to_dict ( ) , [string] : features_to_drop , [string] : final_features } [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $fklearn.types.LogType$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $fklearn.types.LogType$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Union , Dict , Any , List [EOL] import typing [EOL] import fklearn [EOL] import builtins [EOL] import pandas [EOL] from typing import Any , Dict , List [EOL] [EOL] import pandas as pd [EOL] from sklearn . ensemble import IsolationForest [EOL] import sklearn [EOL] from toolz import curry , merge [EOL] [EOL] from fklearn . common_docstrings import learner_pred_fn_docstring , learner_return_docstring [EOL] from fklearn . types import LearnerReturnType [EOL] from fklearn . training . utils import log_learner_time , expand_features_encoded [EOL] [EOL] [EOL] @ curry @ log_learner_time ( learner_name = [string] ) def isolation_forest_learner ( df , features , params = None , prediction_column = [string] , encode_extra_cols = True ) : [EOL] [docstring] [EOL] [EOL] default_params = { [string] : - [number] , [string] : [number] , [string] : [number] , [string] : [string] } [EOL] params = default_params if not params else merge ( default_params , params ) [EOL] [EOL] features = features if not encode_extra_cols else expand_features_encoded ( df , features ) [EOL] [EOL] model = IsolationForest ( ) [EOL] model . set_params ( ** params ) [EOL] model . fit ( df [ features ] . values ) [EOL] [EOL] def p ( new_df ) : [EOL] output_col = { prediction_column : model . decision_function ( new_df [ features ] ) } [EOL] [EOL] return new_df . assign ( ** output_col ) [EOL] [EOL] p . __doc__ = learner_pred_fn_docstring ( [string] ) [EOL] [EOL] log = { [string] : { [string] : features , [string] : params , [string] : prediction_column , [string] : [string] , [string] : sklearn . __version__ , [string] : len ( df ) } } [EOL] [EOL] return p , p ( df ) , log [EOL] [EOL] [EOL] isolation_forest_learner . __doc__ += learner_return_docstring ( [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $fklearn.types.LearnerReturnType$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List [EOL] import typing [EOL] import fklearn [EOL] import builtins [EOL] import pandas [EOL] from functools import reduce , wraps [EOL] from time import time [EOL] import re [EOL] from typing import Any , List [EOL] [EOL] import pandas as pd [EOL] from toolz import curry [EOL] import toolz as fp [EOL] [EOL] from fklearn . types import LearnerReturnType , UncurriedLearnerFnType [EOL] [EOL] [EOL] @ curry def log_learner_time ( learner , learner_name ) : [EOL] @ wraps ( learner ) def timed_learner ( * args , ** kwargs ) : [EOL] t0 = time ( ) [EOL] ( p , d , l ) = learner ( * args , ** kwargs ) [EOL] return p , d , fp . assoc_in ( l , [ learner_name , [string] ] , [string] % ( time ( ) - t0 ) ) [EOL] [EOL] return timed_learner [EOL] [EOL] [EOL] @ curry def print_learner_run ( learner , learner_name ) : [EOL] @ wraps ( learner ) def printed_learner ( * args , ** kwargs ) : [EOL] print ( [string] % learner_name ) [EOL] return learner ( * args , ** kwargs ) [EOL] [EOL] return printed_learner [EOL] [EOL] [EOL] def expand_features_encoded ( df , features ) : [EOL] [EOL] [docstring] [EOL] [EOL] def fklearn_features ( df ) : [EOL] return list ( filter ( lambda col : col . startswith ( [string] ) , df . columns ) ) [EOL] [EOL] def feature_prefix ( feature ) : [EOL] return feature . split ( [string] ) [ [number] ] [EOL] [EOL] def filter_non_listed_features ( fklearn_features , features ) : [EOL] possible_prefixes_with_listed_features = [ [string] + f for f in features ] [EOL] return list ( filter ( lambda col : feature_prefix ( col ) in possible_prefixes_with_listed_features , fklearn_features ) ) [EOL] [EOL] def remove_original_pre_encoded_features ( features , encoded_features ) : [EOL] expr = [string] [EOL] original_preencoded_features = reduce ( lambda x , y : x + y , ( map ( lambda x : re . findall ( expr , x ) , encoded_features ) ) , [ ] ) [EOL] return list ( filter ( lambda col : col not in set ( original_preencoded_features ) , features ) ) [EOL] [EOL] all_fklearn_features = fklearn_features ( df ) [EOL] encoded_features = filter_non_listed_features ( all_fklearn_features , features ) [EOL] not_encoded_features = remove_original_pre_encoded_features ( features , encoded_features ) [EOL] return not_encoded_features + encoded_features [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $fklearn.types.UncurriedLearnerFnType$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $fklearn.types.LearnerReturnType$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Union , Dict , Any , List [EOL] import typing [EOL] import pandas [EOL] import fklearn [EOL] import sklearn [EOL] import builtins [EOL] from typing import Any , Dict , List , Union [EOL] [EOL] import numpy as np [EOL] import pandas as pd [EOL] from toolz import merge , curry , assoc [EOL] from sklearn . linear_model import LinearRegression [EOL] from sklearn . gaussian_process import GaussianProcessRegressor , kernels [EOL] from sklearn import __version__ as sk_version [EOL] [EOL] from fklearn . common_docstrings import learner_pred_fn_docstring , learner_return_docstring [EOL] from fklearn . types import LearnerReturnType [EOL] from fklearn . training . utils import log_learner_time , expand_features_encoded [EOL] [EOL] [EOL] @ curry @ log_learner_time ( learner_name = [string] ) def linear_regression_learner ( df , features , target , params = None , prediction_column = [string] , weight_column = None , encode_extra_cols = True ) : [EOL] [docstring] [EOL] [EOL] def_params = { [string] : True } [EOL] params = def_params if not params else merge ( def_params , params ) [EOL] [EOL] weights = df [ weight_column ] . values if weight_column else None [EOL] [EOL] features = features if not encode_extra_cols else expand_features_encoded ( df , features ) [EOL] [EOL] regr = LinearRegression ( ** params ) [EOL] regr . fit ( df [ features ] . values , df [ target ] . values , sample_weight = weights ) [EOL] [EOL] def p ( new_df ) : [EOL] return new_df . assign ( ** { prediction_column : regr . predict ( new_df [ features ] . values ) } ) [EOL] [EOL] p . __doc__ = learner_pred_fn_docstring ( [string] ) [EOL] [EOL] log = { [string] : { [string] : features , [string] : target , [string] : params , [string] : prediction_column , [string] : [string] , [string] : sk_version , [string] : dict ( zip ( features , regr . coef_ . flatten ( ) ) ) , [string] : len ( df ) } , [string] : regr } [EOL] [EOL] return p , p ( df ) , log [EOL] [EOL] [EOL] linear_regression_learner . __doc__ += learner_return_docstring ( [string] ) [EOL] [EOL] [EOL] @ curry @ log_learner_time ( learner_name = [string] ) def xgb_regression_learner ( df , features , target , learning_rate = [number] , num_estimators = [number] , extra_params = None , prediction_column = [string] , weight_column = None , encode_extra_cols = True ) : [EOL] [docstring] [EOL] [EOL] import xgboost as xgb [EOL] [EOL] weights = df [ weight_column ] . values if weight_column else None [EOL] params = extra_params if extra_params else { } [EOL] params = assoc ( params , [string] , learning_rate ) [EOL] params = params if [string] in params else assoc ( params , [string] , [string] ) [EOL] [EOL] features = features if not encode_extra_cols else expand_features_encoded ( df , features ) [EOL] [EOL] dtrain = xgb . DMatrix ( df [ features ] . values , label = df [ target ] . values , weight = weights , feature_names = map ( str , features ) ) [EOL] [EOL] bst = xgb . train ( params , dtrain , num_estimators ) [EOL] [EOL] def p ( new_df , apply_shap = False ) : [EOL] dtest = xgb . DMatrix ( new_df [ features ] . values , feature_names = map ( str , features ) ) [EOL] col_dict = { prediction_column : bst . predict ( dtest ) } [EOL] [EOL] if apply_shap : [EOL] import shap [EOL] explainer = shap . TreeExplainer ( bst ) [EOL] shap_values = list ( explainer . shap_values ( new_df [ features ] ) ) [EOL] shap_expected_value = explainer . expected_value [EOL] [EOL] shap_output = { [string] : shap_values , [string] : np . repeat ( shap_expected_value , len ( shap_values ) ) } [EOL] [EOL] col_dict = merge ( col_dict , shap_output ) [EOL] [EOL] return new_df . assign ( ** col_dict ) [EOL] [EOL] p . __doc__ = learner_pred_fn_docstring ( [string] , shap = True ) [EOL] [EOL] log = { [string] : { [string] : features , [string] : target , [string] : prediction_column , [string] : [string] , [string] : xgb . __version__ , [string] : assoc ( params , [string] , num_estimators ) , [string] : bst . get_score ( ) , [string] : len ( df ) } , [string] : bst } [EOL] [EOL] return p , p ( df ) , log [EOL] [EOL] [EOL] xgb_regression_learner . __doc__ += learner_return_docstring ( [string] ) [EOL] [EOL] [EOL] @ curry @ log_learner_time ( learner_name = [string] ) def catboost_regressor_learner ( df , features , target , learning_rate = [number] , num_estimators = [number] , extra_params = None , prediction_column = [string] , weight_column = None ) : [EOL] [docstring] [EOL] from catboost import Pool , CatBoostRegressor [EOL] import catboost [EOL] [EOL] weights = df [ weight_column ] . values if weight_column else None [EOL] params = extra_params if extra_params else { } [EOL] params = assoc ( params , [string] , learning_rate ) [EOL] [EOL] dtrain = Pool ( df [ features ] . values , df [ target ] . values , weight = weights , feature_names = list ( map ( str , features ) ) ) [EOL] cat_boost_regressor = CatBoostRegressor ( iterations = num_estimators , ** params ) [EOL] cbr = cat_boost_regressor . fit ( dtrain , verbose = [number] ) [EOL] [EOL] def p ( new_df , apply_shap = False ) : [EOL] dtest = Pool ( new_df [ features ] . values , feature_names = list ( map ( str , features ) ) ) [EOL] col_dict = { prediction_column : cbr . predict ( dtest ) } [EOL] [EOL] if apply_shap : [EOL] import shap [EOL] explainer = shap . TreeExplainer ( cbr ) [EOL] shap_values = list ( explainer . shap_values ( new_df [ features ] ) ) [EOL] shap_expected_value = explainer . expected_value [EOL] [EOL] shap_output = { [string] : shap_values , [string] : np . repeat ( shap_expected_value , len ( shap_values ) ) } [EOL] [EOL] col_dict = merge ( col_dict , shap_output ) [EOL] [EOL] return new_df . assign ( ** col_dict ) [EOL] [EOL] p . __doc__ = learner_pred_fn_docstring ( [string] , shap = False ) [EOL] [EOL] log = { [string] : { [string] : features , [string] : target , [string] : prediction_column , [string] : [string] , [string] : catboost . __version__ , [string] : assoc ( params , [string] , num_estimators ) , [string] : cbr . feature_importances_ , [string] : len ( df ) } , [string] : cbr } [EOL] [EOL] return p , p ( df ) , log [EOL] [EOL] [EOL] catboost_regressor_learner . __doc__ += learner_return_docstring ( [string] ) [EOL] [EOL] [EOL] @ curry @ log_learner_time ( learner_name = [string] ) def gp_regression_learner ( df , features , target , kernel = None , alpha = [number] , extra_variance = [string] , return_std = False , extra_params = None , prediction_column = [string] , encode_extra_cols = True ) : [EOL] [docstring] [EOL] [EOL] params = extra_params if extra_params else { } [EOL] [EOL] params [ [string] ] = alpha [EOL] params [ [string] ] = kernel [EOL] [EOL] features = features if not encode_extra_cols else expand_features_encoded ( df , features ) [EOL] [EOL] gp = GaussianProcessRegressor ( ** params ) [EOL] gp . fit ( df [ features ] , df [ target ] ) [EOL] [EOL] extra_variance = df [ target ] . std ( ) if extra_variance == [string] else extra_variance if extra_variance else [number] [EOL] [EOL] def p ( new_df ) : [EOL] if return_std : [EOL] pred_mean , pred_std = gp . predict ( df [ features ] , return_std = True ) [EOL] pred_std *= extra_variance [EOL] return new_df . assign ( ** { prediction_column : pred_mean , prediction_column + [string] : pred_std } ) [EOL] else : [EOL] return new_df . assign ( ** { prediction_column : gp . predict ( df [ features ] ) } ) [EOL] [EOL] p . __doc__ = learner_pred_fn_docstring ( [string] ) [EOL] [EOL] log = { [string] : { [string] : features , [string] : target , [string] : merge ( params , { [string] : extra_variance , [string] : return_std } ) , [string] : prediction_column , [string] : [string] , [string] : sk_version , [string] : len ( df ) } , [string] : gp } [EOL] [EOL] return p , p ( df ) , log [EOL] [EOL] [EOL] gp_regression_learner . __doc__ += learner_return_docstring ( [string] ) [EOL] [EOL] [EOL] @ curry @ log_learner_time ( learner_name = [string] ) def lgbm_regression_learner ( df , features , target , learning_rate = [number] , num_estimators = [number] , extra_params = None , prediction_column = [string] , weight_column = None , encode_extra_cols = True ) : [EOL] [docstring] [EOL] [EOL] import lightgbm as lgbm [EOL] [EOL] params = extra_params if extra_params else { } [EOL] params = assoc ( params , [string] , learning_rate ) [EOL] params = params if [string] in params else assoc ( params , [string] , [string] ) [EOL] [EOL] weights = df [ weight_column ] . values if weight_column else None [EOL] [EOL] features = features if not encode_extra_cols else expand_features_encoded ( df , features ) [EOL] [EOL] dtrain = lgbm . Dataset ( df [ features ] . values , label = df [ target ] , feature_name = list ( map ( str , features ) ) , weight = weights , silent = True ) [EOL] [EOL] bst = lgbm . train ( params , dtrain , num_estimators ) [EOL] [EOL] def p ( new_df , apply_shap = False ) : [EOL] col_dict = { prediction_column : bst . predict ( new_df [ features ] . values ) } [EOL] [EOL] if apply_shap : [EOL] import shap [EOL] explainer = shap . TreeExplainer ( bst ) [EOL] shap_values = list ( explainer . shap_values ( new_df [ features ] ) ) [EOL] shap_expected_value = explainer . expected_value [EOL] [EOL] shap_output = { [string] : shap_values , [string] : np . repeat ( shap_expected_value , len ( shap_values ) ) } [EOL] [EOL] col_dict = merge ( col_dict , shap_output ) [EOL] [EOL] return new_df . assign ( ** col_dict ) [EOL] [EOL] p . __doc__ = learner_pred_fn_docstring ( [string] , shap = True ) [EOL] [EOL] log = { [string] : { [string] : features , [string] : target , [string] : prediction_column , [string] : [string] , [string] : lgbm . __version__ , [string] : assoc ( params , [string] , num_estimators ) , [string] : dict ( zip ( features , bst . feature_importance ( ) . tolist ( ) ) ) , [string] : len ( df ) } , [string] : bst } [EOL] [EOL] return p , p ( df ) , log [EOL] [EOL] [EOL] lgbm_regression_learner . __doc__ += learner_return_docstring ( [string] ) [EOL] [EOL] [EOL] @ curry @ log_learner_time ( learner_name = [string] ) def custom_supervised_model_learner ( df , features , target , model , supervised_type , log , prediction_column = [string] ) : [EOL] [docstring] [EOL] [EOL] if len ( log ) != [number] : [EOL] raise ValueError ( [string] ) [EOL] if supervised_type not in ( [string] , [string] ) : [EOL] raise TypeError ( [string] ) [EOL] if not hasattr ( model , [string] ) : [EOL] raise AttributeError ( [string] ) [EOL] if supervised_type == [string] and not hasattr ( model , [string] ) : [EOL] raise AttributeError ( [string] ) [EOL] if supervised_type == [string] and not hasattr ( model , [string] ) : [EOL] raise AttributeError ( [string] ) [EOL] [EOL] model . fit ( df [ features ] . values , df [ target ] . values ) [EOL] [EOL] def p ( new_df ) : [EOL] if supervised_type == [string] : [EOL] pred = model . predict_proba ( new_df [ features ] . values ) [EOL] col_dict = { } [EOL] for ( key , value ) in enumerate ( pred . T ) : [EOL] col_dict . update ( { prediction_column + [string] + str ( key ) : value } ) [EOL] elif supervised_type == [string] : [EOL] col_dict = { prediction_column : model . predict ( new_df [ features ] . values ) } [EOL] [EOL] return new_df . assign ( ** col_dict ) [EOL] [EOL] p . __doc__ = learner_pred_fn_docstring ( [string] ) [EOL] [EOL] log [ [string] ] = model [EOL] [EOL] return p , p ( df ) , log [EOL] [EOL] [EOL] custom_supervised_model_learner . __doc__ += learner_return_docstring ( [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $fklearn.types.LearnerReturnType$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , Any [EOL] import typing [EOL] import fklearn [EOL] import builtins [EOL] import pandas [EOL] import pandas as pd [EOL] import sklearn [EOL] from sklearn . isotonic import IsotonicRegression [EOL] from toolz import curry [EOL] [EOL] from fklearn . common_docstrings import learner_pred_fn_docstring , learner_return_docstring [EOL] from fklearn . types import LearnerReturnType [EOL] from fklearn . training . utils import log_learner_time [EOL] [EOL] [EOL] @ curry @ log_learner_time ( learner_name = [string] ) def isotonic_calibration_learner ( df , target_column = [string] , prediction_column = [string] , output_column = [string] , y_min = [number] , y_max = [number] ) : [EOL] [docstring] [EOL] [EOL] clf = IsotonicRegression ( y_min = y_min , y_max = y_max , out_of_bounds = [string] ) [EOL] [EOL] clf . fit ( df [ prediction_column ] , df [ target_column ] ) [EOL] [EOL] def p ( new_df ) : [EOL] return new_df . assign ( ** { output_column : clf . predict ( new_df [ prediction_column ] ) } ) [EOL] [EOL] p . __doc__ = learner_pred_fn_docstring ( [string] ) [EOL] [EOL] log = { [string] : { [string] : output_column , [string] : target_column , [string] : prediction_column , [string] : [string] , [string] : sklearn . __version__ , [string] : len ( df ) } , [string] : clf } [EOL] [EOL] return p , p ( df ) , log [EOL] [EOL] [EOL] isotonic_calibration_learner . __doc__ += learner_return_docstring ( [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $fklearn.types.LearnerReturnType$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Union , Dict , Any , List [EOL] import typing [EOL] import pandas [EOL] import fklearn [EOL] import numpy [EOL] import builtins [EOL] from typing import List , Any [EOL] [EOL] import numpy as np [EOL] import pandas as pd [EOL] from toolz import curry , merge , assoc [EOL] from sklearn . feature_extraction . text import TfidfVectorizer [EOL] from sklearn . linear_model import LogisticRegression [EOL] from sklearn import __version__ as sk_version [EOL] [EOL] from fklearn . types import LearnerReturnType , LogType [EOL] from fklearn . common_docstrings import learner_return_docstring , learner_pred_fn_docstring [EOL] from fklearn . training . utils import log_learner_time , expand_features_encoded [EOL] [EOL] [EOL] @ curry @ log_learner_time ( learner_name = [string] ) def logistic_classification_learner ( df , features , target , params = None , prediction_column = [string] , weight_column = None , encode_extra_cols = True ) : [EOL] [docstring] [EOL] [EOL] def_params = { [string] : [number] , [string] : [string] , [string] : [string] } [EOL] merged_params = def_params if not params else merge ( def_params , params ) [EOL] [EOL] weights = df [ weight_column ] . values if weight_column else None [EOL] [EOL] features = features if not encode_extra_cols else expand_features_encoded ( df , features ) [EOL] [EOL] clf = LogisticRegression ( ** merged_params ) [EOL] clf . fit ( df [ features ] . values , df [ target ] . values , sample_weight = weights ) [EOL] [EOL] def p ( new_df ) : [EOL] pred = clf . predict_proba ( new_df [ features ] . values ) [EOL] if merged_params [ [string] ] == [string] : [EOL] col_dict = { prediction_column + [string] + str ( key ) : value for ( key , value ) in enumerate ( pred . T ) } [EOL] col_dict . update ( { prediction_column : pred . argmax ( axis = [number] ) } ) [EOL] else : [EOL] col_dict = { prediction_column : pred [ : , [number] ] } [EOL] [EOL] return new_df . assign ( ** col_dict ) [EOL] [EOL] p . __doc__ = learner_pred_fn_docstring ( [string] ) [EOL] [EOL] log = { [string] : { [string] : features , [string] : target , [string] : merged_params , [string] : prediction_column , [string] : [string] , [string] : sk_version , [string] : dict ( zip ( features , clf . coef_ . flatten ( ) ) ) , [string] : len ( df ) } , [string] : clf } [EOL] [EOL] return p , p ( df ) , log [EOL] [EOL] [EOL] logistic_classification_learner . __doc__ += learner_return_docstring ( [string] ) [EOL] [EOL] [EOL] @ curry @ log_learner_time ( learner_name = [string] ) def xgb_classification_learner ( df , features , target , learning_rate = [number] , num_estimators = [number] , extra_params = None , prediction_column = [string] , weight_column = None , encode_extra_cols = True ) : [EOL] [docstring] [EOL] [EOL] import xgboost as xgb [EOL] [EOL] params = extra_params if extra_params else { } [EOL] params = assoc ( params , [string] , learning_rate ) [EOL] params = params if [string] in params else assoc ( params , [string] , [string] ) [EOL] [EOL] weights = df [ weight_column ] . values if weight_column else None [EOL] [EOL] features = features if not encode_extra_cols else expand_features_encoded ( df , features ) [EOL] [EOL] dtrain = xgb . DMatrix ( df [ features ] . values , label = df [ target ] . values , feature_names = map ( str , features ) , weight = weights ) [EOL] [EOL] bst = xgb . train ( params , dtrain , num_estimators ) [EOL] [EOL] def p ( new_df , apply_shap = False ) : [EOL] [EOL] dtest = xgb . DMatrix ( new_df [ features ] . values , feature_names = map ( str , features ) ) [EOL] [EOL] pred = bst . predict ( dtest ) [EOL] if params [ [string] ] == [string] : [EOL] col_dict = { prediction_column + [string] + str ( key ) : value for ( key , value ) in enumerate ( pred . T ) } [EOL] col_dict . update ( { prediction_column : pred . argmax ( axis = [number] ) } ) [EOL] else : [EOL] col_dict = { prediction_column : pred } [EOL] [EOL] if apply_shap : [EOL] import shap [EOL] explainer = shap . TreeExplainer ( bst ) [EOL] shap_values = explainer . shap_values ( new_df [ features ] ) [EOL] shap_expected_value = explainer . expected_value [EOL] [EOL] if params [ [string] ] == [string] : [EOL] shap_values_multiclass = { f" [string] { class_index }" : list ( value ) for ( class_index , value ) in enumerate ( shap_values ) } [EOL] shap_expected_value_multiclass = { f" [string] { class_index }" : np . repeat ( expected_value , len ( class_shap_values ) ) for ( class_index , ( expected_value , class_shap_values ) ) in enumerate ( zip ( shap_expected_value , shap_values ) ) } [EOL] shap_output = merge ( shap_values_multiclass , shap_expected_value_multiclass ) [EOL] [EOL] else : [EOL] shap_values = list ( shap_values ) [EOL] shap_output = { [string] : shap_values , [string] : np . repeat ( shap_expected_value , len ( shap_values ) ) } [EOL] [EOL] col_dict = merge ( col_dict , shap_output ) [EOL] [EOL] return new_df . assign ( ** col_dict ) [EOL] [EOL] p . __doc__ = learner_pred_fn_docstring ( [string] , shap = True ) [EOL] [EOL] log = { [string] : { [string] : features , [string] : target , [string] : prediction_column , [string] : [string] , [string] : xgb . __version__ , [string] : assoc ( params , [string] , num_estimators ) , [string] : bst . get_score ( ) , [string] : len ( df ) } , [string] : bst } [EOL] [EOL] return p , p ( df ) , log [EOL] [EOL] [EOL] xgb_classification_learner . __doc__ += learner_return_docstring ( [string] ) [EOL] [EOL] [EOL] @ curry def _get_catboost_shap_values ( df , cbr , features , target , weights , cat_features ) : [EOL] [docstring] [EOL] import catboost [EOL] dtrain = catboost . Pool ( df [ features ] . values , df [ target ] . values , weight = weights , feature_names = list ( map ( str , features ) ) , cat_features = cat_features ) [EOL] return cbr . get_feature_importance ( type = catboost . EFstrType . ShapValues , data = dtrain ) [EOL] [EOL] [EOL] @ curry @ log_learner_time ( learner_name = [string] ) def catboost_classification_learner ( df , features , target , learning_rate = [number] , num_estimators = [number] , extra_params = None , prediction_column = [string] , weight_column = None , encode_extra_cols = True ) : [EOL] [docstring] [EOL] from catboost import Pool , CatBoostClassifier [EOL] import catboost [EOL] [EOL] weights = df [ weight_column ] . values if weight_column else None [EOL] params = extra_params if extra_params else { } [EOL] params = assoc ( params , [string] , learning_rate ) [EOL] params = params if [string] in params else assoc ( params , [string] , [string] ) [EOL] [EOL] features = features if not encode_extra_cols else expand_features_encoded ( df , features ) [EOL] [EOL] cat_features = params [ [string] ] if [string] in params else None [EOL] [EOL] dtrain = Pool ( df [ features ] . values , df [ target ] . values , weight = weights , feature_names = list ( map ( str , features ) ) , cat_features = cat_features ) [EOL] [EOL] cat_boost_classifier = CatBoostClassifier ( iterations = num_estimators , ** params ) [EOL] cbr = cat_boost_classifier . fit ( dtrain , verbose = [number] ) [EOL] [EOL] def p ( new_df , apply_shap = False ) : [EOL] [EOL] pred = cbr . predict_proba ( new_df [ features ] ) [EOL] if params [ [string] ] == [string] : [EOL] col_dict = { prediction_column + [string] + str ( key ) : value for ( key , value ) in enumerate ( pred . T ) } [EOL] col_dict . update ( { prediction_column : pred . argmax ( axis = [number] ) } ) [EOL] else : [EOL] col_dict = { prediction_column : pred [ : , [number] ] } [EOL] [EOL] if apply_shap : [EOL] import shap [EOL] if params [ [string] ] == [string] : [EOL] shap_values = _get_catboost_shap_values ( df , cbr , features , target , weights , cat_features ) [EOL] [comment] [EOL] [comment] [EOL] shap_values = shap_values . transpose ( [number] , [number] , [number] ) [EOL] shap_values_multiclass = { f" [string] { class_index }" : list ( value [ : , : - [number] ] ) for ( class_index , value ) in enumerate ( shap_values ) } [EOL] shap_expected_value_multiclass = { f" [string] { class_index }" : value [ : , - [number] ] for ( class_index , value ) in enumerate ( shap_values ) } [EOL] shap_output = merge ( shap_values_multiclass , shap_expected_value_multiclass ) [EOL] [EOL] else : [EOL] explainer = shap . TreeExplainer ( cbr ) [EOL] shap_values = explainer . shap_values ( new_df [ features ] ) [EOL] shap_expected_value = explainer . expected_value [EOL] shap_values = list ( shap_values ) [EOL] shap_output = { [string] : shap_values , [string] : np . repeat ( shap_expected_value , len ( shap_values ) ) } [EOL] [EOL] col_dict = merge ( col_dict , shap_output ) [EOL] [EOL] return new_df . assign ( ** col_dict ) [EOL] [EOL] p . __doc__ = learner_pred_fn_docstring ( [string] , shap = True ) [EOL] [EOL] log = { [string] : { [string] : features , [string] : target , [string] : prediction_column , [string] : [string] , [string] : catboost . __version__ , [string] : assoc ( params , [string] , num_estimators ) , [string] : cbr . feature_importances_ , [string] : len ( df ) } , [string] : cbr } [EOL] [EOL] return p , p ( df ) , log [EOL] [EOL] [EOL] catboost_classification_learner . __doc__ += learner_return_docstring ( [string] ) [EOL] [EOL] [EOL] @ curry @ log_learner_time ( learner_name = [string] ) def nlp_logistic_classification_learner ( df , text_feature_cols , target , vectorizer_params = None , logistic_params = None , prediction_column = [string] ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] default_vect_params = { [string] : [string] , [string] : [number] } [EOL] merged_vect_params = default_vect_params if not vectorizer_params else merge ( default_vect_params , vectorizer_params ) [EOL] [EOL] default_clf_params = { [string] : [number] , [string] : [string] , [string] : [string] } [EOL] merged_logistic_params = default_clf_params if not logistic_params else merge ( default_clf_params , logistic_params ) [EOL] [EOL] vect = TfidfVectorizer ( ** merged_vect_params ) [EOL] clf = LogisticRegression ( ** merged_logistic_params ) [EOL] [EOL] text_df = df [ text_feature_cols ] . apply ( lambda x : x + [string] , axis = [number] ) . sum ( axis = [number] ) [EOL] vect . fit ( text_df . values ) [EOL] sparse_vect = vect . transform ( text_df . values ) [EOL] clf . fit ( sparse_vect , df [ target ] . values ) [EOL] [EOL] def p ( new_df ) : [EOL] [EOL] predict_text_df = new_df [ text_feature_cols ] . apply ( lambda x : x + [string] , axis = [number] ) . sum ( axis = [number] ) [EOL] predict_sparse_vect = vect . transform ( predict_text_df ) [EOL] [EOL] if merged_logistic_params [ [string] ] == [string] : [EOL] col_dict = { prediction_column + [string] + str ( key ) : value for ( key , value ) in enumerate ( clf . predict_proba ( predict_sparse_vect ) . T ) } [EOL] else : [EOL] col_dict = { prediction_column : clf . predict_proba ( predict_sparse_vect ) [ : , [number] ] } [EOL] [EOL] return new_df . assign ( ** col_dict ) [EOL] [EOL] p . __doc__ = learner_pred_fn_docstring ( [string] ) [EOL] [EOL] params = { [string] : merged_vect_params , [string] : merged_logistic_params } [EOL] [EOL] log = { [string] : { [string] : text_feature_cols , [string] : target , [string] : prediction_column , [string] : assoc ( params , [string] , sparse_vect . shape [ [number] ] ) , [string] : [string] , [string] : sk_version , [string] : len ( df ) } , [string] : clf } [EOL] [EOL] return p , p ( df ) , log [EOL] [EOL] [EOL] nlp_logistic_classification_learner . __doc__ += learner_return_docstring ( [string] ) [EOL] [EOL] [EOL] @ curry @ log_learner_time ( learner_name = [string] ) def lgbm_classification_learner ( df , features , target , learning_rate = [number] , num_estimators = [number] , extra_params = None , prediction_column = [string] , weight_column = None , encode_extra_cols = True ) : [EOL] [docstring] [EOL] [EOL] import lightgbm as lgbm [EOL] [EOL] params = extra_params if extra_params else { } [EOL] params = assoc ( params , [string] , learning_rate ) [EOL] params = params if [string] in params else assoc ( params , [string] , [string] ) [EOL] [EOL] weights = df [ weight_column ] . values if weight_column else None [EOL] [EOL] features = features if not encode_extra_cols else expand_features_encoded ( df , features ) [EOL] [EOL] dtrain = lgbm . Dataset ( df [ features ] . values , label = df [ target ] , feature_name = list ( map ( str , features ) ) , weight = weights , silent = True ) [EOL] [EOL] bst = lgbm . train ( params , dtrain , num_estimators ) [EOL] [EOL] def p ( new_df , apply_shap = False ) : [EOL] if params [ [string] ] == [string] : [EOL] col_dict = { prediction_column + [string] + str ( key ) : value for ( key , value ) in enumerate ( bst . predict ( new_df [ features ] . values ) . T ) } [EOL] else : [EOL] col_dict = { prediction_column : bst . predict ( new_df [ features ] . values ) } [EOL] [EOL] if apply_shap : [EOL] import shap [EOL] explainer = shap . TreeExplainer ( bst ) [EOL] shap_values = explainer . shap_values ( new_df [ features ] ) [EOL] shap_expected_value = explainer . expected_value [EOL] [EOL] if params [ [string] ] == [string] : [EOL] shap_values_multiclass = { f" [string] { class_index }" : list ( value ) for ( class_index , value ) in enumerate ( shap_values ) } [EOL] shap_expected_value_multiclass = { f" [string] { class_index }" : np . repeat ( expected_value , len ( class_shap_values ) ) for ( class_index , ( expected_value , class_shap_values ) ) in enumerate ( zip ( shap_expected_value , shap_values ) ) } [EOL] shap_output = merge ( shap_values_multiclass , shap_expected_value_multiclass ) [EOL] [EOL] else : [EOL] shap_values = list ( shap_values [ [number] ] ) [EOL] shap_output = { [string] : shap_values , [string] : np . repeat ( shap_expected_value [ [number] ] , len ( shap_values ) ) } [EOL] [EOL] col_dict = merge ( col_dict , shap_output ) [EOL] [EOL] return new_df . assign ( ** col_dict ) [EOL] [EOL] p . __doc__ = learner_pred_fn_docstring ( [string] , shap = True ) [EOL] [EOL] log = { [string] : { [string] : features , [string] : target , [string] : prediction_column , [string] : [string] , [string] : lgbm . __version__ , [string] : assoc ( params , [string] , num_estimators ) , [string] : dict ( zip ( features , bst . feature_importance ( ) . tolist ( ) ) ) , [string] : len ( df ) } , [string] : bst } [EOL] [EOL] return p , p ( df ) , log [EOL] [EOL] [EOL] lgbm_classification_learner . __doc__ += learner_return_docstring ( [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $fklearn.types.LearnerReturnType$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Optional , Dict , Any , List [EOL] import typing [EOL] import fklearn [EOL] import builtins [EOL] import pandas [EOL] from typing import Any , List , Optional [EOL] [EOL] import pandas as pd [EOL] from sklearn . impute import SimpleImputer [EOL] from toolz import curry , identity [EOL] [EOL] from fklearn . common_docstrings import learner_return_docstring , learner_pred_fn_docstring [EOL] from fklearn . types import LearnerReturnType [EOL] from fklearn . training . utils import log_learner_time [EOL] [EOL] [EOL] @ curry @ log_learner_time ( learner_name = [string] ) def imputer ( df , columns_to_impute , impute_strategy = [string] , placeholder_value = None ) : [EOL] [docstring] [EOL] [EOL] if placeholder_value is not None : [EOL] mask_feat_is_na = df [ columns_to_impute ] . isna ( ) . all ( axis = [number] ) [EOL] columns_to_fill = mask_feat_is_na [ mask_feat_is_na ] . index . values [EOL] columns_imputable = mask_feat_is_na [ ~ mask_feat_is_na ] . index . values [EOL] [EOL] fill_fn , _ , fill_logs = placeholder_imputer ( df , columns_to_impute = columns_to_fill , placeholder_value = placeholder_value ) [EOL] else : [EOL] columns_to_fill = list ( ) [EOL] columns_imputable = columns_to_impute [EOL] fill_fn , _ , fill_logs = identity , None , dict ( ) [EOL] [EOL] imp = SimpleImputer ( strategy = impute_strategy ) [EOL] [EOL] imp . fit ( df [ columns_imputable ] . values ) [EOL] [EOL] def p ( new_data_set ) : [EOL] new_data = imp . transform ( new_data_set [ columns_imputable ] ) [EOL] new_cols = pd . DataFrame ( data = new_data , columns = columns_imputable ) . to_dict ( [string] ) [EOL] return fill_fn ( new_data_set . assign ( ** new_cols ) ) [EOL] [EOL] p . __doc__ = learner_pred_fn_docstring ( [string] ) [EOL] [EOL] log = { [string] : { [string] : impute_strategy , [string] : placeholder_value , [string] : columns_to_impute , [string] : columns_to_fill , [string] : columns_imputable , [string] : df [ columns_to_impute ] . isnull ( ) . mean ( axis = [number] ) . to_dict ( ) , [string] : imp . statistics_ , [string] : fill_fn , [string] : fill_logs , } } [EOL] [EOL] return p , p ( df ) , log [EOL] [EOL] [EOL] imputer . __doc__ += learner_return_docstring ( [string] ) [EOL] [EOL] [EOL] @ curry @ log_learner_time ( learner_name = [string] ) def placeholder_imputer ( df , columns_to_impute , placeholder_value = - [number] ) : [EOL] [docstring] [EOL] [EOL] def p ( new_data_set ) : [EOL] new_cols = new_data_set [ columns_to_impute ] . fillna ( placeholder_value ) . to_dict ( [string] ) [EOL] return new_data_set . assign ( ** new_cols ) [EOL] [EOL] p . __doc__ = learner_pred_fn_docstring ( [string] ) [EOL] [EOL] log = { [string] : { [string] : columns_to_impute , [string] : df [ columns_to_impute ] . isnull ( ) . mean ( axis = [number] ) . to_dict ( ) , [string] : placeholder_value } } [EOL] [EOL] return p , p ( df ) , log [EOL] [EOL] [EOL] placeholder_imputer . __doc__ += learner_return_docstring ( [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $fklearn.types.LearnerReturnType$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Union , Dict , Any , List , Callable , Type [EOL] import typing [EOL] from datetime import datetime [EOL] from typing import Any , Callable , Dict , List , Tuple , Union [EOL] [EOL] import pandas as pd [EOL] [EOL] [comment] [EOL] DateType = Union [ pd . Period , datetime , str ] [EOL] [EOL] [comment] [EOL] LogType = Dict [ str , Any ] [EOL] LogListType = List [ LogType ] [EOL] ListLogListType = List [ LogListType ] [EOL] [EOL] [comment] [EOL] PredictFnType = Callable [ [ pd . DataFrame ] , pd . DataFrame ] [EOL] LearnerLogType = Dict [ str , LogType ] [EOL] LearnerReturnType = Tuple [ PredictFnType , pd . DataFrame , LearnerLogType ] [EOL] [EOL] UncurriedLearnerFnType = Callable [ ... , LearnerReturnType ] [EOL] LearnerFnType = Callable [ [ pd . DataFrame ] , LearnerReturnType ] [EOL] [EOL] [comment] [EOL] EvalReturnType = Dict [ str , Union [ float , Dict ] ] [EOL] UncurriedEvalFnType = Callable [ ... , EvalReturnType ] [EOL] EvalFnType = Callable [ [ pd . DataFrame ] , EvalReturnType ] [EOL] [EOL] [comment] [EOL] FoldType = List [ Tuple [ pd . Index , List [ pd . Index ] ] ] [EOL] SplitterReturnType = Tuple [ FoldType , LogListType ] [EOL] SplitterFnType = Callable [ [ pd . DataFrame ] , SplitterReturnType ] [EOL] [EOL] [comment] [EOL] ValidatorReturnType = Dict [ str , Union [ LogType , LogListType ] ] [EOL] [EOL] [comment] [EOL] PerturbFnType = Callable [ [ pd . DataFrame ] , pd . DataFrame ] [EOL] ColumnWisePerturbFnType = Callable [ [ pd . Series ] , pd . Series ] [EOL] [EOL] [comment] [EOL] ExtractorFnType = Callable [ [ str ] , float ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from fklearn . types . types import * [EOL]	0 0 0 0 0 0 0 0 0
from typing import Dict , Any , List [EOL] import typing [EOL] import collections [EOL] from datetime import datetime [EOL] from itertools import chain , repeat [EOL] [EOL] import pandas as pd [EOL] from toolz import curry [EOL] from numpy import nan [EOL] [EOL] [EOL] @ curry def evaluator_extractor ( result , evaluator_name ) : [EOL] metric_value = result [ evaluator_name ] if result else nan [EOL] return pd . DataFrame ( { evaluator_name : [ metric_value ] } ) [EOL] [EOL] [EOL] @ curry def combined_evaluator_extractor ( result , base_extractors ) : [EOL] return pd . concat ( [ x ( result ) for x in base_extractors ] , axis = [number] ) [EOL] [EOL] [EOL] @ curry def split_evaluator_extractor_iteration ( split_value , result , split_col , base_extractor ) : [EOL] key = [string] + split_col + [string] + str ( split_value ) [EOL] return ( base_extractor ( result . get ( key , { } ) ) . assign ( ** { [string] + split_col : split_value } ) ) [EOL] [EOL] [EOL] @ curry def split_evaluator_extractor ( result , split_col , split_values , base_extractor ) : [EOL] return pd . concat ( list ( map ( split_evaluator_extractor_iteration ( result = result , split_col = split_col , base_extractor = base_extractor ) , split_values ) ) ) [EOL] [EOL] [EOL] @ curry def temporal_split_evaluator_extractor ( result , time_col , base_extractor , time_format = [string] , eval_name = None ) : [EOL] if eval_name is None : [EOL] eval_name = [string] + time_col [EOL] [EOL] split_keys = [ key for key in result . keys ( ) if eval_name in key ] [EOL] split_values = [ ] [EOL] for key in split_keys : [EOL] date = key . split ( eval_name ) [ [number] ] [ [number] : ] [EOL] try : [EOL] [comment] [EOL] datetime . strptime ( date , time_format ) [EOL] split_values . append ( date ) [EOL] except ValueError : [EOL] [comment] [EOL] pass [EOL] [EOL] return split_evaluator_extractor ( result , time_col , split_values , base_extractor ) [EOL] [EOL] [EOL] @ curry def learning_curve_evaluator_extractor ( result , base_extractor ) : [EOL] return base_extractor ( result ) . assign ( lc_period_end = result [ [string] ] ) [EOL] [EOL] [EOL] @ curry def reverse_learning_curve_evaluator_extractor ( result , base_extractor ) : [EOL] return base_extractor ( result ) . assign ( reverse_lc_period_start = result [ [string] ] ) [EOL] [EOL] [EOL] @ curry def stability_curve_evaluator_extractor ( result , base_extractor ) : [EOL] return base_extractor ( result ) . assign ( sc_period = result [ [string] ] ) [EOL] [EOL] [EOL] @ curry def repeat_split_log ( split_log , results_len ) : [EOL] if isinstance ( split_log , collections . Iterable ) : [EOL] n_repeat = results_len // len ( split_log ) [EOL] [comment] [EOL] return list ( chain . from_iterable ( zip ( * repeat ( split_log , n_repeat ) ) ) ) [EOL] else : [EOL] return split_log [EOL] [EOL] [EOL] @ curry def extract_base_iteration ( result , extractor ) : [EOL] extracted_results = pd . concat ( list ( map ( extractor , result [ [string] ] ) ) ) [EOL] repeat_fn = repeat_split_log ( results_len = len ( extracted_results ) ) [EOL] [EOL] keys = result [ [string] ] . keys ( ) [EOL] assignments = { k : repeat_fn ( result [ [string] ] [ k ] ) for k in keys } [EOL] [EOL] return ( extracted_results . assign ( fold_num = result [ [string] ] ) . assign ( ** assignments ) ) [EOL] [EOL] [EOL] @ curry def extract ( validator_results , extractor ) : [EOL] return pd . concat ( list ( map ( extract_base_iteration ( extractor = extractor ) , validator_results ) ) ) [EOL] [EOL] [EOL] @ curry def extract_lc ( validator_results , extractor ) : [EOL] return extract ( validator_results , learning_curve_evaluator_extractor ( base_extractor = extractor ) ) [EOL] [EOL] [EOL] @ curry def extract_reverse_lc ( validator_results , extractor ) : [EOL] return extract ( validator_results , reverse_learning_curve_evaluator_extractor ( base_extractor = extractor ) ) [EOL] [EOL] [EOL] @ curry def extract_sc ( validator_results , extractor ) : [EOL] return extract ( validator_results , stability_curve_evaluator_extractor ( base_extractor = extractor ) ) [EOL] [EOL] [EOL] @ curry def extract_param_tuning_iteration ( iteration , tuning_log , base_extractor , model_learner_name ) : [EOL] iter_df = base_extractor ( tuning_log [ iteration ] [ [string] ] ) [EOL] return iter_df . assign ( ** tuning_log [ iteration ] [ [string] ] [ model_learner_name ] [ [string] ] ) [EOL] [EOL] [EOL] @ curry def extract_tuning ( tuning_log , base_extractor , model_learner_name ) : [EOL] iter_fn = extract_param_tuning_iteration ( tuning_log = tuning_log , base_extractor = base_extractor , model_learner_name = model_learner_name ) [EOL] return pd . concat ( list ( map ( iter_fn , range ( len ( tuning_log ) ) ) ) ) [EOL] [EOL] [EOL] @ curry def permutation_extractor ( results , base_extractor ) : [EOL] df = pd . concat ( base_extractor ( r ) for r in results [ [string] ] . values ( ) ) [EOL] df . index = results [ [string] ] . keys ( ) [EOL] if [string] in results : [comment] [EOL] baseline = base_extractor ( results [ [string] ] ) [EOL] baseline . index = [ [string] ] [EOL] df = pd . concat ( ( df , baseline ) ) [EOL] for c in baseline . columns : [EOL] df [ c + [string] ] = baseline [ c ] . iloc [ [number] ] - df [ c ] [EOL] return df [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] from typing import Dict , Any , Tuple , List [EOL] import typing [EOL] import os [EOL] import sys [EOL] from datetime import datetime [EOL] [EOL] from fklearn import __version__ [EOL] [EOL] sys . path . insert ( [number] , os . path . abspath ( [string] ) ) [EOL] [EOL] [EOL] [comment] [EOL] [EOL] project = [string] [EOL] current_year = str ( datetime . now ( ) . year ) [EOL] copyright = current_year + [string] [EOL] author = [string] [EOL] [EOL] [comment] [EOL] version = __version__ [EOL] [comment] [EOL] release = __version__ [EOL] [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] extensions = [ [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] [EOL] [comment] [EOL] templates_path = [ [string] ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] source_suffix = [ [string] , [string] ] [EOL] [EOL] [comment] [EOL] master_doc = [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] language = None [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] exclude_patterns = [ [string] ] [EOL] [EOL] [comment] [EOL] pygments_style = [string] [EOL] [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] html_theme = [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] html_static_path = [ ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] htmlhelp_basename = [string] [EOL] [EOL] [EOL] [comment] [EOL] [EOL] latex_elements = { } [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] latex_documents = [ ( master_doc , [string] , [string] , [string] , [string] ) , ] [EOL] [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] man_pages = [ ( master_doc , [string] , [string] , [ author ] , [number] ) ] [EOL] [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] texinfo_documents = [ ( master_doc , [string] , [string] , author , [string] , [string] , [string] ) , ] [EOL] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str,builtins.str,builtins.str,builtins.str]]$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str,builtins.str,typing.List[builtins.str],builtins.int]]$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str,builtins.str,builtins.str,builtins.str,builtins.str,builtins.str]]$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Union , Dict , List [EOL] import typing [EOL] LOGS = [ { [string] : { [string] : { [string] : [ [string] , [string] , [string] , [string] , [string] , [string] ] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : { [string] : [string] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] } , [string] : { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] } , [string] : [number] , [string] : [string] } } , [string] : [ { [string] : [number] , [string] : [ { [string] : [number] } ] , [string] : { [string] : [number] , [string] : [number] } } , { [string] : [number] , [string] : [ { [string] : [number] } ] , [string] : { [string] : [number] , [string] : [number] } } ] , [string] : [ [string] , [string] ] } , { [string] : { [string] : { [string] : [ [string] , [string] , [string] , [string] , [string] , [string] ] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : { [string] : [string] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] } , [string] : { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] } , [string] : [number] , [string] : [string] } } , [string] : [ { [string] : [number] , [string] : [ { [string] : [number] } ] , [string] : { [string] : [number] , [string] : [number] } } , { [string] : [number] , [string] : [ { [string] : [number] } ] , [string] : { [string] : [number] , [string] : [number] } } ] , [string] : [ [string] , [string] ] } ] [EOL] [EOL] [EOL] PARALLEL_LOGS = [ [ { [string] : { [string] : { [string] : [ [string] , [string] , [string] , [string] , [string] , [string] ] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : { [string] : [string] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] } , [string] : { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] } , [string] : [number] , [string] : [string] } } , [string] : [ { [string] : [number] , [string] : [ { [string] : [number] } ] , [string] : { [string] : [number] , [string] : [number] } } , { [string] : [number] , [string] : [ { [string] : [number] } ] , [string] : { [string] : [number] , [string] : [number] } } ] , [string] : [ [string] , [string] , [string] ] } , { [string] : { [string] : { [string] : [ [string] , [string] , [string] , [string] , [string] , [string] ] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : { [string] : [string] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] } , [string] : { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] } , [string] : [number] , [string] : [string] } } , [string] : [ { [string] : [number] , [string] : [ { [string] : [number] } ] , [string] : { [string] : [number] , [string] : [number] } } , { [string] : [number] , [string] : [ { [string] : [number] } ] , [string] : { [string] : [number] , [string] : [number] } } ] , [string] : [ [string] , [string] , [string] ] } ] , [ { [string] : { [string] : { [string] : [ [string] , [string] , [string] , [string] , [string] , [string] ] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : { [string] : [string] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] } , [string] : { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] } , [string] : [number] , [string] : [string] } } , [string] : [ { [string] : [number] , [string] : [ { [string] : [number] } ] , [string] : { [string] : [number] , [string] : [number] } } , { [string] : [number] , [string] : [ { [string] : [number] } ] , [string] : { [string] : [number] , [string] : [number] } } ] , [string] : [ [string] , [string] , [string] ] } , { [string] : { [string] : { [string] : [ [string] , [string] , [string] , [string] , [string] , [string] ] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : { [string] : [string] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] } , [string] : { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] } , [string] : [number] , [string] : [string] } } , [string] : [ { [string] : [number] , [string] : [ { [string] : [number] } ] , [string] : { [string] : [number] , [string] : [number] } } , { [string] : [number] , [string] : [ { [string] : [number] } ] , [string] : { [string] : [number] , [string] : [number] } } ] , [string] : [ [string] , [string] , [string] ] } ] ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import ValuesView , Any [EOL] import typing [EOL] from collections import Counter [EOL] [EOL] import hypothesis . strategies as st [EOL] import pandas as pd [EOL] from hypothesis import given [EOL] from hypothesis . extra . pandas import columns , data_frames , range_indexes [EOL] from pandas . util . testing import assert_frame_equal [EOL] [EOL] from fklearn . preprocessing . splitting import space_time_split_dataset , time_split_dataset , stratified_split_dataset [EOL] [EOL] df = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] , [string] , [string] ] , [string] : [ pd . to_datetime ( [string] ) , pd . to_datetime ( [string] ) , pd . to_datetime ( [string] ) , pd . to_datetime ( [string] ) , pd . to_datetime ( [string] ) , pd . to_datetime ( [string] ) ] } ) [EOL] [EOL] df_with_new_id = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] , [string] , [string] , [string] ] , [string] : [ pd . to_datetime ( [string] ) , pd . to_datetime ( [string] ) , pd . to_datetime ( [string] ) , pd . to_datetime ( [string] ) , pd . to_datetime ( [string] ) , pd . to_datetime ( [string] ) , pd . to_datetime ( [string] ) ] } ) [EOL] [EOL] df_only_one_point_per_id = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ pd . to_datetime ( [string] ) , pd . to_datetime ( [string] ) , pd . to_datetime ( [string] ) , pd . to_datetime ( [string] ) ] } ) [EOL] [EOL] MAX_STRATIFIED_SPLIT_SIZE_DIFFERENCE = [number] [EOL] [EOL] [EOL] def test_time_split_dataset ( test_df = df ) : [EOL] in_time_train_set , out_time_test_set = time_split_dataset ( dataset = test_df , train_start_date = [string] , train_end_date = [string] , holdout_end_date = [string] , time_column = [string] ) [EOL] [EOL] expected_train = pd . DataFrame ( { [string] : [ [string] , [string] ] , [string] : [ pd . to_datetime ( [string] ) , pd . to_datetime ( [string] ) ] } ) [EOL] [EOL] expected_test = pd . DataFrame ( { [string] : [ [string] , [string] ] , [string] : [ pd . to_datetime ( [string] ) , pd . to_datetime ( [string] ) ] } ) [EOL] [EOL] assert in_time_train_set . reset_index ( drop = True ) . equals ( expected_train ) [EOL] assert out_time_test_set . reset_index ( drop = True ) . equals ( expected_test ) [EOL] [EOL] [comment] [EOL] in_time_train_set , out_time_test_set = time_split_dataset ( dataset = test_df , train_start_date = [string] , train_end_date = [string] , holdout_start_date = [string] , holdout_end_date = [string] , time_column = [string] ) [EOL] [EOL] expected_train = pd . DataFrame ( { [string] : [ [string] , [string] ] , [string] : [ pd . to_datetime ( [string] ) , pd . to_datetime ( [string] ) ] } ) [EOL] [EOL] expected_test = pd . DataFrame ( { [string] : [ [string] , [string] ] , [string] : [ pd . to_datetime ( [string] ) , pd . to_datetime ( [string] ) ] } ) [EOL] [EOL] assert in_time_train_set . reset_index ( drop = True ) . equals ( expected_train ) [EOL] assert out_time_test_set . reset_index ( drop = True ) . equals ( expected_test ) [EOL] [EOL] [EOL] def test_space_time_split_dataset ( test_df = df , test_df_with_new_id = df_with_new_id , test_df_only_one_point_per_id = df_only_one_point_per_id ) : [EOL] [EOL] train_set , intime_outspace_hdout , outtime_inspace_hdout , outtime_outspace_hdout = space_time_split_dataset ( dataset = test_df , train_start_date = [string] , train_end_date = [string] , holdout_end_date = [string] , split_seed = [number] , space_holdout_percentage = [number] , space_column = [string] , time_column = [string] ) [EOL] [EOL] expected_train = pd . DataFrame ( { [string] : [ [string] ] , [string] : [ pd . to_datetime ( [string] ) ] } ) [EOL] [EOL] expected_intime_outspace_holdout = pd . DataFrame ( { [string] : [ [string] ] , [string] : [ pd . to_datetime ( [string] ) ] } ) [EOL] [EOL] expected_outtime_outspace_holdout = pd . DataFrame ( { [string] : [ [string] ] , [string] : [ pd . to_datetime ( [string] ) ] } ) [EOL] [EOL] expected_outtime_inspace_holdout = pd . DataFrame ( { [string] : [ [string] ] , [string] : [ pd . to_datetime ( [string] ) ] } ) [EOL] [EOL] assert train_set . reset_index ( drop = True ) . equals ( expected_train ) [EOL] assert intime_outspace_hdout . reset_index ( drop = True ) . equals ( expected_intime_outspace_holdout ) [EOL] assert outtime_inspace_hdout . reset_index ( drop = True ) . equals ( expected_outtime_inspace_holdout ) [EOL] assert outtime_outspace_hdout . reset_index ( drop = True ) . equals ( expected_outtime_outspace_holdout ) [EOL] [EOL] [comment] [EOL] train_set , intime_outspace_hdout , outtime_inspace_hdout , outtime_outspace_hdout = space_time_split_dataset ( dataset = test_df , train_start_date = [string] , train_end_date = [string] , holdout_start_date = [string] , holdout_end_date = [string] , split_seed = [number] , space_holdout_percentage = [number] , space_column = [string] , time_column = [string] ) [EOL] [EOL] expected_train = pd . DataFrame ( { [string] : [ [string] ] , [string] : [ pd . to_datetime ( [string] ) ] } ) [EOL] [EOL] expected_intime_outspace_holdout = pd . DataFrame ( { [string] : [ [string] ] , [string] : [ pd . to_datetime ( [string] ) ] } ) [EOL] [EOL] expected_outtime_outspace_holdout = pd . DataFrame ( { [string] : [ [string] ] , [string] : [ pd . to_datetime ( [string] ) ] } ) [EOL] [EOL] expected_outtime_inspace_holdout = pd . DataFrame ( { [string] : [ [string] ] , [string] : [ pd . to_datetime ( [string] ) ] } ) [EOL] [EOL] assert train_set . reset_index ( drop = True ) . equals ( expected_train ) [EOL] assert intime_outspace_hdout . reset_index ( drop = True ) . equals ( expected_intime_outspace_holdout ) [EOL] assert outtime_inspace_hdout . reset_index ( drop = True ) . equals ( expected_outtime_inspace_holdout ) [EOL] assert outtime_outspace_hdout . reset_index ( drop = True ) . equals ( expected_outtime_outspace_holdout ) [EOL] [EOL] [comment] [EOL] train_set , intime_outspace_hdout , outtime_inspace_hdout , outtime_outspace_hdout = space_time_split_dataset ( dataset = test_df_with_new_id , train_start_date = [string] , train_end_date = [string] , holdout_end_date = [string] , split_seed = [number] , space_holdout_percentage = [number] , space_column = [string] , time_column = [string] ) [EOL] [EOL] expected_train = pd . DataFrame ( { [string] : [ [string] ] , [string] : [ pd . to_datetime ( [string] ) ] } ) [EOL] [EOL] expected_intime_outspace_holdout = pd . DataFrame ( { [string] : [ [string] ] , [string] : [ pd . to_datetime ( [string] ) ] } ) [EOL] [EOL] expected_outtime_outspace_holdout = pd . DataFrame ( { [string] : [ [string] , [string] ] , [string] : [ pd . to_datetime ( [string] ) , pd . to_datetime ( [string] ) ] } ) [EOL] [EOL] expected_outtime_inspace_holdout = pd . DataFrame ( { [string] : [ [string] ] , [string] : [ pd . to_datetime ( [string] ) ] } ) [EOL] [EOL] assert train_set . reset_index ( drop = True ) . equals ( expected_train ) [EOL] assert intime_outspace_hdout . reset_index ( drop = True ) . equals ( expected_intime_outspace_holdout ) [EOL] assert outtime_inspace_hdout . reset_index ( drop = True ) . equals ( expected_outtime_inspace_holdout ) [EOL] assert outtime_outspace_hdout . reset_index ( drop = True ) . equals ( expected_outtime_outspace_holdout ) [EOL] [EOL] [comment] [EOL] train_set , intime_outspace_hdout , outtime_inspace_hdout , outtime_outspace_hdout = space_time_split_dataset ( dataset = test_df_only_one_point_per_id , train_start_date = [string] , train_end_date = [string] , holdout_end_date = [string] , split_seed = [number] , space_holdout_percentage = [number] , space_column = [string] , time_column = [string] ) [EOL] [EOL] expected_train = pd . DataFrame ( { [string] : [ [string] ] , [string] : [ pd . to_datetime ( [string] ) ] } ) [EOL] [EOL] expected_intime_outspace_holdout = pd . DataFrame ( { [string] : [ [string] ] , [string] : [ pd . to_datetime ( [string] ) ] } ) [EOL] [EOL] expected_outtime_outspace_holdout = pd . DataFrame ( { [string] : [ [string] , [string] ] , [string] : [ pd . to_datetime ( [string] ) , pd . to_datetime ( [string] ) ] } ) [EOL] [EOL] assert train_set . reset_index ( drop = True ) . equals ( expected_train ) [EOL] assert intime_outspace_hdout . reset_index ( drop = True ) . equals ( expected_intime_outspace_holdout ) [EOL] assert outtime_inspace_hdout . empty [EOL] assert outtime_outspace_hdout . reset_index ( drop = True ) . equals ( expected_outtime_outspace_holdout ) [EOL] [EOL] [EOL] @ st . composite def gen_stratified_test_data ( draw ) : [EOL] column_name_strategy = st . text ( st . characters ( whitelist_categories = [ [string] , [string] ] ) , min_size = [number] ) [EOL] all_column_names = draw ( st . lists ( column_name_strategy , min_size = [number] , max_size = [number] , unique = True ) ) [EOL] target_column_name = all_column_names [ - [number] ] [EOL] [EOL] column_strategies = columns ( all_column_names , dtype = int ) [EOL] data_set = draw ( data_frames ( column_strategies , index = range_indexes ( min_size = [number] , max_size = [number] ) ) ) [EOL] [EOL] num_classes = draw ( st . integers ( min_value = [number] , max_value = [number] ) ) [EOL] data_set [ target_column_name ] = [ i % num_classes for i in range ( len ( data_set ) ) ] [EOL] [EOL] return data_set , target_column_name , num_classes [EOL] [EOL] [EOL] def assert_sample_size_per_class ( data , target_column_name , expected_samples_per_class ) : [EOL] count_per_class = Counter ( data [ target_column_name ] ) . values ( ) [EOL] [EOL] for count in count_per_class : [EOL] assert abs ( count - expected_samples_per_class ) <= MAX_STRATIFIED_SPLIT_SIZE_DIFFERENCE [EOL] [EOL] [EOL] @ given ( sample = gen_stratified_test_data ( ) , random_state = st . integers ( min_value = [number] , max_value = [number] ) , test_size = st . floats ( min_value = [number] , max_value = [number] ) ) def test_stratified_split_dataset ( sample , random_state , test_size ) : [EOL] expected_data , target_column_name , num_classes = sample [EOL] [EOL] train_data , test_data = stratified_split_dataset ( expected_data , target_column_name , test_size = test_size , random_state = random_state ) [EOL] [EOL] total_samples = len ( expected_data ) [EOL] expected_test_size = int ( total_samples * test_size ) [EOL] expected_train_size = total_samples - expected_test_size [EOL] [EOL] expected_test_samples_per_class = expected_test_size / num_classes [EOL] expected_train_samples_per_class = expected_train_size / num_classes [EOL] [EOL] data = pd . concat ( [ train_data , test_data ] ) [EOL] [EOL] assert abs ( len ( train_data ) - expected_train_size ) <= MAX_STRATIFIED_SPLIT_SIZE_DIFFERENCE [EOL] assert abs ( len ( test_data ) - expected_test_size ) <= MAX_STRATIFIED_SPLIT_SIZE_DIFFERENCE [EOL] [EOL] assert_frame_equal ( data , expected_data , check_like = True ) [EOL] assert_sample_size_per_class ( train_data , target_column_name , expected_train_samples_per_class ) [EOL] assert_sample_size_per_class ( test_data , target_column_name , expected_test_samples_per_class ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] from fklearn . preprocessing . rebalancing import rebalance_by_categorical , rebalance_by_continuous [EOL] import pandas as pd [EOL] [EOL] data1 = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] ] } ) [EOL] data2 = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] [EOL] def test_rebalance_by_categorical ( ) : [EOL] result1 = rebalance_by_categorical ( data1 , [string] ) . sort_values ( by = [string] ) [EOL] [EOL] expected1 = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] , [string] , [string] ] , } ) [EOL] [EOL] assert result1 . reset_index ( drop = True ) . equals ( expected1 ) , [string] [EOL] [EOL] result2 = rebalance_by_categorical ( data2 , [string] , max_lines_by_categ = [number] ) . sort_values ( by = [string] ) [EOL] [EOL] expected2 = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , } ) [EOL] [EOL] assert result2 . reset_index ( drop = True ) . equals ( expected2 ) , [string] [EOL] [EOL] [EOL] def test_rebalance_by_continuous ( ) : [EOL] [EOL] result1 = ( rebalance_by_continuous ( data2 , [string] , buckets = [number] , by_quantile = False ) . sort_values ( [string] ) . reset_index ( drop = True ) ) [EOL] [EOL] expected1 = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , } ) . sort_values ( [string] ) . reset_index ( drop = True ) [EOL] [EOL] assert result1 . reset_index ( drop = True ) . equals ( expected1 ) , [string] [EOL] [EOL] result1 = ( rebalance_by_continuous ( data2 , [string] , buckets = [number] , by_quantile = True ) . sort_values ( [string] ) . reset_index ( drop = True ) ) [EOL] [EOL] expected1 = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , } ) . sort_values ( [string] ) . reset_index ( drop = True ) [EOL] [EOL] assert result1 . equals ( expected1 ) , [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] from typing import Any , List [EOL] import typing [EOL] from collections import Counter [EOL] [EOL] import pandas as pd [EOL] [EOL] from fklearn . training . utils import expand_features_encoded [EOL] [EOL] [EOL] def test_expand_features_encoded ( ) : [EOL] df_A = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] df_B = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] df_C = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] features_all = [ [string] , [string] , [string] , [string] , [string] ] [EOL] features_partial = [ [string] , [string] , [string] ] [EOL] features_partialler = [ [string] , [string] ] [EOL] [EOL] transformed_1 = expand_features_encoded ( df_A , features_all ) [EOL] expected_1 = [ [string] , [string] , [string] , [string] , [string] ] [EOL] [EOL] transformed_2 = expand_features_encoded ( df_A , features_partial ) [EOL] expected_2 = [ [string] , [string] , [string] ] [EOL] [EOL] transformed_3 = expand_features_encoded ( df_B , features_partial ) [EOL] expected_3 = [ [string] , [string] , [string] , [string] , [string] ] [EOL] [EOL] transformed_4 = expand_features_encoded ( df_C , features_partial ) [EOL] expected_4 = [ [string] , [string] , [string] , [string] , [string] ] [EOL] [EOL] transformed_5 = expand_features_encoded ( df_C , features_partialler ) [EOL] expected_5 = [ [string] , [string] , [string] , [string] ] [EOL] [EOL] assert Counter ( transformed_1 ) == Counter ( expected_1 ) [EOL] assert Counter ( transformed_2 ) == Counter ( expected_2 ) [EOL] assert Counter ( transformed_3 ) == Counter ( expected_3 ) [EOL] assert Counter ( transformed_4 ) == Counter ( expected_4 ) [EOL] assert Counter ( transformed_5 ) == Counter ( expected_5 ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] import pandas as pd [EOL] [EOL] from fklearn . training . imputation import imputer , placeholder_imputer [EOL] [EOL] [EOL] def test_imputer ( ) : [EOL] input_df = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , None ] } ) [EOL] [EOL] input_df2 = pd . DataFrame ( { [string] : [ [number] , None ] , [string] : [ None , [number] ] } ) [EOL] [EOL] expected1 = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] } ) [EOL] [EOL] expected2 = pd . DataFrame ( { [string] : [ [number] , [number] ] , [string] : [ [number] , [number] ] } ) [EOL] [EOL] pred_fn , data , log = imputer ( input_df , [ [string] , [string] ] , [string] ) [EOL] [EOL] assert expected1 . equals ( data ) [EOL] assert expected2 . equals ( pred_fn ( input_df2 ) ) [EOL] [EOL] [EOL] def test_imputer_with_fill_value ( ) : [EOL] input_df = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , None ] , [string] : [ None , None , None ] } ) [EOL] [EOL] df = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , None , None ] } ) [EOL] [EOL] expected = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , - [number] , - [number] ] } ) [EOL] [EOL] pred_fn , data , log = imputer ( input_df , [ [string] , [string] , [string] ] , [string] , placeholder_value = - [number] ) [EOL] [EOL] assert expected . equals ( pred_fn ( df ) ) [EOL] [EOL] [EOL] def test_placeholder_imputer ( ) : [EOL] input_df = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , None ] } ) [EOL] [EOL] input_df2 = pd . DataFrame ( { [string] : [ [number] , None ] , [string] : [ None , [number] ] } ) [EOL] [EOL] expected1 = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , - [number] ] } ) [EOL] [EOL] expected2 = pd . DataFrame ( { [string] : [ [number] , - [number] ] , [string] : [ - [number] , [number] ] } ) [EOL] [EOL] pred_fn , data , log = placeholder_imputer ( input_df , [ [string] , [string] ] , - [number] ) [EOL] [EOL] assert expected1 . equals ( data ) [EOL] assert expected2 . equals ( pred_fn ( input_df2 ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] import pandas as pd [EOL] [EOL] from fklearn . training . calibration import isotonic_calibration_learner [EOL] [EOL] [EOL] def test_isotonic_calibration_learner ( ) : [EOL] df_train = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] df_test = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] learner = isotonic_calibration_learner ( prediction_column = [string] , target_column = [string] ) [EOL] [EOL] predict_fn , pred_train , log = learner ( df_train ) [EOL] [EOL] pred_test = predict_fn ( df_test ) [EOL] [EOL] assert [string] in pred_train . columns . values [EOL] assert [string] in pred_test . columns . values [EOL] assert pred_test . calibrated_prediction . max ( ) <= [number] [EOL] assert pred_test . calibrated_prediction . min ( ) >= [number] [EOL] assert pred_test . calibrated_prediction . isnull ( ) . max ( ) == [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] from typing import Dict , Any , List [EOL] import typing [EOL] from fklearn . training . ensemble import xgb_octopus_classification_learner [EOL] from collections import Counter [EOL] import pandas as pd [EOL] [EOL] [EOL] def test_xgb_octopus_classification_learner ( ) : [EOL] df = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] df_test = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] train_split_bins = [ [number] , [number] ] [EOL] train_split_col = [string] [EOL] target = [string] [EOL] [EOL] learning_rate_by_bin = { [number] : [number] , [number] : [number] } [EOL] num_estimators_by_bin = { [number] : [number] , [number] : [number] } [EOL] extra_params_by_bin = { split_bin : { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] } for split_bin in train_split_bins } [EOL] [EOL] features_by_bin = { [number] : [ [string] ] , [number] : [ [string] , [string] ] } [EOL] [EOL] train_fn = xgb_octopus_classification_learner ( learning_rate_by_bin = learning_rate_by_bin , num_estimators_by_bin = num_estimators_by_bin , extra_params_by_bin = extra_params_by_bin , features_by_bin = features_by_bin , train_split_col = train_split_col , train_split_bins = train_split_bins , nthread = [number] , target_column = target , prediction_column = [string] ) [EOL] [EOL] pred_fn , pred_train , logs = train_fn ( df ) [EOL] [EOL] pred_test = pred_fn ( df_test ) [EOL] [EOL] expected_col_train = df . columns . tolist ( ) + [ [string] , [string] , [string] ] [EOL] expected_col_test = df_test . columns . tolist ( ) + [ [string] , [string] , [string] ] [EOL] [EOL] assert Counter ( expected_col_train ) == Counter ( pred_train . columns . tolist ( ) ) [EOL] assert Counter ( expected_col_test ) == Counter ( pred_test . columns . tolist ( ) ) [EOL] assert pred_test [ [string] ] . max ( ) < [number] [EOL] assert pred_test [ [string] ] . min ( ) > [number] [EOL] assert ( pred_test . columns == pred_train . columns ) . all ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] from typing import Any [EOL] import typing [EOL] from collections import Counter [EOL] [EOL] import pandas as pd [EOL] [EOL] from fklearn . training . unsupervised import isolation_forest_learner [EOL] [EOL] [EOL] def test_anomaly_learner ( ) : [EOL] df_train_binary = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] df_test_binary = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , - [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] [comment] [EOL] predict_fn , pred_train , log = isolation_forest_learner ( df_train_binary , features = [ [string] , [string] ] ) [EOL] [EOL] pred_test = predict_fn ( df_test_binary ) [EOL] [EOL] expected_col_train = df_train_binary . columns . tolist ( ) + [ [string] ] [EOL] expected_col_test = df_test_binary . columns . tolist ( ) + [ [string] ] [EOL] [EOL] assert Counter ( expected_col_train ) == Counter ( pred_train . columns . tolist ( ) ) [EOL] assert Counter ( expected_col_test ) == Counter ( pred_test . columns . tolist ( ) ) [EOL] assert ( pred_test . columns == pred_train . columns ) . all ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List [EOL] import typing [EOL] from collections import Counter [EOL] [EOL] import numpy as np [EOL] import pandas as pd [EOL] [EOL] from fklearn . training . regression import linear_regression_learner , gp_regression_learner , xgb_regression_learner , lgbm_regression_learner , catboost_regressor_learner , custom_supervised_model_learner [EOL] [EOL] [EOL] def test_linear_regression_learner ( ) : [EOL] df_train = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , - [number] ] } ) [EOL] [EOL] df_test = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , - [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , - [number] , [number] , [number] ] } ) [EOL] [EOL] learner = linear_regression_learner ( features = [ [string] , [string] ] , target = [string] , params = None , prediction_column = [string] , weight_column = [string] ) [EOL] [EOL] predict_fn , pred_train , log = learner ( df_train ) [EOL] [EOL] pred_test = predict_fn ( df_test ) [EOL] [EOL] expected_col_train = df_train . columns . tolist ( ) + [ [string] ] [EOL] expected_col_test = df_test . columns . tolist ( ) + [ [string] ] [EOL] [EOL] assert Counter ( expected_col_train ) == Counter ( pred_train . columns . tolist ( ) ) [EOL] assert Counter ( expected_col_test ) == Counter ( pred_test . columns . tolist ( ) ) [EOL] assert ( pred_test . columns == pred_train . columns ) . all ( ) [EOL] assert [string] in pred_test . columns [EOL] [EOL] [EOL] def test_gp_regression_learner ( ) : [EOL] df_train = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , - [number] ] } ) [EOL] [EOL] df_test = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , - [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , - [number] , [number] , [number] ] } ) [EOL] [EOL] from sklearn . gaussian_process . kernels import RBF , WhiteKernel , DotProduct [EOL] [EOL] kernel = RBF ( ) + WhiteKernel ( ) + DotProduct ( ) [EOL] [EOL] learner = gp_regression_learner ( features = [ [string] , [string] ] , target = [string] , kernel = kernel , alpha = [number] , extra_variance = [string] , return_std = True , extra_params = None , prediction_column = [string] ) [EOL] [EOL] predict_fn , pred_train , log = learner ( df_train ) [EOL] [EOL] pred_test = predict_fn ( df_test ) [EOL] [EOL] expected_col_train = df_train . columns . tolist ( ) + [ [string] , [string] ] [EOL] expected_col_test = df_test . columns . tolist ( ) + [ [string] , [string] ] [EOL] [EOL] assert Counter ( expected_col_train ) == Counter ( pred_train . columns . tolist ( ) ) [EOL] assert Counter ( expected_col_test ) == Counter ( pred_test . columns . tolist ( ) ) [EOL] assert ( pred_test . columns == pred_train . columns ) . all ( ) [EOL] assert [string] in pred_test . columns [EOL] [EOL] [EOL] def test_xgb_regression_learner ( ) : [EOL] df_train = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , - [number] ] } ) [EOL] [EOL] df_test = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , - [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , - [number] , [number] , [number] ] } ) [EOL] [EOL] features = [ [string] , [string] ] [EOL] [EOL] learner = xgb_regression_learner ( features = features , target = [string] , learning_rate = [number] , num_estimators = [number] , extra_params = { [string] : [number] , [string] : [number] } , prediction_column = [string] , weight_column = [string] ) [EOL] [EOL] predict_fn , pred_train , log = learner ( df_train ) [EOL] [EOL] pred_test = predict_fn ( df_test ) [EOL] [EOL] expected_col_train = df_train . columns . tolist ( ) + [ [string] ] [EOL] expected_col_test = df_test . columns . tolist ( ) + [ [string] ] [EOL] [EOL] assert Counter ( expected_col_train ) == Counter ( pred_train . columns . tolist ( ) ) [EOL] assert Counter ( expected_col_test ) == Counter ( pred_test . columns . tolist ( ) ) [EOL] assert ( pred_test . columns == pred_train . columns ) . all ( ) [EOL] assert [string] in pred_test . columns [EOL] [EOL] [comment] [EOL] pred_shap = predict_fn ( df_test , apply_shap = True ) [EOL] assert [string] in pred_shap . columns [EOL] assert [string] in pred_shap . columns [EOL] assert np . vstack ( pred_shap [ [string] ] ) . shape == ( [number] , [number] ) [EOL] [EOL] [EOL] def test_lgbm_regression_learner ( ) : [EOL] df_train = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , - [number] ] } ) [EOL] [EOL] df_test = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , - [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , - [number] , [number] , [number] ] } ) [EOL] [EOL] features = [ [string] , [string] ] [EOL] [EOL] learner = lgbm_regression_learner ( features = features , target = [string] , learning_rate = [number] , num_estimators = [number] , extra_params = { [string] : [number] , [string] : [number] } , prediction_column = [string] , weight_column = [string] ) [EOL] [EOL] predict_fn , pred_train , log = learner ( df_train ) [EOL] [EOL] pred_test = predict_fn ( df_test ) [EOL] [EOL] expected_col_train = df_train . columns . tolist ( ) + [ [string] ] [EOL] expected_col_test = df_test . columns . tolist ( ) + [ [string] ] [EOL] [EOL] assert Counter ( expected_col_train ) == Counter ( pred_train . columns . tolist ( ) ) [EOL] assert Counter ( expected_col_test ) == Counter ( pred_test . columns . tolist ( ) ) [EOL] assert ( pred_test . columns == pred_train . columns ) . all ( ) [EOL] assert [string] in pred_test . columns [EOL] [EOL] [comment] [EOL] pred_shap = predict_fn ( df_test , apply_shap = True ) [EOL] assert [string] in pred_shap . columns [EOL] assert [string] in pred_shap . columns [EOL] assert np . vstack ( pred_shap [ [string] ] ) . shape == ( [number] , [number] ) [EOL] [EOL] [EOL] def test_catboost_regressor_learner ( ) : [EOL] df_train = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , - [number] ] } ) [EOL] [EOL] df_test = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , - [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , - [number] , [number] , [number] ] } ) [EOL] [EOL] features = [ [string] , [string] ] [EOL] [EOL] learner = catboost_regressor_learner ( features = features , target = [string] , learning_rate = [number] , num_estimators = [number] , extra_params = { [string] : [number] , [string] : [number] } , prediction_column = [string] , weight_column = [string] ) [EOL] [EOL] predict_fn , pred_train , log = learner ( df_train ) [EOL] [EOL] pred_test = predict_fn ( df_test ) [EOL] [EOL] expected_col_train = df_train . columns . tolist ( ) + [ [string] ] [EOL] expected_col_test = df_test . columns . tolist ( ) + [ [string] ] [EOL] [EOL] assert Counter ( expected_col_train ) == Counter ( pred_train . columns . tolist ( ) ) [EOL] assert Counter ( expected_col_test ) == Counter ( pred_test . columns . tolist ( ) ) [EOL] assert ( pred_test . columns == pred_train . columns ) . all ( ) [EOL] assert [string] in pred_test . columns [EOL] [EOL] [comment] [EOL] pred_shap = predict_fn ( df_test , apply_shap = True ) [EOL] assert [string] in pred_shap . columns [EOL] assert [string] in pred_shap . columns [EOL] assert np . vstack ( pred_shap [ [string] ] ) . shape == ( [number] , [number] ) [EOL] [EOL] [EOL] def test_custom_supervised_model_learner ( ) : [EOL] from sklearn import tree [EOL] from sklearn . gaussian_process import GaussianProcessRegressor [EOL] [EOL] df_train_classification = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] df_test_classification = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , - [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] df_train_regression = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , - [number] ] } ) [EOL] df_test_regression = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , - [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , - [number] , [number] , [number] ] } ) [EOL] [EOL] features = [ [string] , [string] ] [EOL] custom_classifier_learner = custom_supervised_model_learner ( features = features , target = [string] , model = tree . DecisionTreeClassifier ( ) , supervised_type = [string] , log = { [string] : None } ) [EOL] predict_fn_classification , pred_train_classification , log = custom_classifier_learner ( df_train_classification ) [EOL] pred_test_classification = predict_fn_classification ( df_test_classification ) [EOL] [EOL] expected_col_train = df_train_classification . columns . tolist ( ) + [ [string] , [string] ] [EOL] expected_col_test = df_test_classification . columns . tolist ( ) + [ [string] , [string] ] [EOL] assert ( Counter ( expected_col_train ) == Counter ( pred_train_classification . columns . tolist ( ) ) ) [EOL] assert ( Counter ( expected_col_test ) == Counter ( pred_test_classification . columns . tolist ( ) ) ) [EOL] assert ( pred_test_classification . prediction_0 . max ( ) <= [number] ) [EOL] assert ( pred_test_classification . prediction_0 . min ( ) >= [number] ) [EOL] assert ( pred_test_classification . prediction_1 . max ( ) <= [number] ) [EOL] assert ( pred_test_classification . prediction_1 . min ( ) >= [number] ) [EOL] [EOL] custom_regression_learner = custom_supervised_model_learner ( features = features , target = [string] , model = GaussianProcessRegressor ( ) , supervised_type = [string] , log = { [string] : None } ) [EOL] predict_fn , pred_train , log = custom_regression_learner ( df_train_regression ) [EOL] pred_test = predict_fn ( df_test_regression ) [EOL] [EOL] expected_col_train = df_train_regression . columns . tolist ( ) + [ [string] ] [EOL] expected_col_test = df_test_regression . columns . tolist ( ) + [ [string] ] [EOL] assert ( Counter ( expected_col_train ) == Counter ( pred_train . columns . tolist ( ) ) ) [EOL] assert ( Counter ( expected_col_test ) == Counter ( pred_test . columns . tolist ( ) ) ) [EOL] assert ( ( pred_test . columns == pred_train . columns ) . all ( ) ) [EOL] assert ( [string] in pred_test . columns ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Union , Dict , Any , List [EOL] import typing [EOL] from collections import OrderedDict [EOL] [EOL] import math [EOL] import pandas as pd [EOL] from numpy import nan , round , sqrt , floor , log as ln [EOL] from numpy . testing import assert_almost_equal [EOL] [EOL] from fklearn . training . transformation import selector , capper , floorer , prediction_ranger , count_categorizer , label_categorizer , quantile_biner , truncate_categorical , rank_categorical , onehot_categorizer , target_categorizer , standard_scaler , ecdfer , discrete_ecdfer , custom_transformer , value_mapper , null_injector , missing_warner [EOL] [EOL] [EOL] def test_selector ( ) : [EOL] input_df = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] } ) [EOL] [EOL] expected = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] } ) [EOL] [EOL] expected2 = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , } ) [EOL] [EOL] pred_fn , data , log = selector ( input_df , [ [string] , [string] ] , [ [string] ] ) [EOL] [EOL] [comment] [EOL] assert expected . equals ( data ) [EOL] [EOL] [comment] [EOL] assert expected2 . equals ( pred_fn ( input_df ) ) [EOL] [EOL] [EOL] def test_capper ( ) : [EOL] input_df = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , None ] , } ) [EOL] [EOL] input_df2 = pd . DataFrame ( { [string] : [ [number] , [number] ] , [string] : [ [number] , None ] , } ) [EOL] [EOL] expected1 = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , None ] , } ) [EOL] [EOL] expected2 = pd . DataFrame ( { [string] : [ [number] , [number] ] , [string] : [ [number] , None ] , } ) [EOL] [EOL] pred_fn , data , log = capper ( input_df , [ [string] , [string] ] , { [string] : [number] } ) [EOL] [EOL] assert expected1 . equals ( data ) [EOL] [EOL] assert expected2 . equals ( pred_fn ( input_df2 ) ) [EOL] [EOL] [EOL] def test_floorer ( ) : [EOL] input_df = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , None ] , } ) [EOL] [EOL] input_df2 = pd . DataFrame ( { [string] : [ [number] , [number] ] , [string] : [ [number] , None ] , } ) [EOL] [EOL] expected1 = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , None ] , } ) [EOL] [EOL] expected2 = pd . DataFrame ( { [string] : [ [number] , [number] ] , [string] : [ [number] , None ] , } ) [EOL] [EOL] pred_fn , data , log = floorer ( input_df , [ [string] , [string] ] , { [string] : [number] } ) [EOL] [EOL] assert expected1 . equals ( data ) [EOL] [EOL] assert expected2 . equals ( pred_fn ( input_df2 ) ) [EOL] [EOL] [EOL] def test_prediction_ranger ( ) : [EOL] input_df = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , None ] , } ) [EOL] [EOL] pred_fn , data , log = prediction_ranger ( input_df , [number] , [number] ) [EOL] [EOL] expected = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , None ] , } ) [EOL] [EOL] assert expected . equals ( data ) [EOL] [EOL] [EOL] def test_value_mapper ( ) : [EOL] input_df = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , None ] , [string] : [ [string] , [string] , [string] , [string] ] } ) [EOL] [EOL] value_maps = { [string] : { [number] : [number] , [number] : [number] } , [string] : { [number] : [ [number] , [number] , [number] ] } , [string] : { [string] : [string] , [string] : nan } } [EOL] [EOL] pred_fn , data_ignore , log = value_mapper ( input_df , value_maps ) [EOL] pred_fn , data_not_ignore , log = value_mapper ( input_df , value_maps , ignore_unseen = False ) [EOL] [EOL] expected_ignore = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [ [number] , [number] , [number] ] , [number] , [number] , None ] , [string] : [ [string] , nan , [string] , nan ] } ) [EOL] [EOL] expected_not_ignore = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , nan ] , [string] : [ [ [number] , [number] , [number] ] , nan , nan , nan ] , [string] : [ [string] , nan , nan , nan ] } ) [EOL] [EOL] assert expected_ignore . equals ( data_ignore ) [EOL] assert expected_not_ignore . equals ( data_not_ignore ) [EOL] [EOL] [EOL] def test_count_categorizer ( ) : [EOL] input_df_train = pd . DataFrame ( { [string] : [ [number] , [number] , nan , [number] ] , [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [string] , [string] , [string] , nan ] } ) [EOL] [EOL] expected_output_train = pd . DataFrame ( { [string] : [ [number] , [number] , nan , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , nan ] } ) [EOL] [EOL] input_df_test = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ nan , nan , [string] , [string] ] } ) [EOL] [EOL] expected_output_test = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ nan , nan , [number] , [number] ] } ) [EOL] [EOL] categorizer_learner = count_categorizer ( columns_to_categorize = [ [string] , [string] ] , replace_unseen = [number] ) [EOL] [EOL] pred_fn , data , log = categorizer_learner ( input_df_train ) [EOL] [EOL] test_result = pred_fn ( input_df_test ) [EOL] [EOL] assert data . equals ( expected_output_train ) [EOL] assert test_result . equals ( expected_output_test ) [EOL] [EOL] [EOL] def test_label_categorizer ( ) : [EOL] input_df_train = pd . DataFrame ( { [string] : [ [number] , [number] , nan , [number] ] , [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [string] , [string] , [string] , nan ] } ) [EOL] [EOL] expected_output_train = pd . DataFrame ( { [string] : [ [number] , [number] , nan , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , nan ] } ) [EOL] [EOL] input_df_test = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ nan , nan , [string] , [string] ] } ) [EOL] [EOL] expected_output_test = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , - [number] ] , [string] : [ nan , nan , [number] , [number] ] } ) [EOL] [EOL] categorizer_learner = label_categorizer ( columns_to_categorize = [ [string] , [string] ] , replace_unseen = - [number] ) [EOL] [EOL] pred_fn , data , log = categorizer_learner ( input_df_train ) [EOL] test_result = pred_fn ( input_df_test ) [EOL] [EOL] assert data . equals ( expected_output_train ) [EOL] assert test_result . equals ( expected_output_test ) [EOL] [EOL] [EOL] def test_quantile_biner ( ) : [EOL] input_df_train = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , nan ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] input_df_test = pd . DataFrame ( { [string] : [ - [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , - [number] , nan ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] expected_output_train = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , nan ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] expected_output_test = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , nan ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] biner_learner = quantile_biner ( columns_to_bin = [ [string] ] , q = [number] , right = True ) [EOL] [EOL] pred_fn , data , log = biner_learner ( input_df_train ) [EOL] test_result = pred_fn ( input_df_test ) [EOL] [EOL] assert data . equals ( expected_output_train ) [EOL] assert test_result . equals ( expected_output_test ) [EOL] [EOL] [EOL] def test_truncate_categorical ( ) : [EOL] input_df_train = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , nan ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] input_df_test = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , nan ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] expected_output_train = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , - [number] , - [number] , - [number] , nan ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] expected_output_test = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , - [number] , - [number] , - [number] , - [number] , nan ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] truncate_learner = truncate_categorical ( columns_to_truncate = [ [string] ] , percentile = [number] ) [EOL] [EOL] pred_fn , data , log = truncate_learner ( input_df_train ) [EOL] test_result = pred_fn ( input_df_test ) [EOL] [EOL] assert data . equals ( expected_output_train ) [EOL] assert test_result . equals ( expected_output_test ) [EOL] [EOL] [EOL] def test_rank_categorical ( ) : [EOL] input_df_train = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , nan , nan , nan ] } ) [EOL] [EOL] input_df_test = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] , [string] , nan , nan ] } ) [EOL] [EOL] expected_output_train = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , nan , nan , nan ] } ) [EOL] [EOL] expected_output_test = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] , [number] , nan , nan ] } ) [EOL] [EOL] pred_fn , data , log = rank_categorical ( input_df_train , [ [string] ] ) [EOL] test_result = pred_fn ( input_df_test ) [EOL] [EOL] assert expected_output_train . equals ( data ) , [string] [EOL] assert expected_output_test . equals ( test_result ) , [string] [EOL] [EOL] [EOL] def test_onehot_categorizer ( ) : [EOL] input_df_train = pd . DataFrame ( { [string] : [ [number] , [number] , nan , [number] ] , [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [string] , [string] , [string] , nan ] } ) [EOL] [EOL] expected_output_train_no_hardcode = pd . DataFrame ( OrderedDict ( ( ( [string] , [ [number] , [number] , nan , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) ) ) ) [EOL] [EOL] expected_output_train_hardcode = pd . DataFrame ( OrderedDict ( ( ( [string] , [ [number] , [number] , nan , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) ) ) ) [EOL] [EOL] expected_output_train_drop_first = pd . DataFrame ( OrderedDict ( ( ( [string] , [ [number] , [number] , nan , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) ) ) ) [EOL] [EOL] input_df_test = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ nan , nan , [string] , [string] ] } ) [EOL] [EOL] expected_output_test_no_hardcode = pd . DataFrame ( OrderedDict ( ( ( [string] , [ [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) ) ) ) [EOL] [EOL] expected_output_test_hardcode = pd . DataFrame ( OrderedDict ( ( ( [string] , [ [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) ) ) ) [EOL] [EOL] expected_output_test_drop_first = pd . DataFrame ( OrderedDict ( ( ( [string] , [ [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] ] ) ) ) ) [EOL] [EOL] [comment] [EOL] categorizer_learner = onehot_categorizer ( columns_to_categorize = [ [string] , [string] ] , hardcode_nans = False ) [EOL] [EOL] pred_fn , data , log = categorizer_learner ( input_df_train ) [EOL] [EOL] test_result = pred_fn ( input_df_test ) [EOL] [EOL] assert ( test_result [ expected_output_test_no_hardcode . columns ] . equals ( expected_output_test_no_hardcode ) ) [EOL] [EOL] assert ( data [ expected_output_train_no_hardcode . columns ] . equals ( expected_output_train_no_hardcode ) ) [EOL] [EOL] [comment] [EOL] categorizer_learner = onehot_categorizer ( columns_to_categorize = [ [string] , [string] ] , hardcode_nans = True ) [EOL] [EOL] pred_fn , data , log = categorizer_learner ( input_df_train ) [EOL] [EOL] test_result = pred_fn ( input_df_test ) [EOL] [EOL] assert ( test_result [ expected_output_test_hardcode . columns ] . equals ( expected_output_test_hardcode ) ) [EOL] [EOL] assert ( data [ expected_output_train_hardcode . columns ] . equals ( expected_output_train_hardcode ) ) [EOL] [EOL] [comment] [EOL] categorizer_learner = onehot_categorizer ( columns_to_categorize = [ [string] , [string] ] , hardcode_nans = False , drop_first_column = True ) [EOL] [EOL] pred_fn , data , log = categorizer_learner ( input_df_train ) [EOL] [EOL] test_result = pred_fn ( input_df_test ) [EOL] [EOL] assert ( test_result [ expected_output_test_drop_first . columns ] . equals ( expected_output_test_drop_first ) ) [EOL] assert ( data [ expected_output_train_drop_first . columns ] . equals ( expected_output_train_drop_first ) ) [EOL] [EOL] [EOL] def test_target_categorizer ( ) : [EOL] input_df_train_binary_target = pd . DataFrame ( { [string] : [ [number] , [number] , nan , [number] , [number] , [number] ] , [string] : [ [string] , [string] , [string] , [string] , [string] , [string] ] , [string] : [ [string] , [string] , [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] expected_output_train_binary_target = pd . DataFrame ( OrderedDict ( ( ( [string] , [ [number] , [number] , nan , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] , [number] , [number] ] ) ) ) ) [EOL] [EOL] input_df_test_binary_target = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ [string] , [string] , [string] ] , [string] : [ [string] , [string] , [string] ] } ) [EOL] [EOL] expected_output_test_binary_target = pd . DataFrame ( OrderedDict ( ( ( [string] , [ [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] ] ) , ( [string] , [ [number] , nan , [number] ] ) ) ) ) [EOL] [EOL] input_df_train_continuous_target = pd . DataFrame ( { [string] : [ [number] , [number] , nan , [number] , [number] , [number] ] , [string] : [ [string] , [string] , [string] , nan , [string] , [string] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] expected_output_train_continuous_target = pd . DataFrame ( OrderedDict ( ( ( [string] , [ [number] , [number] , nan , [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , nan , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] , [number] , [number] , [number] ] ) ) ) ) [EOL] [EOL] input_df_test_continuous_target = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ [string] , [string] , [string] ] , } ) [EOL] [EOL] expected_output_test_continuous_target = pd . DataFrame ( OrderedDict ( ( ( [string] , [ [number] , [number] , [number] ] ) , ( [string] , [ [number] , [number] , [number] ] ) , ) ) ) [EOL] [EOL] [comment] [EOL] categorizer_learner = target_categorizer ( columns_to_categorize = [ [string] , [string] ] , target_column = [string] ) [EOL] [EOL] pred_fn , data , log = categorizer_learner ( input_df_train_binary_target ) [EOL] [EOL] test_result = pred_fn ( input_df_test_binary_target ) [EOL] [EOL] assert ( test_result [ expected_output_test_binary_target . columns ] . equals ( expected_output_test_binary_target ) ) [EOL] [EOL] assert ( data [ expected_output_train_binary_target . columns ] . equals ( expected_output_train_binary_target ) ) [EOL] [EOL] [comment] [EOL] categorizer_learner = target_categorizer ( columns_to_categorize = [ [string] ] , target_column = [string] , ignore_unseen = False ) [EOL] [EOL] pred_fn , data , log = categorizer_learner ( input_df_train_continuous_target ) [EOL] [EOL] test_result = pred_fn ( input_df_test_continuous_target ) [EOL] [EOL] assert_almost_equal ( test_result [ expected_output_test_continuous_target . columns ] . values , expected_output_test_continuous_target . values , decimal = [number] ) [EOL] [EOL] assert_almost_equal ( data [ expected_output_train_continuous_target . columns ] . values , expected_output_train_continuous_target . values , decimal = [number] ) [EOL] [EOL] [EOL] def test_standard_scaler ( ) : [EOL] input_df_train = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , } ) [EOL] [EOL] expected_output_train = pd . DataFrame ( { [string] : [ - [number] , - [number] , [number] ] , } ) [EOL] [EOL] input_df_test = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , } ) [EOL] [EOL] expected_output_test = pd . DataFrame ( { [string] : [ - [number] , - [number] , - [number] ] , } ) [EOL] [EOL] pred_fn , train_result , log = standard_scaler ( input_df_train , [ [string] ] ) [EOL] test_result = pred_fn ( input_df_test ) [EOL] [EOL] assert_almost_equal ( expected_output_train . values , train_result . values , decimal = [number] ) [EOL] [EOL] assert_almost_equal ( test_result . values , expected_output_test . values , decimal = [number] ) [EOL] [EOL] [EOL] def test_ecdfer ( ) : [EOL] fit_df = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] input_df = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] expected_df = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] ascending = True [EOL] prediction_column = [string] [EOL] ecdf_column = [string] [EOL] max_range = [number] [EOL] [EOL] pred_fn , data , log = ecdfer ( fit_df , ascending , prediction_column , ecdf_column , max_range ) [EOL] actual_df = pred_fn ( input_df ) [EOL] [EOL] assert_almost_equal ( expected_df [ ecdf_column ] . values , actual_df [ ecdf_column ] . values , decimal = [number] ) [EOL] [EOL] ascending = False [EOL] pred_fn , data , log = ecdfer ( fit_df , ascending , prediction_column , ecdf_column , max_range ) [EOL] [EOL] expected_df = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] } ) [EOL] actual_df = pred_fn ( input_df ) [EOL] assert_almost_equal ( expected_df [ ecdf_column ] . values , actual_df [ ecdf_column ] . values , decimal = [number] ) [EOL] [EOL] [EOL] def test_discrete_ecdfer ( ) : [EOL] fit_df = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] input_df = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] ascending = True [EOL] prediction_column = [string] [EOL] ecdf_column = [string] [EOL] max_range = [number] [EOL] [EOL] ecdfer_fn , _ , _ = ecdfer ( fit_df , ascending , prediction_column , ecdf_column , max_range ) [EOL] ecdfer_df = ecdfer_fn ( input_df ) [EOL] [EOL] discrete_ecdfer_fn , _ , _ = discrete_ecdfer ( fit_df , ascending , prediction_column , ecdf_column , max_range , round_method = round ) [EOL] discrete_ecdfer_df = discrete_ecdfer_fn ( input_df ) [EOL] [EOL] assert_almost_equal ( ecdfer_df [ ecdf_column ] . values , discrete_ecdfer_df [ ecdf_column ] . values , decimal = [number] ) [EOL] [EOL] ascending = False [EOL] ecdfer_fn , data , log = ecdfer ( fit_df , ascending , prediction_column , ecdf_column , max_range ) [EOL] ecdfer_df = ecdfer_fn ( input_df ) [EOL] [EOL] discrete_ecdfer_fn , _ , _ = discrete_ecdfer ( fit_df , ascending , prediction_column , ecdf_column , max_range , round_method = float ) [EOL] discrete_ecdfer_df = discrete_ecdfer_fn ( input_df ) [EOL] [EOL] assert_almost_equal ( discrete_ecdfer_df [ ecdf_column ] . values , ecdfer_df [ ecdf_column ] . values , decimal = [number] ) [EOL] [EOL] [EOL] def test_custom_transformer ( ) : [EOL] input_df = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ math . e , math . e ** [number] , math . e ** [number] ] , [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] } ) [EOL] [EOL] expected = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ math . e , math . e ** [number] , math . e ** [number] ] , [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] } ) [EOL] [EOL] expected2 = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ math . e , math . e ** [number] , math . e ** [number] ] , [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] } ) [EOL] [EOL] transformer_fn , data , log = custom_transformer ( input_df , [ [string] ] , sqrt ) [EOL] [EOL] [comment] [EOL] assert expected . equals ( data ) [EOL] [EOL] transformer_fn , data , log = custom_transformer ( input_df , [ [string] ] , lambda x : x ** [number] ) [EOL] [EOL] [comment] [EOL] assert expected2 . equals ( data ) [EOL] [EOL] expected3 = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] } ) [EOL] [EOL] expected4 = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ math . e , math . e ** [number] , math . e ** [number] ] , [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] } ) [EOL] [EOL] transformer_fn , data , log = custom_transformer ( input_df , [ [string] ] , ln , is_vectorized = True ) [EOL] [EOL] [comment] [EOL] assert expected3 . equals ( data ) [EOL] [EOL] transformer_fn , data , log = custom_transformer ( input_df , [ [string] ] , floor , is_vectorized = True ) [EOL] [EOL] [comment] [EOL] assert expected4 . equals ( data ) [EOL] [EOL] [EOL] def test_null_injector ( ) : [EOL] train = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , } ) [EOL] [EOL] test = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] } ) [EOL] [EOL] p , result , log = null_injector ( train , [number] , [ [string] , [string] ] , seed = [number] ) [EOL] [EOL] expected = pd . DataFrame ( { [string] : [ [number] , nan , nan , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , nan , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , } ) [EOL] [EOL] assert expected . equals ( result ) [EOL] [EOL] assert p ( test ) . equals ( test ) , [string] [EOL] [EOL] [comment] [EOL] p , result , log = null_injector ( train , [number] , groups = [ [ [string] ] , [ [string] , [string] ] ] , seed = [number] ) [EOL] [EOL] expected = pd . DataFrame ( { [string] : [ [number] , nan , nan , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , nan , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , nan , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , } ) [EOL] [EOL] assert expected . equals ( result ) [EOL] [EOL] assert p ( test ) . equals ( test ) , [string] [EOL] [EOL] [EOL] def test_missing_warner ( ) : [EOL] train = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , nan , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] test = pd . DataFrame ( { [string] : [ [number] , nan , nan , [number] , [number] ] , [string] : [ [number] , nan , [number] , [number] , [number] ] , [string] : [ nan , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , nan , [number] ] } ) [EOL] [EOL] p , result , log = missing_warner ( train , [ [string] , [string] , [string] ] , [string] ) [EOL] [EOL] expected_train_1 = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , nan , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] expected_test_1 = pd . DataFrame ( { [string] : [ [number] , nan , nan , [number] , [number] ] , [string] : [ [number] , nan , [number] , [number] , [number] ] , [string] : [ nan , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , nan , [number] ] , [string] : [ False , True , True , False , False ] } ) [EOL] [EOL] [comment] [EOL] assert expected_train_1 . equals ( result ) [EOL] [EOL] assert expected_test_1 . equals ( p ( test ) ) [EOL] [EOL] p , result , log = missing_warner ( train , [ [string] , [string] , [string] ] , [string] , True , [string] ) [EOL] [EOL] expected_train_2 = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , nan , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] expected_test_2 = pd . DataFrame ( { [string] : [ [number] , nan , nan , [number] , [number] ] , [string] : [ [number] , nan , [number] , [number] , [number] ] , [string] : [ nan , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , nan , [number] ] , [string] : [ False , True , True , False , False ] , [string] : [ [ ] , [ [string] , [string] ] , [ [string] ] , [ ] , [ ] ] } ) [EOL] [EOL] [comment] [EOL] assert expected_train_2 . equals ( result ) [EOL] [EOL] assert expected_test_2 . equals ( p ( test ) ) [EOL] [EOL] [comment] [EOL] [EOL] test_2 = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] expected_test_3 = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] ] , [string] : [ False , False , False , False , False ] , [string] : [ [ ] , [ ] , [ ] , [ ] , [ ] ] } ) [EOL] [EOL] assert expected_test_3 . equals ( p ( test_2 ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Dict , Any , List [EOL] import typing [EOL] from datetime import timedelta [EOL] [EOL] import numpy as np [EOL] import pandas as pd [EOL] from sklearn . datasets import load_boston [EOL] [EOL] from fklearn . data . datasets import make_tutorial_data [EOL] from fklearn . metrics . pd_extractors import ( combined_evaluator_extractor , evaluator_extractor , extract , split_evaluator_extractor , temporal_split_evaluator_extractor ) [EOL] from fklearn . training . regression import linear_regression_learner [EOL] from fklearn . validation . evaluators import ( combined_evaluators , r2_evaluator , spearman_evaluator , split_evaluator , temporal_split_evaluator , mse_evaluator ) [EOL] from fklearn . validation . splitters import ( forward_stability_curve_time_splitter , out_of_time_and_space_splitter , stability_curve_time_splitter , time_learning_curve_splitter ) [EOL] from fklearn . validation . validator import validator [EOL] [EOL] [EOL] def test__split_evaluator_extractor__when_split_value_is_missing ( ) : [EOL] expected = [ { [string] : np . nan , [string] : pd . Timestamp ( [string] ) , [string] : [string] } , { [string] : [number] , [string] : pd . Timestamp ( [string] ) , [string] : [string] } , { [string] : np . nan , [string] : pd . Timestamp ( [string] ) , [string] : [string] } , { [string] : [number] , [string] : pd . Timestamp ( [string] ) , [string] : [string] } , { [string] : np . nan , [string] : pd . Timestamp ( [string] ) , [string] : [string] } , { [string] : [number] , [string] : pd . Timestamp ( [string] ) , [string] : [string] } , { [string] : [number] , [string] : pd . Timestamp ( [string] ) , [string] : [string] } , { [string] : np . nan , [string] : pd . Timestamp ( [string] ) , [string] : [string] } , { [string] : [number] , [string] : pd . Timestamp ( [string] ) , [string] : [string] } , { [string] : np . nan , [string] : pd . Timestamp ( [string] ) , [string] : [string] } , { [string] : [number] , [string] : pd . Timestamp ( [string] ) , [string] : [string] } , { [string] : np . nan , [string] : pd . Timestamp ( [string] ) , [string] : [string] } , { [string] : np . nan , [string] : pd . Timestamp ( [string] ) , [string] : [string] } , { [string] : [number] , [string] : pd . Timestamp ( [string] ) , [string] : [string] } ] [EOL] expected_df = pd . DataFrame . from_dict ( expected ) [EOL] data = make_tutorial_data ( [number] ) . dropna ( subset = [ [string] ] ) . assign ( prediction = lambda d : d . target ) [EOL] [EOL] feature3_evaluator = split_evaluator ( eval_fn = mse_evaluator , split_col = [string] ) [EOL] feature3_date_evaluator = split_evaluator ( eval_fn = feature3_evaluator , split_col = [string] ) [EOL] [EOL] results = feature3_date_evaluator ( data ) [EOL] [EOL] date_values = [ np . datetime64 ( [string] ) , np . datetime64 ( [string] ) , np . datetime64 ( [string] ) , np . datetime64 ( [string] ) , np . datetime64 ( [string] ) , np . datetime64 ( [string] ) , np . datetime64 ( [string] ) , ] [EOL] [EOL] base_evaluator = evaluator_extractor ( evaluator_name = [string] ) [EOL] feature3_extractor = split_evaluator_extractor ( base_extractor = base_evaluator , split_col = [string] , split_values = [ [string] , [string] ] ) [EOL] feature3_date_extractor = split_evaluator_extractor ( base_extractor = feature3_extractor , split_col = [string] , split_values = date_values ) [EOL] [EOL] actual_df = feature3_date_extractor ( results ) . reset_index ( drop = True ) [EOL] pd . testing . assert_frame_equal ( actual_df , expected_df , check_like = True ) [EOL] [EOL] [EOL] def test_extract ( ) : [EOL] boston = load_boston ( ) [EOL] df = pd . DataFrame ( boston [ [string] ] , columns = boston [ [string] ] ) [EOL] df [ [string] ] = boston [ [string] ] [EOL] df [ [string] ] = pd . date_range ( start = [string] , periods = len ( df ) ) [EOL] np . random . seed ( [number] ) [EOL] df [ [string] ] = np . random . randint ( [number] , [number] , size = len ( df ) ) [EOL] [EOL] [comment] [EOL] train_fn = linear_regression_learner ( features = boston [ [string] ] . tolist ( ) , target = [string] ) [EOL] [EOL] [comment] [EOL] base_evaluator = combined_evaluators ( evaluators = [ r2_evaluator ( target_column = [string] , prediction_column = [string] ) , spearman_evaluator ( target_column = [string] , prediction_column = [string] ) ] ) [EOL] [EOL] splitter = split_evaluator ( eval_fn = base_evaluator , split_col = [string] , split_values = [ [number] , [number] , [number] ] ) [EOL] temporal_week_splitter = temporal_split_evaluator ( eval_fn = base_evaluator , time_col = [string] , time_format = [string] ) [EOL] temporal_year_splitter = temporal_split_evaluator ( eval_fn = base_evaluator , time_col = [string] , time_format = [string] ) [EOL] [EOL] eval_fn = combined_evaluators ( evaluators = [ base_evaluator , splitter ] ) [EOL] temporal_week_eval_fn = combined_evaluators ( evaluators = [ base_evaluator , temporal_week_splitter ] ) [EOL] temporal_year_eval_fn = combined_evaluators ( evaluators = [ base_evaluator , temporal_year_splitter ] ) [EOL] [EOL] [comment] [EOL] cv_split_fn = out_of_time_and_space_splitter ( n_splits = [number] , in_time_limit = [string] , time_column = [string] , space_column = [string] ) [EOL] [EOL] tlc_split_fn = time_learning_curve_splitter ( training_time_limit = [string] , time_column = [string] , min_samples = [number] ) [EOL] [EOL] sc_split_fn = stability_curve_time_splitter ( training_time_limit = [string] , time_column = [string] , min_samples = [number] ) [EOL] [EOL] fw_sc_split_fn = forward_stability_curve_time_splitter ( training_time_start = [string] , training_time_end = [string] , holdout_gap = timedelta ( days = [number] ) , holdout_size = timedelta ( days = [number] ) , step = timedelta ( days = [number] ) , time_column = [string] ) [EOL] [EOL] [comment] [EOL] cv_results = validator ( df , cv_split_fn , train_fn , eval_fn ) [ [string] ] [EOL] tlc_results = validator ( df , tlc_split_fn , train_fn , eval_fn ) [ [string] ] [EOL] sc_results = validator ( df , sc_split_fn , train_fn , eval_fn ) [ [string] ] [EOL] fw_sc_results = validator ( df , fw_sc_split_fn , train_fn , eval_fn ) [ [string] ] [EOL] [EOL] [comment] [EOL] predict_fn , _ , _ = train_fn ( df ) [EOL] temporal_week_results = temporal_week_eval_fn ( predict_fn ( df ) ) [EOL] temporal_year_results = temporal_year_eval_fn ( predict_fn ( df ) ) [EOL] [EOL] [comment] [EOL] base_extractors = combined_evaluator_extractor ( base_extractors = [ evaluator_extractor ( evaluator_name = [string] ) , evaluator_extractor ( evaluator_name = [string] ) ] ) [EOL] [EOL] splitter_extractor = split_evaluator_extractor ( split_col = [string] , split_values = [ [number] , [number] , [number] ] , base_extractor = base_extractors ) [EOL] [EOL] temporal_week_splitter_extractor = temporal_split_evaluator_extractor ( time_col = [string] , time_format = [string] , base_extractor = base_extractors ) [EOL] [EOL] temporal_year_splitter_extractor = temporal_split_evaluator_extractor ( time_col = [string] , time_format = [string] , base_extractor = base_extractors ) [EOL] [EOL] assert extract ( cv_results , base_extractors ) . shape == ( [number] , [number] ) [EOL] assert extract ( cv_results , splitter_extractor ) . shape == ( [number] , [number] ) [EOL] [EOL] assert extract ( tlc_results , base_extractors ) . shape == ( [number] , [number] ) [EOL] assert extract ( tlc_results , splitter_extractor ) . shape == ( [number] , [number] ) [EOL] [EOL] assert extract ( sc_results , base_extractors ) . shape == ( [number] , [number] ) [EOL] assert extract ( sc_results , splitter_extractor ) . shape == ( [number] , [number] ) [EOL] [EOL] assert extract ( fw_sc_results , base_extractors ) . shape == ( [number] , [number] ) [EOL] assert extract ( fw_sc_results , splitter_extractor ) . shape == ( [number] , [number] ) [EOL] [EOL] n_time_week_folds = len ( df [ [string] ] . dt . strftime ( [string] ) . unique ( ) ) [EOL] n_time_year_folds = len ( df [ [string] ] . dt . strftime ( [string] ) . unique ( ) ) [EOL] assert temporal_week_splitter_extractor ( temporal_week_results ) . shape == ( n_time_week_folds , [number] ) [EOL] assert temporal_year_splitter_extractor ( temporal_year_results ) . shape == ( n_time_year_folds , [number] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Any [EOL] import typing [EOL] import numpy as np [EOL] [EOL] from fklearn . data . datasets import make_tutorial_data , make_confounded_data [EOL] [EOL] [EOL] def test_make_tutorial_data ( ) : [EOL] df = make_tutorial_data ( [number] ) [EOL] assert df . shape [ [number] ] == [number] [EOL] [EOL] [EOL] def test_make_confounded_data ( ) : [EOL] f_rnd , df_obs , df_ctf = make_confounded_data ( [number] ) [EOL] traeat_corr = f_rnd . corr ( ) . loc [ [ [string] , [string] , [string] ] , [string] ] [EOL] [EOL] assert f_rnd . shape [ [number] ] == df_obs . shape [ [number] ] == df_ctf . shape [ [number] ] [EOL] assert np . all ( np . abs ( traeat_corr ) < [number] ) , [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List [EOL] import typing [EOL] import pandas as pd [EOL] import pytest [EOL] from tests import LOGS , PARALLEL_LOGS [EOL] from toolz . curried import first [EOL] [EOL] from fklearn . metrics . pd_extractors import evaluator_extractor [EOL] from fklearn . training . classification import logistic_classification_learner [EOL] from fklearn . tuning . samplers import ( remove_by_feature_importance , remove_by_feature_shuffling , remove_features_subsets ) [EOL] from fklearn . validation . evaluators import roc_auc_evaluator [EOL] [EOL] [EOL] @ pytest . fixture ( ) def logs ( ) : [EOL] return LOGS [EOL] [EOL] [EOL] @ pytest . fixture ( ) def parallel_logs ( ) : [EOL] return PARALLEL_LOGS [EOL] [EOL] [EOL] @ pytest . fixture ( ) def base_extractor ( ) : [EOL] return evaluator_extractor ( evaluator_name = [string] ) [EOL] [EOL] [EOL] @ pytest . fixture ( ) def metric_name ( ) : [EOL] return [string] [EOL] [EOL] [EOL] @ pytest . fixture ( ) def train_df ( ) : [EOL] df_train_binary = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] df_train_binary2 = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] df_train_binary3 = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] return pd . concat ( [ df_train_binary , df_train_binary2 , df_train_binary3 ] ) [EOL] [EOL] [EOL] @ pytest . fixture ( ) def holdout_df ( ) : [EOL] return pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] [EOL] @ pytest . fixture ( ) def train_fn ( ) : [EOL] return logistic_classification_learner ( target = [string] , prediction_column = [string] , weight_column = [string] , params = { [string] : [number] } ) [EOL] [EOL] [EOL] @ pytest . fixture ( ) def eval_fn ( ) : [EOL] return roc_auc_evaluator [EOL] [EOL] [EOL] def test_remove_by_feature_importance ( logs ) : [EOL] log = first ( logs ) [EOL] next_features = remove_by_feature_importance ( log , num_removed_by_step = [number] ) [EOL] assert next_features == [ [string] , [string] , [string] ] [EOL] [EOL] [EOL] def test_remove_features_subsets ( logs , base_extractor , metric_name ) : [EOL] next_subsets = remove_features_subsets ( logs , base_extractor , metric_name , num_removed_by_step = [number] ) [EOL] assert sorted ( next_subsets ) == [ ( [string] , ) , ( [string] , ) ] [EOL] [EOL] [EOL] def test_remove_by_shuffling ( train_df , holdout_df , train_fn , eval_fn , base_extractor , metric_name , logs ) : [EOL] features = [ [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] predict_fn , _ , train_logs = train_fn ( train_df , features ) [EOL] next_features = remove_by_feature_shuffling ( logs [ [number] ] , predict_fn , eval_fn , holdout_df , base_extractor , metric_name , max_removed_by_step = [number] , threshold = [number] , speed_up_by_importance = True ) [EOL] [EOL] assert sorted ( next_features ) == sorted ( [ [string] , [string] , [string] ] ) [EOL] [EOL] [comment] [EOL] next_features = remove_by_feature_shuffling ( logs [ [number] ] , predict_fn , eval_fn , holdout_df , base_extractor , metric_name , max_removed_by_step = [number] , threshold = [number] , speed_up_by_importance = False , parallel = True , nthread = [number] ) [EOL] [EOL] assert sorted ( next_features ) == sorted ( [ [string] , [string] , [string] ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Union , Dict , Any , List , Callable [EOL] import typing [EOL] import numpy as np [EOL] import pandas as pd [EOL] from toolz import curry [EOL] [EOL] from fklearn . training . classification import xgb_classification_learner [EOL] from fklearn . tuning . parameter_tuners import random_search_tuner , grid_search_cv [EOL] from fklearn . validation . evaluators import roc_auc_evaluator [EOL] from fklearn . validation . splitters import out_of_time_and_space_splitter [EOL] [EOL] [EOL] def test_random_search_tuner ( tmpdir ) : [EOL] train_set = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : pd . to_datetime ( [ [string] , [string] , [string] , [string] ] ) , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] eval_fn = roc_auc_evaluator ( target_column = [string] ) [EOL] [EOL] space = { [string] : lambda : np . random . choice ( [ [number] , [number] , [number] , [number] , [number] ] ) , [string] : lambda : np . random . choice ( [ [number] , [number] , [number] ] ) } [EOL] [EOL] @ curry def param_train_fn ( space , train_set ) : [EOL] return xgb_classification_learner ( features = [ [string] ] , target = [string] , learning_rate = space [ [string] ] , num_estimators = space [ [string] ] ) ( train_set ) [EOL] [EOL] split_fn = out_of_time_and_space_splitter ( n_splits = [number] , in_time_limit = [string] , space_column = [string] , time_column = [string] ) [EOL] [EOL] tuning_log = random_search_tuner ( space = space , train_set = train_set , param_train_fn = param_train_fn , split_fn = split_fn , eval_fn = eval_fn , iterations = [number] , random_seed = [number] ) [EOL] assert len ( tuning_log ) == [number] [EOL] [EOL] [EOL] def test_grid_search_tuner ( tmpdir ) : [EOL] train_set = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : pd . to_datetime ( [ [string] , [string] , [string] , [string] ] ) , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] eval_fn = roc_auc_evaluator ( target_column = [string] ) [EOL] [EOL] space = { [string] : lambda : [ [number] , [number] , [number] ] , [string] : lambda : [ [number] , [number] ] , [string] : lambda : [ True ] } [EOL] [EOL] @ curry def param_train_fn ( space , train_set ) : [EOL] return xgb_classification_learner ( features = [ [string] ] , target = [string] , learning_rate = space [ [string] ] , num_estimators = space [ [string] ] ) ( train_set ) [EOL] [EOL] split_fn = out_of_time_and_space_splitter ( n_splits = [number] , in_time_limit = [string] , space_column = [string] , time_column = [string] ) [EOL] [EOL] tuning_log = grid_search_cv ( space = space , train_set = train_set , param_train_fn = param_train_fn , split_fn = split_fn , eval_fn = eval_fn ) [EOL] [EOL] assert len ( tuning_log ) == [number] * [number] [EOL] [EOL] space = { [string] : lambda : [ [number] , [number] , [number] , [number] ] , [string] : lambda : [ [number] , [number] ] , [string] : lambda : [ True ] } [EOL] [EOL] tuning_log = grid_search_cv ( space = space , train_set = train_set , param_train_fn = param_train_fn , split_fn = split_fn , eval_fn = eval_fn ) [EOL] [EOL] assert len ( tuning_log ) == [number] * [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List [EOL] import typing [EOL] import pandas as pd [EOL] import pytest [EOL] [EOL] from fklearn . training . classification import logistic_classification_learner [EOL] from fklearn . metrics . pd_extractors import evaluator_extractor [EOL] from fklearn . tuning . utils import get_avg_metric_from_extractor , get_best_performing_log , get_used_features , gen_key_avgs_from_dicts , gen_key_avgs_from_logs , order_feature_importance_avg_from_logs , gen_key_avgs_from_iteration , gen_dict_extract [EOL] [EOL] [EOL] @ pytest . fixture ( ) def logs ( ) : [EOL] return [ { [string] : { [string] : { [string] : [ [string] , [string] , [string] , [string] , [string] , [string] ] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : { [string] : [string] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] } , [string] : { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] } , [string] : [number] , [string] : [string] } } , [string] : [ { [string] : [number] , [string] : [ { [string] : [number] } ] , [string] : { [string] : [number] , [string] : [number] } } , { [string] : [number] , [string] : [ { [string] : [number] } ] , [string] : { [string] : [number] , [string] : [number] } } ] , [string] : [ [string] , [string] ] } , { [string] : { [string] : { [string] : [ [string] , [string] , [string] , [string] , [string] , [string] ] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : { [string] : [string] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] } , [string] : { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] } , [string] : [number] , [string] : [string] } } , [string] : [ { [string] : [number] , [string] : [ { [string] : [number] } ] , [string] : { [string] : [number] , [string] : [number] } } , { [string] : [number] , [string] : [ { [string] : [number] } ] , [string] : { [string] : [number] , [string] : [number] } } ] , [string] : [ [string] , [string] ] } ] [EOL] [EOL] [EOL] @ pytest . fixture ( ) def base_extractor ( ) : [EOL] return evaluator_extractor ( evaluator_name = [string] ) [EOL] [EOL] [EOL] @ pytest . fixture ( ) def metric_name ( ) : [EOL] return [string] [EOL] [EOL] [EOL] @ pytest . fixture ( ) def train_df ( ) : [EOL] df_train_binary = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] df_train_binary2 = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] df_train_binary3 = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] return pd . concat ( [ df_train_binary , df_train_binary2 , df_train_binary3 ] ) [EOL] [EOL] [EOL] @ pytest . fixture ( ) def holdout_df ( ) : [EOL] return pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] [EOL] @ pytest . fixture ( ) def train_fn ( ) : [EOL] return logistic_classification_learner ( target = [string] , prediction_column = [string] , weight_column = [string] , params = { [string] : [number] } ) [EOL] [EOL] [EOL] def test_get_avg_metric_from_extractor ( logs , base_extractor , metric_name ) : [EOL] result = get_avg_metric_from_extractor ( logs [ [number] ] , base_extractor , metric_name ) [EOL] assert result == [number] [EOL] [EOL] [EOL] def test_get_best_performing_log ( logs , base_extractor , metric_name ) : [EOL] result = get_best_performing_log ( logs , base_extractor , metric_name ) [EOL] assert result == logs [ [number] ] [EOL] [EOL] [EOL] def test_get_used_features ( logs ) : [EOL] result = get_used_features ( logs [ [number] ] ) [EOL] assert result == [ [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] [EOL] [EOL] def test_order_feature_importance_avg_from_logs ( logs ) : [EOL] result = order_feature_importance_avg_from_logs ( logs [ [number] ] ) [EOL] assert result == [ [string] , [string] , [string] , [string] , [string] ] [EOL] [EOL] [EOL] def test_gen_key_avgs_from_logs ( logs ) : [EOL] result = gen_key_avgs_from_logs ( [string] , logs ) [EOL] assert result == { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] } [EOL] [EOL] [EOL] def test_gen_key_avgs_from_iteration ( logs ) : [EOL] result = gen_key_avgs_from_iteration ( [string] , logs [ [number] ] ) [EOL] assert result == { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] } [EOL] [EOL] [EOL] def test_gen_key_avgs_from_dicts ( ) : [EOL] result = gen_key_avgs_from_dicts ( [ { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] } , { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] } ] ) [EOL] assert result == { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] } [EOL] [EOL] [EOL] def test_gen_dict_extract ( logs ) : [EOL] result = list ( gen_dict_extract ( [string] , logs [ [number] ] ) ) [EOL] assert result == [ { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] } ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
import pytest [EOL] [EOL] from fklearn . metrics . pd_extractors import evaluator_extractor [EOL] from fklearn . tuning . stoppers import stop_by_iter_num , stop_by_no_improvement , stop_by_num_features , stop_by_no_improvement_parallel , stop_by_num_features_parallel [EOL] [EOL] from tests import LOGS , PARALLEL_LOGS [EOL] [EOL] [EOL] @ pytest . fixture ( ) def logs ( ) : [EOL] return LOGS [EOL] [EOL] [EOL] @ pytest . fixture ( ) def parallel_logs ( ) : [EOL] return PARALLEL_LOGS [EOL] [EOL] [EOL] @ pytest . fixture ( ) def base_extractor ( ) : [EOL] return evaluator_extractor ( evaluator_name = [string] ) [EOL] [EOL] [EOL] @ pytest . fixture ( ) def metric_name ( ) : [EOL] return [string] [EOL] [EOL] [EOL] def test_stop_by_iter_num ( logs ) : [EOL] assert stop_by_iter_num ( logs , iter_limit = [number] ) [EOL] assert not stop_by_iter_num ( logs , iter_limit = [number] ) [EOL] [EOL] [EOL] def test_stop_by_no_improvement ( logs , base_extractor , metric_name ) : [EOL] assert stop_by_no_improvement ( logs , base_extractor , metric_name , early_stop = [number] , threshold = [number] ) [EOL] assert not stop_by_no_improvement ( logs , base_extractor , metric_name , early_stop = [number] , threshold = [number] ) [EOL] [EOL] assert stop_by_no_improvement ( logs , base_extractor , metric_name , early_stop = [number] , threshold = [number] ) [EOL] assert not stop_by_no_improvement ( logs , base_extractor , metric_name , early_stop = [number] , threshold = [number] ) [EOL] [EOL] [EOL] def test_stop_by_num_features ( logs ) : [EOL] assert stop_by_num_features ( logs , min_num_features = [number] ) [EOL] assert not stop_by_num_features ( logs , min_num_features = [number] ) [EOL] [EOL] [EOL] def test_stop_by_no_improvement_parallel ( parallel_logs , base_extractor , metric_name ) : [EOL] assert stop_by_no_improvement_parallel ( parallel_logs , base_extractor , metric_name , early_stop = [number] , threshold = [number] ) [EOL] assert not stop_by_no_improvement_parallel ( parallel_logs , base_extractor , metric_name , early_stop = [number] , threshold = [number] ) [EOL] [EOL] assert stop_by_no_improvement_parallel ( parallel_logs , base_extractor , metric_name , early_stop = [number] , threshold = [number] ) [EOL] assert not stop_by_no_improvement_parallel ( parallel_logs , base_extractor , metric_name , early_stop = [number] , threshold = [number] ) [EOL] [EOL] [EOL] def test_stop_by_num_features_parallel ( parallel_logs , base_extractor , metric_name ) : [EOL] assert stop_by_num_features_parallel ( parallel_logs , base_extractor , metric_name , min_num_features = [number] ) [EOL] assert not stop_by_num_features_parallel ( parallel_logs , base_extractor , metric_name , min_num_features = [number] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List [EOL] import typing [EOL] import pandas as pd [EOL] from fklearn . tuning . model_agnostic_fc import variance_feature_selection , correlation_feature_selection [EOL] [EOL] [EOL] def test_correlation_feature_selection ( ) : [EOL] [EOL] train_set = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : pd . to_datetime ( [ [string] , [string] , [string] , [string] ] ) , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ - [number] , - [number] , - [number] , - [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] features = [ [string] , [string] , [string] , [string] , [string] ] [EOL] [EOL] result = correlation_feature_selection ( train_set , features , threshold = [number] ) [EOL] [EOL] assert set ( result [ [string] ] ) == { [string] , [string] } [EOL] assert set ( result [ [string] ] ) == { [string] , [string] , [string] } [EOL] [EOL] [EOL] def test_variance_feature_selection ( ) : [EOL] [EOL] train_set = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : pd . to_datetime ( [ [string] , [string] , [string] , [string] ] ) , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ - [number] , - [number] , - [number] , - [number] ] , [string] : [ - [number] , - [number] , - [number] , - [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] features = [ [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] [EOL] result = variance_feature_selection ( train_set , features ) [EOL] [EOL] assert set ( result [ [string] ] ) == { [string] } [EOL] assert set ( result [ [string] ] ) == { [string] , [string] , [string] , [string] , [string] } [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , Any , List [EOL] import typing [EOL] import pandas as pd [EOL] import pytest [EOL] [EOL] from toolz . curried import first [EOL] [EOL] from fklearn . metrics . pd_extractors import evaluator_extractor [EOL] from fklearn . training . classification import logistic_classification_learner [EOL] from fklearn . tuning . utils import get_used_features [EOL] from fklearn . tuning . selectors import feature_importance_backward_selection , poor_man_boruta_selection , backward_subset_feature_selection [EOL] from fklearn . validation . evaluators import roc_auc_evaluator [EOL] from fklearn . validation . splitters import k_fold_splitter [EOL] [EOL] from tests import LOGS , PARALLEL_LOGS [EOL] [EOL] [EOL] @ pytest . fixture ( ) def logs ( ) : [EOL] return LOGS [EOL] [EOL] [EOL] @ pytest . fixture ( ) def parallel_logs ( ) : [EOL] return PARALLEL_LOGS [EOL] [EOL] [EOL] @ pytest . fixture ( ) def base_extractor ( ) : [EOL] return evaluator_extractor ( evaluator_name = [string] ) [EOL] [EOL] [EOL] @ pytest . fixture ( ) def metric_name ( ) : [EOL] return [string] [EOL] [EOL] [EOL] @ pytest . fixture ( ) def train_df ( ) : [EOL] df_train_binary = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] df_train_binary2 = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] df_train_binary3 = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] return pd . concat ( [ df_train_binary , df_train_binary2 , df_train_binary3 ] ) [EOL] [EOL] [EOL] @ pytest . fixture ( ) def holdout_df ( ) : [EOL] return pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] [EOL] @ pytest . fixture ( ) def train_fn ( ) : [EOL] return logistic_classification_learner ( target = [string] , prediction_column = [string] , weight_column = [string] , params = { [string] : [number] } ) [EOL] [EOL] [EOL] @ pytest . fixture ( ) def eval_fn ( ) : [EOL] return roc_auc_evaluator [EOL] [EOL] [EOL] @ pytest . fixture ( ) def split_fn ( ) : [EOL] return k_fold_splitter ( n_splits = [number] , random_state = [number] ) [EOL] [EOL] [EOL] def test_feature_importance_backward_selection ( train_df , train_fn , eval_fn , split_fn , base_extractor , metric_name ) : [EOL] features = [ [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] logs = feature_importance_backward_selection ( train_df , train_fn , features , split_fn , eval_fn , base_extractor , metric_name , num_removed_by_step = [number] , threshold = [number] , early_stop = [number] , iter_limit = [number] , min_remaining_features = [number] ) [EOL] assert len ( get_used_features ( first ( logs ) ) ) <= [number] [comment] [EOL] [EOL] logs = feature_importance_backward_selection ( train_df , train_fn , features , split_fn , eval_fn , base_extractor , metric_name , num_removed_by_step = [number] , threshold = [number] , early_stop = [number] , iter_limit = [number] , min_remaining_features = [number] ) [EOL] assert len ( logs ) == [number] [comment] [EOL] [EOL] logs = feature_importance_backward_selection ( train_df , train_fn , features , split_fn , eval_fn , base_extractor , metric_name , num_removed_by_step = [number] , threshold = [number] , early_stop = [number] , iter_limit = [number] , min_remaining_features = [number] ) [EOL] assert len ( logs ) == [number] [comment] [EOL] [EOL] [EOL] def test_poor_man_boruta_selection ( train_df , holdout_df , train_fn , eval_fn , base_extractor , metric_name ) : [EOL] features = [ [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] logs = poor_man_boruta_selection ( train_df , holdout_df , train_fn , features , eval_fn , base_extractor , metric_name , max_removed_by_step = [number] , threshold = [number] , early_stop = [number] , iter_limit = [number] , min_remaining_features = [number] ) [EOL] [EOL] assert len ( get_used_features ( first ( logs ) ) ) <= [number] [comment] [EOL] [EOL] logs = poor_man_boruta_selection ( train_df , holdout_df , train_fn , features , eval_fn , base_extractor , metric_name , max_removed_by_step = [number] , threshold = [number] , early_stop = [number] , iter_limit = [number] , min_remaining_features = [number] ) [EOL] assert len ( logs ) == [number] [comment] [EOL] [EOL] logs = poor_man_boruta_selection ( train_df , holdout_df , train_fn , features , eval_fn , base_extractor , metric_name , max_removed_by_step = [number] , threshold = [number] , early_stop = [number] , iter_limit = [number] , min_remaining_features = [number] ) [EOL] assert len ( logs ) == [number] [comment] [EOL] [EOL] [EOL] def test_backward_subset_feature_selection ( train_df , train_fn , eval_fn , split_fn , base_extractor , metric_name ) : [EOL] features_sets = { [string] : [ [string] , [string] ] , [string] : [ [string] , [string] ] , [string] : [ [string] , [string] ] } [EOL] [EOL] logs = backward_subset_feature_selection ( train_df , train_fn , features_sets , split_fn , eval_fn , base_extractor , metric_name , num_removed_by_step = [number] , threshold = - [number] , early_stop = [number] , iter_limit = [number] , min_remaining_features = [number] ) [EOL] assert len ( get_used_features ( first ( logs ) [ [number] ] ) ) <= [number] [comment] [EOL] [EOL] logs = backward_subset_feature_selection ( train_df , train_fn , features_sets , split_fn , eval_fn , base_extractor , metric_name , num_removed_by_step = [number] , threshold = [number] , early_stop = [number] , iter_limit = [number] , min_remaining_features = [number] ) [EOL] [EOL] assert len ( logs ) == [number] [comment] [EOL] [EOL] logs = backward_subset_feature_selection ( train_df , train_fn , features_sets , split_fn , eval_fn , base_extractor , metric_name , num_removed_by_step = [number] , threshold = [number] , early_stop = [number] , iter_limit = [number] , min_remaining_features = [number] ) [EOL] [EOL] assert len ( logs ) == [number] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
	0
from typing import Any [EOL] import typing [EOL] from fklearn . validation . perturbators import shift_mu , random_noise , nullify , sample_columns , perturbator [EOL] [EOL] import pandas as pd [EOL] import numpy as np [EOL] [EOL] [EOL] def test_shift_mu ( ) : [EOL] series = pd . Series ( [ [number] , [number] , [number] , [number] , [number] ] ) [EOL] shift_by = [number] [EOL] expected = pd . Series ( [ [number] , [number] , [number] , [number] , [number] ] ) [EOL] new_series = shift_mu ( col = series , perc = shift_by ) [EOL] map ( np . testing . assert_approx_equal , zip ( expected , new_series ) ) [EOL] [EOL] [EOL] def test_random_noise ( ) : [EOL] series = pd . Series ( [ [number] , [number] , [number] , [number] , [number] ] ) [EOL] random_noise ( col = series , mag = [number] ) [EOL] [EOL] [EOL] def test_nullify ( ) : [EOL] series = pd . Series ( [ [number] , [number] , [number] , [number] , [number] ] ) [EOL] expected_nan_count = [number] [EOL] new_series = nullify ( col = series , perc = [number] ) [EOL] new_nan_count = sum ( new_series . isna ( ) ) [EOL] assert expected_nan_count == new_nan_count [EOL] [EOL] [EOL] def test_sample_columns ( ) : [EOL] df = pd . DataFrame ( columns = [ [string] , [string] , [string] , [string] ] ) [EOL] expected_len = [number] [EOL] found = sample_columns ( data = df , perc = [number] ) [EOL] assert expected_len == len ( found ) [EOL] assert all ( [ el in df . columns for el in found ] ) [EOL] [EOL] [EOL] def test_perturbator ( ) : [EOL] test_df = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] } ) [EOL] [EOL] expected_df = pd . DataFrame ( { [string] : [ np . nan , np . nan , np . nan ] , [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] } ) [EOL] [EOL] out_df = perturbator ( data = test_df , cols = [ [string] ] , corruption_fn = nullify ( ) ) [EOL] [EOL] assert expected_df . equals ( out_df ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Optional , Dict , Any , List [EOL] import typing [EOL] import string [EOL] [EOL] import numpy as np [EOL] import pandas as pd [EOL] import pytest [EOL] [EOL] from fklearn . validation . evaluators import ( auc_evaluator , brier_score_evaluator , combined_evaluators , correlation_evaluator , expected_calibration_error_evaluator , fbeta_score_evaluator , hash_evaluator , logloss_evaluator , mean_prediction_evaluator , mse_evaluator , permutation_evaluator , pr_auc_evaluator , precision_evaluator , r2_evaluator , recall_evaluator , roc_auc_evaluator , spearman_evaluator , ndcg_evaluator , split_evaluator , temporal_split_evaluator ) [EOL] [EOL] [EOL] def test_combined_evaluators ( ) : [EOL] predictions = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] } ) [EOL] [EOL] eval_fn1 = r2_evaluator [EOL] eval_fn2 = mse_evaluator [EOL] [EOL] result = combined_evaluators ( predictions , [ eval_fn1 , eval_fn2 ] ) [EOL] [EOL] assert result [ [string] ] == [number] [EOL] assert result [ [string] ] == [number] [EOL] [EOL] [EOL] def test_mean_prediction_evaluator ( ) : [EOL] predictions = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] } ) [EOL] [EOL] eval_fn = mean_prediction_evaluator ( prediction_column = [string] , eval_name = [string] ) [EOL] [EOL] result = eval_fn ( predictions ) [EOL] [EOL] assert result [ [string] ] == ( [number] + [number] + [number] ) / [number] [EOL] [EOL] [EOL] def test_auc_evaluator ( ) : [EOL] predictions = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] eval_fn = auc_evaluator ( prediction_column = [string] , target_column = [string] , eval_name = [string] ) [EOL] [EOL] result = eval_fn ( predictions ) [EOL] [EOL] assert result [ [string] ] == [number] [EOL] [EOL] [EOL] def test_roc_auc_evaluator ( ) : [EOL] predictions = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] eval_fn = roc_auc_evaluator ( prediction_column = [string] , target_column = [string] , eval_name = [string] ) [EOL] [EOL] result = eval_fn ( predictions ) [EOL] [EOL] assert result [ [string] ] == [number] [EOL] [EOL] [EOL] def test_pr_auc_evaluator ( ) : [EOL] predictions = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] eval_fn = pr_auc_evaluator ( prediction_column = [string] , target_column = [string] , eval_name = [string] ) [EOL] [EOL] result = eval_fn ( predictions ) [EOL] [EOL] assert result [ [string] ] == pytest . approx ( [number] ) [EOL] [EOL] [EOL] def test_precision_evaluator ( ) : [EOL] predictions = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] eval_fn = precision_evaluator ( prediction_column = [string] , threshold = [number] , target_column = [string] , eval_name = [string] ) [EOL] [EOL] result = eval_fn ( predictions ) [EOL] [EOL] assert result [ [string] ] == [number] [EOL] [EOL] [EOL] def test_recall_evaluator ( ) : [EOL] predictions = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] eval_fn = recall_evaluator ( prediction_column = [string] , threshold = [number] , target_column = [string] , eval_name = [string] ) [EOL] [EOL] result = eval_fn ( predictions ) [EOL] [EOL] assert result [ [string] ] == [number] [EOL] [EOL] [EOL] def test_fbeta_score_evaluator ( ) : [EOL] predictions = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] eval_fn = fbeta_score_evaluator ( prediction_column = [string] , threshold = [number] , beta = [number] , target_column = [string] , eval_name = [string] ) [EOL] [EOL] result = eval_fn ( predictions ) [EOL] [EOL] assert result [ [string] ] == [number] [EOL] [EOL] [EOL] def test_logloss_evaluator ( ) : [EOL] predictions = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] eval_fn = logloss_evaluator ( prediction_column = [string] , target_column = [string] , eval_name = [string] ) [EOL] [EOL] result = eval_fn ( predictions ) [EOL] [EOL] assert abs ( result [ [string] ] - [number] ) < [number] [EOL] [EOL] [EOL] def test_brier_score_evaluator ( ) : [EOL] predictions = pd . DataFrame ( { [string] : [ [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] eval_fn = brier_score_evaluator ( prediction_column = [string] , target_column = [string] , eval_name = [string] ) [EOL] [EOL] result = eval_fn ( predictions ) [EOL] [EOL] assert abs ( result [ [string] ] - [number] ) < [number] [EOL] [EOL] [EOL] def test_binary_calibration_evaluator ( ) : [EOL] np . random . seed ( [number] ) [EOL] probs = np . linspace ( [number] , [number] - [number] , [number] ) [EOL] target = np . random . binomial ( n = [number] , p = probs , size = [number] ) [EOL] [EOL] predictions = pd . DataFrame ( { [string] : target , [string] : probs } ) [EOL] [EOL] eval_fn = expected_calibration_error_evaluator ( prediction_column = [string] , target_column = [string] , eval_name = [string] , n_bins = [number] , bin_choice = [string] ) [EOL] [EOL] result_count = eval_fn ( predictions ) [EOL] [EOL] assert result_count [ [string] ] < [number] [EOL] [EOL] eval_fn = expected_calibration_error_evaluator ( prediction_column = [string] , target_column = [string] , eval_name = [string] , n_bins = [number] , bin_choice = [string] ) [EOL] [EOL] result_prob = eval_fn ( predictions ) [EOL] [EOL] assert result_prob [ [string] ] < [number] [EOL] [EOL] assert abs ( result_count [ [string] ] - result_prob [ [string] ] ) < [number] [EOL] [EOL] [EOL] def test_r2_evaluator ( ) : [EOL] predictions = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] } ) [EOL] [EOL] result = r2_evaluator ( predictions ) [EOL] [EOL] assert result [ [string] ] == [number] [EOL] [EOL] [EOL] def test_mse_evaluator ( ) : [EOL] predictions = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] } ) [EOL] [EOL] result = mse_evaluator ( predictions ) [EOL] [EOL] assert result [ [string] ] == [number] [EOL] [EOL] [EOL] def test_correlation_evaluator ( ) : [EOL] predictions = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] } ) [EOL] [EOL] result = correlation_evaluator ( predictions ) [EOL] [EOL] assert result [ [string] ] == [number] [EOL] [EOL] [EOL] def test_spearman_evaluator ( ) : [EOL] predictions = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] } ) [EOL] [EOL] result = spearman_evaluator ( predictions ) [EOL] [EOL] assert result [ [string] ] == [number] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ False , True ] ) def test_ndcg_evaluator ( exponential_gain ) : [EOL] predictions = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] } ) [EOL] [EOL] k_raises = [ - [number] , [number] , [number] ] [EOL] for k in k_raises : [EOL] with pytest . raises ( ValueError ) : [EOL] ndcg_evaluator ( predictions , k = k , exponential_gain = exponential_gain ) [EOL] [EOL] k_not_raises = [ None , [number] , [number] , [number] ] [EOL] for k in k_not_raises : [EOL] result = ndcg_evaluator ( predictions , k = k , exponential_gain = exponential_gain ) [EOL] assert result [ [string] ] == [number] [EOL] [EOL] [EOL] def test_split_evaluator ( ) : [EOL] predictions = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] } ) [EOL] [EOL] base_eval = mean_prediction_evaluator [EOL] split_eval = split_evaluator ( eval_fn = base_eval , split_col = [string] , split_values = [ [number] ] ) [EOL] [EOL] result = split_evaluator ( predictions , split_eval , [string] , [ [number] ] ) [EOL] [EOL] assert result [ [string] ] [ [string] ] [ [string] ] == [number] [EOL] [EOL] [EOL] def test_temporal_split_evaluator ( ) : [EOL] predictions = pd . DataFrame ( { [string] : pd . date_range ( [string] , periods = [number] , freq = [string] ) , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] } ) [EOL] [EOL] base_eval = mean_prediction_evaluator [EOL] result = temporal_split_evaluator ( predictions , eval_fn = base_eval , time_col = [string] ) [EOL] [EOL] expected = { [string] : { [string] : [number] } , [string] : { [string] : [number] } , [string] : { [string] : [number] } } [EOL] [EOL] assert result == expected [EOL] [EOL] [EOL] def test_permutation_evaluator ( ) : [EOL] test_df = pd . DataFrame ( { [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] , [string] : [ [number] , [number] , [number] ] } ) [EOL] [EOL] base_eval = r2_evaluator [EOL] [EOL] def fake_predict ( df ) : [EOL] return df . assign ( prediction = [ [number] , [number] , [number] ] ) [EOL] [EOL] expected_results = { [string] : [number] } [EOL] [EOL] pimp1 = permutation_evaluator ( test_df , fake_predict , base_eval , features = [ [string] ] , baseline = True , shuffle_all_at_once = False ) [EOL] [EOL] assert pimp1 [ [string] ] [ [string] ] == expected_results [EOL] assert pimp1 [ [string] ] == expected_results [EOL] [EOL] pimp2 = permutation_evaluator ( test_df , fake_predict , base_eval , features = [ [string] , [string] ] , baseline = False , shuffle_all_at_once = False ) [EOL] [EOL] assert pimp2 [ [string] ] [ [string] ] == expected_results [EOL] assert pimp2 [ [string] ] [ [string] ] == expected_results [EOL] [EOL] pimp3 = permutation_evaluator ( test_df , fake_predict , base_eval , features = [ [string] , [string] ] , baseline = True , shuffle_all_at_once = True ) [EOL] [EOL] assert pimp3 [ [string] ] [ [string] ] == expected_results [EOL] assert pimp3 [ [string] ] == expected_results [EOL] [EOL] test_df2 = pd . DataFrame ( { [string] : np . linspace ( [number] , [number] , [number] ) , [string] : [number] - np . linspace ( [number] , [number] , [number] ) , [string] : np . ones ( [number] ) } ) [EOL] [EOL] def fake_predict2 ( df ) : [EOL] return df . assign ( prediction = df [ [string] ] + df [ [string] ] ) [EOL] [EOL] expected_results2 = { [string] : [number] } [EOL] [EOL] pimp4 = permutation_evaluator ( test_df2 , fake_predict2 , base_eval , features = [ [string] ] , baseline = True , shuffle_all_at_once = False , random_state = [number] ) [EOL] [EOL] assert pimp4 [ [string] ] [ [string] ] != expected_results2 [EOL] assert pimp4 [ [string] ] == expected_results2 [EOL] [EOL] [EOL] def test_hash_evaluator ( ) : [EOL] rows = [number] [EOL] np . random . seed ( [number] ) [EOL] [EOL] [comment] [EOL] categories = [ [string] . join ( np . random . choice ( list ( string . ascii_uppercase + string . digits ) , size = [number] ) ) for _ in range ( [number] ) ] [EOL] [comment] [EOL] df1 = pd . DataFrame ( { [string] : np . random . normal ( size = rows ) , [string] : np . random . choice ( categories , size = rows ) , [string] : np . repeat ( [ [number] , [number] ] , int ( rows / [number] ) ) } ) [EOL] [EOL] [comment] [EOL] df2 = df1 . copy ( ) . sample ( frac = [number] ) . reset_index ( drop = True ) [EOL] df2 [ [string] ] = np . repeat ( [ [number] , [number] ] , int ( rows / [number] ) ) [EOL] [comment] [EOL] df3 = df1 . copy ( ) [EOL] df3 . iloc [ [number] , [number] ] = [number] [EOL] [EOL] [comment] [EOL] eval_fn = hash_evaluator ( hash_columns = [ [string] , [string] ] , eval_name = [string] ) [EOL] [comment] [EOL] eval_fn_all = hash_evaluator ( eval_name = [string] ) [EOL] eval_fn_order = hash_evaluator ( hash_columns = [ [string] , [string] ] , eval_name = [string] , consider_index = True ) [EOL] [EOL] [comment] [EOL] assert eval_fn ( df1 ) [ [string] ] == eval_fn ( df2 ) [ [string] ] [EOL] [comment] [EOL] assert eval_fn_order ( df1 ) [ [string] ] != eval_fn_order ( df2 ) [ [string] ] [EOL] [comment] [EOL] assert eval_fn ( df1 ) [ [string] ] != eval_fn ( df3 ) [ [string] ] [EOL] [comment] [EOL] assert eval_fn_all ( df1 ) [ [string] ] != eval_fn_all ( df2 ) [ [string] ] [EOL] [comment] [EOL] assert eval_fn_all ( df1 ) [ [string] ] == - [number] [EOL] assert eval_fn_all ( df2 ) [ [string] ] == - [number] [EOL] assert eval_fn_all ( df3 ) [ [string] ] == [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] from datetime import timedelta [EOL] [EOL] import pandas as pd [EOL] [EOL] from fklearn . validation . splitters import k_fold_splitter , out_of_time_and_space_splitter , spatial_learning_curve_splitter , time_learning_curve_splitter , reverse_time_learning_curve_splitter , stability_curve_time_splitter , stability_curve_time_in_space_splitter , stability_curve_time_space_splitter , forward_stability_curve_time_splitter , time_and_space_learning_curve_splitter [EOL] [EOL] sample_data = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] , [string] , [string] , [string] ] , [string] : pd . to_datetime ( [ [string] , [string] , [string] , [string] , [string] , [string] , [string] ] ) } ) [EOL] [EOL] [comment] [EOL] sample_data . index = [ [number] ] * sample_data . shape [ [number] ] [EOL] [EOL] [EOL] def test_k_fold_splitter ( ) : [EOL] [comment] [EOL] result , logs = k_fold_splitter ( sample_data , [number] , random_state = [number] ) [EOL] [EOL] assert len ( result ) == [number] [EOL] [EOL] train_1_idx = result [ [number] ] [ [number] ] [EOL] test_1_idx = result [ [number] ] [ [number] ] [ [number] ] [EOL] train_2_idx = result [ [number] ] [ [number] ] [EOL] test_2_idx = result [ [number] ] [ [number] ] [ [number] ] [EOL] [EOL] assert set ( train_1_idx ) == set ( test_2_idx ) [EOL] assert set ( test_1_idx ) == set ( train_2_idx ) [EOL] [EOL] [comment] [EOL] result , logs = k_fold_splitter ( sample_data , [number] , random_state = [number] , stratify_column = [string] ) [EOL] [EOL] assert len ( result ) == [number] [EOL] [EOL] train_1_idx = result [ [number] ] [ [number] ] [EOL] test_1_idx = result [ [number] ] [ [number] ] [ [number] ] [EOL] train_2_idx = result [ [number] ] [ [number] ] [EOL] test_2_idx = result [ [number] ] [ [number] ] [ [number] ] [EOL] [EOL] assert set ( train_1_idx ) == set ( test_2_idx ) [EOL] assert set ( test_1_idx ) == set ( train_2_idx ) [EOL] [EOL] train_1_strat = sample_data . iloc [ train_1_idx ] [ [string] ] [EOL] test_1_strat = sample_data . iloc [ test_1_idx ] [ [string] ] [EOL] train_2_strat = sample_data . iloc [ train_2_idx ] [ [string] ] [EOL] test_2_strat = sample_data . iloc [ test_2_idx ] [ [string] ] [EOL] [EOL] assert train_1_strat . nunique ( ) == test_2_strat . nunique ( ) [EOL] assert train_2_strat . nunique ( ) == test_1_strat . nunique ( ) [EOL] [EOL] [EOL] def test_out_of_time_and_space_splitter ( ) : [EOL] result , logs = out_of_time_and_space_splitter ( sample_data , [number] , [string] , time_column = [string] , space_column = [string] , holdout_gap = timedelta ( days = [number] ) ) [EOL] [EOL] assert len ( result ) == [number] [EOL] train_1 = sample_data . iloc [ result [ [number] ] [ [number] ] ] [EOL] test_1 = sample_data . iloc [ result [ [number] ] [ [number] ] [ [number] ] ] [EOL] train_2 = sample_data . iloc [ result [ [number] ] [ [number] ] ] [EOL] test_2 = sample_data . iloc [ result [ [number] ] [ [number] ] [ [number] ] ] [EOL] [EOL] [comment] [EOL] assert len ( train_1 [ train_1 . space . isin ( train_2 . space ) ] ) == [number] [EOL] assert len ( train_2 [ train_2 . space . isin ( train_1 . space ) ] ) == [number] [EOL] [EOL] [comment] [EOL] assert len ( train_1 [ train_1 . time > [string] ] ) == [number] [EOL] assert len ( train_2 [ train_2 . time > [string] ] ) == [number] [EOL] [EOL] [comment] [EOL] assert len ( test_1 [ test_1 . time <= [string] ] ) == [number] [EOL] assert len ( test_2 [ test_2 . time <= [string] ] ) == [number] [EOL] [EOL] [comment] [EOL] assert len ( train_1 ) + len ( train_2 ) == len ( sample_data [ sample_data . time <= [string] ] ) [EOL] [EOL] [EOL] def test_time_and_space_learning_curve_splitter ( ) : [EOL] random_state = [number] [EOL] result , logs = time_and_space_learning_curve_splitter ( sample_data , [string] , space_column = [string] , time_column = [string] , holdout_gap = timedelta ( days = [number] ) , random_state = random_state , min_samples = [number] ) [EOL] [EOL] assert len ( result ) == [number] [EOL] test_1 = sample_data . iloc [ result [ [number] ] [ [number] ] [ [number] ] ] [EOL] train_4 = sample_data . iloc [ result [ [number] ] [ [number] ] ] [EOL] test_4 = sample_data . iloc [ result [ [number] ] [ [number] ] [ [number] ] ] [EOL] [EOL] [comment] [EOL] assert set ( result [ [number] ] [ [number] ] [ [number] ] ) == set ( result [ [number] ] [ [number] ] [ [number] ] ) [EOL] assert set ( result [ [number] ] [ [number] ] [ [number] ] ) == set ( result [ [number] ] [ [number] ] [ [number] ] ) [EOL] assert set ( result [ [number] ] [ [number] ] [ [number] ] ) == set ( result [ [number] ] [ [number] ] [ [number] ] ) [EOL] assert len ( test_1 [ test_1 . time <= [string] ] ) == [number] [EOL] [EOL] [comment] [EOL] assert set ( result [ [number] ] [ [number] ] ) . issubset ( set ( result [ [number] ] [ [number] ] ) ) [EOL] assert set ( result [ [number] ] [ [number] ] ) . issubset ( set ( result [ [number] ] [ [number] ] ) ) [EOL] assert set ( result [ [number] ] [ [number] ] ) . issubset ( set ( result [ [number] ] [ [number] ] ) ) [EOL] assert len ( train_4 [ train_4 . time > [string] ] ) == [number] [EOL] [EOL] [comment] [EOL] assert len ( test_4 [ test_4 . space . isin ( train_4 . space ) ] ) == [number] [EOL] assert len ( train_4 [ train_4 . space . isin ( test_4 . space ) ] ) == [number] [EOL] [EOL] [EOL] def test_spatial_learning_curve_splitte ( ) : [EOL] result , logs = spatial_learning_curve_splitter ( sample_data , train_percentages = [ [number] , [number] ] , space_column = [string] , time_column = [string] , training_limit = [string] , holdout_gap = timedelta ( days = [number] ) , random_state = [number] ) [EOL] [EOL] assert len ( result ) == [number] [EOL] [EOL] train_1 = sample_data . iloc [ result [ [number] ] [ [number] ] ] [EOL] train_2 = sample_data . iloc [ result [ [number] ] [ [number] ] ] [EOL] test_1 = sample_data . iloc [ result [ [number] ] [ [number] ] [ [number] ] ] [EOL] test_2 = sample_data . iloc [ result [ [number] ] [ [number] ] [ [number] ] ] [EOL] [EOL] assert test_1 . equals ( test_2 ) [EOL] assert len ( set ( train_1 [ [string] ] ) . intersection ( train_2 [ [string] ] ) ) > [number] [EOL] assert train_1 [ [string] ] . max ( ) < test_1 [ [string] ] . min ( ) [EOL] assert train_2 [ [string] ] . max ( ) < test_2 [ [string] ] . min ( ) [EOL] assert test_1 [ [string] ] . min ( ) - train_1 [ [string] ] . max ( ) >= timedelta ( days = [number] ) [EOL] assert test_2 [ [string] ] . min ( ) - train_2 [ [string] ] . max ( ) >= timedelta ( days = [number] ) [EOL] assert len ( train_2 ) > len ( train_1 ) [EOL] [EOL] [EOL] def test_time_learning_curve_splitter ( ) : [EOL] result , logs = time_learning_curve_splitter ( sample_data , [string] , time_column = [string] , holdout_gap = timedelta ( days = [number] ) , min_samples = [number] ) [EOL] [EOL] assert len ( result ) == [number] [EOL] train_1 = sample_data . iloc [ result [ [number] ] [ [number] ] ] [EOL] test_1 = sample_data . iloc [ result [ [number] ] [ [number] ] [ [number] ] ] [EOL] train_2 = sample_data . iloc [ result [ [number] ] [ [number] ] ] [EOL] train_3 = sample_data . iloc [ result [ [number] ] [ [number] ] ] [EOL] train_4 = sample_data . iloc [ result [ [number] ] [ [number] ] ] [EOL] test_4 = sample_data . iloc [ result [ [number] ] [ [number] ] [ [number] ] ] [EOL] [EOL] [comment] [EOL] assert set ( result [ [number] ] [ [number] ] [ [number] ] ) == set ( result [ [number] ] [ [number] ] [ [number] ] ) [EOL] assert set ( result [ [number] ] [ [number] ] [ [number] ] ) == set ( result [ [number] ] [ [number] ] [ [number] ] ) [EOL] assert set ( result [ [number] ] [ [number] ] [ [number] ] ) == set ( result [ [number] ] [ [number] ] [ [number] ] ) [EOL] assert len ( test_1 [ test_1 . time <= [string] ] ) == [number] [EOL] [EOL] [comment] [EOL] assert set ( result [ [number] ] [ [number] ] ) . issubset ( set ( result [ [number] ] [ [number] ] ) ) [EOL] assert set ( result [ [number] ] [ [number] ] ) . issubset ( set ( result [ [number] ] [ [number] ] ) ) [EOL] assert set ( result [ [number] ] [ [number] ] ) . issubset ( set ( result [ [number] ] [ [number] ] ) ) [EOL] assert len ( train_4 [ train_4 . time > [string] ] ) == [number] [EOL] [EOL] [comment] [EOL] assert set ( test_4 . space ) == set ( sample_data . space ) [EOL] [EOL] [comment] [EOL] assert train_2 . time . max ( ) > train_1 . time . max ( ) [EOL] assert train_3 . time . max ( ) > train_2 . time . max ( ) [EOL] [EOL] [EOL] def test_reverse_time_learning_curve_splitter ( ) : [EOL] result , logs = reverse_time_learning_curve_splitter ( sample_data , time_column = [string] , training_time_limit = [string] , holdout_gap = timedelta ( days = [number] ) , min_samples = [number] ) [EOL] [EOL] assert len ( result ) == [number] [EOL] train_1 = sample_data . iloc [ result [ [number] ] [ [number] ] ] [EOL] test_1 = sample_data . iloc [ result [ [number] ] [ [number] ] [ [number] ] ] [EOL] train_2 = sample_data . iloc [ result [ [number] ] [ [number] ] ] [EOL] train_3 = sample_data . iloc [ result [ [number] ] [ [number] ] ] [EOL] [EOL] [comment] [EOL] assert set ( result [ [number] ] [ [number] ] [ [number] ] ) == set ( result [ [number] ] [ [number] ] [ [number] ] ) [EOL] assert set ( result [ [number] ] [ [number] ] [ [number] ] ) == set ( result [ [number] ] [ [number] ] [ [number] ] ) [EOL] assert len ( test_1 [ test_1 . time <= [string] ] ) == [number] [EOL] [EOL] [comment] [EOL] assert set ( result [ [number] ] [ [number] ] ) . issubset ( set ( result [ [number] ] [ [number] ] ) ) [EOL] assert set ( result [ [number] ] [ [number] ] ) . issubset ( set ( result [ [number] ] [ [number] ] ) ) [EOL] assert len ( train_3 [ train_3 . time > [string] ] ) == [number] [EOL] [EOL] [comment] [EOL] assert train_2 . time . min ( ) < train_1 . time . min ( ) [EOL] assert train_3 . time . min ( ) < train_2 . time . min ( ) [EOL] [EOL] [comment] [EOL] assert len ( train_1 ) == [number] [EOL] [comment] [EOL] assert len ( train_3 ) == [number] [EOL] [EOL] [EOL] def test_stability_curve_time_splitter ( ) : [EOL] result , logs = stability_curve_time_splitter ( sample_data , [string] , time_column = [string] , min_samples = [number] ) [EOL] [EOL] assert len ( result ) == [number] [EOL] assert len ( result [ [number] ] ) == [number] [EOL] [EOL] train_1 = sample_data . iloc [ result [ [number] ] [ [number] ] ] [EOL] test_1 = sample_data . iloc [ result [ [number] ] [ [number] ] [ [number] ] ] [EOL] test_2 = sample_data . iloc [ result [ [number] ] [ [number] ] [ [number] ] ] [EOL] test_3 = sample_data . iloc [ result [ [number] ] [ [number] ] [ [number] ] ] [EOL] [EOL] [comment] [EOL] assert len ( train_1 [ train_1 . time > [string] ] ) == [number] [EOL] [EOL] [comment] [EOL] assert len ( test_1 [ test_1 . time <= [string] ] ) == [number] [EOL] assert len ( test_2 [ test_2 . time <= [string] ] ) == [number] [EOL] assert len ( test_3 [ test_3 . time <= [string] ] ) == [number] [EOL] [EOL] [comment] [EOL] assert test_1 . time . max ( ) < test_2 . time . min ( ) [EOL] assert test_2 . time . max ( ) < test_3 . time . min ( ) [EOL] [EOL] [EOL] def test_stability_curve_time_in_space_splitter ( ) : [EOL] result , logs = stability_curve_time_in_space_splitter ( sample_data , [string] , random_state = [number] , time_column = [string] , min_samples = [number] , space_column = [string] , space_hold_percentage = [number] ) [EOL] [EOL] train_1 = sample_data . iloc [ result [ [number] ] [ [number] ] ] [EOL] test_1 = sample_data . iloc [ result [ [number] ] [ [number] ] [ [number] ] ] [EOL] [EOL] [comment] [EOL] assert len ( train_1 [ train_1 . time > [string] ] ) == [number] [EOL] [EOL] [comment] [EOL] assert len ( test_1 [ test_1 . time <= [string] ] ) == [number] [EOL] [EOL] [comment] [EOL] assert train_1 . space . isin ( test_1 . space . values ) . any ( ) [EOL] [EOL] [EOL] def test_stability_curve_time_space_splitter ( ) : [EOL] result , logs = stability_curve_time_space_splitter ( sample_data , [string] , random_state = [number] , time_column = [string] , min_samples = [number] , space_column = [string] , space_hold_percentage = [number] ) [EOL] [EOL] assert len ( result ) == [number] [EOL] assert len ( result [ [number] ] ) == [number] [EOL] train_1 = sample_data . iloc [ result [ [number] ] [ [number] ] ] [EOL] test_1 = sample_data . iloc [ result [ [number] ] [ [number] ] [ [number] ] ] [EOL] test_2 = sample_data . iloc [ result [ [number] ] [ [number] ] [ [number] ] ] [EOL] test_3 = sample_data . iloc [ result [ [number] ] [ [number] ] [ [number] ] ] [EOL] [EOL] [comment] [EOL] assert len ( train_1 [ train_1 . time > [string] ] ) == [number] [EOL] [EOL] [comment] [EOL] assert len ( test_1 [ test_1 . time <= [string] ] ) == [number] [EOL] assert len ( test_2 [ test_2 . time <= [string] ] ) == [number] [EOL] assert len ( test_3 [ test_3 . time <= [string] ] ) == [number] [EOL] [EOL] [comment] [EOL] assert test_1 . time . max ( ) < test_2 . time . min ( ) [EOL] assert test_2 . time . max ( ) < test_3 . time . min ( ) [EOL] [EOL] [comment] [EOL] assert len ( test_1 [ test_1 . space . isin ( train_1 . space ) ] ) == [number] [EOL] assert len ( train_1 [ train_1 . space . isin ( test_1 . space ) ] ) == [number] [EOL] [EOL] assert len ( test_2 [ test_2 . space . isin ( train_1 . space ) ] ) == [number] [EOL] assert len ( train_1 [ train_1 . space . isin ( test_2 . space ) ] ) == [number] [EOL] [EOL] assert len ( test_3 [ test_3 . space . isin ( train_1 . space ) ] ) == [number] [EOL] assert len ( train_1 [ train_1 . space . isin ( test_3 . space ) ] ) == [number] [EOL] [EOL] [EOL] def test_forward_stability_curve_time_splitter ( ) : [EOL] result , logs = forward_stability_curve_time_splitter ( sample_data , training_time_start = [string] , training_time_end = [string] , holdout_gap = timedelta ( days = [number] ) , holdout_size = timedelta ( days = [number] ) , step = timedelta ( days = [number] ) , time_column = [string] ) [EOL] [EOL] assert len ( result ) == [number] [EOL] assert len ( result [ [number] ] ) == [number] [EOL] [EOL] [comment] [EOL] assert len ( result [ [number] ] [ [number] ] ) == [number] [EOL] assert len ( result [ [number] ] [ [number] ] ) == [number] [EOL] assert len ( result [ [number] ] [ [number] ] ) == [number] [EOL] assert len ( result [ [number] ] [ [number] ] ) == [number] [EOL] [EOL] [comment] [EOL] assert len ( result [ [number] ] [ [number] ] [ [number] ] ) == [number] [EOL] assert len ( result [ [number] ] [ [number] ] [ [number] ] ) == [number] [EOL] assert len ( result [ [number] ] [ [number] ] [ [number] ] ) == [number] [EOL] assert len ( result [ [number] ] [ [number] ] [ [number] ] ) == [number] [EOL] [EOL] train_1 = sample_data . iloc [ result [ [number] ] [ [number] ] ] [EOL] train_2 = sample_data . iloc [ result [ [number] ] [ [number] ] ] [EOL] train_3 = sample_data . iloc [ result [ [number] ] [ [number] ] ] [EOL] [EOL] test_1 = sample_data . iloc [ result [ [number] ] [ [number] ] [ [number] ] ] [EOL] test_2 = sample_data . iloc [ result [ [number] ] [ [number] ] [ [number] ] ] [EOL] [EOL] assert train_2 . time . max ( ) < test_2 . time . min ( ) [EOL] [EOL] assert train_1 . time . min ( ) < train_2 . time . min ( ) [EOL] assert train_2 . time . min ( ) < train_3 . time . min ( ) [EOL] [EOL] assert test_1 . time . min ( ) < test_2 . time . min ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Union , Dict , Any , List [EOL] import typing [EOL] import warnings [EOL] [EOL] import pandas as pd [EOL] from toolz . functoolz import identity [EOL] [EOL] from fklearn . validation . validator import validator_iteration , validator , parallel_validator [EOL] from fklearn . validation . perturbators import perturbator , nullify [EOL] [EOL] [EOL] def train_fn ( df ) : [EOL] def p ( new_df ) : [EOL] return new_df . assign ( prediction = [number] ) [EOL] [EOL] log = { [string] : { [string] : [ [string] ] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : { [string] : [number] } , [string] : { [string] : [number] } , [string] : [string] , [string] : len ( df ) } } [EOL] [EOL] return p , p ( df ) , log [EOL] [EOL] [EOL] def eval_fn ( test_data ) : [EOL] return { [string] : [number] } [EOL] [EOL] [EOL] def split_fn ( df ) : [EOL] return [ ( [ [number] , [number] ] , [ [ [number] , [number] ] , [ [number] ] , [ [number] ] ] ) , ( [ [number] , [number] ] , [ [ [number] , [number] ] ] ) ] , [ { [string] : [number] } , { [string] : [number] } ] [EOL] [EOL] [EOL] perturb_fn_train = identity [EOL] perturb_fn_test = perturbator ( cols = [ [string] ] , corruption_fn = nullify ( perc = [number] ) ) [EOL] [EOL] [EOL] data = pd . DataFrame ( { [string] : [ [string] , [string] , [string] , [string] ] } ) [EOL] [EOL] [EOL] def test_validator_iteration ( ) : [EOL] train_index = [ [number] , [number] ] [EOL] test_indexes = [ [ [number] , [number] ] ] [EOL] [EOL] result = validator_iteration ( data , train_index , test_indexes , [number] , train_fn , eval_fn ) [EOL] [EOL] assert result [ [string] ] == [number] [EOL] assert result [ [string] ] [ [string] ] [ [string] ] == [ [string] ] [EOL] assert result [ [string] ] [ [number] ] [ [string] ] == [number] [EOL] [EOL] [comment] [EOL] with warnings . catch_warnings ( record = True ) as w : [EOL] warnings . simplefilter ( [string] ) [EOL] validator_iteration ( data , [ ] , test_indexes , [number] , train_fn , eval_fn ) [EOL] assert len ( w ) == [number] [EOL] assert [string] in str ( w [ - [number] ] . message ) [EOL] [EOL] [EOL] def test_validator ( ) : [EOL] result = validator ( data , split_fn , train_fn , eval_fn , perturb_fn_train , perturb_fn_test ) [EOL] [EOL] validator_log = result [ [string] ] [EOL] [EOL] assert len ( validator_log ) == [number] [EOL] assert validator_log [ [number] ] [ [string] ] == [number] [EOL] assert result [ [string] ] [ [string] ] [ [string] ] == [ [string] ] [EOL] [EOL] assert len ( validator_log [ [number] ] [ [string] ] ) == [number] [EOL] [EOL] assert validator_log [ [number] ] [ [string] ] == [number] [EOL] assert len ( validator_log [ [number] ] [ [string] ] ) == [number] [EOL] [EOL] perturbator_log = result [ [string] ] [EOL] [EOL] assert perturbator_log [ [string] ] == [ ] [EOL] assert perturbator_log [ [string] ] == [ [string] ] [EOL] [EOL] [EOL] def test_parallel_validator ( ) : [EOL] result = parallel_validator ( data , split_fn , train_fn , eval_fn , n_jobs = [number] ) [EOL] [EOL] validator_log = result [ [string] ] [EOL] [EOL] assert len ( validator_log ) == [number] [EOL] assert validator_log [ [number] ] [ [string] ] == [number] [EOL] assert result [ [string] ] [ [number] ] [ [string] ] [ [string] ] == [ [string] ] [EOL] [EOL] assert len ( validator_log [ [number] ] [ [string] ] ) == [number] [EOL] [EOL] assert validator_log [ [number] ] [ [string] ] == [number] [EOL] assert len ( validator_log [ [number] ] [ [string] ] ) == [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0