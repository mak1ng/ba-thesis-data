from typing import List [EOL] import typing [EOL] import pathlib [EOL] import hashlib [EOL] import json [EOL] import os [EOL] import pathlib [EOL] import shlex [EOL] [EOL] import nbformat [EOL] from invoke import task [EOL] [EOL] files_to_format = [ [string] , [string] , [string] ] [EOL] [EOL] inventories = [ [string] , [string] , [string] , [string] , [string] , [string] , ] [EOL] [EOL] directories_to_test = [ [string] , [string] ] [EOL] [EOL] [EOL] @ task def precommit ( c ) : [EOL] format ( c ) [EOL] docs ( c ) [EOL] test ( c ) [EOL] [EOL] [EOL] @ task def test ( c ) : [EOL] run ( c , [string] , * directories_to_test ) [EOL] [EOL] [EOL] @ task def docs ( c ) : [EOL] run ( c , * [ [string] , [string] , [string] , [string] ] , * ( part for inventory in inventories for part in [ [string] , inventory ] ) , * [ [string] , [string] ] , ) [EOL] [EOL] self_path = pathlib . Path ( __file__ ) . parent . resolve ( ) [EOL] [EOL] for p in self_path . glob ( [string] ) : [EOL] run ( c , * [ [string] , [string] , [string] , [string] ] , * [ str ( p ) , str ( p . with_suffix ( [string] ) ) ] , ) [EOL] [EOL] [EOL] @ task def format ( c ) : [EOL] run ( c , [string] , * files_to_format ) [EOL] [EOL] [EOL] @ task def release ( c , yes = False ) : [EOL] import packaging . version [EOL] [EOL] with c . cd ( [string] ) : [EOL] run ( c , [string] , [string] , [string] ) [EOL] [EOL] latest_package = max ( ( package for package in os . listdir ( [string] ) if not package . startswith ( [string] ) and package . endswith ( [string] ) ) , key = packaging . version . parse , ) [EOL] [EOL] if not yes : [EOL] answer = input ( f" [string] { latest_package } [string] " ) [EOL] if answer != [string] : [EOL] print ( [string] ) [EOL] return [EOL] [EOL] with c . cd ( [string] ) : [EOL] run ( c , [string] , [string] , latest_package ) [EOL] [EOL] [EOL] def run ( c , * args , ** kwargs ) : [EOL] args = [ shlex . quote ( arg ) for arg in args ] [EOL] args = [string] . join ( args ) [EOL] return c . run ( args , ** kwargs ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] import requests [EOL] import bz2 [EOL] import os . path [EOL] import sys [EOL] [EOL] import pandas as pd [EOL] import requests [EOL] [EOL] from chmp . ds import Object [EOL] [EOL] [EOL] def read_rhc_df ( fname , download = True ) : [EOL] if download : [EOL] ensure_rhc_data_exists ( fname ) [EOL] [EOL] df = pd . read_csv ( fname ) [EOL] [EOL] [comment] [EOL] df . columns = [ [string] , * df . columns [ [number] : ] ] [EOL] [EOL] df = df . set_index ( [string] ) [EOL] [EOL] for col in { [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , } : [EOL] df [ col ] = df [ col ] . astype ( [string] ) [EOL] [EOL] meta = Object ( outcome = [string] , treatment = [string] , ) [EOL] [EOL] return df , meta [EOL] [EOL] [EOL] def ensure_rhc_data_exists ( fname ) : [EOL] if os . path . exists ( fname ) : [EOL] return [EOL] [EOL] print ( [string] , file = sys . stderr ) [EOL] r = requests . get ( [string] , stream = True ) [EOL] r . raise_for_status ( ) [EOL] [EOL] with bz2 . open ( fname , [string] ) as fobj : [EOL] for line in r . iter_lines ( decode_unicode = True ) : [EOL] fobj . write ( line ) [EOL] [EOL] if not line . endswith ( [string] ) : [EOL] fobj . write ( [string] ) [EOL] [EOL] [EOL] def normalize_rhc_df ( df , meta ) : [EOL] [comment] [EOL] [comment] [EOL] [EOL] df = pd . DataFrame ( { [string] : ( df [ [string] ] == [string] ) . astype ( float ) , [string] : ( df [ [string] ] == [string] ) . astype ( float ) , [string] : ( df [ [string] ] == [string] ) . astype ( float ) , [string] : ( df [ [string] ] == [string] ) . astype ( float ) , [string] : ( df [ [string] ] == [string] ) . astype ( float ) , [string] : ( df [ [string] ] == [string] ) . astype ( float ) , [string] : ( df [ [string] ] == [string] ) . astype ( float ) , [string] : ( df [ [string] ] == [string] ) . astype ( float ) , [string] : ( df [ [string] ] == [string] ) . astype ( float ) , [string] : ( df [ [string] ] == [string] ) . astype ( float ) , [string] : ( df [ meta . outcome ] == [string] ) . astype ( int ) , [string] : ( df [ meta . treatment ] == [string] ) . astype ( int ) , [string] : df [ [string] ] , [string] : df [ [string] ] , } ) [EOL] meta = Object ( outcome = [string] , treatment = [string] , covariates = sorted ( { [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] } ) ) [EOL] [EOL] return df , meta [EOL] [EOL] [EOL] def read_proximity_df ( fname ) : [EOL] [docstring] [EOL] df = pd . read_csv ( fname ) [EOL] df . columns = [ [string] , * df . columns [ [number] : ] ] [EOL] df = df . drop ( columns = [ [string] ] ) . set_index ( [string] ) [EOL] df [ [string] ] = ( df [ [string] ] > [number] ) . astype ( [string] ) [EOL] [EOL] meta = Object ( instrument = [string] , treatment = [string] , outcome = [string] , ) [EOL] [EOL] return df , meta	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import List , Any [EOL] import typing [EOL] import numpy as np [EOL] import pandas as pd [EOL] [EOL] [EOL] def psmatch ( ps , treatment , * , m = [number] ) : [EOL] df = pd . DataFrame ( { [string] : ps , [string] : treatment } ) [EOL] return match ( df , treatment = [string] , covariates = [ [string] ] , m = m ) [EOL] [EOL] [EOL] def match ( df , * , treatment , covariates , m = [number] ) : [EOL] covariates = list ( covariates ) [EOL] [EOL] df_0 = df . loc [ df [ treatment ] == [number] , covariates ] [EOL] df_1 = df . loc [ df [ treatment ] == [number] , covariates ] [EOL] [EOL] if len ( df_1 ) < len ( df_0 ) : [EOL] needles , haystack = df_1 , df_0 [EOL] [EOL] else : [EOL] needles , haystack = df_0 , df_1 [EOL] [EOL] inv_cov = np . linalg . inv ( np . asarray ( df [ covariates ] . cov ( ) ) ) [EOL] [EOL] needles = np . asarray ( needles ) [EOL] haystack = np . asarray ( haystack ) [EOL] [EOL] needle_indices = np . arange ( len ( needles ) ) [EOL] np . random . shuffle ( needle_indices ) [EOL] [EOL] all_indices = np . arange ( len ( haystack ) , dtype = np . int64 ) [EOL] matched_indices = np . zeros ( m * len ( needles ) , dtype = np . int64 ) [EOL] taken = np . zeros ( len ( haystack ) , dtype = np . bool ) [EOL] [EOL] for k in range ( len ( needles ) ) : [EOL] i = needle_indices [ k ] [EOL] [EOL] available_indices = all_indices [ ~ taken ] [EOL] dx = haystack [ ~ taken ] - needles [ i , None , : ] [EOL] [EOL] dd = ( dx * ( dx @ inv_cov ) ) . sum ( axis = [number] ) [EOL] [EOL] selected = np . argsort ( dd ) [ : m ] [EOL] selected_indices = available_indices [ selected ] [EOL] matched_indices [ k * m : ( k + [number] ) * m ] = selected_indices [EOL] taken [ selected_indices ] = True [EOL] [EOL] assert np . sum ( taken ) == m * len ( needles ) [EOL] [EOL] if len ( df_1 ) < len ( df_0 ) : [EOL] return df_0 . index [ matched_indices ] , df_1 . index [ needle_indices ] [EOL] [EOL] else : [EOL] return df_0 . index [ needle_indices ] , df_1 . index [ matched_indices ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import List , Any [EOL] import typing [EOL] def prob ( counts , variables = None , condition = ( ) , transform = False ) : [EOL] [docstring] [EOL] condition = list ( condition ) [EOL] [EOL] if variables is None : [EOL] variables = [ * counts . index . names ] [EOL] [EOL] else : [EOL] variables = list ( variables ) [EOL] [EOL] if transform : [EOL] complement = [ name for name in counts . index . names if name not in { * variables } ] [EOL] [EOL] else : [EOL] complement = condition [EOL] [EOL] grouped = counts . groupby ( level = condition + variables ) [EOL] [EOL] counts = grouped . agg ( [string] ) if not transform else grouped . transform ( [string] ) [EOL] if not complement : [EOL] result = counts / counts . sum ( ) [EOL] [EOL] else : [EOL] result = counts / counts . groupby ( level = complement ) . transform ( [string] ) [EOL] [EOL] if len ( result . index . names ) > [number] : [EOL] return result . reorder_levels ( sorted ( result . index . names ) ) [EOL] [EOL] else : [EOL] return result [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from . tabular import prob [EOL]	0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] import numpy as np [EOL] import pandas as pd [EOL] import pandas . util . testing as pdt [EOL] [EOL] from chmp . app . causality . tabular import prob [EOL] [EOL] [EOL] def test_prob__conditional_transform ( ) : [EOL] df = pd . DataFrame ( ) . assign ( z = lambda df : np . random . binomial ( [number] , p = [number] , size = [number] ) , x = lambda df : np . random . binomial ( [number] , p = [number] + [number] * df [ [string] ] ) , y = lambda df : np . random . binomial ( [number] , p = [number] + [number] * df [ [string] ] + [number] * df [ [string] ] ) , ) [EOL] counts = df . groupby ( [ [string] , [string] , [string] ] ) . size ( ) [EOL] [EOL] pdt . assert_almost_equal ( counts . pipe ( prob , [ [string] ] , [ [string] ] ) . sort_index ( ) , ( counts . pipe ( prob , [ [string] ] , [ [string] ] , transform = True ) . groupby ( level = [ [string] , [string] ] ) . mean ( ) . sort_index ( ) ) , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import List , Tuple , Any [EOL] import typing [EOL] import argparse [EOL] import logging [EOL] [docstring] [EOL] import argparse [EOL] import logging [EOL] import os . path [EOL] [EOL] import numpy as np [EOL] import pandas as pd [EOL] import sklearn . linear_model [EOL] import sklearn . pipeline [EOL] [EOL] from chmp . ds import ( FuncTransformer , OneHotEncoder , DataFrameEstimator , FilterLowFrequencyTransfomer , ) [EOL] [EOL] _logger = logging . getLogger ( __name__ ) [EOL] [EOL] source_url = ( [string] ) [EOL] [EOL] columns = [ ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ] [EOL] [EOL] features = [ name for name , _ in columns if name != [string] ] [EOL] [EOL] [EOL] def create ( data_path ) : [EOL] def rename ( df ) : [EOL] df . columns = [ name for name , _ in columns ] [EOL] return df [EOL] [EOL] data_fname = os . path . join ( data_path , [string] ) [EOL] test_fname = os . path . join ( data_path , [string] ) [EOL] target_fname = os . path . join ( data_path , [string] ) [EOL] [EOL] if os . path . exists ( target_fname ) : [EOL] _logger . info ( [string] , target_fname ) [EOL] return [EOL] [EOL] if not os . path . exists ( data_fname ) or not os . path . exists ( test_fname ) : [EOL] raise RuntimeError ( [string] + source_url ) [EOL] [EOL] _logger . info ( [string] ) [EOL] train_data = ( pd . read_csv ( data_fname , sep = [string] , header = None ) . pipe ( rename ) . assign ( train = [number] ) ) [EOL] test_data = ( pd . read_csv ( test_fname , sep = [string] , header = None ) . pipe ( rename ) . assign ( train = [number] ) ) [EOL] [EOL] df = generate_census_data ( train_data , test_data ) [EOL] [EOL] _logger . info ( [string] , target_fname ) [EOL] df . to_parquet ( target_fname , engine = [string] , compression = [string] ) [EOL] [EOL] [EOL] def generate_census_data ( train_data , test_data ) : [EOL] df = pd . concat ( [ train_data , test_data ] , axis = [number] , ignore_index = True ) [EOL] [EOL] _logger . info ( [string] ) [EOL] for col , typ in columns : [EOL] df = df . assign ( ** { col : df [ col ] . astype ( typ ) } ) [EOL] [EOL] df = df . assign ( target = ( df [ [string] ] . str . strip ( ) == [string] ) . astype ( [string] ) ) [EOL] [EOL] [comment] [EOL] df = pd . concat ( [ df [ df [ [string] ] == [number] ] . sample ( n = [number] * len ( df ) // [number] , replace = True ) , df [ df [ [string] ] == [number] ] . sample ( n = [number] * len ( df ) // [number] , replace = True ) , ] , axis = [number] , ignore_index = True , ) [EOL] [EOL] [comment] [EOL] df = df . sample ( frac = [number] ) [EOL] [EOL] _logger . info ( [string] ) [EOL] est = assemble_census_policy_pipeline ( ) [EOL] est . fit ( df . iloc [ : [number] ] , [string] ) [EOL] [EOL] _logger . info ( [string] ) [EOL] _ , df [ [string] ] = est . predict_proba ( df ) . T [EOL] [EOL] [comment] [EOL] df [ [string] ] = ( df [ [string] ] == [number] ) * df [ [string] ] + ( df [ [string] ] == [number] ) * ( [number] - df [ [string] ] ) [EOL] [EOL] df [ [string] ] = sample_bernoulli ( df [ [string] ] ) [EOL] [EOL] gain = [number] * ( ( df [ [string] ] > [number] ) == ( df [ [string] ] > [number] ) ) [EOL] mean = [number] * ( [number] + gain ) * ( [number] + df [ [string] ] ) [EOL] [EOL] df [ [string] ] = mean [EOL] df [ [string] ] = np . random . normal ( mean ) [EOL] [EOL] df [ [string] ] = [number] * ( df [ [string] ] > [number] ) + [number] * ( df [ [string] ] < [number] ) [EOL] df [ [string] ] = [number] * ( df [ [string] ] > [number] ) + [number] * ( df [ [string] ] < [number] ) [EOL] [EOL] df [ [string] ] = ( [number] - df [ [string] ] ) * df [ [string] ] + df [ [string] ] * df [ [string] ] [EOL] df [ [string] ] = sample_bernoulli ( df [ [string] ] ) [EOL] [EOL] return df [EOL] [EOL] [EOL] def assemble_census_policy_pipeline ( C = [number] ) : [EOL] est = sklearn . pipeline . Pipeline ( [ ( [string] , FuncTransformer ( lambda x : x . drop ( [ [string] , [string] , [string] , [string] , [string] , ] , axis = [number] , ) ) , ) , ( [string] , FilterLowFrequencyTransfomer ( ) ) , ( [string] , OneHotEncoder ( ) ) , ( [string] , sklearn . linear_model . LogisticRegression ( C = C , random_state = [number] ) , ) , ] ) [EOL] return DataFrameEstimator ( est ) [EOL] [EOL] [EOL] def sample_bernoulli ( p ) : [EOL] u = np . random . uniform ( size = np . shape ( p ) ) [EOL] return ( u < p ) . astype ( float ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] logging . basicConfig ( level = logging . INFO ) [EOL] [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] ) [EOL] args = parser . parse_args ( ) [EOL] [EOL] create ( args . data_path ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 $argparse.Namespace$ 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 $argparse.Namespace$ 0 0 0 0
	0
from typing import Any [EOL] import typing [EOL] import argparse [EOL] import logging [EOL] import argparse [EOL] import logging [EOL] import os . path [EOL] [EOL] import numpy as np [EOL] import pandas as pd [EOL] import patsy [EOL] [EOL] _logger = logging . getLogger ( __name__ ) [EOL] _basedir = os . path . abspath ( os . path . dirname ( __file__ ) ) [EOL] [EOL] [EOL] def create ( data_path ) : [EOL] target_fname = os . path . join ( data_path , [string] ) [EOL] if os . path . exists ( target_fname ) : [EOL] _logger . info ( [string] , target_fname ) [EOL] return [EOL] [EOL] _logger . info ( [string] , target_fname ) [EOL] generate_customer_data ( n_samples = [number] ) . to_parquet ( target_fname , engine = [string] , compression = [string] ) [EOL] [EOL] [EOL] def generate_customer_data ( n_samples = [number] , n_occupations = [number] , seed = [number] , p_random = [number] , train_ratio = [number] ) : [EOL] [docstring] [EOL] [EOL] np . random . seed ( seed ) [EOL] age_latent = sigmoid ( np . random . normal ( size = n_samples ) ) [EOL] gender_latent = sigmoid ( np . random . normal ( size = n_samples ) ) [EOL] occupation_latent = sample_categorical ( n_occupations , size = n_samples , alpha = [number] ) [EOL] [EOL] generic_latent = sigmoid ( np . random . normal ( size = n_samples ) ) [EOL] [EOL] salary_latent = spline ( sample_cauchy ( size = ( [number] , n_occupations ) ) + np . random . normal ( loc = [number] , scale = [number] , size = ( [number] , n_occupations ) ) . cumsum ( axis = [number] ) , age_latent , ) + spline ( sample_cauchy ( size = ( [number] , n_occupations ) ) + np . random . normal ( loc = [number] , scale = [number] , size = ( [number] , n_occupations ) ) . cumsum ( axis = [number] ) , gender_latent , ) [EOL] salary_latent = salary_latent [ np . arange ( n_samples ) , occupation_latent ] [EOL] [EOL] dist_city_latent = spline ( np . random . laplace ( loc = + [number] , scale = [number] , size = ( [number] , n_occupations ) ) . cumsum ( axis = [number] ) , age_latent , ) [EOL] dist_city_latent = dist_city_latent [ np . arange ( n_samples ) , occupation_latent ] [EOL] [EOL] count_mean = normalize ( generic_latent ) * np . random . gamma ( [number] , [number] / [number] , size = n_samples ) [EOL] count = np . random . poisson ( count_mean ) [EOL] [EOL] occupation_delta = np . random . laplace ( size = n_occupations , loc = [number] , scale = [number] ) [EOL] [EOL] effect_noise_0 = np . random . normal ( scale = [number] , size = n_samples ) [EOL] effect_noise_1 = np . random . normal ( scale = [number] , size = n_samples ) [EOL] [EOL] generic = spline ( np . random . laplace ( loc = + [number] , scale = [number] , size = [number] ) . cumsum ( axis = [number] ) , generic_latent ) [EOL] [EOL] data = pd . DataFrame ( ) [EOL] [EOL] data [ [string] ] = spline ( [ [number] , [number] , [number] , [number] , [number] , [number] ] , normalize ( age_latent ) + np . random . normal ( scale = [number] , size = n_samples ) , ) [EOL] data [ [string] ] = ( ( gender_latent + np . random . normal ( scale = [number] , size = n_samples ) ) > [number] ) . astype ( float ) [EOL] data [ [string] ] = spline ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , normalize ( salary_latent ) + np . random . normal ( scale = [number] , size = n_samples ) , ) [EOL] data [ [string] ] = sigmoid ( [number] * normalize ( dist_city_latent ) - [number] + np . random . normal ( scale = [number] , size = n_samples ) ) [EOL] data [ [string] ] = random_cat_swaps ( occupation_latent , eps = [number] ) [EOL] [EOL] data [ [string] ] = generic [EOL] data [ [string] ] = count [EOL] [EOL] data [ [string] ] = sigmoid ( - [number] + [number] * ( normalize ( age_latent ) - [number] ) + [number] * ( normalize ( salary_latent ) - [number] ) ) [EOL] [EOL] data [ [string] ] = sigmoid ( [number] + - [number] * occupation_delta [ occupation_latent ] * normalize ( salary_latent ) ** [number] + - [number] * normalize ( age_latent ) ** [number] + + [number] * ( normalize ( gender_latent ) - [number] ) * ( normalize ( generic_latent ) - [number] ) ) [EOL] [EOL] data [ [string] ] = sigmoid ( logit ( data [ [string] ] ) - [number] * logit ( data [ [string] ] ) ) [EOL] data [ [string] ] = sigmoid ( logit ( data [ [string] ] ) + [number] * logit ( data [ [string] ] ) ) [EOL] [EOL] data [ [string] ] = sigmoid ( logit ( data [ [string] ] ) - [number] * effect_noise_0 * occupation_delta [ occupation_latent ] ) [EOL] data [ [string] ] = sigmoid ( logit ( data [ [string] ] ) + [number] * effect_noise_1 * occupation_delta [ occupation_latent ] ) [EOL] [EOL] cutoff = logit ( p_random ) [EOL] [EOL] data [ [string] ] = ( data [ [string] ] - [number] ) / [number] [EOL] data [ [string] ] = sigmoid ( np . clip ( data [ [string] ] , - cutoff , + cutoff ) ) [EOL] data [ [string] ] = sample_bernoulli ( data [ [string] ] ) [EOL] [EOL] data [ [string] ] = ( data [ [string] ] == [number] ) * data [ [string] ] + ( data [ [string] ] == [number] ) * data [ [string] ] [EOL] [EOL] data [ [string] ] = sample_bernoulli ( data [ [string] ] ) [EOL] [EOL] data [ [string] ] = [number] [EOL] data . iloc [ int ( train_ratio * len ( data ) ) : , data . columns . get_loc ( [string] ) ] = [number] [EOL] [EOL] return data [EOL] [EOL] [EOL] def reject ( proposal , accept , max_iter = [number] ) : [EOL] res = [ ] [EOL] [EOL] for _ in range ( max_iter ) : [EOL] cand = proposal ( ) [EOL] n_target = cand . shape [ [number] ] [EOL] [EOL] sel = accept ( cand ) [EOL] cand = cand [ sel ] [EOL] [EOL] res = np . concatenate ( [ res , cand ] ) [EOL] n_current = res . shape [ [number] ] [EOL] [EOL] if n_current >= n_target : [EOL] return res [ : n_target ] [EOL] [EOL] raise ValueError ( ) [EOL] [EOL] [EOL] def sample_bernoulli ( p ) : [EOL] u = np . random . uniform ( size = np . shape ( p ) ) [EOL] return ( u < p ) . astype ( float ) [EOL] [EOL] [EOL] def sigmoid ( x ) : [EOL] x = np . clip ( x , - [number] , + [number] ) [EOL] return [number] / ( [number] + np . exp ( - x ) ) [EOL] [EOL] [EOL] def logit ( x ) : [EOL] x = np . clip ( x , [number] , [number] - [number] ) [EOL] return np . log ( x / ( [number] - x ) ) [EOL] [EOL] [EOL] def sample_categorical ( n_categories , size , alpha = [number] ) : [EOL] p = np . random . dirichlet ( [ alpha ] * n_categories ) [EOL] return np . random . choice ( np . arange ( n_categories ) , size = size , p = p ) [EOL] [EOL] [EOL] def spline ( w , x ) : [EOL] w = np . asarray ( w ) [EOL] x = np . asarray ( x ) [EOL] splines = patsy . bs ( x , df = w . shape [ [number] ] , lower_bound = np . min ( x ) , upper_bound = np . max ( x ) , include_intercept = True , ) [EOL] return np . dot ( splines , w ) [EOL] [EOL] [EOL] def sample_cauchy ( loc = [number] , scale = [number] , size = [number] ) : [EOL] u = np . random . uniform ( size = size ) [EOL] return loc + scale * np . tan ( np . pi * ( u + [number] ) ) [EOL] [EOL] [EOL] def normalize ( x ) : [EOL] return ( x - np . min ( x ) ) / np . ptp ( x ) [EOL] [EOL] [EOL] def random_cat_swaps ( x , eps = [number] ) : [EOL] n_categories = np . max ( x ) + [number] [EOL] [EOL] u = np . random . uniform ( size = np . size ( x ) ) [EOL] sel = u < eps [EOL] [EOL] x = x . copy ( ) [EOL] x [ sel ] = np . random . randint ( [number] , n_categories , size = sel . sum ( ) ) [EOL] return x [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] logging . basicConfig ( level = logging . INFO ) [EOL] [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] ) [EOL] args = parser . parse_args ( ) [EOL] [EOL] create ( args . data_path ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 $argparse.Namespace$ 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 $argparse.Namespace$ 0 0 0 0
from typing import List , Dict , Any [EOL] import typing [EOL] import logging [EOL] import inspect [EOL] import inspect [EOL] import logging [EOL] [EOL] import matplotlib . pyplot as plt [EOL] import numpy as np [EOL] [EOL] [EOL] _logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def evaluate ( est , df , reward_column = [string] , action_column = [string] , value_columns = None , propensity_column = None , label = None , ) : [EOL] action_values = [ int ( v ) for v in np . unique ( df [ action_column ] ) ] [EOL] [EOL] _logger . info ( [string] , label ) [EOL] action , value = est . predict ( df ) [EOL] [EOL] _logger . info ( [string] , label ) [EOL] return _compute_metrics ( { [string] : len ( df ) , [string] : label , [string] : action , [string] : value , [string] : action_values , [string] : sum ( ( df [ action_column ] == action_value ) * action [ : , action_value ] for action_value in action_values ) , [string] : np . asarray ( df [ action_column ] , dtype = np . int ) [EOL] if action_column is not None [EOL] else None , [string] : df [ reward_column ] if reward_column is not None else None , [string] : np . vstack ( [ df [ col ] for col in value_columns ] ) . T [EOL] if value_columns is not None [EOL] else None , [string] : df [ propensity_column ] [EOL] if propensity_column is not None [EOL] else None , } ) [EOL] [EOL] [EOL] def _compute_metrics ( keywords ) : [EOL] [comment] [EOL] metrics = { [string] : keywords [ [string] ] } [EOL] [EOL] if keywords [ [string] ] is not None : [EOL] metrics [ [string] ] = keywords [ [string] ] [EOL] [EOL] [comment] [EOL] for func in [ compute_direct_method_reward , compute_mean_observed_reward , compute_value_mad , compute_value_plots , compute_true_reward , compute_ips_rewards , compute_doubly_robust_reward , ] : [EOL] spec = inspect . getfullargspec ( func ) [EOL] kw = { k : keywords [ k ] for k in spec . args } [EOL] [EOL] if any ( v is None for v in kw . values ( ) ) : [EOL] continue [EOL] [EOL] metrics . update ( func ( ** kw ) ) [EOL] [EOL] for metric in [ [string] , [string] , [string] , [string] ] : [EOL] if metric in metrics : [EOL] metrics [ [string] ] = metrics [ metric ] [EOL] break [EOL] [EOL] return metrics [EOL] [EOL] [EOL] def compute_mean_observed_reward ( reward ) : [EOL] return { [string] : np . mean ( reward ) } [EOL] [EOL] [EOL] def compute_direct_method_reward ( policy_p , reward ) : [EOL] [comment] [EOL] return { [string] : np . sum ( policy_p * reward ) / policy_p . sum ( ) } [EOL] [EOL] [EOL] def compute_value_mad ( value , true_value ) : [EOL] assert value . shape == true_value . shape [EOL] [EOL] return { f" [string] { i }" : np . mean ( np . abs ( value [ : , i ] - true_value [ : , i ] ) ) for i in range ( value . shape [ [number] ] ) } [EOL] [EOL] [EOL] def compute_value_plots ( value ) : [EOL] vmin = min ( np . min ( value [ : , [number] ] ) , np . min ( value [ : , [number] ] ) ) [EOL] vmax = max ( np . max ( value [ : , [number] ] ) , np . max ( value [ : , [number] ] ) ) [EOL] [EOL] return { [string] : canned_hist2d ( value [ : , [number] ] , value [ : , [number] ] , range = ( ( vmin , vmax ) , ( vmin , vmax ) ) , bins = ( [number] , [number] ) ) } [EOL] [EOL] [EOL] def compute_true_reward ( action , true_value ) : [EOL] true_reward = np . mean ( np . sum ( action * true_value , axis = [number] ) ) [EOL] optimal_reward = np . mean ( np . max ( true_value , axis = [number] ) ) [EOL] [EOL] return { [string] : true_reward , [string] : optimal_reward , [string] : true_reward - optimal_reward , } [EOL] [EOL] [EOL] def compute_ips_rewards ( reward , policy_p , propensity ) : [EOL] weight = policy_p / propensity [EOL] [EOL] return { [string] : np . mean ( weight * reward ) , [string] : np . mean ( weight * reward ) / np . mean ( weight ) , } [EOL] [EOL] [EOL] def compute_doubly_robust_reward ( action , reward , propensity , observed_action , value , action_values , policy_p ) : [EOL] observed_value_estimate = value [ np . arange ( value . shape [ [number] ] ) , observed_action ] [EOL] [EOL] return { [string] : ( np . mean ( ( reward - observed_value_estimate ) * policy_p / propensity ) + sum ( np . mean ( value [ : , action_value ] * action [ : , action_value ] ) for action_value in action_values ) ) } [EOL] [EOL] [EOL] def canned_hist2d ( x , y , ** kwargs ) : [EOL] data , edges_x , edges_y = np . histogram2d ( x , y , ** kwargs ) [EOL] return CannedHist2dPlot ( edges_x , edges_y , data ) [EOL] [EOL] [EOL] class CannedHist2dPlot : [EOL] def __init__ ( self , edges_x , edges_y , data ) : [EOL] self . edges_x = edges_x [EOL] self . edges_y = edges_y [EOL] self . data = data [EOL] [EOL] def plot ( self , ** kwargs ) : [EOL] plt . pcolor ( self . edges_x , self . edges_y , self . data . T , ** kwargs ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import List [EOL] import typing [EOL] from . evaluation import evaluate [EOL] from . util import action_p_to_propensity , RegressingBinaryClassifier [EOL] from . models import ( build_standard_sklearn_classifier , BinaryOutcomeRegressionPolicy , DirectClassifierPolicy , DoublyRobustClassifierPolicy , ) [EOL] [EOL] [EOL] __all__ = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] import numpy as np [EOL] import pandas as pd [EOL] import sklearn . base [EOL] [EOL] from chmp . ds import find_categorical_columns [EOL] [EOL] [EOL] def action_p_to_propensity ( action , action_p ) : [EOL] return action * action_p + ( [number] - action ) * ( [number] - action_p ) [EOL] [EOL] [EOL] class RegressingBinaryClassifier ( sklearn . base . BaseEstimator , sklearn . base . RegressorMixin ) : [EOL] def __init__ ( self , est ) : [EOL] self . est = est [EOL] [EOL] def fit ( self , x , y ) : [EOL] self . est . fit ( x , y ) [EOL] return self [EOL] [EOL] def predict ( self , x ) : [EOL] _ , score = self . est . predict_proba ( x ) . T [EOL] return score [EOL] [EOL] [EOL] class CategoricalMeanTargetEncoder ( sklearn . base . BaseEstimator , sklearn . base . TransformerMixin ) : [EOL] def __init__ ( self , columns = None , pseudo_count = [number] ) : [EOL] self . columns = columns [EOL] self . pseudo_count = pseudo_count [EOL] self . columns_ = columns [EOL] self . rates_ = { } [EOL] self . population_mean_ = None [EOL] [EOL] def fit ( self , x , y ) : [EOL] if self . columns_ is None : [EOL] self . columns_ = find_categorical_columns ( x ) [EOL] [EOL] self . population_mean_ = np . nanmean ( y ) [EOL] [EOL] for col in self . columns_ : [EOL] agg = pd . Series ( y , index = x . index ) . groupby ( x [ col ] ) . agg ( [ [string] , [string] ] ) [EOL] mean = ( agg [ [string] ] + self . population_mean_ * self . pseudo_count ) / ( agg [ [string] ] + self . pseudo_count ) [EOL] self . rates_ [ col ] = mean [EOL] [EOL] return self [EOL] [EOL] def transform ( self , x , y = None ) : [EOL] for col in self . columns_ : [EOL] try : [EOL] mean = self . rates_ [ col ] [EOL] s = x [ col ] . replace ( mean ) [EOL] s [ ~ x [ col ] . isin ( mean . index ) ] = np . nan [EOL] s = s . astype ( float ) [EOL] [EOL] x = x . assign ( ** { col : s } ) [EOL] [EOL] except Exception as e : [EOL] raise RuntimeError ( f" [string] { col }" ) from e [EOL] [EOL] return x [EOL] [EOL] [EOL] class CategoricalIndexEncoder ( sklearn . base . BaseEstimator , sklearn . base . TransformerMixin ) : [EOL] def __init__ ( self , columns = None , pseudo_count = [number] ) : [EOL] self . columns = columns [EOL] self . pseudo_count = pseudo_count [EOL] self . columns_ = columns [EOL] self . replacements_ = { } [EOL] self . population_mean_ = None [EOL] [EOL] def fit ( self , x , y ) : [EOL] if self . columns_ is None : [EOL] self . columns_ = find_categorical_columns ( x ) [EOL] [EOL] self . population_mean_ = np . nanmean ( y ) [EOL] [EOL] for col in self . columns_ : [EOL] agg = pd . Series ( y , index = x . index ) . groupby ( x [ col ] ) . agg ( [ [string] , [string] ] ) [EOL] mean = ( agg [ [string] ] + self . population_mean_ * self . pseudo_count ) / ( agg [ [string] ] + self . pseudo_count ) [EOL] self . replacements_ [ col ] = pd . Series ( np . argsort ( mean . values ) , index = mean . index ) [EOL] [EOL] return self [EOL] [EOL] def transform ( self , x , y = None ) : [EOL] for col in self . columns_ : [EOL] try : [EOL] repl = self . replacements_ [ col ] [EOL] s = x [ col ] . replace ( repl ) [EOL] s [ ~ x [ col ] . isin ( repl . index ) ] = np . nan [EOL] s = s . astype ( int ) [EOL] [EOL] x = x . assign ( ** { col : s } ) [EOL] [EOL] except Exception as e : [EOL] raise RuntimeError ( f" [string] { col }" ) from e [EOL] [EOL] return x [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0
from typing import Any [EOL] import typing [EOL] [docstring] [EOL] import numpy as np [EOL] import pandas as pd [EOL] import sklearn . pipeline [EOL] import sklearn . ensemble [EOL] [EOL] from chmp . ds import ( FuncTransformer , FilterLowFrequencyTransfomer , find_categorical_columns , Loop , ) [EOL] [EOL] from . util import CategoricalMeanTargetEncoder , CategoricalIndexEncoder [EOL] [EOL] [EOL] def build_standard_sklearn_classifier ( features ) : [EOL] return sklearn . pipeline . Pipeline ( [ ( [string] , FuncTransformer ( lambda df : df [ list ( features ) ] ) ) , ( [string] , FilterLowFrequencyTransfomer ( ) ) , ( [string] , CategoricalMeanTargetEncoder ( ) ) , ( [string] , sklearn . ensemble . GradientBoostingClassifier ( n_estimators = [number] , subsample = [number] , max_depth = [number] ) , ) , ] ) [EOL] [EOL] [EOL] def get_weight_keyword ( est ) : [EOL] if isinstance ( est , sklearn . pipeline . Pipeline ) : [EOL] key , _ = est . steps [ - [number] ] [EOL] return f"{ key } [string] " [EOL] [EOL] return [string] [EOL] [EOL] [EOL] def binary_offset_tree_transform ( reward , action , action_propensity = None ) : [EOL] [comment] [EOL] [comment] [EOL] reward = ( reward - np . min ( reward ) ) / np . ptp ( reward ) [EOL] [EOL] fit_weight = np . abs ( reward - [number] ) [EOL] if action_propensity is not None : [EOL] fit_weight = fit_weight / action_propensity [EOL] [EOL] fit_target = ( reward >= [number] ) * action + ( reward < [number] ) * ( [number] - action ) [EOL] [EOL] return fit_weight , fit_target [EOL] [EOL] [EOL] class RegressionPolicy : [EOL] def predict_value ( self , df ) : [EOL] raise NotImplementedError ( ) [EOL] [EOL] def predict_action ( self , df ) : [EOL] action , _ = self . predict ( df ) [EOL] return action [EOL] [EOL] def predict ( self , df ) : [EOL] [comment] [EOL] value = self . predict_value ( df ) [EOL] action = np . concatenate ( [ np . asarray ( value [ : , None , [number] ] < value [ : , None , [number] ] , dtype = np . int ) , np . asarray ( value [ : , None , [number] ] >= value [ : , None , [number] ] , dtype = np . int ) , ] , axis = - [number] , ) [EOL] [EOL] return action , value [EOL] [EOL] [EOL] [comment] [EOL] class BinaryOutcomeRegressionPolicy ( RegressionPolicy ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , est , action_column = [string] , target_column = [string] ) : [EOL] self . est = est [EOL] self . action_column = action_column [EOL] self . target_column = target_column [EOL] [EOL] def fit ( self , df ) : [EOL] df = df . reset_index ( drop = True ) [EOL] self . est . fit ( df , np . asarray ( df [ self . target_column ] ) ) [EOL] return self [EOL] [EOL] def predict_value ( self , df ) : [EOL] _ , value_0 = self . est . predict_proba ( df . assign ( ** { self . action_column : [number] } ) ) . T [EOL] _ , value_1 = self . est . predict_proba ( df . assign ( ** { self . action_column : [number] } ) ) . T [EOL] return np . concatenate ( [ value_0 [ ... , None ] , value_1 [ ... , None ] ] , axis = - [number] ) [EOL] [EOL] [EOL] class DirectClassifierPolicy : [EOL] def __init__ ( self , est , action_column = [string] , reward_column = [string] , propensity_column = None , sample_weight_keyword = None , clipping_value = [number] , ) : [EOL] if sample_weight_keyword is None : [EOL] sample_weight_keyword = get_weight_keyword ( est ) [EOL] [EOL] [comment] [EOL] if propensity_column is None : [EOL] raise RuntimeError ( [string] ) [EOL] [EOL] self . est = est [EOL] self . action_column = action_column [EOL] self . reward_column = reward_column [EOL] self . propensity_column = propensity_column [EOL] self . sample_weight_keyword = sample_weight_keyword [EOL] self . clipping_value = clipping_value [EOL] [EOL] def fit ( self , df ) : [EOL] df = df . reset_index ( drop = True ) [EOL] [EOL] reward = np . asarray ( df [ self . reward_column ] ) [EOL] action = df [ self . action_column ] [EOL] [EOL] [comment] [EOL] propensity = df [ self . propensity_column ] [EOL] propensity = np . maximum ( self . clipping_value , propensity ) [EOL] [EOL] [comment] [EOL] fit_weight , fit_target = binary_offset_tree_transform ( reward = reward , action = action , action_propensity = propensity ) [EOL] self . est . fit ( df , fit_target , ** { self . sample_weight_keyword : fit_weight } ) [EOL] [EOL] return self [EOL] [EOL] def predict ( self , df ) : [EOL] return self . est . predict_proba ( df ) , None [EOL] [EOL] [EOL] class DoublyRobustClassifierPolicy : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , value_est , action_est , action_values , action_column = [string] , reward_column = [string] , propensity_column = None , sample_weight_keyword = None , clipping_value = [number] , ) : [EOL] if sample_weight_keyword is None : [EOL] sample_weight_keyword = get_weight_keyword ( action_est ) [EOL] [EOL] [comment] [EOL] if propensity_column is None : [EOL] raise RuntimeError ( [string] ) [EOL] [EOL] self . value_est = value_est [EOL] self . action_est = action_est [EOL] self . action_values = action_values [EOL] [EOL] self . action_column = action_column [EOL] self . reward_column = reward_column [EOL] self . propensity_column = propensity_column [EOL] self . sample_weight_keyword = sample_weight_keyword [EOL] self . clipping_value = clipping_value [EOL] [EOL] def fit ( self , df ) : [EOL] df = df . reset_index ( drop = True ) [EOL] [EOL] reward = np . asarray ( df [ self . reward_column ] ) [EOL] observed_action = df [ self . action_column ] [EOL] [EOL] [comment] [EOL] propensity = df [ self . propensity_column ] [EOL] propensity = np . maximum ( self . clipping_value , propensity ) [EOL] [EOL] [comment] [EOL] self . value_est . fit ( df , reward ) [EOL] [EOL] full_df = [ ] [EOL] full_reward = [ ] [EOL] [EOL] for action in self . action_values : [EOL] df_with_action = df . assign ( ** { self . action_column : action } ) [EOL] reward_estimate = self . value_est . predict ( df_with_action ) [EOL] [EOL] full_reward . append ( ( reward - reward_estimate ) / propensity * ( action == observed_action ) + reward_estimate ) [EOL] full_df . append ( df_with_action ) [EOL] [EOL] full_reward = np . concatenate ( full_reward , axis = [number] ) [EOL] full_df = pd . concat ( full_df , axis = [number] , ignore_index = True ) [EOL] [EOL] [comment] [EOL] fit_weight , fit_target = binary_offset_tree_transform ( reward = full_reward , action = np . asarray ( full_df [ [string] ] ) ) [EOL] self . action_est . fit ( full_df , fit_target , ** { self . sample_weight_keyword : fit_weight } ) [EOL] [EOL] return self [EOL] [EOL] def predict ( self , df ) : [EOL] values = [ self . value_est . predict ( df . assign ( ** { self . action_column : action } ) ) for action in self . action_values ] [EOL] values = np . stack ( values ) . T [EOL] [EOL] return self . action_est . predict_proba ( df ) , values [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from setuptools import setup , PEP420PackageFinder [EOL] [EOL] [EOL] setup ( name = [string] , description = [string] , author = [string] , long_description = open ( [string] ) . read ( ) , long_description_content_type = [string] , packages = PEP420PackageFinder . find ( [string] ) , package_dir = { [string] : [string] } , tests_require = [ [string] ] , use_scm_version = { [string] : [string] , [string] : __file__ } , url = [string] , setup_requires = [ [string] ] , data_files = [ ( [string] , [ [string] , [string] ] , ) , ( [string] , [ [string] ] ) , ] , classifiers = [ [string] , [string] , [string] , ] , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] import pytest [EOL] [EOL] from chmp . label import BaseAnnotator [EOL] [EOL] [EOL] def test_base_annotator__example_session ( ) : [EOL] annotator = BaseAnnotator ( ) [EOL] assert annotator . current_item is None [EOL] [EOL] annotator . annotate ( [ [string] , [string] , [string] ] ) [EOL] assert annotator . current_item == ( [string] , [number] , [string] ) [EOL] [EOL] annotator . annotate_current ( [string] ) [EOL] assert len ( annotator . annotations ) == [number] [EOL] assert annotator . annotations [ - [number] ] == { [string] : [string] , [string] : [number] , [string] : [string] , [string] : [string] , } [EOL] assert annotator . current_item == ( [string] , [number] , [string] ) [EOL] [EOL] annotator . repeat ( [number] ) [EOL] assert len ( annotator . annotations ) == [number] [EOL] assert annotator . annotations [ - [number] ] == { [string] : [string] , [string] : [number] , [string] : [string] , [string] : [string] , } [EOL] assert annotator . current_item == ( [string] , [number] , [string] ) [EOL] [EOL] annotator . annotate_current ( [string] ) [EOL] assert len ( annotator . annotations ) == [number] [EOL] assert annotator . annotations [ - [number] ] == { [string] : [string] , [string] : [number] , [string] : [string] , [string] : [string] , } [EOL] assert annotator . current_item == ( [string] , [number] , [string] ) [EOL] [EOL] annotator . annotate_current ( [string] ) [EOL] assert len ( annotator . annotations ) == [number] [EOL] assert annotator . annotations [ - [number] ] == { [string] : [string] , [string] : [number] , [string] : [string] , [string] : [string] , } [EOL] assert annotator . current_item == ( [string] , [number] , [string] ) [EOL] [EOL] annotator . annotate_current ( [string] ) [EOL] assert len ( annotator . annotations ) == [number] [EOL] assert annotator . annotations [ - [number] ] == { [string] : [string] , [string] : [number] , [string] : [string] , [string] : [string] , } [EOL] assert annotator . current_item is None [EOL] [EOL] annotator . repeat ( [number] ) [EOL] assert len ( annotator . annotations ) == [number] [EOL] assert annotator . annotations [ - [number] ] == { [string] : [string] , [string] : [number] , [string] : [string] , [string] : [string] , } [EOL] assert annotator . current_item == ( [string] , [number] , [string] ) [EOL] [EOL] annotator . annotate_current ( [string] ) [EOL] assert len ( annotator . annotations ) == [number] [EOL] assert annotator . annotations [ - [number] ] == { [string] : [string] , [string] : [number] , [string] : [string] , [string] : [string] , } [EOL] assert annotator . current_item is None [EOL] [EOL] assert annotator . get_latest ( ) == [ { [string] : [string] , [string] : [number] , [string] : [string] , [string] : [string] } , { [string] : [string] , [string] : [number] , [string] : [string] , [string] : [string] } , { [string] : [string] , [string] : [number] , [string] : [string] , [string] : [string] } , ] [EOL] [EOL] [EOL] def test_base_annotator__clear ( ) : [EOL] annotator = BaseAnnotator ( ) [EOL] annotator . annotate ( [ [string] , [string] , [string] ] ) [EOL] [EOL] with pytest . raises ( RuntimeError ) : [EOL] annotator . annotate ( [ [string] , [string] , [string] ] ) [EOL] [EOL] annotator . clear ( ) [EOL] annotator . annotate ( [ [string] , [string] , [string] ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Literal , Dict , Any , Set , List , Type , Tuple [EOL] import typing [EOL] import typing_extensions [EOL] import chmp [EOL] import logging [EOL] [docstring] [EOL] import base64 [EOL] import collections . abc [EOL] import datetime [EOL] import glob [EOL] import html [EOL] import json [EOL] import logging [EOL] import os . path [EOL] [EOL] from ipywidgets import DOMWidget , Button , Text , HBox , VBox , jslink , register [EOL] from IPython . display import display_javascript , Javascript [EOL] from traitlets import Unicode , Float [EOL] [EOL] _logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def annotate ( items , * , classes , history_length = [number] , display_value = None , cls = None , kwargs = None ) : [EOL] [docstring] [EOL] from IPython . core . display import display [EOL] [EOL] kwargs = { } if kwargs is None else dict ( kwargs ) [EOL] [EOL] kwargs . update ( history_length = history_length ) [EOL] if display_value is not None : [EOL] kwargs . update ( display_value = display_value ) [EOL] [EOL] if cls == [string] : [EOL] annotator = AudioAnnotator ( classes , ** kwargs ) [EOL] [EOL] elif cls == [string] : [EOL] annotator = ImageAnnotator ( classes , ** kwargs ) [EOL] [EOL] elif cls is not None : [EOL] annotator = cls ( classes , ** kwargs ) [EOL] [EOL] elif display_value is not None : [EOL] annotator = FunctionalAnnotator ( classes , ** kwargs ) [EOL] [EOL] else : [EOL] annotator = FunctionalAnnotator ( classes , lambda item : [string] . format ( html . escape ( repr ( item ) ) ) ) [EOL] [EOL] annotator . annotate ( items ) [EOL] display ( annotator ) [EOL] [EOL] return annotator . annotations [EOL] [EOL] [EOL] def listdata ( pattern , valid_lables = None ) : [EOL] fnames = glob . glob ( pattern ) [EOL] result = [ ] [EOL] [EOL] for fname in fnames : [EOL] if has_label ( fname ) : [EOL] d = dict ( get_label ( fname ) , file = os . path . abspath ( fname ) ) [EOL] [EOL] else : [EOL] d = dict ( label = [string] , file = os . path . abspath ( fname ) ) [EOL] [EOL] if valid_lables is None or d [ [string] ] in valid_lables : [EOL] result . append ( d ) [EOL] [EOL] return result [EOL] [EOL] [EOL] def get_label ( fname ) : [EOL] fname = get_label_fname ( fname ) [EOL] with open ( fname , [string] ) as fobj : [EOL] return json . load ( fobj ) [EOL] [EOL] [EOL] def find_labeled ( pattern , recursive = False ) : [EOL] return _find_predicate ( pattern , recursive , lambda fname : has_label ( fname ) ) [EOL] [EOL] [EOL] def find_unlabeled ( pattern , recursive = False ) : [EOL] return _find_predicate ( pattern , recursive , lambda fname : not has_label ( fname ) ) [EOL] [EOL] [EOL] def _find_predicate ( pattern , recursive , predicate ) : [EOL] return [ fname for fname in glob . iglob ( pattern , recursive = recursive ) if predicate ( fname ) ] [EOL] [EOL] [EOL] def has_label ( fname ) : [EOL] return os . path . exists ( get_label_fname ( fname ) ) [EOL] [EOL] [EOL] def write_label ( * args , keep_existing = True , ** kwargs ) : [EOL] if len ( args ) == [number] : [EOL] fname , = args [EOL] d = { } [EOL] [EOL] elif len ( args ) == [number] : [EOL] fname , d = args [EOL] d = dict ( d ) [EOL] [EOL] else : [EOL] raise ValueError ( [string] . format ( len ( args ) ) ) [EOL] [EOL] d . update ( kwargs ) [EOL] label_fname = get_label_fname ( fname ) [EOL] [EOL] if keep_existing : [EOL] if os . path . exists ( label_fname ) : [EOL] _logger . info ( [string] , label_fname ) [EOL] with open ( label_fname , [string] ) as fobj : [EOL] old_label = json . load ( fobj ) [EOL] [EOL] d [ [string] ] = old_label [EOL] [EOL] if [string] not in d : [EOL] d [ [string] ] = datetime . datetime . now ( ) . strftime ( [string] ) [EOL] [EOL] _logger . info ( [string] , label_fname ) [EOL] with open ( label_fname , [string] ) as fobj : [EOL] json . dump ( d , fobj , indent = [number] , sort_keys = True ) [EOL] [EOL] [EOL] def get_label_fname ( fname ) : [EOL] label_fname , _ = os . path . splitext ( fname ) [EOL] label_fname = label_fname + [string] [EOL] [EOL] return label_fname [EOL] [EOL] [EOL] def write_latest_labels ( annotator , skip_class = [string] , label_key = [string] , fname_key = [string] ) : [EOL] [docstring] [EOL] [EOL] def unpack ( * dict_and_keys ) : [EOL] d , * keys = dict_and_keys [EOL] return tuple ( d [ k ] for k in keys ) [EOL] [EOL] for item in annotator . get_latest ( ) : [EOL] fname = item [ fname_key ] [EOL] label = item [ label_key ] [EOL] [EOL] if label == skip_class : [EOL] continue [EOL] [EOL] kwargs = dict ( item , fname = os . path . basename ( fname ) , label = label ) [EOL] write_label ( fname , ** kwargs ) [EOL] [EOL] [EOL] class BaseAnnotator : [EOL] [docstring] [EOL] [EOL] def __init__ ( self ) : [EOL] self . data = None [EOL] self . annotations = None [EOL] self . current_item = None [EOL] [EOL] def get_latest ( self ) : [EOL] if self . annotations is None : [EOL] return [ ] [EOL] [EOL] return self . annotations . get_latest ( ) [EOL] [EOL] def update_display ( self ) : [EOL] [docstring] [EOL] pass [EOL] [EOL] def clear ( self ) : [EOL] self . annotations = None [EOL] self . data = None [EOL] self . current_item = None [EOL] [EOL] def annotate ( self , data ) : [EOL] if self . annotations is not None : [EOL] raise RuntimeError ( [string] ) [EOL] [EOL] self . annotations = Annotations ( ) [EOL] self . data = [ ( [string] , idx , item ) for idx , item in enumerate ( data ) ] [EOL] self . next ( ) [EOL] [EOL] def next ( self , item = None ) : [EOL] if item is not None : [EOL] self . current_item = item [EOL] [EOL] elif self . data : [EOL] self . current_item = self . data . pop ( [number] ) [EOL] [EOL] else : [EOL] self . current_item = None [EOL] self . update_display ( ) [EOL] return [EOL] [EOL] self . update_display ( ) [EOL] [EOL] def annotate_current ( self , label ) : [EOL] if self . annotations is None or self . current_item is None : [EOL] return [EOL] [EOL] reason , index , item = self . current_item [EOL] self . annotations . append ( dict ( index = index , reason = reason , item = item , label = label ) ) [EOL] self . next ( ) [EOL] [EOL] def repeat ( self , idx ) : [EOL] if idx < [number] or idx >= len ( self . annotations ) : [EOL] return [EOL] [EOL] if self . current_item is not None : [EOL] self . data . insert ( [number] , self . current_item ) [EOL] [EOL] index , item = self . annotations [ idx ] [ [string] ] , self . annotations [ idx ] [ [string] ] [EOL] item = [string] , index , item [EOL] [EOL] self . next ( item ) [EOL] [EOL] [EOL] class Annotator ( BaseAnnotator ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , classes , history_length = [number] ) : [EOL] super ( ) . __init__ ( ) [EOL] self . history_length = int ( history_length ) [EOL] self . last_repeat = [number] [EOL] self . _build ( classes ) [EOL] [EOL] def build_display_value ( self , item ) : [EOL] [docstring] [EOL] return html . escape ( repr ( item ) ) [EOL] [EOL] def clear ( self ) : [EOL] super ( ) . clear ( ) [EOL] self . last_repeat = [number] [EOL] [EOL] def update_display ( self ) : [EOL] if self . current_item is None : [EOL] self . _html . value = [string] [EOL] self . _info . value = [string] [EOL] [EOL] else : [EOL] reason , index , item = self . current_item [EOL] self . _html . value = self . build_display_value ( item ) [EOL] self . _info . value = html . escape ( [string] . format ( index , reason ) ) [EOL] [EOL] if len ( self . annotations ) > self . last_repeat : [EOL] from ipywidgets import Button , Layout [EOL] [EOL] repeats = list ( self . _history . children ) [EOL] [EOL] for idx in range ( self . last_repeat , len ( self . annotations ) ) : [EOL] annotation = self . annotations [ idx ] [EOL] [EOL] repeat_button = Button ( description = f'{ annotation [ [string] ] } [string] { annotation [ [string] ] !r}' , layout = Layout ( width = [string] ) , ) [EOL] repeat_button . on_click ( lambda b : self . repeat ( idx ) ) [EOL] [EOL] repeats = [ repeat_button ] + repeats [EOL] [EOL] self . last_repeat = len ( self . annotations ) [EOL] [EOL] repeats = repeats [ : self . history_length ] [EOL] self . _history . children = repeats [EOL] [EOL] def _build ( self , classes ) : [EOL] from ipywidgets import HTML , VBox , Layout , Box [EOL] [EOL] self . _html = HTML ( value = [string] ) [EOL] self . _info = HTML ( value = [string] ) [EOL] self . _history = VBox ( layout = Layout ( margin = [string] ) ) [EOL] [EOL] self . _widget = VBox ( [ self . _html , self . _info , Box ( [ self . _build_label_button ( label ) for label in classes ] , layout = Layout ( flex_flow = [string] ) , ) , self . _history , ] ) [EOL] [EOL] def _build_label_button ( self , label ) : [EOL] from ipywidgets import Button [EOL] [EOL] if not isinstance ( label , collections . abc . Mapping ) : [EOL] label = { [string] : label , [string] : [string] } [EOL] [EOL] else : [EOL] label = dict ( label ) [EOL] label . setdefault ( [string] , [string] ) [EOL] [EOL] b = Button ( description = label [ [string] ] , button_style = label [ [string] ] ) [EOL] b . on_click ( lambda b : self . annotate_current ( label [ [string] ] ) ) [EOL] return b [EOL] [EOL] def _ipython_display_ ( self , ** kwargs ) : [EOL] return self . _widget . _ipython_display_ ( ** kwargs ) [EOL] [EOL] [EOL] class ImageAnnotator ( Annotator ) : [EOL] [docstring] [EOL] [EOL] def build_display_value ( self , item ) : [EOL] return [string] . format ( url = build_data_url ( item ) ) [EOL] [EOL] [EOL] class AudioAnnotator ( Annotator ) : [EOL] [docstring] [EOL] [EOL] def build_display_value ( self , item ) : [EOL] return [string] . format ( url = build_data_url ( item ) ) [EOL] [EOL] [EOL] class FunctionalAnnotator ( Annotator ) : [EOL] def __init__ ( self , classes , display_value , * , history_length = [number] , kwargs = None ) : [EOL] if kwargs is None : [EOL] kwargs = { } [EOL] [EOL] super ( ) . __init__ ( classes = classes , history_length = history_length ) [EOL] self . display_value = display_value [EOL] self . kwargs = kwargs [EOL] [EOL] def build_display_value ( self , item ) : [EOL] return self . display_value ( item , ** self . kwargs ) [EOL] [EOL] [EOL] class Annotations ( list ) : [EOL] def get_latest ( self ) : [EOL] result = [ ] [EOL] added = set ( ) [EOL] [EOL] for item in reversed ( self ) : [EOL] if item [ [string] ] in added : [EOL] continue [EOL] [EOL] added . add ( item [ [string] ] ) [EOL] result . append ( item ) [EOL] [EOL] return result [EOL] [EOL] [EOL] def build_data_url ( fname , mime_type = None ) : [EOL] [docstring] [EOL] _ , ext = os . path . splitext ( fname ) [EOL] ext = ext . lower ( ) [EOL] [EOL] if mime_type is None : [EOL] try : [EOL] mime_type = _mime_types [ ext ] [EOL] [EOL] except AttributeError : [EOL] raise ValueError ( [string] . format ( ext ) ) [EOL] [EOL] with open ( fname , [string] ) as fobj : [EOL] data = fobj . read ( ) [EOL] [EOL] data = base64 . b64encode ( data ) [EOL] data = data . decode ( [string] ) [EOL] [EOL] return [string] . format ( mime_type = mime_type , data = data ) [EOL] [EOL] [EOL] _mime_types = { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , } [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] def annotate_bounding_boxes ( images ) : [EOL] annotations = [ ] [EOL] position = [number] [EOL] [EOL] bounding_boxer = BoundingBoxer ( ) [EOL] annotation_display = AnnotationDisplay ( ) [EOL] label = Text ( placeholder = [string] ) [EOL] prev_button = Button ( description = [string] ) [EOL] next_button = Button ( description = [string] ) [EOL] [EOL] widget = VBox ( [ HBox ( [ label , prev_button , next_button ] ) , bounding_boxer , annotation_display ] ) [EOL] [EOL] def show ( ) : [EOL] if bounding_boxer . url : [EOL] annotations . append ( ( bounding_boxer . url , bounding_boxer . annotations ) ) [EOL] [EOL] if position < len ( images ) : [EOL] url = images [ position ] [EOL] [EOL] else : [EOL] url = [string] [EOL] [EOL] if callable ( url ) : [EOL] url = url ( ) [EOL] [EOL] bounding_boxer . url = url [EOL] bounding_boxer . annotations = [ ] [EOL] [EOL] def _advance ( delta ) : [EOL] nonlocal position [EOL] [comment] [EOL] position = max ( [number] , min ( len ( images ) , position + delta ) ) [EOL] show ( ) [EOL] [EOL] show ( ) [EOL] jslink ( ( bounding_boxer , [string] ) , ( annotation_display , [string] ) ) [EOL] jslink ( ( bounding_boxer , [string] ) , ( label , [string] ) ) [EOL] [EOL] @ bounding_boxer . on_msg def _ ( widget , ev , _ ) : [EOL] if ev [ [string] ] == [string] and ev [ [string] ] == [number] : [EOL] _advance ( + [number] ) [EOL] [EOL] prev_button . on_click ( lambda * _ : _advance ( - [number] ) ) [EOL] next_button . on_click ( lambda * _ : _advance ( + [number] ) ) [EOL] [EOL] return widget , annotations [EOL] [EOL] [EOL] @ register class BoundingBoxer ( DOMWidget ) : [EOL] [docstring] [EOL] [EOL] _view_name = Unicode ( [string] ) . tag ( sync = True ) [EOL] _view_module = Unicode ( [string] ) . tag ( sync = True ) [EOL] _view_module_version = Unicode ( [string] ) . tag ( sync = True ) [EOL] [EOL] url = Unicode ( None , allow_none = True ) . tag ( sync = True ) [EOL] current_tag = Unicode ( ) . tag ( sync = True ) [EOL] scale = Float ( [number] ) . tag ( sync = True ) [EOL] [EOL] _annotations = Unicode ( [string] ) . tag ( sync = True ) [EOL] [EOL] def __init__ ( self ) : [EOL] super ( ) . __init__ ( ) [EOL] inject_bounding_boxer_js ( ) [EOL] [EOL] @ property def annotations ( self ) : [EOL] return json . loads ( self . _annotations ) [EOL] [EOL] @ annotations . setter def annotations ( self , value ) : [EOL] self . _annotations = json . dumps ( value ) [EOL] [EOL] [EOL] @ register class AnnotationDisplay ( DOMWidget ) : [EOL] [docstring] [EOL] [EOL] _view_name = Unicode ( [string] ) . tag ( sync = True ) [EOL] _view_module = Unicode ( [string] ) . tag ( sync = True ) [EOL] _view_module_version = Unicode ( [string] ) . tag ( sync = True ) [EOL] [EOL] _annotations = Unicode ( [string] ) . tag ( sync = True ) [EOL] [EOL] def __init__ ( self ) : [EOL] super ( ) . __init__ ( ) [EOL] inject_bounding_boxer_js ( ) [EOL] [EOL] @ property def annotations ( self ) : [EOL] return json . loads ( self . _annotations ) [EOL] [EOL] @ annotations . setter def annotations ( self , value ) : [EOL] self . _annotations = json . dumps ( value ) [EOL] [EOL] [EOL] def inject_bounding_boxer_js ( ) : [EOL] if getattr ( inject_bounding_boxer_js , [string] , False ) is True : [EOL] return [EOL] [EOL] inject_bounding_boxer_js . injected = True [EOL] display_javascript ( Javascript ( _bounding_boxer_js ) ) [EOL] [EOL] [EOL] _bounding_boxer_js = [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing_extensions.Literal,typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing_extensions.Literal,typing.Any,typing.Any]$ 0 0 0 0 0 $typing.Tuple[typing_extensions.Literal,typing.Any,typing.Any]$ 0 0 0 0 0 0 $typing.Tuple[typing_extensions.Literal,typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 $typing.Any$ 0 0 $typing.List[typing.Any]$ 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[chmp.src.chmp.label.BoundingBoxer]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[chmp.src.chmp.label.BoundingBoxer]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[chmp.src.chmp.label.BoundingBoxer]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[chmp.src.chmp.label.BoundingBoxer]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[chmp.src.chmp.label.BoundingBoxer]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[chmp.src.chmp.label.BoundingBoxer]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[chmp.src.chmp.label.BoundingBoxer]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[chmp.src.chmp.label.AnnotationDisplay]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[chmp.src.chmp.label.AnnotationDisplay]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[chmp.src.chmp.label.AnnotationDisplay]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[chmp.src.chmp.label.AnnotationDisplay]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0
from typing import Dict , Any [EOL] import typing [EOL] import contextlib [EOL] import json [EOL] import operator as op [EOL] import hashlib [EOL] [EOL] import vmprof [EOL] [EOL] [EOL] @ contextlib . contextmanager def collect_profile ( fname = [string] ) : [EOL] with open ( fname , [string] ) as fobj : [EOL] vmprof . enable ( fobj . fileno ( ) , memory = False ) [EOL] try : [EOL] yield Profile ( fname ) [EOL] [EOL] finally : [EOL] vmprof . disable ( ) [EOL] [EOL] [EOL] class Profile : [EOL] def __init__ ( self , fname ) : [EOL] self . fname = fname [EOL] self . _stats = None [EOL] [EOL] @ property def stats ( self ) : [EOL] if self . _stats is None : [EOL] self . _stats = vmprof . read_profile ( self . fname ) [EOL] [EOL] return self . _stats [EOL] [EOL] @ property def tree ( self ) : [EOL] return self . stats . get_tree ( ) [EOL] [EOL] def show ( self ) : [EOL] plot_profile ( self , show = True ) [EOL] [EOL] [EOL] def plot_profile ( stats , show = False ) : [EOL] from bokeh . models import HoverTool [EOL] from bokeh . plotting import figure , show as do_show [EOL] [EOL] if isinstance ( stats , Profile ) : [EOL] stats = stats . stats [EOL] [EOL] ds = build_data ( stats ) [EOL] [EOL] p = figure ( active_scroll = [string] , x_axis_label = [string] , y_axis_label = [string] , plot_width = [number] , plot_height = [number] , ) [EOL] p . tools . append ( HoverTool ( tooltips = [ ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ] , point_policy = [string] , ) ) [EOL] p . rect ( [string] , [string] , [string] , [string] , color = [string] , source = ds , line_color = [string] ) [EOL] [EOL] if show : [EOL] do_show ( p ) [EOL] [EOL] else : [EOL] return p [EOL] [EOL] [EOL] def build_data ( stats , cmap = [string] , skip_empty = True ) : [EOL] from bokeh . models import ColumnDataSource [EOL] from matplotlib import cm [EOL] [EOL] tree = stats . get_tree ( ) [EOL] time_factor = stats . get_runtime_in_microseconds ( ) / tree . count [EOL] [EOL] if skip_empty : [EOL] while len ( tree . children ) == [number] : [EOL] tree , = tree . children . values ( ) [EOL] [EOL] cmap = cm . get_cmap ( cmap ) [EOL] [EOL] data = { } [EOL] for d in _build_data ( tree , offset = [number] , depth = [number] , parent_count = tree . count , cmap = cmap , time_factor = time_factor , ) : [EOL] for k , v in d . items ( ) : [EOL] data . setdefault ( k , [ ] ) . append ( v ) [EOL] [EOL] return ColumnDataSource ( data = data ) [EOL] [EOL] [EOL] def _build_data ( node , * , offset , parent_count , depth , cmap , time_factor ) : [EOL] r , g , b , a = cmap ( random ( node . name ) ) [EOL] type , name , lineno , file = node . name . split ( [string] ) [EOL] [EOL] yield dict ( x = time_factor * ( offset + node . count / [number] ) / [number] , y = depth , width = time_factor * node . count / [number] , height = [number] , color = [string] . format ( [number] * r , [number] * g , [number] * b , [number] * a ) , name = name [ : [number] ] , file = [string] . format ( file [ - [number] : ] , lineno ) , count = node . count , type = type , time = format_time ( time_factor * node . count ) , ) [EOL] [EOL] for child in sorted ( node . children . values ( ) , key = op . attrgetter ( [string] ) , reverse = True ) : [EOL] yield from _build_data ( child , offset = offset , depth = depth + [number] , parent_count = node . count , cmap = cmap , time_factor = time_factor , ) [EOL] offset += child . count [EOL] [EOL] [EOL] def format_time ( time ) : [EOL] if time < [number] : [EOL] return [string] . format ( time ) [EOL] [EOL] if time < [number] : [EOL] return [string] . format ( time / [number] ) [EOL] [EOL] return [string] . format ( time / [number] ) [EOL] [EOL] [EOL] def sha1 ( obj ) : [EOL] [docstring] [EOL] return int ( str_sha1 ( obj ) [ : [number] ] , [number] ) [EOL] [EOL] [EOL] def str_sha1 ( obj ) : [EOL] s = json . dumps ( obj , indent = None , sort_keys = True , separators = ( [string] , [string] ) ) [EOL] s = s . encode ( [string] ) [EOL] return hashlib . sha1 ( s ) . hexdigest ( ) [EOL] [EOL] [EOL] def random ( obj ) : [EOL] [docstring] [EOL] maximum_15_digit_hex = float ( [number] ) [EOL] return min ( sha1 ( obj ) / maximum_15_digit_hex , [number] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Set , Dict , Any [EOL] import typing [EOL] import logging [EOL] import json [EOL] import functools as ft [EOL] import logging [EOL] [EOL] import nbformat [EOL] [EOL] _logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def main ( input , output = None ) : [EOL] if output is None : [EOL] _logger . info ( [string] , input ) [EOL] [EOL] else : [EOL] _logger . info ( [string] , input , output ) [EOL] [EOL] nb = nbformat . read ( input , as_version = [number] ) [EOL] source = [string] . join ( export_notebook ( nb ) ) [EOL] [EOL] if output is None : [EOL] print ( source ) [EOL] [EOL] else : [EOL] with open ( output , [string] ) as fobj : [EOL] fobj . write ( source ) [EOL] [EOL] [EOL] [comment] [EOL] def dispatch ( func ) : [EOL] [docstring] [EOL] registry = { } [EOL] [EOL] @ ft . wraps ( func ) def wrapper ( * args , ** kwargs ) : [EOL] key = func ( * args , ** kwargs ) [EOL] handler = resolver ( registry , key ) [EOL] return handler ( * args , ** kwargs ) [EOL] [EOL] def resolver ( registery , key ) : [EOL] try : [EOL] return registry [ key ] [EOL] [EOL] except KeyError : [EOL] raise DispatchError ( [string] . format ( key ) ) [EOL] [EOL] def resolve ( func ) : [EOL] nonlocal resolver [EOL] resolver = func [EOL] return func [EOL] [EOL] def register ( key ) : [EOL] def decorator ( func ) : [EOL] registry [ key ] = func [EOL] return func [EOL] [EOL] return decorator [EOL] [EOL] wrapper . key = func [EOL] wrapper . resolve = resolve [EOL] wrapper . register = register [EOL] [EOL] return wrapper [EOL] [EOL] [EOL] class DispatchError ( Exception ) : [EOL] pass [EOL] [EOL] [EOL] @ dispatch def export_notebook ( obj , * args , ** kwargs ) : [EOL] if [string] in obj : [EOL] return [string] [EOL] [EOL] elif [string] in obj : [EOL] return [string] . format ( obj [ [string] ] ) [EOL] [EOL] [EOL] @ export_notebook . register ( [string] ) def export_notebook_notebook ( obj ) : [EOL] for cell in obj [ [string] ] : [EOL] yield from export_notebook ( cell ) [EOL] [EOL] [EOL] @ export_notebook . register ( [string] ) def export_notebook_cell_raw ( obj ) : [EOL] tags = { * obj [ [string] ] . get ( [string] , ( ) ) } [EOL] if [string] in tags : [EOL] return [EOL] [EOL] if [string] in tags : [EOL] meta = json . loads ( obj [ [string] ] ) [EOL] [EOL] yield f" [string] { meta [ [string] ] }" [EOL] yield f" [string] { meta [ [string] ] }" [EOL] yield f" [string] { meta [ [string] ] }" [EOL] yield [string] [EOL] yield [string] [EOL] [EOL] else : [EOL] raise ValueError ( [string] ) [EOL] [EOL] [EOL] @ export_notebook . register ( [string] ) def export_notebook_cell_markdown ( obj ) : [EOL] source = obj [ [string] ] . splitlines ( ) [EOL] yield from source [EOL] yield [string] [EOL] [EOL] [EOL] @ export_notebook . register ( [string] ) def export_notebook_cell_code ( obj ) : [EOL] tags = { * obj [ [string] ] . get ( [string] , ( ) ) } [EOL] tags = { tag for tag in tags if tag . startswith ( [string] ) } [EOL] [EOL] if [string] in tags : [EOL] return [EOL] [EOL] hide_output = [string] in tags [EOL] tags = tags - { [string] } [EOL] [EOL] if tags : [EOL] raise ValueError ( [string] . format ( tags ) ) [EOL] [EOL] yield [string] [EOL] yield from obj [ [string] ] . splitlines ( ) [EOL] yield [string] [EOL] yield [string] [EOL] [EOL] if not hide_output and obj [ [string] ] : [EOL] raise ValueError ( [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] import pytest [EOL] [EOL] from chmp . tools . mddocs import transform , transform_file , format_signature [EOL] [EOL] doc = [string] [EOL] [EOL] [EOL] class C : [EOL] def positional_only ( self , a , b , c ) : [EOL] pass [EOL] [EOL] def varargs_only ( * args ) : [EOL] pass [EOL] [EOL] def varargs ( self , a , b , * c ) : [EOL] pass [EOL] [EOL] def defaults ( self , a , b = [number] , c = [number] ) : [EOL] pass [EOL] [EOL] def kwargs ( self , a , ** b ) : [EOL] pass [EOL] [EOL] def pure_kwonly ( self , a , * , b , c ) : [EOL] pass [EOL] [EOL] def vargs_kwonly ( self , a , * b , c ) : [EOL] pass [EOL] [EOL] def kwonly_defaults ( self , a , * , b , c = [number] ) : [EOL] pass [EOL] [EOL] def kwonly_kwargs ( self , a , * , b , c = [number] , ** d ) : [EOL] pass [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( C . positional_only , [string] ) , ( C . varargs_only , [string] ) , ( C . varargs , [string] ) , ( C . defaults , [string] ) , ( C . pure_kwonly , [string] ) , ( C . vargs_kwonly , [string] ) , ( C . kwonly_defaults , [string] ) , ( C . kwargs , [string] ) , ( C . kwonly_kwargs , [string] ) , ] , ) def test_format_signature ( func , expected ) : [EOL] assert format_signature ( [string] , func ) == expected [EOL] [EOL] [EOL] def test_examples ( ) : [EOL] [docstring] [EOL] result = transform ( doc , __file__ ) [EOL] [EOL] [comment] [EOL] assert [string] in result [EOL] assert [string] in result [EOL] assert [string] in result [EOL] assert [string] in result [EOL] assert [string] in result [EOL] assert [string] in result [EOL] assert [string] in result [EOL] [EOL] [EOL] def test_multifile_exampele ( tmpdir ) : [EOL] tmpdir . join ( [string] ) . write ( root_source ) [EOL] tmpdir . join ( [string] ) . write ( doc ) [EOL] [EOL] source = str ( tmpdir . join ( [string] ) ) [EOL] target = str ( tmpdir . join ( [string] ) ) [EOL] transform_file ( source , target ) [EOL] [EOL] [EOL] root_source = [string] [EOL] [EOL] [EOL] def example_numpy ( ) : [EOL] [docstring] [EOL] [EOL] [EOL] def example_rest_style ( ) : [EOL] [docstring] [EOL] [EOL] [EOL] def example_adminitions ( ) : [EOL] [docstring] [EOL] [EOL] [EOL] class Foo : [EOL] [docstring] [EOL] [EOL] def __init__ ( self ) : [EOL] [docstring] [EOL] pass [EOL] [EOL] def method ( self , a , b ) : [EOL] [docstring] [EOL] pass [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] import pathlib [EOL] import bz2 [EOL] import json [EOL] import logging [EOL] import os . path [EOL] import pathlib [EOL] import sys [EOL] [EOL] import click [EOL] [EOL] [EOL] @ click . group ( ) def main ( ) : [EOL] [docstring] [EOL] pass [EOL] [EOL] [EOL] @ main . command ( ) @ click . argument ( [string] ) @ click . argument ( [string] ) @ click . option ( [string] , [string] , is_flag = True ) @ click . option ( [string] , multiple = True ) def mddocs ( src , dst , continue_on_error , inventory = ( ) ) : [EOL] [docstring] [EOL] from chmp . tools . mddocs import transform_directories [EOL] [EOL] if continue_on_error : [EOL] print ( [string] , file = sys . stderr ) [EOL] [EOL] inventory = open_inventory ( inventory ) [EOL] [EOL] print ( [string] , src , [string] , dst , file = sys . stderr ) [EOL] transform_directories ( src , dst , continue_on_error = continue_on_error , inventory = inventory ) [EOL] print ( [string] , file = sys . stderr ) [EOL] [EOL] [EOL] def open_inventory ( inventory , cache_file = [string] ) : [EOL] from chmp . tools . mddocs import load_inventory [EOL] [EOL] if not inventory : [EOL] return { } [EOL] [EOL] if os . path . exists ( cache_file ) : [EOL] with bz2 . open ( cache_file , [string] ) as fobj : [EOL] cached_inventory = json . load ( fobj ) [EOL] [EOL] print ( [string] , cache_file , file = sys . stderr ) [EOL] if cached_inventory [ [string] ] == list ( inventory ) : [EOL] return cached_inventory [ [string] ] [EOL] [EOL] print ( [string] , inventory , file = sys . stderr ) [EOL] inventory = load_inventory ( inventory ) [EOL] [EOL] print ( [string] , cache_file , file = sys . stderr ) [EOL] with bz2 . open ( cache_file , [string] ) as fobj : [EOL] json . dump ( inventory , fobj , indent = [number] , sort_keys = True ) [EOL] [EOL] return inventory [ [string] ] [EOL] [EOL] [EOL] @ main . command ( ) @ click . argument ( [string] , type = click . Path ( exists = True ) ) @ click . argument ( [string] , type = click . Path ( exists = True ) ) @ click . option ( [string] , [string] , is_flag = True , default = False ) def paper ( source_path , target_path , yes = False ) : [EOL] [docstring] [EOL] from chmp . tools . papers import sort_arxiv_papers , sort_non_arxiv_papers [EOL] [EOL] non_arxiv_source_path = pathlib . Path ( source_path ) / [string] [EOL] [EOL] print ( f" [string] " ) [EOL] print ( f" [string] { source_path !s} [string] { target_path !s}" ) [EOL] print ( f" [string] { non_arxiv_source_path !s} [string] { target_path !s}" ) [EOL] [EOL] if not yes and input ( [string] ) != [string] : [EOL] return [EOL] [EOL] print ( ) [EOL] print ( [string] ) [EOL] sort_arxiv_papers ( source_path , target_path ) [EOL] [EOL] print ( [string] ) [EOL] sort_non_arxiv_papers ( non_arxiv_source_path , target_path ) [EOL] [EOL] [EOL] @ main . command ( ) @ click . argument ( [string] , type = click . Path ( exists = True ) ) @ click . argument ( [string] , type = click . Path ( ) , required = False ) def blog ( source_path , target_path = None ) : [EOL] from chmp . tools . blog import main [EOL] [EOL] main ( source_path , target_path ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] logging . basicConfig ( level = logging . INFO ) [EOL] main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Pattern , List , Dict , Any [EOL] import typing [EOL] import subprocess [EOL] import pathlib [EOL] [docstring] [EOL] [EOL] import json [EOL] import pathlib [EOL] import re [EOL] import shutil [EOL] import subprocess [EOL] [EOL] import requests [EOL] [EOL] [EOL] def sort_arxiv_papers ( source_path , target_path ) : [EOL] source_path = pathlib . Path ( source_path ) [EOL] target_path = pathlib . Path ( target_path ) [EOL] [EOL] arxiv_papers = [ p for p in source_path . glob ( [string] ) if is_arxiv_paper ( p ) ] [EOL] existing_arxiv_papers = [ ] [EOL] [EOL] for idx , p in enumerate ( arxiv_papers ) : [EOL] meta_file_name = [string] . format ( p . stem ) [EOL] [EOL] if ( target_path / meta_file_name ) . exists ( ) : [EOL] print ( [string] , p ) [EOL] existing_arxiv_papers += [ p ] [EOL] continue [EOL] [EOL] print ( [string] , p , idx , [string] , len ( arxiv_papers ) ) [EOL] meta = fetch_meta_data ( p ) [EOL] meta = parse_meta_data ( meta ) [EOL] [EOL] normalized_title = meta [ [string] ] [EOL] normalized_title = re . sub ( [string] , [string] , normalized_title ) [EOL] normalized_title = normalized_title . lower ( ) [EOL] normalized_title = [string] . join ( re . split ( [string] , normalized_title ) ) [EOL] [EOL] normalized_file_name = [string] . format ( p . stem , normalized_title ) [EOL] [EOL] if ( target_path / normalized_file_name ) . exists ( ) : [EOL] print ( [string] , target_path / normalized_file_name ) [EOL] continue [EOL] [EOL] shutil . move ( p , target_path / normalized_file_name ) [EOL] [EOL] with ( target_path / meta_file_name ) . open ( [string] ) as fobj : [EOL] json . dump ( meta , fobj , indent = [number] , sort_keys = True ) [EOL] [EOL] return existing_arxiv_papers [EOL] [EOL] [EOL] def sort_non_arxiv_papers ( source_path , target_path ) : [EOL] source_path = pathlib . Path ( source_path ) . resolve ( ) [EOL] target_path = pathlib . Path ( target_path ) . resolve ( ) [EOL] [EOL] print ( source_path ) [EOL] candidate_papers = list ( source_path . glob ( [string] ) ) [EOL] [EOL] for p in candidate_papers : [EOL] s = shasum ( p ) [EOL] [EOL] normalized_file_name = re . sub ( [string] , [string] , p . stem ) [EOL] normalized_file_name = normalized_file_name . lower ( ) [EOL] normalized_file_name = normalized_file_name . replace ( [string] , [string] ) [EOL] normalized_file_name = normalized_file_name . replace ( [string] , [string] ) [EOL] normalized_file_name = f"{ s [ : [number] ] } [string] { normalized_file_name } [string] " [EOL] [EOL] target_fname = target_path / normalized_file_name [EOL] [EOL] if target_fname . exists ( ) : [EOL] print ( [string] , p , [string] , target_fname ) [EOL] continue [EOL] [EOL] print ( p , [string] , target_fname ) [EOL] shutil . move ( p , target_fname ) [EOL] [EOL] [EOL] def shasum ( p ) : [EOL] p = subprocess . run ( [ [string] , p ] , stdout = subprocess . PIPE , check = True ) [EOL] s = p . stdout . decode ( ) [EOL] s , = s . splitlines ( ) [EOL] s , * _ = s . partition ( [string] ) [EOL] return s [EOL] [EOL] [EOL] def is_arxiv_paper ( p ) : [EOL] return arxiv_path_pattern . match ( p . name ) is not None [EOL] [EOL] [EOL] def fetch_meta_data ( p ) : [EOL] url = [string] . format ( p . stem ) [EOL] return requests . get ( url ) . content . decode ( ) [EOL] [EOL] [EOL] def parse_meta_data ( desc ) : [EOL] [docstring] [EOL] data = desc . split ( [string] ) [EOL] [EOL] header = data [ [number] ] . strip ( ) [EOL] abstract = data [ [number] ] . strip ( ) [EOL] [EOL] res = { } [EOL] for line in header . splitlines ( ) : [EOL] if not line : [EOL] continue [EOL] [EOL] key , _ , val = line . partition ( [string] ) [EOL] res [ key . strip ( ) ] = val . strip ( ) [EOL] [EOL] res [ [string] ] = abstract [EOL] return res [EOL] [EOL] [EOL] arxiv_path_pattern = re . compile ( [string] , re . VERBOSE , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Pattern[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Pattern[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Union , Type , Dict , Any [EOL] import typing [EOL] import chmp [EOL] import _ast [EOL] import ast [EOL] import functools as ft [EOL] import threading [EOL] import uuid [EOL] import weakref [EOL] [EOL] from ipywidgets import DOMWidget , register [EOL] from traitlets import Unicode [EOL] [EOL] [EOL] def _jupyter_nbextension_paths ( ) : [EOL] [docstring] [EOL] return [ dict ( section = [string] , src = [string] , dest = [string] , require = [string] , ) ] [EOL] [EOL] [EOL] @ register class FocusCell ( DOMWidget ) : [EOL] [docstring] [EOL] [EOL] _view_name = Unicode ( [string] ) . tag ( sync = True ) [EOL] _view_module = Unicode ( [string] ) . tag ( sync = True ) [EOL] _view_module_version = Unicode ( [string] ) . tag ( sync = True ) [EOL] [EOL] [EOL] @ register class CommandInput ( DOMWidget ) : [EOL] [docstring] [EOL] [EOL] _view_name = Unicode ( [string] ) . tag ( sync = True ) [EOL] _view_module = Unicode ( [string] ) . tag ( sync = True ) [EOL] _view_module_version = Unicode ( [string] ) . tag ( sync = True ) [EOL] [EOL] def __init__ ( self , on_command = None ) : [EOL] super ( ) . __init__ ( ) [EOL] self . _on_command = on_command [EOL] self . on_msg ( self . _on_msg ) [EOL] [EOL] def on_command ( self , callback ) : [EOL] self . _on_command = callback [EOL] [EOL] def _on_msg ( self , _ , ev , __ ) : [EOL] if ev . get ( [string] ) != [string] : [EOL] return [EOL] [EOL] if self . _on_command is None : [EOL] return [EOL] [EOL] self . _on_command ( ev [ [string] ] ) [EOL] [EOL] [EOL] class WidgetRegistry : [EOL] [docstring] [EOL] [EOL] def __init__ ( self ) : [EOL] self . widgets = { } [EOL] [EOL] def __call__ ( self , key , widget ) : [EOL] self . widgets [ key ] = widget [EOL] return widget [EOL] [EOL] def __getattr__ ( self , key ) : [EOL] try : [EOL] return self . widgets [ key ] [EOL] [EOL] except KeyError as _ : [EOL] raise AttributeError ( key ) [EOL] [EOL] def __dir__ ( self ) : [EOL] return [ * super ( ) . __dir__ ( ) , * self . widgets ] [EOL] [EOL] [EOL] class PersistentDatasets : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , datasets = None ) : [EOL] if datasets is None : [EOL] datasets = { } [EOL] [EOL] self . datasets = dict ( datasets ) [EOL] self . widgets = { } [EOL] [EOL] def bind ( self , widget , datasets ) : [EOL] for key in datasets : [EOL] ref = weakref . ref ( widget , self . _update_widgets ) [EOL] self . widgets . setdefault ( key , [ ] ) . append ( ref ) [EOL] [EOL] def _update_widgets ( self , _ ) : [EOL] for key in datasets : [EOL] self . widgets [ key ] = [ ref for ref in self . widgets [ key ] if ref ( ) is not None ] [EOL] [EOL] self . widgets = { key : refs for key , refs in self . widgets . items ( ) if refs } [EOL] [EOL] def clear ( self , key ) : [EOL] if key in self . datasets : [EOL] self . datasets [ key ] = [ ] [EOL] [EOL] for widget in self . widgets . get ( key , [ ] ) : [EOL] widget = widget ( ) [EOL] if widget is not None : [EOL] widget . update ( key , remove = [string] ) [EOL] [EOL] def clear_all ( self ) : [EOL] for key in { * self . datasets , * self . widgets } : [EOL] self . clear ( key ) [EOL] [EOL] def get ( self , key ) : [EOL] return { [string] : key , [string] : self . datasets . get ( key , [ ] ) } [EOL] [EOL] def update ( self , key , * , remove = None , insert = None ) : [EOL] for widget in self . widgets . get ( key , [ ] ) : [EOL] widget = widget ( ) [EOL] if widget is not None : [EOL] widget . update ( key , remove = remove , insert = insert ) [EOL] [EOL] self . _update_self ( key , remove = remove , insert = insert ) [EOL] [EOL] def _update_self ( self , key , remove = None , insert = None ) : [EOL] if insert is None and remove is None : [EOL] return [EOL] [EOL] data = self . datasets . get ( key , [ ] ) [EOL] [EOL] if remove is not None : [EOL] remove_expr = JSExpr ( [ [string] ] , remove ) [EOL] data = [ item for item in data if not remove_expr ( JSObj ( item ) ) ] [EOL] [EOL] if insert is not None : [EOL] data = data + list ( insert ) [EOL] [EOL] self . datasets [ key ] = data [EOL] [EOL] [EOL] def run_thread ( func = None , * , key = None , registry = None , interval = None , wake_interval = [number] ) : [EOL] [docstring] [EOL] [EOL] def decorator ( func ) : [EOL] if interval is not None : [EOL] func = _make_loop ( func = func , interval = interval , wake_interval = wake_interval ) [EOL] [EOL] _run_thread_primitive ( func = func , key = key , registry = registry ) [EOL] return func [EOL] [EOL] return decorator if func is None else decorator ( func ) [EOL] [EOL] [EOL] def stop_thread ( func_or_key , * , registry = None ) : [EOL] [docstring] [EOL] registry = ensure_thread_registry ( registry ) [EOL] key = func_or_key if isinstance ( func_or_key , str ) else func_or_key . __name__ [EOL] [EOL] _stop_thread_primitive ( registry , key ) [EOL] [EOL] [EOL] def _make_loop ( func , interval , wake_interval ) : [EOL] import time [EOL] [EOL] @ ft . wraps ( func ) def loop ( ctx ) : [EOL] next_update = time . time ( ) [EOL] while ctx . running : [EOL] if time . time ( ) >= next_update : [EOL] func ( ctx ) [EOL] next_update = time . time ( ) + interval [EOL] [EOL] time . sleep ( wake_interval ) [EOL] [EOL] return loop [EOL] [EOL] [EOL] def _run_thread_primitive ( * , func , key = None , registry = None ) : [EOL] registry = ensure_thread_registry ( registry ) [EOL] [EOL] if key is None : [EOL] key = func . __name__ [EOL] [EOL] _stop_thread_primitive ( registry , key ) [EOL] [EOL] registry [ key ] = Context ( ) [EOL] registry [ key ] . running = True [EOL] registry [ key ] . thread = threading . Thread ( target = func , args = ( registry [ key ] , ) ) [EOL] registry [ key ] . thread . start ( ) [EOL] [EOL] [EOL] def ensure_thread_registry ( registry = None ) : [EOL] if registry is not None : [EOL] return registry [EOL] [EOL] import __main__ [EOL] [EOL] if not hasattr ( __main__ , [string] ) : [EOL] __main__ . _bg_threads = { } [EOL] [EOL] return __main__ . _bg_threads [EOL] [EOL] [EOL] def _stop_thread_primitive ( registry , key ) : [EOL] if key in registry and registry [ key ] . running : [EOL] registry [ key ] . running = False [EOL] registry [ key ] . thread . join ( ) [EOL] [EOL] if key in registry : [EOL] del registry [ key ] [EOL] [EOL] [EOL] class Context : [EOL] def __init__ ( self , running = False , thread = None ) : [EOL] self . running = running [EOL] self . thread = thread [EOL] [EOL] def __repr__ ( self ) : [EOL] return f" [string] { self . running } [string] { self . thread !r} [string] " [EOL] [EOL] [EOL] class JSExpr : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , argnames , expr ) : [EOL] self . argnames = argnames [EOL] self . expr = expr [EOL] self . code = self . build_code ( expr ) [EOL] [EOL] @ staticmethod def build_code ( expr , filename = None ) : [EOL] try : [EOL] import pyjsparser [EOL] [EOL] except ImportError : [EOL] raise RuntimeError ( [string] ) [EOL] [EOL] if filename is None : [EOL] filename = [string] . format ( uuid . uuid4 ( ) ) [EOL] [EOL] js_ast = pyjsparser . parse ( expr ) [EOL] py_ast = _transform_js_to_python ( js_ast ) [EOL] return compile ( py_ast , filename , mode = [string] ) [EOL] [EOL] def __call__ ( self , * args ) : [EOL] scope = dict ( zip ( self . argnames , args ) ) [EOL] return eval ( self . code , scope ) [EOL] [EOL] def __repr__ ( self ) : [EOL] return [string] . format ( self . argnames , self . expr ) [EOL] [EOL] [EOL] class JSObj : [EOL] [docstring] [EOL] [EOL] def __init__ ( * args , ** kwargs ) : [EOL] if len ( args ) == [number] : [EOL] self , obj = args [EOL] [EOL] else : [EOL] self , = args [EOL] obj = { } [EOL] [EOL] assert isinstance ( obj , dict ) [EOL] self . obj = dict ( obj , ** kwargs ) [EOL] [EOL] def __getattr__ ( self , key ) : [EOL] return self . obj [ key ] [EOL] [EOL] def __getitem__ ( self , key ) : [EOL] return self . obj [ key ] [EOL] [EOL] [EOL] def _dispatch_on_type ( func ) : [EOL] [docstring] [EOL] registry = { } [EOL] [EOL] @ ft . wraps ( func ) def wrapper ( obj ) : [EOL] handler = registry . get ( obj [ [string] ] , func ) [EOL] return handler ( obj ) [EOL] [EOL] def register ( key ) : [EOL] def decorator ( func ) : [EOL] registry [ key ] = func [EOL] [EOL] return decorator [EOL] [EOL] wrapper . register = register [EOL] [EOL] return wrapper [EOL] [EOL] [EOL] @ _dispatch_on_type def _transform_js_to_python ( obj ) : [EOL] [docstring] [EOL] raise ValueError ( [string] . format ( obj [ [string] ] ) ) [EOL] [EOL] [EOL] @ _transform_js_to_python . register ( [string] ) def _transform_js_to_python_program ( obj ) : [EOL] is_single_expression = ( len ( obj [ [string] ] ) == [number] ) and ( obj [ [string] ] [ [number] ] [ [string] ] == [string] ) [EOL] [EOL] if not is_single_expression : [EOL] raise ValueError ( [string] ) [EOL] [EOL] expr_ast = _transform_js_to_python ( obj [ [string] ] [ [number] ] [ [string] ] ) [EOL] return ast . Expression ( body = expr_ast , lineno = [number] , col_offset = [number] ) [EOL] [EOL] [EOL] @ _transform_js_to_python . register ( [string] ) def _transform_js_to_python_member_expression ( obj ) : [EOL] value = _transform_js_to_python ( obj [ [string] ] ) [EOL] [EOL] if obj [ [string] ] [ [string] ] == [string] : [EOL] attr = obj [ [string] ] [ [string] ] [EOL] return ast . Attribute ( value = value , attr = attr , ctx = ast . Load ( ) , lineno = [number] , col_offset = [number] ) [EOL] [EOL] else : [EOL] key = _transform_js_to_python ( obj [ [string] ] ) [EOL] [EOL] return ast . Subscript ( value = value , slice = ast . Index ( value = key , lineno = [number] , col_offset = [number] ) , ctx = ast . Load ( ) , lineno = [number] , col_offset = [number] , ) [EOL] [EOL] [EOL] @ _transform_js_to_python . register ( [string] ) def _transform_js_to_python_binary_epxression ( obj ) : [EOL] left = _transform_js_to_python ( obj [ [string] ] ) [EOL] right = _transform_js_to_python ( obj [ [string] ] ) [EOL] op = obj [ [string] ] [EOL] [EOL] compapare_ops = { [string] : ast . Lt , [string] : ast . Gt , [string] : ast . LtE , [string] : ast . GtE , [string] : ast . Eq , [string] : ast . NotEq , } [EOL] [EOL] if op in compapare_ops : [EOL] return ast . Compare ( left = left , ctx = ast . Load ( ) , ops = [ compapare_ops [ op ] ( ) ] , comparators = [ right ] , lineno = [number] , col_offset = [number] , ) [EOL] [EOL] else : [EOL] raise NotImplementedError ( obj [ [string] ] ) [EOL] [EOL] [EOL] @ _transform_js_to_python . register ( [string] ) def _transform_js_to_python_identifier ( obj ) : [EOL] return ast . Name ( id = obj [ [string] ] , ctx = ast . Load ( ) , lineno = [number] , col_offset = [number] ) [EOL] [EOL] [EOL] @ _transform_js_to_python . register ( [string] ) def _transform_js_to_python_literal ( obj ) : [EOL] if isinstance ( obj [ [string] ] , str ) : [EOL] return ast . Str ( s = obj [ [string] ] , lineno = [number] , col_offset = [number] ) [EOL] [EOL] elif isinstance ( obj [ [string] ] , float ) : [EOL] try : [EOL] n = int ( obj [ [string] ] ) [EOL] [EOL] except ValueError : [EOL] n = float ( obj [ [string] ] ) [EOL] [EOL] return ast . Num ( n = n , lineno = [number] , col_offset = [number] ) [EOL] [EOL] elif isinstance ( obj [ [string] ] , bool ) : [EOL] return ast . NameConstant ( value = obj [ [string] ] , lineno = [number] , col_offset = [number] ) [EOL] [EOL] elif obj [ [string] ] is None : [EOL] return ast . NameConstant ( value = None , lineno = [number] , col_offset = [number] ) [EOL] [EOL] else : [EOL] raise ValueError ( [string] . format ( type ( obj [ [string] ] ) . __name__ ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[chmp.src.chmp.widgets.FocusCell]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[chmp.src.chmp.widgets.FocusCell]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[chmp.src.chmp.widgets.FocusCell]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[chmp.src.chmp.widgets.CommandInput]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[chmp.src.chmp.widgets.CommandInput]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[chmp.src.chmp.widgets.CommandInput]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.widgets.JSExpr$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 $chmp.src.chmp.widgets.JSExpr$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] from chmp . widgets import JSExpr , JSObj [EOL] [EOL] import pytest [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [string] , { [string] : [number] } , [number] ) , ( [string] , { [string] : [number] } , True ) , ( [string] , { [string] : [number] } , False ) , ( [string] , { } , True ) , ( [string] , { } , False ) , ( [string] , { } , None ) , ( [string] , JSObj ( date = [string] ) , False ) , ( [string] , JSObj ( date = [string] ) , True ) , ] , ) def test_js_expr ( expr , obj , expected ) : [EOL] actual = JSExpr ( [ [string] ] , expr ) ( obj ) [EOL] assert actual is expected [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import List , Dict , Any [EOL] import typing [EOL] import logging [EOL] [docstring] [EOL] import bz2 [EOL] import contextlib [EOL] import json [EOL] import logging [EOL] import os . path [EOL] import tempfile [EOL] import time [EOL] [EOL] from mlflow import ( active_run , log_metric , log_artifacts , log_artifact , log_param , set_tag , ) [EOL] [EOL] [EOL] __all__ = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , ] [EOL] _logger = logging . getLogger ( ) [EOL] [EOL] [EOL] def get_store ( uri = None ) : [EOL] from mlflow import get_tracking_uri [EOL] from mlflow . store . file_store import FileStore [EOL] [EOL] if uri is None : [EOL] uri = get_tracking_uri ( ) [EOL] [EOL] return FileStore ( uri ) [EOL] [EOL] [EOL] def get_artifact_repository ( run_uuid , store = None ) : [EOL] from mlflow . store . artifact_repo import ArtifactRepository [EOL] [EOL] store = _ensure_store ( store ) [EOL] run = store . get_run ( run_uuid ) [EOL] return ArtifactRepository . from_artifact_uri ( run . info . artifact_uri , store ) [EOL] [EOL] [EOL] def is_local_artifact_respository ( artifact_repo ) : [EOL] from mlflow . store . local_artifact_repo import LocalArtifactRepository [EOL] [EOL] return isinstance ( artifact_repo , LocalArtifactRepository ) [EOL] [EOL] [EOL] def list_all_runs ( store = None ) : [EOL] [docstring] [EOL] store = _ensure_store ( store ) [EOL] [EOL] return [ run_info . run_uuid for experiment in store . list_experiments ( ) for run_info in store . list_run_infos ( experiment . experiment_id ) ] [EOL] [EOL] [EOL] @ contextlib . contextmanager def new_run ( ** kwargs ) : [EOL] import mlflow [EOL] [EOL] with mlflow . start_run ( ** kwargs ) as run , tempfile . TemporaryDirectory ( ) as tmpdir : [EOL] _logger . info ( [string] , run . info . run_uuid ) [EOL] run . tmpdir = tmpdir [EOL] [EOL] try : [EOL] yield run [EOL] [EOL] finally : [EOL] log_artifacts ( tmpdir ) [EOL] [EOL] [EOL] def log_tempdir ( ) : [EOL] run = active_run ( ) [EOL] assert run is not None [EOL] log_artifacts ( run . tmpdir ) [EOL] [EOL] [EOL] def has_active_run ( ) : [EOL] return active_run ( ) is not None [EOL] [EOL] [EOL] @ contextlib . contextmanager def open_artifact ( run_uuid , artifact_path , mode = [string] , * , open = open , store = None ) : [EOL] artifact_repo = get_artifact_repository ( run_uuid , store ) [EOL] assert is_local_artifact_respository ( artifact_repo ) , [string] [EOL] [EOL] local_path = artifact_repo . download_artifacts ( artifact_path ) [EOL] with open ( local_path , mode ) as fobj : [EOL] yield fobj [EOL] [EOL] [comment] [EOL] [EOL] [EOL] def list_artifacts ( run_uuid , path = [string] , store = None ) : [EOL] artifact_repo = get_artifact_repository ( run_uuid , store = store ) [EOL] return artifact_repo . list_artifacts ( path ) [EOL] [EOL] [EOL] def log_fobj ( fobj , fname ) : [EOL] [docstring] [EOL] if hasattr ( fobj , [string] ) : [EOL] mode = [string] [EOL] [EOL] else : [EOL] mode = [string] [EOL] [EOL] with tempfile . TemporaryDirectory ( ) as tempdir : [EOL] target_fname = os . path . join ( tempdir , fname ) [EOL] with open ( target_fname , mode ) as target : [EOL] while True : [EOL] chunk = fobj . read ( [number] * [number] ) [EOL] if len ( chunk ) == [number] : [EOL] break [EOL] [EOL] target . write ( chunk ) [EOL] [EOL] log_artifact ( target_fname ) [EOL] [EOL] [EOL] def log_structured ( ** values ) : [EOL] [docstring] [EOL] tempdir = get_tempdir ( ) [EOL] [EOL] [comment] [EOL] values = dict ( values , timestamp = str ( int ( [number] * time . time ( ) ) ) ) [EOL] [EOL] with bz2 . open ( os . path . join ( tempdir , [string] ) , [string] ) as fobj : [EOL] fobj . write ( json . dumps ( values ) ) [EOL] fobj . write ( [string] ) [EOL] [EOL] [EOL] def get_structured ( run_uuid , store = None ) : [EOL] with open_artifact ( run_uuid , [string] , open = bz2 . open , store = store ) as fobj : [EOL] [comment] [EOL] return [ dict ( d , timestamp = int ( d [ [string] ] ) ) for d in ( json . loads ( line ) for line in fobj ) ] [EOL] [EOL] [EOL] def get_tempdir ( ) : [EOL] [docstring] [EOL] run = active_run ( ) [EOL] [EOL] if run is None : [EOL] raise RuntimeError ( [string] ) [EOL] [EOL] if not hasattr ( run , [string] ) : [EOL] raise RuntimeError ( [string] ) [EOL] [EOL] return run . tmpdir [EOL] [EOL] [EOL] def active_run_uuid ( ) : [EOL] run = active_run ( ) [EOL] return None if run is None else run . info . run_uuid [EOL] [EOL] [EOL] def get_all_infos_df ( ) : [EOL] import pandas as pd [EOL] [EOL] infos = pd . DataFrame ( get_all_infos ( ) ) [EOL] [EOL] infos . columns = pd . MultiIndex . from_tuples ( infos . columns ) [EOL] infos [ [string] , [string] ] = pd . to_datetime ( infos [ [string] , [string] ] , unit = [string] ) [EOL] infos [ [string] , [string] ] = pd . to_datetime ( infos [ [string] , [string] ] , unit = [string] ) [EOL] infos [ [string] , [string] ] = pd . to_timedelta ( infos [ [string] , [string] ] , unit = [string] ) [EOL] [EOL] return infos [EOL] [EOL] [EOL] def get_all_infos ( store = None ) : [EOL] return [ get_infos ( run_uuid , store = store ) for run_uuid in list_all_runs ( store = store ) ] [EOL] [EOL] [EOL] def get_infos ( run_uuid , store = None ) : [EOL] from mlflow . entities import RunStatus [EOL] [EOL] run = get_run ( run_uuid , store = store ) [EOL] [EOL] if run . info . end_time is None : [EOL] duration = None [EOL] [EOL] else : [EOL] duration = run . info . end_time - run . info . start_time [EOL] [EOL] return { ( [string] , [string] ) : run . info . run_uuid , ( [string] , [string] ) : run . info . experiment_id , ( [string] , [string] ) : RunStatus . to_string ( run . info . status ) , ( [string] , [string] ) : run . info . start_time , ( [string] , [string] ) : run . info . end_time , ( [string] , [string] ) : duration , ** { ( [string] , m . key ) : m . value for m in get_all_metrics ( run_uuid , store = store ) } , ** { ( [string] , p . key ) : p . value for p in get_all_params ( run_uuid , store = store ) } , } [EOL] [EOL] [EOL] def log_all_metrics ( ** metrics ) : [EOL] _kv_apply ( log_metric , metrics ) [EOL] [EOL] [EOL] def log_all_params ( ** params ) : [EOL] _kv_apply ( log_param , params ) [EOL] [EOL] [EOL] def set_all_tags ( ** tags ) : [EOL] _kv_apply ( set_tag , tags ) [EOL] [EOL] [EOL] def _kv_apply ( func , mapping ) : [EOL] for k , v in mapping . items ( ) : [EOL] func ( k , v ) [EOL] [EOL] [EOL] def get_run ( run_uuid , store = None ) : [EOL] return _ensure_store ( store ) . get_run ( run_uuid ) [EOL] [EOL] [EOL] def get_all_metrics ( run_uuid , store = None ) : [EOL] return _ensure_store ( store ) . get_all_metrics ( run_uuid ) [EOL] [EOL] [EOL] def get_all_params ( run_uuid , store = None ) : [EOL] return _ensure_store ( store ) . get_all_params ( run_uuid ) [EOL] [EOL] [EOL] def get_metric ( run_uuid , metric_key , store = None ) : [EOL] return _ensure_store ( store ) . get_metric ( run_uuid , metric_key ) [EOL] [EOL] [EOL] def get_metric_history ( run_uuid , metric_key , store = None ) : [EOL] return _ensure_store ( store ) . get_metric_history ( run_uuid , metric_key ) [EOL] [EOL] [EOL] def get_param ( run_uuid , param_key , store = None ) : [EOL] return _ensure_store ( store ) . get_param ( run_uuid , param_key ) [EOL] [EOL] [EOL] def delete_experiment ( run_uuid , store = None ) : [EOL] return _ensure_store ( store ) . delete_experiment ( run_uuid ) [EOL] [EOL] [EOL] def restore_experiment ( run_uuid , store = None ) : [EOL] return _ensure_store ( store ) . restore_experiment ( store ) [EOL] [EOL] [EOL] def get_trash_folder ( store = None ) : [EOL] return _ensure_store ( store ) . trash_folder [EOL] [EOL] [EOL] def _ensure_store ( store ) : [EOL] return store if store is not None else get_store ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , Any , Union , List , ItemsView , Tuple [EOL] import typing [EOL] from __future__ import print_function , division , absolute_import [EOL] [EOL] import collections [EOL] import itertools as it [EOL] import operator as op [EOL] [EOL] import dask . bag as db [EOL] import pytest [EOL] import toolz [EOL] import toolz . curried as curried [EOL] [EOL] from toolz import first , second [EOL] [EOL] from chmp . distributed import apply , chained , mean , var , std [EOL] [EOL] [EOL] examples = { [string] : ( mean , range ( [number] ) ) , [string] : ( var , range ( [number] ) ) , [string] : ( std , range ( [number] ) ) , [string] : ( var ( ddof = [number] ) , range ( [number] ) ) , [string] : ( std ( ddof = [number] ) , range ( [number] ) ) , [string] : ( any , [ True , False , False ] ) , [string] : ( any , [ False , False , False ] ) , [string] : ( any , [ True , True , True ] ) , [string] : ( all , [ True , False , False ] ) , [string] : ( all , [ False , False , False ] ) , [string] : ( all , [ True , True , True ] ) , [string] : ( sum , list ( range ( [number] ) ) ) , [string] : ( min , list ( range ( [number] ) ) ) , [string] : ( max , list ( range ( [number] ) ) ) , [string] : ( len , list ( range ( [number] ) ) ) , [string] : ( list , list ( range ( [number] ) ) ) , [string] : ( dict , [ ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) ] ) , [string] : ( chained ( dict , op . methodcaller ( [string] ) , list ) , [ ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) ] , ) , [string] : ( chained ( dict , op . methodcaller ( [string] ) , list ) , [ ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) ] , ) , [string] : ( chained ( dict , op . methodcaller ( [string] ) , list ) , [ ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) ] , ) , [string] : ( chained ( dict , dict . items , list ) , [ ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) ] , ) , [string] : ( chained ( it . chain . from_iterable , list ) , [ ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) ] , ) , [string] : ( chained ( collections . Counter , dict ) , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , ) , [string] : ( chained ( collections . Counter , op . methodcaller ( [string] ) , sorted ) , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , ) , [string] : ( chained ( collections . Counter , op . methodcaller ( [string] , [number] ) , sorted ) , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] , ) , [string] : ( chained ( set , sorted ) , [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) , [string] : ( chained ( curried . map ( lambda x : [number] * x ) , list ) , [ [number] , [number] , [number] , [number] , [number] , [number] ] ) , [string] : ( chained ( curried . filter ( lambda x : x % [number] == [number] ) , list ) , range ( [number] ) ) , [string] : ( chained ( curried . remove ( lambda x : x % [number] == [number] ) , list ) , range ( [number] ) ) , [string] : ( chained ( curried . pluck ( [string] ) , list ) , [ { [string] : [number] , [string] : [string] } , { [string] : [number] , [string] : [string] } ] , ) , [string] : ( chained ( curried . pluck ( [ [number] , [number] ] ) , list ) , [ [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] ] ) , [string] : ( chained ( curried . join ( second , [ ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ] , first , ) , curried . map ( lambda t : ( t [ [number] ] [ [number] ] , t [ [number] ] [ [number] ] ) ) , sorted , ) , [ ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ] , ) , [string] : ( curried . countby ( lambda x : x % [number] == [number] ) , range ( [number] ) ) , [string] : ( chained ( curried . groupby ( lambda x : x % [number] == [number] ) , curried . valmap ( sorted ) ) , range ( [number] ) , ) , [string] : ( chained ( dict , curried . keymap ( lambda x : [number] * x ) ) , dict . items ( { [number] : [number] , [number] : [number] , [number] : [number] , [number] : [number] , [number] : [number] } ) , ) , [string] : ( chained ( dict , curried . valmap ( lambda x : [number] * x ) ) , dict . items ( { [number] : [number] , [number] : [number] , [number] : [number] , [number] : [number] , [number] : [number] } ) , ) , [string] : ( chained ( dict , curried . keyfilter ( lambda x : x > [number] ) ) , dict . items ( { [number] : [number] , [number] : [number] , [number] : [number] , [number] : [number] , [number] : [number] } ) , ) , [string] : ( chained ( dict , curried . valfilter ( lambda x : x > [number] ) ) , dict . items ( { [number] : [number] , [number] : [number] , [number] : [number] , [number] : [number] , [number] : [number] } ) , ) , [string] : ( chained ( dict , curried . itemfilter ( lambda i : i [ [number] ] % [number] == [number] and i [ [number] ] < [number] ) ) , dict . items ( { [number] : [number] , [number] : [number] , [number] : [number] , [number] : [number] } ) , ) , [string] : ( chained ( curried . mapcat ( lambda s : [ c . upper ( ) for c in s ] ) , list ) , [ [ [string] , [string] ] , [ [string] , [string] , [string] ] ] , ) , [string] : ( curried . reduce ( op . add ) , range ( [number] ) ) , [string] : ( curried . reduceby ( lambda x : x % [number] == [number] , op . add ) , range ( [number] ) ) , [string] : ( chained ( curried . topk ( [number] ) , list ) , range ( [number] ) ) , [string] : ( chained ( curried . unique , sorted ) , [ [number] , [number] , [number] , [number] , [number] , [number] ] ) , [string] : ( chained ( toolz . unique , sorted ) , [ [number] , [number] , [number] , [number] , [number] , [number] ] ) , } [EOL] [EOL] [EOL] def params ( spec , m ) : [EOL] return pytest . mark . parametrize ( spec , [ v for ( _ , v ) in sorted ( m . items ( ) ) ] , ids = sorted ( m . keys ( ) ) ) [EOL] [EOL] [EOL] @ params ( [string] , examples ) def test_input_outputs ( func , arg ) : [EOL] actual_no_dask = func ( arg ) [EOL] actual_dask = apply ( db . from_sequence ( arg , npartitions = [number] ) , func ) . compute ( ) [EOL] [EOL] assert actual_dask == actual_no_dask [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Iterator , List , Counter , Any [EOL] import typing [EOL] import chmp [EOL] import collections [EOL] [docstring] [EOL] from __future__ import print_function , division , absolute_import [EOL] [EOL] import collections [EOL] import itertools as it [EOL] import math [EOL] [EOL] import toolz [EOL] from toolz import curry , curried [EOL] [EOL] __all__ = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , ] [EOL] [EOL] [EOL] def apply ( transformation , obj ) : [EOL] [docstring] [EOL] return rules ( obj , transformation ) [EOL] [EOL] [EOL] class RuleSet ( object ) : [EOL] def __init__ ( self , rules = ( ) ) : [EOL] self . rules = list ( rules ) [EOL] [EOL] def add ( self , match , apply , help = None ) : [EOL] self . rules . append ( dict ( match = match , apply = apply , help = help ) ) [EOL] [EOL] def __or__ ( self , other ) : [EOL] return RuleSet ( self . rules + other . rules ) [EOL] [EOL] def __call__ ( self , * args ) : [EOL] for rule in self . rules : [EOL] match = rule [ [string] ] [EOL] does_match = match ( self , * args ) [EOL] [EOL] if does_match : [EOL] apply = rule [ [string] ] [EOL] return apply ( self , * args ) [EOL] [EOL] raise RuntimeWarning ( [string] ) [EOL] [EOL] [EOL] def eq ( obj ) : [EOL] if isinstance ( obj , curry ) : [EOL] return lambda _ , other , __ : isinstance ( other , curry ) and other . func == obj . func [EOL] [EOL] return lambda _ , other , __ : other == obj [EOL] [EOL] [EOL] def a ( t ) : [EOL] return lambda _ , other , __ : isinstance ( other , t ) [EOL] [EOL] [EOL] def _raise ( exc , * args , ** kwargs ) : [EOL] def impl ( * _ , ** __ ) : [EOL] raise exc ( * args , ** kwargs ) [EOL] [EOL] return impl [EOL] [EOL] [EOL] class DaskDict ( object ) : [EOL] def __init__ ( self , items ) : [EOL] if isinstance ( items , DaskDict ) : [EOL] items = items . _items [EOL] [EOL] self . _items = items [EOL] [EOL] def items ( self ) : [EOL] return self . _items [EOL] [EOL] def keys ( self ) : [EOL] return self . _items . map ( lambda t : t [ [number] ] ) [EOL] [EOL] def values ( self ) : [EOL] return self . _items . map ( lambda t : t [ [number] ] ) [EOL] [EOL] def copy ( self ) : [EOL] [docstring] [EOL] return self [EOL] [EOL] def compute ( self , ** kwargs ) : [EOL] return dict ( self . _items . compute ( ** kwargs ) ) [EOL] [EOL] [EOL] class DaskCounter ( DaskDict ) : [EOL] def _call ( self , func ) : [EOL] def impl ( items ) : [EOL] counter = collections . Counter ( ) [EOL] for k , v in items : [EOL] counter [ k ] = v [EOL] return func ( counter ) [EOL] [EOL] return self . _items . repartition ( [number] ) . map_partitions ( impl ) [EOL] [EOL] def elements ( self ) : [EOL] return self . _call ( lambda obj : list ( obj . elements ( ) ) ) [EOL] [EOL] def most_common ( self , n ) : [EOL] return self . _call ( lambda obj : list ( obj . most_common ( n ) ) ) [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] stdlib_rules = RuleSet ( ) [EOL] [EOL] stdlib_rules . add ( eq ( any ) , lambda _ , __ , obj : obj . any ( ) ) [EOL] stdlib_rules . add ( eq ( all ) , lambda _ , __ , obj : obj . all ( ) ) [EOL] stdlib_rules . add ( eq ( min ) , lambda _ , __ , obj : obj . min ( ) ) [EOL] stdlib_rules . add ( eq ( max ) , lambda _ , __ , obj : obj . max ( ) ) [EOL] stdlib_rules . add ( eq ( sum ) , lambda _ , __ , obj : obj . sum ( ) ) [EOL] stdlib_rules . add ( eq ( len ) , lambda _ , __ , obj : obj . count ( ) ) [EOL] stdlib_rules . add ( eq ( set ) , lambda _ , __ , obj : obj . distinct ( ) ) [EOL] stdlib_rules . add ( eq ( list ) , lambda _ , __ , obj : obj ) [EOL] stdlib_rules . add ( eq ( dict ) , lambda _ , __ , obj : DaskDict ( obj ) ) [EOL] stdlib_rules . add ( eq ( dict . items ) , lambda _ , __ , obj : DaskDict ( obj ) . items ( ) ) [EOL] stdlib_rules . add ( eq ( it . chain . from_iterable ) , lambda _ , __ , obj : obj . flatten ( ) ) [EOL] stdlib_rules . add ( eq ( collections . Counter ) , lambda _ , __ , obj : DaskCounter ( obj . frequencies ( ) ) ) [EOL] [EOL] [comment] [EOL] stdlib_rules . add ( eq ( sorted ) , lambda _ , __ , obj : obj . repartition ( [number] ) . map_partitions ( sorted ) ) [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] def _map_items ( impl ) : [EOL] [docstring] [EOL] return lambda _ , f , o : DaskDict ( DaskDict ( o ) . items ( ) . map ( lambda t : impl ( f . args [ [number] ] , t [ [number] ] , t [ [number] ] ) ) ) [EOL] [EOL] [EOL] def _filter_items ( impl ) : [EOL] [docstring] [EOL] return lambda _ , f , o : DaskDict ( DaskDict ( o ) . items ( ) . filter ( lambda t : impl ( f . args [ [number] ] , t [ [number] ] , t [ [number] ] ) ) ) [EOL] [EOL] [EOL] def _toolz_item_filter ( _ , func , obj ) : [EOL] return DaskDict ( DaskDict ( obj ) . items ( ) . filter ( func . args [ [number] ] ) ) [EOL] [EOL] [EOL] def _toolz_join ( _ , func , obj ) : [EOL] [comment] [EOL] def impl ( leftkey , leftseq , rightkey ) : [EOL] return obj . join ( leftseq , on_self = rightkey , on_other = leftkey ) [EOL] [EOL] return impl ( * func . args , ** func . keywords ) [EOL] [EOL] [EOL] def _call ( impl , f ) : [EOL] return impl ( * f . args , ** f . keywords ) [EOL] [EOL] [EOL] toolz_rules = RuleSet ( ) [EOL] toolz_rules . add ( eq ( curried . map ) , lambda _ , f , o : _call ( o . map , f ) ) [EOL] toolz_rules . add ( eq ( curried . filter ) , lambda _ , f , o : _call ( o . filter , f ) ) [EOL] toolz_rules . add ( eq ( curried . pluck ) , lambda _ , f , o : _call ( o . pluck , f ) ) [EOL] toolz_rules . add ( eq ( curried . join ) , _toolz_join ) [EOL] toolz_rules . add ( eq ( curried . countby ) , lambda _ , f , o : DaskDict ( _call ( o . map , f ) . frequencies ( ) ) ) [EOL] toolz_rules . add ( eq ( curried . groupby ) , lambda _ , f , o : DaskDict ( _call ( o . groupby , f ) ) ) [EOL] toolz_rules . add ( eq ( curried . keymap ) , _map_items ( lambda f , k , v : ( f ( k ) , v ) ) ) [EOL] toolz_rules . add ( eq ( curried . valmap ) , _map_items ( lambda f , k , v : ( k , f ( v ) ) ) ) [EOL] toolz_rules . add ( eq ( curried . keyfilter ) , _filter_items ( lambda f , k , v : f ( k ) ) ) [EOL] toolz_rules . add ( eq ( curried . valfilter ) , _filter_items ( lambda f , k , v : f ( v ) ) ) [EOL] toolz_rules . add ( eq ( curried . itemfilter ) , _toolz_item_filter ) [EOL] toolz_rules . add ( eq ( curried . mapcat ) , lambda _ , f , o : o . map ( f . args [ [number] ] ) . flatten ( ) ) [EOL] toolz_rules . add ( eq ( curried . random_sample ) , lambda _ , f , o : _call ( o . random_sample , f ) ) [EOL] toolz_rules . add ( eq ( curried . reduce ) , lambda _ , f , o : _call ( o . fold , f ) ) [EOL] toolz_rules . add ( eq ( curried . reduceby ) , lambda _ , f , o : DaskDict ( _call ( o . foldby , f ) ) ) [EOL] toolz_rules . add ( eq ( curried . remove ) , lambda _ , f , o : _call ( o . remove , f ) ) [EOL] toolz_rules . add ( eq ( curried . topk ) , lambda _ , f , o : _call ( o . topk , f ) ) [EOL] toolz_rules . add ( eq ( curried . unique ) , lambda _ , f , o : _call ( o . distinct , f ) ) [EOL] toolz_rules . add ( eq ( toolz . unique ) , lambda _ , __ , o : o . distinct ( ) ) [EOL] [EOL] toolz_rules . add ( eq ( curried . accumulate ) , _raise ( NotImplementedError ) ) [EOL] toolz_rules . add ( eq ( curried . assoc ) , _raise ( NotImplementedError ) ) [EOL] toolz_rules . add ( eq ( curried . assoc_in ) , _raise ( NotImplementedError ) ) [EOL] toolz_rules . add ( eq ( curried . cons ) , _raise ( NotImplementedError ) ) [EOL] toolz_rules . add ( eq ( curried . do ) , _raise ( NotImplementedError ) ) [EOL] toolz_rules . add ( eq ( curried . drop ) , _raise ( NotImplementedError ) ) [EOL] toolz_rules . add ( eq ( curried . excepts ) , _raise ( NotImplementedError ) ) [EOL] toolz_rules . add ( eq ( curried . get ) , _raise ( NotImplementedError ) ) [EOL] toolz_rules . add ( eq ( curried . get_in ) , _raise ( NotImplementedError ) ) [EOL] toolz_rules . add ( eq ( curried . interpose ) , _raise ( NotImplementedError ) ) [EOL] toolz_rules . add ( eq ( curried . iterate ) , _raise ( NotImplementedError ) ) [EOL] toolz_rules . add ( eq ( curried . nth ) , _raise ( NotImplementedError ) ) [EOL] toolz_rules . add ( eq ( curried . partial ) , _raise ( NotImplementedError ) ) [EOL] toolz_rules . add ( eq ( curried . partition ) , _raise ( NotImplementedError ) ) [EOL] toolz_rules . add ( eq ( curried . partition_all ) , _raise ( NotImplementedError ) ) [EOL] toolz_rules . add ( eq ( curried . partitionby ) , _raise ( NotImplementedError ) ) [EOL] toolz_rules . add ( eq ( curried . sliding_window ) , _raise ( NotImplementedError ) ) [EOL] toolz_rules . add ( eq ( curried . sorted ) , _raise ( NotImplementedError ) ) [EOL] toolz_rules . add ( eq ( curried . tail ) , _raise ( NotImplementedError ) ) [EOL] toolz_rules . add ( eq ( curried . take ) , _raise ( NotImplementedError ) ) [EOL] toolz_rules . add ( eq ( curried . take_nth ) , _raise ( NotImplementedError ) ) [EOL] toolz_rules . add ( eq ( curried . update_in ) , _raise ( NotImplementedError ) ) [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] class reduction ( object ) : [EOL] [docstring] [EOL] [EOL] pass [EOL] [EOL] [EOL] def mean ( l ) : [EOL] [docstring] [EOL] l = iter ( l ) [EOL] [EOL] s0 = [number] [EOL] try : [EOL] s1 = next ( l ) [EOL] [EOL] except StopIteration : [EOL] raise RuntimeError ( [string] ) [EOL] [EOL] for x in l : [EOL] s1 += x [EOL] s0 += [number] [EOL] [EOL] return s1 / s0 [EOL] [EOL] [EOL] def var ( * args , ** kwargs ) : [EOL] if not args : [EOL] return _var ( ** kwargs ) [EOL] [EOL] return _var ( ** kwargs ) ( * args ) [EOL] [EOL] [EOL] def std ( * args , ** kwargs ) : [EOL] if not args : [EOL] return _std ( ** kwargs ) [EOL] [EOL] return _std ( ** kwargs ) ( * args ) [EOL] [EOL] [EOL] class _var ( object ) : [EOL] def __init__ ( self , ddof = [number] ) : [EOL] self . ddof = ddof [EOL] [EOL] def __call__ ( self , seq ) : [EOL] s2 , s1 , s0 = [number] , [number] , [number] [EOL] [EOL] for x in seq : [EOL] s2 += x ** [number] [EOL] s1 += x [EOL] s0 += [number] [EOL] [EOL] return ( ( s2 / s0 ) - ( s1 / s0 ) ** [number] ) * s0 / ( s0 - self . ddof ) [EOL] [EOL] [EOL] class _std ( object ) : [EOL] def __init__ ( self , ddof = [number] ) : [EOL] self . ddof = ddof [EOL] [EOL] def __call__ ( self , seq ) : [EOL] return math . sqrt ( _var ( self . ddof ) ( seq ) ) [EOL] [EOL] [EOL] reduction_rules = RuleSet ( ) [EOL] reduction_rules . add ( eq ( mean ) , lambda _ , __ , o : o . mean ( ) ) [EOL] reduction_rules . add ( a ( _var ) , lambda _ , f , o : o . var ( f . ddof ) ) [EOL] reduction_rules . add ( a ( _std ) , lambda _ , f , o : o . std ( f . ddof ) ) [EOL] reduction_rules . add ( eq ( var ) , lambda _ , f , o : o . var ( ) ) [EOL] reduction_rules . add ( eq ( std ) , lambda _ , f , o : o . std ( ) ) [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] class chained ( object ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , * funcs ) : [EOL] self . funcs = funcs [EOL] [EOL] def __call__ ( self , obj ) : [EOL] for func in self . funcs : [EOL] obj = func ( obj ) [EOL] [EOL] return obj [EOL] [EOL] def __repr__ ( self ) : [EOL] return [string] . format ( [string] . join ( repr ( func ) for func in self . funcs ) ) [EOL] [EOL] def __iter__ ( self ) : [EOL] return iter ( self . funcs ) [EOL] [EOL] [EOL] def _db_chained ( rules , chain , obj ) : [EOL] for func in chain : [EOL] obj = rules ( func , obj ) [EOL] [EOL] return obj [EOL] [EOL] [EOL] class repartition ( object ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , n ) : [EOL] self . n = n [EOL] [EOL] def __call__ ( self , obj ) : [EOL] return obj [EOL] [EOL] [EOL] extension_rules = RuleSet ( ) [EOL] extension_rules . add ( a ( chained ) , _db_chained ) [EOL] extension_rules . add ( a ( repartition ) , lambda _ , f , o : o . repartition ( f . n ) ) [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] rules = stdlib_rules | toolz_rules | reduction_rules | extension_rules [EOL] rules . add ( lambda _ , func , __ : callable ( func ) , lambda _ , func , obj : func ( obj ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $collections.Counter[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $collections.Counter[typing.Any]$ 0 0 0 0 0 0 0 0 0 $collections.Counter[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 $chmp.src.chmp.distributed.RuleSet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $chmp.src.chmp.distributed.RuleSet$ 0 $chmp.src.chmp.distributed.RuleSet$ 0 $chmp.src.chmp.distributed.RuleSet$ 0 $chmp.src.chmp.distributed.RuleSet$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from setuptools import setup [EOL] [EOL] setup ( name = [string] , version = [string] , description = [string] , author = [string] , author_email = [string] , license = [string] , packages = [ [string] ] , package_dir = { [string] : [string] } , install_requires = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , ] , classifiers = [ [string] , [string] , [string] , ] , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import List , Set , Tuple , Any [EOL] import typing [EOL] import logging [EOL] import kwdetect [EOL] import KeywordDetection [EOL] import logging [EOL] [EOL] import numpy as np [EOL] import torch [EOL] import torch . nn . functional as F [EOL] [EOL] from python_speech_features import mfcc [EOL] [EOL] from . segmentation import compute_speechiness [EOL] from . util import DEFAULT_SAMPLERATE , label_encoding , load_sample [EOL] [EOL] [EOL] _logger = logging . getLogger ( __name__ ) [EOL] n_features = [number] [EOL] [EOL] [EOL] def batch_transform_samples ( samples ) : [EOL] batch = [ mfcc ( sample , DEFAULT_SAMPLERATE , winlen = [number] , winstep = [number] , numcep = n_features ) for sample in samples ] [EOL] samples , lengths = pad_sequences ( batch ) [EOL] [EOL] return ( torch . as_tensor ( samples , dtype = torch . float32 ) , torch . as_tensor ( lengths , dtype = torch . long ) , ) [EOL] [EOL] [EOL] def transform_x ( desc ) : [EOL] sample = load_sample ( desc [ [string] ] ) [EOL] return mfcc ( sample , DEFAULT_SAMPLERATE , winlen = [number] , winstep = [number] , numcep = n_features ) [EOL] [EOL] [EOL] def transform_y ( desc ) : [EOL] return label_encoding . get ( desc [ [string] ] , - [number] ) [EOL] [EOL] [EOL] def batch_transform_x ( descs ) : [EOL] batch = [ transform_x ( desc ) for desc in descs ] [EOL] samples , lengths = pad_sequences ( batch ) [EOL] [EOL] return ( torch . as_tensor ( samples , dtype = torch . float32 ) , torch . as_tensor ( lengths , dtype = torch . long ) , ) [EOL] [EOL] [EOL] def batch_transform_y ( descs ) : [EOL] batch = [ transform_y ( desc ) for desc in descs ] [EOL] return torch . as_tensor ( np . asarray ( batch , dtype = np . int64 ) ) [EOL] [EOL] [EOL] def batch_transform_xy ( desc ) : [EOL] return batch_transform_x ( desc ) , batch_transform_y ( desc ) [EOL] [EOL] [EOL] def extract_single_block ( sample , block = [number] ) : [EOL] if sample . ndim == [number] : [EOL] sample = np . mean ( sample , axis = [number] ) [EOL] [EOL] _ , blocks = compute_speechiness ( sample ) [EOL] [EOL] if len ( blocks ) == [number] : [EOL] raise ValueError ( [string] ) [EOL] [EOL] elif len ( blocks ) > [number] : [EOL] print ( [string] ) [EOL] [EOL] return sample [ blocks [ block ] ] [EOL] [EOL] [EOL] class KeywordModel ( torch . nn . Module ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , n_features , n_classes , kernel_size = [number] , dilation_rate = [number] , n_hidden = [number] , n_layers = [number] , ) : [EOL] super ( ) . __init__ ( ) [EOL] self . cnn_stack = build_cnn_stack ( n_features , n_hidden , n_hidden = n_hidden , kernel_size = kernel_size , dilation_rate = dilation_rate , n_layers = n_layers , ) [EOL] self . gru_pooling = GRUPooling ( n_hidden , n_hidden ) [EOL] self . final = torch . nn . Linear ( n_hidden , n_classes ) [EOL] [EOL] def forward ( self , inputs , lengths ) : [EOL] [comment] [EOL] [comment] [EOL] res = inputs . permute ( [number] , [number] , [number] ) [EOL] res = self . cnn_stack ( res ) [EOL] [EOL] [comment] [EOL] res , unsort_indices = pack_conv_output ( res , lengths ) [EOL] res = self . gru_pooling ( res ) [EOL] res = res [ unsort_indices ] [EOL] [EOL] res = F . relu ( res ) [EOL] res = self . final ( res ) [EOL] [EOL] return res [EOL] [EOL] [EOL] def build_cnn_stack ( n_input , n_output , * , kernel_size = [number] , dilation_rate = [number] , n_hidden = [number] , n_layers = [number] ) : [EOL] input_dims = [ n_input ] + ( n_layers - [number] ) * [ n_hidden ] [EOL] output_dims = ( n_layers - [number] ) * [ n_hidden ] + [ n_output ] [EOL] [EOL] cnn_stack = [ ] [EOL] [EOL] for input_dim , output_dim in zip ( input_dims , output_dims ) : [EOL] cnn_stack += [ torch . nn . ConstantPad1d ( ( dilation_rate * ( kernel_size - [number] ) , [number] ) , [number] ) , torch . nn . Conv1d ( input_dim , output_dim , dilation = dilation_rate , kernel_size = kernel_size ) , torch . nn . ReLU ( ) , ] [EOL] [EOL] return torch . nn . Sequential ( * cnn_stack ) [EOL] [EOL] [EOL] class GRUPooling ( torch . nn . Module ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , in_features , out_features , n_layers = [number] ) : [EOL] super ( ) . __init__ ( ) [EOL] self . gru = torch . nn . GRU ( in_features , out_features , num_layers = n_layers ) [EOL] [EOL] def forward ( self , seq ) : [EOL] _ , hn = self . gru ( seq ) [EOL] return hn [ - [number] ] [EOL] [EOL] [EOL] def pack_conv_output ( inputs , lengths , sorted = False ) : [EOL] [comment] [EOL] [comment] [EOL] [EOL] if not sorted : [EOL] _ , sort_indices = torch . sort ( lengths , descending = True ) [EOL] inputs = inputs [ sort_indices ] [EOL] lengths = lengths [ sort_indices ] [EOL] _ , unsort_indices = torch . sort ( sort_indices ) [EOL] [EOL] else : [EOL] unsort_indices = torch . arange ( len ( inputs ) ) [EOL] [EOL] seq = torch . nn . utils . rnn . pack_padded_sequence ( inputs . permute ( [number] , [number] , [number] ) , lengths , ) [EOL] [EOL] return seq , unsort_indices [EOL] [EOL] [EOL] def pad_sequences ( * sequence_batches , dtype = [string] , length = None , length_dtype = [string] , factory = None ) : [EOL] [docstring] [EOL] if length is None : [EOL] length = _pad_sequences_determine_max_lengths ( sequence_batches ) [EOL] [EOL] if factory is None : [EOL] factory = np . zeros [EOL] [EOL] length = ensure_tuple ( length , len ( sequence_batches ) ) [EOL] dtype = ensure_tuple ( dtype , len ( sequence_batches ) ) [EOL] [EOL] tail_shapes = _pad_sequences_determine_tail_shapes ( sequence_batches ) [EOL] batch_size = _pad_sequences_determine_batch_size ( sequence_batches ) [EOL] [EOL] result = [ ] [EOL] [EOL] for sequence_batch , l , dt , ts in zip ( sequence_batches , length , dtype , tail_shapes ) : [EOL] sequence_padded = factory ( ( batch_size , l , * ts ) , dtype = dt ) [EOL] sequence_length = factory ( batch_size , dtype = length_dtype ) [EOL] [EOL] for i , sequence in enumerate ( sequence_batch ) : [EOL] sequence_padded [ i , : len ( sequence ) ] = sequence [EOL] sequence_length [ i ] = len ( sequence ) [EOL] [EOL] result += [ sequence_padded , sequence_length ] [EOL] [EOL] return tuple ( result ) [EOL] [EOL] [EOL] def _pad_sequences_determine_max_lengths ( sequence_batches ) : [EOL] return max ( sequence . shape [ [number] ] for sequence_batch in sequence_batches for sequence in sequence_batch ) [EOL] [EOL] [EOL] def _pad_sequences_determine_tail_shapes ( sequence_batches ) : [EOL] tail_shapes = [ { tuple ( sequence . shape [ [number] : ] ) for sequence in sequence_batch } for sequence_batch in sequence_batches ] [EOL] [EOL] for idx , tail_shape in enumerate ( tail_shapes ) : [EOL] if len ( tail_shape ) != [number] : [EOL] raise RuntimeError ( f" [string] { idx } [string] { tail_shape }" ) [EOL] [EOL] [comment] [EOL] tail_shapes = [ tail_shape for tail_shape , in tail_shapes ] [EOL] [EOL] return tail_shapes [EOL] [EOL] [EOL] def _pad_sequences_determine_batch_size ( sequence_batches ) : [EOL] batch_size = { len ( sequence_batch ) for sequence_batch in sequence_batches } [EOL] [EOL] if len ( batch_size ) != [number] : [EOL] raise RuntimeError ( f" [string] { batch_size }" ) [EOL] [EOL] batch_size , = batch_size [EOL] [EOL] return batch_size [EOL] [EOL] [EOL] def ensure_tuple ( obj , length ) : [EOL] if not isinstance ( obj , tuple ) : [EOL] return tuple ( obj for _ in range ( length ) ) [EOL] [EOL] return obj [EOL] [EOL] [EOL] def get_number_of_samples ( values ) : [EOL] sample_counts = { len ( item ) for item in values if item is not None } [EOL] if len ( sample_counts ) != [number] : [EOL] raise ValueError ( [string] ) [EOL] [EOL] n_samples , = sample_counts [EOL] return n_samples [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $20170813-KeywordDetection.chmp-app-kwdetect.src.chmp.app.kwdetect.model.GRUPooling$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Tuple , Any [EOL] import typing [EOL] import queue as _queue [EOL] [EOL] import numpy as np [EOL] import numba [EOL] [EOL] from scipy . ndimage . measurements import label [EOL] [EOL] from . util import DEFAULT_SAMPLERATE [EOL] [EOL] [EOL] class StreamProcessor ( object ) : [EOL] [docstring] [EOL] def __init__ ( self , queue = None , samplerate = DEFAULT_SAMPLERATE ) : [EOL] if queue is None : [EOL] queue = _queue . Queue ( ) [EOL] [EOL] self . queue = queue [EOL] self . in_speech = False [EOL] self . buffer = [ ] [EOL] self . samplerate = samplerate [EOL] [EOL] def process ( self , indata ) : [EOL] was_in_speech = self . in_speech [EOL] self . in_speech , blocks = compute_speechiness ( indata , samplerate = self . samplerate , in_speech = self . in_speech , ) [EOL] [EOL] [comment] [EOL] if was_in_speech and self . in_speech and len ( blocks ) == [number] : [EOL] self . buffer . extend ( indata [ b ] for b in blocks ) [EOL] [EOL] else : [EOL] [comment] [EOL] if was_in_speech : [EOL] self . buffer . extend ( indata [ b ] for b in blocks [ : [number] ] ) [EOL] self . finish ( ) [EOL] blocks = blocks [ [number] : ] [EOL] [EOL] [comment] [EOL] if self . in_speech : [EOL] b = blocks [ - [number] ] [EOL] self . buffer . append ( indata [ b ] ) [EOL] blocks = blocks [ : - [number] ] [EOL] [EOL] [comment] [EOL] for b in blocks : [EOL] self . queue . put ( indata [ b ] , block = False ) [EOL] [EOL] def finish ( self ) : [EOL] if not self . buffer : [EOL] return [EOL] [EOL] self . queue . put ( np . concatenate ( self . buffer ) , block = False ) [EOL] self . buffer = [ ] [EOL] [EOL] [EOL] def compute_speechiness ( sample , samplerate = DEFAULT_SAMPLERATE , in_speech = False ) : [EOL] [docstring] [EOL] speechiness = np . convolve ( abs ( sample ) , np . ones ( [number] ) / [number] , mode = [string] ) [EOL] result = np . zeros_like ( speechiness , dtype = np . int8 ) [EOL] in_speech = _compute_speechiness ( np . asarray ( speechiness , dtype = np . float32 ) , [number] , samplerate // [number] , out = result , in_speech = in_speech , ) [EOL] [EOL] indices , num_features = label ( result ) [EOL] [EOL] blocks = [ ] [EOL] for feature in range ( [number] , num_features + [number] ) : [EOL] block , = np . nonzero ( indices == feature ) [EOL] blocks . append ( block ) [EOL] [EOL] return in_speech , blocks [EOL] [EOL] [EOL] @ numba . jit ( [string] , nopython = True , nogil = True ) def _compute_speechiness ( speechiness , threshold , advance , out , in_speech = False ) : [EOL] if not in_speech : [EOL] idx = [number] [EOL] start = [number] [EOL] end = [number] [EOL] [EOL] else : [EOL] idx = [number] [EOL] start = [number] [EOL] end = advance [EOL] [EOL] while idx < len ( speechiness ) : [EOL] above_threshold = ( speechiness [ idx ] > threshold ) [EOL] [EOL] if not in_speech and above_threshold : [EOL] start = max ( [number] , idx - advance ) [EOL] end = min ( len ( speechiness ) - [number] , start + advance ) [EOL] in_speech = True [EOL] [EOL] if in_speech and above_threshold : [EOL] end = idx + advance [EOL] idx += [number] [EOL] [EOL] elif in_speech and not above_threshold : [EOL] idx += [number] [EOL] out [ start : end ] = [number] [EOL] in_speech = False [EOL] [EOL] idx += [number] [EOL] [EOL] if in_speech : [EOL] out [ start : len ( out ) - [number] ] = [number] [EOL] [EOL] return out [ len ( out ) - [number] ] == [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import List , Dict , Any [EOL] import typing [EOL] import os [EOL] import os . path [EOL] import uuid [EOL] [EOL] import numpy as np [EOL] import sounddevice as sd [EOL] import soundfile as sf [EOL] import torch [EOL] [EOL] [EOL] DEFAULT_SAMPLERATE = [number] [EOL] [EOL] labels = [ [string] , [string] , [string] , [string] , [string] ] [EOL] [EOL] label_encoding = { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] } [EOL] [EOL] label_decoding = { v : k for k , v in label_encoding . items ( ) } [EOL] [EOL] [EOL] def play_file ( fname ) : [EOL] data , sr = sf . read ( fname ) [EOL] sd . play ( data , sr , blocking = True ) [EOL] [EOL] [EOL] def load_sample ( fname ) : [EOL] sample , _ = sf . read ( fname ) [EOL] [EOL] if sample . ndim == [number] : [EOL] sample = np . mean ( sample , axis = [number] ) [EOL] [EOL] return sample [EOL] [EOL] [EOL] def load_optional_model ( model ) : [EOL] if model is None : [EOL] return None [EOL] [EOL] return torch . load ( model ) [EOL] [EOL] [EOL] def unique_filename ( * p ) : [EOL] * tail , head = p [EOL] [EOL] while True : [EOL] fname = os . path . join ( * tail , head . format ( uuid . uuid4 ( ) ) ) [EOL] [EOL] if not os . path . exists ( fname ) : [EOL] return fname [EOL] [EOL] [EOL] def fit ( s , l ) : [EOL] return s . ljust ( l ) [ : l ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.int,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] import logging [EOL] import kwdetect [EOL] import KeywordDetection [EOL] [docstring] [EOL] import logging [EOL] [EOL] import janus [EOL] import numpy as np [EOL] import sounddevice as sd [EOL] import soundfile as sf [EOL] [EOL] from . model import batch_transform_samples [EOL] from . util import DEFAULT_SAMPLERATE , label_decoding as default_label_decoding , unique_filename [EOL] from . segmentation import StreamProcessor [EOL] [EOL] _logger = logging . getLogger ( ) [EOL] [EOL] [EOL] class unset : [EOL] pass [EOL] [EOL] [EOL] async def detect ( model , samplerate = DEFAULT_SAMPLERATE , label_decoding = None , sample_target = None , start_token = unset , ) : [EOL] if label_decoding is None : [EOL] label_decoding = default_label_decoding [EOL] [EOL] async for sample in record ( samplerate = samplerate , start_token = start_token ) : [EOL] if sample is start_token : [EOL] yield sample [EOL] [EOL] else : [EOL] label = predict_label ( model , sample , label_decoding = label_decoding ) [EOL] save_sample ( sample_target , sample , samplerate = samplerate ) [EOL] yield label [EOL] [EOL] [EOL] def predict_label ( model , sample , * , label_decoding ) : [EOL] if model is None : [EOL] return [string] [EOL] [EOL] padded , lengths = batch_transform_samples ( [ sample ] ) [EOL] [EOL] pred = model . predict ( ( padded , lengths ) ) [EOL] pred = np . argmax ( pred , axis = [number] ) [EOL] [EOL] return label_decoding [ pred [ [number] ] ] [EOL] [EOL] [EOL] def save_sample ( sample_target , sample , samplerate = DEFAULT_SAMPLERATE ) : [EOL] if sample_target is None : [EOL] return [EOL] [EOL] fname = unique_filename ( sample_target , [string] ) [EOL] _logger . info ( [string] , fname ) [EOL] sf . write ( fname , sample , samplerate = samplerate ) [EOL] [EOL] [EOL] async def record ( samplerate = DEFAULT_SAMPLERATE , start_token = unset ) : [EOL] [docstring] [EOL] queue = janus . Queue ( ) [EOL] [EOL] processor = StreamProcessor ( queue = queue . sync_q , samplerate = samplerate ) [EOL] [EOL] def callback ( indata , _outdata , _frames , _time , _status ) : [EOL] indata = np . mean ( indata , axis = [number] ) [EOL] processor . process ( indata ) [EOL] [EOL] try : [EOL] with sd . Stream ( samplerate = samplerate , blocksize = ( [number] * samplerate ) // [number] , channels = [number] , callback = callback ) : [EOL] _logger . info ( [string] ) [EOL] if start_token is not unset : [EOL] yield start_token [EOL] [EOL] while True : [EOL] yield await queue . async_q . get ( ) [EOL] [EOL] finally : [EOL] _logger . info ( [string] ) [EOL] processor . finish ( ) [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , Any [EOL] import typing [EOL] import logging [EOL] import asyncio [EOL] import asyncio [EOL] import json [EOL] import logging [EOL] import os . path [EOL] import random [EOL] [EOL] import click [EOL] import sounddevice as sd [EOL] import soundfile as sf [EOL] from chmp . label import write_label , find_unlabeled [EOL] from chmp . app . kwdetect . aio import detect as _async_detect [EOL] from chmp . app . kwdetect . util import load_optional_model [EOL] [EOL] [EOL] _logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] @ click . group ( ) def main ( ) : [EOL] pass [EOL] [EOL] [EOL] @ main . command ( ) @ click . argument ( [string] ) @ click . option ( [string] ) def detect ( target , model ) : [EOL] [docstring] [EOL] loop = asyncio . get_event_loop ( ) [EOL] [EOL] [comment] [EOL] loop . set_exception_handler ( print ) [EOL] loop . run_until_complete ( _detect ( target , model ) ) [EOL] [EOL] [EOL] async def _detect ( target , model ) : [EOL] _logger . info ( [string] ) [EOL] model = load_optional_model ( model ) [EOL] [EOL] _logger . info ( [string] ) [EOL] async for label in _async_detect ( model , sample_target = target ) : [EOL] print ( [string] , label ) [EOL] [EOL] [EOL] @ main . command ( ) @ click . argument ( [string] ) @ click . option ( [string] ) def label ( path , labels ) : [EOL] [docstring] [EOL] with open ( labels , [string] ) as fobj : [EOL] labels = json . load ( fobj ) [EOL] [EOL] label_decoding = { int ( key ) : label for label , key in labels . items ( ) } [EOL] label_decoding [ - [number] ] = [string] [EOL] [EOL] unlabeled_files = find_unlabeled ( os . path . join ( path , [string] ) ) [EOL] [EOL] if not unlabeled_files : [EOL] print ( [string] ) [EOL] return [EOL] [EOL] random . shuffle ( unlabeled_files ) [EOL] [EOL] print ( f' [string] { len ( unlabeled_files ) } [string] ' ) [EOL] print ( [string] ) [EOL] [EOL] while unlabeled_files : [EOL] try : [EOL] fname = unlabeled_files . pop ( ) [EOL] _label_example ( fname , label_decoding ) [EOL] [EOL] except KeyboardInterrupt : [EOL] print ( [string] ) [EOL] raise SystemExit ( [number] ) [EOL] [EOL] print ( [string] ) [EOL] [EOL] [EOL] def _label_example ( fname , label_decoding ) : [EOL] print ( f' [string] { fname }' ) [EOL] [EOL] sample , _ = sf . read ( fname ) [EOL] [EOL] while True : [EOL] sd . play ( sample , blocking = True ) [EOL] [EOL] label = _get_label_from_user ( label_decoding ) [EOL] [EOL] if label == [string] : [EOL] print ( [string] ) [EOL] return [EOL] [EOL] elif label == [string] : [EOL] continue [EOL] [EOL] else : [EOL] write_label ( fname , label = label , file = os . path . basename ( fname ) ) [EOL] return [EOL] [EOL] [EOL] def _get_label_from_user ( label_decoding ) : [EOL] print ( [string] , [string] . join ( f'{ label !r} [string] { code } [string] ' for code , label in label_decoding . items ( ) ) ) [EOL] while True : [EOL] user_input = input ( [string] ) [EOL] [EOL] if not user_input . strip ( ) : [EOL] return [string] [EOL] [EOL] try : [EOL] user_input = int ( user_input ) [EOL] [EOL] except ValueError : [EOL] print ( [string] ) [EOL] [EOL] else : [EOL] if user_input not in label_decoding : [EOL] print ( [string] ) [EOL] continue [EOL] [EOL] return label_decoding [ user_input ] [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] logging . basicConfig ( level = logging . INFO ) [EOL] main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Set , Any [EOL] import typing [EOL] import pytest [EOL] import torch [EOL] [EOL] from chmp . app . kwdetect . model import KeywordModel [EOL] [EOL] [EOL] def test_keyword_model_batch_shape ( ) : [EOL] inputs = torch . normal ( torch . zeros ( [number] , [number] , [number] ) , torch . ones ( [number] , [number] , [number] ) ) [EOL] lengths = torch . tensor ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) [EOL] [EOL] model = KeywordModel ( n_features = [number] , n_classes = [number] ) [EOL] model_params = { name for name , _ in model . named_parameters ( ) } [EOL] logits = model ( inputs , lengths ) [EOL] [EOL] assert logits . shape == ( [number] , [number] ) [EOL] [EOL] [comment] [EOL] assert get_params_with_grad ( model ) == set ( ) [EOL] logits . sum ( ) . backward ( ) [EOL] assert get_params_with_grad ( model ) == model_params [EOL] [EOL] [EOL] def test_keyword_model_sorting_works ( ) : [EOL] inputs = torch . normal ( torch . zeros ( [number] , [number] , [number] ) , torch . ones ( [number] , [number] , [number] ) ) [EOL] lengths = torch . tensor ( [ [number] , [number] , [number] , [number] , [number] ] ) [EOL] [EOL] [comment] [EOL] sort_indices = torch . tensor ( [ [number] , [number] , [number] , [number] , [number] ] ) [EOL] unsort_indices = torch . tensor ( [ [number] , [number] , [number] , [number] , [number] ] ) [EOL] [EOL] [comment] [EOL] model = KeywordModel ( n_features = [number] , n_classes = [number] ) [EOL] unsorted_logits = model ( inputs , lengths ) [EOL] [EOL] [comment] [EOL] sorted_logits = model ( inputs [ sort_indices ] , lengths [ sort_indices ] ) [EOL] sorted_logits = sorted_logits [ unsort_indices ] [EOL] [EOL] assert sorted_logits . detach ( ) . numpy ( ) == pytest . approx ( unsorted_logits . detach ( ) . numpy ( ) ) [EOL] [EOL] [EOL] def get_params_with_grad ( module ) : [EOL] return { name for name , param in module . named_parameters ( ) if param . grad is not None } [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from setuptools import setup [EOL] [EOL] [EOL] setup ( name = [string] , version = [string] , py_modules = [ [string] ] , package_dir = { [string] : [string] } , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from invoke import task [EOL] [EOL] [EOL] @ task ( ) def precommit ( c ) : [EOL] format ( c ) [EOL] test ( c ) [EOL] [EOL] [EOL] @ task ( ) def format ( c ) : [EOL] c . run ( [string] ) [EOL] [EOL] [EOL] @ task ( ) def test ( c ) : [EOL] c . run ( [string] ) [EOL] c . run ( [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from keep_odds import keep_odds [EOL] [EOL] [EOL] def test_keep_odds ( ) : [EOL] assert keep_odds ( [ [number] , [number] , [number] , [number] , [number] , [number] ] ) == [ [number] , [number] , [number] ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
def keep_odds ( iterable ) : [EOL] return [ item for item in iterable if item % [number] == [number] ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0