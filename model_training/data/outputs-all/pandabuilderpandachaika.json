[comment] [EOL] [comment] [EOL] from typing import List [EOL] import logging [EOL] import typing [EOL] import core [EOL] import os [EOL] import sys [EOL] [EOL] import django [EOL] import logging [EOL] [EOL] from django . conf import settings [EOL] [EOL] sys . path . append ( os . path . dirname ( __file__ ) ) [EOL] [EOL] os . environ . setdefault ( [string] , [string] ) [EOL] [EOL] django . setup ( ) [EOL] [EOL] from core . web . crawler import WebCrawler [EOL] [EOL] crawler_settings = settings . CRAWLER_SETTINGS [EOL] logger = logging . getLogger ( ) [EOL] [EOL] h = logging . StreamHandler ( stream = sys . stdout ) [EOL] h . setLevel ( logging . DEBUG ) [EOL] logger . addHandler ( h ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] argv = sys . argv [ [number] : ] [EOL] [EOL] web_crawler = WebCrawler ( crawler_settings ) [EOL] [EOL] web_crawler . start_crawling ( argv ) [EOL] [EOL] logger . removeHandler ( h ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 $logging.StreamHandler$ 0 0 0 0 0 0 0 0 0 0 0 0 $logging.StreamHandler$ 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 $logging.StreamHandler$ 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 $core.web.crawler.WebCrawler$ 0 0 0 0 0 0 0 $core.web.crawler.WebCrawler$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 $logging.Logger$ 0 0 0 $logging.StreamHandler$ 0 0
[comment] [EOL] import os [EOL] import sys [EOL] [EOL] if __name__ == [string] : [EOL] os . environ . setdefault ( [string] , [string] ) [EOL] [EOL] from django . core . management import execute_from_command_line [EOL] [EOL] execute_from_command_line ( sys . argv ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] from typing import List [EOL] import logging [EOL] import typing [EOL] import core [EOL] import os [EOL] import sys [EOL] [EOL] import django [EOL] import logging [EOL] [EOL] from django . conf import settings [EOL] [EOL] sys . path . append ( os . path . dirname ( __file__ ) ) [EOL] [EOL] os . environ . setdefault ( [string] , [string] ) [EOL] django . setup ( ) [EOL] [EOL] from core . local . foldercrawler import FolderCrawler [EOL] [EOL] crawler_settings = settings . CRAWLER_SETTINGS [EOL] logger = logging . getLogger ( ) [EOL] [EOL] h = logging . StreamHandler ( stream = sys . stdout ) [EOL] h . setLevel ( logging . DEBUG ) [EOL] logger . addHandler ( h ) [EOL] [EOL] if __name__ == [string] : [EOL] argv = sys . argv [ [number] : ] [EOL] [EOL] folder_crawler = FolderCrawler ( crawler_settings ) [EOL] [EOL] folder_crawler . start_crawling ( argv ) [EOL] [EOL] logger . removeHandler ( h ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 $logging.StreamHandler$ 0 0 0 0 0 0 0 0 0 0 0 0 $logging.StreamHandler$ 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 $logging.StreamHandler$ 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 $core.local.foldercrawler.FolderCrawler$ 0 0 0 0 0 0 0 $core.local.foldercrawler.FolderCrawler$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 $logging.Logger$ 0 0 0 $logging.StreamHandler$ 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0
from typing import Any , Dict , Tuple , Union , List [EOL] import core [EOL] import typing [EOL] import builtins [EOL] [docstring] [EOL] [EOL] [comment] [EOL] import os [EOL] from typing import Any , Dict [EOL] [EOL] from core . base . setup import Settings [EOL] from core . base . utilities import module_exists [EOL] [EOL] BASE_DIR = os . path . dirname ( os . path . dirname ( __file__ ) ) [EOL] [EOL] if [string] in os . environ : [EOL] crawler_settings = Settings ( load_from_disk = True , default_dir = os . environ [ [string] ] ) [EOL] else : [EOL] crawler_settings = Settings ( load_from_disk = True ) [EOL] [EOL] MAIN_LOGGER = crawler_settings . log_location [EOL] [EOL] if not os . path . exists ( os . path . dirname ( MAIN_LOGGER ) ) : [EOL] os . makedirs ( os . path . dirname ( MAIN_LOGGER ) ) [EOL] [EOL] [comment] [EOL] SECRET_KEY = crawler_settings . django_secret_key [EOL] [EOL] [comment] [EOL] DEBUG = crawler_settings . django_debug_mode [EOL] [EOL] [comment] [EOL] ALLOWED_HOSTS = [ [string] ] [EOL] [EOL] if crawler_settings . urls . behind_proxy : [EOL] USE_X_FORWARDED_HOST = True [EOL] SECURE_PROXY_SSL_HEADER = ( [string] , [string] ) [EOL] [EOL] LOGGING = { [string] : [number] , [string] : False , [string] : { [string] : { [string] : [string] [string] } , [string] : { [string] : [string] } , [string] : { [string] : [string] } , [string] : { [string] : [string] , [string] : [string] } , } , [string] : { [string] : { [string] : [string] , } , } , [string] : { [string] : { [string] : [string] , [string] : [string] , [string] : MAIN_LOGGER , [string] : [number] * [number] * [number] , [string] : [number] , [string] : [string] , [string] : [string] , } , [string] : { [string] : [string] , [string] : [ [string] ] , [string] : [string] , [string] : [string] } } , [string] : { [string] : { [string] : [ [string] , [string] ] , [string] : [string] if DEBUG else [string] } , [string] : { [string] : [ [string] , [string] ] , [string] : [string] if DEBUG else [string] } , [string] : { [string] : [ [string] , [string] ] , [string] : True , [string] : [string] , } , } } [EOL] [EOL] [EOL] [comment] [EOL] [EOL] INSTALLED_APPS = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , ] [EOL] [EOL] if module_exists ( [string] ) : [EOL] INSTALLED_APPS += [ [string] ] [EOL] [EOL] if module_exists ( [string] ) : [EOL] INSTALLED_APPS += [ [string] ] [EOL] [EOL] if DEBUG and module_exists ( [string] ) : [EOL] INSTALLED_APPS += [ [string] ] [EOL] [EOL] if DEBUG and module_exists ( [string] ) : [EOL] INSTALLED_APPS += [ [string] ] [EOL] TEST_RUNNER = [string] [EOL] NOSE_ARGS = [ [string] , [string] , [string] , ] [EOL] [EOL] MIDDLEWARE = [ [string] , [string] , [string] , [string] , [string] , [string] , ] [EOL] [EOL] STATICFILES_FINDERS = [ [string] , [string] ] [EOL] [EOL] STATICFILES_DIRS = ( os . path . join ( BASE_DIR , [string] ) , ) [EOL] [EOL] WEBPACK_LOADER = { [string] : { [string] : [string] , [string] : os . path . join ( BASE_DIR , [string] ) , } } [EOL] [EOL] if module_exists ( [string] ) : [EOL] STATICFILES_FINDERS += [ [string] ] [EOL] COMPRESS_FILTERS = { [string] : [ [string] , [string] ] , [string] : [ [string] ] } [EOL] COMPRESS_ENABLED = not DEBUG [EOL] COMPRESS_OFFLINE = True [EOL] [EOL] ROOT_URLCONF = [string] [EOL] [EOL] WSGI_APPLICATION = [string] [EOL] [EOL] [comment] [EOL] if DEBUG and module_exists ( [string] ) : [EOL] INTERNAL_IPS = [ [string] ] [EOL] DEBUG_TOOLBAR_PATCH_SETTINGS = False [EOL] MIDDLEWARE = [ [string] ] + MIDDLEWARE [EOL] [EOL] [EOL] [comment] [EOL] if crawler_settings . db_engine == [string] : [EOL] DATABASES = { [string] : { [string] : [string] , [string] : crawler_settings . database [ [string] ] , [string] : crawler_settings . database [ [string] ] , [string] : crawler_settings . database [ [string] ] , [string] : crawler_settings . database [ [string] ] , [string] : crawler_settings . database [ [string] ] , [string] : { [string] : [string] , [string] : [string] } , } } [EOL] elif crawler_settings . db_engine == [string] : [EOL] DATABASES = { [string] : { [string] : [string] , [string] : crawler_settings . database [ [string] ] , [string] : crawler_settings . database [ [string] ] , [string] : crawler_settings . database [ [string] ] , [string] : crawler_settings . database [ [string] ] , [string] : crawler_settings . database [ [string] ] , } } [EOL] else : [EOL] DATABASES = { [string] : { [string] : [string] , [string] : crawler_settings . database [ [string] ] , } } [EOL] [EOL] [comment] [EOL] [EOL] LANGUAGE_CODE = [string] [EOL] [EOL] TIME_ZONE = [string] [EOL] [EOL] USE_I18N = True [EOL] [EOL] USE_L10N = True [EOL] [EOL] USE_TZ = True [EOL] [EOL] [comment] [EOL] [EOL] FILE_UPLOAD_PERMISSIONS = [number] [EOL] [EOL] [comment] [EOL] [EOL] MAIN_URL = crawler_settings . urls . viewer_main_url [EOL] [EOL] STATIC_ROOT = os . path . join ( BASE_DIR , [string] ) [EOL] STATIC_URL = MAIN_URL . replace ( [string] , [string] ) + crawler_settings . urls . static_url [EOL] [EOL] MEDIA_ROOT = crawler_settings . MEDIA_ROOT [EOL] MEDIA_URL = MAIN_URL . replace ( [string] , [string] ) + crawler_settings . urls . media_url [EOL] [EOL] if MAIN_URL != [string] : [EOL] STATIC_URL = [string] + STATIC_URL [EOL] MEDIA_URL = [string] + MEDIA_URL [EOL] CSRF_COOKIE_PATH = [string] + MAIN_URL [EOL] SESSION_COOKIE_PATH = [string] + MAIN_URL [EOL] [EOL] LOGIN_URL = [string] [EOL] LOGOUT_URL = [string] [EOL] [EOL] TEMPLATES = [ { [string] : [string] , [string] : [ os . path . join ( BASE_DIR , [string] ) ] , [string] : True , [string] : { [string] : crawler_settings . django_debug_mode , [string] : [ [string] , [string] , [string] , [string] , ] } , } , ] [EOL] [EOL] [comment] [EOL] if crawler_settings . mail_logging . enable : [EOL] EMAIL_HOST = crawler_settings . mail_logging . mailhost [EOL] EMAIL_PORT = [number] [EOL] EMAIL_HOST_USER = crawler_settings . mail_logging . username [EOL] EMAIL_HOST_PASSWORD = crawler_settings . mail_logging . password [EOL] EMAIL_SUBJECT_PREFIX = crawler_settings . mail_logging . subject + [string] [EOL] SERVER_EMAIL = crawler_settings . mail_logging . from_ [EOL] ADMINS = [ ( [string] , crawler_settings . mail_logging . to ) , ] [EOL] EMAIL_USE_TLS = True [EOL] [comment] [EOL] [EOL] LOGGING [ [string] ] [ [string] ] = { [string] : [string] , [string] : [string] , [string] : [string] , } [EOL] [EOL] LOGGING [ [string] ] [ [string] ] = { [string] : [string] , [string] : [string] , [string] : [string] , } [EOL] [EOL] LOGGING [ [string] ] [ [string] ] [ [string] ] . append ( [string] ) [EOL] LOGGING [ [string] ] [ [string] ] [ [string] ] . append ( [string] ) [EOL] LOGGING [ [string] ] [ [string] ] [ [string] ] . append ( [string] ) [EOL] [EOL] if crawler_settings . elasticsearch . enable : [EOL] from elasticsearch import Elasticsearch , RequestsHttpConnection [EOL] ES_CLIENT = Elasticsearch ( [ crawler_settings . elasticsearch . url ] , connection_class = RequestsHttpConnection ) [EOL] ES_ENABLED = True [EOL] else : [EOL] ES_CLIENT = None [EOL] ES_ENABLED = False [EOL] [EOL] MAX_RESULT_WINDOW = crawler_settings . elasticsearch . max_result_window [EOL] ES_AUTOREFRESH = crawler_settings . elasticsearch . auto_refresh [EOL] ES_AUTOREFRESH_GALLERY = crawler_settings . elasticsearch . auto_refresh_gallery [EOL] ES_INDEX_NAME = crawler_settings . elasticsearch . index_name [EOL] ES_GALLERY_INDEX_NAME = crawler_settings . elasticsearch . gallery_index_name [EOL] ES_ONLY_INDEX_PUBLIC = crawler_settings . elasticsearch . only_index_public [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] PROVIDERS = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , ] [EOL] [EOL] PROVIDER_CONTEXT = crawler_settings . provider_context [EOL] CRAWLER_SETTINGS = crawler_settings [EOL] WORKERS = crawler_settings . workers [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.setup.Settings$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.setup.Settings$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $core.base.setup.Settings$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 $core.base.setup.Settings$ 0 0 0 0 0 0 $builtins.bool$ 0 $core.base.setup.Settings$ 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 $core.base.setup.Settings$ 0 0 0 0 0 0 $builtins.bool$ 0 0 0 $typing.Tuple[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.str]$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Dict[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 $typing.Dict[builtins.str,typing.List[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 $builtins.bool$ 0 $builtins.bool$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 $builtins.bool$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 $core.base.setup.Settings$ 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Dict[builtins.str,typing.Any]]$ 0 0 0 0 0 0 0 0 0 0 0 $core.base.setup.Settings$ 0 0 0 0 0 0 0 0 $core.base.setup.Settings$ 0 0 0 0 0 0 0 0 $core.base.setup.Settings$ 0 0 0 0 0 0 0 0 $core.base.setup.Settings$ 0 0 0 0 0 0 0 0 $core.base.setup.Settings$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.setup.Settings$ 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Dict[builtins.str,typing.Any]]$ 0 0 0 0 0 0 0 0 0 0 0 $core.base.setup.Settings$ 0 0 0 0 0 0 0 0 $core.base.setup.Settings$ 0 0 0 0 0 0 0 0 $core.base.setup.Settings$ 0 0 0 0 0 0 0 0 $core.base.setup.Settings$ 0 0 0 0 0 0 0 0 $core.base.setup.Settings$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Dict[builtins.str,typing.Any]]$ 0 0 0 0 0 0 0 0 0 0 0 $core.base.setup.Settings$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.bool$ 0 0 0 0 $builtins.bool$ 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 $builtins.str$ 0 $core.base.setup.Settings$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 $core.base.setup.Settings$ 0 0 0 0 0 0 $builtins.str$ 0 $core.base.setup.Settings$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 $core.base.setup.Settings$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $typing.List[typing.Dict[builtins.str,typing.Union[typing.Dict[builtins.str,typing.Union[typing.List[builtins.str],builtins.bool]],typing.List[builtins.str],builtins.bool,builtins.str]]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.setup.Settings$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.setup.Settings$ 0 0 0 0 0 0 $builtins.str$ 0 $core.base.setup.Settings$ 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.str$ 0 $core.base.setup.Settings$ 0 0 0 0 0 $builtins.str$ 0 $core.base.setup.Settings$ 0 0 0 0 0 $builtins.str$ 0 $core.base.setup.Settings$ 0 0 0 0 0 0 0 $builtins.str$ 0 $core.base.setup.Settings$ 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 $core.base.setup.Settings$ 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.setup.Settings$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 $core.base.setup.Settings$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 $None$ 0 0 0 $builtins.bool$ 0 0 0 0 $builtins.int$ 0 $core.base.setup.Settings$ 0 0 0 0 0 $builtins.bool$ 0 $core.base.setup.Settings$ 0 0 0 0 0 $builtins.bool$ 0 $core.base.setup.Settings$ 0 0 0 0 0 $builtins.str$ 0 $core.base.setup.Settings$ 0 0 0 0 0 $builtins.str$ 0 $core.base.setup.Settings$ 0 0 0 0 0 $builtins.bool$ 0 $core.base.setup.Settings$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.providers.ProviderContext$ 0 $core.base.setup.Settings$ 0 0 0 $core.base.setup.Settings$ 0 $core.base.setup.Settings$ 0 $core.workers.holder.WorkerContext$ 0 $core.base.setup.Settings$ 0 0 0
from typing import Any , List [EOL] import typing [EOL] from django . conf . urls import include , url [EOL] from django . conf import settings [EOL] from django . conf . urls . static import static [EOL] [EOL] from django . contrib import admin [EOL] [EOL] from viewer . views . complete import ( ArchiveAutocomplete , TagAutocomplete , NonCustomTagAutocomplete , CustomTagAutocomplete , GalleryAutocomplete , SourceAutocomplete , ReasonAutocomplete , UploaderAutocomplete , WantedGalleryAutocomplete , CategoryAutocomplete , ProviderAutocomplete , TagPkAutocomplete , GallerySelectAutocomplete , ArchiveSelectAutocomplete , ArchiveGroupAutocomplete , ArchiveGroupSelectAutocomplete , ArchiveSelectSimpleAutocomplete ) [EOL] [EOL] admin . autodiscover ( ) [EOL] [EOL] urlpatterns = [ url ( [string] + settings . MAIN_URL + [string] , admin . site . urls ) , ] [EOL] [EOL] urlpatterns += [ url ( [string] + settings . MAIN_URL + [string] , ArchiveAutocomplete . as_view ( ) , name = [string] , ) , url ( [string] + settings . MAIN_URL + [string] , ArchiveGroupAutocomplete . as_view ( ) , name = [string] , ) , url ( [string] + settings . MAIN_URL + [string] , ArchiveGroupSelectAutocomplete . as_view ( ) , name = [string] , ) , url ( [string] + settings . MAIN_URL + [string] , ArchiveSelectSimpleAutocomplete . as_view ( ) , name = [string] , ) , url ( [string] + settings . MAIN_URL + [string] , ArchiveSelectAutocomplete . as_view ( ) , name = [string] , ) , url ( [string] + settings . MAIN_URL + [string] , GalleryAutocomplete . as_view ( ) , name = [string] , ) , url ( [string] + settings . MAIN_URL + [string] , GallerySelectAutocomplete . as_view ( ) , name = [string] , ) , url ( [string] + settings . MAIN_URL + [string] , TagAutocomplete . as_view ( ) , name = [string] , ) , url ( [string] + settings . MAIN_URL + [string] , TagPkAutocomplete . as_view ( ) , name = [string] , ) , url ( [string] + settings . MAIN_URL + [string] , NonCustomTagAutocomplete . as_view ( ) , name = [string] , ) , url ( [string] + settings . MAIN_URL + [string] , CustomTagAutocomplete . as_view ( create_field = [string] ) , name = [string] , ) , url ( [string] + settings . MAIN_URL + [string] , WantedGalleryAutocomplete . as_view ( ) , name = [string] , ) , url ( [string] + settings . MAIN_URL + [string] , SourceAutocomplete . as_view ( ) , name = [string] , ) , url ( [string] + settings . MAIN_URL + [string] , ProviderAutocomplete . as_view ( ) , name = [string] , ) , url ( [string] + settings . MAIN_URL + [string] , ReasonAutocomplete . as_view ( ) , name = [string] , ) , url ( [string] + settings . MAIN_URL + [string] , UploaderAutocomplete . as_view ( ) , name = [string] , ) , url ( [string] + settings . MAIN_URL + [string] , CategoryAutocomplete . as_view ( ) , name = [string] , ) , ] [EOL] [EOL] if settings . DEBUG : [EOL] try : [EOL] import debug_toolbar [EOL] urlpatterns += [ url ( [string] + settings . MAIN_URL + [string] , include ( debug_toolbar . urls ) ) , ] [EOL] urlpatterns += static ( settings . STATIC_URL , document_root = settings . STATIC_ROOT ) [EOL] urlpatterns += static ( settings . MEDIA_URL , document_root = settings . MEDIA_ROOT ) [EOL] except ImportError : [EOL] debug_toolbar = None [EOL] [EOL] urlpatterns += [ url ( [string] + settings . MAIN_URL , include ( [string] ) ) , ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] [docstring] [EOL] [EOL] import os [EOL] [EOL] os . environ . setdefault ( [string] , [string] ) [EOL] [EOL] from django . core . wsgi import get_wsgi_application [EOL] application = get_wsgi_application ( ) [EOL] [EOL] from pandabackup import settings [EOL] settings . WORKERS . start_workers ( settings . CRAWLER_SETTINGS ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Optional , Any , Iterable , Dict [EOL] import typing [EOL] import viewer [EOL] import datetime [EOL] import django [EOL] import builtins [EOL] from typing import Iterable , Any , Optional [EOL] [EOL] from datetime import datetime [EOL] from django . contrib . syndication . views import Feed [EOL] from django . core . paginator import EmptyPage , Paginator [EOL] from django . http import HttpRequest [EOL] from django . utils . safestring import SafeText [EOL] [EOL] from viewer . models import Archive [EOL] from viewer . views . head import filter_archives_simple , archive_filter_keys [EOL] [EOL] [EOL] class LatestArchivesFeed ( Feed ) : [EOL] title = [string] [EOL] link = [string] [EOL] description = [string] [EOL] [EOL] def get_object ( self , request , * args , ** kwargs ) : [comment] [EOL] return request [EOL] [EOL] def items ( self , request ) : [EOL] [EOL] args = request . GET . copy ( ) [EOL] [EOL] params = { [string] : [string] , [string] : [string] , } [EOL] [EOL] for k , v in args . items ( ) : [EOL] params [ k ] = v [EOL] [EOL] for k in archive_filter_keys : [EOL] if k not in params : [EOL] params [ k ] = [string] [EOL] [EOL] results = filter_archives_simple ( params ) [EOL] [EOL] if not request . user . is_authenticated : [EOL] results = results . filter ( public = True ) . order_by ( [string] ) [EOL] [EOL] paginator = Paginator ( results , [number] ) [EOL] try : [EOL] page = int ( request . GET . get ( [string] , [string] ) ) [EOL] except ValueError : [EOL] page = [number] [EOL] try : [EOL] archives = paginator . page ( page ) [EOL] except EmptyPage : [EOL] [comment] [EOL] archives = paginator . page ( paginator . num_pages ) [EOL] [EOL] return archives [EOL] [EOL] def item_title ( self , item ) : [comment] [EOL] return item . title or item . title_jpn or [string] [EOL] [EOL] def item_description ( self , item ) : [comment] [EOL] return item . tags_str ( ) [EOL] [EOL] def item_pubdate ( self , item ) : [EOL] return item . public_date [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $django.http.HttpRequest$ 0 0 0 $django.http.HttpRequest$ 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 $django.http.HttpRequest$ 0 0 0 $typing.Iterable[viewer.models.Archive]$ 0 0 0 $django.http.HttpRequest$ 0 0 0 0 $typing.Any$ 0 $django.http.HttpRequest$ 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 $django.http.HttpRequest$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $django.http.HttpRequest$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $builtins.int$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 $builtins.str$ 0 0 0 $viewer.models.Archive$ 0 0 0 0 0 $viewer.models.Archive$ 0 0 0 $viewer.models.Archive$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $viewer.models.Archive$ 0 0 0 0 0 $viewer.models.Archive$ 0 0 0 0 0 0 0 $typing.Optional[datetime.datetime]$ 0 0 0 $viewer.models.Archive$ 0 0 0 0 $viewer.models.Archive$ 0 0 0
from typing import Any , Type , Dict , Tuple , List [EOL] import typing [EOL] import django [EOL] import builtins [EOL] import viewer [EOL] import os [EOL] from typing import Dict , Any , List [EOL] [EOL] from django import forms [EOL] from django . contrib . auth . forms import PasswordChangeForm [EOL] from django . contrib . auth . models import User [EOL] from django . core . exceptions import ValidationError [EOL] from django . core . files . uploadedfile import TemporaryUploadedFile [EOL] from django . forms . models import BaseModelFormSet , modelformset_factory , ModelChoiceField , ModelForm , inlineformset_factory , BaseInlineFormSet [EOL] from django . forms . utils import ErrorList [EOL] from django . utils . safestring import mark_safe [EOL] from django . utils . encoding import force_str [EOL] from django . forms . utils import flatatt [EOL] from django . conf import settings [EOL] [EOL] [EOL] from dal import autocomplete [EOL] from dal_jal . widgets import JalWidgetMixin [EOL] from viewer . models import Archive , ArchiveMatches , Image , Gallery , Profile , WantedGallery , ArchiveGroup , ArchiveGroupEntry , Tag [EOL] [EOL] from dal . widgets import ( WidgetMixin ) [EOL] [EOL] from django . utils . translation import gettext_lazy [EOL] [EOL] crawler_settings = settings . CRAWLER_SETTINGS [EOL] [EOL] [EOL] class JalTextWidget ( JalWidgetMixin , WidgetMixin , forms . TextInput ) : [EOL] [EOL] class Media : [EOL] css = { [string] : ( [string] , ) , } [EOL] js = ( [string] , [string] , [string] , [string] , [string] , ) [EOL] [EOL] def __init__ ( self , url = None , forward = None , attrs = None , * args , ** kwargs ) : [EOL] forms . TextInput . __init__ ( self , * args , ** kwargs ) [EOL] [EOL] WidgetMixin . __init__ ( self , url = url , forward = forward ) [EOL] [EOL] self . attrs . update ( attrs ) [EOL] [EOL] def render ( self , name , value , attrs = None , renderer = None ) : [EOL] [docstring] [EOL] html = [string] . format ( id = attrs [ [string] ] , name = name , value = force_str ( [string] if value is None else value ) , attrs = flatatt ( self . build_attrs ( attrs ) ) , ) [EOL] [EOL] return mark_safe ( html ) [EOL] [EOL] def build_attrs ( self , * args , ** kwargs ) : [EOL] [EOL] attrs = { [string] : [string] , [string] : [string] , [string] : self . url , [string] : gettext_lazy ( [string] ) , } [EOL] [EOL] attrs . update ( self . attrs ) [EOL] [EOL] if [string] not in attrs . keys ( ) : [EOL] attrs [ [string] ] = [string] [EOL] attrs [ [string] ] += [string] [EOL] [EOL] return attrs [EOL] [EOL] [EOL] class MatchesModelChoiceField ( ModelChoiceField ) : [EOL] def label_from_instance ( self , obj ) : [comment] [EOL] first_artist_tag = Tag . objects . filter ( gallery = obj . id ) . first_artist_tag ( ) [comment] [EOL] tag_name = [string] [EOL] if first_artist_tag : [EOL] tag_name = first_artist_tag . name [EOL] return [string] . format ( tag_name , obj . pk , obj . title , obj . provider , obj . filecount , obj . filesize ) [EOL] [EOL] [EOL] class ArchiveGroupSearchForm ( forms . Form ) : [EOL] [EOL] title = forms . CharField ( required = False , widget = JalTextWidget ( url = [string] , attrs = { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , } , ) , ) [EOL] [EOL] [EOL] class ArchiveSearchForm ( forms . Form ) : [EOL] [EOL] title = forms . CharField ( required = False , widget = JalTextWidget ( url = [string] , attrs = { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , } , ) , ) [EOL] [EOL] tags = forms . CharField ( required = False , widget = JalTextWidget ( url = [string] , attrs = { [string] : [string] , [string] : [string] , [string] : [string] [string] , [string] : [number] , } , ) , ) [EOL] [EOL] [EOL] class ArchiveSearchSimpleForm ( forms . Form ) : [EOL] [EOL] filecount_from = forms . IntegerField ( required = False , label = [string] , widget = forms . NumberInput ( attrs = { [string] : [string] , [string] : [string] } ) ) [EOL] filecount_to = forms . IntegerField ( required = False , label = [string] , widget = forms . NumberInput ( attrs = { [string] : [string] , [string] : [string] } ) ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] posted_from = forms . DateTimeField ( required = False , label = [string] , widget = forms . DateInput ( attrs = { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [number] } ) , input_formats = [ [string] ] ) [EOL] posted_to = forms . DateTimeField ( required = False , label = [string] , widget = forms . DateInput ( attrs = { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [number] } ) , input_formats = [ [string] ] ) [EOL] source_type = forms . CharField ( required = False , label = [string] , widget = JalTextWidget ( url = [string] , attrs = { [string] : [string] , [string] : [string] , [string] : [number] , [string] : [number] , } , ) , ) [EOL] [EOL] reason = forms . CharField ( required = False , label = [string] , widget = JalTextWidget ( url = [string] , attrs = { [string] : [string] , [string] : [string] , [string] : [number] , [string] : [number] , } , ) , ) [EOL] [EOL] uploader = forms . CharField ( required = False , label = [string] , widget = JalTextWidget ( url = [string] , attrs = { [string] : [string] , [string] : [string] , [string] : [number] , [string] : [number] , } , ) , ) [EOL] [EOL] category = forms . CharField ( required = False , label = [string] , widget = JalTextWidget ( url = [string] , attrs = { [string] : [string] , [string] : [string] , [string] : [number] , [string] : [number] , } , ) , ) [EOL] [EOL] filesize_from = forms . IntegerField ( required = False , label = [string] , widget = forms . NumberInput ( attrs = { [string] : [string] , [string] : [string] } ) ) [EOL] filesize_to = forms . IntegerField ( required = False , label = [string] , widget = forms . NumberInput ( attrs = { [string] : [string] , [string] : [string] } ) ) [EOL] [EOL] [EOL] class SpanErrorList ( ErrorList ) : [EOL] def __str__ ( self ) : [comment] [EOL] return self . as_divs ( ) [EOL] [EOL] def as_divs ( self ) : [EOL] if not self : [EOL] return [string] [EOL] return [string] % [string] . join ( [ [string] % e for e in self ] ) [EOL] [EOL] [EOL] class ArchiveGroupSelectForm ( forms . Form ) : [EOL] [EOL] archive_group = forms . ModelMultipleChoiceField ( required = False , queryset = ArchiveGroup . objects . none ( ) , widget = autocomplete . ModelSelect2Multiple ( url = [string] , attrs = { [string] : [number] , [string] : [string] , [string] : [string] } ) , ) [EOL] [EOL] [EOL] class ArchiveModForm ( forms . ModelForm ) : [EOL] [EOL] class Meta : [EOL] model = Archive [EOL] fields = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] widgets = { [string] : autocomplete . ModelSelect2Multiple ( url = [string] , attrs = { [string] : [number] , [string] : [string] , [string] : [string] } ) , [string] : autocomplete . ModelSelect2Multiple ( url = [string] , attrs = { [string] : [number] , [string] : [string] , [string] : [string] } ) , [string] : forms . widgets . TextInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . TextInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . TextInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . TextInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . TextInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . Textarea ( attrs = { [string] : [string] } ) , } [EOL] [EOL] def __init__ ( self , * args , ** kwargs ) : [EOL] super ( ArchiveModForm , self ) . __init__ ( * args , ** kwargs ) [EOL] self . fields [ [string] ] . queryset = self . instance . possible_matches . order_by ( [string] ) [EOL] [EOL] possible_matches = MatchesModelChoiceField ( required = False , queryset = ArchiveMatches . objects . none ( ) , widget = forms . widgets . Select ( attrs = { [string] : [string] } ) , ) [EOL] [EOL] [EOL] class GallerySearchForm ( forms . Form ) : [EOL] [EOL] title = forms . CharField ( required = False , widget = JalTextWidget ( url = [string] , attrs = { [string] : [string] , [string] : [string] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , } , ) , ) [EOL] [EOL] tags = forms . CharField ( required = False , widget = JalTextWidget ( url = [string] , attrs = { [string] : [string] , [string] : [string] [string] , [string] : [number] , } , ) , ) [EOL] [EOL] [EOL] class WantedGallerySearchForm ( forms . Form ) : [EOL] [EOL] title = forms . CharField ( required = False , widget = JalTextWidget ( url = [string] , attrs = { [string] : [string] , [string] : [string] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , } , ) , ) [EOL] [EOL] tags = forms . CharField ( required = False , widget = JalTextWidget ( url = [string] , attrs = { [string] : [string] , [string] : [string] [string] , [string] : [number] , } , ) , ) [EOL] [EOL] [EOL] class Html5DateInput ( forms . DateInput ) : [EOL] input_type = [string] [EOL] [EOL] [EOL] class WantedGalleryCreateOrEditForm ( ModelForm ) : [EOL] [EOL] class Meta : [EOL] model = WantedGallery [EOL] fields = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] help_texts = { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] } [EOL] widgets = { [string] : forms . widgets . TextInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . TextInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . TextInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . CheckboxInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . TextInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . CheckboxInput ( attrs = { [string] : [string] } ) , [string] : autocomplete . ModelSelect2Multiple ( url = [string] , attrs = { [string] : [string] , [string] : [string] } ) , [string] : autocomplete . ModelSelect2Multiple ( url = [string] , attrs = { [string] : [string] , [string] : [string] } ) , [string] : forms . widgets . CheckboxInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . TextInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . NumberInput ( attrs = { [string] : [number] , [string] : [string] } ) , [string] : forms . widgets . NumberInput ( attrs = { [string] : [number] , [string] : [string] } ) , [string] : JalTextWidget ( url = [string] , attrs = { [string] : [string] , [string] : [string] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , } , ) , [string] : Html5DateInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . CheckboxInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . CheckboxInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . TextInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . TextInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . TextInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . NumberInput ( attrs = { [string] : [number] , [string] : [string] } ) , } [EOL] [EOL] [EOL] class ArchiveGroupCreateOrEditForm ( ModelForm ) : [EOL] [EOL] class Meta : [EOL] model = ArchiveGroup [EOL] fields = [ [string] , [string] , [string] , [string] ] [EOL] widgets = { [string] : forms . widgets . TextInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . Textarea ( attrs = { [string] : [string] } ) , [string] : forms . widgets . NumberInput ( attrs = { [string] : [number] , [string] : [string] } ) , [string] : forms . widgets . CheckboxInput ( attrs = { [string] : [string] } ) } [EOL] [EOL] def save ( self , commit = True ) : [EOL] archive_group = super ( ArchiveGroupCreateOrEditForm , self ) . save ( commit = commit ) [EOL] [EOL] for archive_group_entry in archive_group . archivegroupentry_set . all ( ) : [EOL] archive_group_entry . save ( ) [EOL] return archive_group [EOL] [EOL] [EOL] class ArchiveGroupEntryForm ( ModelForm ) : [EOL] [EOL] class Meta : [EOL] model = ArchiveGroupEntry [EOL] fields = [ [string] , [string] , [string] ] [EOL] widgets = { [string] : forms . widgets . TextInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . NumberInput ( attrs = { [string] : [string] } ) , [string] : autocomplete . ModelSelect2 ( url = [string] , attrs = { [string] : [number] , [string] : [string] , [string] : [string] , [string] : [string] } ) , } [EOL] [EOL] [EOL] class BaseArchiveGroupEntryFormSet ( BaseInlineFormSet ) : [EOL] def clean ( self ) : [EOL] super ( ) . clean ( ) [EOL] if any ( self . errors ) : [EOL] return [EOL] positions = [ ] [EOL] for form in self . forms : [EOL] if [string] in form . cleaned_data : [EOL] position = form . cleaned_data [ [string] ] [EOL] if position in positions : [EOL] raise forms . ValidationError ( [string] . format ( position ) ) [EOL] positions . append ( position ) [EOL] [EOL] [EOL] ArchiveGroupEntryFormSet = inlineformset_factory ( ArchiveGroup , ArchiveGroupEntry , form = ArchiveGroupEntryForm , extra = [number] , formset = BaseArchiveGroupEntryFormSet , can_delete = True ) [EOL] [EOL] [EOL] class ArchiveCreateForm ( ModelForm ) : [EOL] [EOL] class Meta : [EOL] model = Archive [EOL] fields = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] widgets = { [string] : forms . widgets . FileInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . TextInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . TextInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . TextInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . TextInput ( attrs = { [string] : [string] } ) , [string] : autocomplete . ModelSelect2 ( url = [string] , attrs = { [string] : [number] , [string] : [string] , [string] : [string] , [string] : [string] } ) , [string] : forms . widgets . Textarea ( attrs = { [string] : [string] } ) , } [EOL] [EOL] def clean_zipped ( self ) : [EOL] zipped = self . cleaned_data [ [string] ] [EOL] full_path = os . path . join ( crawler_settings . MEDIA_ROOT , [string] . format ( file = zipped . name ) ) [EOL] if os . path . isfile ( full_path ) : [EOL] raise ValidationError ( [string] ) [EOL] return zipped [EOL] [EOL] [EOL] class ArchiveEditForm ( ModelForm ) : [EOL] [EOL] class Meta : [EOL] model = Archive [EOL] fields = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] widgets = { [string] : forms . widgets . TextInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . TextInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . TextInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . TextInput ( attrs = { [string] : [string] } ) , [string] : autocomplete . ModelSelect2 ( url = [string] , attrs = { [string] : [number] , [string] : [string] , [string] : [string] , [string] : [string] } ) , [string] : autocomplete . ModelSelect2Multiple ( url = [string] , attrs = { [string] : [number] , [string] : [string] , [string] : [string] , [string] : [string] } ) , [string] : forms . widgets . Textarea ( attrs = { [string] : [string] } ) , } [EOL] [EOL] [EOL] class ImageForm ( forms . ModelForm ) : [EOL] position = forms . IntegerField ( required = True , widget = forms . NumberInput ( attrs = { [string] : [number] } ) ) [EOL] [EOL] class Meta : [EOL] model = Image [EOL] fields = [ [string] ] [EOL] [EOL] def __init__ ( self , * args , ** kwargs ) : [EOL] super ( ImageForm , self ) . __init__ ( * args , ** kwargs ) [EOL] if self . instance . image : [EOL] self . fields [ [string] ] . label = os . path . basename ( self . instance . image . path ) [EOL] else : [EOL] self . fields [ [string] ] . label = self . instance . position [EOL] [EOL] [EOL] class BaseImageFormSet ( BaseModelFormSet ) : [EOL] def clean ( self ) : [EOL] if any ( self . errors ) : [EOL] return [EOL] positions = [ ] [EOL] for form in self . forms : [EOL] position = form . cleaned_data [ [string] ] [EOL] if position in positions : [EOL] raise forms . ValidationError ( [string] . format ( position ) ) [EOL] positions . append ( position ) [EOL] [EOL] [EOL] ImageFormSet = modelformset_factory ( Image , form = ImageForm , extra = [number] , formset = BaseImageFormSet , can_delete = True ) [EOL] [EOL] [EOL] class BootstrapPasswordChangeForm ( PasswordChangeForm ) : [EOL] [EOL] def __init__ ( self , user , * args , ** kwargs ) : [EOL] super ( ) . __init__ ( user , * args , ** kwargs ) [EOL] self . fields [ [string] ] . widget . attrs . update ( { [string] : [string] } ) [EOL] self . fields [ [string] ] . widget . attrs . update ( { [string] : [string] } ) [EOL] self . fields [ [string] ] . widget . attrs . update ( { [string] : [string] } ) [EOL] [EOL] [EOL] class UserChangeForm ( forms . ModelForm ) : [EOL] [EOL] class Meta : [EOL] model = User [EOL] fields = [ [string] ] [EOL] widgets = { [string] : forms . widgets . EmailInput ( attrs = { [string] : [string] } ) , } [EOL] [EOL] [EOL] class ProfileChangeForm ( forms . ModelForm ) : [EOL] [EOL] class Meta : [EOL] model = Profile [EOL] fields = [ [string] , [string] , [string] ] [EOL] widgets = { [string] : forms . widgets . CheckboxInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . CheckboxInput ( attrs = { [string] : [string] } ) , [string] : forms . widgets . CheckboxInput ( attrs = { [string] : [string] } ) , } [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from django . apps import AppConfig [EOL] from django . conf import settings [EOL] [EOL] [EOL] class ViewerConfig ( AppConfig ) : [EOL] name = [string] [EOL] [EOL] def ready ( self ) : [EOL] from . import handlers [EOL] settings . PROVIDER_CONTEXT . register_providers ( settings . PROVIDERS ) [EOL] settings . CRAWLER_SETTINGS . load_config_from_file ( ) [EOL] from . models import Archive , Gallery , FoundGallery , WantedGallery [EOL] [EOL] settings . CRAWLER_SETTINGS . set_models ( Gallery , Archive , FoundGallery , WantedGallery ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Tuple , List [EOL] import logging [EOL] import typing [EOL] import viewer [EOL] import logging [EOL] import typing [EOL] from urllib . parse import urljoin [EOL] [EOL] from django . conf import settings [EOL] from django . core . mail import BadHeaderError [EOL] from django . db . models import Q [EOL] from django . dispatch import receiver [EOL] from django . urls import reverse [EOL] from django . utils . html import urlize , linebreaks [EOL] [EOL] from viewer . models import Gallery , users_with_perm , WantedGallery [EOL] from viewer . signals import wanted_gallery_found [EOL] from viewer . utils . functions import send_mass_html_mail [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] crawler_settings = settings . CRAWLER_SETTINGS [EOL] [EOL] [EOL] @ receiver ( wanted_gallery_found , sender = Gallery ) def wanted_gallery_found_handler ( sender , ** kwargs ) : [EOL] gallery = kwargs [ [string] ] [EOL] wanted_gallery_list = kwargs [ [string] ] [EOL] [EOL] notify_wanted_filters = [ [string] . format ( ( x . title or [string] ) , ( x . reason or [string] ) ) for x in wanted_gallery_list if x . notify_when_found ] [EOL] [EOL] if not notify_wanted_filters : [EOL] return [EOL] [EOL] main_url = crawler_settings . urls . main_webserver_url [EOL] [EOL] message = [string] . format ( gallery . title , gallery . get_link ( ) , urljoin ( main_url , gallery . get_absolute_url ( ) ) , [string] . join ( notify_wanted_filters ) , [string] . join ( gallery . tag_list_sorted ( ) ) ) [EOL] [EOL] message += [string] . format ( urljoin ( main_url , reverse ( [string] ) ) ) [EOL] [EOL] [comment] [EOL] users_to_mail = users_with_perm ( [string] , [string] , Q ( email__isnull = False ) | ~ Q ( email__exact = [string] ) , profile__notify_wanted_gallery_found = True ) [EOL] [EOL] mails = users_to_mail . values_list ( [string] , flat = True ) [EOL] [EOL] try : [EOL] logger . info ( [string] ) [EOL] [comment] [EOL] datatuples = tuple ( [ ( [string] , message , urlize ( linebreaks ( message ) ) , crawler_settings . mail_logging . from_ , ( mail , ) ) for mail in mails ] ) [EOL] send_mass_html_mail ( datatuples , fail_silently = True ) [EOL] except BadHeaderError : [EOL] logger . error ( [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
default_app_config = [string] [EOL]	$builtins.str$ 0 0 0
from typing import Any [EOL] import typing [EOL] from django . dispatch import Signal [EOL] [EOL] [EOL] wanted_gallery_found = Signal ( providing_args = [ [string] , [string] ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List [EOL] import typing [EOL] from django . conf . urls import url [EOL] from django . urls import path [EOL] [EOL] from viewer . views import head , browser , wanted , exp , api , archive , admin , manager , collaborators , groups , admin_api [EOL] from viewer . feeds import LatestArchivesFeed [EOL] from viewer . views . elasticsearch import ESHomePageView , autocomplete_view , title_suggest_view [EOL] [EOL] app_name = [string] [EOL] [EOL] urlpatterns = [ url ( [string] , browser . directory_parser , name = [string] ) , url ( [string] , api . json_search , name = [string] ) , url ( [string] , api . json_search , name = [string] ) , url ( [string] , api . json_parser , name = [string] ) , url ( [string] , api . json_parser , name = [string] ) , url ( [string] , archive . archive_details , name = [string] ) , url ( [string] , archive . archive_details , name = [string] ) , url ( [string] , archive . extract_toggle , name = [string] ) , url ( [string] , archive . public_toggle , name = [string] ) , url ( [string] , archive . recalc_info , name = [string] ) , url ( [string] , archive . recall_api , name = [string] ) , url ( [string] , archive . generate_matches , name = [string] ) , url ( [string] , archive . rematch_archive , name = [string] ) , url ( [string] , archive . delete_archive , name = [string] ) , url ( [string] , archive . archive_download , name = [string] ) , url ( [string] , archive . archive_ext_download , name = [string] ) , url ( [string] , archive . archive_thumb , name = [string] ) , url ( [string] , archive . archive_update , name = [string] ) , url ( [string] , archive . archive_update , name = [string] ) , url ( [string] , archive . archive_update , name = [string] ) , url ( [string] , archive . archive_update , name = [string] ) , url ( [string] , head . gallery_thumb , name = [string] ) , url ( [string] , head . gallery_details , name = [string] ) , url ( [string] , head . gallery_details , name = [string] ) , url ( [string] , wanted . wanted_gallery , name = [string] ) , url ( [string] , head . user_archive_preferences , name = [string] ) , url ( [string] , head . url_submit , name = [string] ) , url ( [string] , head . viewer_login , name = [string] ) , url ( [string] , head . viewer_logout , name = [string] ) , url ( [string] , head . change_password , name = [string] ) , url ( [string] , head . change_profile , name = [string] ) , url ( [string] , head . session_settings , name = [string] ) , url ( [string] , head . image_url , name = [string] ) , url ( [string] , head . panda_userscript , name = [string] ) , url ( [string] , head . search , name = [string] ) , url ( [string] , head . gallery_list , name = [string] ) , url ( [string] , head . gallery_list , name = [string] ) , url ( [string] , head . search , name = [string] ) , url ( [string] , head . about , name = [string] ) , url ( [string] , head . search , name = [string] ) , ] [EOL] [EOL] [comment] [EOL] urlpatterns += [ url ( [string] , manager . repeated_archives_for_galleries , name = [string] ) , url ( [string] , manager . repeated_archives_by_field , name = [string] ) , url ( [string] , manager . repeated_galleries_by_field , name = [string] ) , url ( [string] , manager . archive_filesize_different_from_gallery , name = [string] ) , url ( [string] , manager . missing_archives_for_galleries , name = [string] ) , url ( [string] , manager . archives_not_present_in_filesystem , name = [string] ) , url ( [string] , manager . archives_not_matched_with_gallery , name = [string] ) , url ( [string] , manager . wanted_galleries , name = [string] ) , url ( [string] , manager . found_galleries , name = [string] ) , ] [EOL] [EOL] [comment] [EOL] urlpatterns += [ url ( [string] , head . image_viewer , name = [string] ) , url ( [string] , exp . new_image_viewer , name = [string] ) , ] [EOL] [EOL] [comment] [EOL] urlpatterns += [ url ( [string] , admin . tools , name = [string] ) , url ( [string] , admin . tools , name = [string] ) , url ( [string] , admin . tools , name = [string] ) , url ( [string] , admin . logs , name = [string] ) , url ( [string] , admin . stats_collection , name = [string] ) , url ( [string] , head . public_stats , name = [string] ) , url ( [string] , admin . stats_workers , name = [string] ) , url ( [string] , admin . stats_settings , name = [string] ) , url ( [string] , admin . queue_operations , name = [string] ) , url ( [string] , admin . crawler , name = [string] ) , url ( [string] , admin . foldercrawler , name = [string] ) , url ( [string] , admin_api . tools , name = [string] ) , url ( [string] , admin_api . tools , name = [string] ) , ] [EOL] [EOL] [comment] [EOL] urlpatterns += [ url ( [string] , collaborators . my_event_log , name = [string] ) , url ( [string] , collaborators . submit_queue , name = [string] ) , url ( [string] , collaborators . upload_archive , name = [string] ) , url ( [string] , collaborators . manage_archives , name = [string] ) , url ( [string] , collaborators . wanted_galleries , name = [string] ) , url ( [string] , collaborators . wanted_gallery , name = [string] ) , url ( [string] , collaborators . user_crawler , name = [string] ) , url ( [string] , collaborators . archives_not_matched_with_gallery , name = [string] ) , url ( [string] , collaborators . archive_update , name = [string] ) , url ( [string] , collaborators . archive_update , name = [string] ) , url ( [string] , collaborators . archive_update , name = [string] ) , url ( [string] , collaborators . archive_update , name = [string] ) , url ( [string] , collaborators . users_event_log , name = [string] ) , ] [EOL] [EOL] [comment] [EOL] urlpatterns += [ url ( [string] , groups . archive_groups_explorer , name = [string] ) , path ( [string] , groups . archive_group , name = [string] ) , path ( [string] , groups . archive_group , name = [string] ) , path ( [string] , groups . archive_group_edit , name = [string] ) , path ( [string] , groups . archive_group_edit , name = [string] ) , ] [EOL] [EOL] urlpatterns += [ url ( [string] , LatestArchivesFeed ( ) , name = [string] ) , ] [EOL] [EOL] urlpatterns += [ url ( [string] , exp . tag_frequency , name = [string] ) , url ( [string] , exp . gallery_frequency , name = [string] ) , url ( [string] , exp . seeder ) , url ( [string] , exp . release_date_seeder ) , url ( [string] , exp . api , name = [string] ) , url ( [string] , exp . api , name = [string] ) , url ( [string] , exp . api , name = [string] ) , ] [EOL] [EOL] urlpatterns += [ url ( [string] , autocomplete_view , name = [string] ) , url ( [string] , title_suggest_view , name = [string] ) , url ( [string] , ESHomePageView . as_view ( ) , name = [string] ) , ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] from typing import Any , Tuple , List [EOL] import typing [EOL] from django . db import migrations [EOL] [EOL] [EOL] def add_permissions ( apps , schema_editor ) : [EOL] pass [EOL] [EOL] [EOL] def remove_permissions ( apps , schema_editor ) : [EOL] [docstring] [EOL] ContentType = apps . get_model ( [string] ) [EOL] Permission = apps . get_model ( [string] ) [EOL] try : [EOL] content_type = ContentType . objects . get ( model = [string] , app_label = [string] , ) [EOL] except ContentType . DoesNotExist : [EOL] return [EOL] [comment] [EOL] Permission . objects . filter ( content_type = content_type , codename__in = ( [string] , [string] , [string] ) , ) . delete ( ) [EOL] [EOL] [EOL] class Migration ( migrations . Migration ) : [EOL] [EOL] dependencies = [ ( [string] , [string] ) , ] [EOL] [EOL] operations = [ migrations . RunPython ( remove_permissions , add_permissions ) , ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] from typing import Tuple , List [EOL] import typing [EOL] from django . db import migrations [EOL] [EOL] [EOL] class Migration ( migrations . Migration ) : [EOL] [EOL] dependencies = [ ( [string] , [string] ) , ] [EOL] [EOL] operations = [ migrations . RenameModel ( [string] , [string] ) ] [EOL] [EOL] atomic = False [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0
[comment] [EOL] [comment] [EOL] from typing import Tuple , List [EOL] import typing [EOL] from __future__ import unicode_literals [EOL] [EOL] from django . db import migrations , models [EOL] import django . utils . timezone [EOL] [EOL] [EOL] class Migration ( migrations . Migration ) : [EOL] [EOL] dependencies = [ ( [string] , [string] ) , ] [EOL] [EOL] operations = [ migrations . CreateModel ( name = [string] , fields = [ ( [string] , models . AutoField ( auto_created = True , primary_key = True , serialize = False , verbose_name = [string] ) ) , ( [string] , models . CharField ( max_length = [number] ) ) , ( [string] , models . CharField ( default = [string] , max_length = [number] ) ) , ( [string] , models . DateTimeField ( blank = True , default = django . utils . timezone . now , null = True , verbose_name = [string] ) ) , ] , ) , ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] from typing import Tuple , List [EOL] import typing [EOL] from __future__ import unicode_literals [EOL] [EOL] from django . db import migrations [EOL] [EOL] [EOL] class Migration ( migrations . Migration ) : [EOL] [EOL] dependencies = [ ( [string] , [string] ) , ] [EOL] [EOL] operations = [ migrations . RenameField ( model_name = [string] , old_name = [string] , new_name = [string] , ) , ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] from typing import Tuple , List [EOL] import typing [EOL] from django . db import migrations [EOL] [EOL] [EOL] class Migration ( migrations . Migration ) : [EOL] [EOL] dependencies = [ ( [string] , [string] ) , ] [EOL] [EOL] operations = [ migrations . AlterUniqueTogether ( name = [string] , unique_together = { ( [string] , [string] ) } , ) , ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] from typing import Tuple , List [EOL] import typing [EOL] from __future__ import unicode_literals [EOL] [EOL] from django . db import migrations , models [EOL] [EOL] [EOL] class Migration ( migrations . Migration ) : [EOL] [EOL] dependencies = [ ( [string] , [string] ) , ] [EOL] [EOL] operations = [ migrations . AddField ( model_name = [string] , name = [string] , field = models . BooleanField ( default = False ) , ) , ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] from typing import Tuple , List [EOL] import typing [EOL] from __future__ import unicode_literals [EOL] [EOL] from django . db import migrations , models [EOL] import viewer . models [EOL] [EOL] [EOL] class Migration ( migrations . Migration ) : [EOL] [EOL] dependencies = [ ( [string] , [string] ) , ] [EOL] [EOL] operations = [ migrations . AlterField ( model_name = [string] , name = [string] , field = models . ImageField ( blank = True , default = [string] , height_field = [string] , max_length = [number] , upload_to = viewer . models . gallery_thumb_path_handler , width_field = [string] ) , ) , ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] from typing import Tuple , List [EOL] import typing [EOL] from django . db import migrations [EOL] [EOL] [EOL] class Migration ( migrations . Migration ) : [EOL] [EOL] dependencies = [ ( [string] , [string] ) , ] [EOL] [EOL] operations = [ migrations . AlterModelOptions ( name = [string] , options = { [string] : [ [string] ] } , ) , ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] from typing import Tuple , List [EOL] import typing [EOL] from __future__ import unicode_literals [EOL] [EOL] from django . db import migrations , models [EOL] import viewer . models [EOL] [EOL] [EOL] class Migration ( migrations . Migration ) : [EOL] [EOL] dependencies = [ ( [string] , [string] ) , ] [EOL] [EOL] operations = [ migrations . AddField ( model_name = [string] , name = [string] , field = models . ImageField ( default = [string] , max_length = [number] , upload_to = viewer . models . gallery_thumb_path_handler ) , ) , migrations . AddField ( model_name = [string] , name = [string] , field = models . URLField ( blank = True , default = [string] , max_length = [number] , null = True ) , ) , ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] from typing import Tuple , List [EOL] import typing [EOL] from __future__ import unicode_literals [EOL] [EOL] from django . db import migrations [EOL] [EOL] [EOL] class Migration ( migrations . Migration ) : [EOL] [EOL] dependencies = [ ( [string] , [string] ) , ] [EOL] [EOL] operations = [ migrations . AlterModelOptions ( name = [string] , options = { [string] : [string] } , ) , ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] from typing import Tuple , List [EOL] import typing [EOL] from django . db import migrations , models [EOL] [EOL] [EOL] class Migration ( migrations . Migration ) : [EOL] [EOL] dependencies = [ ( [string] , [string] ) , ] [EOL] [EOL] operations = [ migrations . AddConstraint ( model_name = [string] , constraint = models . UniqueConstraint ( fields = ( [string] , [string] ) , name = [string] ) , ) , ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] from typing import Tuple , List [EOL] import typing [EOL] from __future__ import unicode_literals [EOL] [EOL] from django . db import migrations [EOL] [EOL] [EOL] class Migration ( migrations . Migration ) : [EOL] [EOL] dependencies = [ ( [string] , [string] ) , ] [EOL] [EOL] operations = [ migrations . RenameModel ( old_name = [string] , new_name = [string] , ) , ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] from typing import Tuple , List [EOL] import typing [EOL] from __future__ import unicode_literals [EOL] [EOL] from django . db import migrations [EOL] [EOL] [EOL] class Migration ( migrations . Migration ) : [EOL] [EOL] dependencies = [ ( [string] , [string] ) , ] [EOL] [EOL] operations = [ migrations . RemoveField ( model_name = [string] , name = [string] , ) , ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] from typing import Tuple , List [EOL] import typing [EOL] from django . db import migrations [EOL] [EOL] [EOL] class Migration ( migrations . Migration ) : [EOL] [EOL] dependencies = [ ( [string] , [string] ) , ] [EOL] [EOL] operations = [ migrations . RenameField ( [string] , [string] , [string] ) , migrations . RenameField ( [string] , [string] , [string] ) , ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
[comment] [EOL] from typing import Tuple , List [EOL] import typing [EOL] from __future__ import unicode_literals [EOL] [EOL] from django . db import migrations , models [EOL] [EOL] [EOL] class Migration ( migrations . Migration ) : [EOL] [EOL] dependencies = [ ( [string] , [string] ) , ] [EOL] [EOL] operations = [ migrations . AlterModelOptions ( name = [string] , options = { [string] : [string] } , ) , migrations . AlterField ( model_name = [string] , name = [string] , field = models . ForeignKey ( related_name = [string] , to = [string] , null = True , blank = True , on_delete = models . SET_NULL ) , ) , migrations . AlterField ( model_name = [string] , name = [string] , field = models . ForeignKey ( to = [string] , null = True , blank = True , on_delete = models . SET_NULL ) , ) , ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] from typing import Tuple , List [EOL] import typing [EOL] from __future__ import unicode_literals [EOL] [EOL] from django . db import migrations , models [EOL] import django . utils . timezone [EOL] [EOL] [EOL] class Migration ( migrations . Migration ) : [EOL] [EOL] dependencies = [ ( [string] , [string] ) , ] [EOL] [EOL] operations = [ migrations . CreateModel ( name = [string] , fields = [ ( [string] , models . AutoField ( verbose_name = [string] , auto_created = True , serialize = False , primary_key = True ) ) , ( [string] , models . PositiveIntegerField ( blank = True , null = True ) ) , ( [string] , models . CharField ( default = [string] , max_length = [number] , null = True , blank = True ) ) , ( [string] , models . CharField ( default = [string] , max_length = [number] , null = True , blank = True ) ) , ( [string] , models . DateTimeField ( verbose_name = [string] , blank = True , null = True , default = django . utils . timezone . now ) ) , ( [string] , models . CharField ( default = [string] , max_length = [number] , null = True , blank = True ) ) , ] , ) , ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] from typing import Tuple , List [EOL] import typing [EOL] from __future__ import unicode_literals [EOL] [EOL] from django . db import migrations [EOL] [EOL] [EOL] class Migration ( migrations . Migration ) : [EOL] [EOL] dependencies = [ ( [string] , [string] ) , ] [EOL] [EOL] operations = [ migrations . RenameField ( model_name = [string] , old_name = [string] , new_name = [string] , ) , ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] from typing import Tuple , List [EOL] import typing [EOL] from django . db import migrations , models [EOL] import viewer . models [EOL] [EOL] [EOL] class Migration ( migrations . Migration ) : [EOL] [EOL] dependencies = [ ( [string] , [string] ) , ] [EOL] [EOL] operations = [ migrations . AlterField ( model_name = [string] , name = [string] , field = models . FileField ( max_length = [number] , storage = viewer . models . OriginalFilenameFileSystemStorage ( ) , upload_to = viewer . models . archive_path_handler , verbose_name = [string] ) , ) , ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Optional , Tuple , List [EOL] import typing [EOL] from django . test import TestCase [EOL] [EOL] from core . base . comparison import get_list_closer_gallery_titles_from_list [EOL] from viewer . models import Gallery [EOL] [EOL] [EOL] class CoreTest ( TestCase ) : [EOL] def setUp ( self ) : [EOL] [comment] [EOL] self . test_gallery1 = Gallery . objects . create ( title = [string] , gid = [string] , provider = [string] ) [EOL] self . test_gallery2 = Gallery . objects . create ( title = [string] , gid = [string] , provider = [string] ) [EOL] [EOL] def test_repeated_archives ( self ) : [EOL] [EOL] title_to_check = [string] [EOL] galleries_title_id = [ ( gallery . title , gallery . pk ) for gallery in Gallery . objects . all ( ) ] [EOL] cutoff = [number] [EOL] max_matches = [number] [EOL] [EOL] similar_list = get_list_closer_gallery_titles_from_list ( title_to_check , galleries_title_id , cutoff , max_matches ) [EOL] [EOL] self . assertIsNone ( similar_list ) [EOL] [EOL] title_to_check_2 = [string] [EOL] [EOL] similar_list = get_list_closer_gallery_titles_from_list ( title_to_check_2 , galleries_title_id , cutoff , max_matches ) [EOL] [EOL] self . assertIsNotNone ( similar_list ) [EOL] self . assertEqual ( len ( similar_list ) , [number] ) [EOL] self . assertEqual ( similar_list [ [number] ] [ [number] ] , [string] ) [EOL] self . assertEqual ( similar_list [ [number] ] [ [number] ] , [number] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.List[typing.Tuple[unknown,unknown]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 $builtins.int$ 0 0 0 0 $typing.Optional[typing.List[typing.Tuple[builtins.str,builtins.str,builtins.float]]]$ 0 0 0 $builtins.str$ 0 $typing.List[typing.Tuple[unknown,unknown]]$ 0 $builtins.float$ 0 $builtins.int$ 0 0 0 0 0 0 0 $typing.Optional[typing.List[typing.Tuple[builtins.str,builtins.str,builtins.float]]]$ 0 0 0 $builtins.str$ 0 0 0 0 $typing.Optional[typing.List[typing.Tuple[builtins.str,builtins.str,builtins.float]]]$ 0 0 0 $builtins.str$ 0 $typing.List[typing.Tuple[unknown,unknown]]$ 0 $builtins.float$ 0 $builtins.int$ 0 0 0 0 0 0 0 $typing.Optional[typing.List[typing.Tuple[builtins.str,builtins.str,builtins.float]]]$ 0 0 0 0 0 0 0 0 $typing.Optional[typing.List[typing.Tuple[builtins.str,builtins.str,builtins.float]]]$ 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.List[typing.Tuple[builtins.str,builtins.str,builtins.float]]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.List[typing.Tuple[builtins.str,builtins.str,builtins.float]]]$ 0 0 0 0 0 0 0 0 0 0
import builtins [EOL] from typing import Optional , Type [EOL] import core [EOL] import typing [EOL] import viewer [EOL] import dateutil . parser [EOL] from django . test import TestCase [EOL] [EOL] from core . base . setup import Settings [EOL] from core . base . types import GalleryData [EOL] from core . providers . fakku . parsers import Parser as FakkuParser [EOL] from core . providers . nhentai . parsers import Parser as NhentaiParser [EOL] from core . providers . nexus . parsers import Parser as NexusParser [EOL] [EOL] [EOL] class TestPageParsers ( TestCase ) : [EOL] maxDiff = None [EOL] [EOL] def test_nhentai_parser ( self ) : [EOL] [docstring] [EOL] settings = Settings ( load_from_disk = True ) [EOL] [EOL] gallery_link = [string] [EOL] parser = NhentaiParser ( settings ) [EOL] data = parser . fetch_gallery_data ( gallery_link ) [EOL] [EOL] expected_data = GalleryData ( [string] , [string] , title = [string] , title_jpn = [string] , filecount = [number] , link = [string] , posted = dateutil . parser . parse ( [string] ) , category = [string] , tags = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , ] ) [EOL] [EOL] self . assertEqual ( data , expected_data ) [EOL] [EOL] def test_fakku_parser ( self ) : [EOL] [docstring] [EOL] settings = Settings ( load_from_disk = True ) [EOL] [EOL] gallery_link = [string] [EOL] parser = FakkuParser ( settings ) [EOL] data = parser . fetch_gallery_data ( gallery_link ) [EOL] [EOL] expected_data = GalleryData ( [string] , [string] , link = gallery_link , title = [string] , thumbnail_url = [string] , filecount = [number] , category = [string] , tags = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , ] , comment = [string] , ) [EOL] [EOL] self . assertEqual ( data , expected_data ) [EOL] [EOL] gallery_link = [string] [EOL] parser = FakkuParser ( settings ) [EOL] data = parser . fetch_gallery_data ( gallery_link ) [EOL] [EOL] expected_data = GalleryData ( [string] , [string] , link = gallery_link , title = [string] , filecount = [number] , category = [string] , tags = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , ] , comment = [string] , thumbnail_url = [string] , ) [EOL] [EOL] self . assertEqual ( data , expected_data ) [EOL] [EOL] def test_nexus_parser ( self ) : [EOL] [docstring] [EOL] settings = Settings ( load_from_disk = True ) [EOL] [EOL] gallery_link = [string] [EOL] parser = NexusParser ( settings ) [EOL] data = parser . fetch_gallery_data ( gallery_link ) [EOL] [EOL] expected_data = GalleryData ( [string] , [string] , link = gallery_link , archiver_key = [string] , title = [string] , thumbnail_url = [string] , filecount = [number] , filesize = [number] , expunged = False , posted = None , category = [string] , tags = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , ] , comment = [string] , ) [EOL] [EOL] self . assertEqual ( data , expected_data ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.setup.Settings$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $core.providers.nhentai.parsers.Parser$ 0 0 0 $core.base.setup.Settings$ 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 $core.providers.nhentai.parsers.Parser$ 0 0 0 $builtins.str$ 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.providers.nhentai.parsers.Parser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.setup.Settings$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $core.providers.fakku.parsers.Parser$ 0 0 0 $core.base.setup.Settings$ 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 $core.providers.fakku.parsers.Parser$ 0 0 0 $builtins.str$ 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 $core.base.types.GalleryData$ 0 0 0 $builtins.str$ 0 0 0 $core.providers.fakku.parsers.Parser$ 0 0 0 $core.base.setup.Settings$ 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 $core.providers.fakku.parsers.Parser$ 0 0 0 $builtins.str$ 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.setup.Settings$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $core.providers.nexus.parsers.Parser$ 0 0 0 $core.base.setup.Settings$ 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 $core.providers.nexus.parsers.Parser$ 0 0 0 $builtins.str$ 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 $core.base.types.GalleryData$ 0 0
	0
from typing import Any [EOL] import typing [EOL] [docstring] [EOL] from django . test import TestCase , Client [EOL] from django . contrib . auth . models import User [EOL] from django . urls import reverse [EOL] [EOL] from viewer . models import Tag , Archive , Gallery [EOL] [EOL] [EOL] class TagTestCase ( TestCase ) : [EOL] def setUp ( self ) : [EOL] Tag . objects . create ( name = [string] , scope = [string] ) [EOL] Tag . objects . create ( name = [string] , scope = [string] ) [EOL] [EOL] def test_first_artist_tag ( self ) : [EOL] [docstring] [EOL] artist_tag = Tag . objects . first_artist_tag ( ) [EOL] self . assertIsNotNone ( artist_tag ) [EOL] [EOL] def test_tag_formatting ( self ) : [EOL] [docstring] [EOL] tag = Tag . objects . get ( scope = [string] , name = [string] ) [EOL] self . assertIn ( [string] , str ( tag ) ) [EOL] [EOL] [EOL] class PrivateURLsTest ( TestCase ) : [EOL] def setUp ( self ) : [EOL] [EOL] [comment] [EOL] test_admin1 = User . objects . create_user ( username = [string] , password = [string] ) [EOL] test_admin1 . is_staff = True [EOL] test_admin1 . save ( ) [EOL] [EOL] [comment] [EOL] test_user1 = User . objects . create_user ( username = [string] , password = [string] ) [EOL] test_user1 . save ( ) [EOL] [EOL] [comment] [EOL] self . test_book1 = Archive . objects . create ( title = [string] , user = test_admin1 ) [EOL] self . test_book2 = Archive . objects . create ( title = [string] , user = test_admin1 , public = True ) [EOL] self . test_book3 = Archive . objects . create ( title = [string] , user = test_admin1 , public = True ) [EOL] [EOL] def test_redirect_if_not_logged_in ( self ) : [EOL] [docstring] [EOL] resp = self . client . get ( reverse ( [string] ) ) [EOL] self . assertEqual ( resp . status_code , [number] ) [EOL] self . assertTrue ( resp . url . startswith ( [string] ) ) [EOL] [EOL] def test_HTTP404_for_invalid_archive ( self ) : [EOL] self . client . login ( username = [string] , password = [string] ) [EOL] resp = self . client . get ( reverse ( [string] , args = [ [number] ] ) ) [EOL] self . assertEqual ( resp . status_code , [number] ) [EOL] self . client . logout ( ) [EOL] resp = self . client . get ( reverse ( [string] , args = [ [number] ] ) ) [EOL] self . assertEqual ( resp . status_code , [number] ) [EOL] [EOL] def test_HTTP404_for_non_public_archive_if_not_logged_in ( self ) : [EOL] resp = self . client . get ( reverse ( [string] , args = [ self . test_book1 . pk ] ) ) [EOL] self . assertEqual ( resp . status_code , [number] ) [EOL] [EOL] def test_for_public_archive_if_not_logged_in ( self ) : [EOL] resp = self . client . get ( reverse ( [string] , args = [ self . test_book2 . pk ] ) ) [EOL] self . assertEqual ( resp . status_code , [number] ) [EOL] [EOL] def test_public_archive_search ( self ) : [EOL] response = self . client . get ( reverse ( [string] ) , { [string] : [string] } ) [EOL] self . assertEqual ( response . status_code , [number] ) [EOL] [comment] [EOL] self . assertFalse ( response . context [ [string] ] . has_next ( ) ) [EOL] self . assertFalse ( response . context [ [string] ] . has_previous ( ) ) [EOL] [comment] [EOL] self . assertEqual ( len ( response . context [ [string] ] ) , [number] ) [EOL] [EOL] def test_logged_in_archive_search ( self ) : [EOL] [comment] [EOL] c = Client ( ) [EOL] c . login ( username = [string] , password = [string] ) [EOL] response = c . get ( reverse ( [string] ) , { [string] : [string] } ) [EOL] self . assertEqual ( response . status_code , [number] ) [EOL] self . assertEqual ( len ( response . context [ [string] ] ) , [number] ) [EOL] [EOL] def test_quick_search ( self ) : [EOL] [comment] [EOL] response = self . client . get ( reverse ( [string] ) , { [string] : [string] } ) [EOL] self . assertEqual ( response . status_code , [number] ) [EOL] [comment] [EOL] self . assertFalse ( response . context [ [string] ] . has_next ( ) ) [EOL] self . assertFalse ( response . context [ [string] ] . has_previous ( ) ) [EOL] [comment] [EOL] self . assertEqual ( len ( response . context [ [string] ] ) , [number] ) [EOL] [EOL] [EOL] class GeneralPagesTest ( TestCase ) : [EOL] def setUp ( self ) : [EOL] [EOL] [comment] [EOL] test_admin1 = User . objects . create_user ( username = [string] , password = [string] ) [EOL] test_admin1 . is_staff = True [EOL] test_admin1 . save ( ) [EOL] [EOL] [comment] [EOL] test_user1 = User . objects . create_user ( username = [string] , password = [string] ) [EOL] test_user1 . save ( ) [EOL] [EOL] [comment] [EOL] self . test_gallery1 = Gallery . objects . create ( title = [string] , gid = [string] , provider = [string] ) [EOL] self . test_gallery2 = Gallery . objects . create ( title = [string] , gid = [string] , provider = [string] ) [EOL] self . test_gallery3 = Gallery . objects . create ( title = [string] , gid = [string] , provider = [string] , public = True ) [EOL] [EOL] [comment] [EOL] self . test_book1 = Archive . objects . create ( title = [string] , user = test_admin1 , gallery = self . test_gallery1 ) [EOL] self . test_book1b = Archive . objects . create ( title = [string] , user = test_admin1 , gallery = self . test_gallery1 ) [EOL] self . test_book2 = Archive . objects . create ( title = [string] , user = test_admin1 , gallery = self . test_gallery2 , public = True ) [EOL] self . test_book3 = Archive . objects . create ( title = [string] , user = test_admin1 , public = True ) [EOL] self . test_book4 = Archive . objects . create ( title = [string] , user = test_admin1 , gallery = self . test_gallery2 , public = True ) [EOL] self . test_book5 = Archive . objects . create ( title = [string] , user = test_admin1 , gallery = self . test_gallery2 , public = True ) [EOL] [EOL] def test_repeated_archives ( self ) : [EOL] c = Client ( ) [EOL] c . login ( username = [string] , password = [string] ) [EOL] response = c . get ( reverse ( [string] ) , { [string] : [string] } ) [EOL] self . assertEqual ( response . status_code , [number] ) [EOL] [comment] [EOL] self . assertFalse ( response . context [ [string] ] . has_next ( ) ) [EOL] self . assertFalse ( response . context [ [string] ] . has_previous ( ) ) [EOL] [comment] [EOL] self . assertEqual ( len ( response . context [ [string] ] ) , [number] ) [EOL] self . assertEqual ( response . context [ [string] ] [ [number] ] . archive_set . count ( ) , [number] ) [EOL] self . assertEqual ( response . context [ [string] ] [ [number] ] . archive_set . count ( ) , [number] ) [EOL] [EOL] [comment] [EOL] response = c . post ( reverse ( [string] ) , { [string] . format ( self . test_gallery1 . pk ) : [ self . test_book1b . pk ] } ) [EOL] self . assertEqual ( response . status_code , [number] ) [EOL] self . assertEqual ( Archive . objects . count ( ) , [number] ) [EOL] self . assertEqual ( len ( response . context [ [string] ] ) , [number] ) [EOL] [EOL] [comment] [EOL] response = c . get ( reverse ( [string] ) ) [EOL] self . assertEqual ( response . status_code , [number] ) [EOL] [EOL] def test_main_pages_anonymous ( self ) : [EOL] c = Client ( ) [EOL] [comment] [EOL] response = c . get ( reverse ( [string] ) ) [EOL] self . assertEqual ( response . status_code , [number] ) [EOL] response = c . get ( reverse ( [string] ) , { [string] : [string] } ) [EOL] self . assertEqual ( response . status_code , [number] ) [EOL] response = c . get ( reverse ( [string] ) , { [string] : [string] } ) [EOL] self . assertEqual ( response . status_code , [number] ) [EOL] [EOL] response = c . get ( reverse ( [string] ) ) [EOL] self . assertEqual ( response . status_code , [number] ) [EOL] [EOL] response = c . get ( reverse ( [string] ) ) [EOL] self . assertEqual ( response . status_code , [number] ) [EOL] [EOL] response = c . get ( reverse ( [string] ) ) [EOL] self . assertEqual ( response . status_code , [number] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] response = c . get ( reverse ( [string] ) ) [EOL] self . assertEqual ( response . status_code , [number] ) [EOL] [EOL] def test_element_pages_anonymous ( self ) : [EOL] c = Client ( ) [EOL] [comment] [EOL] response = c . get ( reverse ( [string] , args = [ self . test_book2 . pk ] ) ) [EOL] self . assertEqual ( response . status_code , [number] ) [EOL] response = c . get ( reverse ( [string] , args = [ self . test_gallery3 . pk ] ) ) [EOL] self . assertEqual ( response . status_code , [number] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0
	0
	0
[comment] [EOL] [comment] [EOL] [EOL] from typing import Any , Iterable , Literal , Dict , Tuple , Set , Union , List [EOL] import typing [EOL] import viewer [EOL] import core [EOL] import typing_extensions [EOL] import django [EOL] import builtins [EOL] import json [EOL] import re [EOL] from collections import defaultdict [EOL] [EOL] from typing import Dict , Any , List , Union , Iterable [EOL] [EOL] from django . core . paginator import Paginator , EmptyPage [EOL] from django . db . models import Q , QuerySet [EOL] from django . http import HttpResponse , HttpRequest [EOL] from django . http . request import QueryDict [EOL] from django . urls import reverse [EOL] from django . views . decorators . csrf import csrf_exempt [EOL] from django . conf import settings [EOL] [EOL] from core . base . setup import Settings [EOL] from core . base . utilities import str_to_int [EOL] from core . base . utilities import timestamp_or_zero [EOL] from viewer . models import Archive , Gallery , ArchiveQuerySet , GalleryQuerySet [EOL] from viewer . utils . matching import generate_possible_matches_for_archives [EOL] from viewer . views . head import gallery_filter_keys , gallery_order_fields , filter_archives_simple , archive_filter_keys [EOL] [EOL] crawler_settings = settings . CRAWLER_SETTINGS [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] @ csrf_exempt def json_search ( request ) : [EOL] [EOL] if request . method == [string] : [EOL] data = request . GET [EOL] [comment] [EOL] if [string] in data : [EOL] try : [EOL] archive_id = int ( data [ [string] ] ) [EOL] except ValueError : [EOL] return HttpResponse ( json . dumps ( { [string] : [string] } ) , content_type = [string] ) [EOL] try : [EOL] archive = Archive . objects . get ( pk = archive_id ) [EOL] except Archive . DoesNotExist : [EOL] return HttpResponse ( json . dumps ( { [string] : [string] } ) , content_type = [string] ) [EOL] if not archive . public and not request . user . is_authenticated : [EOL] return HttpResponse ( json . dumps ( { [string] : [string] } ) , content_type = [string] ) [EOL] response = json . dumps ( { [string] : archive . title , [string] : archive . title_jpn , [string] : archive . gallery . category if archive . gallery else [string] , [string] : archive . gallery . uploader if archive . gallery else [string] , [string] : int ( timestamp_or_zero ( archive . gallery . posted ) ) if archive . gallery else [string] , [string] : archive . filecount , [string] : archive . filesize , [string] : archive . gallery . expunged if archive . gallery else [string] , [string] : float ( str_to_int ( archive . gallery . rating ) ) if archive . gallery else [string] , [string] : archive . gallery . fjord if archive . gallery else [string] , [string] : archive . tag_list ( ) , [string] : reverse ( [string] , args = ( archive . pk , ) ) , [string] : archive . gallery . pk if archive . gallery else [string] , } , sort_keys = True , ensure_ascii = False , ) [EOL] return HttpResponse ( response , content_type = [string] ) [EOL] [comment] [EOL] elif [string] in data : [EOL] try : [EOL] archive_id = int ( data [ [string] ] ) [EOL] except ValueError : [EOL] return HttpResponse ( json . dumps ( { [string] : [string] } ) , content_type = [string] ) [EOL] try : [EOL] archive = Archive . objects . get ( pk = archive_id ) [EOL] except Archive . DoesNotExist : [EOL] return HttpResponse ( json . dumps ( { [string] : [string] } ) , content_type = [string] ) [EOL] if not archive . public and not request . user . is_authenticated : [EOL] return HttpResponse ( json . dumps ( { [string] : [string] } ) , content_type = [string] ) [EOL] response = json . dumps ( { [string] : archive . tag_list_sorted ( ) , } , sort_keys = True , ensure_ascii = False , ) [EOL] return HttpResponse ( response , content_type = [string] ) [EOL] [comment] [EOL] elif [string] in data : [EOL] try : [EOL] gallery_id = int ( data [ [string] ] ) [EOL] except ValueError : [EOL] return HttpResponse ( json . dumps ( { [string] : [string] } ) , content_type = [string] ) [EOL] try : [EOL] gallery = Gallery . objects . get ( pk = gallery_id ) [EOL] except Gallery . DoesNotExist : [EOL] return HttpResponse ( json . dumps ( { [string] : [string] } ) , content_type = [string] ) [EOL] if not gallery . public and not request . user . is_authenticated : [EOL] return HttpResponse ( json . dumps ( { [string] : [string] } ) , content_type = [string] ) [EOL] response = json . dumps ( { [string] : gallery . title , [string] : gallery . title_jpn , [string] : gallery . category , [string] : gallery . uploader , [string] : int ( timestamp_or_zero ( gallery . posted ) ) , [string] : gallery . filecount , [string] : gallery . filesize , [string] : gallery . expunged , [string] : float ( str_to_int ( gallery . rating ) ) , [string] : gallery . fjord , [string] : gallery . tag_list ( ) , [string] : [ { [string] : archive . id , [string] : reverse ( [string] , args = ( archive . pk , ) ) } for archive in gallery . archive_set . filter_by_authenticated_status ( authenticated = request . user . is_authenticated ) ] , } , sort_keys = True , ensure_ascii = False , ) [EOL] return HttpResponse ( response , content_type = [string] ) [EOL] [comment] [EOL] elif [string] in data : [EOL] archives = Archive . objects . filter ( image__sha1 = data [ [string] ] ) [EOL] if not archives : [EOL] return HttpResponse ( json . dumps ( [ ] ) , content_type = [string] ) [EOL] if not request . user . is_authenticated : [EOL] archives = archives . filter ( public = True ) [EOL] if not archives : [EOL] return HttpResponse ( json . dumps ( [ ] ) , content_type = [string] ) [EOL] response = json . dumps ( [ { [string] : archive . id , [string] : archive . title , [string] : archive . title_jpn , [string] : archive . gallery . category if archive . gallery else [string] , [string] : archive . gallery . uploader if archive . gallery else [string] , [string] : int ( timestamp_or_zero ( archive . gallery . posted ) ) if archive . gallery else [string] , [string] : archive . filecount , [string] : archive . filesize , [string] : archive . gallery . expunged if archive . gallery else [string] , [string] : float ( str_to_int ( archive . gallery . rating ) ) if archive . gallery else [string] , [string] : archive . gallery . fjord if archive . gallery else [string] , [string] : archive . tag_list ( ) , [string] : reverse ( [string] , args = ( archive . pk , ) ) , [string] : archive . gallery . pk if archive . gallery else [string] , } for archive in archives ] , sort_keys = True , ensure_ascii = False , ) [EOL] return HttpResponse ( response , content_type = [string] ) [EOL] [comment] [EOL] elif [string] in data : [EOL] [EOL] archive_args = request . GET . copy ( ) [EOL] [EOL] params = { [string] : [string] , [string] : [string] , } [EOL] [EOL] for k , v in archive_args . items ( ) : [EOL] params [ k ] = v [EOL] [EOL] for k in archive_filter_keys : [EOL] if k not in params : [EOL] params [ k ] = [string] [EOL] [EOL] results = filter_archives_simple ( params ) [EOL] [EOL] if not request . user . is_authenticated : [EOL] results = results . filter ( public = True ) . order_by ( [string] ) [EOL] [EOL] response = json . dumps ( [ { [string] : o . pk , [string] : o . title , [string] : o . tag_list ( ) , [string] : reverse ( [string] , args = ( o . pk , ) ) } for o in results ] ) [EOL] return HttpResponse ( response , content_type = [string] ) [EOL] [comment] [EOL] elif [string] in data : [EOL] q_args = data [ [string] ] [EOL] if not request . user . is_authenticated : [EOL] results = simple_archive_filter ( q_args , public = True ) [EOL] else : [EOL] results = simple_archive_filter ( q_args , public = False ) [EOL] response = json . dumps ( [ { [string] : o . pk , [string] : o . title , [string] : o . tag_list ( ) , [string] : reverse ( [string] , args = ( o . pk , ) ) } for o in results ] ) [EOL] return HttpResponse ( response , content_type = [string] ) [EOL] [comment] [EOL] elif [string] in data : [EOL] galleries = Gallery . objects . filter ( Q ( archive__crc32 = data [ [string] ] ) ) [EOL] if not galleries : [EOL] return HttpResponse ( json . dumps ( [ ] ) , content_type = [string] ) [EOL] if not request . user . is_authenticated : [EOL] galleries = galleries . filter ( public = True ) [EOL] if not galleries : [EOL] return HttpResponse ( json . dumps ( [ ] ) , content_type = [string] ) [EOL] response = json . dumps ( [ { [string] : gallery . pk , [string] : gallery . gid , [string] : gallery . token , [string] : gallery . title , [string] : gallery . title_jpn , [string] : gallery . category , [string] : gallery . uploader , [string] : gallery . comment , [string] : int ( timestamp_or_zero ( gallery . posted ) ) , [string] : gallery . filecount , [string] : gallery . filesize , [string] : gallery . expunged , [string] : gallery . provider , [string] : gallery . rating , [string] : gallery . reason , [string] : gallery . fjord , [string] : gallery . tag_list ( ) , [string] : gallery . get_link ( ) , [string] : request . build_absolute_uri ( reverse ( [string] , args = ( gallery . pk , ) ) ) if gallery . thumbnail else [string] , [string] : gallery . thumbnail_url , [string] : gallery . thumbnail_height , [string] : gallery . thumbnail_width , [string] : gallery . gallery_container . gid if gallery . gallery_container else [string] } for gallery in galleries ] , sort_keys = True , ensure_ascii = False , ) [EOL] return HttpResponse ( response , content_type = [string] ) [EOL] [comment] [EOL] elif [string] in data : [EOL] [EOL] args = data . copy ( ) [EOL] [EOL] for k in gallery_filter_keys : [EOL] if k not in args : [EOL] args [ k ] = [string] [EOL] [EOL] keys = ( [string] , [string] ) [EOL] [EOL] for k in keys : [EOL] if k not in args : [EOL] args [ k ] = [string] [EOL] [EOL] [comment] [EOL] if not request . user . is_authenticated : [EOL] args [ [string] ] = True [comment] [EOL] else : [EOL] args [ [string] ] = False [comment] [EOL] results_gallery = filter_galleries_no_request ( args ) [EOL] if not results_gallery : [EOL] return HttpResponse ( json . dumps ( [ ] ) , content_type = [string] ) [EOL] response = json . dumps ( [ { [string] : gallery . title , [string] : gallery . title_jpn , [string] : gallery . category , [string] : gallery . uploader , [string] : int ( timestamp_or_zero ( gallery . posted ) ) , [string] : gallery . filecount , [string] : gallery . filesize , [string] : gallery . expunged , [string] : gallery . provider , [string] : float ( str_to_int ( gallery . rating ) ) , [string] : gallery . fjord , [string] : gallery . tag_list ( ) , } for gallery in results_gallery ] , sort_keys = True , ensure_ascii = False , ) [EOL] return HttpResponse ( response , content_type = [string] ) [EOL] [comment] [EOL] [comment] [EOL] elif [string] in data : [EOL] [EOL] args = data . copy ( ) [EOL] [EOL] for k in gallery_filter_keys : [EOL] if k not in args : [EOL] args [ k ] = [string] [EOL] [EOL] keys = ( [string] , [string] ) [EOL] [EOL] for k in keys : [EOL] if k not in args : [EOL] args [ k ] = [string] [EOL] [EOL] [comment] [EOL] if not request . user . is_authenticated : [EOL] args [ [string] ] = True [comment] [EOL] else : [EOL] args [ [string] ] = False [comment] [EOL] results_gallery = filter_galleries_no_request ( args ) [EOL] if not results_gallery : [EOL] return HttpResponse ( json . dumps ( [ ] ) , content_type = [string] ) [EOL] response = json . dumps ( [ { [string] : gallery . gid , [string] : gallery . token , [string] : gallery . title , [string] : gallery . title_jpn , [string] : gallery . category , [string] : gallery . uploader , [string] : int ( timestamp_or_zero ( gallery . posted ) ) , [string] : gallery . filecount , [string] : gallery . filesize , [string] : gallery . expunged , [string] : gallery . provider , [string] : gallery . rating , [string] : gallery . fjord , [string] : gallery . tag_list ( ) , [string] : gallery . get_link ( ) } for gallery in results_gallery ] , sort_keys = True , ensure_ascii = False , ) [EOL] return HttpResponse ( response , content_type = [string] ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] elif [string] in data : [EOL] [EOL] args = data . copy ( ) [EOL] [EOL] for k in gallery_filter_keys : [EOL] if k not in args : [EOL] args [ k ] = [string] [EOL] [EOL] keys = ( [string] , [string] ) [EOL] [EOL] for k in keys : [EOL] if k not in args : [EOL] args [ k ] = [string] [EOL] [EOL] [comment] [EOL] if not request . user . is_authenticated : [EOL] args [ [string] ] = True [comment] [EOL] else : [EOL] args [ [string] ] = False [comment] [EOL] results_gallery = filter_galleries_no_request ( args ) [EOL] if not results_gallery : [EOL] return HttpResponse ( json . dumps ( [ ] ) , content_type = [string] ) [EOL] response = json . dumps ( gallery_search_results_to_json ( request , results_gallery ) , sort_keys = True , ensure_ascii = False , ) [EOL] return HttpResponse ( response , content_type = [string] ) [EOL] [comment] [EOL] elif [string] in data : [EOL] [EOL] args = data . copy ( ) [EOL] [EOL] for k in gallery_filter_keys : [EOL] if k not in args : [EOL] args [ k ] = [string] [EOL] [EOL] keys = ( [string] , [string] ) [EOL] [EOL] for k in keys : [EOL] if k not in args : [EOL] args [ k ] = [string] [EOL] [EOL] [comment] [EOL] if not request . user . is_authenticated : [EOL] args [ [string] ] = True [comment] [EOL] else : [EOL] args [ [string] ] = False [comment] [EOL] results_gallery = filter_galleries_no_request ( args ) [EOL] [EOL] paginator = Paginator ( results_gallery , [number] ) [EOL] try : [EOL] page = int ( args . get ( [string] , [string] ) ) [EOL] except ValueError : [EOL] page = [number] [EOL] try : [EOL] results_page = paginator . page ( page ) [EOL] except EmptyPage : [EOL] [comment] [EOL] results_page = paginator . page ( paginator . num_pages ) [EOL] [EOL] response = json . dumps ( { [string] : gallery_search_results_to_json ( request , results_page ) , [string] : results_page . has_previous ( ) , [string] : results_page . has_next ( ) , [string] : paginator . num_pages , [string] : paginator . count , [string] : results_page . number , } , sort_keys = True , ensure_ascii = False , ) [EOL] return HttpResponse ( response , content_type = [string] ) [EOL] [comment] [EOL] elif [string] in data : [EOL] try : [EOL] gallery_id = int ( data [ [string] ] ) [EOL] except ValueError : [EOL] return HttpResponse ( json . dumps ( { [string] : [string] } ) , content_type = [string] ) [EOL] try : [EOL] gallery = Gallery . objects . get ( pk = gallery_id ) [EOL] except Gallery . DoesNotExist : [EOL] return HttpResponse ( json . dumps ( { [string] : [string] } ) , content_type = [string] ) [EOL] if not gallery . public and not request . user . is_authenticated : [EOL] return HttpResponse ( json . dumps ( { [string] : [string] } ) , content_type = [string] ) [EOL] response = json . dumps ( { [string] : gallery . pk , [string] : gallery . gid , [string] : gallery . token , [string] : gallery . title , [string] : gallery . title_jpn , [string] : gallery . category , [string] : gallery . uploader , [string] : gallery . comment , [string] : int ( timestamp_or_zero ( gallery . posted ) ) , [string] : gallery . filecount , [string] : gallery . filesize , [string] : gallery . expunged , [string] : gallery . provider , [string] : gallery . rating , [string] : gallery . fjord , [string] : gallery . tag_list ( ) , [string] : gallery . get_link ( ) , [string] : request . build_absolute_uri ( reverse ( [string] , args = ( gallery . pk , ) ) ) if gallery . thumbnail else [string] , [string] : gallery . thumbnail_url , [string] : [ { [string] : request . build_absolute_uri ( reverse ( [string] , args = ( archive . pk , ) ) ) , [string] : archive . source_type , [string] : archive . reason } for archive in gallery . archive_set . filter_by_authenticated_status ( authenticated = request . user . is_authenticated ) ] , } , sort_keys = True , ensure_ascii = False , ) [EOL] return HttpResponse ( response , content_type = [string] ) [EOL] else : [EOL] return HttpResponse ( json . dumps ( { [string] : [string] } ) , content_type = [string] ) [EOL] else : [EOL] return HttpResponse ( json . dumps ( { [string] : [string] } ) , content_type = [string] ) [EOL] [EOL] [EOL] def gallery_search_results_to_json ( request , galleries ) : [EOL] return [ { [string] : gallery . pk , [string] : gallery . gid , [string] : gallery . token , [string] : gallery . title , [string] : gallery . title_jpn , [string] : gallery . category , [string] : gallery . uploader , [string] : gallery . comment , [string] : int ( timestamp_or_zero ( gallery . posted ) ) , [string] : gallery . filecount , [string] : gallery . filesize , [string] : gallery . expunged , [string] : gallery . provider , [string] : gallery . rating , [string] : gallery . fjord , [string] : gallery . tag_list ( ) , [string] : gallery . get_link ( ) , [string] : request . build_absolute_uri ( reverse ( [string] , args = ( gallery . pk , ) ) ) if gallery . thumbnail else [string] , [string] : gallery . thumbnail_url , [string] : [ { [string] : request . build_absolute_uri ( reverse ( [string] , args = ( archive . pk , ) ) ) , [string] : archive . source_type , [string] : archive . reason } for archive in gallery . archive_set . filter_by_authenticated_status ( authenticated = request . user . is_authenticated ) ] , } for gallery in galleries ] [EOL] [EOL] [EOL] [comment] [EOL] @ csrf_exempt def json_parser ( request ) : [EOL] response = { } [EOL] [EOL] if request . method == [string] : [EOL] if not request . body : [EOL] response [ [string] ] = [string] [EOL] return HttpResponse ( json . dumps ( response ) , content_type = [string] ) [EOL] data = json . loads ( request . body . decode ( [string] ) ) [EOL] if [string] not in data : [EOL] response [ [string] ] = [string] [EOL] return HttpResponse ( json . dumps ( response ) , content_type = [string] ) [EOL] elif data [ [string] ] != crawler_settings . api_key : [EOL] response [ [string] ] = [string] [EOL] return HttpResponse ( json . dumps ( response ) , content_type = [string] ) [EOL] [comment] [EOL] else : [EOL] if [string] not in data or [string] not in data : [EOL] response [ [string] ] = [string] [EOL] else : [EOL] args = data [ [string] ] [EOL] response = { } [EOL] [comment] [EOL] if data [ [string] ] == [string] and [string] in args : [EOL] if not crawler_settings . workers . web_queue : [EOL] response [ [string] ] = [string] [EOL] elif [string] in args : [EOL] current_settings = Settings ( load_from_config = crawler_settings . config ) [EOL] if not current_settings . workers . web_queue : [EOL] response [ [string] ] = [string] [EOL] else : [EOL] current_settings . allow_downloaders_only ( [ args [ [string] ] ] , True , True , True ) [EOL] archive = None [EOL] parsers = current_settings . provider_context . get_parsers ( current_settings ) [EOL] for parser in parsers : [EOL] if parser . id_from_url_implemented ( ) : [EOL] urls_filtered = parser . filter_accepted_urls ( ( args [ [string] ] , ) ) [EOL] for url_filtered in urls_filtered : [EOL] gallery_gid = parser . id_from_url ( url_filtered ) [EOL] if gallery_gid : [EOL] archive = Archive . objects . filter ( gallery__gid = gallery_gid , gallery__provider = parser . name ) . first ( ) [EOL] if urls_filtered : [EOL] break [EOL] current_settings . workers . web_queue . enqueue_args_list ( ( args [ [string] ] , ) , override_options = current_settings ) [EOL] if archive : [EOL] response [ [string] ] = [string] + args [ [string] ] [EOL] else : [EOL] response [ [string] ] = [string] + args [ [string] ] [EOL] else : [EOL] if [string] in args : [EOL] parent_archive = None [EOL] parsers = crawler_settings . provider_context . get_parsers ( crawler_settings ) [EOL] for parser in parsers : [EOL] if parser . id_from_url_implemented ( ) : [EOL] urls_filtered = parser . filter_accepted_urls ( ( args [ [string] ] , ) ) [EOL] for url_filtered in urls_filtered : [EOL] gallery_gid = parser . id_from_url ( url_filtered ) [EOL] if gallery_gid : [EOL] parent_archive = Archive . objects . filter ( gallery__gid = gallery_gid , gallery__provider = parser . name ) . first ( ) [EOL] if urls_filtered : [EOL] break [EOL] if parent_archive and parent_archive . gallery : [EOL] link = parent_archive . gallery . get_link ( ) [EOL] if [string] in args and args [ [string] ] == [string] : [EOL] parent_archive . gallery . mark_as_deleted ( ) [EOL] parent_archive . gallery = None [EOL] parent_archive . delete_all_files ( ) [EOL] parent_archive . delete_files_but_archive ( ) [EOL] parent_archive . delete ( ) [EOL] response [ [string] ] = [string] + args [ [string] ] + [string] + link [EOL] crawler_settings . workers . web_queue . enqueue_args ( args [ [string] ] ) [EOL] elif [string] in args and args [ [string] ] == [string] : [EOL] response [ [string] ] = [string] + args [ [string] ] + [string] + link [EOL] crawler_settings . workers . web_queue . enqueue_args ( args [ [string] ] ) [EOL] else : [EOL] response [ [string] ] = [string] + link [EOL] response [ [string] ] = [string] [EOL] else : [EOL] archive = None [EOL] parsers = crawler_settings . provider_context . get_parsers ( crawler_settings ) [EOL] for parser in parsers : [EOL] if parser . id_from_url_implemented ( ) : [EOL] urls_filtered = parser . filter_accepted_urls ( ( args [ [string] ] , ) ) [EOL] for url_filtered in urls_filtered : [EOL] gallery_gid = parser . id_from_url ( url_filtered ) [EOL] if gallery_gid : [EOL] archive = Archive . objects . filter ( gallery__gid = gallery_gid , gallery__provider = parser . name ) . first ( ) [EOL] if urls_filtered : [EOL] break [EOL] if archive : [EOL] response [ [string] ] = [string] + args [ [string] ] [EOL] else : [EOL] response [ [string] ] = [string] + args [ [string] ] [EOL] crawler_settings . workers . web_queue . enqueue_args ( args [ [string] ] ) [EOL] else : [EOL] archive = None [EOL] parsers = crawler_settings . provider_context . get_parsers ( crawler_settings ) [EOL] for parser in parsers : [EOL] if parser . id_from_url_implemented ( ) : [EOL] urls_filtered = parser . filter_accepted_urls ( ( args [ [string] ] , ) ) [EOL] for url_filtered in urls_filtered : [EOL] gallery_gid = parser . id_from_url ( url_filtered ) [EOL] if gallery_gid : [EOL] archive = Archive . objects . filter ( gallery__gid = gallery_gid , gallery__provider = parser . name ) . first ( ) [EOL] if urls_filtered : [EOL] break [EOL] if archive : [EOL] response [ [string] ] = [string] + args [ [string] ] [EOL] else : [EOL] response [ [string] ] = [string] + args [ [string] ] [EOL] crawler_settings . workers . web_queue . enqueue_args ( args [ [string] ] ) [EOL] if not response : [EOL] response [ [string] ] = [string] [EOL] return HttpResponse ( json . dumps ( response ) , content_type = [string] ) [EOL] [comment] [EOL] elif data [ [string] ] == [string] : [EOL] provider_dict = defaultdict ( list ) [EOL] for gid_provider in args : [EOL] provider_dict [ gid_provider [ [number] ] ] . append ( gid_provider [ [number] ] ) [EOL] gallery_ids = [ ] [EOL] for provider , gid_list in provider_dict . items ( ) : [EOL] gallery_ids . append ( Gallery . objects . filter ( provider = provider , gid__in = gid_list ) . values_list ( [string] , flat = True ) ) [EOL] archives_query = Archive . objects . filter_non_existent ( crawler_settings . MEDIA_ROOT , gallery__pk__in = gallery_ids ) [EOL] archives = [ { [string] : archive . gallery . gid , [string] : archive . gallery . provider , [string] : archive . id , [string] : archive . zipped . name , [string] : archive . filesize } for archive in archives_query if archive . gallery ] [EOL] response_text = json . dumps ( { [string] : archives } ) [EOL] return HttpResponse ( response_text , content_type = [string] ) [EOL] [comment] [EOL] elif data [ [string] ] in ( [string] , [string] ) : [EOL] urls = args [EOL] new_urls_set = set ( ) [EOL] gids_set = set ( ) [EOL] [EOL] parsers = crawler_settings . provider_context . get_parsers ( crawler_settings ) [EOL] for parser in parsers : [EOL] if parser . id_from_url_implemented ( ) : [EOL] urls_filtered = parser . filter_accepted_urls ( urls ) [EOL] for url in urls_filtered : [EOL] gid = parser . id_from_url ( url ) [EOL] gids_set . add ( gid ) [EOL] [EOL] gids_list = list ( gids_set ) [EOL] [EOL] existing_galleries = Gallery . objects . filter ( gid__in = gids_list ) [EOL] for gallery_object in existing_galleries : [EOL] if gallery_object . is_submitted ( ) : [EOL] gallery_object . delete ( ) [EOL] [comment] [EOL] elif data [ [string] ] == [string] and [string] in gallery_object . dl_type and not gallery_object . archive_set . all ( ) : [EOL] gallery_object . delete ( ) [EOL] elif data [ [string] ] == [string] and not gallery_object . archive_set . all ( ) : [EOL] gallery_object . delete ( ) [EOL] already_present_gids = list ( Gallery . objects . filter ( gid__in = gids_list ) . values_list ( [string] , flat = True ) ) [EOL] [comment] [EOL] [EOL] for parser in parsers : [EOL] if parser . id_from_url_implemented ( ) : [EOL] urls_filtered = parser . filter_accepted_urls ( urls ) [EOL] for url in urls_filtered : [EOL] gid = parser . id_from_url ( url ) [EOL] if gid not in already_present_gids : [EOL] new_urls_set . add ( url ) [EOL] [EOL] pages_links = list ( new_urls_set ) [EOL] if len ( pages_links ) > [number] : [EOL] current_settings = Settings ( load_from_config = crawler_settings . config ) [EOL] if data [ [string] ] == [string] : [EOL] current_settings . allow_type_downloaders_only ( [string] ) [EOL] elif data [ [string] ] == [string] : [EOL] if [string] in data : [EOL] current_settings . archive_reason = data [ [string] ] [EOL] if [string] in data : [EOL] current_settings . archive_details = data [ [string] ] [EOL] current_settings . allow_type_downloaders_only ( [string] ) [EOL] if current_settings . workers . web_queue : [EOL] current_settings . workers . web_queue . enqueue_args_list ( pages_links , override_options = current_settings ) [EOL] else : [EOL] pages_links = [ ] [EOL] return HttpResponse ( json . dumps ( { [string] : str ( len ( pages_links ) ) } ) , content_type = [string] ) [EOL] [comment] [EOL] elif data [ [string] ] == [string] : [EOL] links = args [EOL] if len ( links ) > [number] and crawler_settings . workers . web_queue : [EOL] crawler_settings . workers . web_queue . enqueue_args_list ( links ) [EOL] return HttpResponse ( json . dumps ( { [string] : str ( len ( links ) ) } ) , content_type = [string] ) [EOL] [comment] [EOL] elif data [ [string] ] == [string] : [EOL] archive_obj = Archive . objects . filter ( pk = args [ [string] ] ) [EOL] if archive_obj : [EOL] generate_possible_matches_for_archives ( archive_obj , filters = ( args [ [string] ] , ) , match_local = False , match_web = True , ) [EOL] return HttpResponse ( json . dumps ( { [string] : [string] } ) , content_type = [string] ) [EOL] elif data [ [string] ] == [string] : [EOL] archive = Archive . objects . get ( pk = args [ [string] ] ) [EOL] if archive : [EOL] clear_title = True if [string] in args else False [EOL] provider_filter = args . get ( [string] , [string] ) [EOL] try : [EOL] cutoff = float ( request . GET . get ( [string] , [string] ) ) [EOL] except ValueError : [EOL] cutoff = [number] [EOL] try : [EOL] max_matches = int ( request . GET . get ( [string] , [string] ) ) [EOL] except ValueError : [EOL] max_matches = [number] [EOL] [EOL] archive . generate_possible_matches ( clear_title = clear_title , provider_filter = provider_filter , cutoff = cutoff , max_matches = max_matches ) [EOL] archive . save ( ) [EOL] return HttpResponse ( json . dumps ( { [string] : [string] } ) , content_type = [string] ) [EOL] else : [EOL] response [ [string] ] = [string] [EOL] elif request . method == [string] : [EOL] data = request . GET [EOL] if [string] not in data : [EOL] response [ [string] ] = [string] [EOL] return HttpResponse ( json . dumps ( response ) , content_type = [string] ) [EOL] elif data [ [string] ] != crawler_settings . api_key : [EOL] response [ [string] ] = [string] [EOL] return HttpResponse ( json . dumps ( response ) , content_type = [string] ) [EOL] [comment] [EOL] else : [EOL] if [string] in data : [EOL] args = data . copy ( ) [EOL] [EOL] for k in gallery_filter_keys : [EOL] if k not in args : [EOL] args [ k ] = [string] [EOL] [EOL] keys = ( [string] , [string] ) [EOL] [EOL] for k in keys : [EOL] if k not in args : [EOL] args [ k ] = [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] args [ [string] ] = False [EOL] [EOL] results = filter_galleries_no_request ( args ) [EOL] if not results : [EOL] return HttpResponse ( json . dumps ( [ ] ) , content_type = [string] ) [EOL] response_text = json . dumps ( [ { [string] : gallery . gid , [string] : gallery . token , [string] : gallery . title , [string] : gallery . title_jpn , [string] : gallery . category , [string] : gallery . uploader , [string] : gallery . comment , [string] : int ( timestamp_or_zero ( gallery . posted ) ) , [string] : gallery . filecount , [string] : gallery . filesize , [string] : gallery . expunged , [string] : gallery . rating , [string] : gallery . hidden , [string] : gallery . fjord , [string] : gallery . public , [string] : gallery . provider , [string] : gallery . dl_type , [string] : gallery . tag_list ( ) , [string] : gallery . get_link ( ) , [string] : request . build_absolute_uri ( reverse ( [string] , args = ( gallery . pk , ) ) ) if gallery . thumbnail else [string] , [string] : gallery . thumbnail_url } for gallery in results ] , sort_keys = True , ensure_ascii = False , ) [EOL] return HttpResponse ( response_text , content_type = [string] ) [EOL] else : [EOL] response [ [string] ] = [string] [EOL] else : [EOL] response [ [string] ] = [string] . format ( request . method ) [EOL] return HttpResponse ( json . dumps ( response ) , content_type = [string] ) [EOL] [EOL] [EOL] def simple_archive_filter ( args , public = True ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] order = [string] [EOL] [EOL] if public : [EOL] results = Archive . objects . order_by ( order ) . filter ( public = True ) [EOL] else : [EOL] results = Archive . objects . order_by ( order ) [EOL] [EOL] q_formatted = [string] + args . replace ( [string] , [string] ) + [string] [EOL] results_title = results . filter ( Q ( title__ss = q_formatted ) | Q ( title_jpn__ss = q_formatted ) ) [EOL] [EOL] tags = args . split ( [string] ) [EOL] for tag in tags : [EOL] tag = tag . strip ( ) . replace ( [string] , [string] ) [EOL] tag_clean = re . sub ( [string] , [string] , tag ) [EOL] scope_name = tag_clean . split ( [string] , maxsplit = [number] ) [EOL] if len ( scope_name ) > [number] : [EOL] tag_scope = scope_name [ [number] ] [EOL] tag_name = scope_name [ [number] ] [EOL] else : [EOL] tag_scope = [string] [EOL] tag_name = scope_name [ [number] ] [EOL] if tag . startswith ( [string] ) : [EOL] if tag_name != [string] and tag_scope != [string] : [EOL] tag_query = ( ( Q ( tags__name__contains = tag_name ) & Q ( tags__scope__contains = tag_scope ) ) | ( Q ( custom_tags__name__contains = tag_name ) & Q ( custom_tags__scope__contains = tag_scope ) ) ) [EOL] elif tag_name != [string] : [EOL] tag_query = ( Q ( tags__name__contains = tag_name ) | Q ( custom_tags__name__contains = tag_name ) ) [EOL] else : [EOL] tag_query = ( Q ( tags__scope__contains = tag_scope ) | Q ( custom_tags__scope__contains = tag_scope ) ) [EOL] [EOL] results = results . exclude ( tag_query ) [EOL] elif tag . startswith ( [string] ) : [EOL] if tag_name != [string] and tag_scope != [string] : [EOL] tag_query = ( ( Q ( tags__name__exact = tag_name ) & Q ( tags__scope__exact = tag_scope ) ) | ( Q ( custom_tags__name__exact = tag_name ) & Q ( custom_tags__scope__exact = tag_scope ) ) ) [EOL] elif tag_name != [string] : [EOL] tag_query = ( Q ( tags__name__exact = tag_name ) | Q ( custom_tags__name__exact = tag_name ) ) [EOL] else : [EOL] tag_query = ( Q ( tags__scope__exact = tag_scope ) | Q ( custom_tags__scope__exact = tag_scope ) ) [EOL] [EOL] results = results . filter ( tag_query ) [EOL] else : [EOL] if tag_name != [string] and tag_scope != [string] : [EOL] tag_query = ( ( Q ( tags__name__contains = tag_name ) & Q ( tags__scope__contains = tag_scope ) ) | ( Q ( custom_tags__name__contains = tag_name ) & Q ( custom_tags__scope__contains = tag_scope ) ) ) [EOL] elif tag_name != [string] : [EOL] tag_query = ( Q ( tags__name__contains = tag_name ) | Q ( custom_tags__name__contains = tag_name ) ) [EOL] else : [EOL] tag_query = ( Q ( tags__scope__contains = tag_scope ) | Q ( custom_tags__scope__contains = tag_scope ) ) [EOL] [EOL] results = results . filter ( tag_query ) [EOL] results = results | results_title [EOL] [EOL] results = results . distinct ( ) [EOL] [EOL] return results [EOL] [EOL] [EOL] def filter_galleries_no_request ( filter_args ) : [EOL] [EOL] [comment] [EOL] order = [string] [EOL] if filter_args [ [string] ] and filter_args [ [string] ] in gallery_order_fields : [EOL] order = filter_args [ [string] ] [EOL] if filter_args [ [string] ] == [string] : [EOL] order = [string] + order [EOL] [EOL] results = Gallery . objects . eligible_for_use ( ) . order_by ( order ) [EOL] [EOL] if filter_args [ [string] ] : [EOL] results = results . filter ( public = bool ( filter_args [ [string] ] ) ) [EOL] [EOL] if filter_args [ [string] ] : [EOL] q_formatted = [string] + filter_args [ [string] ] . replace ( [string] , [string] ) + [string] [EOL] results = results . filter ( Q ( title__ss = q_formatted ) | Q ( title_jpn__ss = q_formatted ) ) [EOL] if filter_args [ [string] ] : [EOL] results = results . filter ( rating__gte = float ( filter_args [ [string] ] ) ) [EOL] if filter_args [ [string] ] : [EOL] results = results . filter ( rating__lte = float ( filter_args [ [string] ] ) ) [EOL] if filter_args [ [string] ] : [EOL] results = results . filter ( filecount__gte = int ( float ( filter_args [ [string] ] ) ) ) [EOL] if filter_args [ [string] ] : [EOL] results = results . filter ( filecount__lte = int ( float ( filter_args [ [string] ] ) ) ) [EOL] if filter_args [ [string] ] : [EOL] results = results . filter ( filesize__gte = float ( filter_args [ [string] ] ) ) [EOL] if filter_args [ [string] ] : [EOL] results = results . filter ( filesize__lte = float ( filter_args [ [string] ] ) ) [EOL] if filter_args [ [string] ] : [EOL] results = results . filter ( posted__gte = filter_args [ [string] ] ) [EOL] if filter_args [ [string] ] : [EOL] results = results . filter ( posted__lte = filter_args [ [string] ] ) [EOL] if filter_args [ [string] ] : [EOL] results = results . filter ( create_date__gte = filter_args [ [string] ] ) [EOL] if filter_args [ [string] ] : [EOL] results = results . filter ( create_date__lte = filter_args [ [string] ] ) [EOL] if filter_args [ [string] ] : [EOL] results = results . filter ( category__icontains = filter_args [ [string] ] ) [EOL] if filter_args [ [string] ] : [EOL] results = results . filter ( expunged = filter_args [ [string] ] ) [EOL] if filter_args [ [string] ] : [EOL] results = results . filter ( hidden = filter_args [ [string] ] ) [EOL] if filter_args [ [string] ] : [EOL] results = results . filter ( fjord = filter_args [ [string] ] ) [EOL] if filter_args [ [string] ] : [EOL] results = results . filter ( uploader = filter_args [ [string] ] ) [EOL] if filter_args [ [string] ] : [EOL] results = results . filter ( provider = filter_args [ [string] ] ) [EOL] if filter_args [ [string] ] : [EOL] results = results . filter ( dl_type = filter_args [ [string] ] ) [EOL] if filter_args [ [string] ] : [EOL] results = results . filter ( reason__icontains = filter_args [ [string] ] ) [EOL] [EOL] if filter_args [ [string] ] : [EOL] tags = filter_args [ [string] ] . split ( [string] ) [EOL] for tag in tags : [EOL] tag = tag . strip ( ) . replace ( [string] , [string] ) [EOL] tag_clean = re . sub ( [string] , [string] , tag ) [EOL] scope_name = tag_clean . split ( [string] , maxsplit = [number] ) [EOL] if len ( scope_name ) > [number] : [EOL] tag_scope = scope_name [ [number] ] [EOL] tag_name = scope_name [ [number] ] [EOL] else : [EOL] tag_scope = [string] [EOL] tag_name = scope_name [ [number] ] [EOL] if tag . startswith ( [string] ) : [EOL] if tag_name != [string] and tag_scope != [string] : [EOL] tag_query = Q ( tags__name__contains = tag_name ) & Q ( tags__scope__contains = tag_scope ) [EOL] elif tag_name != [string] : [EOL] tag_query = Q ( tags__name__contains = tag_name ) [EOL] else : [EOL] tag_query = Q ( tags__scope__contains = tag_scope ) [EOL] [EOL] results = results . exclude ( tag_query ) [EOL] elif tag . startswith ( [string] ) : [EOL] if tag_name != [string] and tag_scope != [string] : [EOL] tag_query = Q ( tags__name__exact = tag_name ) & Q ( tags__scope__exact = tag_scope ) [EOL] elif tag_name != [string] : [EOL] tag_query = Q ( tags__name__exact = tag_name ) [EOL] else : [EOL] tag_query = Q ( tags__scope__exact = tag_scope ) [EOL] [EOL] results = results . filter ( tag_query ) [EOL] else : [EOL] if tag_name != [string] and tag_scope != [string] : [EOL] tag_query = Q ( tags__name__contains = tag_name ) & Q ( tags__scope__contains = tag_scope ) [EOL] elif tag_name != [string] : [EOL] tag_query = Q ( tags__name__contains = tag_name ) [EOL] else : [EOL] tag_query = Q ( tags__scope__contains = tag_scope ) [EOL] [EOL] results = results . filter ( tag_query ) [EOL] [EOL] results = results . distinct ( ) [EOL] [EOL] return results [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $'QuerySet[Archive]'$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $'QuerySet[Gallery]'$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Type , Iterable , Optional , Match [EOL] import typing [EOL] import django [EOL] import builtins [EOL] import viewer [EOL] import json [EOL] import re [EOL] from typing import Iterable , Any , Optional [EOL] [EOL] import typing [EOL] from dal import autocomplete [EOL] from dal . views import BaseQuerySetView [EOL] from dal_select2 . views import Select2ViewMixin [EOL] from django import http [EOL] from django . db . models import Q , QuerySet [EOL] from django . http import HttpResponse , HttpRequest [EOL] from django . template import Context [EOL] from django . utils . html import format_html [EOL] [EOL] from viewer . models import Archive , Tag , Gallery , WantedGallery , ArchiveGroup [EOL] [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from django . db . models . query import ValuesQuerySet [EOL] [EOL] [EOL] class ArchiveAutocomplete ( autocomplete . JalQuerySetView ) : [EOL] model = Archive [EOL] [EOL] choice_html_format = [string] [EOL] empty_html_format = [string] [EOL] autocomplete_html_format = [string] [EOL] limit_choices = [number] [EOL] [EOL] def choice_html ( self , choice ) : [EOL] return self . choice_html_format % ( choice . title , choice . get_absolute_url ( ) , choice . title ) [EOL] [EOL] def render_to_response ( self , context ) : [EOL] [EOL] html = [string] . join ( [ self . choice_html ( c ) for c in self . choices_for_request ( ) ] ) [EOL] [EOL] if not html : [EOL] html = self . empty_html_format % [string] [EOL] [EOL] return HttpResponse ( self . autocomplete_html_format % html ) [EOL] [EOL] def choices_for_request ( self ) : [EOL] qs = Archive . objects . all ( ) . order_by ( [string] ) [EOL] [EOL] q = self . request . GET . get ( [string] , [string] ) [EOL] q_formatted = [string] + q . replace ( [string] , [string] ) + [string] [EOL] if self . request . user . is_authenticated : [EOL] qs = qs . filter ( Q ( title__ss = q_formatted ) | Q ( title_jpn__ss = q_formatted ) ) [EOL] else : [EOL] qs = qs . filter ( public = True ) . order_by ( [string] ) . filter ( Q ( title__ss = q_formatted ) | Q ( title_jpn__ss = q_formatted ) ) [EOL] [EOL] return qs [ [number] : self . limit_choices ] [EOL] [EOL] [EOL] class GalleryAutocomplete ( autocomplete . JalQuerySetView ) : [EOL] [EOL] model = Gallery [EOL] [EOL] choice_html_format = [string] [EOL] empty_html_format = [string] [EOL] autocomplete_html_format = [string] [EOL] limit_choices = [number] [EOL] [EOL] def choice_html ( self , choice ) : [EOL] return self . choice_html_format % ( choice . title , choice . get_absolute_url ( ) , choice . title ) [EOL] [EOL] def render_to_response ( self , context ) : [EOL] [EOL] html = [string] . join ( [ self . choice_html ( c ) for c in self . choices_for_request ( ) ] ) [EOL] [EOL] if not html : [EOL] html = self . empty_html_format % [string] [EOL] [EOL] return HttpResponse ( self . autocomplete_html_format % html ) [EOL] [EOL] def choices_for_request ( self ) : [EOL] qs = Gallery . objects . eligible_for_use ( ) . order_by ( [string] ) [EOL] [EOL] q = self . request . GET . get ( [string] , [string] ) [EOL] q_formatted = [string] + q . replace ( [string] , [string] ) + [string] [EOL] m = re . search ( [string] , q ) [EOL] if m : [EOL] q_object = Q ( title__ss = q_formatted ) | Q ( title_jpn__ss = q_formatted ) | Q ( gid__exact = m . group ( [number] ) ) [EOL] else : [EOL] q_object = Q ( title__ss = q_formatted ) | Q ( title_jpn__ss = q_formatted ) [EOL] if self . request . user . is_authenticated : [EOL] qs = qs . filter ( q_object ) [EOL] else : [EOL] qs = qs . filter ( public = True ) . filter ( q_object ) [EOL] [EOL] return qs [ [number] : self . limit_choices ] [EOL] [EOL] [EOL] class WantedGalleryAutocomplete ( autocomplete . JalQuerySetView ) : [EOL] [EOL] model = WantedGallery [EOL] [EOL] choice_html_format = [string] [EOL] empty_html_format = [string] [EOL] autocomplete_html_format = [string] [EOL] limit_choices = [number] [EOL] [EOL] def choice_html ( self , choice ) : [EOL] return self . choice_html_format % ( choice . title , choice . get_absolute_url ( ) , choice . title ) [EOL] [EOL] def render_to_response ( self , context ) : [EOL] [EOL] html = [string] . join ( [ self . choice_html ( c ) for c in self . choices_for_request ( ) ] ) [EOL] [EOL] if not html : [EOL] html = self . empty_html_format % [string] [EOL] [EOL] return HttpResponse ( self . autocomplete_html_format % html ) [EOL] [EOL] def choices_for_request ( self ) : [EOL] qs = WantedGallery . objects . all ( ) . order_by ( [string] ) [EOL] [EOL] q = self . request . GET . get ( [string] , [string] ) [EOL] q_formatted = [string] + q . replace ( [string] , [string] ) + [string] [EOL] q_object = Q ( title__ss = q_formatted ) | Q ( title_jpn__ss = q_formatted ) | Q ( search_title__ss = q_formatted ) | Q ( unwanted_title__ss = q_formatted ) [EOL] if self . request . user . is_authenticated : [EOL] qs = qs . filter ( q_object ) [EOL] else : [EOL] return [ ] [EOL] [EOL] return qs [ [number] : self . limit_choices ] [EOL] [EOL] [EOL] class ArchiveGroupAutocomplete ( autocomplete . JalQuerySetView ) : [EOL] model = ArchiveGroup [EOL] [EOL] choice_html_format = [string] [EOL] empty_html_format = [string] [EOL] autocomplete_html_format = [string] [EOL] limit_choices = [number] [EOL] [EOL] def choice_html ( self , choice ) : [EOL] return self . choice_html_format % ( choice . title , choice . get_absolute_url ( ) , choice . title ) [EOL] [EOL] def render_to_response ( self , context ) : [EOL] [EOL] html = [string] . join ( [ self . choice_html ( c ) for c in self . choices_for_request ( ) ] ) [EOL] [EOL] if not html : [EOL] html = self . empty_html_format % [string] [EOL] [EOL] return HttpResponse ( self . autocomplete_html_format % html ) [EOL] [EOL] def choices_for_request ( self ) : [EOL] qs = ArchiveGroup . objects . all ( ) . order_by ( [string] ) [EOL] [EOL] q = self . request . GET . get ( [string] , [string] ) [EOL] q_formatted = [string] + q . replace ( [string] , [string] ) + [string] [EOL] if self . request . user . is_authenticated : [EOL] qs = qs . filter ( Q ( title__ss = q_formatted ) ) [EOL] else : [EOL] qs = qs . filter ( public = True ) . filter ( Q ( title__ss = q_formatted ) ) [EOL] [EOL] return qs [ [number] : self . limit_choices ] [EOL] [EOL] [EOL] class ArchiveFieldAutocomplete ( autocomplete . JalQuerySetView ) : [EOL] [EOL] model = Archive [EOL] [EOL] choice_html_format = [string] [EOL] empty_html_format = [string] [EOL] autocomplete_html_format = [string] [EOL] limit_choices = [number] [EOL] [EOL] def render_to_response ( self , context ) : [EOL] [EOL] html = [string] . join ( [ self . choice_html ( c ) for c in self . choices_for_request ( ) ] ) [EOL] [EOL] if not html : [EOL] html = self . empty_html_format % [string] [EOL] [EOL] return HttpResponse ( self . autocomplete_html_format % html ) [EOL] [EOL] def choice_html ( self , choice ) : [EOL] return self . choice_html_format % ( self . get_result_value ( choice ) , self . get_result_label ( choice ) ) [EOL] [EOL] @ staticmethod def get_result_value ( result ) : [EOL] if result : [EOL] return result [EOL] else : [EOL] return [string] [EOL] [EOL] @ staticmethod def get_result_label ( result ) : [EOL] if result : [EOL] return result [EOL] else : [EOL] return [string] [EOL] [EOL] def choices_for_request ( self ) : [EOL] raise NotImplementedError [EOL] [EOL] [EOL] class SourceAutocomplete ( ArchiveFieldAutocomplete ) : [EOL] [EOL] def choices_for_request ( self ) : [EOL] [EOL] q = self . request . GET . get ( [string] , [string] ) [EOL] [EOL] if self . request . user . is_authenticated : [EOL] sources = Archive . objects . filter ( source_type__contains = q ) . order_by ( [string] ) . values_list ( [string] , flat = True ) . distinct ( ) [EOL] else : [EOL] sources = Archive . objects . filter ( source_type__contains = q , public = True ) . order_by ( [string] ) . values_list ( [string] , flat = True ) . distinct ( ) [EOL] [EOL] return sources [ [number] : self . limit_choices ] [EOL] [EOL] [EOL] class ProviderAutocomplete ( ArchiveFieldAutocomplete ) : [EOL] [EOL] def choices_for_request ( self ) : [EOL] [EOL] q = self . request . GET . get ( [string] , [string] ) [EOL] [EOL] if self . request . user . is_authenticated : [EOL] sources = Archive . objects . filter ( gallery__provider__icontains = q ) . order_by ( [string] ) . values_list ( [string] , flat = True ) . distinct ( ) [EOL] else : [EOL] sources = Archive . objects . filter ( gallery__provider__icontains = q , public = True ) . order_by ( [string] ) . values_list ( [string] , flat = True ) . distinct ( ) [EOL] [EOL] return sources [ [number] : self . limit_choices ] [EOL] [EOL] [EOL] class ReasonAutocomplete ( ArchiveFieldAutocomplete ) : [EOL] [EOL] def choices_for_request ( self ) : [EOL] [EOL] q = self . request . GET . get ( [string] , [string] ) [EOL] [EOL] if self . request . user . is_authenticated : [EOL] sources = Archive . objects . filter ( reason__contains = q ) . order_by ( [string] ) . values_list ( [string] , flat = True ) . distinct ( ) [EOL] else : [EOL] sources = Archive . objects . filter ( reason__contains = q , public = True ) . order_by ( [string] ) . values_list ( [string] , flat = True ) . distinct ( ) [EOL] [EOL] return sources [ [number] : self . limit_choices ] [EOL] [EOL] [EOL] class UploaderAutocomplete ( ArchiveFieldAutocomplete ) : [EOL] [EOL] def choices_for_request ( self ) : [EOL] [EOL] q = self . request . GET . get ( [string] , [string] ) [EOL] [EOL] if self . request . user . is_authenticated : [EOL] sources = Archive . objects . filter ( gallery__uploader__icontains = q ) . order_by ( [string] ) . values_list ( [string] , flat = True ) . distinct ( ) [EOL] else : [EOL] sources = Archive . objects . filter ( gallery__uploader__icontains = q , public = True ) . order_by ( [string] ) . values_list ( [string] , flat = True ) . distinct ( ) [EOL] [EOL] return sources [ [number] : self . limit_choices ] [EOL] [EOL] [EOL] class CategoryAutocomplete ( ArchiveFieldAutocomplete ) : [EOL] [EOL] def choices_for_request ( self ) : [EOL] [EOL] q = self . request . GET . get ( [string] , [string] ) [EOL] [EOL] if self . request . user . is_authenticated : [EOL] sources = Archive . objects . filter ( gallery__category__icontains = q ) . order_by ( [string] ) . values_list ( [string] , flat = True ) . distinct ( ) [EOL] else : [EOL] sources = Archive . objects . filter ( gallery__category__icontains = q , public = True ) . order_by ( [string] ) . values_list ( [string] , flat = True ) . distinct ( ) [EOL] [EOL] return sources [ [number] : self . limit_choices ] [EOL] [EOL] [EOL] class TagAutocomplete ( autocomplete . JalQuerySetView ) : [EOL] [EOL] model = Tag [EOL] [EOL] choice_html_format = [string] [EOL] empty_html_format = [string] [EOL] autocomplete_html_format = [string] [EOL] limit_choices = [number] [EOL] [EOL] def __init__ ( self , ** kwargs ) : [EOL] super ( ) . __init__ ( ** kwargs ) [EOL] self . modifier = [string] [EOL] [EOL] def render_to_response ( self , context ) : [EOL] [EOL] html = [string] . join ( [ self . choice_html ( c ) for c in self . choices_for_request ( ) ] ) [EOL] [EOL] if not html : [EOL] html = self . empty_html_format % [string] [EOL] [EOL] return HttpResponse ( self . autocomplete_html_format % html ) [EOL] [EOL] def choice_html ( self , choice ) : [EOL] return self . choice_html_format % ( self . get_result_value ( choice ) , self . get_result_label ( choice ) ) [EOL] [EOL] def get_result_value ( self , result ) : [EOL] return self . modifier + str ( result ) [EOL] [EOL] def get_result_label ( self , result ) : [EOL] return self . modifier + str ( result ) [EOL] [EOL] def choices_for_request ( self ) : [EOL] [EOL] tag_clean = self . request . GET . get ( [string] , [string] ) . replace ( [string] , [string] ) [EOL] m = re . match ( [string] , tag_clean ) [EOL] if m : [EOL] self . modifier = m . group ( [number] ) [EOL] tag_clean = tag_clean . replace ( self . modifier , [string] ) [EOL] else : [EOL] self . modifier = [string] [EOL] scope_name = tag_clean . split ( [string] , maxsplit = [number] ) [EOL] [EOL] if len ( scope_name ) > [number] : [EOL] results = Tag . objects . filter ( Q ( name__contains = scope_name [ [number] ] ) , Q ( scope__contains = scope_name [ [number] ] ) ) [EOL] else : [EOL] results = Tag . objects . filter ( Q ( name__contains = tag_clean ) | Q ( scope__contains = tag_clean ) ) [EOL] [EOL] return results . distinct ( ) . order_by ( [string] ) [ [number] : self . limit_choices ] [EOL] [EOL] [EOL] class Select2ViewMixinNoCreate ( Select2ViewMixin ) : [EOL] def render_to_response ( self , context ) : [EOL] [docstring] [EOL] return http . HttpResponse ( json . dumps ( { [string] : self . get_results ( context ) , [string] : { [string] : self . has_more ( context ) } } ) , content_type = [string] , ) [EOL] [EOL] [EOL] class Select2QuerySetViewNoCreate ( Select2ViewMixinNoCreate , BaseQuerySetView ) : [EOL] [docstring] [EOL] [EOL] [EOL] class TagPkAutocomplete ( Select2QuerySetViewNoCreate ) : [EOL] model = Tag [EOL] [EOL] [EOL] class NonCustomTagAutocomplete ( autocomplete . Select2QuerySetView ) : [EOL] model = Tag [EOL] [EOL] def __init__ ( self , ** kwargs ) : [EOL] super ( ) . __init__ ( ** kwargs ) [EOL] self . modifier = [string] [EOL] [EOL] def get_result_value ( self , result ) : [EOL] return self . modifier + str ( result ) [EOL] [EOL] def get_result_label ( self , result ) : [EOL] return self . modifier + str ( result ) [EOL] [EOL] def get_queryset ( self ) : [EOL] [EOL] tag_clean = self . request . GET . get ( [string] , [string] ) . replace ( [string] , [string] ) [EOL] m = re . match ( [string] , tag_clean ) [EOL] if m : [EOL] self . modifier = m . group ( [number] ) [EOL] tag_clean = tag_clean . replace ( self . modifier , [string] ) [EOL] else : [EOL] self . modifier = [string] [EOL] scope_name = tag_clean . split ( [string] , maxsplit = [number] ) [EOL] [EOL] if len ( scope_name ) > [number] : [EOL] results = Tag . objects . exclude ( source = [string] ) . filter ( Q ( name__contains = scope_name [ [number] ] ) , Q ( scope__contains = scope_name [ [number] ] ) ) [EOL] else : [EOL] results = Tag . objects . exclude ( source = [string] ) . filter ( Q ( name__contains = tag_clean ) | Q ( scope__contains = tag_clean ) ) [EOL] [EOL] return results . distinct ( ) . order_by ( [string] ) [EOL] [EOL] [EOL] class CustomTagAutocomplete ( autocomplete . Select2QuerySetView ) : [EOL] model = Tag [EOL] [EOL] def post ( self , request ) : [EOL] [EOL] if not self . has_add_permission ( request ) : [EOL] return http . HttpResponseForbidden ( ) [EOL] [EOL] t = request . POST . get ( [string] , None ) [EOL] [EOL] if t is None : [EOL] return http . HttpResponseBadRequest ( ) [EOL] [EOL] t = t . replace ( [string] , [string] ) [EOL] [EOL] scope_name = t . split ( [string] , maxsplit = [number] ) [EOL] if len ( scope_name ) > [number] : [EOL] name = scope_name [ [number] ] [EOL] scope = scope_name [ [number] ] [EOL] else : [EOL] name = t [EOL] scope = [string] [EOL] custom_tag = Tag . objects . filter ( name = name , scope = scope ) . first ( ) [EOL] if custom_tag : [EOL] return http . JsonResponse ( { [string] : custom_tag . pk , [string] : str ( custom_tag ) , } ) [EOL] else : [EOL] tag = Tag . objects . create ( name = name , scope = scope , source = [string] ) [EOL] return http . JsonResponse ( { [string] : tag . pk , [string] : str ( tag ) , } ) [EOL] [EOL] [EOL] class GallerySelectAutocomplete ( autocomplete . Select2QuerySetView ) : [EOL] model = Gallery [EOL] limit_choices = [number] [EOL] [EOL] def get_result_label ( self , result ) : [EOL] return [string] . format ( result . pk , result . title , result . provider ) [EOL] [EOL] def get_queryset ( self ) : [EOL] qs = Gallery . objects . eligible_for_use ( ) . order_by ( [string] ) [EOL] [EOL] q = self . q [EOL] q_formatted = [string] + q . replace ( [string] , [string] ) + [string] [EOL] m = re . search ( [string] , q ) [EOL] if m : [EOL] q_object = Q ( title__ss = q_formatted ) | Q ( title_jpn__ss = q_formatted ) | Q ( gid__exact = m . group ( [number] ) ) [EOL] else : [EOL] q_object = Q ( title__ss = q_formatted ) | Q ( title_jpn__ss = q_formatted ) [EOL] if self . request . user . is_authenticated : [EOL] qs = qs . filter ( q_object ) [EOL] else : [EOL] qs = qs . filter ( public = True ) . filter ( q_object ) [EOL] [EOL] return qs [ [number] : self . limit_choices ] [EOL] [EOL] [EOL] class ArchiveSelectSimpleAutocomplete ( autocomplete . Select2QuerySetView ) : [EOL] model = Archive [EOL] limit_choices = [number] [EOL] [EOL] def get_result_label ( self , result ) : [EOL] return [string] . format ( result . pk , result . title , result . source_type ) [EOL] [EOL] def get_queryset ( self ) : [EOL] qs = Archive . objects . all ( ) . order_by ( [string] ) [EOL] [EOL] q = self . q [EOL] q_formatted = [string] + q . replace ( [string] , [string] ) + [string] [EOL] [EOL] q_object = Q ( title__ss = q_formatted ) | Q ( title_jpn__ss = q_formatted ) [EOL] [EOL] if self . request . user . is_authenticated : [EOL] qs = qs . filter ( q_object ) [EOL] else : [EOL] qs = qs . filter ( public = True ) . filter ( q_object ) [EOL] [EOL] return qs [ [number] : self . limit_choices ] [EOL] [EOL] [EOL] class ArchiveSelectAutocomplete ( autocomplete . Select2QuerySetView ) : [EOL] model = Archive [EOL] limit_choices = [number] [EOL] [EOL] def get_result_label ( self , result ) : [EOL] return format_html ( [string] , result . title , result . thumbnail . url ) [EOL] [EOL] def get_queryset ( self ) : [EOL] qs = Archive . objects . all ( ) . order_by ( [string] ) [EOL] [EOL] q = self . q [EOL] q_formatted = [string] + q . replace ( [string] , [string] ) + [string] [EOL] [EOL] q_object = Q ( title__ss = q_formatted ) | Q ( title_jpn__ss = q_formatted ) [EOL] [EOL] if self . request . user . is_authenticated : [EOL] qs = qs . filter ( q_object ) [EOL] else : [EOL] qs = qs . filter ( public = True ) . filter ( q_object ) [EOL] [EOL] return qs [ [number] : self . limit_choices ] [EOL] [EOL] [EOL] class ArchiveGroupSelectAutocomplete ( autocomplete . Select2QuerySetView ) : [EOL] model = ArchiveGroup [EOL] limit_choices = [number] [EOL] [EOL] def get_result_label ( self , result ) : [EOL] return [string] . format ( result . pk , result . title ) [EOL] [EOL] def get_queryset ( self ) : [EOL] qs = ArchiveGroup . objects . all ( ) . order_by ( [string] ) [EOL] [EOL] q = self . q [EOL] q_formatted = [string] + q . replace ( [string] , [string] ) + [string] [EOL] if self . request . user . is_authenticated : [EOL] qs = qs . filter ( Q ( title__ss = q_formatted ) ) [EOL] else : [EOL] qs = qs . filter ( public = True ) . filter ( Q ( title__ss = q_formatted ) ) [EOL] [EOL] return qs [ [number] : self . limit_choices ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[viewer.models.Archive]$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.str$ 0 0 0 $viewer.models.Archive$ 0 0 0 0 0 0 0 0 0 $viewer.models.Archive$ 0 0 0 $viewer.models.Archive$ 0 0 0 0 0 $viewer.models.Archive$ 0 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 $django.template.Context$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $typing.Iterable[viewer.models.Archive]$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[viewer.models.Gallery]$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.str$ 0 0 0 $viewer.models.Gallery$ 0 0 0 0 0 0 0 0 0 $viewer.models.Gallery$ 0 0 0 $viewer.models.Gallery$ 0 0 0 0 0 $viewer.models.Gallery$ 0 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 $django.template.Context$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $typing.Iterable[viewer.models.Gallery]$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 $typing.Any$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[viewer.models.WantedGallery]$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.str$ 0 0 0 $viewer.models.WantedGallery$ 0 0 0 0 0 0 0 0 0 $viewer.models.WantedGallery$ 0 0 0 $viewer.models.WantedGallery$ 0 0 0 0 0 $viewer.models.WantedGallery$ 0 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 $django.template.Context$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $typing.Iterable[viewer.models.WantedGallery]$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[viewer.models.ArchiveGroup]$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.str$ 0 0 0 $viewer.models.ArchiveGroup$ 0 0 0 0 0 0 0 0 0 $viewer.models.ArchiveGroup$ 0 0 0 $viewer.models.ArchiveGroup$ 0 0 0 0 0 $viewer.models.ArchiveGroup$ 0 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 $django.template.Context$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $typing.Iterable[viewer.models.ArchiveGroup]$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[viewer.models.Archive]$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.int$ 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 $django.template.Context$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 $builtins.str$ 0 $typing.Optional[builtins.str]$ 0 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $typing.Optional[builtins.str]$ 0 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 $'ValuesQuerySet[Archive,Optional[str]]'$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $'ValuesQuerySet[Archive,Optional[str]]'$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $'ValuesQuerySet[Archive,Optional[str]]'$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $'ValuesQuerySet[Archive,Optional[str]]'$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $'ValuesQuerySet[Archive,Optional[str]]'$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $'ValuesQuerySet[Archive,Optional[str]]'$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[viewer.models.Tag]$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.int$ 0 0 0 0 0 $None$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 $django.template.Context$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $viewer.models.Tag$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $viewer.models.Tag$ 0 0 0 0 0 0 $viewer.models.Tag$ 0 0 0 0 0 $builtins.str$ 0 0 0 $viewer.models.Tag$ 0 0 0 0 0 0 0 0 0 0 $viewer.models.Tag$ 0 0 0 0 $builtins.str$ 0 0 0 $viewer.models.Tag$ 0 0 0 0 0 0 0 0 0 0 $viewer.models.Tag$ 0 0 0 0 $typing.Iterable[viewer.models.Tag]$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 $builtins.str$ 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[viewer.models.Tag]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[viewer.models.Tag]$ 0 0 0 0 0 $None$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $viewer.models.Tag$ 0 0 0 0 0 0 0 0 0 0 $viewer.models.Tag$ 0 0 0 0 $builtins.str$ 0 0 0 $viewer.models.Tag$ 0 0 0 0 0 0 0 0 0 0 $viewer.models.Tag$ 0 0 0 0 $django.db.models.QuerySet$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 $builtins.str$ 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[viewer.models.Tag]$ 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 $django.http.HttpRequest$ 0 0 0 0 0 0 0 0 0 0 $django.http.HttpRequest$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $django.http.HttpRequest$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 $builtins.str$ 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $builtins.str$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[viewer.models.Gallery]$ 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.str$ 0 0 0 $viewer.models.Gallery$ 0 0 0 0 0 0 0 0 $viewer.models.Gallery$ 0 0 0 $viewer.models.Gallery$ 0 0 0 $viewer.models.Gallery$ 0 0 0 0 0 0 $django.db.models.QuerySet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 $typing.Any$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[viewer.models.Archive]$ 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.str$ 0 0 0 $viewer.models.Archive$ 0 0 0 0 0 0 0 0 $viewer.models.Archive$ 0 0 0 $viewer.models.Archive$ 0 0 0 $viewer.models.Archive$ 0 0 0 0 0 0 $django.db.models.QuerySet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[viewer.models.Archive]$ 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.str$ 0 0 0 $viewer.models.Archive$ 0 0 0 0 0 0 0 0 $viewer.models.Archive$ 0 0 0 $viewer.models.Archive$ 0 0 0 0 0 0 0 0 $django.db.models.QuerySet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[viewer.models.ArchiveGroup]$ 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.str$ 0 0 0 $viewer.models.ArchiveGroup$ 0 0 0 0 0 0 0 0 $viewer.models.ArchiveGroup$ 0 0 0 $viewer.models.ArchiveGroup$ 0 0 0 0 0 0 $django.db.models.QuerySet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Dict , Tuple , Generator , Set , Match , List [EOL] import typing [EOL] import viewer [EOL] import threading [EOL] import logging [EOL] import io [EOL] import core [EOL] import django [EOL] import builtins [EOL] import logging [EOL] import os . path [EOL] import re [EOL] import signal [EOL] import threading [EOL] import typing [EOL] from functools import reduce [EOL] [EOL] from django . contrib import messages [EOL] from django . contrib . auth . decorators import login_required [EOL] from django . core . paginator import Paginator , InvalidPage , EmptyPage [EOL] from django . urls import reverse [EOL] from django . db . models import Avg , Max , Min , Sum , Count [EOL] from django . http import HttpResponseRedirect , HttpRequest , HttpResponse [EOL] from django . shortcuts import render [EOL] from django . utils . dateparse import parse_date [EOL] [EOL] from core . base . setup import Settings [EOL] from core . base . utilities import ( get_thread_status , get_thread_status_bool , thread_exists , get_schedulers_status ) [EOL] from core . local . foldercrawlerthread import FolderCrawlerThread [EOL] from core . web . crawlerthread import CrawlerThread [EOL] [EOL] from core . workers . imagework import ImageWorker [EOL] [EOL] from viewer . models import ( Archive , Tag , Gallery , ArchiveMatches , WantedGallery , FoundGallery ) [EOL] from viewer . utils . matching import ( create_matches_wanted_galleries_from_providers , create_matches_wanted_galleries_from_providers_internal , generate_possible_matches_for_archives ) [EOL] from django . conf import settings [EOL] from viewer . views . head import render_error [EOL] [EOL] MAIN_LOGGER = settings . MAIN_LOGGER [EOL] crawler_settings = settings . CRAWLER_SETTINGS [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] @ login_required def stats_settings ( request ) : [EOL] [docstring] [EOL] [EOL] if not request . user . is_staff : [EOL] return render_error ( request , [string] ) [EOL] [EOL] stats_dict = { [string] : crawler_settings , } [EOL] [EOL] d = { [string] : stats_dict } [EOL] [EOL] return render ( request , [string] , d ) [EOL] [EOL] [EOL] @ login_required def stats_workers ( request ) : [EOL] [docstring] [EOL] [EOL] if not request . user . is_staff : [EOL] return render_error ( request , [string] ) [EOL] [EOL] stats_dict = { [string] : crawler_settings , [string] : get_thread_status ( ) , [string] : crawler_settings . workers . web_queue , [string] : crawler_settings . workers . timed_downloader , [string] : get_schedulers_status ( crawler_settings . workers . get_active_initialized_workers ( ) ) } [EOL] [EOL] d = { [string] : stats_dict } [EOL] [EOL] return render ( request , [string] , d ) [EOL] [EOL] [EOL] @ login_required def stats_collection ( request ) : [EOL] [docstring] [EOL] [EOL] if not request . user . is_staff : [EOL] return render_error ( request , [string] ) [EOL] [EOL] [comment] [EOL] stats_dict = { [string] : Archive . objects . count ( ) , [string] : Archive . objects . filter ( extracted = True ) . count ( ) , [string] : Archive . objects . filter_by_dl_remote ( ) . count ( ) , [string] : Gallery . objects . count ( ) , [string] : Archive . objects . filter ( filesize__gt = [number] ) . aggregate ( Avg ( [string] ) , Max ( [string] ) , Min ( [string] ) , Sum ( [string] ) ) , [string] : Gallery . objects . filter ( filesize__gt = [number] ) . aggregate ( Avg ( [string] ) , Max ( [string] ) , Min ( [string] ) , Sum ( [string] ) ) , [string] : Gallery . objects . filter ( hidden = True ) . count ( ) , [string] : Gallery . objects . filter ( filesize__gt = [number] , hidden = True ) . aggregate ( Sum ( [string] ) ) , [string] : Gallery . objects . filter ( fjord = True ) . count ( ) , [string] : Gallery . objects . filter ( expunged = True ) . count ( ) , [string] : Tag . objects . count ( ) , [string] : Tag . objects . values ( [string] ) . distinct ( ) . count ( ) , [string] : Tag . objects . are_custom ( ) . count ( ) , [string] : Tag . objects . annotate ( num_archive = Count ( [string] ) ) . order_by ( [string] ) [ : [number] ] , [string] : Tag . objects . filter ( scope = [string] ) . annotate ( num_archive = Count ( [string] ) ) . order_by ( [string] ) [ : [number] ] , [string] : Tag . objects . filter ( scope = [string] ) . annotate ( num_archive = Count ( [string] ) ) . order_by ( [string] ) [ : [number] ] , [string] : { [string] : WantedGallery . objects . all ( ) . count ( ) , [string] : WantedGallery . objects . filter ( found = True ) . count ( ) , [string] : FoundGallery . objects . all ( ) . count ( ) , [string] : WantedGallery . objects . filter ( book_type = [string] ) . count ( ) , } } [EOL] [EOL] [comment] [EOL] providers = Gallery . objects . all ( ) . values_list ( [string] , flat = True ) . distinct ( ) [EOL] [EOL] providers_dict = { } [EOL] [EOL] for provider in providers : [EOL] providers_dict [ provider ] = { [string] : Gallery . objects . filter ( provider = provider ) . count ( ) , [string] : Archive . objects . filter ( gallery__provider = provider ) . count ( ) , [string] : WantedGallery . objects . filter ( provider = provider ) . count ( ) , } [EOL] [EOL] d = { [string] : stats_dict , [string] : providers_dict } [EOL] [EOL] return render ( request , [string] , d ) [EOL] [EOL] [EOL] @ login_required def queue_operations ( request , operation , arguments = [string] ) : [EOL] [EOL] if not request . user . is_staff : [EOL] return render_error ( request , [string] ) [EOL] if operation == [string] : [EOL] if arguments and crawler_settings . workers . web_queue : [EOL] crawler_settings . workers . web_queue . remove_by_index ( int ( arguments ) ) [EOL] else : [EOL] return render_error ( request , [string] ) [EOL] else : [EOL] return render_error ( request , [string] ) [EOL] [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] [EOL] [EOL] @ login_required def tools ( request , tool = [string] , tool_arg = [string] ) : [EOL] [docstring] [EOL] settings_text = [string] [EOL] if not request . user . is_staff : [EOL] return render_error ( request , [string] ) [EOL] if tool == [string] : [EOL] crawler_thread = CrawlerThread ( crawler_settings , [string] . split ( ) ) [EOL] crawler_thread . start ( ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] crawler_thread = CrawlerThread ( crawler_settings , [string] . split ( ) ) [EOL] crawler_thread . start ( ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] p = request . GET [EOL] if p and [string] in p : [EOL] newer_than_date = p [ [string] ] [EOL] try : [EOL] if parse_date ( newer_than_date ) is not None and crawler_settings . workers . web_queue : [EOL] crawler_settings . workers . web_queue . enqueue_args_list ( ( [string] , newer_than_date ) ) [EOL] messages . success ( request , [string] + newer_than_date ) [EOL] else : [EOL] messages . error ( request , [string] , extra_tags = [string] ) [EOL] except ValueError : [EOL] messages . error ( request , [string] , extra_tags = [string] ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] p = request . GET [EOL] if p and [string] in p and crawler_settings . workers . web_queue : [EOL] [EOL] try : [EOL] limit_number = int ( p [ [string] ] ) [EOL] [EOL] provider = request . GET . get ( [string] , [string] ) [EOL] if provider : [EOL] crawler_settings . workers . web_queue . enqueue_args_list ( ( [string] , str ( limit_number ) , [string] , provider ) ) [EOL] else : [EOL] crawler_settings . workers . web_queue . enqueue_args_list ( ( [string] , str ( limit_number ) ) ) [EOL] messages . success ( request , [string] . format ( limit_number ) ) [EOL] [EOL] except ValueError : [EOL] messages . error ( request , [string] , extra_tags = [string] ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] archives_no_thumbnail = Archive . objects . filter ( thumbnail = [string] ) [EOL] for archive in archives_no_thumbnail : [EOL] logger . info ( [string] . format ( archive . zipped . name ) ) [EOL] archive . generate_thumbnails ( ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] archives_missing_info = Archive . objects . filter_by_missing_file_info ( ) [EOL] for archive in archives_missing_info : [EOL] logger . info ( [string] . format ( archive . zipped . name ) ) [EOL] archive . recalc_fileinfo ( ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] if thread_exists ( [string] ) : [EOL] return render_error ( request , [string] ) [EOL] [EOL] archives = Archive . objects . all ( ) [EOL] logger . info ( [string] . format ( archives . count ( ) ) ) [EOL] [EOL] image_worker_thread = ImageWorker ( [number] ) [EOL] for archive in archives : [EOL] if os . path . exists ( archive . zipped . path ) : [EOL] image_worker_thread . enqueue_archive ( archive ) [EOL] fileinfo_thread = threading . Thread ( name = [string] , target = image_worker_thread . start_info_thread ) [EOL] fileinfo_thread . start ( ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] [EOL] archives = Archive . objects . filter ( gallery__hidden = True ) [EOL] [EOL] for archive in archives : [EOL] if os . path . isfile ( archive . zipped . path ) : [EOL] archive . public = True [EOL] archive . save ( ) [EOL] if archive . gallery : [EOL] archive . gallery . public = True [EOL] archive . gallery . save ( ) [EOL] [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] if thread_exists ( [string] ) : [EOL] return render_error ( request , [string] ) [EOL] [EOL] archives = Archive . objects . all ( ) [EOL] logger . info ( [string] . format ( archives . count ( ) ) ) [EOL] [EOL] image_worker_thread = ImageWorker ( [number] ) [EOL] for archive in archives : [EOL] if os . path . exists ( archive . zipped . path ) : [EOL] image_worker_thread . enqueue_archive ( archive ) [EOL] thumbnails_thread = threading . Thread ( name = [string] , target = image_worker_thread . start_thumbs_thread ) [EOL] thumbnails_thread . start ( ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] if thread_exists ( [string] ) : [EOL] return render_error ( request , [string] ) [EOL] provider = request . GET . get ( [string] , [string] ) [EOL] try : [EOL] cutoff = float ( request . GET . get ( [string] , [string] ) ) [EOL] except ValueError : [EOL] cutoff = [number] [EOL] try : [EOL] max_matches = int ( request . GET . get ( [string] , [string] ) ) [EOL] except ValueError : [EOL] max_matches = [number] [EOL] logger . info ( [string] [string] [string] . format ( cutoff , max_matches , provider ) ) [EOL] matching_thread = threading . Thread ( name = [string] , target = generate_possible_matches_for_archives , args = ( None , ) , kwargs = { [string] : cutoff , [string] : max_matches , [string] : ( provider , ) , [string] : True , [string] : False } ) [EOL] matching_thread . daemon = True [EOL] matching_thread . start ( ) [EOL] messages . success ( request , [string] . format ( provider , cutoff ) ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] ArchiveMatches . objects . all ( ) . delete ( ) [EOL] logger . info ( [string] ) [EOL] messages . success ( request , [string] ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] if thread_exists ( [string] ) : [EOL] messages . error ( request , [string] , extra_tags = [string] ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] results = WantedGallery . objects . eligible_to_search ( ) [EOL] [EOL] if not results : [EOL] logger . info ( [string] ) [EOL] messages . success ( request , [string] ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] [EOL] provider = request . GET . get ( [string] , [string] ) [EOL] [EOL] logger . info ( [string] ) [EOL] messages . success ( request , [string] ) [EOL] [EOL] panda_search_thread = threading . Thread ( name = [string] , target = create_matches_wanted_galleries_from_providers , args = ( results , provider ) , ) [EOL] panda_search_thread . daemon = True [EOL] panda_search_thread . start ( ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] if thread_exists ( [string] ) : [EOL] return render_error ( request , [string] ) [EOL] [EOL] non_match_wanted = WantedGallery . objects . eligible_to_search ( ) [EOL] [EOL] if not non_match_wanted : [EOL] logger . info ( [string] ) [EOL] messages . success ( request , [string] ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] [EOL] logger . info ( [string] [string] ) [EOL] [EOL] provider = request . GET . get ( [string] , [string] ) [EOL] [EOL] try : [EOL] cutoff = float ( request . GET . get ( [string] , [string] ) ) [EOL] except ValueError : [EOL] cutoff = [number] [EOL] try : [EOL] max_matches = int ( request . GET . get ( [string] , [string] ) ) [EOL] except ValueError : [EOL] max_matches = [number] [EOL] [EOL] matching_thread = threading . Thread ( name = [string] , target = create_matches_wanted_galleries_from_providers_internal , args = ( non_match_wanted , ) , kwargs = { [string] : provider , [string] : cutoff , [string] : max_matches } ) [EOL] matching_thread . daemon = True [EOL] matching_thread . start ( ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] crawler_settings . workers . stop_workers_and_wait ( ) [EOL] if hasattr ( signal , [string] ) : [EOL] os . kill ( os . getpid ( ) , signal . SIGUSR2 ) [comment] [EOL] else : [EOL] return render_error ( request , [string] ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] p = request . POST [EOL] if p : [EOL] settings_text = p [ [string] ] [EOL] if ( os . path . isfile ( os . path . join ( crawler_settings . default_dir , [string] ) ) ) : [EOL] with open ( os . path . join ( crawler_settings . default_dir , [string] ) , [string] , encoding = [string] ) as f : [EOL] f . write ( settings_text ) [EOL] logger . info ( [string] ) [EOL] messages . success ( request , [string] ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] else : [EOL] if ( os . path . isfile ( os . path . join ( crawler_settings . default_dir , [string] ) ) ) : [EOL] with open ( os . path . join ( crawler_settings . default_dir , [string] ) , [string] , encoding = [string] ) as f : [EOL] first = f . read ( [number] ) [EOL] if first != [string] : [EOL] [comment] [EOL] f . seek ( [number] ) [EOL] settings_text = f . read ( ) [EOL] elif tool == [string] : [EOL] return render ( request , [string] ) [EOL] elif tool == [string] : [EOL] if not request . user . is_staff : [EOL] return render_error ( request , [string] ) [EOL] crawler_settings . load_config_from_file ( ) [EOL] logger . info ( [string] ) [EOL] messages . success ( request , [string] ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] if crawler_settings . workers . timed_downloader : [EOL] crawler_settings . workers . timed_downloader . start_running ( timer = crawler_settings . timed_downloader_cycle_timer ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] if crawler_settings . workers . timed_downloader : [EOL] crawler_settings . workers . timed_downloader . stop_running ( ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] if crawler_settings . workers . timed_downloader : [EOL] crawler_settings . workers . timed_downloader . stop_running ( ) [EOL] crawler_settings . workers . timed_downloader . force_run_once = True [EOL] crawler_settings . workers . timed_downloader . start_running ( timer = crawler_settings . timed_downloader_cycle_timer ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] if tool_arg : [EOL] for provider_auto_crawler in crawler_settings . workers . timed_auto_crawlers : [EOL] if provider_auto_crawler . provider_name == tool_arg : [EOL] provider_auto_crawler . start_running ( timer = crawler_settings . providers [ provider_auto_crawler . provider_name ] . autochecker_timer ) [EOL] break [EOL] else : [EOL] for provider_auto_crawler in crawler_settings . workers . timed_auto_crawlers : [EOL] provider_auto_crawler . start_running ( timer = crawler_settings . providers [ provider_auto_crawler . provider_name ] . autochecker_timer ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] if tool_arg : [EOL] for provider_auto_crawler in crawler_settings . workers . timed_auto_crawlers : [EOL] if provider_auto_crawler . provider_name == tool_arg : [EOL] provider_auto_crawler . stop_running ( ) [EOL] break [EOL] else : [EOL] for provider_auto_crawler in crawler_settings . workers . timed_auto_crawlers : [EOL] provider_auto_crawler . stop_running ( ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] if tool_arg : [EOL] for provider_auto_crawler in crawler_settings . workers . timed_auto_crawlers : [EOL] if provider_auto_crawler . provider_name == tool_arg : [EOL] provider_auto_crawler . stop_running ( ) [EOL] provider_auto_crawler . force_run_once = True [EOL] provider_auto_crawler . start_running ( timer = crawler_settings . providers [ provider_auto_crawler . provider_name ] . autochecker_timer ) [EOL] break [EOL] else : [EOL] for provider_auto_crawler in crawler_settings . workers . timed_auto_crawlers : [EOL] provider_auto_crawler . stop_running ( ) [EOL] provider_auto_crawler . force_run_once = True [EOL] provider_auto_crawler . start_running ( timer = crawler_settings . providers [ provider_auto_crawler . provider_name ] . autochecker_timer ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] if crawler_settings . workers . timed_updater : [EOL] crawler_settings . workers . timed_updater . start_running ( timer = crawler_settings . autoupdater . cycle_timer ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] if crawler_settings . workers . timed_updater : [EOL] crawler_settings . workers . timed_updater . stop_running ( ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] if crawler_settings . workers . timed_updater : [EOL] crawler_settings . workers . timed_updater . stop_running ( ) [EOL] crawler_settings . workers . timed_updater . force_run_once = True [EOL] crawler_settings . workers . timed_updater . start_running ( timer = crawler_settings . autoupdater . cycle_timer ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] if crawler_settings . workers . timed_auto_wanted : [EOL] crawler_settings . workers . timed_auto_wanted . start_running ( timer = crawler_settings . auto_wanted . cycle_timer ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] if crawler_settings . workers . timed_auto_wanted : [EOL] crawler_settings . workers . timed_auto_wanted . stop_running ( ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] if crawler_settings . workers . timed_auto_wanted : [EOL] crawler_settings . workers . timed_auto_wanted . stop_running ( ) [EOL] crawler_settings . workers . timed_auto_wanted . force_run_once = True [EOL] crawler_settings . workers . timed_auto_wanted . start_running ( timer = crawler_settings . auto_wanted . cycle_timer ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] if crawler_settings . workers . web_queue : [EOL] crawler_settings . workers . web_queue . start_running ( ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] [EOL] threads_status = get_thread_status_bool ( ) [EOL] [EOL] autochecker_providers = ( ( provider_name , threads_status [ [string] + provider_name ] ) for provider_name in crawler_settings . autochecker . providers if [string] + provider_name in threads_status ) [EOL] [EOL] d = { [string] : tool , [string] : settings_text , [string] : threads_status , [string] : autochecker_providers } [EOL] [EOL] return render ( request , [string] , d ) [EOL] [EOL] [EOL] @ login_required def logs ( request , tool = [string] ) : [EOL] [docstring] [EOL] [EOL] if not request . user . is_staff : [EOL] return render_error ( request , [string] ) [EOL] [EOL] log_lines = [ ] [EOL] [EOL] if tool == [string] or tool == [string] : [EOL] [EOL] f = open ( MAIN_LOGGER , [string] , encoding = [string] ) [EOL] log_lines = f . read ( ) . split ( [string] ) [EOL] f . close ( ) [EOL] log_lines . pop ( ) [EOL] log_lines . reverse ( ) [EOL] [EOL] log_filter = request . GET . get ( [string] , [string] ) [EOL] if log_filter : [EOL] log_lines = [ x for x in log_lines if log_filter . lower ( ) in x . lower ( ) ] [EOL] [EOL] current_base_uri = re . escape ( [string] . format ( scheme = request . scheme , host = request . get_host ( ) ) ) [EOL] [comment] [EOL] if crawler_settings . urls . viewer_main_url : [EOL] patterns = [ [string] + current_base_uri + [string] + crawler_settings . urls . viewer_main_url + [string] , [string] + current_base_uri + [string] + crawler_settings . urls . viewer_main_url + [string] , [string] + current_base_uri + [string] + crawler_settings . urls . viewer_main_url + [string] , ] [EOL] else : [EOL] patterns = [ [string] + current_base_uri + [string] , [string] + current_base_uri + [string] , [string] + current_base_uri + [string] , ] [EOL] [EOL] def build_request ( match_obj ) : [EOL] return request . build_absolute_uri ( match_obj . group ( [number] ) ) [EOL] [EOL] log_lines = [ reduce ( lambda v , pattern : re . sub ( pattern , build_request , v ) , patterns , line ) for line in log_lines ] [EOL] [EOL] paginator = Paginator ( log_lines , [number] ) [EOL] try : [EOL] page = int ( request . GET . get ( [string] , [string] ) ) [EOL] except ValueError : [EOL] page = [number] [EOL] [EOL] try : [EOL] log_lines_paginated = paginator . page ( page ) [EOL] except ( InvalidPage , EmptyPage ) : [EOL] log_lines_paginated = paginator . page ( paginator . num_pages ) [EOL] [EOL] d = { [string] : log_lines_paginated } [EOL] return render ( request , [string] , d ) [EOL] [EOL] [EOL] @ login_required def crawler ( request ) : [EOL] [docstring] [EOL] [EOL] if not request . user . is_staff : [EOL] return render_error ( request , [string] ) [EOL] [EOL] d = { } [EOL] [EOL] p = request . POST [EOL] [EOL] if p : [EOL] if [string] in p : [EOL] current_settings = crawler_settings [EOL] else : [EOL] current_settings = Settings ( load_from_config = crawler_settings . config ) [EOL] url_set = set ( ) [EOL] [comment] [EOL] current_settings . replace_metadata = False [EOL] current_settings . config [ [string] ] [ [string] ] = [string] [EOL] for k , v in p . items ( ) : [EOL] if k . startswith ( [string] ) : [EOL] k , dl = k . split ( [string] ) [EOL] current_settings . config [ [string] ] [ dl ] = v [EOL] current_settings . downloaders [ dl ] = int ( v ) [EOL] elif k == [string] : [EOL] current_settings . config [ [string] ] [ k ] = [string] [EOL] current_settings . replace_metadata = True [EOL] elif k == [string] : [EOL] url_list = v . split ( [string] ) [EOL] for item in url_list : [EOL] url_set . add ( item . rstrip ( [string] ) ) [EOL] urls = list ( url_set ) [EOL] [EOL] if [string] in p and p [ [string] ] != [string] : [EOL] reason = p [ [string] ] [EOL] [comment] [EOL] current_settings . archive_reason = reason [ : [number] ] [EOL] current_settings . gallery_reason = reason [ : [number] ] [EOL] [EOL] if [string] in p : [EOL] current_settings . write ( ) [EOL] current_settings . load_config_from_file ( ) [EOL] if [string] in p : [EOL] crawler_thread = CrawlerThread ( current_settings , urls ) [EOL] crawler_thread . start ( ) [EOL] else : [EOL] if current_settings . workers . web_queue : [EOL] current_settings . workers . web_queue . enqueue_args_list ( urls , override_options = current_settings ) [EOL] messages . success ( request , [string] ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] return HttpResponseRedirect ( reverse ( [string] ) ) [EOL] [EOL] d . update ( { [string] : crawler_settings , [string] : crawler_settings . provider_context . get_downloaders_name_priority ( crawler_settings ) } ) [EOL] [EOL] return render ( request , [string] , d ) [EOL] [EOL] [EOL] @ login_required def foldercrawler ( request ) : [EOL] [docstring] [EOL] if not request . user . is_staff : [EOL] return render_error ( request , [string] ) [EOL] [EOL] d = { [string] : os . path . realpath ( crawler_settings . MEDIA_ROOT ) } [EOL] [EOL] p = request . POST [EOL] [EOL] if p : [EOL] if [string] in p : [EOL] current_settings = crawler_settings [EOL] else : [EOL] current_settings = Settings ( load_from_config = crawler_settings . config ) [EOL] commands = set ( ) [EOL] [comment] [EOL] for k , v in p . items ( ) : [EOL] if k . startswith ( [string] ) : [EOL] k , matcher = k . split ( [string] ) [EOL] current_settings . config [ [string] ] [ matcher ] = v [EOL] current_settings . matchers [ matcher ] = int ( v ) [EOL] elif k == [string] : [EOL] command_list = v . split ( [string] ) [EOL] for item in command_list : [EOL] commands . add ( item . rstrip ( [string] ) ) [EOL] elif k == [string] : [EOL] current_settings . internal_matches_for_non_matches = True [EOL] [EOL] if [string] in p and p [ [string] ] != [string] : [EOL] reason = p [ [string] ] [EOL] [comment] [EOL] current_settings . archive_reason = reason [ : [number] ] [EOL] current_settings . gallery_reason = reason [ : [number] ] [EOL] [EOL] if [string] in p and p [ [string] ] != [string] : [EOL] source = p [ [string] ] [EOL] [comment] [EOL] current_settings . archive_source = source [ : [number] ] [EOL] [EOL] if [string] in p : [EOL] current_settings . write ( ) [EOL] current_settings . load_config_from_file ( ) [EOL] folder_crawler = FolderCrawlerThread ( current_settings , list ( commands ) ) [EOL] folder_crawler . start ( ) [EOL] messages . success ( request , [string] ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] return HttpResponseRedirect ( reverse ( [string] ) ) [EOL] [EOL] d . update ( { [string] : crawler_settings , [string] : crawler_settings . provider_context . get_matchers_name_priority ( crawler_settings ) } ) [EOL] [EOL] return render ( request , [string] , d ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Tuple , Dict , List [EOL] import typing [EOL] import viewer [EOL] import logging [EOL] import django [EOL] import builtins [EOL] import django . utils . timezone as django_tz [EOL] import logging [EOL] from django . contrib . auth . decorators import login_required [EOL] from django . http import Http404 , HttpResponseRedirect , HttpRequest , HttpResponse [EOL] from django . shortcuts import render [EOL] from django . urls import reverse [EOL] from django . conf import settings [EOL] [EOL] from viewer . models import ( Gallery , WantedGallery , FoundGallery , GalleryMatch ) [EOL] from viewer . utils . tags import sort_tags [EOL] [EOL] [EOL] crawler_settings = settings . CRAWLER_SETTINGS [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] @ login_required def wanted_gallery ( request , pk ) : [EOL] [docstring] [EOL] if not request . user . is_staff : [EOL] try : [EOL] wanted_gallery_instance = WantedGallery . objects . get ( pk = pk , public = True ) [EOL] except WantedGallery . DoesNotExist : [EOL] raise Http404 ( [string] ) [EOL] wanted_tag_lists = sort_tags ( wanted_gallery_instance . wanted_tags . all ( ) ) [EOL] unwanted_tag_lists = sort_tags ( wanted_gallery_instance . unwanted_tags . all ( ) ) [EOL] [EOL] d = { [string] : wanted_gallery_instance , [string] : wanted_tag_lists , [string] : unwanted_tag_lists , } [EOL] else : [EOL] tool = request . GET . get ( [string] , [string] ) [EOL] tool_use_id = request . GET . get ( [string] , [string] ) [EOL] try : [EOL] wanted_gallery_instance = WantedGallery . objects . get ( pk = pk ) [EOL] except WantedGallery . DoesNotExist : [EOL] raise Http404 ( [string] ) [EOL] if tool == [string] : [EOL] provider = request . GET . get ( [string] , [string] ) [EOL] try : [EOL] cutoff = float ( request . GET . get ( [string] , [string] ) ) [EOL] except ValueError : [EOL] cutoff = [number] [EOL] try : [EOL] max_matches = int ( request . GET . get ( [string] , [string] ) ) [EOL] except ValueError : [EOL] max_matches = [number] [EOL] matchers = crawler_settings . provider_context . get_matchers ( crawler_settings , filter_name = provider , force = True , matcher_type = [string] ) [EOL] for matcher_element in matchers : [EOL] matcher = matcher_element [ [number] ] [EOL] results = matcher . create_closer_matches_values ( wanted_gallery_instance . search_title , cutoff = cutoff , max_matches = max_matches ) [EOL] logger . info ( [string] . format ( str ( matcher ) , len ( results ) ) ) [EOL] for gallery_data in results : [EOL] gallery_data [ [number] ] . dl_type = [string] [EOL] gallery = Gallery . objects . update_or_create_from_values ( gallery_data [ [number] ] ) [EOL] if gallery : [EOL] GalleryMatch . objects . get_or_create ( wanted_gallery = wanted_gallery_instance , gallery = gallery , defaults = { [string] : gallery_data [ [number] ] } ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] provider = request . GET . get ( [string] , [string] ) [EOL] try : [EOL] cutoff = float ( request . GET . get ( [string] , [string] ) ) [EOL] except ValueError : [EOL] cutoff = [number] [EOL] try : [EOL] max_matches = int ( request . GET . get ( [string] , [string] ) ) [EOL] except ValueError : [EOL] max_matches = [number] [EOL] wanted_gallery_instance . search_gallery_title_internal_matches ( provider_filter = provider , max_matches = max_matches , cutoff = cutoff ) [EOL] logger . info ( [string] . format ( wanted_gallery_instance , reverse ( [string] , args = ( wanted_gallery_instance . pk , ) ) , wanted_gallery_instance . possible_matches . count ( ) ) ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] wanted_gallery_instance . possible_matches . clear ( ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] wanted_gallery_instance . match_against_galleries ( ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] try : [EOL] matched_gallery = Gallery . objects . get ( pk = tool_use_id ) [EOL] except Gallery . DoesNotExist : [EOL] raise Http404 ( [string] ) [EOL] FoundGallery . objects . get_or_create ( wanted_gallery = wanted_gallery_instance , gallery = matched_gallery ) [EOL] wanted_gallery_instance . found = True [EOL] wanted_gallery_instance . date_found = django_tz . now ( ) [EOL] [comment] [EOL] [comment] [EOL] gm = GalleryMatch . objects . filter ( wanted_gallery = wanted_gallery_instance , gallery = matched_gallery ) [EOL] if gm : [EOL] gm . delete ( ) [EOL] wanted_gallery_instance . save ( ) [EOL] [EOL] if wanted_gallery_instance . add_as_hidden and not matched_gallery . hidden : [EOL] matched_gallery . hidden = True [EOL] matched_gallery . save ( ) [EOL] [EOL] logger . info ( [string] . format ( wanted_gallery_instance , reverse ( [string] , args = ( wanted_gallery_instance . pk , ) ) , matched_gallery , reverse ( [string] , args = ( matched_gallery . pk , ) ) , ) ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] try : [EOL] matched_gallery = Gallery . objects . get ( pk = tool_use_id ) [EOL] except Gallery . DoesNotExist : [EOL] raise Http404 ( [string] ) [EOL] fg = FoundGallery . objects . filter ( wanted_gallery = wanted_gallery_instance , gallery = matched_gallery ) [EOL] if fg : [EOL] fg . delete ( ) [EOL] gm = GalleryMatch . objects . filter ( wanted_gallery = wanted_gallery_instance , gallery = matched_gallery ) [EOL] if gm : [EOL] gm . delete ( ) [EOL] wanted_gallery_instance . save ( ) [EOL] [EOL] logger . info ( [string] . format ( matched_gallery , reverse ( [string] , args = ( matched_gallery . pk , ) ) , wanted_gallery_instance , reverse ( [string] , args = ( wanted_gallery_instance . pk , ) ) ) ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] wanted_gallery_instance . should_search = False [EOL] [comment] [EOL] wanted_gallery_instance . save ( ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] wanted_gallery_instance . public_toggle ( ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] [EOL] wanted_tag_lists = sort_tags ( wanted_gallery_instance . wanted_tags . all ( ) ) [EOL] unwanted_tag_lists = sort_tags ( wanted_gallery_instance . unwanted_tags . all ( ) ) [EOL] [EOL] d = { [string] : wanted_gallery_instance , [string] : wanted_tag_lists , [string] : unwanted_tag_lists , } [EOL] return render ( request , [string] , d ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Tuple , List [EOL] import typing [EOL] import django [EOL] import viewer [EOL] import json [EOL] import os [EOL] [EOL] from django . contrib . auth . decorators import login_required [EOL] from django . http import HttpResponse , HttpRequest [EOL] from django . conf import settings [EOL] [EOL] from viewer . utils . dirbrowser import DirBrowser [EOL] [EOL] [EOL] @ login_required def directory_parser ( request ) : [EOL] if not request . user . is_staff : [EOL] return HttpResponse ( json . dumps ( { [string] : [string] } ) , content_type = [string] ) [EOL] p = request . GET [EOL] directory = [string] [EOL] if p and [string] in p : [EOL] directory = p [ [string] ] [EOL] fs = DirBrowser ( settings . MEDIA_ROOT ) [EOL] if fs . isdir ( directory ) : [EOL] files = fs . files ( directory ) [EOL] else : [EOL] files = fs . files ( os . path . dirname ( directory ) ) [EOL] return HttpResponse ( json . dumps ( ( fs . relativepath ( directory ) , files ) ) , content_type = [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Dict , List [EOL] import typing [EOL] import viewer [EOL] import logging [EOL] import django [EOL] import builtins [EOL] import logging [EOL] from typing import Dict , Any [EOL] [EOL] from django . contrib import messages [EOL] from django . contrib . auth . decorators import login_required , permission_required [EOL] from django . core . paginator import Paginator , InvalidPage , EmptyPage [EOL] from django . db . models import Q , Prefetch , F , Case , When [EOL] from django . http import HttpRequest , HttpResponse , Http404 , HttpResponseRedirect [EOL] from django . shortcuts import render [EOL] from django . urls import reverse [EOL] [EOL] from viewer . utils . actions import event_log [EOL] from viewer . forms import ArchiveGroupSearchForm , ArchiveGroupCreateOrEditForm , ArchiveSearchForm , ArchiveGroupEntryFormSet [EOL] from viewer . models import ArchiveGroup , ArchiveGroupEntry , Archive [EOL] [EOL] from viewer . views . head import archive_filter_keys , filter_archives_simple [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] @ login_required def archive_groups_explorer ( request ) : [EOL] get = request . GET [EOL] [EOL] title = get . get ( [string] , [string] ) [EOL] [EOL] try : [EOL] page = int ( get . get ( [string] , [string] ) ) [EOL] except ValueError : [EOL] page = [number] [EOL] [EOL] if [string] in get : [EOL] form = ArchiveGroupSearchForm ( ) [EOL] else : [EOL] form = ArchiveGroupSearchForm ( initial = { [string] : title } ) [EOL] [EOL] d = { [string] : form , } [EOL] [EOL] if request . user . has_perm ( [string] ) : [EOL] if request . POST . get ( [string] ) : [EOL] [comment] [EOL] edit_form = ArchiveGroupCreateOrEditForm ( request . POST ) [EOL] [comment] [EOL] if edit_form . is_valid ( ) : [EOL] new_archive_group = edit_form . save ( ) [EOL] message = [string] [EOL] messages . success ( request , message ) [EOL] logger . info ( [string] . format ( request . user . username , message ) ) [EOL] event_log ( request . user , [string] , content_object = new_archive_group , result = [string] ) [EOL] else : [EOL] messages . error ( request , [string] , extra_tags = [string] ) [EOL] [comment] [EOL] else : [EOL] edit_form = ArchiveGroupCreateOrEditForm ( ) [EOL] [EOL] d . update ( edit_form = edit_form ) [EOL] [EOL] order = [string] [EOL] [EOL] results = ArchiveGroup . objects . order_by ( F ( order ) . asc ( nulls_last = True ) ) [EOL] [EOL] if not request . user . is_authenticated : [EOL] results = results . filter ( public = True ) [EOL] [EOL] q_formatted = [string] + title . replace ( [string] , [string] ) + [string] [EOL] results = results . filter ( Q ( title__ss = q_formatted ) ) [EOL] [EOL] results = results . prefetch_related ( Prefetch ( [string] , queryset = ArchiveGroupEntry . objects . select_related ( [string] , [string] ) . prefetch_related ( Prefetch ( [string] , ) ) , to_attr = [string] ) , ) [EOL] [EOL] paginator = Paginator ( results , [number] ) [EOL] try : [EOL] results_page = paginator . page ( page ) [EOL] except ( InvalidPage , EmptyPage ) : [EOL] results_page = paginator . page ( paginator . num_pages ) [EOL] [EOL] d . update ( results = results_page ) [EOL] [EOL] return render ( request , [string] , d ) [EOL] [EOL] [EOL] @ login_required def archive_group ( request , pk = None , slug = None ) : [EOL] [docstring] [EOL] try : [EOL] if pk is not None : [EOL] archive_group_instance = ArchiveGroup . objects . get ( pk = pk ) [EOL] elif slug is not None : [EOL] archive_group_instance = ArchiveGroup . objects . get ( title_slug = slug ) [EOL] else : [EOL] raise Http404 ( [string] ) [EOL] except ArchiveGroup . DoesNotExist : [EOL] raise Http404 ( [string] ) [EOL] if not archive_group_instance . public and not request . user . is_authenticated : [EOL] raise Http404 ( [string] ) [EOL] [EOL] d = { [string] : archive_group_instance , } [EOL] [EOL] return render ( request , [string] , d ) [EOL] [EOL] [EOL] @ permission_required ( [string] ) def archive_group_edit ( request , pk = None , slug = None ) : [EOL] [docstring] [EOL] try : [EOL] if pk is not None : [EOL] archive_group_instance = ArchiveGroup . objects . prefetch_related ( [string] ) . get ( pk = pk ) [EOL] elif slug is not None : [EOL] archive_group_instance = ArchiveGroup . objects . prefetch_related ( [string] ) . get ( title_slug = slug ) [EOL] else : [EOL] raise Http404 ( [string] ) [EOL] except ArchiveGroup . DoesNotExist : [EOL] raise Http404 ( [string] ) [EOL] if not archive_group_instance . public and not request . user . is_authenticated : [EOL] raise Http404 ( [string] ) [EOL] [EOL] get = request . GET [EOL] p = request . POST [EOL] [EOL] user_reason = p . get ( [string] , [string] ) [EOL] [EOL] d = { [string] : archive_group_instance , } [EOL] [EOL] if request . POST . get ( [string] ) : [EOL] [comment] [EOL] edit_form = ArchiveGroupCreateOrEditForm ( request . POST , instance = archive_group_instance ) [EOL] archive_group_entry_formset = ArchiveGroupEntryFormSet ( request . POST , instance = archive_group_instance ) [EOL] [EOL] [comment] [EOL] if edit_form . is_valid ( ) and archive_group_entry_formset . is_valid ( ) : [EOL] new_archive_group = edit_form . save ( ) [EOL] [EOL] [comment] [EOL] archive_group_entries = archive_group_entry_formset . save ( commit = False ) [EOL] for archive_group_entry in archive_group_entries : [EOL] archive_group_entry . save ( ) [EOL] for archive_group_entry in archive_group_entry_formset . deleted_objects : [EOL] archive_group_entry . delete ( ) [EOL] [EOL] message = [string] [EOL] messages . success ( request , message ) [EOL] logger . info ( [string] . format ( request . user . username , message ) ) [EOL] event_log ( request . user , [string] , content_object = new_archive_group , result = [string] ) [EOL] return HttpResponseRedirect ( reverse ( [string] , args = [ archive_group_instance . title_slug ] ) ) [EOL] else : [EOL] messages . error ( request , [string] , extra_tags = [string] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] else : [EOL] edit_form = ArchiveGroupCreateOrEditForm ( instance = archive_group_instance ) [EOL] archive_group_entry_formset = ArchiveGroupEntryFormSet ( instance = archive_group_instance ) [EOL] [EOL] if [string] in p : [EOL] [EOL] pks = [ ] [EOL] for k , v in p . items ( ) : [EOL] if k . startswith ( [string] ) : [EOL] [comment] [EOL] [comment] [EOL] pks . append ( v ) [EOL] [EOL] preserved = Case ( * [ When ( pk = pk , then = pos ) for pos , pk in enumerate ( pks ) ] ) [EOL] [EOL] archives = Archive . objects . filter ( id__in = pks ) . order_by ( preserved ) [EOL] [EOL] for archive in archives : [EOL] if not ArchiveGroupEntry . objects . filter ( archive = archive , archive_group = archive_group_instance ) . exists ( ) : [EOL] [EOL] archive_group_entry = ArchiveGroupEntry ( archive = archive , archive_group = archive_group_instance ) [EOL] archive_group_entry . save ( ) [EOL] [EOL] message = [string] . format ( archive . title , archive . get_absolute_url ( ) , archive_group_instance . title , archive_group_instance . get_absolute_url ( ) ) [EOL] if [string] in p and p [ [string] ] != [string] : [EOL] message += [string] . format ( p [ [string] ] ) [EOL] logger . info ( [string] . format ( request . user . username , message ) ) [EOL] messages . success ( request , message ) [EOL] event_log ( request . user , [string] , content_object = archive , reason = user_reason , result = [string] ) [EOL] [EOL] return HttpResponseRedirect ( reverse ( [string] , args = [ archive_group_instance . title_slug ] ) + [string] + request . META [ [string] ] ) [EOL] [EOL] d . update ( edit_form = edit_form ) [EOL] [EOL] [comment] [EOL] [EOL] title = get . get ( [string] , [string] ) [EOL] tags = get . get ( [string] , [string] ) [EOL] [EOL] try : [EOL] page = int ( get . get ( [string] , [string] ) ) [EOL] except ValueError : [EOL] page = [number] [EOL] [EOL] if [string] in get : [EOL] if [string] in get : [EOL] search_form = ArchiveSearchForm ( ) [EOL] else : [EOL] search_form = ArchiveSearchForm ( initial = { [string] : title , [string] : tags } ) [EOL] [EOL] params = { [string] : get . get ( [string] , [string] ) , [string] : get . get ( [string] , [string] ) , } [EOL] [EOL] for k , v in get . items ( ) : [EOL] params [ k ] = v [EOL] [EOL] for k in archive_filter_keys : [EOL] if k not in params : [EOL] params [ k ] = [string] [EOL] [EOL] search_results = filter_archives_simple ( params ) [EOL] [EOL] search_results = search_results . exclude ( archive_groups = archive_group_instance ) [EOL] [EOL] if [string] in get and get [ [string] ] : [EOL] search_results = search_results . filter ( archive_groups__isnull = True ) [EOL] [EOL] search_results = search_results . prefetch_related ( [string] ) [EOL] [EOL] paginator = Paginator ( search_results , [number] ) [EOL] try : [EOL] search_results_page = paginator . page ( page ) [EOL] except ( InvalidPage , EmptyPage ) : [EOL] search_results_page = paginator . page ( paginator . num_pages ) [EOL] [EOL] d . update ( search_form = search_form , search_results = search_results_page , ) [EOL] [EOL] d . update ( archive_group_entry_formset = archive_group_entry_formset ) [EOL] [EOL] return render ( request , [string] , d ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [EOL] from typing import Any , Literal , Dict , Union , List [EOL] import typing [EOL] import viewer [EOL] import logging [EOL] import core [EOL] import typing_extensions [EOL] import django [EOL] import builtins [EOL] import logging [EOL] from os . path import basename [EOL] from urllib . parse import quote [EOL] import typing [EOL] [EOL] from django . contrib import messages [EOL] from django . contrib . auth . decorators import login_required [EOL] from django . core . paginator import Paginator , InvalidPage , EmptyPage , Page [EOL] from django . urls import reverse [EOL] from django . db import transaction [EOL] from django . http import Http404 , HttpRequest [EOL] from django . http import HttpResponseRedirect , HttpResponse [EOL] from django . shortcuts import render [EOL] from django . conf import settings [EOL] [EOL] from core . base . setup import Settings [EOL] from core . local . foldercrawlerthread import FolderCrawlerThread [EOL] from viewer . utils . actions import event_log [EOL] from viewer . forms import ( ArchiveModForm , ImageFormSet , ArchiveEditForm ) [EOL] from viewer . models import ( Archive , Tag , Gallery , UserArchivePrefs ) [EOL] from viewer . views . head import render_error [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] crawler_settings = settings . CRAWLER_SETTINGS [EOL] [EOL] [EOL] def archive_details ( request , pk , view = [string] ) : [EOL] [docstring] [EOL] [EOL] try : [EOL] archive = Archive . objects . get ( pk = pk ) [EOL] except Archive . DoesNotExist : [EOL] raise Http404 ( [string] ) [EOL] if not archive . public and not request . user . is_authenticated : [EOL] raise Http404 ( [string] ) [EOL] [EOL] if not request . user . is_authenticated : [EOL] view = [string] [EOL] [EOL] num_images = [number] [EOL] if view in ( [string] , [string] ) : [EOL] num_images = [number] [EOL] if view in ( [string] , [string] ) : [EOL] num_images = [number] [EOL] [EOL] images = archive . image_set . filter ( extracted = True ) [EOL] [EOL] if images : [EOL] paginator = Paginator ( images , num_images ) [EOL] try : [EOL] page = int ( request . GET . get ( [string] , [string] ) ) [EOL] except ValueError : [EOL] page = [number] [EOL] [EOL] try : [EOL] images_page = paginator . page ( page ) [EOL] except ( InvalidPage , EmptyPage ) : [EOL] images_page = paginator . page ( paginator . num_pages ) [EOL] [EOL] else : [EOL] images_page = None [EOL] [EOL] d = { [string] : archive , [string] : images_page , [string] : view } [EOL] [EOL] if view == [string] and request . user . is_staff : [EOL] [EOL] paginator = Paginator ( archive . image_set . all ( ) , num_images ) [EOL] try : [EOL] page = int ( request . GET . get ( [string] , [string] ) ) [EOL] except ValueError : [EOL] page = [number] [EOL] [EOL] try : [EOL] all_images = paginator . page ( page ) [EOL] except ( InvalidPage , EmptyPage ) : [EOL] all_images = paginator . page ( paginator . num_pages ) [EOL] [EOL] form = ArchiveModForm ( instance = archive ) [EOL] image_formset = ImageFormSet ( queryset = all_images . object_list , prefix = [string] ) [EOL] d . update ( { [string] : form , [string] : image_formset , [string] : crawler_settings . provider_context . get_matchers ( crawler_settings , force = True ) , [string] : crawler_settings . api_key , } ) [EOL] [EOL] if request . user . is_authenticated : [EOL] user_archive_preferences = UserArchivePrefs . objects . get_or_create ( user = request . user . pk , archive = pk , defaults = { [string] : [number] } ) [EOL] d . update ( { [string] : user_archive_preferences } ) [EOL] [EOL] [comment] [EOL] if request . user . has_perm ( [string] ) : [EOL] if request . POST . get ( [string] ) : [EOL] [comment] [EOL] edit_form = ArchiveEditForm ( request . POST , instance = archive ) [EOL] [comment] [EOL] if edit_form . is_valid ( ) : [EOL] new_archive = edit_form . save ( commit = False ) [EOL] new_archive . simple_save ( ) [EOL] edit_form . save_m2m ( ) [EOL] if new_archive . gallery and new_archive . gallery . tags . all ( ) : [EOL] new_archive . tags . set ( new_archive . gallery . tags . all ( ) ) [EOL] [EOL] message = [string] [EOL] messages . success ( request , message ) [EOL] logger . info ( [string] . format ( request . user . username , message ) ) [EOL] event_log ( request . user , [string] , content_object = new_archive , result = [string] ) [EOL] [comment] [EOL] else : [EOL] messages . error ( request , [string] , extra_tags = [string] ) [EOL] [comment] [EOL] else : [EOL] edit_form = ArchiveEditForm ( instance = archive ) [EOL] d . update ( { [string] : edit_form } ) [EOL] [EOL] return render ( request , [string] , d ) [EOL] [EOL] [EOL] @ login_required def archive_update ( request , pk , tool = None , tool_use_id = None ) : [EOL] [docstring] [EOL] if not request . user . is_staff : [EOL] messages . error ( request , [string] ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] try : [EOL] archive = Archive . objects . get ( pk = pk ) [EOL] except Archive . DoesNotExist : [EOL] raise Http404 ( [string] ) [EOL] [EOL] if tool == [string] and tool_use_id : [EOL] try : [EOL] gallery_id = int ( tool_use_id ) [EOL] archive . select_as_match ( gallery_id ) [EOL] if archive . gallery : [EOL] logger . info ( [string] . format ( archive , reverse ( [string] , args = ( archive . pk , ) ) , archive . gallery , reverse ( [string] , args = ( archive . gallery . pk , ) ) , ) ) [EOL] except ValueError : [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] elif tool == [string] : [EOL] archive . possible_matches . clear ( ) [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] [EOL] user_archive_preferences = UserArchivePrefs . objects . get_or_create ( user = request . user . pk , archive = pk , defaults = { [string] : [number] } ) [EOL] [EOL] d = { [string] : archive , [string] : [string] , [string] : user_archive_preferences } [EOL] [EOL] if request . method == [string] : [EOL] p = request . POST [EOL] image_formset = ImageFormSet ( p , queryset = archive . image_set . all ( ) , prefix = [string] ) [EOL] if image_formset . is_valid ( ) : [EOL] images = image_formset . save ( commit = False ) [EOL] for image in images : [EOL] image . save ( ) [EOL] for image in image_formset . deleted_objects : [EOL] image . delete_plus_files ( ) [EOL] [EOL] archive . title = p [ [string] ] [EOL] archive . title_jpn = p [ [string] ] [EOL] archive . source_type = p [ [string] ] [EOL] archive . reason = p [ [string] ] [EOL] archive . details = p [ [string] ] [EOL] [EOL] if [string] in p : [EOL] if p [ [string] ] != [string] and p [ [string] ] != archive . zipped : [EOL] result = archive . rename_zipped_pathname ( p [ [string] ] ) [EOL] if not result : [EOL] messages . error ( request , [string] . format ( p [ [string] ] ) ) [EOL] [EOL] if [string] in p : [EOL] lst = [ ] [EOL] tags = p . getlist ( [string] ) [EOL] for t in tags : [EOL] lst . append ( Tag . objects . get ( pk = t ) ) [EOL] archive . custom_tags . set ( lst ) [EOL] else : [EOL] archive . custom_tags . clear ( ) [EOL] if [string] in p and p [ [string] ] != [string] : [EOL] [EOL] matched_gallery = Gallery . objects . get ( pk = p [ [string] ] ) [EOL] [EOL] archive . gallery_id = p [ [string] ] [EOL] archive . title = matched_gallery . title [EOL] archive . title_jpn = matched_gallery . title_jpn [EOL] archive . tags . set ( matched_gallery . tags . all ( ) ) [EOL] [EOL] archive . match_type = [string] [EOL] archive . possible_matches . clear ( ) [EOL] [EOL] if [string] in matched_gallery . dl_type : [EOL] matched_gallery . dl_type = [string] [EOL] matched_gallery . save ( ) [EOL] if [string] in p : [EOL] lst = [ ] [EOL] alternative_sources = p . getlist ( [string] ) [EOL] for alternative_gallery in alternative_sources : [EOL] lst . append ( Gallery . objects . get ( pk = alternative_gallery ) ) [EOL] archive . alternative_sources . set ( lst ) [EOL] else : [EOL] archive . alternative_sources . clear ( ) [EOL] archive . simple_save ( ) [EOL] [EOL] messages . success ( request , [string] . format ( archive . title ) ) [EOL] [EOL] else : [EOL] image_formset = ImageFormSet ( queryset = archive . image_set . all ( ) , prefix = [string] ) [EOL] form = ArchiveModForm ( instance = archive ) [EOL] d . update ( { [string] : form , [string] : image_formset , [string] : crawler_settings . provider_context . get_matchers ( crawler_settings , force = True ) , [string] : crawler_settings . api_key , } ) [EOL] [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] [EOL] [EOL] def archive_download ( request , pk ) : [EOL] try : [EOL] archive = Archive . objects . get ( pk = pk ) [EOL] except Archive . DoesNotExist : [EOL] raise Http404 ( [string] ) [EOL] if not archive . public and not request . user . is_authenticated : [EOL] raise Http404 ( [string] ) [EOL] if [string] in request . META : [EOL] response = HttpResponse ( ) [EOL] response [ [string] ] = [string] [EOL] if [string] in request . GET : [EOL] response [ [string] ] = [string] . format ( quote ( basename ( archive . zipped . name ) ) ) [EOL] else : [EOL] response [ [string] ] = [string] . format ( archive . pretty_name ) [EOL] response [ [string] ] = [string] . format ( quote ( archive . zipped . name ) ) . encode ( [string] ) [EOL] return response [EOL] else : [EOL] return HttpResponseRedirect ( archive . zipped . url ) [EOL] [EOL] [EOL] def archive_ext_download ( request , pk ) : [EOL] try : [EOL] archive = Archive . objects . get ( pk = pk ) [EOL] except Archive . DoesNotExist : [EOL] raise Http404 ( [string] ) [EOL] if not archive . public and not request . user . is_authenticated : [EOL] raise Http404 ( [string] ) [EOL] [EOL] if [string] in request . GET : [EOL] filename = quote ( basename ( archive . zipped . name ) ) [EOL] else : [EOL] filename = archive . pretty_name [EOL] [EOL] redirect_url = [string] . format ( crawler_settings . urls . external_media_server , quote ( archive . zipped . name ) , filename ) [EOL] [EOL] return HttpResponseRedirect ( redirect_url ) [EOL] [EOL] [EOL] def archive_thumb ( request , pk ) : [EOL] try : [EOL] archive = Archive . objects . get ( pk = pk ) [EOL] except Archive . DoesNotExist : [EOL] raise Http404 ( [string] ) [EOL] if not archive . public and not request . user . is_authenticated : [EOL] raise Http404 ( [string] ) [EOL] if [string] in request . META : [EOL] response = HttpResponse ( ) [EOL] response [ [string] ] = [string] [EOL] [comment] [EOL] [comment] [EOL] response [ [string] ] = [string] . format ( archive . thumbnail . name ) [EOL] return response [EOL] else : [EOL] return HttpResponseRedirect ( archive . thumbnail . url ) [EOL] [EOL] [EOL] @ login_required def extract_toggle ( request , pk ) : [EOL] [docstring] [EOL] [EOL] if not request . user . is_staff : [EOL] return render_error ( request , [string] ) [EOL] [EOL] try : [EOL] with transaction . atomic ( ) : [EOL] archive = Archive . objects . select_for_update ( ) . get ( pk = pk ) [EOL] logger . info ( [string] + archive . zipped . name ) [EOL] archive . extract_toggle ( ) [EOL] except Archive . DoesNotExist : [EOL] raise Http404 ( [string] ) [EOL] [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] [EOL] [EOL] @ login_required def public_toggle ( request , pk ) : [EOL] [docstring] [EOL] [EOL] if not request . user . is_staff : [EOL] return render_error ( request , [string] ) [EOL] [EOL] try : [EOL] archive = Archive . objects . get ( pk = pk ) [EOL] except Archive . DoesNotExist : [EOL] raise Http404 ( [string] ) [EOL] [EOL] if archive . public : [EOL] archive . set_private ( ) [EOL] logger . info ( [string] + archive . zipped . name ) [EOL] event_log ( request . user , [string] , content_object = archive , result = [string] ) [EOL] else : [EOL] archive . set_public ( ) [EOL] logger . info ( [string] + archive . zipped . name ) [EOL] event_log ( request . user , [string] , content_object = archive , result = [string] ) [EOL] [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] [EOL] [EOL] @ login_required def recalc_info ( request , pk ) : [EOL] [docstring] [EOL] [EOL] if not request . user . is_staff : [EOL] return render_error ( request , [string] ) [EOL] [EOL] try : [EOL] archive = Archive . objects . get ( pk = pk ) [EOL] except Archive . DoesNotExist : [EOL] raise Http404 ( [string] ) [EOL] [EOL] logger . info ( [string] + archive . zipped . name ) [EOL] archive . recalc_fileinfo ( ) [EOL] archive . generate_image_set ( force = False ) [EOL] archive . generate_thumbnails ( ) [EOL] [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] [EOL] [EOL] @ login_required def recall_api ( request , pk ) : [EOL] [docstring] [EOL] [EOL] if not request . user . is_staff : [EOL] return render_error ( request , [string] ) [EOL] [EOL] try : [EOL] archive = Archive . objects . get ( pk = pk ) [EOL] except Archive . DoesNotExist : [EOL] raise Http404 ( [string] ) [EOL] [EOL] if not archive . gallery_id : [EOL] return render_error ( request , [string] ) [EOL] [EOL] gallery = Gallery . objects . get ( pk = archive . gallery_id ) [EOL] [EOL] current_settings = Settings ( load_from_config = crawler_settings . config ) [EOL] [EOL] if current_settings . workers . web_queue and gallery . provider : [EOL] [EOL] current_settings . set_update_metadata_options ( providers = ( gallery . provider , ) ) [EOL] [EOL] current_settings . workers . web_queue . enqueue_args_list ( ( gallery . get_link ( ) , ) , override_options = current_settings ) [EOL] [EOL] logger . info ( [string] . format ( gallery . get_absolute_url ( ) ) ) [EOL] [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] [EOL] [EOL] @ login_required def generate_matches ( request , pk ) : [EOL] [docstring] [EOL] [EOL] if not request . user . is_staff : [EOL] return render_error ( request , [string] ) [EOL] [EOL] try : [EOL] archive = Archive . objects . get ( pk = pk ) [EOL] except Archive . DoesNotExist : [EOL] raise Http404 ( [string] ) [EOL] [EOL] if archive . gallery : [EOL] return render_error ( request , [string] ) [EOL] [EOL] clear_title = True if [string] in request . GET else False [EOL] [EOL] provider_filter = request . GET . get ( [string] , [string] ) [EOL] try : [EOL] cutoff = float ( request . GET . get ( [string] , [string] ) ) [EOL] except ValueError : [EOL] cutoff = [number] [EOL] try : [EOL] max_matches = int ( request . GET . get ( [string] , [string] ) ) [EOL] except ValueError : [EOL] max_matches = [number] [EOL] [EOL] archive . generate_possible_matches ( clear_title = clear_title , provider_filter = provider_filter , cutoff = cutoff , max_matches = max_matches ) [EOL] archive . save ( ) [EOL] [EOL] logger . info ( [string] . format ( archive . zipped . path , archive . possible_matches . count ( ) ) ) [EOL] [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] [EOL] [EOL] @ login_required def rematch_archive ( request , pk ) : [EOL] [docstring] [EOL] [EOL] if not request . user . is_staff : [EOL] return render_error ( request , [string] ) [EOL] [EOL] try : [EOL] archive = Archive . objects . get ( pk = pk ) [EOL] except Archive . DoesNotExist : [EOL] raise Http404 ( [string] ) [EOL] [EOL] if archive . gallery : [EOL] archive . gallery . archive_set . remove ( archive ) [EOL] [EOL] folder_crawler_thread = FolderCrawlerThread ( crawler_settings , [ [string] , archive . zipped . path ] ) [EOL] folder_crawler_thread . start ( ) [EOL] [EOL] logger . info ( [string] . format ( archive . title ) ) [EOL] [EOL] return HttpResponseRedirect ( request . META [ [string] ] ) [EOL] [EOL] [EOL] @ login_required def delete_archive ( request , pk ) : [EOL] [docstring] [EOL] [EOL] if not request . user . is_staff : [EOL] return render_error ( request , [string] ) [EOL] [EOL] try : [EOL] archive = Archive . objects . get ( pk = pk ) [EOL] except Archive . DoesNotExist : [EOL] raise Http404 ( [string] ) [EOL] [EOL] if request . method == [string] : [EOL] [EOL] p = request . POST [EOL] if [string] in p : [EOL] [EOL] message_list = list ( ) [EOL] [EOL] if [string] in p : [EOL] message_list . append ( [string] ) [EOL] if [string] in p : [EOL] message_list . append ( [string] ) [EOL] if [string] in p : [EOL] message_list . append ( [string] ) [EOL] [EOL] message = [string] . format ( archive . title , [string] . join ( message_list ) ) [EOL] [EOL] logger . info ( [string] . format ( request . user . username , message ) ) [EOL] messages . success ( request , message ) [EOL] [EOL] gallery = archive . gallery [EOL] [EOL] if [string] in p and archive . gallery : [EOL] archive . gallery . mark_as_deleted ( ) [EOL] archive . gallery = None [EOL] if [string] in p : [EOL] archive . delete_all_files ( ) [EOL] if [string] in p : [EOL] archive . delete_files_but_archive ( ) [EOL] archive . delete ( ) [EOL] [EOL] user_reason = p . get ( [string] , [string] ) [EOL] [EOL] event_log ( request . user , [string] , reason = user_reason , content_object = gallery , result = [string] ) [EOL] [EOL] return HttpResponseRedirect ( reverse ( [string] ) ) [EOL] [EOL] d = { [string] : archive } [EOL] [EOL] return render ( request , [string] , d ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Literal , Dict , Tuple , List [EOL] import typing [EOL] import elasticsearch_dsl [EOL] import core [EOL] import typing_extensions [EOL] import django [EOL] import builtins [EOL] import json [EOL] from typing import Any , Dict , List [EOL] [EOL] from urllib . parse import urlencode [EOL] from copy import deepcopy [EOL] from datetime import datetime [EOL] [EOL] from django . conf import settings [EOL] from django . http import HttpResponse , QueryDict , HttpRequest [EOL] from django . views . generic . base import TemplateView [EOL] [EOL] [EOL] from math import ceil [EOL] [EOL] from elasticsearch_dsl . response import AggResponse [EOL] [EOL] from core . base . types import DataDict [EOL] [EOL] es_client = settings . ES_CLIENT [EOL] max_result_window = settings . MAX_RESULT_WINDOW [EOL] es_index_name = settings . ES_INDEX_NAME [EOL] [EOL] if es_client : [EOL] import elasticsearch [EOL] from elasticsearch_dsl import Search [EOL] [EOL] [EOL] class ESHomePageView ( TemplateView ) : [EOL] [EOL] template_name = [string] [EOL] [EOL] def get_context_data ( self , ** kwargs ) : [EOL] [EOL] if not settings . ES_ENABLED or not es_client : [EOL] return { [string] : [string] } [EOL] [EOL] s = Search ( using = es_client , index = es_index_name ) [EOL] [EOL] message = None [EOL] count_result = [number] [EOL] [EOL] if [string] in self . request . GET : [EOL] self . request . GET = QueryDict ( [string] ) [EOL] [EOL] s = self . gen_es_query ( self . request , s ) [EOL] [EOL] s . aggs . bucket ( [string] , [string] , field = [string] , size = [number] ) [EOL] s . aggs . bucket ( [string] , [string] , field = [string] , size = [number] ) [EOL] s . aggs . bucket ( [string] , [string] , field = [string] , size = [number] ) [EOL] try : [EOL] count_result = s . count ( ) [EOL] except elasticsearch . exceptions . RequestError : [EOL] message = [string] [EOL] per_page = [number] [EOL] [EOL] context = super ( ESHomePageView , self ) . get_context_data ( ** kwargs ) [EOL] [EOL] if count_result > [number] : [EOL] es_pagination = self . gen_pagination ( self . request , count_result , per_page ) [EOL] [EOL] if es_pagination [ [string] ] [ [string] ] > max_result_window : [EOL] es_pagination [ [string] ] [ [string] ] = max_result_window - per_page [EOL] es_pagination [ [string] ] [ [string] ] = max_result_window [EOL] message = [string] . format ( max_result_window ) [EOL] [EOL] [comment] [EOL] possible_sorts = ( [string] , [string] , [string] , [string] , [string] , ) [EOL] sort = self . request . GET . get ( [string] , [string] ) [EOL] order = self . request . GET . get ( [string] , [string] ) [EOL] [EOL] if not sort and ( sort not in possible_sorts ) : [EOL] if not self . request . user . is_authenticated : [EOL] sort = [string] [EOL] else : [EOL] sort = [string] [EOL] if order == [string] : [EOL] sort = [string] + sort [EOL] [EOL] s = s . sort ( sort ) [EOL] [EOL] [comment] [EOL] s = s [ es_pagination [ [string] ] [ [string] ] : es_pagination [ [string] ] [ [string] ] ] [EOL] [EOL] search_result = s . execute ( ) [EOL] [EOL] context [ [string] ] = [ self . convert_hit_to_template ( c ) for c in search_result ] [EOL] [EOL] context [ [string] ] = { [string] : es_pagination [ [string] ] [ [string] ] + [number] , [string] : es_pagination [ [string] ] [ [string] ] + len ( context [ [string] ] ) } [EOL] [EOL] context [ [string] ] = self . prepare_facet_data ( search_result . aggregations , self . request . GET ) [EOL] context [ [string] ] = es_pagination [EOL] [EOL] context [ [string] ] = self . request . GET . get ( [string] , [string] ) [EOL] context [ [string] ] = self . request . GET . get ( [string] , [string] ) [EOL] context [ [string] ] = self . request . GET . get ( [string] , [string] ) [EOL] context [ [string] ] = message [EOL] [EOL] return context [EOL] [EOL] @ staticmethod def num_pages ( count , per_page ) : [EOL] [docstring] [EOL] if count == [number] : [EOL] return [number] [EOL] hits = max ( [number] , count ) [EOL] return int ( ceil ( hits / float ( per_page ) ) ) [EOL] [EOL] @ staticmethod def convert_hit_to_template ( hit ) : [EOL] hit . pk = hit . meta . id [EOL] [comment] [EOL] hit . create_date_c = datetime . strptime ( hit . create_date . replace ( [string] , [string] ) , [string] ) [EOL] if hit . public_date : [EOL] hit . public_date_c = datetime . strptime ( hit . public_date . replace ( [string] , [string] ) , [string] ) [EOL] else : [EOL] hit . public_date_c = None [EOL] if hit . original_date : [EOL] hit . original_date_c = datetime . strptime ( hit . original_date . replace ( [string] , [string] ) , [string] ) [EOL] else : [EOL] hit . original_date_c = None [EOL] return hit [EOL] [EOL] @ staticmethod def facet_url_args ( url_args , field_name , field_value ) : [EOL] is_active = False [EOL] if url_args . get ( field_name ) : [EOL] base_list = url_args [ field_name ] . split ( [string] ) [EOL] if field_value in base_list : [EOL] del base_list [ base_list . index ( field_value ) ] [EOL] is_active = True [EOL] else : [EOL] base_list . append ( field_value ) [EOL] url_args [ field_name ] = [string] . join ( base_list ) [EOL] else : [EOL] url_args [ field_name ] = field_value [EOL] return url_args , is_active [EOL] [EOL] def prepare_facet_data ( self , aggregations , get_args ) : [EOL] resp = { } [EOL] for area , agg in aggregations . to_dict ( ) . items ( ) : [EOL] resp [ area ] = [ ] [EOL] for item in aggregations [ area ] . buckets : [EOL] url_args , is_active = self . facet_url_args ( url_args = deepcopy ( get_args . dict ( ) ) , field_name = area , field_value = str ( item . key ) ) [EOL] resp [ area ] . append ( { [string] : urlencode ( url_args ) , [string] : item . key , [string] : item . doc_count , [string] : is_active } ) [EOL] return resp [EOL] [EOL] @ staticmethod def gen_es_query ( request , s ) : [EOL] req_dict = deepcopy ( request . GET . dict ( ) ) [EOL] if not request . user . is_authenticated : [EOL] s = s . filter ( [string] , public = True ) [EOL] if not req_dict : [EOL] return s . filter ( [string] ) [EOL] q = req_dict . get ( [string] , [string] ) [EOL] if q : [EOL] s = s . query ( [string] , query = q , fields = [ [string] , [string] , [string] ] ) [EOL] else : [EOL] s = s . query ( [string] ) [EOL] for field_name in req_dict . keys ( ) : [EOL] if field_name in ( [string] , [string] , [string] , [string] ) : [EOL] continue [EOL] if [string] in field_name : [EOL] filter_field_name = field_name . replace ( [string] , [string] ) [EOL] else : [EOL] filter_field_name = field_name [EOL] for field_value in req_dict [ field_name ] . split ( [string] ) : [EOL] if not field_value : [EOL] continue [EOL] if field_value . startswith ( [string] ) : [EOL] s = s . exclude ( [string] , ** { filter_field_name : field_value . replace ( [string] , [string] ) } ) [EOL] else : [EOL] s = s . filter ( [string] , ** { filter_field_name : field_value } ) [EOL] return s [EOL] [EOL] def gen_pagination ( self , request , count , per_page ) : [EOL] [EOL] paginator = { } [EOL] [EOL] try : [EOL] page = int ( request . GET . get ( [string] , [string] ) ) [EOL] if page < [number] : [EOL] page = [number] [EOL] except ValueError : [EOL] page = [number] [EOL] [EOL] num_pages = self . num_pages ( count , per_page ) [EOL] [EOL] number = page [EOL] if number > num_pages : [EOL] number = num_pages [EOL] [EOL] paginator [ [string] ] = count [EOL] paginator [ [string] ] = number [EOL] paginator [ [string] ] = num_pages [EOL] paginator [ [string] ] = list ( range ( max ( [number] , number - [number] - max ( [number] , number - ( num_pages - [number] ) ) ) , min ( num_pages + [number] , number + [number] + [number] - min ( [number] , number - [number] - [number] ) ) ) ) [EOL] bottom = ( number - [number] ) * per_page [EOL] if bottom < [number] : [EOL] bottom = [number] [EOL] top = bottom + per_page [EOL] if top >= count : [EOL] top = count [EOL] [EOL] paginator [ [string] ] = { [string] : bottom , [string] : top } [EOL] [EOL] return paginator [EOL] [EOL] [EOL] [comment] [EOL] def autocomplete_view ( request ) : [EOL] query = request . GET . get ( [string] , [string] ) [EOL] resp = es_client . suggest ( index = es_index_name , body = { [string] : { [string] : query , [string] : { [string] : [string] , } } } ) [EOL] options = resp [ [string] ] [ [number] ] [ [string] ] [EOL] data = json . dumps ( [ { [string] : i [ [string] ] , [string] : i [ [string] ] } for i in options ] ) [EOL] mime_type = [string] [EOL] return HttpResponse ( data , mime_type ) [EOL] [EOL] [EOL] [comment] [EOL] def title_suggest_view ( request ) : [EOL] query = request . GET . get ( [string] , [string] ) [EOL] s = Search ( using = es_client , index = es_index_name ) . source ( [ [string] ] ) . query ( [string] , title_suggest = { [string] : query , [string] : [string] , [string] : [string] } ) [EOL] response = s . execute ( ) [EOL] [EOL] data = json . dumps ( [ { [string] : i . meta . id , [string] : i . title } for i in response ] ) [EOL] mime_type = [string] [EOL] return HttpResponse ( data , mime_type ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $typing.Any$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.Dict[builtins.str,typing.List[typing.Dict[builtins.str,builtins.str]]]$ 0 0 0 $elasticsearch_dsl.response.AggResponse$ 0 $django.http.QueryDict$ 0 0 0 $core.base.types.DataDict$ 0 0 0 0 0 0 0 0 0 $elasticsearch_dsl.response.AggResponse$ 0 0 0 0 0 0 0 0 0 0 $core.base.types.DataDict$ 0 0 0 0 0 0 0 0 0 0 $elasticsearch_dsl.response.AggResponse$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.http.QueryDict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.DataDict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.DataDict$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 $django.http.HttpRequest$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $django.http.HttpRequest$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 $builtins.int$ 0 $builtins.int$ 0 0 $builtins.int$ 0 $builtins.int$ 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 $builtins.int$ 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 $builtins.int$ 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 $builtins.int$ 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 $builtins.int$ 0 0 0 0 $builtins.int$ 0 0 $builtins.int$ 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.int$ 0 0 $builtins.int$ 0 $builtins.int$ 0 0 $builtins.int$ 0 $builtins.int$ 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [EOL] from typing import Any , Literal , Dict , Tuple , List [EOL] import typing [EOL] import viewer [EOL] import core [EOL] import typing_extensions [EOL] import django [EOL] import builtins [EOL] import json [EOL] import re [EOL] from itertools import chain [EOL] import typing [EOL] [EOL] from django . contrib . auth . decorators import login_required [EOL] from django . core import serializers [EOL] from django . db import transaction [EOL] from django . db . models import Q , QuerySet [EOL] from django . http import HttpResponse , HttpRequest [EOL] from django . http . request import QueryDict [EOL] from django . shortcuts import render [EOL] from django . core . paginator import Paginator , EmptyPage [EOL] from django . urls import reverse [EOL] from django . conf import settings [EOL] [EOL] from core . base . types import DataDict [EOL] from core . base . utilities import timestamp_or_zero , str_to_int [EOL] from viewer . forms import ArchiveSearchForm [EOL] from viewer . models import Gallery , Tag , Archive , Image , UserArchivePrefs , GalleryQuerySet , ArchiveQuerySet [EOL] from viewer . views . head import archive_filter_keys , filter_archives [EOL] [EOL] [EOL] crawler_settings = settings . CRAWLER_SETTINGS [EOL] [EOL] [EOL] [comment] [EOL] def tag_frequency ( request ) : [EOL] title = request . GET . get ( [string] , [string] ) [EOL] tags = request . GET . get ( [string] , [string] ) [EOL] if [string] in request . GET : [EOL] form = ArchiveSearchForm ( ) [EOL] else : [EOL] form = ArchiveSearchForm ( initial = { [string] : title , [string] : tags } ) [EOL] d = { [string] : form } [EOL] return render ( request , [string] , d ) [EOL] [EOL] [EOL] def gallery_frequency ( request ) : [EOL] title = request . GET . get ( [string] , [string] ) [EOL] tags = request . GET . get ( [string] , [string] ) [EOL] if [string] in request . GET : [EOL] form = ArchiveSearchForm ( ) [EOL] else : [EOL] form = ArchiveSearchForm ( initial = { [string] : title , [string] : tags } ) [EOL] d = { [string] : form } [EOL] return render ( request , [string] , d ) [EOL] [EOL] [EOL] def get_gallery_data ( data ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] order = [string] [EOL] [EOL] results = Gallery . objects . order_by ( order ) [EOL] [EOL] if [string] in data : [EOL] q_formatted = [string] + data [ [string] ] . replace ( [string] , [string] ) + [string] [EOL] results = results . filter ( Q ( title__ss = q_formatted ) | Q ( title_jpn__ss = q_formatted ) ) [EOL] [EOL] if [string] in data : [EOL] tags = data [ [string] ] . split ( [string] ) [EOL] for tag in tags : [EOL] tag = tag . strip ( ) . replace ( [string] , [string] ) [EOL] tag_clean = re . sub ( [string] , [string] , tag ) [EOL] scope_name = tag_clean . split ( [string] , maxsplit = [number] ) [EOL] if len ( scope_name ) > [number] : [EOL] tag_scope = scope_name [ [number] ] [EOL] tag_name = scope_name [ [number] ] [EOL] else : [EOL] tag_scope = [string] [EOL] tag_name = scope_name [ [number] ] [EOL] if tag . startswith ( [string] ) : [EOL] if tag_name != [string] and tag_scope != [string] : [EOL] tag_query = Q ( tags__name__contains = tag_name ) & Q ( tags__scope__contains = tag_scope ) [EOL] elif tag_name != [string] : [EOL] tag_query = Q ( tags__name__contains = tag_name ) [EOL] else : [EOL] tag_query = Q ( tags__scope__contains = tag_scope ) [EOL] [EOL] results = results . exclude ( tag_query ) [EOL] elif tag . startswith ( [string] ) : [EOL] if tag_name != [string] and tag_scope != [string] : [EOL] tag_query = Q ( tags__name__exact = tag_name ) & Q ( tags__scope__exact = tag_scope ) [EOL] elif tag_name != [string] : [EOL] tag_query = Q ( tags__name__exact = tag_name ) [EOL] else : [EOL] tag_query = Q ( tags__scope__exact = tag_scope ) [EOL] [EOL] results = results . filter ( tag_query ) [EOL] else : [EOL] if tag_name != [string] and tag_scope != [string] : [EOL] tag_query = Q ( tags__name__contains = tag_name ) & Q ( tags__scope__contains = tag_scope ) [EOL] elif tag_name != [string] : [EOL] tag_query = Q ( tags__name__contains = tag_name ) [EOL] else : [EOL] tag_query = Q ( tags__scope__contains = tag_scope ) [EOL] [EOL] results = results . filter ( tag_query ) [EOL] [EOL] results = results . distinct ( ) [EOL] [EOL] return results [comment] [EOL] [EOL] [EOL] def seeder ( request ) : [EOL] if request . method == [string] : [EOL] data = request . GET [EOL] if [string] not in data and [string] not in data : [EOL] response = json . dumps ( { [string] : [string] } ) [EOL] else : [EOL] galleries = get_gallery_data ( data ) [EOL] tags = Tag . objects . filter ( gallery__in = galleries ) . distinct ( ) [EOL] combined = list ( chain ( tags , galleries ) ) [EOL] response = serializers . serialize ( [string] , combined , fields = ( [string] , [string] , [string] , [string] , [string] ) ) [EOL] else : [EOL] response = json . dumps ( { [string] : [string] } ) [EOL] return HttpResponse ( response , content_type = [string] ) [EOL] [EOL] [EOL] def release_date_seeder ( request ) : [EOL] if request . method == [string] : [EOL] data = request . GET [EOL] if [string] not in data and [string] not in data : [EOL] response = json . dumps ( { [string] : [string] } ) [EOL] else : [EOL] galleries = get_gallery_data ( data ) . filter ( posted__gt = [string] ) [EOL] [comment] [EOL] [comment] [EOL] response = serializers . serialize ( [string] , list ( galleries ) , fields = ( [string] , [string] , [string] ) ) [EOL] else : [EOL] response = json . dumps ( { [string] : [string] } ) [EOL] return HttpResponse ( response , content_type = [string] ) [EOL] [EOL] [EOL] def get_archive_data ( data ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] order = [string] [EOL] if [string] in data : [EOL] order = data [ [string] ] [EOL] if order == [string] : [EOL] order = [string] + order [EOL] elif order == [string] : [EOL] order = [string] + order [EOL] if [string] not in data : [EOL] order = [string] + order [EOL] [EOL] results = Archive . objects . order_by ( order ) [EOL] [EOL] if [string] in data : [EOL] q_formatted = [string] + data [ [string] ] . replace ( [string] , [string] ) + [string] [EOL] results = results . filter ( Q ( title__ss = q_formatted ) | Q ( title_jpn__ss = q_formatted ) ) [EOL] [EOL] if [string] in data : [EOL] results = results . filter ( zipped__icontains = data [ [string] ] ) [EOL] if [string] in data : [EOL] results = results . filter ( gallery__rating__gte = float ( data [ [string] ] ) ) [EOL] if [string] in data : [EOL] results = results . filter ( gallery__rating__lte = float ( data [ [string] ] ) ) [EOL] if [string] in data : [EOL] results = results . filter ( filecount__gte = int ( float ( data [ [string] ] ) ) ) [EOL] if [string] in data : [EOL] results = results . filter ( filecount__lte = int ( float ( data [ [string] ] ) ) ) [EOL] if [string] in data : [EOL] results = results . filter ( filesize__gte = int ( float ( data [ [string] ] ) ) ) [EOL] if [string] in data : [EOL] results = results . filter ( filesize__lte = int ( float ( data [ [string] ] ) ) ) [EOL] if [string] in data : [EOL] results = results . filter ( gallery__posted__gte = data [ [string] ] ) [EOL] if [string] in data : [EOL] results = results . filter ( gallery__posted__lte = data [ [string] ] ) [EOL] if [string] in data : [EOL] results = results . filter ( match_type__icontains = data [ [string] ] ) [EOL] if [string] in data : [EOL] results = results . filter ( source_type__icontains = data [ [string] ] ) [EOL] if [string] in data : [EOL] results = results . filter ( extracted = True ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] if [string] in data : [EOL] terms = data [ [string] ] . split ( ) [EOL] for term in terms : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] tag = term . strip ( ) . replace ( [string] , [string] ) [EOL] tag_clean = re . sub ( [string] , [string] , tag ) [EOL] scope_name = tag_clean . split ( [string] , maxsplit = [number] ) [EOL] if term . startswith ( [string] ) : [EOL] tag_query = ( Q ( tags__name__contains = scope_name [ [number] ] ) & Q ( tags__scope__contains = scope_name [ [number] ] ) ) if len ( scope_name ) > [number] else Q ( tags__name__contains = scope_name [ [number] ] ) [EOL] results = results . exclude ( tag_query ) [EOL] elif term . startswith ( [string] ) : [EOL] tag_query = ( Q ( tags__name__exact = scope_name [ [number] ] ) & Q ( tags__scope__exact = scope_name [ [number] ] ) ) if len ( scope_name ) > [number] else Q ( tags__name__exact = scope_name [ [number] ] ) [EOL] results = results . filter ( tag_query ) [EOL] else : [EOL] tag_query = ( Q ( tags__name__contains = scope_name [ [number] ] ) & Q ( tags__scope__contains = scope_name [ [number] ] ) ) if len ( scope_name ) > [number] else Q ( tags__name__contains = scope_name [ [number] ] ) [EOL] results = results . filter ( tag_query ) [EOL] [EOL] results = results . distinct ( ) . prefetch_related ( [string] ) [EOL] [EOL] return results [comment] [EOL] [EOL] [EOL] [comment] [EOL] def api ( request , model = None , obj_id = None , action = None ) : [EOL] if request . method == [string] : [EOL] data = request . GET [EOL] if model == [string] and obj_id is not None : [EOL] try : [EOL] archive_id = int ( obj_id ) [EOL] except ( ValueError , TypeError ) : [EOL] return HttpResponse ( json . dumps ( { [string] : [string] } ) , content_type = [string] ) [EOL] if action == [string] : [EOL] try : [EOL] if request . user . is_staff or data . get ( [string] , [string] ) == crawler_settings . api_key : [EOL] with transaction . atomic ( ) : [EOL] archive = Archive . objects . select_for_update ( ) . get ( pk = archive_id ) [EOL] archive . extract_toggle ( ) [EOL] else : [EOL] return HttpResponse ( json . dumps ( { [string] : [string] } ) , content_type = [string] ) [EOL] except Archive . DoesNotExist : [EOL] return HttpResponse ( json . dumps ( { [string] : [string] } ) , content_type = [string] ) [EOL] [EOL] response = json . dumps ( { [string] : [string] , [string] : { [string] : [string] , [string] : archive . extracted , } , } ) [EOL] elif action == [string] : [EOL] positions = data . getlist ( [string] ) [EOL] try : [EOL] if request . user . is_authenticated or data . get ( [string] , [string] ) == crawler_settings . api_key : [EOL] images = Image . objects . filter ( archive = archive_id , position__in = positions , extracted = True ) [EOL] else : [EOL] images = Image . objects . filter ( archive = archive_id , position__in = positions , extracted = True ) . filter ( archive__public = True ) [EOL] except Archive . DoesNotExist : [EOL] return HttpResponse ( json . dumps ( { [string] : [string] } ) , content_type = [string] ) [EOL] image_urls = [ { [string] : image . position , [string] : request . build_absolute_uri ( image . image . url ) , [string] : image . image_width / image . image_height > [number] if image . image_width and image . image_height else False , [string] : image . image_width , [string] : image . image_height } for image in sorted ( images , key = lambda img : positions . index ( str ( img . position ) ) ) ] [EOL] response = json . dumps ( image_urls ) [EOL] else : [EOL] try : [EOL] if request . user . is_authenticated or data . get ( [string] , [string] ) == crawler_settings . api_key : [EOL] archive = Archive . objects . select_related ( [string] ) . prefetch_related ( [string] ) . get ( pk = archive_id ) [EOL] else : [EOL] archive = Archive . objects . filter ( public = True , extracted = True ) . select_related ( [string] ) . prefetch_related ( [string] ) . get ( pk = archive_id ) [EOL] except Archive . DoesNotExist : [EOL] return HttpResponse ( json . dumps ( { [string] : [string] } ) , content_type = [string] ) [EOL] position = int ( data [ [string] ] ) if [string] in data else [number] [EOL] [EOL] [comment] [EOL] [comment] [EOL] response = json . dumps ( { [string] : archive . pk , [string] : archive . title , [string] : archive . title_jpn , [string] : archive . gallery . category if archive . gallery else [string] , [string] : archive . gallery . uploader if archive . gallery else [string] , [string] : int ( timestamp_or_zero ( archive . gallery . posted ) ) if archive . gallery else [string] , [string] : archive . filecount , [string] : archive . filesize , [string] : request . build_absolute_uri ( reverse ( [string] , args = ( archive . pk , ) ) ) , [string] : request . build_absolute_uri ( reverse ( [string] , args = ( archive . pk , ) ) ) , [string] : archive . gallery . expunged if archive . gallery else [string] , [string] : float ( str_to_int ( archive . gallery . rating ) ) if archive . gallery else [string] , [string] : archive . gallery . fjord if archive . gallery else [string] , [string] : archive . tag_list_sorted ( ) , [string] : archive . extracted , [string] : ( request . build_absolute_uri ( archive . thumbnail . url ) if archive . thumbnail else None ) , [string] : int ( archive . image_set . count ( ) ) or archive . filecount , [string] : archive . image_set . get ( position = position ) . dump_image ( request ) if archive . extracted else None , } , sort_keys = True , ensure_ascii = False , ) [EOL] elif model == [string] : [EOL] archives_list = get_archive_data ( data ) [EOL] if not request . user . is_authenticated and not data . get ( [string] , [string] ) == crawler_settings . api_key : [EOL] archives_list = archives_list . filter ( public = True , extracted = True ) [EOL] if [string] in data and data [ [string] ] and request . user . is_authenticated : [EOL] user_arch_ids = UserArchivePrefs . objects . filter ( user = request . user . id , favorite_group = int ( data [ [string] ] ) ) . values_list ( [string] ) [EOL] archives_list = archives_list . filter ( id__in = user_arch_ids ) [EOL] response = archives_to_json_response ( archives_list , request ) [EOL] elif model == [string] : [EOL] [EOL] display_prms = { } [EOL] [EOL] if [string] in request . session : [EOL] parameters = request . session [ [string] ] [EOL] else : [EOL] parameters = { } [EOL] [EOL] keys = ( [string] , [string] ) [EOL] [EOL] for k in keys : [EOL] if k not in parameters : [EOL] parameters [ k ] = [string] [EOL] [EOL] for k in archive_filter_keys : [EOL] if k not in display_prms : [EOL] display_prms [ k ] = [string] [EOL] [EOL] for k , v in data . items ( ) : [EOL] if k in parameters : [EOL] parameters [ k ] = v [EOL] elif k in display_prms : [EOL] display_prms [ k ] = v [EOL] [EOL] if [string] not in parameters or parameters [ [string] ] == [string] : [EOL] parameters [ [string] ] = [string] [EOL] if [string] not in parameters or parameters [ [string] ] == [string] : [EOL] parameters [ [string] ] = [string] [EOL] if [string] not in parameters or parameters [ [string] ] == [string] : [EOL] if request . user . is_authenticated or data . get ( [string] , [string] ) == crawler_settings . api_key : [EOL] parameters [ [string] ] = [string] [EOL] else : [EOL] parameters [ [string] ] = [string] [EOL] [EOL] if data . get ( [string] , [string] ) == crawler_settings . api_key : [EOL] force_private = True [EOL] else : [EOL] force_private = False [EOL] [EOL] archives_list_filtered = filter_archives ( request , parameters , display_prms , force_private = force_private ) [EOL] if [string] in data : [EOL] archives_list_filtered = archives_list_filtered . filter ( extracted = True ) [EOL] [EOL] response = archives_to_json_response ( archives_list_filtered , request ) [EOL] elif model == [string] : [EOL] response = json . dumps ( { [string] : request . user . id , [string] : request . user . username , [string] : request . user . is_staff , } ) [EOL] else : [EOL] response = json . dumps ( { [string] : [string] } ) [EOL] else : [EOL] response = json . dumps ( { [string] : [string] } ) [EOL] [EOL] http_response = HttpResponse ( response , content_type = [string] ) [EOL] [comment] [EOL] [comment] [EOL] return http_response [EOL] [EOL] [EOL] def archives_to_json_response ( archives_list , request ) : [EOL] paginator = Paginator ( archives_list , [number] ) [EOL] try : [EOL] page = int ( request . GET . get ( [string] , [string] ) ) [EOL] except ValueError : [EOL] page = [number] [EOL] try : [EOL] archives = paginator . page ( page ) [EOL] except EmptyPage : [EOL] [comment] [EOL] archives = paginator . page ( paginator . num_pages ) [EOL] response = json . dumps ( { [string] : [ { [string] : archive . pk , [string] : archive . title , [string] : archive . filecount , [string] : archive . filesize , [string] : request . build_absolute_uri ( reverse ( [string] , args = ( archive . pk , ) ) ) , [string] : request . build_absolute_uri ( reverse ( [string] , args = ( archive . pk , ) ) ) , [string] : ( request . build_absolute_uri ( archive . thumbnail . url ) if archive . thumbnail else None ) , [string] : ( archive . thumbnail_height if archive . thumbnail else None ) , [string] : ( archive . thumbnail_width if archive . thumbnail else None ) , [string] : archive . tag_list_sorted ( ) , [string] : archive . extracted , } for archive in archives ] , [string] : archives . has_previous ( ) , [string] : archives . has_next ( ) , [string] : paginator . num_pages , [string] : paginator . count , [string] : archives . number , } ) [EOL] return response [EOL] [EOL] [EOL] @ login_required def new_image_viewer ( request , archive = None , image = None ) : [EOL] [EOL] return render ( request , [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.http.HttpResponse$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] from django . core . mail import get_connection , EmailMultiAlternatives [EOL] [EOL] [EOL] def send_mass_html_mail ( datatuple , fail_silently = False , user = None , password = None , connection = None ) : [EOL] [docstring] [EOL] connection = connection or get_connection ( username = user , password = password , fail_silently = fail_silently ) [EOL] messages = [ ] [EOL] for subject , text , html , from_email , recipient in datatuple : [EOL] message = EmailMultiAlternatives ( subject , text , from_email , recipient , headers = { [string] : [string] } ) [EOL] message . attach_alternative ( html , [string] ) [EOL] messages . append ( message ) [EOL] return connection . send_messages ( messages ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Tuple , List [EOL] import typing [EOL] import builtins [EOL] import os [EOL] from typing import List , Tuple [EOL] [EOL] [EOL] class DirBrowser ( object ) : [EOL] [EOL] def __init__ ( self , path ) : [EOL] self . path = os . path . normpath ( path ) [EOL] [EOL] def realpath ( self , path ) : [EOL] p = os . path . normpath ( os . path . join ( self . path , path ) ) [EOL] if not p . startswith ( self . path ) : [EOL] p = self . path [EOL] return p [EOL] [EOL] def relativepath ( self , path ) : [EOL] p = os . path . normpath ( os . path . join ( self . path , path ) ) [EOL] if not p . startswith ( self . path ) : [EOL] p = self . path [EOL] return str ( os . path . relpath ( p , self . path ) ) [EOL] [EOL] def isdir ( self , path ) : [EOL] p = os . path . normpath ( os . path . join ( self . path , path ) ) [EOL] if not p . startswith ( self . path ) : [EOL] p = self . path [EOL] return os . path . isdir ( p ) [EOL] [EOL] def files ( self , path = [string] ) : [EOL] p = os . path . normpath ( os . path . join ( self . path , path ) ) [EOL] if not p . startswith ( self . path ) : [EOL] p = self . path [EOL] dir_list = os . listdir ( p ) [EOL] files = sorted ( [ ( f , os . path . isdir ( os . path . join ( p , f ) ) ) for f in dir_list ] ) [EOL] if not self . path == p : [EOL] files . insert ( [number] , ( [string] , os . path . isdir ( os . path . join ( p , [string] ) ) ) ) [EOL] return files [EOL] [EOL] def file ( self , path ) : [EOL] p = os . path . normpath ( os . path . join ( self . path , path ) ) [EOL] if not p . startswith ( self . path ) : [EOL] p = self . path [EOL] return p [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.bool$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.bool]]$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.bool]]$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.bool]]$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.bool]]$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0
	0
from typing import Any , Iterable , Tuple , List [EOL] import typing [EOL] import django [EOL] import builtins [EOL] import typing [EOL] from typing import List , Tuple , Iterable [EOL] [EOL] from django . db . models import QuerySet [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from viewer . models import Tag [EOL] [EOL] scope_priorities = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] [EOL] [EOL] def sort_tags ( tag_list ) : [EOL] [EOL] prioritized_tag_list = list ( ) [EOL] [EOL] for scope in scope_priorities : [EOL] matched_tags = sorted ( [ x for x in tag_list if x . scope == scope ] , key = str ) [EOL] if matched_tags : [EOL] prioritized_tag_list . append ( ( scope , matched_tags ) ) [EOL] [EOL] remaining_tags = sorted ( [ x for x in tag_list if x . scope not in scope_priorities ] , key = str ) [EOL] if remaining_tags : [EOL] prioritized_tag_list . append ( ( [string] , remaining_tags ) ) [EOL] [EOL] return prioritized_tag_list [EOL] [EOL] [EOL] def sort_tags_str ( tag_list ) : [EOL] [EOL] prioritized_tag_list = list ( ) [EOL] [EOL] for scope in scope_priorities : [EOL] matched_tags = sorted ( [ str ( x ) for x in tag_list if x . scope == scope ] , key = str ) [EOL] if matched_tags : [EOL] prioritized_tag_list . extend ( matched_tags ) [EOL] [EOL] remaining_tags = sorted ( [ str ( x ) for x in tag_list if x . scope not in scope_priorities ] , key = str ) [EOL] if remaining_tags : [EOL] prioritized_tag_list . extend ( remaining_tags ) [EOL] [EOL] return prioritized_tag_list [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,typing.List['Tag']]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] import django . dispatch [EOL] from django . utils import timezone as django_tz [EOL] [EOL] from viewer . models import EventLog [EOL] [EOL] [EOL] def event_log ( user , action , reason = None , data = None , result = None , content_object = None , create_date = None ) : [EOL] if user is not None and not user . is_authenticated : [EOL] user = None [EOL] if create_date is None : [EOL] create_date = django_tz . now ( ) [EOL] [EOL] event = EventLog . objects . create ( user = user , action = action , reason = reason , data = data , result = result , content_object = content_object , create_date = create_date ) [EOL] django . dispatch . Signal ( providing_args = [ [string] ] ) . send ( sender = EventLog , event = event ) [EOL] return event [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Type , Dict , Union , List [EOL] import typing [EOL] import viewer [EOL] from typing import Union , Type [EOL] [EOL] from django . conf import settings [EOL] from django . core . management . base import BaseCommand [EOL] from viewer . models import Archive , Gallery [EOL] [EOL] crawler_settings = settings . CRAWLER_SETTINGS [EOL] [EOL] [EOL] class Command ( BaseCommand ) : [EOL] help = [string] [EOL] [EOL] def __init__ ( self , * args , ** kwargs ) : [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] from elasticsearch import Elasticsearch , RequestsHttpConnection [EOL] [EOL] self . es_client = Elasticsearch ( [ crawler_settings . elasticsearch . url ] , connection_class = RequestsHttpConnection ) [EOL] [EOL] def add_arguments ( self , parser ) : [EOL] parser . add_argument ( [string] , [string] , required = False , action = [string] , default = False , help = [string] ) [EOL] parser . add_argument ( [string] , [string] , required = False , action = [string] , default = False , help = [string] ) [EOL] parser . add_argument ( [string] , [string] , required = False , action = [string] , default = False , help = [string] ) [EOL] parser . add_argument ( [string] , [string] , required = False , action = [string] , default = False , help = [string] ) [EOL] [EOL] def handle ( self , * args , ** options ) : [EOL] [EOL] if options [ [string] ] : [EOL] self . recreate_index_model ( Archive ) [EOL] if options [ [string] ] : [EOL] self . recreate_index_model ( Gallery ) [EOL] if options [ [string] ] : [EOL] self . push_db_to_index_model ( Archive ) [EOL] if options [ [string] ] : [EOL] self . push_db_to_index_model ( Gallery ) [EOL] [EOL] def recreate_index_model ( self , model ) : [EOL] [EOL] from elasticsearch . client import IndicesClient [EOL] [EOL] indices_client = IndicesClient ( client = self . es_client ) [EOL] index_name = model . _meta . es_index_name [EOL] if indices_client . exists ( index_name ) : [EOL] indices_client . delete ( index = index_name ) [EOL] indices_client . create ( index = index_name ) [EOL] indices_client . close ( index = index_name ) [EOL] indices_client . put_settings ( index = index_name , body = { [string] : { [string] : settings . MAX_RESULT_WINDOW } , [string] : { [string] : { [string] : { [string] : [string] , [string] : [number] , [string] : [number] } } , [string] : { [string] : { [string] : [string] , [string] : [string] , [string] : [ [string] , [string] ] } } } } ) [EOL] indices_client . put_mapping ( body = model . _meta . es_mapping , index = index_name , ) [EOL] indices_client . open ( index = index_name ) [EOL] [EOL] def push_db_to_index_model ( self , model ) : [EOL] [EOL] from elasticsearch . helpers import bulk [EOL] [EOL] if settings . ES_ONLY_INDEX_PUBLIC : [EOL] data = [ self . convert_for_bulk ( s , [string] ) for s in model . objects . filter ( public = True ) ] [EOL] else : [EOL] data = [ self . convert_for_bulk ( s , [string] ) for s in model . objects . all ( ) ] [EOL] bulk ( client = self . es_client , actions = data , stats_only = True ) [EOL] [EOL] def convert_for_bulk ( self , django_object , action = None ) : [EOL] data = django_object . es_repr ( ) [EOL] metadata = { [string] : action , [string] : django_object . _meta . es_index_name , } [EOL] data . update ( ** metadata ) [EOL] return data [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Union[typing.Type[viewer.models.Gallery],typing.Type[viewer.models.Archive]]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Union[typing.Type[viewer.models.Gallery],typing.Type[viewer.models.Archive]]$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Union[typing.Type[viewer.models.Gallery],typing.Type[viewer.models.Archive]]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Union[typing.Type[viewer.models.Gallery],typing.Type[viewer.models.Archive]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Union[typing.Type[viewer.models.Gallery],typing.Type[viewer.models.Archive]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Union[typing.Type[viewer.models.Gallery],typing.Type[viewer.models.Archive]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Dict[builtins.str,unknown]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Dict[builtins.str,unknown]$ 0 0 0 $typing.Any$ 0
from typing import Any , Dict , List [EOL] import requests [EOL] import typing [EOL] import viewer [EOL] import ftplib [EOL] import ssl [EOL] import socket [EOL] from ftplib import FTP_TLS [EOL] import json [EOL] import os [EOL] import ssl [EOL] import time [EOL] import requests [EOL] [EOL] from django . core . management . base import BaseCommand [EOL] from django . conf import settings [EOL] from viewer . models import Archive , Gallery [EOL] [EOL] crawler_settings = settings . CRAWLER_SETTINGS [EOL] [EOL] [EOL] def get_gid_path_association ( site_page , api_key ) : [EOL] [EOL] archives_gid_provider = list ( Archive . objects . filter ( gallery__hidden = True ) . values_list ( [string] , [string] ) ) [EOL] data = { [string] : [string] , [string] : api_key , [string] : json . dumps ( archives_gid_provider ) } [EOL] [EOL] headers = { [string] : [string] } [EOL] r = requests . post ( site_page , data = json . dumps ( data ) , headers = { ** headers } , timeout = [number] ) [EOL] response_data = { } [EOL] try : [EOL] response_data = r . json ( ) [EOL] except ( ValueError , KeyError ) : [EOL] pass [EOL] [EOL] return response_data [EOL] [EOL] [EOL] def send_urls_from_archive_list ( site_page , api_key , reason , details , archive_ids ) : [EOL] [EOL] url_list = [ x . get_link ( ) for x in Archive . objects . filter ( pk__in = archive_ids ) ] [EOL] [EOL] data = { [string] : [string] , [string] : api_key , [string] : url_list } [EOL] [EOL] if reason : [EOL] data [ [string] ] = reason [EOL] if details : [EOL] data [ [string] ] = details [EOL] [EOL] headers = { [string] : [string] } [EOL] r = requests . post ( site_page , data = json . dumps ( data ) , headers = { ** headers } , timeout = [number] ) [EOL] try : [EOL] response_data = r . json ( ) [EOL] yield( [string] . format ( response_data [ [string] ] ) ) [EOL] except ( ValueError , KeyError ) : [EOL] yield( [string] . format ( r . text ) ) [EOL] [EOL] [EOL] def send_urls_from_archives ( site_page , api_key , reason , details ) : [EOL] [EOL] url_list = [ x . get_link ( ) for x in Archive . objects . filter ( gallery__hidden = True ) ] [EOL] [EOL] data = { [string] : [string] , [string] : api_key , [string] : url_list } [EOL] [EOL] if reason : [EOL] data [ [string] ] = reason [EOL] if details : [EOL] data [ [string] ] = details [EOL] [EOL] headers = { [string] : [string] } [EOL] r = requests . post ( site_page , data = json . dumps ( data ) , headers = { ** headers } , timeout = [number] ) [EOL] try : [EOL] response_data = r . json ( ) [EOL] yield( [string] . format ( response_data [ [string] ] ) ) [EOL] except ( ValueError , KeyError ) : [EOL] yield( [string] . format ( r . text ) ) [EOL] [EOL] [EOL] def send_urls_from_galleries ( site_page , api_key ) : [EOL] [EOL] url_list = [ x . get_link ( ) for x in Gallery . objects . filter ( hidden = True ) ] [EOL] [EOL] data = { [string] : [string] , [string] : api_key , [string] : url_list } [EOL] [EOL] headers = { [string] : [string] } [EOL] r = requests . post ( site_page , data = json . dumps ( data ) , headers = { ** headers } , timeout = [number] ) [EOL] try : [EOL] response_data = r . json ( ) [EOL] yield( [string] . format ( response_data [ [string] ] ) ) [EOL] except ( ValueError , KeyError ) : [EOL] yield( [string] . format ( r . text ) ) [EOL] [EOL] [EOL] def send_urls_fakku ( site_page , api_key ) : [EOL] [EOL] url_list = [ x . get_link ( ) for x in Gallery . objects . filter ( provider__contains = [string] ) ] [EOL] [EOL] data = { [string] : [string] , [string] : api_key , [string] : url_list } [EOL] [EOL] headers = { [string] : [string] } [EOL] r = requests . post ( site_page , data = json . dumps ( data ) , headers = { ** headers } , timeout = [number] ) [EOL] try : [EOL] response_data = r . json ( ) [EOL] yield( [string] . format ( response_data [ [string] ] ) ) [EOL] except ( ValueError , KeyError ) : [EOL] yield( [string] . format ( r . text ) ) [EOL] [EOL] [EOL] class FTPHandler ( object ) : [EOL] [EOL] def __init__ ( self , c_settings , print_method = print ) : [EOL] self . settings = c_settings [EOL] self . upload_current = [number] [EOL] self . upload_total = [number] [EOL] self . print_method = print_method [EOL] [EOL] def upload_archive_file ( self , local_filename , remote_filename , target_dir ) : [EOL] [EOL] yield( [string] . format ( local_filename , target_dir , remote_filename ) ) [EOL] [EOL] local_filesize = os . stat ( local_filename ) . st_size [EOL] self . upload_total = os . stat ( local_filename ) . st_size [EOL] self . upload_current = [number] [EOL] [EOL] if self . settings . ftps [ [string] ] : [EOL] context = ssl . SSLContext ( ssl . PROTOCOL_TLSv1_2 ) [EOL] context . verify_mode = ssl . CERT_NONE [EOL] context . check_hostname = False [EOL] else : [EOL] context = ssl . create_default_context ( ) [EOL] ftps = FTP_TLS ( host = self . settings . ftps [ [string] ] , user = self . settings . ftps [ [string] ] , passwd = self . settings . ftps [ [string] ] , context = context , source_address = self . settings . ftps [ [string] ] , timeout = self . settings . timeout_timer ) [EOL] ftps . cwd ( target_dir ) [EOL] ftps . encoding = [string] [EOL] ftps . prot_p ( ) [EOL] for line in ftps . mlsd ( facts = [ [string] ] ) : [EOL] if ( line [ [number] ] == remote_filename [EOL] and local_filesize == int ( line [ [number] ] [ [string] ] ) ) : [EOL] yield( [string] ) [EOL] ftps . close ( ) [EOL] return [EOL] with open ( local_filename , [string] ) as file : [EOL] for retry_count in range ( [number] ) : [EOL] try : [EOL] ftps . storbinary ( [string] % remote_filename , file , callback = lambda data , args = self . print_method : self . print_progress ( data , args ) ) [EOL] except ( ConnectionResetError , socket . timeout , TimeoutError ) : [EOL] yield( [string] ) [EOL] else : [EOL] break [EOL] yield( [string] ) [EOL] ftps . close ( ) [EOL] [EOL] def print_progress ( self , data , print_method ) : [EOL] self . upload_current += len ( data ) [EOL] progress = self . upload_current / self . upload_total * [number] [EOL] print_method ( [string] . format ( progress ) , ending = [string] ) [EOL] [EOL] def check_remote ( self , all_archives , remote_site_api , api_key , remote_folder ) : [EOL] [EOL] remote_info = get_gid_path_association ( remote_site_api , api_key ) [EOL] [EOL] yield ( [string] . format ( all_archives . count ( ) , len ( remote_info [ [string] ] ) ) ) [EOL] [EOL] for cnt , remote_archive in enumerate ( remote_info [ [string] ] , start = [number] ) : [EOL] [EOL] yield( [string] . format ( cnt , len ( remote_info [ [string] ] ) ) ) [EOL] [EOL] local_archives = Archive . objects . filter ( gallery__gid = remote_archive [ [string] ] , gallery__provider = remote_archive [ [string] ] , ) [EOL] [EOL] if local_archives and local_archives . count ( ) == [number] : [EOL] local_archive = local_archives . first ( ) [EOL] if not os . path . isfile ( local_archive . zipped . path ) : [EOL] yield( [string] . format ( local_archive . title ) ) [EOL] continue [EOL] yield( [string] . format ( local_archive . title , local_archive . filesize ) ) [EOL] for message in self . upload_archive_file ( local_archive . zipped . path , os . path . split ( remote_archive [ [string] ] ) [ [number] ] , os . path . join ( remote_folder , str ( remote_archive [ [string] ] ) ) ) : [EOL] yield(message) [EOL] else : [EOL] yield( [string] . format ( remote_archive [ [string] ] ) ) [EOL] [EOL] yield( [string] ) [EOL] [EOL] [EOL] class Command ( BaseCommand ) : [EOL] help = [string] [EOL] [EOL] def add_arguments ( self , parser ) : [EOL] parser . add_argument ( [string] , [string] , required = False , action = [string] , default = False , help = ( [string] [string] [string] [string] ) ) [EOL] parser . add_argument ( [string] , [string] , required = False , action = [string] , nargs = [string] , type = int , help = [string] ) [EOL] parser . add_argument ( [string] , [string] , required = False , action = [string] , default = [string] , help = [string] ) [EOL] parser . add_argument ( [string] , [string] , required = False , action = [string] , default = [string] , help = [string] ) [EOL] parser . add_argument ( [string] , [string] , required = False , action = [string] , default = False , help = [string] ) [EOL] parser . add_argument ( [string] , [string] , required = False , action = [string] , default = False , help = [string] ) [EOL] parser . add_argument ( [string] , [string] , required = False , action = [string] , default = False , help = [string] ) [EOL] [EOL] def handle ( self , * args , ** options ) : [EOL] start = time . perf_counter ( ) [EOL] if options [ [string] ] : [EOL] for message in send_urls_from_archive_list ( crawler_settings . remote_site [ [string] ] , crawler_settings . remote_site [ [string] ] , options [ [string] ] , options [ [string] ] , options [ [string] ] , ) : [EOL] self . stdout . write ( message ) [EOL] if options [ [string] ] : [EOL] for message in send_urls_from_archives ( crawler_settings . remote_site [ [string] ] , crawler_settings . remote_site [ [string] ] , options [ [string] ] , options [ [string] ] ) : [EOL] self . stdout . write ( message ) [EOL] if options [ [string] ] : [EOL] for message in send_urls_from_galleries ( crawler_settings . remote_site [ [string] ] , crawler_settings . remote_site [ [string] ] ) : [EOL] self . stdout . write ( message ) [EOL] if options [ [string] ] : [EOL] for message in send_urls_fakku ( crawler_settings . remote_site [ [string] ] , crawler_settings . remote_site [ [string] ] ) : [EOL] self . stdout . write ( message ) [EOL] if options [ [string] ] : [EOL] all_archives = Archive . objects . filter_and_order_by_posted ( gallery__hidden = True ) [EOL] [EOL] ftp_handler = FTPHandler ( crawler_settings , print_method = self . stdout . write ) [EOL] for message in ftp_handler . check_remote ( all_archives , crawler_settings . remote_site [ [string] ] , crawler_settings . remote_site [ [string] ] , crawler_settings . remote_site [ [string] ] ) : [EOL] self . stdout . write ( message ) [EOL] [EOL] end = time . perf_counter ( ) [EOL] [EOL] self . stdout . write ( self . style . SUCCESS ( [string] . format ( end - start , ( end - start ) / [number] ) ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 $ftplib.FTP_TLS$ 0 0 0 0 0 $ssl.SSLContext$ 0 0 0 0 0 0 0 0 0 0 $ssl.SSLContext$ 0 $builtins.int$ 0 0 0 0 0 $ssl.SSLContext$ 0 $builtins.bool$ 0 0 0 0 0 0 $ssl.SSLContext$ 0 0 0 0 0 0 0 $ftplib.FTP_TLS$ 0 0 0 0 0 0 0 0 0 $ftplib.FTP_TLS$ 0 0 0 0 0 0 0 0 0 0 $ftplib.FTP_TLS$ 0 0 0 0 0 0 0 0 0 0 $ftplib.FTP_TLS$ 0 0 0 0 $ssl.SSLContext$ 0 $ssl.SSLContext$ 0 0 0 0 0 0 0 $ftplib.FTP_TLS$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $ftplib.FTP_TLS$ 0 0 0 0 0 0 $ftplib.FTP_TLS$ 0 $builtins.str$ 0 0 0 $ftplib.FTP_TLS$ 0 0 0 0 0 0 0 0 $ftplib.FTP_TLS$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $ftplib.FTP_TLS$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $ftplib.FTP_TLS$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $ftplib.FTP_TLS$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $viewer.models.ArchiveQuerySet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $viewer.management.commands.remotesite.FTPHandler$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $viewer.management.commands.remotesite.FTPHandler$ 0 0 0 $viewer.models.ArchiveQuerySet$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 $builtins.float$ 0 0 $builtins.float$ 0 $builtins.float$ 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] import time [EOL] [EOL] from django . core . management . base import BaseCommand [EOL] from django . conf import settings [EOL] [EOL] from core . providers . twitter . utilities import match_tweet_with_wanted_galleries [EOL] from core . providers . twitter import constants [EOL] from viewer . models import TweetPost [EOL] [EOL] crawler_settings = settings . CRAWLER_SETTINGS [EOL] [EOL] [EOL] class Command ( BaseCommand ) : [EOL] help = [string] [EOL] [EOL] def add_arguments ( self , parser ) : [EOL] parser . add_argument ( [string] , [string] , required = False , action = [string] , type = int , help = [string] ) [EOL] parser . add_argument ( [string] , [string] , required = False , action = [string] , default = [string] , help = [string] ) [EOL] parser . add_argument ( [string] , [string] , required = False , action = [string] , default = False , help = [string] ) [EOL] [EOL] def handle ( self , * args , ** options ) : [EOL] start = time . perf_counter ( ) [EOL] [EOL] tweets = TweetPost . objects . all ( ) [EOL] [EOL] if options [ [string] ] : [EOL] tweets = tweets . filter ( tweet_id__gte = options [ [string] ] ) [EOL] if options [ [string] ] : [EOL] tweets = tweets . filter ( tweet_id__lte = options [ [string] ] ) [EOL] [EOL] if options [ [string] ] : [EOL] own_settings = settings . providers [ constants . provider_name ] [EOL] for tweet_obj in tweets : [EOL] for message in match_tweet_with_wanted_galleries ( tweet_obj , crawler_settings , own_settings ) : [EOL] self . stdout . write ( message ) [EOL] [EOL] end = time . perf_counter ( ) [EOL] [EOL] self . stdout . write ( self . style . SUCCESS ( [string] . format ( end - start , ( end - start ) / [number] ) ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 $builtins.float$ 0 0 $builtins.float$ 0 $builtins.float$ 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] import builtins [EOL] import types [EOL] import time [EOL] from types import ModuleType [EOL] [EOL] from django . core . management . base import BaseCommand [EOL] from django . conf import settings [EOL] from viewer . models import Provider [EOL] [EOL] crawler_settings = settings . CRAWLER_SETTINGS [EOL] [EOL] [EOL] class Command ( BaseCommand ) : [EOL] help = [string] [EOL] [EOL] def add_arguments ( self , parser ) : [EOL] parser . add_argument ( [string] , [string] , required = False , action = [string] , default = False , help = ( [string] [string] ) ) [EOL] parser . add_argument ( [string] , [string] , required = False , action = [string] , nargs = [string] , type = str , help = ( [string] [string] ) ) [EOL] parser . add_argument ( [string] , [string] , required = False , action = [string] , nargs = [string] , type = str , help = [string] ) [EOL] parser . add_argument ( [string] , [string] , required = False , action = [string] , default = False , help = [string] ) [EOL] [EOL] def handle ( self , * args , ** options ) : [EOL] start = time . perf_counter ( ) [EOL] if options [ [string] ] : [EOL] for provider_name , constants in crawler_settings . provider_context . constants : [EOL] self . register_provider_from_constants ( constants , provider_name ) [EOL] if options [ [string] ] : [EOL] for provider_to_register in options [ [string] ] : [EOL] constants_list = crawler_settings . provider_context . get_constants ( provider_to_register ) [EOL] for constants in constants_list : [EOL] provider_name = getattr ( constants , [string] ) [EOL] self . register_provider_from_constants ( constants , provider_name ) [EOL] if options [ [string] ] : [EOL] providers = Provider . objects . all ( name__in = options [ [string] ] ) [EOL] self . stdout . write ( [string] . format ( providers . count ( ) ) ) [EOL] providers . delete ( ) [EOL] if options [ [string] ] : [EOL] for provider in Provider . objects . all ( ) : [EOL] self . stdout . write ( [string] . format ( provider . name , provider . slug , provider . home_page , provider . description , provider . information , ) ) [EOL] [EOL] end = time . perf_counter ( ) [EOL] [EOL] self . stdout . write ( self . style . SUCCESS ( [string] . format ( end - start , ( end - start ) / [number] ) ) ) [EOL] [EOL] def register_provider_from_constants ( self , constants , provider_name ) : [EOL] provider_instance = Provider . objects . filter ( slug = provider_name ) . first ( ) [EOL] if not provider_instance : [EOL] self . stdout . write ( [string] . format ( provider_name ) ) [EOL] Provider . objects . create ( slug = getattr ( constants , [string] ) if hasattr ( constants , [string] ) else provider_name , name = getattr ( constants , [string] ) if hasattr ( constants , [string] ) else provider_name , home_page = getattr ( constants , [string] ) if hasattr ( constants , [string] ) else [string] , description = getattr ( constants , [string] ) if hasattr ( constants , [string] ) else [string] , information = getattr ( constants , [string] ) if hasattr ( constants , [string] ) else [string] , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 $builtins.float$ 0 0 $builtins.float$ 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $types.ModuleType$ 0 $builtins.str$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $types.ModuleType$ 0 0 0 0 0 0 $types.ModuleType$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 $types.ModuleType$ 0 0 0 0 0 0 $types.ModuleType$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 $types.ModuleType$ 0 0 0 0 0 0 $types.ModuleType$ 0 0 0 0 0 0 0 0 0 0 $types.ModuleType$ 0 0 0 0 0 0 $types.ModuleType$ 0 0 0 0 0 0 0 0 0 0 $types.ModuleType$ 0 0 0 0 0 0 $types.ModuleType$ 0 0 0 0 0 0 0 0
	0
	0
provider_name = [string] [EOL] home_page = [string] [EOL] [EOL] main_page = [string] [EOL] [EOL] gallery_container_url = [string] [EOL] [EOL] rss_url = main_page [EOL]	$builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0
	0
from typing import Any , Type , Dict , Tuple , Optional [EOL] import requests [EOL] import core [EOL] import typing [EOL] import logging [EOL] import logging [EOL] import os [EOL] from typing import Optional [EOL] [EOL] import requests [EOL] [EOL] from core . base . types import DataDict [EOL] from core . base . utilities import calc_crc32 , get_base_filename_string_from_gallery_data , get_zip_fileinfo , construct_request_dict [EOL] from core . downloaders . handlers import BaseDownloader , BaseInfoDownloader [EOL] from viewer . models import Archive [EOL] from core . base . utilities import ( available_filename , replace_illegal_name ) [EOL] from . import constants [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class ArchiveDownloader ( BaseDownloader ) : [EOL] [EOL] type = [string] [EOL] provider = constants . provider_name [EOL] [EOL] def start_download ( self ) : [EOL] [EOL] if not self . gallery or not self . gallery . link or not self . gallery . archiver_key : [EOL] return [EOL] [EOL] to_use_filename = get_base_filename_string_from_gallery_data ( self . gallery ) [EOL] [EOL] to_use_filename = replace_illegal_name ( to_use_filename ) [EOL] [EOL] self . gallery . filename = available_filename ( self . settings . MEDIA_ROOT , os . path . join ( self . own_settings . archive_dl_folder , to_use_filename + [string] ) ) [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] [EOL] request_file = requests . get ( self . gallery . archiver_key , stream = [string] , ** request_dict ) [EOL] [EOL] filepath = os . path . join ( self . settings . MEDIA_ROOT , self . gallery . filename ) [EOL] with open ( filepath , [string] ) as fo : [EOL] for chunk in request_file . iter_content ( [number] ) : [EOL] fo . write ( chunk ) [EOL] [EOL] self . gallery . filesize , self . gallery . filecount = get_zip_fileinfo ( filepath ) [EOL] if self . gallery . filesize > [number] : [EOL] self . crc32 = calc_crc32 ( filepath ) [EOL] [EOL] self . fileDownloaded = [number] [EOL] self . return_code = [number] [EOL] [EOL] else : [EOL] logger . error ( [string] ) [EOL] os . remove ( filepath ) [EOL] self . return_code = [number] [EOL] [EOL] def update_archive_db ( self , default_values ) : [EOL] [EOL] if not self . gallery : [EOL] return None [EOL] [EOL] values = { [string] : self . gallery . title , [string] : [string] , [string] : self . gallery . filename , [string] : self . crc32 , [string] : self . gallery . filesize , [string] : self . gallery . filecount , } [EOL] default_values . update ( values ) [EOL] return Archive . objects . update_or_create_by_values_and_gid ( default_values , ( self . gallery . gid , self . gallery . provider ) , zipped = self . gallery . filename ) [EOL] [EOL] [EOL] class InfoDownloader ( BaseInfoDownloader ) : [EOL] [EOL] provider = constants . provider_name [EOL] [EOL] [EOL] API = ( ArchiveDownloader , InfoDownloader , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] from typing import Any , Type , Pattern , Dict , Tuple , Optional , Set , Match , List [EOL] import requests [EOL] import typing [EOL] import logging [EOL] import core [EOL] import django [EOL] import builtins [EOL] import logging [EOL] import re [EOL] import time [EOL] import typing [EOL] from collections import defaultdict [EOL] from typing import Optional , List [EOL] [EOL] import bs4 [EOL] from bs4 import BeautifulSoup [EOL] from django . db . models import QuerySet [EOL] [EOL] from core . base . parsers import BaseParser [EOL] from core . base . utilities import ( translate_tag_list , request_with_retries , construct_request_dict ) [EOL] from core . base . types import GalleryData [EOL] from . import constants [EOL] from viewer . models import Gallery [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from viewer . models import WantedGallery [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class Parser ( BaseParser ) : [EOL] name = constants . provider_name [EOL] accepted_urls = [ constants . main_page , constants . rss_url ] [EOL] [EOL] def get_values_from_gallery_link ( self , link ) : [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] [EOL] response = request_with_retries ( link , request_dict , post = False , ) [EOL] [EOL] if not response : [EOL] logger . error ( [string] . format ( link ) ) [EOL] return None [EOL] [EOL] response . encoding = [string] [EOL] [EOL] match_string = re . compile ( constants . main_page + [string] ) [EOL] [EOL] tags = [ ] [EOL] [EOL] soup = BeautifulSoup ( response . text , [string] ) [EOL] [EOL] content_container = soup . find_all ( [string] , class_ = [string] ) [ [number] ] [EOL] [EOL] if not content_container : [EOL] logger . error ( [string] ) [EOL] return None [EOL] [EOL] is_doujinshi = False [EOL] [EOL] artists_container = content_container . find_all ( [string] , href = re . compile ( [string] ) ) [EOL] [EOL] for artist in artists_container : [EOL] tags . append ( [string] . format ( artist . get_text ( ) ) ) [EOL] [EOL] language_container = content_container . find_all ( [string] , href = re . compile ( [string] ) ) [EOL] [EOL] for language in language_container : [EOL] tags . append ( [string] . format ( language . get_text ( ) ) ) [EOL] [EOL] magazine_container = content_container . find_all ( [string] , href = re . compile ( [string] ) ) [EOL] [EOL] for magazine in magazine_container : [EOL] tags . append ( [string] . format ( magazine . get_text ( ) ) ) [EOL] [EOL] parody_container = content_container . find_all ( [string] , href = re . compile ( [string] ) ) [EOL] [EOL] for parody in parody_container : [EOL] tags . append ( [string] . format ( parody . get_text ( ) ) ) [EOL] [EOL] publisher_container = content_container . find_all ( [string] , href = re . compile ( [string] ) ) [EOL] [EOL] for publisher in publisher_container : [EOL] tags . append ( [string] . format ( publisher . get_text ( ) ) ) [EOL] [EOL] tags_container = content_container . find_all ( [string] , href = re . compile ( [string] ) ) [EOL] [EOL] for tag in tags_container : [EOL] tag_cleaned = tag . get_text ( ) . replace ( [string] , [string] ) . replace ( [string] , [string] ) [EOL] tags . append ( tag_cleaned ) [EOL] [EOL] if tag_cleaned == [string] : [EOL] is_doujinshi = True [EOL] [EOL] thumbnail_url = soup . find ( [string] , property = [string] ) . get ( [string] ) [EOL] [EOL] match_result = match_string . match ( soup . find ( [string] , property = [string] ) . get ( [string] ) ) [EOL] if not match_result : [EOL] logger . error ( [string] ) [EOL] return None [EOL] [EOL] gallery_id = match_result . group ( [number] ) [EOL] [EOL] gallery = GalleryData ( gallery_id , self . name , link = link , title = content_container . find ( [string] , class_ = [string] ) . get_text ( ) , thumbnail_url = thumbnail_url , posted = None , filesize = [number] , expunged = False , tags = translate_tag_list ( tags ) , ) [EOL] [EOL] table_container = content_container . find ( [string] , class_ = [string] ) [EOL] [EOL] if table_container : [EOL] tr_container = table_container . find_all ( [string] ) [EOL] [EOL] for tr in tr_container : [EOL] [EOL] if isinstance ( tr , bs4 . element . Tag ) : [EOL] [EOL] td_container = tr . find_all ( [string] ) [EOL] [EOL] is_description = False [EOL] is_pages = False [EOL] [EOL] for td in td_container : [EOL] if is_description : [EOL] gallery . comment = td . get_text ( ) . replace ( [string] , [string] ) . replace ( [string] , [string] ) [EOL] is_description = False [EOL] if isinstance ( td , bs4 . element . Tag ) and td . get_text ( ) == [string] : [EOL] is_description = True [EOL] [EOL] if is_pages : [EOL] right_text = td . get_text ( ) . replace ( [string] , [string] ) . replace ( [string] , [string] ) [EOL] m = re . search ( [string] , right_text ) [EOL] if m : [EOL] gallery . filecount = int ( m . group ( [number] ) ) [EOL] is_pages = False [EOL] if isinstance ( td , bs4 . element . Tag ) and td . get_text ( ) == [string] : [EOL] is_pages = True [EOL] [EOL] gallery . archiver_key = [string] . format ( constants . main_page , gallery_id ) [EOL] [EOL] if is_doujinshi : [EOL] gallery . category = [string] [EOL] else : [EOL] gallery . category = [string] [EOL] [EOL] return gallery [EOL] [EOL] [comment] [EOL] [comment] [EOL] def get_values_from_gallery_link_list ( self , links ) : [EOL] response = [ ] [EOL] for i , element in enumerate ( links ) : [EOL] if i > [number] : [EOL] time . sleep ( self . own_settings . wait_timer ) [EOL] [EOL] logger . info ( [string] [string] . format ( self . name , i + [number] , len ( links ) ) ) [EOL] [EOL] values = self . fetch_gallery_data ( element ) [EOL] if values : [EOL] response . append ( values ) [EOL] else : [EOL] logger . error ( [string] . format ( element ) ) [EOL] continue [EOL] return response [EOL] [EOL] @ staticmethod def get_feed_urls ( ) : [EOL] return [ constants . rss_url , ] [EOL] [EOL] def crawl_feed ( self , feed_url = None ) : [EOL] [EOL] urls = [ ] [EOL] [EOL] if not feed_url : [EOL] feed_url = constants . rss_url [EOL] [EOL] current_page = [number] [EOL] [EOL] m = re . search ( [string] , feed_url ) [EOL] if m and m . group ( [number] ) : [EOL] current_page = int ( m . group ( [number] ) ) [EOL] feed_url = constants . rss_url [EOL] [EOL] while True : [EOL] [EOL] paged_feed_url = [string] . format ( feed_url , current_page ) [EOL] [EOL] if current_page > [number] : [EOL] time . sleep ( self . own_settings . wait_timer ) [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] [EOL] response = request_with_retries ( paged_feed_url , request_dict , post = False , ) [EOL] [EOL] if not response : [EOL] logger . error ( [string] . format ( paged_feed_url ) ) [EOL] return urls [EOL] [EOL] response . encoding = [string] [EOL] [EOL] match_string = re . compile ( [string] ) [EOL] [EOL] soup = BeautifulSoup ( response . text , [string] ) [EOL] [EOL] content_container = soup . find ( [string] , class_ = [string] ) [EOL] [EOL] if not content_container : [EOL] logger . error ( [string] ) [EOL] return urls [EOL] [EOL] url_containers = content_container . find_all ( [string] , href = match_string ) [EOL] [EOL] current_gids = [ ] [EOL] [EOL] for url_container in url_containers : [EOL] [EOL] url_link = url_container . get ( [string] ) [EOL] [EOL] complete_url = [string] . format ( constants . main_page , url_link ) [EOL] [EOL] gid = self . id_from_url ( complete_url ) [EOL] [EOL] if gid : [EOL] current_gids . append ( gid ) [EOL] [EOL] if len ( current_gids ) < [number] : [EOL] logger . info ( [string] [string] . format ( current_page ) ) [EOL] break [EOL] [EOL] used = Gallery . objects . filter ( gid__in = current_gids , provider = constants . provider_name ) [EOL] [EOL] if used . count ( ) == len ( current_gids ) : [EOL] logger . info ( [string] . format ( current_page ) ) [EOL] break [EOL] [EOL] used_gids = used . values_list ( [string] , flat = True ) [EOL] [EOL] current_urls = [ [string] . format ( constants . main_page , x ) for x in list ( set ( current_gids ) . difference ( used_gids ) ) ] [EOL] [EOL] urls . extend ( current_urls ) [EOL] [EOL] current_page += [number] [EOL] [EOL] return urls [EOL] [EOL] def fetch_gallery_data ( self , url ) : [EOL] return self . get_values_from_gallery_link ( url ) [EOL] [EOL] def fetch_multiple_gallery_data ( self , url_list ) : [EOL] return self . get_values_from_gallery_link_list ( url_list ) [EOL] [EOL] @ staticmethod def id_from_url ( url ) : [EOL] m = re . search ( constants . main_page + [string] , url ) [EOL] if m and m . group ( [number] ) : [EOL] return m . group ( [number] ) [EOL] else : [EOL] return None [EOL] [EOL] def crawl_urls ( self , urls , wanted_filters = None , wanted_only = False ) : [EOL] [EOL] unique_urls = set ( ) [EOL] gallery_data_list = [ ] [EOL] fetch_format_galleries = [ ] [EOL] gallery_wanted_lists = defaultdict ( list ) [EOL] [EOL] if not self . downloaders : [EOL] logger . warning ( [string] ) [EOL] return [EOL] [EOL] for url in urls : [EOL] [EOL] if constants . main_page not in url : [EOL] logger . warning ( [string] . format ( url ) ) [EOL] continue [EOL] [EOL] if [string] in url or [string] in url or [string] in url : [EOL] if not self . settings . silent_processing : [EOL] logger . info ( [string] . format ( url ) ) [EOL] unique_urls . add ( url ) [EOL] continue [EOL] [EOL] if constants . rss_url in url : [EOL] feed_links = self . crawl_feed ( url ) [EOL] unique_urls . update ( feed_links ) [EOL] logger . info ( [string] . format ( self . name , len ( feed_links ) ) ) [EOL] continue [EOL] [EOL] for gallery in unique_urls : [EOL] [EOL] gid = self . id_from_url ( gallery ) [EOL] if not gid : [EOL] continue [EOL] [EOL] discard_approved , discard_message = self . discard_gallery_by_internal_checks ( gid , link = gallery ) [EOL] [EOL] if discard_approved : [EOL] if not self . settings . silent_processing : [EOL] logger . info ( discard_message ) [EOL] continue [EOL] [EOL] fetch_format_galleries . append ( gallery ) [EOL] [EOL] galleries_data = self . fetch_multiple_gallery_data ( fetch_format_galleries ) [EOL] [EOL] for internal_gallery_data in galleries_data : [EOL] [EOL] if not internal_gallery_data . link : [EOL] continue [EOL] [EOL] if self . general_utils . discard_by_tag_list ( internal_gallery_data . tags ) : [EOL] if not self . settings . silent_processing : [EOL] logger . info ( [string] . format ( internal_gallery_data . link ) ) [EOL] continue [EOL] [EOL] if wanted_filters : [EOL] self . compare_gallery_with_wanted_filters ( internal_gallery_data , internal_gallery_data . link , wanted_filters , gallery_wanted_lists ) [EOL] if wanted_only and not gallery_wanted_lists [ internal_gallery_data . gid ] : [EOL] continue [EOL] [EOL] gallery_data_list . append ( internal_gallery_data ) [EOL] [EOL] self . pass_gallery_data_to_downloaders ( gallery_data_list , gallery_wanted_lists ) [EOL] [EOL] [EOL] API = ( Parser , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Pattern[builtins.str]$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Pattern[builtins.str]$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 $typing.Optional[builtins.str]$ 0 0 $typing.List[builtins.str]$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 $builtins.str$ 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $typing.List[builtins.str]$ 0 $django.db.models.QuerySet$ 0 0 0 $builtins.bool$ 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.db.models.QuerySet$ 0 0 0 0 0 0 0 0 0 0 0 0 $django.db.models.QuerySet$ 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 $builtins.bool$ 0 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 0 0 0 0 0 0 0 0
import builtins [EOL] import re [EOL] import typing [EOL] [EOL] from . import constants [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from viewer . models import Gallery [EOL] [EOL] [EOL] def resolve_url ( gallery ) : [EOL] return [string] . format ( constants . main_page , gallery . gid ) [EOL] [EOL] [EOL] def clean_title ( title ) : [EOL] [comment] [EOL] title = re . sub ( [string] , [string] , title ) [EOL] [comment] [EOL] title = [string] . join ( str ( re . sub ( [string] , [string] , word ) for word in title . split ( ) ) ) [EOL] [comment] [EOL] title = re . sub ( [string] , [string] , title ) [EOL] [comment] [EOL] title = re . sub ( [string] , [string] , title ) [EOL] [comment] [EOL] title = re . sub ( [string] , [string] , title ) [EOL] [comment] [EOL] title = [string] . join ( word for word in title . split ( ) if len ( word ) > [number] ) [EOL] return title [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Type , Dict , Tuple , Optional , Iterator , Set , Match , List [EOL] import requests [EOL] import typing [EOL] import core [EOL] import builtins [EOL] import zipfile [EOL] import os [EOL] import re [EOL] import zipfile [EOL] from typing import Optional , List [EOL] [EOL] import requests [EOL] import time [EOL] [EOL] from core . base . matchers import Matcher [EOL] from core . base . types import MatchesValues , DataDict [EOL] from core . base . utilities import ( filecount_in_zip , get_zip_filesize , discard_zipfile_contents , zfill_to_three , sha1_from_file_object , clean_title , construct_request_dict ) [EOL] from core . providers . panda . utilities import link_from_gid_token_fjord , get_gid_token_from_link , SearchHTMLParser , GalleryHTMLParser [EOL] from . import constants [EOL] [EOL] [EOL] class ImageMatcher ( Matcher ) : [EOL] [EOL] name = [string] [EOL] provider = constants . provider_name [EOL] type = [string] [EOL] time_to_wait_after_compare = [number] [EOL] default_cutoff = [number] [EOL] [EOL] def format_to_search_title ( self , file_name ) : [EOL] return os . path . join ( self . settings . MEDIA_ROOT , file_name ) [EOL] [EOL] def format_to_compare_title ( self , file_name ) : [EOL] return self . get_title_from_path ( file_name ) [EOL] [EOL] def search_method ( self , title_to_search ) : [EOL] return self . compare_by_image ( title_to_search , False ) [EOL] [EOL] def create_closer_matches_values ( self , zip_path , cutoff = None , max_matches = [number] ) : [EOL] [EOL] self . values_array = [ ] [EOL] results = [ ] [EOL] [EOL] if self . search_method ( self . format_to_search_title ( zip_path ) ) : [EOL] if self . time_to_wait_after_compare > [number] : [EOL] time . sleep ( self . time_to_wait_after_compare ) [EOL] galleries_data = self . get_metadata_after_matching ( ) [EOL] if galleries_data : [EOL] galleries_data = [ x for x in galleries_data if not self . general_utils . discard_by_tag_list ( x . tags ) ] [EOL] [comment] [EOL] [comment] [EOL] if galleries_data : [EOL] self . values_array = galleries_data [EOL] results = [ ( gallery . title or gallery . title_jpn or [string] , gallery , [number] ) for gallery in galleries_data ] [EOL] return results [EOL] [EOL] def format_match_values ( self ) : [EOL] [EOL] if not self . match_values : [EOL] return None [EOL] [EOL] self . match_gid = self . match_values . gid [EOL] values = { [string] : self . match_title , [string] : self . match_values . title_jpn , [string] : self . file_path , [string] : self . crc32 , [string] : self . found_by , [string] : get_zip_filesize ( os . path . join ( self . settings . MEDIA_ROOT , self . file_path ) ) , [string] : filecount_in_zip ( os . path . join ( self . settings . MEDIA_ROOT , self . file_path ) ) , [string] : self . provider } [EOL] return values [EOL] [EOL] def compare_by_image ( self , zip_path , only_cover ) : [EOL] [EOL] if os . path . splitext ( zip_path ) [ [number] ] != [string] : [EOL] self . gallery_links = [ ] [EOL] return False [EOL] [EOL] try : [EOL] my_zip = zipfile . ZipFile ( zip_path , [string] ) [EOL] except ( zipfile . BadZipFile , NotImplementedError ) : [EOL] self . gallery_links = [ ] [EOL] return False [EOL] [EOL] filtered_files = list ( filter ( discard_zipfile_contents , sorted ( my_zip . namelist ( ) , key = zfill_to_three ) ) ) [EOL] [EOL] if not filtered_files : [EOL] self . gallery_links = [ ] [EOL] return False [EOL] [EOL] first_file = filtered_files [ [number] ] [EOL] [EOL] payload = { [string] : sha1_from_file_object ( my_zip . open ( first_file ) ) , [string] : os . path . basename ( first_file ) , [string] : [number] if only_cover else [number] , [string] : [number] } [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] request_dict [ [string] ] = payload [EOL] [EOL] r = requests . get ( constants . ex_page , ** request_dict ) [EOL] [EOL] my_zip . close ( ) [EOL] [EOL] parser = SearchHTMLParser ( ) [EOL] parser . feed ( r . text ) [EOL] [EOL] self . gallery_links = list ( parser . galleries ) [EOL] [EOL] if len ( self . gallery_links ) > [number] : [EOL] self . found_by = self . name [EOL] return True [EOL] else : [EOL] return False [EOL] [EOL] [EOL] class CoverMatcher ( ImageMatcher ) : [EOL] [EOL] name = [string] [EOL] [EOL] def search_method ( self , title_to_search ) : [EOL] return self . compare_by_image ( title_to_search , True ) [EOL] [EOL] [EOL] class TitleMatcher ( Matcher ) : [EOL] [EOL] name = [string] [EOL] provider = constants . provider_name [EOL] type = [string] [EOL] time_to_wait_after_compare = [number] [EOL] default_cutoff = [number] [EOL] [EOL] def format_to_search_title ( self , file_name ) : [EOL] if file_name . endswith ( [string] ) : [EOL] return clean_title ( self . get_title_from_path ( file_name ) ) [EOL] else : [EOL] return clean_title ( file_name ) [EOL] [EOL] def format_to_compare_title ( self , file_name ) : [EOL] if file_name . endswith ( [string] ) : [EOL] return clean_title ( self . get_title_from_path ( file_name ) ) [EOL] else : [EOL] return clean_title ( file_name ) [EOL] [EOL] def search_method ( self , title_to_search ) : [EOL] return self . compare_by_title ( title_to_search ) [EOL] [EOL] def format_match_values ( self ) : [EOL] [EOL] if not self . match_values : [EOL] return None [EOL] [EOL] self . match_gid = self . match_values . gid [EOL] values = { [string] : self . match_title , [string] : self . match_values . title_jpn , [string] : self . file_path , [string] : self . crc32 , [string] : self . found_by , [string] : get_zip_filesize ( os . path . join ( self . settings . MEDIA_ROOT , self . file_path ) ) , [string] : filecount_in_zip ( os . path . join ( self . settings . MEDIA_ROOT , self . file_path ) ) , [string] : self . provider } [EOL] return values [EOL] [EOL] def compare_by_title ( self , image_title ) : [EOL] [EOL] filters = { [string] : [string] + image_title + [string] } [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] request_dict [ [string] ] = filters [EOL] [EOL] r = requests . get ( constants . ex_page , ** request_dict ) [EOL] [EOL] parser = SearchHTMLParser ( ) [EOL] parser . feed ( r . text ) [EOL] [EOL] self . gallery_links = list ( parser . galleries ) [EOL] [EOL] if len ( self . gallery_links ) > [number] : [EOL] self . found_by = self . name [EOL] return True [EOL] else : [EOL] return False [EOL] [EOL] [EOL] class TitleGoogleMatcher ( TitleMatcher ) : [EOL] name = [string] [EOL] [EOL] def search_method ( self , title_to_search ) : [EOL] return self . compare_by_title_google ( title_to_search ) [EOL] [EOL] def compare_by_title_google ( self , title ) : [EOL] [EOL] payload = { [string] : [string] + title } [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] request_dict [ [string] ] = payload [EOL] [EOL] r = requests . get ( [string] , ** request_dict ) [EOL] [EOL] matches_links = set ( ) [EOL] [EOL] m = re . finditer ( [string] , r . text ) [EOL] [EOL] if m : [EOL] for match in m : [EOL] matches_links . add ( self . get_final_link_from_link ( link_from_gid_token_fjord ( match . group ( [number] ) , match . group ( [number] ) , False ) ) ) [EOL] [EOL] m2 = re . finditer ( [string] , r . text ) [EOL] [EOL] if m2 : [EOL] for match in m2 : [EOL] matches_links . add ( self . get_final_link_from_link ( link_from_gid_token_fjord ( match . group ( [number] ) , match . group ( [number] ) , False ) ) ) [EOL] [EOL] self . gallery_links = list ( matches_links ) [EOL] if len ( self . gallery_links ) > [number] : [EOL] self . found_by = self . name [EOL] return True [EOL] [EOL] else : [EOL] return False [EOL] [EOL] def get_final_link_from_link ( self , link ) : [EOL] [EOL] time . sleep ( self . own_settings . wait_timer ) [EOL] gallery_gid , gallery_token = get_gid_token_from_link ( link ) [EOL] gallery_link = link_from_gid_token_fjord ( gallery_gid , gallery_token , True ) [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] [EOL] gallery_page_text = requests . get ( gallery_link , ** request_dict ) . text [EOL] [EOL] if [string] in gallery_page_text : [EOL] return gallery_link [EOL] else : [EOL] gallery_parser = GalleryHTMLParser ( ) [EOL] gallery_parser . feed ( gallery_page_text ) [EOL] if gallery_parser . found_non_final_gallery == [number] and gallery_parser . non_final_gallery : [EOL] return self . get_final_link_from_link ( gallery_parser . non_final_gallery ) [EOL] return gallery_link [EOL] [EOL] [EOL] API = ( CoverMatcher , ImageMatcher , TitleMatcher , TitleGoogleMatcher , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[core.base.types.DataDict]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 $builtins.str$ 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 $requests.models.Response$ 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 $core.providers.panda.utilities.SearchHTMLParser$ 0 0 0 0 0 $core.providers.panda.utilities.SearchHTMLParser$ 0 0 0 $requests.models.Response$ 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 $core.providers.panda.utilities.SearchHTMLParser$ 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.bool$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.bool$ 0 0 0 $builtins.str$ 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 $requests.models.Response$ 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 $typing.Iterator[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 $requests.models.Response$ 0 0 0 0 0 0 $typing.Iterator[typing.Match[builtins.str]]$ 0 0 0 0 0 $typing.Iterator[typing.Match[builtins.str]]$ 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterator[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 $requests.models.Response$ 0 0 0 0 0 0 $typing.Iterator[typing.Match[builtins.str]]$ 0 0 0 0 0 $typing.Iterator[typing.Match[builtins.str]]$ 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $core.providers.panda.utilities.GalleryHTMLParser$ 0 0 0 0 0 $core.providers.panda.utilities.GalleryHTMLParser$ 0 0 0 $builtins.str$ 0 0 0 $core.providers.panda.utilities.GalleryHTMLParser$ 0 0 0 0 0 $core.providers.panda.utilities.GalleryHTMLParser$ 0 0 0 0 0 0 0 0 0 $core.providers.panda.utilities.GalleryHTMLParser$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Type , Iterable , Dict , Tuple , Optional , Set , Match , List [EOL] import core [EOL] import typing [EOL] import builtins [EOL] import typing [EOL] from datetime import datetime , timezone [EOL] [EOL] import re [EOL] from html . parser import HTMLParser [EOL] [EOL] from bs4 import BeautifulSoup [EOL] [EOL] from core . base . types import DataDict , GalleryData [EOL] from core . base . utilities import unescape , translate_tag_list [EOL] from . import constants [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from viewer . models import Gallery [EOL] [EOL] [EOL] def map_external_gallery_data_to_internal ( gallery_data ) : [EOL] internal_gallery_data = GalleryData ( gallery_data [ [string] ] , constants . provider_name , token = gallery_data [ [string] ] , archiver_key = gallery_data [ [string] ] , title = unescape ( gallery_data [ [string] ] ) , title_jpn = unescape ( gallery_data [ [string] ] ) , thumbnail_url = gallery_data [ [string] ] , category = gallery_data [ [string] ] , uploader = unescape ( gallery_data [ [string] ] ) , posted = datetime . fromtimestamp ( int ( gallery_data [ [string] ] ) , timezone . utc ) , filecount = gallery_data [ [string] ] , filesize = gallery_data [ [string] ] , expunged = gallery_data [ [string] ] , rating = gallery_data [ [string] ] , tags = translate_tag_list ( gallery_data [ [string] ] ) , ) [EOL] [EOL] internal_gallery_data . extra_data [ [string] ] = gallery_data [ [string] ] [EOL] internal_gallery_data . extra_data [ [string] ] = gallery_data [ [string] ] [EOL] [EOL] internal_gallery_data . root = constants . ge_page [EOL] [EOL] m = re . search ( constants . default_fjord_tags , [string] . join ( internal_gallery_data . tags ) ) [EOL] if m : [EOL] internal_gallery_data . fjord = True [EOL] if internal_gallery_data . thumbnail_url and constants . ex_thumb_url in internal_gallery_data . thumbnail_url : [EOL] internal_gallery_data . thumbnail_url = internal_gallery_data . thumbnail_url . replace ( constants . ex_thumb_url , constants . ge_thumb_url ) [EOL] return internal_gallery_data [EOL] [EOL] [EOL] def link_from_gid_token_fjord ( gid , token , fjord = False ) : [EOL] return [string] . format ( constants . ge_page , gid , token ) [EOL] [EOL] [EOL] def get_gid_token_from_link ( link ) : [EOL] m = re . search ( [string] , link ) [EOL] [EOL] if m : [EOL] return m . group ( [number] ) , m . group ( [number] ) [EOL] else : [EOL] return [string] , [string] [EOL] [EOL] [EOL] def fjord_gid_token_from_link ( link ) : [EOL] m = re . search ( [string] , link ) [EOL] if m : [EOL] return m . group ( [number] ) , m . group ( [number] ) , m . group ( [number] ) [EOL] else : [EOL] return None , None , None [EOL] [EOL] [EOL] def resolve_url ( gallery ) : [EOL] return [string] . format ( constants . ge_page , gallery . gid , gallery . token ) [EOL] [EOL] [EOL] def request_data_from_gid_token_iterable ( api_token_iterable ) : [EOL] return { [string] : [string] , [string] : [string] , [string] : api_token_iterable } [EOL] [EOL] [EOL] AttrList = typing . List [ typing . Tuple [ str , typing . Optional [ str ] ] ] [EOL] [EOL] [EOL] [comment] [EOL] class SearchHTMLParser ( HTMLParser ) : [EOL] [EOL] def __init__ ( self ) : [EOL] HTMLParser . __init__ ( self ) [EOL] self . galleries = set ( ) [EOL] self . stop_at_favorites = [number] [EOL] [EOL] def error ( self , message ) : [EOL] pass [EOL] [EOL] def handle_starttag ( self , tag , attrs ) : [EOL] if tag == [string] and self . stop_at_favorites != [number] : [EOL] for attr in attrs : [EOL] if ( attr [ [number] ] == [string] [EOL] and ( constants . ex_page + [string] in str ( attr [ [number] ] ) or constants . ge_page + [string] in str ( attr [ [number] ] ) ) ) : [EOL] self . galleries . add ( str ( attr [ [number] ] ) ) [EOL] else : [EOL] self . stop_at_favorites = [number] [EOL] [EOL] def handle_data ( self , data ) : [EOL] if data == [string] : [EOL] self . stop_at_favorites = [number] [EOL] [EOL] [EOL] class GalleryHTMLParser ( HTMLParser ) : [EOL] [EOL] def __init__ ( self ) : [EOL] HTMLParser . __init__ ( self , convert_charrefs = True ) [EOL] self . torrent_link = [string] [EOL] self . stop_at_found = [number] [EOL] self . found_non_final_gallery = [number] [EOL] self . parent_gallery = [string] [EOL] self . found_parent_gallery = [number] [EOL] self . found_gallery_link = [number] [EOL] self . non_final_gallery = [string] [EOL] [EOL] def error ( self , message ) : [EOL] pass [EOL] [EOL] def handle_starttag ( self , tag , attrs ) : [EOL] if tag == [string] and self . stop_at_found != [number] : [EOL] self . found_gallery_link = [number] [EOL] for attr in attrs : [EOL] if attr [ [number] ] == [string] and str ( attr [ [number] ] ) == [string] : [EOL] self . found_gallery_link = [number] [EOL] elif ( self . found_non_final_gallery == [number] [EOL] and attr [ [number] ] == [string] [EOL] and [string] in str ( attr [ [number] ] ) ) : [EOL] self . non_final_gallery = str ( attr [ [number] ] ) [EOL] elif ( self . found_parent_gallery == [number] [EOL] and attr [ [number] ] == [string] [EOL] and [string] in str ( attr [ [number] ] ) ) : [EOL] self . parent_gallery = str ( attr [ [number] ] ) [EOL] self . found_parent_gallery = [number] [EOL] elif ( self . found_gallery_link == [number] [EOL] and attr [ [number] ] == [string] [EOL] and [string] in str ( attr [ [number] ] ) ) : [EOL] m = re . search ( [string] , str ( attr [ [number] ] ) ) [EOL] if m and m . group ( [number] ) : [EOL] self . torrent_link = m . group ( [number] ) [EOL] if ( tag == [string] [EOL] and attrs [ [number] ] [ [number] ] == [string] [EOL] and attrs [ [number] ] [ [number] ] == [string] ) : [EOL] self . stop_at_found = [number] [EOL] return [EOL] if tag == [string] and self . found_non_final_gallery == [number] : [EOL] for attr in attrs : [EOL] if attr [ [number] ] == [string] and attr [ [number] ] == [string] : [EOL] self . found_non_final_gallery = [number] [EOL] [EOL] def handle_data ( self , data ) : [EOL] if [string] in data : [EOL] self . found_non_final_gallery = [number] [EOL] elif [string] == data : [EOL] self . found_parent_gallery = [number] [EOL] [EOL] [EOL] class TorrentHTMLParser ( HTMLParser ) : [EOL] [EOL] def __init__ ( self ) : [EOL] HTMLParser . __init__ ( self , convert_charrefs = True ) [EOL] self . torrent = [string] [EOL] self . found_seed_data = [number] [EOL] self . found_posted_data = [number] [EOL] self . posted_date = [string] [EOL] self . seeds = [number] [EOL] [EOL] def error ( self , message ) : [EOL] pass [EOL] [EOL] torrent_root_url = [string] [EOL] [EOL] def handle_starttag ( self , tag , attrs ) : [EOL] if tag == [string] : [EOL] for attr in attrs : [EOL] if ( attr [ [number] ] == [string] [EOL] and self . torrent_root_url in str ( attr [ [number] ] ) [EOL] and self . seeds > [number] ) : [EOL] self . torrent = str ( attr [ [number] ] ) [EOL] [EOL] def handle_data ( self , data ) : [EOL] if [string] == data : [EOL] self . found_seed_data = [number] [EOL] elif [string] == data : [EOL] self . found_seed_data = [number] [EOL] elif self . found_seed_data == [number] : [EOL] m = re . search ( [string] , data ) [EOL] if m : [EOL] self . seeds = int ( m . group ( [number] ) ) [EOL] [EOL] if [string] == data : [EOL] self . found_posted_data = [number] [EOL] elif [string] == data : [EOL] self . found_posted_data = [number] [EOL] elif self . found_posted_data == [number] : [EOL] m = re . search ( [string] , data ) [EOL] if m : [EOL] self . posted_date = m . group ( [number] ) + [string] [EOL] [EOL] [EOL] ARCHIVE_ROOT_URL = [string] [EOL] [EOL] [EOL] def contains_archive_root ( href ) : [EOL] return ARCHIVE_ROOT_URL in href [EOL] [EOL] [EOL] def get_archive_link_from_html_page ( page_text ) : [EOL] soup = BeautifulSoup ( page_text , [string] ) [EOL] archive_link = soup . find ( [string] , href = contains_archive_root ) [EOL] [EOL] if not archive_link : [EOL] return [string] [EOL] [EOL] return str ( archive_link . get ( [string] ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing.Optional[builtins.str],typing.Optional[builtins.str],typing.Optional[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Set[builtins.str]$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 $AttrList$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 $AttrList$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 $AttrList$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $AttrList$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $AttrList$ 0 0 0 0 0 0 0 0 0 0 $AttrList$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 $AttrList$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 $AttrList$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $AttrList$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 $builtins.int$ 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 $builtins.str$ 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] from typing import Any , Type , Iterable , Dict , Tuple , Optional , Set , Union , Match , List [EOL] import requests [EOL] import typing [EOL] import logging [EOL] import urllib [EOL] import core [EOL] import django [EOL] import builtins [EOL] import json [EOL] import logging [EOL] import re [EOL] import time [EOL] import typing [EOL] import urllib . parse [EOL] from collections import defaultdict [EOL] from typing import Optional , Iterable , List , Dict , Set [EOL] [EOL] import feedparser [EOL] import requests [EOL] from django . db . models import QuerySet [EOL] [EOL] from core . base . parsers import BaseParser [EOL] from core . base . utilities import ( chunks , request_with_retries , construct_request_dict ) [EOL] from core . base . types import GalleryData , DataDict [EOL] from viewer . models import Gallery [EOL] from . utilities import link_from_gid_token_fjord , map_external_gallery_data_to_internal , get_gid_token_from_link , fjord_gid_token_from_link , SearchHTMLParser [EOL] from . import constants [EOL] from . import utilities [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from viewer . models import WantedGallery [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class Parser ( BaseParser ) : [EOL] name = constants . provider_name [EOL] accepted_urls = [ constants . ex_page_short , constants . ge_page_short , constants . rss_url ] [EOL] [EOL] [comment] [EOL] def get_galleries_from_page_links ( self , page_links , page_links_results ) : [EOL] [EOL] api_page_links = [ ] [EOL] [EOL] for page_link in page_links : [EOL] [EOL] m = re . search ( [string] , page_link ) [EOL] if not m : [EOL] continue [EOL] api_page_links . append ( { [string] : [ m . group ( [number] ) , m . group ( [number] ) , m . group ( [number] ) ] } ) [EOL] [EOL] api_page_links_chunks = list ( chunks ( api_page_links , [number] ) ) [EOL] [EOL] for i , group in enumerate ( api_page_links_chunks ) : [EOL] [EOL] if i % [number] == [number] : [EOL] time . sleep ( self . own_settings . wait_timer ) [EOL] [EOL] data = { [string] : [string] , [string] : [ x [ [string] ] for x in group ] } [EOL] [EOL] headers = { [string] : [string] } [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] request_dict [ [string] ] = { ** headers , ** self . settings . requests_headers } [EOL] request_dict [ [string] ] = json . dumps ( data ) [EOL] [EOL] response = request_with_retries ( constants . ge_api_url , request_dict , post = True , ) [EOL] [EOL] if not response : [EOL] continue [EOL] try : [EOL] response_data = response . json ( ) [EOL] except ( ValueError , KeyError ) : [EOL] logger . error ( [string] . format ( response . text ) ) [EOL] continue [EOL] [EOL] for gid_token_pair in response_data [ [string] ] : [EOL] [EOL] discard_approved , discard_message = self . discard_gallery_by_internal_checks ( gallery_id = gid_token_pair [ [string] ] , link = link_from_gid_token_fjord ( gid_token_pair [ [string] ] , gid_token_pair [ [string] ] , False ) ) [EOL] [EOL] if discard_approved : [EOL] if not self . settings . silent_processing : [EOL] logger . info ( discard_message ) [EOL] continue [EOL] [EOL] page_links_results . append ( { [string] : ( gid_token_pair [ [string] ] , gid_token_pair [ [string] ] ) , [string] : link_from_gid_token_fjord ( gid_token_pair [ [string] ] , gid_token_pair [ [string] ] , False ) } ) [EOL] [EOL] def get_galleries_from_main_page_link ( self , url ) : [EOL] [EOL] unique_urls = set ( ) [EOL] [EOL] while True : [EOL] [EOL] parsed = urllib . parse . urlparse ( url ) [EOL] query = urllib . parse . parse_qs ( parsed . query ) [EOL] if [string] in query : [EOL] current_page = int ( query [ [string] ] [ [number] ] ) [EOL] else : [EOL] params = { [string] : [ [string] ] } [EOL] query . update ( params ) [EOL] new_query = urllib . parse . urlencode ( query , doseq = True ) [EOL] url = urllib . parse . urlunparse ( list ( parsed [ [number] : [number] ] ) + [ new_query ] + list ( parsed [ [number] : ] ) ) [EOL] current_page = [number] [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] [EOL] main_page_text = requests . get ( url , ** request_dict ) . text [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] [EOL] response = request_with_retries ( url , request_dict , post = False , ) [EOL] [EOL] if not response : [EOL] logger . info ( [string] ) [EOL] break [EOL] [EOL] response . encoding = [string] [EOL] [EOL] if [string] in response . text : [EOL] logger . info ( [string] ) [EOL] break [EOL] else : [EOL] logger . info ( [string] [string] . format ( current_page , url ) ) [EOL] main_page_parser = SearchHTMLParser ( ) [EOL] main_page_parser . feed ( main_page_text ) [EOL] logger . info ( [string] . format ( len ( main_page_parser . galleries ) ) ) [EOL] if len ( main_page_parser . galleries ) >= [number] : [EOL] for gallery_url in main_page_parser . galleries : [EOL] unique_urls . add ( gallery_url ) [EOL] else : [EOL] logger . info ( [string] ) [EOL] break [EOL] if [number] < self . own_settings . stop_page_number <= current_page : [EOL] logger . info ( [string] [string] . format ( self . own_settings . stop_page_number ) ) [EOL] break [EOL] current_page += [number] [EOL] params = { [string] : [ str ( current_page ) ] } [EOL] query . update ( params ) [EOL] new_query = urllib . parse . urlencode ( query , doseq = True ) [EOL] url = urllib . parse . urlunparse ( list ( parsed [ [number] : [number] ] ) + [ new_query ] + list ( parsed [ [number] : ] ) ) [EOL] time . sleep ( self . own_settings . wait_timer ) [EOL] [EOL] return unique_urls [EOL] [EOL] def get_values_from_gallery_link_list ( self , url_list ) : [EOL] [EOL] gid_token_chunks = list ( chunks ( [ get_gid_token_from_link ( link ) for link in url_list ] , [number] ) ) [EOL] [EOL] galleries_data = [ ] [EOL] [EOL] for i , group in enumerate ( gid_token_chunks ) : [EOL] [EOL] if i % [number] == [number] : [EOL] time . sleep ( self . own_settings . wait_timer ) [EOL] if not self . settings . silent_processing : [EOL] logger . info ( [string] [string] . format ( self . name , i + [number] , len ( group ) , len ( gid_token_chunks ) ) ) [EOL] [EOL] data = utilities . request_data_from_gid_token_iterable ( group ) [EOL] [EOL] headers = { [string] : [string] } [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] request_dict [ [string] ] = { ** headers , ** self . settings . requests_headers } [EOL] request_dict [ [string] ] = json . dumps ( data ) [EOL] [EOL] response = request_with_retries ( constants . ge_api_url , request_dict , post = True , ) [EOL] [EOL] if not response : [EOL] continue [EOL] [EOL] try : [EOL] response_data = response . json ( ) [EOL] except ( ValueError , KeyError ) : [EOL] logger . error ( [string] . format ( response . text ) ) [EOL] continue [EOL] [EOL] for gallery_data in response_data [ [string] ] : [EOL] if [string] in gallery_data : [EOL] logger . error ( [string] [string] . format ( gallery_data [ [string] ] , gallery_data [ [string] ] ) ) [EOL] continue [EOL] internal_gallery_data = map_external_gallery_data_to_internal ( gallery_data ) [EOL] m = re . search ( constants . default_fjord_tags , [string] . join ( internal_gallery_data . tags ) ) [EOL] if m : [EOL] internal_gallery_data . fjord = True [EOL] else : [EOL] internal_gallery_data . fjord = False [EOL] galleries_data . append ( internal_gallery_data ) [EOL] [EOL] return galleries_data [EOL] [EOL] def get_values_from_gallery_link ( self , link ) : [EOL] [EOL] fjord , gid , token = fjord_gid_token_from_link ( link ) [EOL] [EOL] if fjord is None or gid is None or token is None : [EOL] return None [EOL] [EOL] data = utilities . request_data_from_gid_token_iterable ( [ ( gid , token ) ] ) [EOL] [EOL] headers = { [string] : [string] } [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] request_dict [ [string] ] = { ** headers , ** self . settings . requests_headers } [EOL] request_dict [ [string] ] = json . dumps ( data ) [EOL] [EOL] response = request_with_retries ( constants . ge_api_url , request_dict , post = True , ) [EOL] [EOL] if not response : [EOL] return None [EOL] try : [EOL] response_data = response . json ( ) [EOL] except ( ValueError , KeyError ) : [EOL] logger . error ( [string] . format ( response . text ) ) [EOL] return None [EOL] for gallery_data in response_data [ [string] ] : [EOL] if [string] in gallery_data : [EOL] logger . error ( [string] [string] . format ( gallery_data [ [string] ] , gallery_data [ [string] ] ) ) [EOL] return None [EOL] internal_gallery_data = map_external_gallery_data_to_internal ( gallery_data ) [EOL] return internal_gallery_data [EOL] return None [EOL] [EOL] @ staticmethod def get_feed_urls ( ) : [EOL] return [ constants . rss_url , ] [EOL] [EOL] def crawl_feed ( self , feed_url = None ) : [EOL] [EOL] urls = [ ] [EOL] [EOL] if not feed_url : [EOL] feed_url = constants . rss_url [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] [EOL] response = request_with_retries ( feed_url , request_dict , post = False , ) [EOL] [EOL] if not response : [EOL] logger . error ( [string] . format ( feed_url ) ) [EOL] return urls [EOL] [EOL] response . encoding = [string] [EOL] [EOL] feed = feedparser . parse ( response . text ) [EOL] [EOL] for item in feed [ [string] ] : [EOL] if any ( [ item [ [string] ] . startswith ( category ) for category in self . own_settings . accepted_rss_categories ] ) : [EOL] urls . append ( item [ [string] ] ) [EOL] return urls [EOL] [EOL] def fetch_gallery_data ( self , url ) : [EOL] return self . get_values_from_gallery_link ( url ) [EOL] [EOL] def fetch_multiple_gallery_data ( self , url_list ) : [EOL] return self . get_values_from_gallery_link_list ( url_list ) [EOL] [EOL] @ staticmethod def id_from_url ( url ) : [EOL] m = re . search ( [string] , url ) [EOL] if m and m . group ( [number] ) : [EOL] return m . group ( [number] ) [EOL] else : [EOL] return None [EOL] [EOL] def crawl_urls ( self , urls , wanted_filters = None , wanted_only = False ) : [EOL] [EOL] unique_urls = set ( ) [EOL] gallery_data_list = [ ] [EOL] fetch_format_galleries = [ ] [EOL] unique_page_urls = set ( ) [EOL] gallery_wanted_lists = defaultdict ( list ) [EOL] [EOL] if not self . downloaders : [EOL] logger . warning ( [string] ) [EOL] return [EOL] [EOL] for url in urls : [EOL] [EOL] if constants . rss_url in url : [EOL] feed_links = self . crawl_feed ( url ) [EOL] unique_urls . update ( feed_links ) [EOL] logger . info ( [string] . format ( self . name , len ( feed_links ) ) ) [EOL] continue [EOL] [EOL] if ( constants . ex_page_short not in url [EOL] and constants . ge_page_short not in url ) : [EOL] logger . warning ( [string] . format ( url ) ) [EOL] continue [EOL] [EOL] if [string] in url : [EOL] if not self . settings . silent_processing : [EOL] logger . info ( [string] . format ( url ) ) [EOL] unique_urls . add ( url ) [EOL] continue [EOL] [EOL] if [string] in url : [EOL] if not self . settings . silent_processing : [EOL] logger . info ( [string] . format ( url ) ) [EOL] unique_page_urls . add ( url ) [EOL] continue [EOL] [EOL] [comment] [EOL] if len ( self . downloaders ) == [number] and self . downloaders [ [number] ] [ [number] ] . type == [string] : [EOL] continue [EOL] [EOL] [comment] [EOL] unique_urls . update ( self . get_galleries_from_main_page_link ( url ) ) [EOL] [EOL] gallery_ids = [ ] [EOL] found_galleries = set ( ) [EOL] total_galleries_filtered = [ ] [EOL] for gallery_url in unique_urls : [EOL] [EOL] m = re . search ( [string] , gallery_url ) [EOL] if m : [EOL] gallery_ids . append ( m . group ( [number] ) ) [EOL] total_galleries_filtered . append ( ( gallery_url , m . group ( [number] ) , m . group ( [number] ) , m . group ( [number] ) ) ) [EOL] [EOL] for galleries_gid_group in list ( chunks ( gallery_ids , [number] ) ) : [EOL] for found_gallery in Gallery . objects . filter ( gid__in = galleries_gid_group ) : [EOL] discard_approved , discard_message = self . discard_gallery_by_internal_checks ( gallery = found_gallery , link = found_gallery . get_link ( ) ) [EOL] [EOL] if discard_approved : [EOL] if not self . settings . silent_processing : [EOL] logger . info ( discard_message ) [EOL] found_galleries . add ( found_gallery . gid ) [EOL] [EOL] for gallery_tuple in total_galleries_filtered : [EOL] [EOL] if gallery_tuple [ [number] ] not in found_galleries : [EOL] fetch_format_galleries . append ( { [string] : ( gallery_tuple [ [number] ] , gallery_tuple [ [number] ] ) , [string] : gallery_tuple [ [number] ] , [string] : gallery_tuple [ [number] ] } ) [EOL] if not self . settings . silent_processing : [EOL] logger . info ( [string] [string] . format ( gallery_tuple [ [number] ] , len ( fetch_format_galleries ) ) ) [EOL] [EOL] if len ( unique_page_urls ) > [number] : [EOL] logger . info ( [string] ) [EOL] page_links_results = [ ] [EOL] self . get_galleries_from_page_links ( unique_page_urls , page_links_results ) [EOL] fetch_format_galleries += page_links_results [EOL] [EOL] if len ( fetch_format_galleries ) == [number] : [EOL] logger . info ( [string] ) [EOL] return [EOL] [EOL] fetch_format_galleries_chunks = list ( chunks ( fetch_format_galleries , [number] ) ) [EOL] for i , group in enumerate ( fetch_format_galleries_chunks ) : [EOL] [comment] [EOL] if i % [number] == [number] : [EOL] time . sleep ( self . own_settings . wait_timer ) [EOL] if not self . settings . silent_processing : [EOL] logger . info ( [string] [string] . format ( self . name , i + [number] , len ( group ) , len ( fetch_format_galleries_chunks ) ) ) [EOL] [EOL] data = utilities . request_data_from_gid_token_iterable ( [ x [ [string] ] for x in group ] ) [EOL] [EOL] headers = { [string] : [string] } [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] request_dict [ [string] ] = { ** headers , ** self . settings . requests_headers } [EOL] request_dict [ [string] ] = json . dumps ( data ) [EOL] [EOL] response = request_with_retries ( constants . ge_api_url , request_dict , post = True , ) [EOL] [EOL] if not response : [EOL] continue [EOL] [EOL] try : [EOL] response_data = response . json ( ) [EOL] except ( ValueError , KeyError ) : [EOL] logger . error ( [string] . format ( response . text ) ) [EOL] continue [EOL] [EOL] for gallery_data in response_data [ [string] ] : [EOL] if [string] in gallery_data : [EOL] logger . error ( [string] [string] . format ( gallery_data [ [string] ] , gallery_data [ [string] ] ) ) [EOL] continue [EOL] internal_gallery_data = map_external_gallery_data_to_internal ( gallery_data ) [EOL] link = link_from_gid_token_fjord ( gallery_data [ [string] ] , gallery_data [ [string] ] , False ) [EOL] internal_gallery_data . link = link [EOL] [EOL] if self . general_utils . discard_by_tag_list ( internal_gallery_data . tags ) : [EOL] if not self . settings . silent_processing : [EOL] logger . info ( [string] . format ( link ) ) [EOL] continue [EOL] [EOL] if wanted_filters : [EOL] self . compare_gallery_with_wanted_filters ( internal_gallery_data , link , wanted_filters , gallery_wanted_lists ) [EOL] if wanted_only and not gallery_wanted_lists [ internal_gallery_data . gid ] : [EOL] continue [EOL] [EOL] gallery_data_list . append ( internal_gallery_data ) [EOL] [EOL] self . pass_gallery_data_to_downloaders ( gallery_data_list , gallery_wanted_lists ) [EOL] [EOL] [EOL] API = ( Parser , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Dict , Union , List [EOL] import typing [EOL] provider_name = [string] [EOL] home_page = [string] [EOL] [EOL] image_search_link = [string] [EOL] [EOL] rss_url = [string] [EOL] [EOL] ex_page = [string] [EOL] ge_page = [string] [EOL] [EOL] ge_thumb_url = [string] [EOL] ex_thumb_url = [string] [EOL] [EOL] ge_api_url = [string] [EOL] [EOL] ex_page_short = [string] [EOL] ge_page_short = [string] [EOL] [EOL] archive_download_data = { [string] : [string] } [EOL] [EOL] default_fjord_tags = [string] [EOL] [EOL] api_data = { [string] : [string] , [string] : [string] , [string] : [ ] } [EOL] [EOL] ge_torrent_tracker_announce = [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $typing.Dict[builtins.str,typing.Union[typing.List[typing.Any],builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0
from typing import Any , Type , Dict , Tuple , Optional , Match , List [EOL] import requests [EOL] import typing [EOL] import logging [EOL] import core [EOL] import datetime [EOL] import builtins [EOL] import logging [EOL] import os [EOL] import re [EOL] from datetime import datetime , timezone , timedelta [EOL] from typing import List , Tuple , Any , Optional , Dict [EOL] import html [EOL] [EOL] import requests [EOL] from bs4 import BeautifulSoup [EOL] [EOL] from core . base . types import DataDict [EOL] from core . base . utilities import calc_crc32 , request_with_retries , get_base_filename_string_from_gallery_data , get_zip_fileinfo , construct_request_dict [EOL] from core . downloaders . handlers import BaseDownloader , BaseInfoDownloader , BaseFakeDownloader , BaseTorrentDownloader [EOL] from core . downloaders . torrent import get_torrent_client [EOL] from core . providers . panda . utilities import TorrentHTMLParser , get_archive_link_from_html_page [EOL] from viewer . models import Archive [EOL] from core . base . utilities import ( available_filename , replace_illegal_name ) [EOL] from . import constants [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] class ArchiveDownloader ( BaseDownloader ) : [EOL] [EOL] type = [string] [EOL] provider = constants . provider_name [EOL] skip_if_hidden = True [EOL] [EOL] def request_archive_download ( self , root , gid , token , key ) : [EOL] [EOL] url = root + [string] [EOL] [EOL] params = { [string] : gid , [string] : token , [string] : key } [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] request_dict [ [string] ] = params [EOL] request_dict [ [string] ] = constants . archive_download_data [EOL] [EOL] response = request_with_retries ( url , request_dict , post = True , ) [EOL] [EOL] return response [EOL] [EOL] def start_download ( self ) : [EOL] [EOL] if not self . gallery : [EOL] return [EOL] [EOL] to_use_filename = get_base_filename_string_from_gallery_data ( self . gallery ) [EOL] [EOL] to_use_filename = replace_illegal_name ( to_use_filename ) [EOL] [EOL] self . gallery . filename = available_filename ( self . settings . MEDIA_ROOT , os . path . join ( self . own_settings . archive_dl_folder , to_use_filename + [string] ) ) [EOL] [EOL] if not ( self . gallery . root and self . gallery . gid and self . gallery . token and self . gallery . archiver_key ) : [EOL] logger . error ( [string] . format ( self . gallery . root , self . gallery . gid , self . gallery . token , self . gallery . archiver_key , ) ) [EOL] self . return_code = [number] [EOL] return [EOL] [EOL] r = self . request_archive_download ( self . gallery . root , self . gallery . gid , self . gallery . token , self . gallery . archiver_key ) [EOL] [EOL] if not r : [EOL] logger . error ( [string] ) [EOL] self . return_code = [number] [EOL] return [EOL] [EOL] r . encoding = [string] [EOL] [EOL] if [string] in r . text : [EOL] logger . error ( [string] ) [EOL] self . return_code = [number] [EOL] else : [EOL] [EOL] archive_link = get_archive_link_from_html_page ( r . text ) [EOL] [EOL] if archive_link == [string] : [EOL] logger . error ( [string] . format ( r . text ) ) [EOL] self . return_code = [number] [EOL] else : [EOL] m = re . match ( [string] , archive_link ) [EOL] if m : [EOL] archive_link = m . group ( [number] ) [EOL] [EOL] logger . info ( [string] . format ( archive_link , r . url ) ) [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] [EOL] request_file = requests . get ( archive_link + [string] , stream = [string] , ** request_dict ) [EOL] [EOL] if r and r . status_code == [number] : [EOL] logger . info ( [string] . format ( to_use_filename ) ) [EOL] filepath = os . path . join ( self . settings . MEDIA_ROOT , self . gallery . filename ) [EOL] with open ( filepath , [string] ) as fo : [EOL] for chunk in request_file . iter_content ( [number] ) : [EOL] fo . write ( chunk ) [EOL] [EOL] self . gallery . filesize , self . gallery . filecount = get_zip_fileinfo ( filepath ) [EOL] if self . gallery . filesize > [number] : [EOL] self . crc32 = calc_crc32 ( filepath ) [EOL] [EOL] self . fileDownloaded = [number] [EOL] self . return_code = [number] [EOL] [EOL] else : [EOL] logger . error ( [string] ) [EOL] self . return_code = [number] [EOL] [EOL] def update_archive_db ( self , default_values ) : [EOL] [EOL] if not self . gallery : [EOL] return None [EOL] [EOL] values = { [string] : self . gallery . title , [string] : self . gallery . title_jpn , [string] : self . gallery . filename , [string] : self . crc32 , [string] : self . gallery . filesize , [string] : self . gallery . filecount , } [EOL] default_values . update ( values ) [EOL] return Archive . objects . update_or_create_by_values_and_gid ( default_values , ( self . gallery . gid , self . gallery . provider ) , zipped = self . gallery . filename ) [EOL] [EOL] [EOL] class TorrentDownloader ( BaseTorrentDownloader ) : [EOL] [EOL] provider = constants . provider_name [EOL] skip_if_hidden = True [EOL] [EOL] def __init__ ( self , * args , ** kwargs ) : [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] self . expected_torrent_name = [string] [EOL] [EOL] def request_torrent_download ( self , root , gid , token ) : [EOL] [EOL] url = root + [string] [EOL] [EOL] params = { [string] : gid , [string] : token } [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] request_dict [ [string] ] = params [EOL] [EOL] response = request_with_retries ( url , request_dict , post = True , ) [EOL] [EOL] return response [EOL] [EOL] @ staticmethod def validate_torrent ( torrent_link , seeds , posted_date , gallery_posted_date ) : [EOL] validated = True [EOL] reasons = [ ] [EOL] if not torrent_link : [EOL] validated = False [EOL] reasons . append ( [string] ) [EOL] else : [EOL] if seeds <= [number] : [EOL] validated = False [EOL] reasons . append ( [string] ) [EOL] if not posted_date or not gallery_posted_date : [EOL] validated = False [EOL] reasons . append ( [string] ) [EOL] else : [EOL] parsed_posted_date = datetime . strptime ( posted_date , [string] ) [EOL] if parsed_posted_date < gallery_posted_date : [EOL] validated = False [EOL] reasons . append ( [string] ) [EOL] return validated , reasons [EOL] [EOL] def start_download ( self ) : [EOL] [EOL] if not self . gallery : [EOL] return [EOL] [EOL] client = get_torrent_client ( self . settings . torrent ) [EOL] if not client : [EOL] self . return_code = [number] [EOL] logger . error ( [string] ) [EOL] return [EOL] [EOL] if not ( self . gallery . root and self . gallery . gid and self . gallery . token ) : [EOL] logger . error ( [string] . format ( self . gallery . root , self . gallery . gid , self . gallery . token , ) ) [EOL] self . return_code = [number] [EOL] return [EOL] [EOL] r = self . request_torrent_download ( self . gallery . root , self . gallery . gid , self . gallery . token ) [EOL] [EOL] if not r : [EOL] logger . error ( [string] ) [EOL] self . return_code = [number] [EOL] return [EOL] [EOL] torrent_page_parser = TorrentHTMLParser ( ) [EOL] torrent_page_parser . feed ( r . text ) [EOL] [EOL] torrent_link = torrent_page_parser . torrent [EOL] [EOL] if not torrent_link : [EOL] logger . error ( [string] ) [EOL] self . return_code = [number] [EOL] return [EOL] [EOL] validated , reasons = self . validate_torrent ( torrent_link , torrent_page_parser . seeds , torrent_page_parser . posted_date , self . gallery . posted ) [EOL] [EOL] if not validated : [EOL] logger . error ( [string] [string] . format ( self . gallery . link , [string] . join ( reasons ) ) ) [EOL] self . return_code = [number] [EOL] return [EOL] [EOL] m = re . match ( [string] , torrent_link ) [EOL] if m and m . group ( [number] ) : [EOL] torrent_link = m . group ( [number] ) [EOL] [EOL] logger . info ( [string] . format ( torrent_page_parser . seeds ) ) [EOL] self . connect_and_download ( client , torrent_link ) [EOL] [EOL] def update_archive_db ( self , default_values ) : [EOL] [EOL] if not self . gallery : [EOL] return None [EOL] [EOL] values = { [string] : self . gallery . title , [string] : self . gallery . title_jpn , [string] : self . gallery . filename , [string] : self . crc32 , [string] : self . gallery . filesize , [string] : self . gallery . filecount , } [EOL] default_values . update ( values ) [EOL] return Archive . objects . update_or_create_by_values_and_gid ( default_values , ( self . gallery . gid , self . gallery . provider ) , zipped = self . gallery . filename ) [EOL] [EOL] [EOL] class TorrentAPIDownloader ( BaseTorrentDownloader ) : [EOL] [EOL] type = [string] [EOL] provider = constants . provider_name [EOL] skip_if_hidden = False [EOL] [EOL] def __init__ ( self , * args , ** kwargs ) : [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] self . expected_torrent_name = [string] [EOL] [EOL] def choose_torrent ( self , torrents ) : [EOL] [EOL] if not self . gallery : [EOL] return None [EOL] [EOL] chosen_torrent_date = None [EOL] chosen_torrent_size = None [EOL] chosen_size_difference = - [number] [EOL] chosen_date_difference = timedelta . max [EOL] [EOL] for torrent_info in torrents : [EOL] if torrent_info [ [string] ] and self . gallery . posted is not None : [EOL] if datetime . fromtimestamp ( int ( torrent_info [ [string] ] ) , timezone . utc ) < self . gallery . posted : [EOL] continue [EOL] date_difference = datetime . fromtimestamp ( int ( torrent_info [ [string] ] ) , timezone . utc ) - self . gallery . posted [EOL] if date_difference < chosen_date_difference : [EOL] chosen_torrent_date = torrent_info [EOL] chosen_date_difference = date_difference [EOL] if torrent_info [ [string] ] and self . gallery . filesize is not None : [EOL] size_different = abs ( int ( torrent_info [ [string] ] ) - self . gallery . filesize ) [EOL] if chosen_size_difference == - [number] or size_different < chosen_size_difference : [EOL] chosen_torrent_size = torrent_info [EOL] chosen_size_difference = size_different [EOL] [EOL] if chosen_torrent_size is not None and chosen_torrent_date is not None : [EOL] if chosen_torrent_size [ [string] ] == chosen_torrent_date [ [string] ] : [EOL] return chosen_torrent_size [EOL] else : [EOL] return chosen_torrent_size [EOL] elif chosen_torrent_size is not None : [EOL] return chosen_torrent_size [EOL] else : [EOL] return chosen_torrent_date [EOL] [EOL] @ staticmethod def format_torrent_magnet_url ( torrent_hash ) : [EOL] torrent_magnet = [string] . format ( torrent_hash , constants . ge_torrent_tracker_announce ) [EOL] return torrent_magnet [EOL] [EOL] def start_download ( self ) : [EOL] [EOL] if not self . gallery : [EOL] return [EOL] [EOL] if [string] not in self . gallery . extra_data or [string] not in self . gallery . extra_data : [EOL] logger . error ( [string] ) [EOL] self . return_code = [number] [EOL] return [EOL] [EOL] if int ( self . gallery . extra_data [ [string] ] ) <= [number] : [EOL] logger . error ( [string] ) [EOL] self . return_code = [number] [EOL] return [EOL] [EOL] client = get_torrent_client ( self . settings . torrent ) [EOL] if not client : [EOL] self . return_code = [number] [EOL] logger . error ( [string] ) [EOL] return [EOL] [EOL] chosen_torrent = self . choose_torrent ( self . gallery . extra_data [ [string] ] ) [EOL] [EOL] if not chosen_torrent : [EOL] self . return_code = [number] [EOL] logger . error ( [string] ) [EOL] return [EOL] [EOL] client . send_url = True [EOL] client . set_expected = False [EOL] [EOL] torrent_magnet_url = self . format_torrent_magnet_url ( chosen_torrent [ [string] ] ) [EOL] client . expected_torrent_name = html . unescape ( chosen_torrent [ [string] ] ) [EOL] [EOL] logger . info ( [string] . format ( torrent_magnet_url , chosen_torrent [ [string] ] , datetime . fromtimestamp ( int ( chosen_torrent [ [string] ] ) , timezone . utc ) , html . unescape ( chosen_torrent [ [string] ] ) ) ) [EOL] self . connect_and_download ( client , torrent_magnet_url ) [EOL] [EOL] def update_archive_db ( self , default_values ) : [EOL] [EOL] if not self . gallery : [EOL] return None [EOL] [EOL] values = { [string] : self . gallery . title , [string] : self . gallery . title_jpn , [string] : self . gallery . filename , [string] : self . crc32 , [string] : self . gallery . filesize , [string] : self . gallery . filecount , } [EOL] default_values . update ( values ) [EOL] return Archive . objects . update_or_create_by_values_and_gid ( default_values , ( self . gallery . gid , self . gallery . provider ) , zipped = self . gallery . filename ) [EOL] [EOL] [EOL] class HathDownloader ( BaseDownloader ) : [EOL] [EOL] type = [string] [EOL] provider = constants . provider_name [EOL] skip_if_hidden = True [EOL] [EOL] def start_download ( self ) : [EOL] [EOL] if not self . gallery : [EOL] return [EOL] [EOL] if not ( self . gallery . root and self . gallery . gid and self . gallery . token and self . gallery . archiver_key ) : [EOL] logger . error ( [string] . format ( self . gallery . root , self . gallery . gid , self . gallery . token , self . gallery . archiver_key , ) ) [EOL] self . return_code = [number] [EOL] return [EOL] [EOL] r = self . request_hath_download ( self . gallery . root , self . gallery . gid , self . gallery . token , self . gallery . archiver_key ) [EOL] [EOL] if r and r . status_code == [number] : [EOL] [EOL] r . encoding = [string] [EOL] soup = BeautifulSoup ( r . content , [string] ) [EOL] [EOL] container = soup . find ( text = re . compile ( [string] ) ) [EOL] [EOL] if not container : [EOL] logger . error ( [string] ) [EOL] self . return_code = [number] [EOL] return [EOL] client_id = container . parent . find ( [string] ) [EOL] if client_id : [EOL] logger . info ( [string] . format ( client_id . get_text ( ) ) ) [EOL] [EOL] to_use_filename = get_base_filename_string_from_gallery_data ( self . gallery ) [EOL] [EOL] self . gallery . filename = available_filename ( self . settings . MEDIA_ROOT , os . path . join ( self . own_settings . hath_dl_folder , replace_illegal_name ( to_use_filename + [string] + str ( self . gallery . gid ) + [string] ) + [string] ) ) [EOL] [EOL] self . fileDownloaded = [number] [EOL] self . return_code = [number] [EOL] else : [EOL] if r : [EOL] logger . error ( [string] . format ( r . text ) ) [EOL] else : [EOL] logger . error ( [string] ) [EOL] self . return_code = [number] [EOL] [EOL] def request_hath_download ( self , root , gid , token , key ) : [EOL] [EOL] url = root + [string] [EOL] [EOL] params = { [string] : gid , [string] : token , [string] : key } [EOL] [EOL] [comment] [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] request_dict [ [string] ] = params [EOL] request_dict [ [string] ] = { [string] : [string] } [EOL] [EOL] for retry_count in range ( [number] ) : [EOL] try : [EOL] r = requests . post ( url , ** request_dict ) [EOL] return r [EOL] except ( requests . exceptions . Timeout , requests . exceptions . ConnectionError ) as e : [EOL] if retry_count < [number] : [EOL] logger . warning ( [string] . format ( retry_count , [number] , str ( e ) ) ) [EOL] continue [EOL] else : [EOL] return None [EOL] return None [EOL] [EOL] def update_archive_db ( self , default_values ) : [EOL] [EOL] if not self . gallery : [EOL] return None [EOL] [EOL] values = { [string] : self . gallery . title , [string] : self . gallery . title_jpn , [string] : self . gallery . filename , [string] : self . crc32 , [string] : self . gallery . filesize , [string] : self . gallery . filecount , } [EOL] default_values . update ( values ) [EOL] return Archive . objects . update_or_create_by_values_and_gid ( default_values , ( self . gallery . gid , self . gallery . provider ) , zipped = self . gallery . filename ) [EOL] [EOL] [EOL] class InfoDownloader ( BaseInfoDownloader ) : [EOL] [EOL] provider = constants . provider_name [EOL] [EOL] [EOL] class FakeDownloader ( BaseFakeDownloader ) : [EOL] [EOL] provider = constants . provider_name [EOL] [EOL] [EOL] class UrlSubmitDownloader ( BaseDownloader ) : [EOL] [EOL] type = [string] [EOL] provider = constants . provider_name [EOL] skip_if_hidden = False [EOL] [EOL] def start_download ( self ) : [EOL] [EOL] if not self . original_gallery : [EOL] return [EOL] [EOL] logger . info ( [string] ) [EOL] [EOL] self . return_code = [number] [EOL] [EOL] [EOL] API = ( ArchiveDownloader , TorrentDownloader , TorrentAPIDownloader , HathDownloader , InfoDownloader , FakeDownloader , UrlSubmitDownloader , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
import builtins [EOL] import re [EOL] import typing [EOL] from urllib . parse import urljoin [EOL] [EOL] from . import constants [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from viewer . models import Gallery [EOL] [EOL] [EOL] def resolve_url ( gallery ) : [EOL] return urljoin ( constants . main_url , gallery . gid ) [EOL] [EOL] [EOL] def clean_title ( title ) : [EOL] [comment] [EOL] adjusted_title = re . sub ( [string] , [string] , re . sub ( [string] , [string] , title ) ) [EOL] [comment] [EOL] [comment] [EOL] return adjusted_title [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Any , Iterable , Dict , Optional , List [EOL] import requests [EOL] import typing [EOL] import viewer [EOL] import logging [EOL] import core [EOL] import builtins [EOL] import logging [EOL] import re [EOL] import time [EOL] import typing [EOL] import urllib . parse [EOL] [EOL] from bs4 import BeautifulSoup [EOL] from django . db . models import QuerySet [EOL] [EOL] from core . base . types import DataDict [EOL] from core . base . utilities import request_with_retries , format_title_to_wanted_search , construct_request_dict [EOL] from viewer . models import Gallery , WantedGallery , Provider , Artist [EOL] from . import constants [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from core . base . setup import Settings [EOL] from viewer . models import AttributeManager [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def wanted_generator ( settings , attrs ) : [EOL] own_settings = settings . providers [ constants . provider_name ] [EOL] [EOL] queries = { } [EOL] [EOL] for attr in attrs . filter ( name__startswith = [string] ) : [EOL] [EOL] attr_info = attr . name . replace ( [string] , [string] ) [EOL] query_name , attr_name = attr_info . split ( [string] , maxsplit = [number] ) [EOL] [EOL] if query_name not in queries : [EOL] queries [ query_name ] = { [string] : [number] } [EOL] [EOL] queries [ query_name ] . update ( { attr_name : attr . value } ) [EOL] [EOL] provider , provider_created = Provider . objects . get_or_create ( slug = constants . provider_name , defaults = { [string] : constants . provider_name } ) [EOL] [EOL] parser = settings . provider_context . get_parsers ( settings , filter_name = constants . provider_name ) [ [number] ] [EOL] [EOL] rounds = [number] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] for query_name , query_values in queries . items ( ) : [EOL] [EOL] while True : [EOL] [EOL] rounds += [number] [EOL] [EOL] if rounds > [number] : [EOL] time . sleep ( own_settings . wait_timer ) [EOL] [EOL] logger . info ( [string] . format ( constants . provider_name , query_name , str ( query_values ) ) ) [EOL] [EOL] if [string] not in query_values : [EOL] logger . error ( [string] . format ( query_name ) ) [EOL] break [EOL] subpath = query_values [ [string] ] [EOL] [EOL] if not { [string] , [string] , [string] } . issubset ( query_values . keys ( ) ) : [EOL] logger . error ( [string] . format ( query_name ) ) [EOL] break [EOL] container_tag = query_values [ [string] ] [EOL] container_attribute_name = query_values [ [string] ] [EOL] container_attribute_value = query_values [ [string] ] [EOL] [EOL] get_text_from_container = False [EOL] link_tag = [string] [EOL] link_attribute_name = [string] [EOL] link_attribute_value = [string] [EOL] url_attribute_name = [string] [EOL] [EOL] if [string] in query_values and query_values [ [string] ] : [EOL] get_text_from_container = True [EOL] else : [EOL] if not { [string] , [string] , [string] , [string] } . issubset ( query_values . keys ( ) ) : [EOL] logger . error ( [string] . format ( query_name ) ) [EOL] break [EOL] link_tag = query_values [ [string] ] [EOL] link_attribute_name = query_values [ [string] ] [EOL] if link_attribute_name == [string] : [EOL] link_attribute_name = [string] [EOL] link_attribute_value = query_values [ [string] ] [EOL] url_attribute_name = query_values [ [string] ] [EOL] [EOL] full_url = urllib . parse . urljoin ( [string] . format ( subpath ) , [string] . format ( query_values [ [string] ] ) ) [EOL] [EOL] link = urllib . parse . urljoin ( constants . main_url , full_url ) [EOL] [EOL] request_dict = construct_request_dict ( settings , own_settings ) [EOL] [EOL] response = request_with_retries ( link , request_dict , post = False , ) [EOL] [EOL] if not response : [EOL] logger . error ( [string] . format ( constants . provider_name , query_values [ [string] ] ) ) [EOL] break [EOL] [EOL] response . encoding = [string] [EOL] [EOL] soup = BeautifulSoup ( response . text , [string] ) [EOL] [EOL] gallery_containers = soup . find_all ( container_tag , ** { container_attribute_name : re . compile ( container_attribute_value ) } ) [EOL] [EOL] gallery_links = [ ] [EOL] gallery_gids = [ ] [EOL] [EOL] for gallery_container in gallery_containers : [EOL] if get_text_from_container : [EOL] gallery_link = gallery_container . get_text ( ) [EOL] else : [EOL] gallery_url_container = gallery_container . find ( link_tag , ** { link_attribute_name : re . compile ( link_attribute_value ) } ) [EOL] if gallery_url_container . has_attr ( url_attribute_name ) : [EOL] gallery_link = gallery_url_container [ url_attribute_name ] [EOL] else : [EOL] continue [EOL] [EOL] gallery_gids . append ( gallery_link [ [number] : ] ) [EOL] [EOL] if not gallery_gids : [EOL] logger . error ( [string] . format ( constants . provider_name , full_url ) ) [EOL] break [EOL] [EOL] [comment] [EOL] [EOL] used = Gallery . objects . filter ( gid__in = gallery_gids , provider = constants . provider_name ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] force_process , force_created = attrs . get_or_create ( provider = provider , name = [string] , data_type = [string] , defaults = { [string] : False , } ) [EOL] [EOL] logger . info ( [string] . format ( len ( gallery_gids ) , used . count ( ) ) ) [EOL] [EOL] if not force_process . value and used . count ( ) == len ( gallery_gids ) : [EOL] logger . info ( [string] . format ( query_values [ [string] ] ) ) [EOL] break [EOL] [EOL] used_gids = used . values_list ( [string] , flat = True ) [EOL] [EOL] for gallery_gid in gallery_gids : [EOL] if gallery_gid not in used_gids : [EOL] gallery_link = urllib . parse . urljoin ( constants . main_url , [string] + gallery_gid ) [EOL] [EOL] gallery_links . append ( gallery_link ) [EOL] [EOL] api_galleries = parser . fetch_multiple_gallery_data ( gallery_links ) [EOL] [EOL] if not api_galleries : [EOL] logger . error ( [string] . format ( query_values [ [string] ] ) ) [EOL] break [EOL] [EOL] for gallery_data in api_galleries : [EOL] if gallery_data . gid not in used_gids : [EOL] if not gallery_data . dl_type : [EOL] gallery_data . dl_type = [string] [EOL] gallery_data . reason = [string] [EOL] wanted_reason = attrs . fetch_value ( [string] . format ( query_name ) ) [EOL] if isinstance ( wanted_reason , str ) : [EOL] gallery_data . reason = wanted_reason or [string] [EOL] gallery = Gallery . objects . add_from_values ( gallery_data ) [EOL] [comment] [EOL] [comment] [EOL] publisher_name = [string] [EOL] publisher = gallery . tags . filter ( scope = [string] ) . first ( ) [EOL] if publisher : [EOL] publisher_name = publisher . name [EOL] [EOL] if not gallery . title : [EOL] continue [EOL] [EOL] search_title = format_title_to_wanted_search ( gallery . title ) [EOL] [EOL] wanted_galleries = WantedGallery . objects . filter ( title = gallery . title , search_title = search_title ) [EOL] [EOL] if not wanted_galleries : [EOL] wanted_gallery = WantedGallery . objects . create ( title = gallery . title , title_jpn = gallery . title_jpn , search_title = search_title , book_type = gallery . category , page_count = gallery . filecount , publisher = publisher_name , add_as_hidden = True , reason = attrs . fetch_value ( [string] . format ( query_name ) ) or [string] , public = attrs . fetch_value ( [string] . format ( query_name ) ) or False , should_search = attrs . fetch_value ( [string] . format ( query_name ) ) or False , keep_searching = attrs . fetch_value ( [string] . format ( query_name ) ) or False , notify_when_found = attrs . fetch_value ( [string] . format ( query_name ) ) or False , ) [EOL] wanted_provider_string = attrs . fetch_value ( [string] . format ( query_name ) ) [EOL] if wanted_provider_string and isinstance ( wanted_provider_string , str ) : [EOL] wanted_provider_instance = Provider . objects . filter ( slug = wanted_provider_string ) . first ( ) [EOL] if wanted_provider_instance : [EOL] wanted_gallery . wanted_providers . add ( wanted_provider_instance ) [EOL] wanted_providers_string = attrs . fetch_value ( [string] . format ( query_name ) ) [EOL] if wanted_providers_string and isinstance ( wanted_providers_string , str ) : [EOL] for wanted_provider in wanted_providers_string . split ( ) : [EOL] wanted_provider = wanted_provider . strip ( ) [EOL] wanted_provider_instance = Provider . objects . filter ( slug = wanted_provider ) . first ( ) [EOL] if wanted_provider_instance : [EOL] wanted_gallery . wanted_providers . add ( wanted_provider_instance ) [EOL] [EOL] for artist in gallery . tags . filter ( scope = [string] ) : [EOL] artist_obj = Artist . objects . filter ( name = artist . name ) . first ( ) [EOL] if not artist_obj : [EOL] artist_obj = Artist . objects . create ( name = artist . name ) [EOL] wanted_gallery . artists . add ( artist_obj ) [EOL] logger . info ( [string] . format ( wanted_gallery . book_type , wanted_gallery . get_absolute_url ( ) , wanted_gallery . search_title ) ) [EOL] [EOL] wanted_galleries = [ wanted_gallery ] [EOL] [EOL] for wanted_gallery in wanted_galleries : [EOL] [EOL] mention , mention_created = wanted_gallery . mentions . get_or_create ( mention_date = gallery . create_date , release_date = gallery . posted , type = [string] , source = constants . provider_name , ) [EOL] if mention_created and gallery . thumbnail : [EOL] mention . copy_img ( gallery . thumbnail . path ) [EOL] wanted_gallery . calculate_nearest_release_date ( ) [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] if len ( api_galleries ) < [number] : [EOL] logger . info ( [string] [string] . format ( query_values [ [string] ] ) ) [EOL] break [EOL] [EOL] query_values [ [string] ] += [number] [EOL] [EOL] logger . info ( [string] . format ( constants . provider_name ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] from typing import Any , Type , Dict , Tuple , Optional , Set , Match , List [EOL] import requests [EOL] import typing [EOL] import logging [EOL] import core [EOL] import datetime [EOL] import django [EOL] import builtins [EOL] import logging [EOL] import re [EOL] import time [EOL] import typing [EOL] from collections import defaultdict [EOL] from datetime import datetime [EOL] from typing import Optional , List , Dict [EOL] [EOL] from bs4 import BeautifulSoup [EOL] from django . db . models import QuerySet [EOL] [EOL] from core . base . parsers import BaseParser [EOL] from core . base . utilities import request_with_retries , construct_request_dict [EOL] from core . base . types import GalleryData [EOL] from core . base . utilities import translate_tag [EOL] from . import constants [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from viewer . models import WantedGallery [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class Parser ( BaseParser ) : [EOL] name = constants . provider_name [EOL] accepted_urls = [ constants . no_scheme_url ] [EOL] [EOL] def get_values_from_gallery_link ( self , link ) : [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] [EOL] response = request_with_retries ( link , request_dict , post = False , ) [EOL] [EOL] if not response : [EOL] return None [EOL] [EOL] response . encoding = [string] [EOL] new_text = re . sub ( [string] , [string] , response . text ) [EOL] soup = BeautifulSoup ( new_text , [string] ) [EOL] gallery_container = soup . find ( [string] , class_ = re . compile ( [string] ) ) [EOL] [EOL] if gallery_container : [EOL] gallery = GalleryData ( link . replace ( constants . main_url + [string] , [string] ) . replace ( [string] , [string] ) , self . name ) [EOL] gallery . link = link [EOL] gallery . tags = [ ] [EOL] gallery . title = gallery_container . find ( [string] , class_ = [string] ) . h1 . get_text ( ) [EOL] [EOL] if gallery . gid . startswith ( [string] ) or gallery . gid . startswith ( [string] ) : [EOL] gallery . category = [string] [EOL] elif gallery . gid . startswith ( [string] ) : [EOL] gallery . category = [string] [EOL] [EOL] thumbnail_container = gallery_container . find ( [string] , class_ = [string] ) [EOL] if thumbnail_container : [EOL] gallery . thumbnail_url = thumbnail_container . get ( [string] ) [EOL] if gallery . thumbnail_url and gallery . thumbnail_url . startswith ( [string] ) : [EOL] gallery . thumbnail_url = [string] + gallery . thumbnail_url [EOL] [EOL] is_doujinshi = False [EOL] for gallery_row in gallery_container . find_all ( [string] , { [string] : [string] } ) : [EOL] left_text = gallery_row . find ( [string] , { [string] : [string] } ) . get_text ( ) [EOL] right_div = gallery_row . find ( [string] , { [string] : [string] } ) [EOL] if left_text == [string] or left_text == [string] : [EOL] right_text = right_div . get_text ( ) [EOL] [comment] [EOL] gallery . tags . append ( translate_tag ( [string] + right_text ) ) [EOL] elif left_text == [string] : [EOL] for artist in right_div . find_all ( [string] ) : [EOL] gallery . tags . append ( translate_tag ( [string] + artist . get_text ( ) ) ) [EOL] elif left_text == [string] : [EOL] for author in right_div . find_all ( [string] ) : [EOL] gallery . tags . append ( translate_tag ( [string] + author . get_text ( ) ) ) [EOL] elif left_text == [string] : [EOL] gallery . tags . append ( translate_tag ( [string] + right_div . get_text ( ) ) ) [EOL] elif left_text == [string] : [EOL] gallery . tags . append ( translate_tag ( [string] + right_div . get_text ( ) ) ) [EOL] elif left_text == [string] : [EOL] gallery . tags . append ( translate_tag ( [string] + right_div . get_text ( ) ) ) [EOL] elif left_text == [string] : [EOL] gallery . tags . append ( translate_tag ( [string] + right_div . get_text ( ) ) ) [EOL] elif left_text == [string] : [EOL] belongs_to_container = right_div . find ( [string] ) [EOL] if belongs_to_container : [EOL] gallery . gallery_container_gid = belongs_to_container . get ( [string] ) [ [number] : ] [EOL] elif left_text == [string] : [EOL] gallery . tags . append ( translate_tag ( [string] + right_div . get_text ( ) ) ) [EOL] elif left_text == [string] : [EOL] right_text = right_div . get_text ( ) [EOL] m = re . search ( [string] , right_text ) [EOL] if m : [EOL] gallery . filecount = int ( m . group ( [number] ) ) [EOL] elif left_text == [string] : [EOL] gallery . uploader , right_date_text = right_div . get_text ( ) . split ( [string] ) [EOL] right_date_text = re . sub ( [string] , [string] , right_date_text ) [EOL] gallery . posted = datetime . strptime ( right_date_text , [string] ) [EOL] elif left_text == [string] : [EOL] gallery . comment = right_div . get_text ( ) [EOL] elif left_text == [string] : [EOL] for tag_a in right_div . find_all ( [string] , href = lambda x : x and [string] in x ) : [EOL] if tag_a . get_text ( ) == [string] : [EOL] is_doujinshi = True [EOL] gallery . tags . append ( translate_tag ( tag_a . get_text ( ) ) ) [EOL] if is_doujinshi : [EOL] gallery . category = [string] [EOL] else : [EOL] gallery . category = [string] [EOL] else : [EOL] return None [EOL] return gallery [EOL] [EOL] [comment] [EOL] [comment] [EOL] def get_values_from_gallery_link_list ( self , links ) : [EOL] response = [ ] [EOL] for i , element in enumerate ( links ) : [EOL] if i > [number] : [EOL] time . sleep ( self . own_settings . wait_timer ) [EOL] [EOL] logger . info ( [string] [string] . format ( self . name , i + [number] , len ( links ) ) ) [EOL] [EOL] values = self . fetch_gallery_data ( element ) [EOL] if values : [EOL] response . append ( values ) [EOL] else : [EOL] logger . error ( [string] . format ( element ) ) [EOL] continue [EOL] return response [EOL] [EOL] [comment] [EOL] def fetch_gallery_data ( self , url ) : [EOL] return self . get_values_from_gallery_link ( url ) [EOL] [EOL] def fetch_multiple_gallery_data ( self , url_list ) : [EOL] return self . get_values_from_gallery_link_list ( url_list ) [EOL] [EOL] @ staticmethod def id_from_url ( url ) : [EOL] m = re . search ( constants . main_url + [string] , url ) [EOL] if m and m . group ( [number] ) : [EOL] return m . group ( [number] ) [EOL] else : [EOL] return None [EOL] [EOL] def crawl_urls ( self , urls , wanted_filters = None , wanted_only = False ) : [EOL] [EOL] unique_urls = set ( ) [EOL] gallery_data_list = [ ] [EOL] fetch_format_galleries = [ ] [EOL] gallery_wanted_lists = defaultdict ( list ) [EOL] [EOL] if not self . downloaders : [EOL] logger . warning ( [string] ) [EOL] return [EOL] [EOL] for url in urls : [EOL] [EOL] if constants . no_scheme_url not in url : [EOL] logger . warning ( [string] . format ( url ) ) [EOL] continue [EOL] url = url . replace ( [string] , [string] ) [EOL] unique_urls . add ( url ) [EOL] [EOL] for gallery in unique_urls : [EOL] gid = self . id_from_url ( gallery ) [EOL] if not gid : [EOL] continue [EOL] [EOL] discard_approved , discard_message = self . discard_gallery_by_internal_checks ( gallery_id = gid , link = gallery ) [EOL] [EOL] if discard_approved : [EOL] if not self . settings . silent_processing : [EOL] logger . info ( discard_message ) [EOL] continue [EOL] [EOL] fetch_format_galleries . append ( gallery ) [EOL] [EOL] if len ( fetch_format_galleries ) == [number] : [EOL] logger . info ( [string] ) [EOL] return [EOL] [EOL] galleries_data = self . fetch_multiple_gallery_data ( fetch_format_galleries ) [EOL] [EOL] if not galleries_data : [EOL] return [EOL] [EOL] for internal_gallery_data in galleries_data : [EOL] [EOL] if not internal_gallery_data . link : [EOL] continue [EOL] [EOL] if self . general_utils . discard_by_tag_list ( internal_gallery_data . tags ) : [EOL] if not self . settings . silent_processing : [EOL] logger . info ( [string] . format ( internal_gallery_data . link ) ) [EOL] continue [EOL] [EOL] if wanted_filters : [EOL] self . compare_gallery_with_wanted_filters ( internal_gallery_data , internal_gallery_data . link , wanted_filters , gallery_wanted_lists ) [EOL] if wanted_only and not gallery_wanted_lists [ internal_gallery_data . gid ] : [EOL] continue [EOL] [EOL] gallery_data_list . append ( internal_gallery_data ) [EOL] [EOL] self . pass_gallery_data_to_downloaders ( gallery_data_list , gallery_wanted_lists ) [EOL] [EOL] [EOL] API = ( Parser , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 0 $typing.List[typing.Any]$ 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.List[core.base.types.GalleryData]]$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 $builtins.str$ 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $typing.List[builtins.str]$ 0 $django.db.models.QuerySet$ 0 0 0 $builtins.bool$ 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.List[core.base.types.GalleryData]]$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 $typing.Optional[typing.List[core.base.types.GalleryData]]$ 0 0 0 0 0 0 0 0 $typing.Optional[typing.List[core.base.types.GalleryData]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.db.models.QuerySet$ 0 0 0 0 0 0 0 0 0 0 0 0 $django.db.models.QuerySet$ 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 $builtins.bool$ 0 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 0 0 0 0 0 0 0 0
provider_name = [string] [EOL] home_page = [string] [EOL] [EOL] main_url = [string] [EOL] no_scheme_url = [string] [EOL]	$builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0
from typing import Any , Type , Dict , Tuple , Optional , Set , List [EOL] import requests [EOL] import typing [EOL] import logging [EOL] import core [EOL] import builtins [EOL] import logging [EOL] import os [EOL] import re [EOL] from typing import Optional [EOL] from urllib . parse import urljoin , quote [EOL] [EOL] from bs4 import BeautifulSoup [EOL] [EOL] from core . base . matchers import Matcher [EOL] from core . base . types import DataDict [EOL] from core . base . utilities import ( filecount_in_zip , get_zip_filesize , request_with_retries , construct_request_dict ) [EOL] from . import constants [EOL] from . utilities import clean_title [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class TitleMatcher ( Matcher ) : [EOL] [EOL] name = [string] [EOL] provider = constants . provider_name [EOL] type = [string] [EOL] time_to_wait_after_compare = [number] [EOL] default_cutoff = [number] [EOL] [EOL] def format_to_search_title ( self , file_name ) : [EOL] if file_name . endswith ( [string] ) : [EOL] return clean_title ( self . get_title_from_path ( file_name ) ) [EOL] else : [EOL] return clean_title ( file_name ) [EOL] [EOL] def format_to_compare_title ( self , file_name ) : [EOL] if file_name . endswith ( [string] ) : [EOL] return clean_title ( self . get_title_from_path ( file_name ) ) [EOL] else : [EOL] return clean_title ( file_name ) [EOL] [EOL] def search_method ( self , title_to_search ) : [EOL] return self . compare_by_title_json ( title_to_search ) [EOL] [EOL] def format_match_values ( self ) : [EOL] [EOL] if not self . match_values : [EOL] return None [EOL] self . match_gid = self . match_values . gid [EOL] values = { [string] : self . match_title , [string] : [string] , [string] : self . file_path , [string] : self . crc32 , [string] : self . found_by , [string] : get_zip_filesize ( os . path . join ( self . settings . MEDIA_ROOT , self . file_path ) ) , [string] : filecount_in_zip ( os . path . join ( self . settings . MEDIA_ROOT , self . file_path ) ) , [string] : self . provider } [EOL] [EOL] return values [EOL] [EOL] def compare_by_title ( self , title ) : [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] [EOL] r = request_with_retries ( urljoin ( constants . main_url , [string] ) + quote ( title ) , request_dict , ) [EOL] [EOL] if not r : [EOL] logger . info ( [string] ) [EOL] return False [EOL] [EOL] r . encoding = [string] [EOL] soup_1 = BeautifulSoup ( r . text , [string] ) [EOL] [EOL] matches_links = set ( ) [EOL] [EOL] [comment] [EOL] for gallery in soup_1 . find_all ( [string] , class_ = re . compile ( [string] ) ) : [EOL] link_container = gallery . find ( [string] , class_ = [string] ) [EOL] if link_container : [EOL] matches_links . add ( urljoin ( constants . main_url , link_container [ [string] ] ) ) [EOL] [EOL] self . gallery_links = list ( matches_links ) [EOL] if len ( self . gallery_links ) > [number] : [EOL] self . found_by = self . name [EOL] return True [EOL] else : [EOL] return False [EOL] [EOL] def compare_by_title_json ( self , title ) : [EOL] [EOL] [comment] [EOL] headers = { [string] : [string] , [string] : constants . main_url + [string] , [string] : [string] , } [EOL] [EOL] logger . info ( [string] . format ( urljoin ( constants . main_url , [string] ) + quote ( title . lower ( ) ) ) ) [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] request_dict [ [string] ] = { ** headers , ** self . settings . requests_headers } [EOL] [EOL] response = request_with_retries ( urljoin ( constants . main_url , [string] ) + quote ( title . lower ( ) ) , request_dict , post = False , retries = [number] ) [EOL] [EOL] if not response : [EOL] logger . info ( [string] ) [EOL] return False [EOL] [EOL] response_data = response . json ( ) [EOL] [EOL] matches_links = set ( ) [EOL] [EOL] if [string] in response_data : [EOL] logger . info ( [string] . format ( response_data [ [string] ] ) ) [EOL] return False [EOL] [EOL] for gallery in response_data : [EOL] if gallery [ [string] ] in ( [string] , [string] , [string] ) : [EOL] matches_links . add ( urljoin ( constants . main_url , gallery [ [string] ] ) ) [EOL] [EOL] self . gallery_links = list ( matches_links ) [EOL] if len ( self . gallery_links ) > [number] : [EOL] self . found_by = self . name [EOL] return True [EOL] else : [EOL] return False [EOL] [EOL] [EOL] API = ( TitleMatcher , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 $typing.Optional[requests.models.Response]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[requests.models.Response]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Optional[requests.models.Response]$ 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Tuple , Type [EOL] import core [EOL] import typing [EOL] from core . downloaders . handlers import BaseFakeDownloader , BaseInfoDownloader [EOL] from . import constants [EOL] [EOL] [EOL] class FakeDownloader ( BaseFakeDownloader ) : [EOL] [EOL] provider = constants . provider_name [EOL] [EOL] [EOL] class InfoDownloader ( BaseInfoDownloader ) : [EOL] [EOL] provider = constants . provider_name [EOL] [EOL] [EOL] API = ( FakeDownloader , InfoDownloader , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
provider_name = [string] [EOL] home_page = [string] [EOL]	$builtins.str$ 0 0 0 $builtins.str$ 0 0 0
import builtins [EOL] from typing import Optional , Any , Match [EOL] import typing [EOL] import viewer [EOL] import re [EOL] import typing [EOL] from datetime import timedelta [EOL] [EOL] from core . base . utilities import format_title_to_wanted_search [EOL] from viewer . models import TweetPost , WantedGallery , Artist [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from core . base . setup import Settings [EOL] from . settings import OwnSettings [EOL] [EOL] [EOL] def match_tweet_with_wanted_galleries ( tweet_obj , settings , own_settings ) : [EOL] [EOL] publisher = [string] [EOL] source = [string] [EOL] [EOL] yield( [string] . format ( tweet_obj . tweet_id ) ) [EOL] [EOL] match_tweet_type = re . search ( [string] , tweet_obj . text , re . DOTALL ) [EOL] if match_tweet_type : [EOL] yield( [string] . format ( match_tweet_type . group ( [number] ) . replace ( [string] , [string] ) , match_tweet_type . group ( [number] ) . replace ( [string] , [string] ) ) ) [EOL] release_type = None [EOL] release_date = None [EOL] date_type = re . search ( [string] , match_tweet_type . group ( [number] ) , re . DOTALL ) [EOL] mention_date = tweet_obj . posted_date [EOL] if date_type : [EOL] release_type = [string] [EOL] release_date = mention_date . replace ( month = int ( date_type . group ( [number] ) ) , day = int ( date_type . group ( [number] ) ) , hour = [number] , minute = [number] , second = [number] ) [EOL] new_book_type = re . search ( [string] , match_tweet_type . group ( [number] ) , re . DOTALL ) [EOL] if new_book_type : [EOL] release_type = [string] [EOL] release_date = tweet_obj . posted_date [EOL] out_today_type = re . search ( [string] , match_tweet_type . group ( [number] ) , re . DOTALL ) [EOL] if out_today_type : [EOL] release_type = [string] [EOL] release_date = tweet_obj . posted_date [EOL] out_tomorrow_type = re . search ( [string] , match_tweet_type . group ( [number] ) , re . DOTALL ) [EOL] if out_tomorrow_type : [EOL] release_type = [string] [EOL] release_date = tweet_obj . posted_date + timedelta ( days = [number] ) [EOL] [EOL] match_title_artists = re . search ( [string] , match_tweet_type . group ( [number] ) , re . DOTALL ) [EOL] if match_title_artists and release_type : [EOL] [EOL] yield( [string] . format ( match_title_artists . group ( [number] ) . replace ( [string] , [string] ) , match_title_artists . group ( [number] ) . replace ( [string] , [string] ) , release_type ) ) [EOL] [EOL] title = match_title_artists . group ( [number] ) [EOL] title = title . replace ( [string] , [string] ) [EOL] artists = set ( match_title_artists . group ( [number] ) . replace ( [string] , [string] ) . split ( [string] ) ) [EOL] if len ( artists ) > [number] : [EOL] book_type = [string] [EOL] else : [EOL] book_type = [string] [EOL] wanted_gallery , created = WantedGallery . objects . get_or_create ( title_jpn = title , search_title = format_title_to_wanted_search ( title ) , publisher = publisher , defaults = { [string] : title , [string] : book_type , [string] : True , [string] : [string] , [string] : [string] , [string] : own_settings . add_as_public , [string] : own_settings . unwanted_title or settings . auto_wanted . unwanted_title } ) [EOL] if created : [EOL] wanted_gallery . should_search = True [EOL] wanted_gallery . keep_searching = True [EOL] wanted_gallery . save ( ) [EOL] yield( [string] . format ( wanted_gallery . get_absolute_url ( ) , title ) ) [EOL] mention , mention_created = wanted_gallery . mentions . get_or_create ( mention_date = mention_date , release_date = release_date , type = release_type , source = source , ) [EOL] [EOL] if mention_created : [EOL] yield( [string] . format ( wanted_gallery . get_absolute_url ( ) , mention_date ) ) [EOL] [EOL] if mention_created and tweet_obj . media_url : [EOL] mention . save_img ( tweet_obj . media_url ) [EOL] [comment] [EOL] wanted_gallery . release_date = release_date [EOL] wanted_gallery . save ( ) [EOL] [EOL] for artist in artists : [EOL] artist_name = artist [EOL] twitter_handle = [string] [EOL] match_artist_handle = re . search ( [string] , artist , re . DOTALL ) [EOL] if match_artist_handle : [EOL] artist_name = match_artist_handle . group ( [number] ) [EOL] twitter_handle = match_artist_handle . group ( [number] ) [EOL] artist_obj = Artist . objects . filter ( name_jpn = artist_name ) . first ( ) [EOL] if not artist_obj : [EOL] artist_obj = Artist . objects . create ( name = artist_name , name_jpn = artist_name , twitter_handle = twitter_handle ) [EOL] wanted_gallery . artists . add ( artist_obj ) [EOL] [EOL] match_artist_title = re . search ( [string] , match_tweet_type . group ( [number] ) , re . DOTALL ) [EOL] if match_artist_title and release_type : [EOL] [EOL] yield( [string] . format ( match_artist_title . group ( [number] ) . replace ( [string] , [string] ) , match_artist_title . group ( [number] ) . replace ( [string] , [string] ) , release_type ) ) [EOL] [EOL] artist = match_artist_title . group ( [number] ) [EOL] artist_name = artist [EOL] twitter_handle = [string] [EOL] match_artist_handle = re . search ( [string] , artist , re . DOTALL ) [EOL] if match_artist_handle : [EOL] artist_name = match_artist_handle . group ( [number] ) [EOL] twitter_handle = match_artist_handle . group ( [number] ) [EOL] title = match_artist_title . group ( [number] ) [EOL] title = title . replace ( [string] , [string] ) [EOL] cover_artist = None [EOL] book_type = None [EOL] if [string] in artist : [EOL] artist_name = artist_name . replace ( [string] , [string] ) [EOL] book_type = [string] [EOL] cover_artist = Artist . objects . filter ( name_jpn = artist_name ) . first ( ) [EOL] if not cover_artist : [EOL] cover_artist = Artist . objects . create ( name = artist_name , name_jpn = artist_name , twitter_handle = twitter_handle ) [EOL] elif [string] in artist and ( [string] not in artist and [string] not in artist ) : [EOL] artist_name = artist_name . replace ( [string] , [string] ) [EOL] book_type = [string] [EOL] cover_artist = Artist . objects . filter ( name_jpn = artist_name ) . first ( ) [EOL] if not cover_artist : [EOL] cover_artist = Artist . objects . create ( name = artist_name , name_jpn = artist_name , twitter_handle = twitter_handle ) [EOL] elif [string] in artist : [EOL] artist_name = artist_name . replace ( [string] , [string] ) [EOL] book_type = [string] [EOL] cover_artist = Artist . objects . filter ( name_jpn = artist_name ) . first ( ) [EOL] if not cover_artist : [EOL] cover_artist = Artist . objects . create ( name = artist_name , name_jpn = artist_name , twitter_handle = twitter_handle ) [EOL] if book_type : [EOL] wanted_gallery , created = WantedGallery . objects . update_or_create ( title_jpn = title , search_title = format_title_to_wanted_search ( title ) , publisher = publisher , defaults = { [string] : cover_artist , [string] : title , [string] : book_type , [string] : True , [string] : [string] , [string] : [string] , [string] : own_settings . add_as_public } ) [EOL] if created : [EOL] wanted_gallery . should_search = True [EOL] wanted_gallery . keep_searching = True [EOL] wanted_gallery . save ( ) [EOL] yield( [string] . format ( wanted_gallery . get_absolute_url ( ) , title ) ) [EOL] mention , mention_created = wanted_gallery . mentions . get_or_create ( mention_date = mention_date , release_date = release_date , type = release_type , source = source , ) [EOL] [EOL] if mention_created : [EOL] yield( [string] . format ( wanted_gallery . get_absolute_url ( ) , mention_date ) ) [EOL] [EOL] if mention_created and tweet_obj . media_url : [EOL] mention . save_img ( tweet_obj . media_url ) [EOL] [comment] [EOL] wanted_gallery . release_date = release_date [EOL] wanted_gallery . save ( ) [EOL] [EOL] artist_obj = Artist . objects . filter ( name_jpn = artist_name ) . first ( ) [EOL] if not artist_obj : [EOL] artist_obj = Artist . objects . create ( name = artist_name , name_jpn = artist_name , twitter_handle = twitter_handle ) [EOL] wanted_gallery . artists . add ( artist_obj ) [EOL] else : [EOL] yield( [string] . format ( tweet_obj . tweet_id ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Dict [EOL] import core [EOL] import typing [EOL] import builtins [EOL] import typing [EOL] [EOL] from core . base . types import ProviderSettings [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from core . base . setup import Settings [EOL] [EOL] [EOL] class OwnSettings ( ProviderSettings ) : [EOL] def __init__ ( self , global_settings , config ) : [EOL] super ( ) . __init__ ( global_settings , config ) [EOL] self . token = [string] [EOL] self . token_secret = [string] [EOL] self . consumer_key = [string] [EOL] self . consumer_secret = [string] [EOL] self . add_as_public = False [EOL] [comment] [EOL] self . unwanted_title = [string] [EOL] [EOL] [EOL] def parse_config ( global_settings , config ) : [EOL] [EOL] settings = OwnSettings ( global_settings , config ) [EOL] if [string] in config : [EOL] if [string] in config [ [string] ] : [EOL] settings . token = config [ [string] ] [ [string] ] [EOL] if [string] in config [ [string] ] : [EOL] settings . token_secret = config [ [string] ] [ [string] ] [EOL] if [string] in config [ [string] ] : [EOL] settings . consumer_key = config [ [string] ] [ [string] ] [EOL] if [string] in config [ [string] ] : [EOL] settings . consumer_secret = config [ [string] ] [ [string] ] [EOL] if [string] in config : [EOL] if [string] in config [ [string] ] : [EOL] settings . add_as_public = config [ [string] ] . getboolean ( [string] ) [EOL] if [string] in config [ [string] ] : [EOL] settings . unwanted_title = config [ [string] ] [ [string] ] [EOL] return settings [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $'Settings'$ 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 $'Settings'$ 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $'OwnSettings'$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
provider_name = [string] [EOL] home_page = [string] [EOL] [EOL] base_url = [string] [EOL] [EOL] api_path = [string] [EOL] feed_url = base_url + [string] [EOL]	$builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0
from typing import Optional , Any , List [EOL] import datetime [EOL] import typing [EOL] import builtins [EOL] from datetime import datetime [EOL] from typing import Optional , List , Any [EOL] [EOL] from core . base . types import GalleryData [EOL] [EOL] [EOL] class ChaikaGalleryData ( GalleryData ) : [EOL] [EOL] def __init__ ( self , gid , token = None , link = None , tags = None , provider = None , title = None , title_jpn = None , comment = None , category = None , posted = None , filesize = None , filecount = None , expunged = None , rating = None , fjord = None , hidden = None , uploader = None , thumbnail_url = None , dl_type = None , public = None , content = None , archiver_key = None , root = None , filename = None , queries = None , thumbnail = None , archives = None , ** kwargs ) : [EOL] super ( ) . __init__ ( gid , token = token , link = link , tags = tags , provider = provider , title = title , title_jpn = title_jpn , comment = comment , category = category , posted = posted , filesize = filesize , filecount = filecount , expunged = expunged , rating = rating , fjord = fjord , hidden = hidden , uploader = uploader , thumbnail_url = thumbnail_url , dl_type = dl_type , public = public , content = content , archiver_key = archiver_key , root = root , filename = filename , queries = queries , thumbnail = thumbnail , ** kwargs ) [EOL] self . archives = archives [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 $typing.Optional[builtins.str]$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 $typing.Optional[typing.List[builtins.str]]$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 $typing.Optional[datetime.datetime]$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 $typing.Optional[builtins.bool]$ 0 0 0 $typing.Optional[builtins.bool]$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 $typing.Optional[builtins.bool]$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 $typing.Optional[builtins.int]$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 $typing.Optional[typing.List[builtins.str]]$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[typing.List[builtins.str]]$ 0 $typing.Optional[typing.List[builtins.str]]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[datetime.datetime]$ 0 $typing.Optional[datetime.datetime]$ 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.bool]$ 0 $typing.Optional[builtins.bool]$ 0 $typing.Optional[builtins.bool]$ 0 $typing.Optional[builtins.bool]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.bool]$ 0 $typing.Optional[builtins.bool]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.int]$ 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 0 $typing.Any$ 0 0 0 0 $typing.Optional[typing.List[builtins.str]]$ 0 $typing.Optional[typing.List[builtins.str]]$ 0
provider_name = [string] [EOL] home_page = [string] [EOL] [EOL] [comment] [EOL] old_base_url = [string] [EOL] base_url = [string] [EOL]	$builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0
[comment] [EOL] from typing import Any , Type , Dict , Tuple , Optional , Set , Match , List [EOL] import requests [EOL] import typing [EOL] import logging [EOL] import core [EOL] import datetime [EOL] import django [EOL] import builtins [EOL] import logging [EOL] import re [EOL] import time [EOL] import typing [EOL] from collections import defaultdict [EOL] from datetime import datetime [EOL] from typing import Optional , List , Dict [EOL] [EOL] from bs4 import BeautifulSoup [EOL] from django . db . models import QuerySet [EOL] [EOL] from core . base . parsers import BaseParser [EOL] from core . base . utilities import request_with_retries , construct_request_dict [EOL] from core . base . types import GalleryData [EOL] from core . base . utilities import translate_tag [EOL] from . import constants [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from viewer . models import WantedGallery [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class Parser ( BaseParser ) : [EOL] name = constants . provider_name [EOL] accepted_urls = [ constants . comic_no_scheme_url ] [EOL] [EOL] def get_values_from_gallery_link ( self , link ) : [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] [EOL] response = request_with_retries ( link , request_dict , post = False , ) [EOL] [EOL] if not response : [EOL] return None [EOL] [EOL] response . encoding = [string] [EOL] soup = BeautifulSoup ( response . text , [string] ) [EOL] gallery_container_head = soup . find ( [string] ) [EOL] [EOL] if gallery_container_head : [EOL] gid_container = gallery_container_head . find ( [string] , property = [string] ) [EOL] [EOL] if gid_container : [EOL] url_parts = gid_container [ [string] ] . split ( [string] ) [EOL] gid = url_parts [ - [number] ] [EOL] gallery = GalleryData ( gid , self . name ) [EOL] gallery . link = link [EOL] gallery . tags = [ ] [EOL] gallery . category = [string] [EOL] [EOL] title_container = gallery_container_head . find ( [string] , property = [string] ) [EOL] image_url_container = gallery_container_head . find ( [string] , property = [string] ) [EOL] tags_containers = gallery_container_head . find_all ( [string] , property = [string] ) [EOL] page_count_container = gallery_container_head . find ( [string] , property = [string] ) [EOL] description_container = gallery_container_head . find ( [string] , property = [string] ) [EOL] author_container = soup . find ( [string] , itemprop = [string] ) [EOL] section_container = soup . find ( [string] , class_ = [string] ) [EOL] gallery_container_titles = soup . find ( [string] , class_ = [string] ) [EOL] [EOL] if title_container : [EOL] gallery . title = title_container [ [string] ] [EOL] if gallery_container_titles : [EOL] title_jpn_container = gallery_container_titles . find ( [string] , lang = [string] ) [EOL] if title_jpn_container : [EOL] gallery . title_jpn = title_jpn_container . get_text ( ) [EOL] if image_url_container : [EOL] gallery . thumbnail_url = image_url_container [ [string] ] [EOL] if description_container : [EOL] gallery . comment = description_container [ [string] ] [EOL] if page_count_container : [EOL] gallery . filecount = int ( page_count_container [ [string] ] ) [EOL] if author_container : [EOL] group_name = author_container . find ( [string] , itemprop = [string] ) [EOL] if group_name : [EOL] gallery . tags . append ( translate_tag ( [string] + group_name [ [string] ] ) ) [EOL] if section_container : [EOL] time_container = section_container . find ( [string] , itemprop = [string] ) [EOL] if time_container : [EOL] gallery . posted = datetime . fromisoformat ( time_container [ [string] ] + [string] ) [EOL] p_containers = section_container . find_all ( [string] ) [EOL] for ps in p_containers : [EOL] p_text = ps . get_text ( ) [EOL] if [string] in p_text : [EOL] parody_name = p_text . replace ( [string] , [string] ) . rstrip ( ) [EOL] gallery . tags . append ( translate_tag ( [string] + parody_name ) ) [EOL] [EOL] for tag_container in tags_containers : [EOL] tag = translate_tag ( tag_container [ [string] ] ) [EOL] gallery . tags . append ( tag ) [EOL] [EOL] gallery . tags . append ( translate_tag ( [string] ) ) [EOL] [EOL] else : [EOL] return None [EOL] else : [EOL] return None [EOL] return gallery [EOL] [EOL] [comment] [EOL] [comment] [EOL] def get_values_from_gallery_link_list ( self , links ) : [EOL] response = [ ] [EOL] for i , element in enumerate ( links ) : [EOL] if i > [number] : [EOL] time . sleep ( self . own_settings . wait_timer ) [EOL] [EOL] logger . info ( [string] [string] . format ( self . name , i + [number] , len ( links ) ) ) [EOL] [EOL] values = self . fetch_gallery_data ( element ) [EOL] if values : [EOL] response . append ( values ) [EOL] else : [EOL] logger . error ( [string] . format ( element ) ) [EOL] continue [EOL] return response [EOL] [EOL] def fetch_gallery_data ( self , url ) : [EOL] return self . get_values_from_gallery_link ( url ) [EOL] [EOL] def fetch_multiple_gallery_data ( self , url_list ) : [EOL] return self . get_values_from_gallery_link_list ( url_list ) [EOL] [EOL] @ staticmethod def id_from_url ( url ) : [EOL] m = re . search ( constants . no_scheme_url + [string] , url ) [EOL] if m and m . group ( [number] ) : [EOL] return m . group ( [number] ) [EOL] else : [EOL] return None [EOL] [EOL] def crawl_urls ( self , urls , wanted_filters = None , wanted_only = False ) : [EOL] [EOL] unique_urls = set ( ) [EOL] gallery_data_list = [ ] [EOL] fetch_format_galleries = [ ] [EOL] gallery_wanted_lists = defaultdict ( list ) [EOL] [EOL] if not self . downloaders : [EOL] logger . warning ( [string] ) [EOL] return [EOL] [EOL] for url in urls : [EOL] [EOL] if constants . no_scheme_url not in url : [EOL] logger . warning ( [string] . format ( url ) ) [EOL] continue [EOL] unique_urls . add ( url ) [EOL] [EOL] for gallery in unique_urls : [EOL] gid = self . id_from_url ( gallery ) [EOL] if not gid : [EOL] continue [EOL] [EOL] discard_approved , discard_message = self . discard_gallery_by_internal_checks ( gallery_id = gid , link = gallery ) [EOL] [EOL] if discard_approved : [EOL] if not self . settings . silent_processing : [EOL] logger . info ( discard_message ) [EOL] continue [EOL] [EOL] fetch_format_galleries . append ( gallery ) [EOL] [EOL] if len ( fetch_format_galleries ) == [number] : [EOL] logger . info ( [string] ) [EOL] return [EOL] [EOL] galleries_data = self . fetch_multiple_gallery_data ( fetch_format_galleries ) [EOL] [EOL] if not galleries_data : [EOL] return [EOL] [EOL] for internal_gallery_data in galleries_data : [EOL] [EOL] if not internal_gallery_data . link : [EOL] continue [EOL] [EOL] if self . general_utils . discard_by_tag_list ( internal_gallery_data . tags ) : [EOL] if not self . settings . silent_processing : [EOL] logger . info ( [string] . format ( internal_gallery_data . link ) ) [EOL] continue [EOL] [EOL] if wanted_filters : [EOL] self . compare_gallery_with_wanted_filters ( internal_gallery_data , internal_gallery_data . link , wanted_filters , gallery_wanted_lists ) [EOL] if wanted_only and not gallery_wanted_lists [ internal_gallery_data . gid ] : [EOL] continue [EOL] [EOL] gallery_data_list . append ( internal_gallery_data ) [EOL] [EOL] self . pass_gallery_data_to_downloaders ( gallery_data_list , gallery_wanted_lists ) [EOL] [EOL] [EOL] API = ( Parser , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 0 $typing.List[typing.Any]$ 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.List[core.base.types.GalleryData]]$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 $builtins.str$ 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $typing.List[builtins.str]$ 0 $django.db.models.QuerySet$ 0 0 0 $builtins.bool$ 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.List[core.base.types.GalleryData]]$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 $typing.Optional[typing.List[core.base.types.GalleryData]]$ 0 0 0 0 0 0 0 0 $typing.Optional[typing.List[core.base.types.GalleryData]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.db.models.QuerySet$ 0 0 0 0 0 0 0 0 0 0 0 0 $django.db.models.QuerySet$ 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 $builtins.bool$ 0 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Type , Dict , Tuple , Optional , Set , List [EOL] import requests [EOL] import typing [EOL] import logging [EOL] import core [EOL] import builtins [EOL] import logging [EOL] import os [EOL] import re [EOL] from typing import Optional [EOL] from urllib . parse import urljoin , quote [EOL] [EOL] from bs4 import BeautifulSoup [EOL] [EOL] from core . base . matchers import Matcher [EOL] from core . base . types import DataDict [EOL] from core . base . utilities import ( filecount_in_zip , get_zip_filesize , request_with_retries , construct_request_dict ) [EOL] from . import constants [EOL] from . utilities import clean_title [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class TitleMatcher ( Matcher ) : [EOL] [EOL] name = [string] [EOL] provider = constants . provider_name [EOL] type = [string] [EOL] time_to_wait_after_compare = [number] [EOL] default_cutoff = [number] [EOL] [EOL] def format_to_search_title ( self , file_name ) : [EOL] if file_name . endswith ( [string] ) : [EOL] return clean_title ( self . get_title_from_path ( file_name ) ) [EOL] else : [EOL] return clean_title ( file_name ) [EOL] [EOL] def format_to_compare_title ( self , file_name ) : [EOL] if file_name . endswith ( [string] ) : [EOL] return clean_title ( self . get_title_from_path ( file_name ) ) [EOL] else : [EOL] return clean_title ( file_name ) [EOL] [EOL] def search_method ( self , title_to_search ) : [EOL] return self . compare_by_title ( title_to_search ) [EOL] [EOL] def format_match_values ( self ) : [EOL] [EOL] if not self . match_values : [EOL] return None [EOL] self . match_gid = self . match_values . gid [EOL] values = { [string] : self . match_title , [string] : [string] , [string] : self . file_path , [string] : self . crc32 , [string] : self . found_by , [string] : get_zip_filesize ( os . path . join ( self . settings . MEDIA_ROOT , self . file_path ) ) , [string] : filecount_in_zip ( os . path . join ( self . settings . MEDIA_ROOT , self . file_path ) ) , [string] : self . provider } [EOL] [EOL] return values [EOL] [EOL] def compare_by_title ( self , title ) : [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] [EOL] request_dict [ [string] ] = { [string] : [string] , [string] : title } [EOL] [EOL] r = request_with_retries ( urljoin ( constants . main_url , [string] ) , request_dict , ) [EOL] [EOL] if not r : [EOL] logger . info ( [string] ) [EOL] return False [EOL] [EOL] r . encoding = [string] [EOL] soup_1 = BeautifulSoup ( r . text , [string] ) [EOL] [EOL] matches_links = set ( ) [EOL] [EOL] for gallery in soup_1 . find_all ( [string] , class_ = re . compile ( [string] ) ) : [EOL] link_container = gallery . find ( [string] ) [EOL] if link_container : [EOL] matches_links . add ( urljoin ( constants . main_url , link_container [ [string] ] ) ) [EOL] [EOL] self . gallery_links = list ( matches_links ) [EOL] if len ( self . gallery_links ) > [number] : [EOL] self . found_by = self . name [EOL] return True [EOL] else : [EOL] return False [EOL] [EOL] [EOL] API = ( TitleMatcher , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
provider_name = [string] [EOL] friendly_name = [string] [EOL] home_page = [string] [EOL] [EOL] main_url = [string] [EOL] no_scheme_url = [string] [EOL] comic_no_scheme_url = [string] [EOL]	$builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0
	0
from typing import Tuple , Type [EOL] import core [EOL] import typing [EOL] from core . downloaders . handlers import BaseInfoDownloader [EOL] from . import constants [EOL] [EOL] [EOL] class InfoDownloader ( BaseInfoDownloader ) : [EOL] [EOL] provider = constants . provider_name [EOL] [EOL] [EOL] API = ( InfoDownloader , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
provider_name = [string] [EOL] home_page = [string] [EOL] [EOL] gallery_container_url = [string] [EOL] [EOL] main_page = [string] [EOL]	$builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0
	0
from typing import Any , Type , Dict , Tuple , Optional [EOL] import core [EOL] import typing [EOL] import logging [EOL] import builtins [EOL] import logging [EOL] from typing import Any , Optional [EOL] from urllib . parse import urljoin [EOL] [EOL] from core . base . types import DataDict [EOL] from core . downloaders . handlers import BaseInfoDownloader , BaseTorrentDownloader , BaseDownloader [EOL] from core . downloaders . torrent import get_torrent_client [EOL] from viewer . models import Archive [EOL] from . import constants [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class TorrentDownloader ( BaseTorrentDownloader ) : [EOL] [EOL] provider = constants . provider_name [EOL] [EOL] def __init__ ( self , * args , ** kwargs ) : [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] self . expected_torrent_name = [string] [EOL] [EOL] @ staticmethod def get_download_link ( url ) : [EOL] return urljoin ( url , [string] ) [EOL] [EOL] def start_download ( self ) : [EOL] [EOL] if not self . gallery or not self . gallery . link : [EOL] return [EOL] [EOL] client = get_torrent_client ( self . settings . torrent ) [EOL] if not client : [EOL] self . return_code = [number] [EOL] logger . error ( [string] ) [EOL] return [EOL] [EOL] if not self . gallery . link : [EOL] self . return_code = [number] [EOL] logger . error ( [string] ) [EOL] return [EOL] [EOL] torrent_link = self . get_download_link ( self . gallery . link ) [EOL] [EOL] logger . info ( [string] . format ( torrent_link ) ) [EOL] self . connect_and_download ( client , torrent_link ) [EOL] [EOL] def update_archive_db ( self , default_values ) : [EOL] [EOL] if not self . gallery : [EOL] return None [EOL] [EOL] values = { [string] : self . gallery . title , [string] : self . gallery . title_jpn , [string] : self . gallery . filename , [string] : self . crc32 , [string] : self . gallery . filesize , [string] : self . gallery . filecount , } [EOL] default_values . update ( values ) [EOL] return Archive . objects . update_or_create_by_values_and_gid ( default_values , ( self . gallery . gid , self . gallery . provider ) , zipped = self . gallery . filename ) [EOL] [EOL] [EOL] class InfoDownloader ( BaseInfoDownloader ) : [EOL] [EOL] provider = constants . provider_name [EOL] [EOL] [EOL] class UrlSubmitDownloader ( BaseDownloader ) : [EOL] [EOL] type = [string] [EOL] provider = constants . provider_name [EOL] skip_if_hidden = False [EOL] [EOL] def start_download ( self ) : [EOL] [EOL] if not self . original_gallery : [EOL] return [EOL] [EOL] logger . info ( [string] ) [EOL] [EOL] self . return_code = [number] [EOL] [EOL] [EOL] API = ( TorrentDownloader , InfoDownloader , UrlSubmitDownloader , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] from typing import Any , Type , Dict , Tuple , Optional , Set , Match , List [EOL] import requests [EOL] import typing [EOL] import logging [EOL] import core [EOL] import datetime [EOL] import django [EOL] import builtins [EOL] import logging [EOL] import re [EOL] import time [EOL] import typing [EOL] from collections import defaultdict [EOL] from typing import Optional , List [EOL] [EOL] import dateutil . parser [EOL] from bs4 import BeautifulSoup [EOL] from django . db . models import QuerySet [EOL] [EOL] from core . base . parsers import BaseParser [EOL] from core . base . utilities import translate_tag , request_with_retries , construct_request_dict [EOL] from core . base . types import GalleryData [EOL] from . import constants [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from viewer . models import WantedGallery [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class Parser ( BaseParser ) : [EOL] name = constants . provider_name [EOL] accepted_urls = [ constants . gallery_container_url ] [EOL] [EOL] def get_values_from_gallery_link ( self , link ) : [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] [EOL] response = request_with_retries ( link , request_dict , post = False , ) [EOL] [EOL] if not response : [EOL] return None [EOL] [EOL] response . encoding = [string] [EOL] soup = BeautifulSoup ( response . text , [string] ) [EOL] [EOL] if soup : [EOL] title_jpn_match = soup . find ( [string] , id = re . compile ( [string] ) ) . h2 [EOL] [EOL] gallery_id_match = re . search ( [string] . format ( constants . gallery_container_url ) , link ) [EOL] [EOL] if not gallery_id_match : [EOL] return None [EOL] gallery_id = [string] + gallery_id_match . group ( [number] ) [EOL] [EOL] gallery = GalleryData ( gallery_id , self . name ) [EOL] gallery . title = soup . h1 . get_text ( ) [EOL] gallery . title_jpn = title_jpn_match . get_text ( ) if title_jpn_match else [string] [EOL] gallery_filecount_match = re . search ( [string] , response . text ) [EOL] if gallery_filecount_match : [EOL] gallery . filecount = int ( gallery_filecount_match . group ( [number] ) ) [EOL] else : [EOL] gallery . filecount = [number] [EOL] gallery . tags = [ ] [EOL] gallery . link = link [EOL] gallery . posted = dateutil . parser . parse ( soup . find ( [string] ) [ [string] ] ) [EOL] [EOL] for tag_container in soup . find_all ( [string] , { [string] : [string] } ) : [EOL] tag_name = [ text for text in tag_container . stripped_strings ] [ [number] ] [EOL] tag_name = tag_name . split ( [string] ) [ [number] ] [EOL] tag_scope = tag_container . parent . parent . get_text ( ) [EOL] tag_ext = tag_container . parent . get_text ( ) [EOL] tag_scope = tag_scope . replace ( tag_ext , [string] ) . replace ( [string] , [string] ) . replace ( [string] , [string] ) . replace ( [string] , [string] ) . lower ( ) [EOL] if tag_scope == [string] : [EOL] gallery . tags . append ( translate_tag ( tag_name ) ) [EOL] elif tag_scope == [string] : [EOL] gallery . category = tag_name . capitalize ( ) [EOL] else : [EOL] gallery . tags . append ( translate_tag ( tag_scope + [string] + tag_name ) ) [EOL] [EOL] else : [EOL] return None [EOL] return gallery [EOL] [EOL] [comment] [EOL] [comment] [EOL] def get_values_from_gallery_link_list ( self , links ) : [EOL] response = [ ] [EOL] for i , element in enumerate ( links ) : [EOL] if i > [number] : [EOL] time . sleep ( self . own_settings . wait_timer ) [EOL] [EOL] logger . info ( [string] [string] . format ( self . name , i + [number] , len ( links ) ) ) [EOL] [EOL] values = self . fetch_gallery_data ( element ) [EOL] if values : [EOL] response . append ( values ) [EOL] else : [EOL] logger . error ( [string] . format ( element ) ) [EOL] continue [EOL] return response [EOL] [EOL] def fetch_gallery_data ( self , url ) : [EOL] return self . get_values_from_gallery_link ( url ) [EOL] [EOL] def fetch_multiple_gallery_data ( self , url_list ) : [EOL] return self . get_values_from_gallery_link_list ( url_list ) [EOL] [EOL] @ staticmethod def id_from_url ( url ) : [EOL] m = re . search ( [string] , url ) [EOL] if m and m . group ( [number] ) : [EOL] return [string] + m . group ( [number] ) [EOL] else : [EOL] return None [EOL] [EOL] def crawl_urls ( self , urls , wanted_filters = None , wanted_only = False ) : [EOL] [EOL] unique_urls = set ( ) [EOL] gallery_data_list = [ ] [EOL] fetch_format_galleries = [ ] [EOL] gallery_wanted_lists = defaultdict ( list ) [EOL] [EOL] if not self . downloaders : [EOL] logger . warning ( [string] ) [EOL] return [EOL] [EOL] for url in urls : [EOL] [EOL] if not ( constants . gallery_container_url in url ) : [EOL] logger . warning ( [string] . format ( url ) ) [EOL] continue [EOL] unique_urls . add ( url ) [EOL] [EOL] for gallery in unique_urls : [EOL] gid = self . id_from_url ( gallery ) [EOL] if not gid : [EOL] continue [EOL] [EOL] discard_approved , discard_message = self . discard_gallery_by_internal_checks ( gid , link = gallery ) [EOL] [EOL] if discard_approved : [EOL] if not self . settings . silent_processing : [EOL] logger . info ( discard_message ) [EOL] continue [EOL] [EOL] fetch_format_galleries . append ( gallery ) [EOL] [EOL] if len ( fetch_format_galleries ) == [number] : [EOL] logger . info ( [string] ) [EOL] return [EOL] [EOL] galleries_data = self . fetch_multiple_gallery_data ( fetch_format_galleries ) [EOL] [EOL] for internal_gallery_data in galleries_data : [EOL] [EOL] if not internal_gallery_data . link : [EOL] continue [EOL] [EOL] if self . general_utils . discard_by_tag_list ( internal_gallery_data . tags ) : [EOL] if not self . settings . silent_processing : [EOL] logger . info ( [string] . format ( internal_gallery_data . link ) ) [EOL] continue [EOL] [EOL] if wanted_filters : [EOL] self . compare_gallery_with_wanted_filters ( internal_gallery_data , internal_gallery_data . link , wanted_filters , gallery_wanted_lists ) [EOL] if wanted_only and not gallery_wanted_lists [ internal_gallery_data . gid ] : [EOL] continue [EOL] [EOL] gallery_data_list . append ( internal_gallery_data ) [EOL] [EOL] self . pass_gallery_data_to_downloaders ( gallery_data_list , gallery_wanted_lists ) [EOL] [EOL] [EOL] API = ( Parser , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 0 $typing.List[typing.Any]$ 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 $builtins.str$ 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $typing.List[builtins.str]$ 0 $django.db.models.QuerySet$ 0 0 0 $builtins.bool$ 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.db.models.QuerySet$ 0 0 0 0 0 0 0 0 0 0 0 0 $django.db.models.QuerySet$ 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 $builtins.bool$ 0 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 0 0 0 0 0 0 0 0
import builtins [EOL] import typing [EOL] [EOL] from . import constants [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from viewer . models import Gallery [EOL] [EOL] [EOL] def resolve_url ( gallery ) : [EOL] return [string] . format ( constants . gallery_container_url , gallery . gid . replace ( [string] , [string] ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
[comment] [EOL] from typing import Any , Type , Pattern , Dict , Tuple , Optional , Set , Match , List [EOL] import requests [EOL] import typing [EOL] import logging [EOL] import core [EOL] import django [EOL] import builtins [EOL] import logging [EOL] import re [EOL] import time [EOL] import typing [EOL] from collections import defaultdict [EOL] from datetime import datetime [EOL] from typing import Optional , List , Union , Type [EOL] from urllib . request import ProxyHandler [EOL] [EOL] import feedparser [EOL] from bs4 import BeautifulSoup [EOL] from django . db . models import QuerySet [EOL] [EOL] from core . base . parsers import BaseParser [EOL] from core . base . utilities import ( translate_tag_list , unescape , request_with_retries , construct_request_dict ) [EOL] from core . base . types import GalleryData [EOL] from . import constants [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from viewer . models import WantedGallery [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class Parser ( BaseParser ) : [EOL] name = constants . provider_name [EOL] accepted_urls = [ constants . main_page , constants . rss_url ] [EOL] [EOL] def get_values_from_gallery_link ( self , link ) : [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] [EOL] response = request_with_retries ( link , request_dict , post = False , ) [EOL] [EOL] if not response : [EOL] return None [EOL] [EOL] response . encoding = [string] [EOL] [EOL] match_string = re . compile ( constants . main_page + [string] ) [EOL] [EOL] tags = [ ] [EOL] [EOL] soup = BeautifulSoup ( response . text , [string] ) [EOL] [EOL] content_container = soup . find ( [string] , class_ = [string] ) [EOL] [EOL] if not content_container : [EOL] return None [EOL] [EOL] artists_container = content_container . find_all ( [string] , href = re . compile ( constants . main_page + [string] ) ) [EOL] [EOL] for artist in artists_container : [EOL] tags . append ( [string] . format ( artist . get_text ( ) ) ) [EOL] [EOL] tags_container = content_container . find_all ( [string] , href = re . compile ( constants . main_page + [string] ) ) [EOL] [EOL] for tag in tags_container : [EOL] tags . append ( tag . get_text ( ) ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] thumbnail_url = soup . find ( [string] , property = [string] ) [EOL] [EOL] match_result = match_string . match ( soup . find ( [string] , property = [string] ) ) [EOL] if not match_result : [EOL] return None [EOL] [EOL] gallery = GalleryData ( match_result . group ( [number] ) , self . name , link = link , title = soup . find ( [string] , property = [string] ) , comment = [string] , thumbnail_url = thumbnail_url , category = [string] , uploader = [string] , posted = None , filecount = [number] , filesize = [number] , expunged = False , rating = [string] , tags = translate_tag_list ( tags ) , content = content_container . encode_contents ( ) , ) [EOL] [EOL] return gallery [EOL] [EOL] def get_values_from_gallery_link_json ( self , link ) : [EOL] [EOL] match_string = re . compile ( constants . main_page + [string] ) [EOL] [EOL] m = match_string . match ( link ) [EOL] [EOL] if m : [EOL] gallery_slug = m . group ( [number] ) [EOL] else : [EOL] return None [EOL] [EOL] api_link = constants . posts_api_url [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] request_dict [ [string] ] = { [string] : gallery_slug } [EOL] [EOL] response = request_with_retries ( api_link , request_dict , post = False , ) [EOL] [EOL] if not response : [EOL] return None [EOL] [EOL] response . encoding = [string] [EOL] try : [EOL] response_data = response . json ( ) [EOL] except ( ValueError , KeyError ) : [EOL] logger . error ( [string] . format ( api_link ) ) [EOL] return None [EOL] [EOL] tags = [ ] [EOL] thumbnail_url = [string] [EOL] [EOL] if len ( response_data ) < [number] : [EOL] return None [EOL] [EOL] api_gallery = response_data [ [number] ] [EOL] [EOL] soup = BeautifulSoup ( api_gallery [ [string] ] [ [string] ] , [string] ) [EOL] [EOL] artists_container = soup . find_all ( [string] , href = re . compile ( constants . main_page + [string] ) ) [EOL] [EOL] for artist in artists_container : [EOL] tags . append ( [string] . format ( artist . get_text ( ) ) ) [EOL] [EOL] tags_container = soup . find_all ( [string] , href = re . compile ( constants . main_page + [string] ) ) [EOL] [EOL] for tag in tags_container : [EOL] tags . append ( tag . get_text ( ) ) [EOL] [EOL] thumbnail_small_container = soup . find ( [string] ) [EOL] if thumbnail_small_container : [EOL] thumbnail_url = thumbnail_small_container . get ( [string] ) [EOL] [EOL] gallery = GalleryData ( gallery_slug , self . name , link = link , title = unescape ( api_gallery [ [string] ] [ [string] ] ) , comment = [string] , thumbnail_url = thumbnail_url , category = [string] , uploader = [string] , posted = datetime . strptime ( api_gallery [ [string] ] + [string] , [string] ) , filecount = [number] , filesize = [number] , expunged = False , rating = [string] , tags = translate_tag_list ( tags ) , content = api_gallery [ [string] ] [ [string] ] , ) [EOL] [EOL] return gallery [EOL] [EOL] [comment] [EOL] [comment] [EOL] def get_values_from_gallery_link_list ( self , links ) : [EOL] response = [ ] [EOL] for i , element in enumerate ( links ) : [EOL] if i > [number] : [EOL] time . sleep ( self . own_settings . wait_timer ) [EOL] [EOL] logger . info ( [string] [string] . format ( self . name , i + [number] , len ( links ) ) ) [EOL] [EOL] values = self . fetch_gallery_data ( element ) [EOL] if values : [EOL] response . append ( values ) [EOL] else : [EOL] logger . error ( [string] . format ( element ) ) [EOL] continue [EOL] return response [EOL] [EOL] @ staticmethod def get_feed_urls ( ) : [EOL] return [ constants . rss_url , ] [EOL] [EOL] def crawl_feed ( self , feed_url = [string] ) : [EOL] [EOL] if not feed_url : [EOL] feed_url = constants . rss_url [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] [EOL] response = request_with_retries ( feed_url , request_dict , post = False , ) [EOL] [EOL] if not response : [EOL] logger . error ( [string] . format ( feed_url ) ) [EOL] return [ ] [EOL] [EOL] response . encoding = [string] [EOL] [EOL] feed = feedparser . parse ( response . text ) [EOL] [EOL] galleries = [ ] [EOL] [EOL] match_string = re . compile ( constants . main_page + [string] ) [EOL] skip_tags = [ [string] ] [EOL] [EOL] logger . info ( [string] . format ( self . name , len ( feed [ [string] ] ) ) ) [EOL] [EOL] for item in feed [ [string] ] : [EOL] tags = [ x . term for x in item [ [string] ] if x . term not in skip_tags ] [EOL] [EOL] thumbnail_url = [string] [EOL] [EOL] for content in item [ [string] ] : [EOL] soup = BeautifulSoup ( content . value , [string] ) [EOL] [EOL] artists_container = soup . find_all ( [string] , href = re . compile ( constants . main_page + [string] ) ) [EOL] [EOL] for artist in artists_container : [EOL] tags . append ( [string] . format ( artist . get_text ( ) ) ) [EOL] [EOL] thumbnail_small_container = soup . find ( [string] ) [EOL] if thumbnail_small_container : [EOL] thumbnail_url = thumbnail_small_container . get ( [string] ) [EOL] [EOL] match_result = match_string . match ( item [ [string] ] ) [EOL] if not match_result : [EOL] continue [EOL] [EOL] gallery = GalleryData ( match_result . group ( [number] ) , self . name , title = item [ [string] ] , comment = item [ [string] ] , thumbnail_url = thumbnail_url , category = [string] , uploader = item [ [string] ] , posted = datetime . strptime ( item [ [string] ] , [string] ) , filecount = [number] , filesize = [number] , expunged = False , rating = [string] , tags = translate_tag_list ( tags ) , content = item [ [string] ] [ [number] ] . value , link = item [ [string] ] ) [EOL] [EOL] [comment] [EOL] if self . general_utils . discard_by_tag_list ( gallery . tags ) : [EOL] continue [EOL] [EOL] if not gallery . link : [EOL] continue [EOL] [EOL] discard_approved , discard_message = self . discard_gallery_by_internal_checks ( gallery . gid , link = gallery . link ) [EOL] if discard_approved : [EOL] if not self . settings . silent_processing : [EOL] logger . info ( discard_message ) [EOL] continue [EOL] [EOL] galleries . append ( gallery ) [EOL] [EOL] return galleries [EOL] [EOL] def fetch_gallery_data ( self , url ) : [EOL] response = self . get_values_from_gallery_link_json ( url ) [EOL] if not response : [EOL] logger . warning ( [string] . format ( url ) ) [EOL] response = self . get_values_from_gallery_link ( url ) [EOL] return response [EOL] [EOL] def fetch_multiple_gallery_data ( self , url_list ) : [EOL] return self . get_values_from_gallery_link_list ( url_list ) [EOL] [EOL] @ staticmethod def id_from_url ( url ) : [EOL] m = re . search ( constants . main_page + [string] , url ) [EOL] if m and m . group ( [number] ) : [EOL] return m . group ( [number] ) [EOL] else : [EOL] return None [EOL] [EOL] def crawl_urls ( self , urls , wanted_filters = None , wanted_only = False ) : [EOL] [EOL] unique_urls = set ( ) [EOL] gallery_data_list = [ ] [EOL] fetch_format_galleries = [ ] [EOL] gallery_wanted_lists = defaultdict ( list ) [EOL] [EOL] if not self . downloaders : [EOL] logger . warning ( [string] ) [EOL] return [EOL] [EOL] for url in urls : [EOL] [EOL] if constants . rss_url in url : [EOL] continue [EOL] [EOL] if constants . main_page not in url : [EOL] logger . warning ( [string] . format ( url ) ) [EOL] continue [EOL] unique_urls . add ( url ) [EOL] [EOL] for gallery in unique_urls : [EOL] [EOL] gid = self . id_from_url ( gallery ) [EOL] if not gid : [EOL] continue [EOL] [EOL] discard_approved , discard_message = self . discard_gallery_by_internal_checks ( gid , link = gallery ) [EOL] [EOL] if discard_approved : [EOL] if not self . settings . silent_processing : [EOL] logger . info ( discard_message ) [EOL] continue [EOL] [EOL] fetch_format_galleries . append ( gallery ) [EOL] [EOL] galleries_data = self . fetch_multiple_gallery_data ( fetch_format_galleries ) [EOL] [EOL] for internal_gallery_data in galleries_data : [EOL] [EOL] if not internal_gallery_data . link : [EOL] continue [EOL] [EOL] if self . general_utils . discard_by_tag_list ( internal_gallery_data . tags ) : [EOL] if not self . settings . silent_processing : [EOL] logger . info ( [string] . format ( internal_gallery_data . link ) ) [EOL] continue [EOL] [EOL] if wanted_filters : [EOL] self . compare_gallery_with_wanted_filters ( internal_gallery_data , internal_gallery_data . link , wanted_filters , gallery_wanted_lists ) [EOL] if wanted_only and not gallery_wanted_lists [ internal_gallery_data . gid ] : [EOL] continue [EOL] [EOL] gallery_data_list . append ( internal_gallery_data ) [EOL] [EOL] if constants . rss_url in urls : [EOL] accepted_feed_data = [ ] [EOL] found_feed_data = self . crawl_feed ( constants . rss_url ) [EOL] [EOL] if found_feed_data : [EOL] logger . info ( [string] . format ( len ( found_feed_data ) ) ) [EOL] [EOL] for feed_gallery in found_feed_data : [EOL] [EOL] if not feed_gallery . link : [EOL] continue [EOL] [EOL] if wanted_filters : [EOL] self . compare_gallery_with_wanted_filters ( feed_gallery , feed_gallery . link , wanted_filters , gallery_wanted_lists ) [EOL] if wanted_only and not gallery_wanted_lists [ feed_gallery . gid ] : [EOL] continue [EOL] accepted_feed_data . append ( feed_gallery ) [EOL] [EOL] gallery_data_list . extend ( accepted_feed_data ) [EOL] [EOL] self . pass_gallery_data_to_downloaders ( gallery_data_list , gallery_wanted_lists ) [EOL] [EOL] [EOL] API = ( Parser , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 0 0 $builtins.str$ 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 $builtins.str$ 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $typing.List[builtins.str]$ 0 $django.db.models.QuerySet$ 0 0 0 $builtins.bool$ 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.db.models.QuerySet$ 0 0 0 0 0 0 0 0 0 0 0 0 $django.db.models.QuerySet$ 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 $builtins.bool$ 0 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 $typing.List[typing.Any]$ 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.db.models.QuerySet$ 0 0 0 0 0 0 0 0 0 0 0 0 $django.db.models.QuerySet$ 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 $builtins.bool$ 0 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 0 0 0 0 0 0 0 0
from typing import List [EOL] import typing [EOL] provider_name = [string] [EOL] home_page = [string] [EOL] [EOL] main_page = [string] [EOL] [EOL] rss_url = [string] . format ( main_page ) [EOL] [EOL] posts_api_url = [string] . format ( main_page ) [EOL] [EOL] bad_urls = [ [string] , [string] ] [EOL]	0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0
from typing import Any , Type , Pattern , Dict , Tuple , Optional , Match , List [EOL] import requests [EOL] import typing [EOL] import logging [EOL] import core [EOL] import builtins [EOL] import json [EOL] import logging [EOL] import os [EOL] import shutil [EOL] import re [EOL] from tempfile import mkdtemp [EOL] from typing import List , Optional [EOL] from zipfile import ZipFile [EOL] [EOL] import requests [EOL] from bs4 import BeautifulSoup [EOL] [EOL] from core . base . types import DataDict [EOL] from core . base . utilities import calc_crc32 , get_base_filename_string_from_gallery_data , get_zip_fileinfo , construct_request_dict [EOL] from core . downloaders . handlers import BaseDownloader , BaseInfoDownloader [EOL] from . utilities import guess_gallery_read_url [EOL] from viewer . models import Archive [EOL] from core . base . utilities import ( available_filename , replace_illegal_name ) [EOL] from . import constants [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class ArchiveDownloader ( BaseDownloader ) : [EOL] [EOL] type = [string] [EOL] provider = constants . provider_name [EOL] [EOL] def start_download ( self ) : [EOL] [EOL] if not self . gallery or not self . gallery . link : [EOL] return [EOL] [EOL] to_use_filename = get_base_filename_string_from_gallery_data ( self . gallery ) [EOL] [EOL] to_use_filename = replace_illegal_name ( to_use_filename ) [EOL] [EOL] self . gallery . filename = available_filename ( self . settings . MEDIA_ROOT , os . path . join ( self . own_settings . archive_dl_folder , to_use_filename + [string] ) ) [EOL] if self . gallery . content : [EOL] soup_1 = BeautifulSoup ( self . gallery . content , [string] ) [EOL] else : [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] gallery_page = requests . get ( self . gallery . link , ** request_dict ) [EOL] soup_1 = BeautifulSoup ( gallery_page . content , [string] ) [EOL] [EOL] gallery_read = soup_1 . find ( [string] , { [string] : [string] } ) [ [string] ] [EOL] [EOL] [comment] [EOL] gallery_read = re . sub ( [string] + re . escape ( constants . main_page ) + [string] , [string] , gallery_read , flags = re . DOTALL ) [EOL] [EOL] if not gallery_read or gallery_read in constants . bad_urls or not gallery_read . startswith ( constants . main_page ) : [EOL] logger . warning ( [string] ) [EOL] gallery_read = guess_gallery_read_url ( self . gallery . link , self . gallery ) [EOL] [EOL] if not gallery_read . endswith ( [string] ) : [EOL] gallery_read += [string] [EOL] [EOL] page_regex = re . compile ( [string] , re . IGNORECASE ) [EOL] [EOL] last_image = [string] [EOL] [EOL] directory_path = mkdtemp ( ) [EOL] [EOL] logger . info ( [string] . format ( self . gallery . title ) ) [EOL] [EOL] second_pass = False [EOL] while True : [EOL] [EOL] try : [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] gallery_read_page = requests . get ( gallery_read , ** request_dict ) [EOL] except requests . exceptions . MissingSchema : [EOL] logger . error ( [string] . format ( gallery_read ) ) [EOL] self . return_code = [number] [EOL] shutil . rmtree ( directory_path , ignore_errors = True ) [EOL] return [EOL] [EOL] if gallery_read_page . status_code == [number] : [EOL] if gallery_read . endswith ( [string] ) : [EOL] if not second_pass : [EOL] gallery_read = guess_gallery_read_url ( self . gallery . link , self . gallery , False ) [EOL] second_pass = True [EOL] continue [EOL] logger . error ( [string] . format ( gallery_read ) ) [EOL] self . return_code = [number] [EOL] shutil . rmtree ( directory_path , ignore_errors = True ) [EOL] return [EOL] [comment] [EOL] break [EOL] [EOL] soup_2 = BeautifulSoup ( gallery_read_page . content , [string] ) [EOL] img_find = soup_2 . find ( [string] , { [string] : [string] } ) [EOL] [EOL] if not img_find : [EOL] logger . error ( [string] ) [EOL] self . return_code = [number] [EOL] shutil . rmtree ( directory_path , ignore_errors = True ) [EOL] return [EOL] [EOL] img = img_find [ [string] ] [EOL] [EOL] if last_image != [string] and last_image == img : [EOL] [comment] [EOL] break [EOL] last_image = img [EOL] img_name = os . path . basename ( img ) [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] request_file = requests . get ( img , ** request_dict ) [EOL] if request_file . status_code == [number] : [EOL] [comment] [EOL] break [EOL] with open ( os . path . join ( directory_path , img_name ) , [string] ) as fo : [EOL] for chunk in request_file . iter_content ( [number] ) : [EOL] fo . write ( chunk ) [EOL] [EOL] page_match = page_regex . search ( gallery_read ) [EOL] [EOL] if page_match : [EOL] gallery_read = page_match . group ( [number] ) + str ( int ( page_match . group ( [number] ) ) + [number] ) [EOL] else : [EOL] [comment] [EOL] break [EOL] [EOL] file_path = os . path . join ( self . settings . MEDIA_ROOT , self . gallery . filename ) [EOL] [EOL] with ZipFile ( file_path , [string] ) as archive : [EOL] for ( root_path , _ , file_names ) in os . walk ( directory_path ) : [EOL] for current_file in file_names : [EOL] archive . write ( os . path . join ( root_path , current_file ) , arcname = os . path . basename ( current_file ) ) [EOL] shutil . rmtree ( directory_path , ignore_errors = True ) [EOL] [EOL] self . gallery . filesize , self . gallery . filecount = get_zip_fileinfo ( file_path ) [EOL] if self . gallery . filesize > [number] : [EOL] self . crc32 = calc_crc32 ( file_path ) [EOL] self . fileDownloaded = [number] [EOL] self . return_code = [number] [EOL] [EOL] def update_archive_db ( self , default_values ) : [EOL] [EOL] if not self . gallery : [EOL] return None [EOL] [EOL] values = { [string] : self . gallery . title , [string] : [string] , [string] : self . gallery . filename , [string] : self . crc32 , [string] : self . gallery . filesize , [string] : self . gallery . filecount , } [EOL] default_values . update ( values ) [EOL] return Archive . objects . update_or_create_by_values_and_gid ( default_values , ( self . gallery . gid , self . gallery . provider ) , zipped = self . gallery . filename ) [EOL] [EOL] [EOL] class ArchiveJSDownloader ( BaseDownloader ) : [EOL] [EOL] type = [string] [EOL] provider = constants . provider_name [EOL] [EOL] @ staticmethod def get_img_urls_from_gallery_read_page ( content ) : [EOL] soup = BeautifulSoup ( content , [string] ) [EOL] script_content = soup . find ( [string] , type = [string] ) [EOL] [EOL] if script_content : [EOL] m = re . search ( [string] , script_content . get_text ( ) ) [EOL] if m : [EOL] urls = json . loads ( m . group ( [number] ) ) [EOL] return [ x [ [string] ] for x in urls ] [EOL] return [ ] [EOL] [EOL] def start_download ( self ) : [EOL] [EOL] if not self . gallery or not self . gallery . link : [EOL] return [EOL] [EOL] to_use_filename = get_base_filename_string_from_gallery_data ( self . gallery ) [EOL] [EOL] to_use_filename = replace_illegal_name ( to_use_filename ) [EOL] [EOL] self . gallery . filename = available_filename ( self . settings . MEDIA_ROOT , os . path . join ( self . own_settings . archive_dl_folder , to_use_filename + [string] ) ) [EOL] if self . gallery . content : [EOL] soup_1 = BeautifulSoup ( self . gallery . content , [string] ) [EOL] else : [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] gallery_page = requests . get ( self . gallery . link , ** request_dict ) [EOL] soup_1 = BeautifulSoup ( gallery_page . content , [string] ) [EOL] [EOL] gallery_read = soup_1 . find ( [string] , { [string] : [string] } ) [ [string] ] [EOL] [EOL] [comment] [EOL] gallery_read = re . sub ( [string] + re . escape ( constants . main_page ) + [string] , [string] , gallery_read , flags = re . DOTALL ) [EOL] [EOL] if not gallery_read or gallery_read in constants . bad_urls or not gallery_read . startswith ( constants . main_page ) : [EOL] logger . warning ( [string] ) [EOL] gallery_read = guess_gallery_read_url ( self . gallery . link , self . gallery ) [EOL] [EOL] if not gallery_read . endswith ( [string] ) : [EOL] gallery_read += [string] [EOL] [EOL] logger . info ( [string] . format ( self . gallery . title ) ) [EOL] [EOL] try : [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] gallery_read_page = requests . get ( gallery_read , ** request_dict ) [EOL] except requests . exceptions . MissingSchema : [EOL] logger . error ( [string] . format ( gallery_read ) ) [EOL] self . return_code = [number] [EOL] return [EOL] [EOL] if gallery_read_page . status_code != [number] : [EOL] gallery_read = guess_gallery_read_url ( self . gallery . link , self . gallery , False ) [EOL] try : [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] gallery_read_page = requests . get ( gallery_read , ** request_dict ) [EOL] except requests . exceptions . MissingSchema : [EOL] logger . error ( [string] . format ( gallery_read ) ) [EOL] self . return_code = [number] [EOL] return [EOL] [EOL] if gallery_read_page . status_code == [number] : [EOL] [EOL] image_urls = self . get_img_urls_from_gallery_read_page ( gallery_read_page . text ) [EOL] [EOL] if not image_urls : [EOL] logger . error ( [string] ) [EOL] self . return_code = [number] [EOL] return [EOL] [EOL] directory_path = mkdtemp ( ) [EOL] [EOL] for image_url in image_urls : [EOL] img_name = os . path . basename ( image_url ) [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] request_file = requests . get ( image_url , ** request_dict ) [EOL] if request_file . status_code == [number] : [EOL] logger . warning ( [string] ) [EOL] break [EOL] with open ( os . path . join ( directory_path , img_name ) , [string] ) as fo : [EOL] for chunk in request_file . iter_content ( [number] ) : [EOL] fo . write ( chunk ) [EOL] [EOL] file_path = os . path . join ( self . settings . MEDIA_ROOT , self . gallery . filename ) [EOL] [EOL] with ZipFile ( file_path , [string] ) as archive : [EOL] for ( root_path , _ , file_names ) in os . walk ( directory_path ) : [EOL] for current_file in file_names : [EOL] archive . write ( os . path . join ( root_path , current_file ) , arcname = os . path . basename ( current_file ) ) [EOL] shutil . rmtree ( directory_path , ignore_errors = True ) [EOL] [EOL] self . gallery . filesize , self . gallery . filecount = get_zip_fileinfo ( file_path ) [EOL] if self . gallery . filesize > [number] : [EOL] self . crc32 = calc_crc32 ( file_path ) [EOL] self . fileDownloaded = [number] [EOL] self . return_code = [number] [EOL] else : [EOL] logger . error ( [string] . format ( gallery_read ) ) [EOL] self . return_code = [number] [EOL] [EOL] def update_archive_db ( self , default_values ) : [EOL] [EOL] if not self . gallery : [EOL] return None [EOL] [EOL] values = { [string] : self . gallery . title , [string] : [string] , [string] : self . gallery . filename , [string] : self . crc32 , [string] : self . gallery . filesize , [string] : self . gallery . filecount , } [EOL] default_values . update ( values ) [EOL] return Archive . objects . update_or_create_by_values_and_gid ( default_values , ( self . gallery . gid , self . gallery . provider ) , zipped = self . gallery . filename ) [EOL] [EOL] [EOL] class InfoDownloader ( BaseInfoDownloader ) : [EOL] [EOL] provider = constants . provider_name [EOL] [EOL] [EOL] API = ( ArchiveDownloader , ArchiveJSDownloader , InfoDownloader , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List [EOL] import core [EOL] import typing [EOL] import builtins [EOL] import re [EOL] import typing [EOL] from urllib . parse import unquote [EOL] [EOL] from core . base . types import GalleryData [EOL] from . import constants [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from viewer . models import Gallery [EOL] [EOL] [EOL] def resolve_url ( gallery ) : [EOL] return [string] . format ( constants . main_page , gallery . gid ) [EOL] [EOL] [EOL] def clean_title ( title ) : [EOL] [comment] [EOL] title = re . sub ( [string] , [string] , title ) [EOL] [comment] [EOL] title = [string] . join ( str ( re . sub ( [string] , [string] , word ) for word in title . split ( ) ) ) [EOL] [comment] [EOL] title = re . sub ( [string] , [string] , title ) [EOL] [comment] [EOL] title = re . sub ( [string] , [string] , title ) [EOL] [comment] [EOL] title = re . sub ( [string] , [string] , title ) [EOL] [comment] [EOL] title = [string] . join ( word for word in title . split ( ) if len ( word ) > [number] ) [EOL] return title [EOL] [EOL] [EOL] def guess_gallery_read_url ( gallery_page_url , gallery , underscore = True ) : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] gallery_page_url = gallery_page_url . replace ( constants . main_page , [string] ) [EOL] artists = [ x . replace ( [string] , [string] ) for x in gallery . tags if x . startswith ( [string] ) ] [EOL] if artists : [EOL] first_artist = artists [ [number] ] [EOL] words_on_artist = first_artist . split ( [string] ) [EOL] for word in words_on_artist : [EOL] gallery_page_url = gallery_page_url . replace ( word , [string] ) [EOL] gallery_page_url = re . sub ( [string] , [string] , gallery_page_url ) [EOL] [comment] [EOL] gallery_page_url = gallery_page_url . replace ( [string] , [string] ) [EOL] gallery_page_url = re . sub ( [string] , [string] , unquote ( gallery_page_url ) ) [EOL] if underscore : [EOL] gallery_page_url = gallery_page_url . replace ( [string] , [string] ) [EOL] gallery_page_url = [string] . format ( constants . main_page , gallery_page_url ) [EOL] return gallery_page_url [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] from typing import Any , Type , Tuple , DefaultDict , Set , List [EOL] import core [EOL] import typing [EOL] import logging [EOL] import builtins [EOL] import logging [EOL] from collections import defaultdict [EOL] from typing import List [EOL] [EOL] from core . base . parsers import BaseParser [EOL] [EOL] [EOL] [comment] [EOL] from core . base . types import GalleryData [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class GenericParser ( BaseParser ) : [EOL] name = [string] [EOL] ignore = False [EOL] [EOL] [comment] [EOL] @ classmethod def filter_accepted_urls ( cls , urls ) : [EOL] return urls [EOL] [EOL] def crawl_urls ( self , urls , wanted_filters = None , wanted_only = False ) : [EOL] [EOL] unique_urls = set ( ) [EOL] gallery_data_list = [ ] [EOL] gallery_wanted_lists = defaultdict ( list ) [EOL] [EOL] if not self . downloaders : [EOL] logger . warning ( [string] ) [EOL] return [EOL] [EOL] for url in urls : [EOL] unique_urls . add ( url ) [EOL] [EOL] for gallery_url in unique_urls : [EOL] gallery_data = GalleryData ( gallery_url , self . name , link = gallery_url ) [EOL] gallery_data_list . append ( gallery_data ) [EOL] [EOL] self . pass_gallery_data_to_downloaders ( gallery_data_list , gallery_wanted_lists ) [EOL] [EOL] [EOL] API = ( GenericParser , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 $typing.List$ 0 0 0 $typing.List$ 0 0 0 0 $typing.List$ 0 0 0 $None$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 $typing.DefaultDict[typing.Any,typing.List[typing.Any]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 $typing.DefaultDict[typing.Any,typing.List[typing.Any]]$ 0 0 0 0 $typing.Tuple[typing.Type[core.providers.generic.parsers.GenericParser]]$ 0 0 0 0 0 0
from typing import Any , Dict [EOL] import core [EOL] import typing [EOL] import builtins [EOL] import os [EOL] import typing [EOL] [EOL] from core . base . types import ProviderSettings [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from core . base . setup import Settings [EOL] [EOL] [EOL] class OwnSettings ( ProviderSettings ) : [EOL] def __init__ ( self , global_settings , config ) : [EOL] super ( ) . __init__ ( global_settings , config ) [EOL] self . torrent_dl_folder = [string] [EOL] [EOL] [EOL] def parse_config ( global_settings , config ) : [EOL] [EOL] settings = OwnSettings ( global_settings , config ) [EOL] [EOL] if [string] in config : [EOL] if [string] in config [ [string] ] : [EOL] settings . torrent_dl_folder = config [ [string] ] [ [string] ] [EOL] if not os . path . exists ( os . path . join ( global_settings . MEDIA_ROOT , settings . torrent_dl_folder ) ) : [EOL] os . makedirs ( os . path . join ( global_settings . MEDIA_ROOT , settings . torrent_dl_folder ) ) [EOL] else : [EOL] settings . torrent_dl_folder = global_settings . torrent_dl_folder [EOL] return settings [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $'Settings'$ 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 $'Settings'$ 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $'OwnSettings'$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL]	0 0
from typing import List [EOL] import typing [EOL] provider_name = [string] [EOL] home_page = [string] [EOL] [EOL] main_page = [string] [EOL] gallery_container_urls = [ [string] , [string] ] [EOL] [EOL] daily_requests = [number] [EOL]	0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0
from typing import Any , Dict [EOL] import core [EOL] import typing [EOL] import builtins [EOL] import typing [EOL] [EOL] from core . base . types import ProviderSettings [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from core . base . setup import Settings [EOL] [EOL] [EOL] class OwnSettings ( ProviderSettings ) : [EOL] def __init__ ( self , global_settings , config ) : [EOL] super ( ) . __init__ ( global_settings , config ) [EOL] self . api_key = [string] [EOL] [comment] [EOL] self . unwanted_title = [string] [EOL] [EOL] [EOL] def parse_config ( global_settings , config ) : [EOL] [EOL] settings = OwnSettings ( global_settings , config ) [EOL] [EOL] if [string] in config : [EOL] if [string] in config [ [string] ] : [EOL] settings . api_key = config [ [string] ] [ [string] ] [EOL] if [string] in config : [EOL] if [string] in config [ [string] ] : [EOL] settings . unwanted_title = config [ [string] ] [ [string] ] [EOL] return settings [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $'Settings'$ 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 $'Settings'$ 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $'OwnSettings'$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
import builtins [EOL] from typing import Any , Iterable , Dict , Optional , List [EOL] import requests [EOL] import typing [EOL] import viewer [EOL] import logging [EOL] import core [EOL] import datetime [EOL] import datetime [EOL] import logging [EOL] import typing [EOL] import urllib . parse [EOL] [EOL] import django . utils . timezone as django_tz [EOL] from django . db . models import QuerySet [EOL] [EOL] from core . base . types import DataDict [EOL] from core . base . utilities import request_with_retries , format_title_to_wanted_search , construct_request_dict [EOL] from core . providers . mugimugi . utilities import convert_api_response_text_to_gallery_dicts [EOL] from viewer . models import Gallery , WantedGallery , Provider , Artist [EOL] from . import constants [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from core . base . setup import Settings [EOL] from viewer . models import AttributeManager [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def wanted_generator ( settings , attrs ) : [EOL] own_settings = settings . providers [ constants . provider_name ] [EOL] [EOL] if not own_settings . api_key : [EOL] logger . error ( [string] . format ( constants . provider_name , constants . main_page ) ) [EOL] return False [EOL] [EOL] queries = { } [EOL] queries_slist_params = { } [EOL] [EOL] for attr in attrs . filter ( name__startswith = [string] ) : [EOL] [EOL] attr_info = attr . name . replace ( [string] , [string] ) [EOL] query_name , attr_name = attr_info . split ( [string] , maxsplit = [number] ) [EOL] [EOL] if query_name not in queries : [EOL] queries [ query_name ] = { [string] : [number] , [string] : [string] , [string] : [number] , [string] : [string] , [string] : [string] } [EOL] [EOL] if attr_name . startswith ( [string] ) : [EOL] if query_name not in queries_slist_params : [EOL] queries_slist_params [ query_name ] = [ ] [EOL] queries_slist_params [ query_name ] . append ( [string] . format ( attr_name . replace ( [string] , [string] ) , attr . value ) ) [EOL] else : [EOL] queries [ query_name ] . update ( { attr_name : attr . value } ) [EOL] [EOL] for query_name , slist_params in queries_slist_params . items ( ) : [EOL] queries [ query_name ] . update ( { [string] : [string] . join ( slist_params ) } ) [EOL] [EOL] for query_name , query_values in queries . items ( ) : [EOL] [EOL] while True : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] new_query = urllib . parse . urlencode ( query_values , doseq = True ) [EOL] [EOL] logger . info ( [string] . format ( constants . provider_name , query_values [ [string] ] , query_name , new_query ) ) [EOL] [EOL] link = [string] . format ( constants . main_page , own_settings . api_key , new_query ) [EOL] [EOL] provider , provider_created = Provider . objects . get_or_create ( slug = constants . provider_name , defaults = { [string] : constants . provider_name } ) [EOL] [EOL] remaining_queries , int_created = attrs . get_or_create ( provider = provider , name = [string] , data_type = [string] , defaults = { [string] : constants . daily_requests , } ) [EOL] [EOL] last_query_date , date_created = attrs . get_or_create ( provider = provider , name = [string] , data_type = [string] , defaults = { [string] : django_tz . now ( ) , } ) [EOL] [EOL] if not date_created : [EOL] limit_time = datetime . time ( tzinfo = datetime . timezone ( datetime . timedelta ( hours = [number] ) ) ) [comment] [EOL] if last_query_date . value . timetz ( ) < limit_time < django_tz . now ( ) . timetz ( ) : [EOL] remaining_queries . value = constants . daily_requests [EOL] remaining_queries . save ( ) [EOL] [EOL] if remaining_queries . value <= [number] : [EOL] logger . warning ( [string] . format ( constants . daily_requests , constants . provider_name ) ) [EOL] return [EOL] [EOL] request_dict = construct_request_dict ( settings , own_settings ) [EOL] [EOL] response = request_with_retries ( link , request_dict , post = False , ) [EOL] [EOL] remaining_queries . value -= [number] [EOL] remaining_queries . save ( ) [EOL] last_query_date . value = django_tz . now ( ) [EOL] last_query_date . save ( ) [EOL] [EOL] if not response : [EOL] logger . error ( [string] . format ( constants . provider_name , query_values [ [string] ] ) ) [EOL] break [EOL] [EOL] response . encoding = [string] [EOL] [comment] [EOL] [EOL] api_galleries = convert_api_response_text_to_gallery_dicts ( response . text ) [EOL] [EOL] if not api_galleries : [EOL] logger . error ( [string] . format ( response . text ) ) [EOL] logger . error ( [string] . format ( constants . provider_name , query_values [ [string] ] ) ) [EOL] break [EOL] [EOL] [comment] [EOL] remaining_queries . value = api_galleries [ [number] ] . queries [EOL] remaining_queries . save ( ) [EOL] [EOL] used = Gallery . objects . filter ( gid__in = [ x . gid for x in api_galleries ] , provider = constants . provider_name ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] force_process , force_created = attrs . get_or_create ( provider = provider , name = [string] , data_type = [string] , defaults = { [string] : False , } ) [EOL] [EOL] logger . info ( [string] . format ( constants . provider_name , len ( api_galleries ) , used . count ( ) ) ) [EOL] [EOL] if not force_process . value and used . count ( ) == len ( api_galleries ) : [EOL] logger . info ( [string] . format ( constants . provider_name , query_values [ [string] ] ) ) [EOL] break [EOL] [EOL] used_gids = used . values_list ( [string] , flat = True ) [EOL] [EOL] for gallery_data in api_galleries : [EOL] if gallery_data . gid not in used_gids : [EOL] if not gallery_data . dl_type : [EOL] gallery_data . dl_type = [string] [EOL] wanted_reason = attrs . fetch_value ( [string] . format ( query_name ) ) [EOL] if isinstance ( wanted_reason , str ) : [EOL] gallery_data . reason = wanted_reason or [string] [EOL] gallery = Gallery . objects . add_from_values ( gallery_data ) [EOL] [comment] [EOL] [comment] [EOL] publisher_name = [string] [EOL] publisher = gallery . tags . filter ( scope = [string] ) . first ( ) [EOL] if publisher : [EOL] publisher_name = publisher . name [EOL] [EOL] if not gallery . title_jpn : [EOL] continue [EOL] [EOL] search_title = format_title_to_wanted_search ( gallery . title_jpn ) [EOL] [EOL] wanted_galleries = WantedGallery . objects . filter ( title_jpn = gallery . title_jpn , search_title = search_title ) [EOL] [EOL] if not wanted_galleries : [EOL] wanted_gallery = WantedGallery . objects . create ( title = gallery . title or gallery . title_jpn , title_jpn = gallery . title_jpn , search_title = search_title , book_type = gallery . category , page_count = gallery . filecount , publisher = publisher_name , add_as_hidden = True , reason = attrs . fetch_value ( [string] . format ( query_name ) ) or [string] , public = attrs . fetch_value ( [string] . format ( query_name ) ) or False , should_search = attrs . fetch_value ( [string] . format ( query_name ) ) or True , keep_searching = attrs . fetch_value ( [string] . format ( query_name ) ) or True , category = [string] , unwanted_title = own_settings . unwanted_title or settings . auto_wanted . unwanted_title ) [EOL] wanted_provider_string = attrs . fetch_value ( [string] . format ( query_name ) ) [EOL] if wanted_provider_string and isinstance ( wanted_provider_string , str ) : [EOL] wanted_provider_instance = Provider . objects . filter ( slug = wanted_provider_string ) . first ( ) [EOL] if wanted_provider_instance : [EOL] wanted_gallery . wanted_providers . add ( wanted_provider_instance ) [EOL] wanted_providers_string = attrs . fetch_value ( [string] . format ( query_name ) ) [EOL] if wanted_providers_string and isinstance ( wanted_providers_string , str ) : [EOL] for wanted_provider in wanted_providers_string . split ( ) : [EOL] wanted_provider = wanted_provider . strip ( ) [EOL] wanted_provider_instance = Provider . objects . filter ( slug = wanted_provider ) . first ( ) [EOL] if wanted_provider_instance : [EOL] wanted_gallery . wanted_providers . add ( wanted_provider_instance ) [EOL] [EOL] for artist in gallery . tags . filter ( scope = [string] ) : [EOL] artist_obj = Artist . objects . filter ( name_jpn = artist . name ) . first ( ) [EOL] if not artist_obj : [EOL] artist_obj = Artist . objects . create ( name = artist . name , name_jpn = artist . name ) [EOL] wanted_gallery . artists . add ( artist_obj ) [EOL] logger . info ( [string] . format ( wanted_gallery . book_type , wanted_gallery . get_absolute_url ( ) , gallery . title_jpn ) ) [EOL] [EOL] wanted_galleries = [ wanted_gallery ] [EOL] [EOL] for wanted_gallery in wanted_galleries : [EOL] [EOL] mention , mention_created = wanted_gallery . mentions . get_or_create ( mention_date = gallery . create_date , release_date = gallery . posted , type = [string] , source = constants . provider_name , ) [EOL] if mention_created and gallery . thumbnail : [EOL] mention . copy_img ( gallery . thumbnail . path ) [EOL] wanted_gallery . calculate_nearest_release_date ( ) [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] if len ( api_galleries ) < [number] : [EOL] logger . info ( [string] [string] . format ( query_values [ [string] ] ) ) [EOL] break [EOL] [EOL] query_values [ [string] ] += [number] [EOL] [EOL] logger . info ( [string] . format ( constants . provider_name ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Tuple , Type [EOL] import core [EOL] import typing [EOL] from core . downloaders . handlers import BaseFakeDownloader , BaseInfoDownloader [EOL] from . import constants [EOL] [EOL] [EOL] class FakeDownloader ( BaseFakeDownloader ) : [EOL] [EOL] provider = constants . provider_name [EOL] [EOL] [EOL] class InfoDownloader ( BaseInfoDownloader ) : [EOL] [EOL] provider = constants . provider_name [EOL] [EOL] [EOL] API = ( FakeDownloader , InfoDownloader , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] from typing import Any , Type , Iterable , Dict , Tuple , Optional , Set , Match , List [EOL] import requests [EOL] import typing [EOL] import logging [EOL] import core [EOL] import django [EOL] import builtins [EOL] import logging [EOL] import re [EOL] import time [EOL] import typing [EOL] from collections import defaultdict [EOL] from typing import Iterable , List , Optional [EOL] [EOL] from django . db . models import QuerySet [EOL] [EOL] from core . base . parsers import BaseParser [EOL] from core . base . types import GalleryData [EOL] from core . base . utilities import ( chunks , request_with_retries , construct_request_dict ) [EOL] from core . providers . mugimugi . utilities import convert_api_response_text_to_gallery_dicts [EOL] from . import constants [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from viewer . models import WantedGallery [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class Parser ( BaseParser ) : [EOL] name = constants . provider_name [EOL] accepted_urls = constants . gallery_container_urls [EOL] [EOL] def get_galleries_from_xml ( self , url_group ) : [EOL] [EOL] possible_gallery_ids = [ self . id_from_url ( gallery_url ) for gallery_url in url_group ] [EOL] [EOL] galleries_ids = [ gallery_id . replace ( [string] , [string] ) for gallery_id in possible_gallery_ids if gallery_id ] [EOL] [EOL] galleries = list ( ) [EOL] [EOL] gallery_chunks = list ( chunks ( galleries_ids , [number] ) ) [EOL] [EOL] for i , group in enumerate ( gallery_chunks ) : [EOL] logger . info ( [string] . format ( self . name , i + [number] , len ( group ) , len ( gallery_chunks ) ) ) [EOL] [EOL] [comment] [EOL] if i > [number] : [EOL] time . sleep ( self . own_settings . wait_timer ) [EOL] [EOL] link = constants . main_page + [string] + self . own_settings . api_key + [string] + [string] . join ( galleries_ids ) [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] [EOL] response = request_with_retries ( link , request_dict , post = False , ) [EOL] [EOL] if not response : [EOL] continue [EOL] [EOL] response . encoding = [string] [EOL] api_galleries = convert_api_response_text_to_gallery_dicts ( response . text ) [EOL] [EOL] if not api_galleries : [EOL] continue [EOL] galleries . extend ( api_galleries ) [EOL] [EOL] return galleries [EOL] [EOL] def fetch_gallery_data ( self , url ) : [EOL] [comment] [EOL] response = self . get_galleries_from_xml ( ( url , ) ) [EOL] if response : [EOL] return response [ [number] ] [EOL] return None [EOL] [EOL] def fetch_multiple_gallery_data ( self , url_list ) : [EOL] return self . get_galleries_from_xml ( url_list ) [EOL] [EOL] @ staticmethod def id_from_url ( url ) : [EOL] m = re . search ( [string] , url ) [EOL] if m and m . group ( [number] ) : [EOL] return [string] + m . group ( [number] ) [EOL] else : [EOL] return None [EOL] [EOL] def crawl_urls ( self , urls , wanted_filters = None , wanted_only = False ) : [EOL] [EOL] unique_urls = set ( ) [EOL] gallery_data_list = [ ] [EOL] fetch_format_galleries = [ ] [EOL] gallery_wanted_lists = defaultdict ( list ) [EOL] [EOL] if not self . downloaders : [EOL] logger . warning ( [string] ) [EOL] return [EOL] [EOL] if not self . own_settings . api_key : [EOL] logger . error ( [string] . format ( self . name , constants . main_page ) ) [EOL] return [EOL] [EOL] for url in urls : [EOL] [EOL] if not any ( word in url for word in constants . gallery_container_urls ) : [EOL] logger . warning ( [string] . format ( url ) ) [EOL] continue [EOL] unique_urls . add ( url ) [EOL] [EOL] for gallery in unique_urls : [EOL] gid = self . id_from_url ( gallery ) [EOL] if not gid : [EOL] continue [EOL] [EOL] discard_approved , discard_message = self . discard_gallery_by_internal_checks ( gid , link = gallery ) [EOL] [EOL] if discard_approved : [EOL] if not self . settings . silent_processing : [EOL] logger . info ( discard_message ) [EOL] continue [EOL] [EOL] fetch_format_galleries . append ( gallery ) [EOL] [EOL] if len ( fetch_format_galleries ) == [number] : [EOL] logger . info ( [string] ) [EOL] return [EOL] [EOL] galleries_data = self . fetch_multiple_gallery_data ( fetch_format_galleries ) [EOL] [EOL] for internal_gallery_data in galleries_data : [EOL] [EOL] if not internal_gallery_data . link : [EOL] continue [EOL] [EOL] if self . general_utils . discard_by_tag_list ( internal_gallery_data . tags ) : [EOL] if not self . settings . silent_processing : [EOL] logger . info ( [string] . format ( internal_gallery_data . link ) ) [EOL] continue [EOL] [EOL] if wanted_filters : [EOL] self . compare_gallery_with_wanted_filters ( internal_gallery_data , internal_gallery_data . link , wanted_filters , gallery_wanted_lists ) [EOL] if wanted_only and not gallery_wanted_lists [ internal_gallery_data . gid ] : [EOL] continue [EOL] [EOL] gallery_data_list . append ( internal_gallery_data ) [EOL] [EOL] self . pass_gallery_data_to_downloaders ( gallery_data_list , gallery_wanted_lists ) [EOL] [EOL] [EOL] API = ( Parser , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 $builtins.str$ 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $typing.List[builtins.str]$ 0 $django.db.models.QuerySet$ 0 0 0 $builtins.bool$ 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $django.db.models.QuerySet$ 0 0 0 0 0 0 0 0 0 0 0 0 $django.db.models.QuerySet$ 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 $builtins.bool$ 0 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 0 0 0 0 0 0 0 0
from typing import Optional , Any , Dict , List [EOL] import typing [EOL] import xml [EOL] import core [EOL] import datetime [EOL] import builtins [EOL] import typing [EOL] from datetime import datetime [EOL] from typing import List [EOL] from xml . etree import ElementTree [EOL] [EOL] from core . base . utilities import translate_tag [EOL] from core . base . types import GalleryData [EOL] from . import constants [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from viewer . models import Gallery [EOL] [EOL] [EOL] def resolve_url ( gallery ) : [EOL] return [string] . format ( constants . main_page , gallery . gid . replace ( [string] , [string] ) ) [EOL] [EOL] [EOL] def translate_language_code ( code ) : [EOL] lang_table = { [number] : [string] , [number] : [string] , [number] : [string] , [number] : [string] , [number] : [string] , [number] : [string] , [number] : [string] , [number] : [string] , [number] : [string] , [number] : [string] , } [EOL] return lang_table [ int ( code ) ] [EOL] [EOL] [EOL] def convert_api_response_text_to_gallery_dicts ( text ) : [EOL] galleries = [ ] [EOL] [comment] [EOL] xml_root = ElementTree . fromstring ( text ) [EOL] error = xml_root . find ( [string] ) [EOL] if error : [EOL] return galleries [EOL] for book in xml_root . findall ( [string] ) : [EOL] [EOL] book_id = book . get ( [string] ) [EOL] [EOL] if book_id is None : [EOL] continue [EOL] [EOL] integer_id = int ( book_id . replace ( [string] , [string] ) ) [EOL] gallery = GalleryData ( [string] + book_id , constants . provider_name ) [EOL] gallery . link = constants . main_page + [string] + str ( integer_id ) [EOL] gallery . tags = [ ] [EOL] found_en_title = book . find ( [string] ) [EOL] if found_en_title is not None : [EOL] gallery . title = found_en_title . text or [string] [EOL] found_jp_title = book . find ( [string] ) [EOL] if found_jp_title is not None : [EOL] gallery . title_jpn = found_jp_title . text or [string] [EOL] gallery . comment = [string] [EOL] gallery . category = [string] [EOL] gallery . filesize = [number] [EOL] found_data_pages = book . find ( [string] ) [EOL] if found_data_pages is not None and found_data_pages . text : [EOL] gallery . filecount = int ( found_data_pages . text ) [EOL] else : [EOL] gallery . filecount = [number] [EOL] gallery . uploader = [string] [EOL] gallery . thumbnail_url = [string] . format ( int ( integer_id / [number] ) , integer_id ) [EOL] found_user = xml_root . find ( [string] ) [EOL] if found_user is not None : [EOL] found_user_queries = found_user . find ( [string] ) [EOL] if found_user_queries is not None and found_user_queries . text : [EOL] gallery . queries = int ( found_user_queries . text ) [EOL] else : [EOL] gallery . queries = [number] [EOL] else : [EOL] gallery . queries = [number] [EOL] [EOL] [comment] [EOL] found_date_released = book . find ( [string] ) [EOL] if found_date_released is not None and found_date_released . text : [EOL] date_components = found_date_released . text . split ( [string] ) [EOL] if len ( date_components ) >= [number] : [EOL] if date_components [ [number] ] != [string] and date_components [ [number] ] != [string] and date_components [ [number] ] != [string] : [EOL] gallery . posted = datetime . strptime ( found_date_released . text + [string] , [string] ) [EOL] [EOL] found_links = book . find ( [string] ) [EOL] [EOL] if found_links is not None : [EOL] for item in found_links : [EOL] item_type = item . get ( [string] ) [EOL] item_name_en = item . find ( [string] ) [EOL] if item_type == [string] : [EOL] item_type = [string] [EOL] elif item_type == [string] : [EOL] item_type = [string] [EOL] elif item_type == [string] and item_name_en is not None : [EOL] gallery . category = item_name_en . text [EOL] continue [EOL] elif item_type is None or item_type == [string] : [EOL] if item_name_en is not None and not ( item_name_en . text == [string] or item_name_en . text is None ) : [EOL] gallery . tags . append ( translate_tag ( item_name_en . text ) ) [EOL] continue [EOL] if item_name_en is not None and not ( item_name_en . text == [string] or item_name_en . text is None ) : [EOL] gallery . tags . append ( translate_tag ( item_type + [string] + item_name_en . text ) ) [EOL] [EOL] found_data_language = book . find ( [string] ) [EOL] [EOL] if found_data_language is not None and not ( found_data_language . text == [string] or found_data_language . text is None ) : [EOL] gallery . tags . append ( translate_tag ( [string] + translate_language_code ( found_data_language . text ) ) ) [EOL] [EOL] [comment] [EOL] found_age = book . find ( [string] ) [EOL] if found_age is not None and not ( found_age . text == [string] or found_age . text is None ) and found_age . text == [string] : [EOL] gallery . tags . append ( translate_tag ( [string] ) ) [EOL] [EOL] galleries . append ( gallery ) [EOL] [EOL] return galleries [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Type , Dict , Tuple , Optional , List [EOL] import requests [EOL] import typing [EOL] import logging [EOL] import core [EOL] import builtins [EOL] import logging [EOL] import os [EOL] from typing import List , Optional [EOL] [EOL] from core . base . matchers import Matcher [EOL] from core . base . types import GalleryData , DataDict [EOL] from core . base . utilities import ( filecount_in_zip , get_zip_filesize , clean_title , request_with_retries , construct_request_dict ) [EOL] from core . providers . mugimugi . utilities import convert_api_response_text_to_gallery_dicts [EOL] from . import constants [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class TitleMatcher ( Matcher ) : [EOL] [EOL] name = [string] [EOL] provider = constants . provider_name [EOL] type = [string] [EOL] time_to_wait_after_compare = [number] [EOL] default_cutoff = [number] [EOL] [EOL] def get_metadata_after_matching ( self ) : [EOL] return self . values_array [EOL] [EOL] def format_to_search_title ( self , file_name ) : [EOL] if file_name . endswith ( [string] ) : [EOL] return clean_title ( self . get_title_from_path ( file_name ) ) [EOL] else : [EOL] return clean_title ( file_name ) [EOL] [EOL] def format_to_compare_title ( self , file_name ) : [EOL] if file_name . endswith ( [string] ) : [EOL] return clean_title ( self . get_title_from_path ( file_name ) ) [EOL] else : [EOL] return clean_title ( file_name ) [EOL] [EOL] def search_method ( self , title_to_search ) : [EOL] return self . search_using_xml_api ( title_to_search ) [EOL] [EOL] def format_match_values ( self ) : [EOL] [EOL] if not self . match_values : [EOL] return None [EOL] [EOL] self . match_gid = self . match_values . gid [EOL] values = { [string] : self . match_title , [string] : self . match_values . title_jpn , [string] : self . file_path , [string] : self . crc32 , [string] : self . found_by , [string] : get_zip_filesize ( os . path . join ( self . settings . MEDIA_ROOT , self . file_path ) ) , [string] : filecount_in_zip ( os . path . join ( self . settings . MEDIA_ROOT , self . file_path ) ) , [string] : self . provider } [EOL] [EOL] return values [EOL] [EOL] def search_using_xml_api ( self , title ) : [EOL] [EOL] if not self . own_settings . api_key : [EOL] logger . error ( [string] . format ( self . name , constants . main_page ) ) [EOL] return False [EOL] [EOL] page = [number] [EOL] galleries = [ ] [EOL] [EOL] while True : [EOL] link = [string] . format ( constants . main_page , self . own_settings . api_key , title , page ) [EOL] [EOL] request_dict = construct_request_dict ( self . settings , self . own_settings ) [EOL] [EOL] response = request_with_retries ( link , request_dict , post = False , ) [EOL] [EOL] if not response : [EOL] break [EOL] [EOL] response . encoding = [string] [EOL] [comment] [EOL] [EOL] api_galleries = convert_api_response_text_to_gallery_dicts ( response . text ) [EOL] [EOL] if not api_galleries : [EOL] break [EOL] [EOL] galleries . extend ( api_galleries ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] if len ( api_galleries ) < [number] : [EOL] break [EOL] [EOL] page += [number] [EOL] [EOL] self . values_array = galleries [EOL] [EOL] self . gallery_links = [ x . link for x in galleries if x . link ] [EOL] if len ( self . gallery_links ) > [number] : [EOL] self . found_by = self . name [EOL] return True [EOL] else : [EOL] return False [EOL] [EOL] [EOL] API = ( TitleMatcher , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Optional , Any , List [EOL] import typing [EOL] import threading [EOL] import logging [EOL] import core [EOL] import datetime [EOL] import builtins [EOL] import threading [EOL] import logging [EOL] [EOL] import datetime [EOL] import traceback [EOL] from typing import Optional [EOL] [EOL] import django . utils . timezone as django_tz [EOL] [EOL] from core . base . setup import Settings [EOL] from viewer . models import Scheduler [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class BaseScheduler ( object ) : [EOL] [EOL] thread_name = [string] [EOL] [EOL] def __init__ ( self , settings , web_queue = None , timer = [number] , pk = None ) : [EOL] self . settings = settings [EOL] self . stop = threading . Event ( ) [EOL] self . web_queue = web_queue [EOL] self . original_timer = timer [EOL] self . timer = self . timer_to_seconds ( timer ) [EOL] self . job_thread = None [EOL] self . last_run = None [EOL] self . force_run_once = False [EOL] self . pk = pk [EOL] [EOL] @ staticmethod def timer_to_seconds ( timer ) : [EOL] return timer * [number] * [number] [EOL] [EOL] def wait_until_next_run ( self ) : [EOL] if self . force_run_once : [EOL] self . force_run_once = False [EOL] return [number] [EOL] if self . last_run : [EOL] seconds_until = ( self . last_run + datetime . timedelta ( seconds = int ( self . timer ) ) - django_tz . now ( ) ) . total_seconds ( ) [EOL] else : [EOL] seconds_until = [number] [EOL] if seconds_until < [number] : [EOL] seconds_until = [number] [EOL] return seconds_until [EOL] [EOL] def update_last_run ( self , last_run ) : [EOL] schedule = Scheduler . objects . get ( pk = self . pk ) [EOL] if schedule : [EOL] schedule . last_run = last_run [EOL] schedule . save ( ) [EOL] self . last_run = last_run [EOL] [EOL] def job_container ( self ) : [EOL] try : [EOL] self . job ( ) [EOL] except BaseException : [EOL] logger . critical ( traceback . format_exc ( ) ) [EOL] [EOL] def job ( self ) : [EOL] raise NotImplementedError [EOL] [EOL] def start_running ( self , timer = None ) : [EOL] [EOL] if self . is_running ( ) : [EOL] return [EOL] [EOL] schedule = Scheduler . objects . get ( pk = self . pk ) [EOL] if schedule : [EOL] self . last_run = schedule . last_run [EOL] [EOL] if timer : [EOL] self . timer = self . timer_to_seconds ( timer ) [EOL] self . stop . clear ( ) [EOL] self . job_thread = threading . Thread ( name = self . thread_name , target = self . job_container ) [EOL] self . job_thread . daemon = True [EOL] self . job_thread . start ( ) [EOL] [EOL] def is_running ( self ) : [EOL] [EOL] thread_list = threading . enumerate ( ) [EOL] for thread in thread_list : [EOL] if thread . name == self . thread_name : [EOL] return True [EOL] [EOL] return False [EOL] [EOL] def stop_running ( self ) : [EOL] [EOL] self . stop . set ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $None$ 0 0 0 $core.base.setup.Settings$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.setup.Settings$ 0 $core.base.setup.Settings$ 0 0 0 $threading.Event$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[threading.Thread]$ 0 0 0 0 0 $typing.Optional[datetime.datetime]$ 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 $builtins.float$ 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $builtins.int$ 0 0 0 0 $builtins.int$ 0 0 0 0 $builtins.int$ 0 0 0 $None$ 0 0 0 $typing.Optional[datetime.datetime]$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 $typing.Optional[datetime.datetime]$ 0 $typing.Optional[datetime.datetime]$ 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Optional[datetime.datetime]$ 0 $typing.Optional[datetime.datetime]$ 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Optional[datetime.datetime]$ 0 $typing.Any$ 0 $typing.Optional[datetime.datetime]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[threading.Thread]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[threading.Thread]$ 0 0 0 0 0 0 0 $typing.Optional[threading.Thread]$ 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 $typing.List[threading.Thread]$ 0 0 0 0 0 0 0 0 0 0 $typing.List[threading.Thread]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0
import logging [EOL] import builtins [EOL] import core [EOL] import logging [EOL] [EOL] import django . utils . timezone as django_tz [EOL] from django . db import connection [EOL] [EOL] from core . base . setup import Settings [EOL] from core . workers . schedulers import BaseScheduler [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class ProviderTimedAutoCrawler ( BaseScheduler ) : [EOL] [EOL] thread_name = [string] [EOL] [EOL] def __init__ ( self , settings , provider_name , web_queue = None , timer = [number] , pk = None ) : [EOL] self . provider_name = provider_name [EOL] self . thread_name = [string] + provider_name [EOL] super ( ) . __init__ ( settings , web_queue , timer , pk ) [EOL] [EOL] @ staticmethod def timer_to_seconds ( timer ) : [EOL] return timer * [number] * [number] [EOL] [EOL] def job ( self ) : [EOL] while not self . stop . is_set ( ) : [EOL] seconds_to_wait = self . wait_until_next_run ( ) [EOL] if self . stop . wait ( timeout = seconds_to_wait ) : [EOL] return [EOL] if self . settings . providers [ self . provider_name ] . autochecker_enable : [EOL] connection . close ( ) [EOL] logger . info ( [string] . format ( self . provider_name ) ) [EOL] current_settings = Settings ( load_from_config = self . settings . config ) [EOL] current_settings . silent_processing = True [EOL] current_settings . replace_metadata = True [EOL] self . web_queue . enqueue_args_list ( [ [string] , [string] , [string] , self . provider_name ] , override_options = current_settings ) [EOL] [EOL] self . update_last_run ( django_tz . now ( ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Callable , Iterable , Dict , Optional , List [EOL] from collections import deque [EOL] import collections [EOL] import typing [EOL] import threading [EOL] import logging [EOL] import core [EOL] import builtins [EOL] import threading [EOL] import traceback [EOL] from collections import deque [EOL] [EOL] import logging [EOL] import typing [EOL] from typing import Iterable , Optional , Callable , List [EOL] [EOL] from core . base . setup import Settings [EOL] from core . base . types import QueueItem [EOL] from core . web . crawlerthread import WebCrawler [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from viewer . models import Gallery , Archive [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class WebQueue ( object ) : [EOL] [EOL] [docstring] [EOL] [EOL] def __init__ ( self , settings ) : [EOL] self . settings = settings [EOL] self . queue = deque ( ) [EOL] self . web_queue_thread = None [EOL] self . current_processing_items = [ ] [EOL] self . thread_name = [string] [EOL] [EOL] def web_worker ( self ) : [EOL] while True : [EOL] try : [EOL] item = self . queue . popleft ( ) [EOL] except IndexError : [EOL] return [EOL] try : [EOL] self . current_processing_items = item [EOL] web_crawler = WebCrawler ( self . settings ) [EOL] web_crawler . start_crawling ( item [ [string] ] , override_options = item [ [string] ] , archive_callback = item . get ( [string] , None ) , gallery_callback = item . get ( [string] , None ) , use_argparser = item . get ( [string] , True ) ) [EOL] self . current_processing_items = [ ] [EOL] except BaseException : [EOL] logger . critical ( traceback . format_exc ( ) ) [EOL] [EOL] def start_running ( self ) : [EOL] [EOL] if self . is_running ( ) : [EOL] return [EOL] if self . current_processing_items : [EOL] self . queue . append ( self . current_processing_items ) [EOL] self . current_processing_items = [ ] [EOL] self . web_queue_thread = threading . Thread ( name = self . thread_name , target = self . web_worker ) [EOL] self . web_queue_thread . daemon = True [EOL] self . web_queue_thread . start ( ) [EOL] [EOL] def is_running ( self ) : [EOL] [EOL] thread_list = threading . enumerate ( ) [EOL] for thread in thread_list : [EOL] if thread . name == self . thread_name : [EOL] return True [EOL] [EOL] return False [EOL] [EOL] def queue_size ( self ) : [EOL] [EOL] return len ( self . queue ) [EOL] [EOL] def remove_by_index ( self , index ) : [EOL] [EOL] try : [EOL] del self . queue [ index ] [EOL] return True [EOL] except IndexError : [EOL] return False [EOL] [EOL] def enqueue_args ( self , args ) : [EOL] [EOL] self . queue . append ( { [string] : args . split ( ) , [string] : None } ) [EOL] self . start_running ( ) [EOL] [EOL] def enqueue_args_list ( self , args , override_options = None , archive_callback = None , gallery_callback = None , use_argparser = True ) : [EOL] [EOL] self . queue . append ( { [string] : args , [string] : override_options , [string] : archive_callback , [string] : gallery_callback , [string] : use_argparser , } ) [EOL] self . start_running ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0
	0
from typing import Any , Tuple , List [EOL] import logging [EOL] import typing [EOL] import builtins [EOL] import core [EOL] import logging [EOL] from datetime import timedelta [EOL] [EOL] import django . utils . timezone as django_tz [EOL] from django . db import connection [EOL] [EOL] from core . base . setup import Settings [EOL] from core . workers . schedulers import BaseScheduler [EOL] from viewer . models import Gallery [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] class TimedAutoUpdater ( BaseScheduler ) : [EOL] [EOL] thread_name = [string] [EOL] [EOL] @ staticmethod def timer_to_seconds ( timer ) : [EOL] return timer * [number] * [number] * [number] [EOL] [EOL] def job ( self ) : [EOL] while not self . stop . is_set ( ) : [EOL] [EOL] seconds_to_wait = self . wait_until_next_run ( ) [EOL] if self . stop . wait ( timeout = seconds_to_wait ) : [EOL] return [EOL] [EOL] if self . settings . autoupdater . enable : [EOL] current_settings = Settings ( load_from_config = self . settings . config ) [EOL] current_settings . keep_dl_type = True [EOL] current_settings . silent_processing = True [EOL] current_settings . config [ [string] ] [ [string] ] = [string] [EOL] [EOL] connection . close ( ) [EOL] [EOL] start_date = django_tz . now ( ) - timedelta ( seconds = int ( self . timer ) ) - timedelta ( days = self . settings . autoupdater . buffer_back ) [EOL] end_date = django_tz . now ( ) - timedelta ( days = self . settings . autoupdater . buffer_after ) [EOL] to_update_providers = current_settings . autoupdater . providers [EOL] [EOL] galleries = Gallery . objects . eligible_for_use ( posted__gte = start_date , posted__lte = end_date , provider__in = to_update_providers ) [EOL] [EOL] if not galleries : [EOL] logger . info ( [string] . format ( start_date , end_date , [string] . join ( to_update_providers ) ) ) [EOL] else : [EOL] [comment] [EOL] downloaders = current_settings . provider_context . get_downloaders_name_priority ( current_settings , filter_name = [string] ) [EOL] downloaders_names = [ x [ [number] ] for x in downloaders if x [ [number] ] . replace ( [string] , [string] ) in to_update_providers ] [EOL] [EOL] current_settings . allow_downloaders_only ( downloaders_names , True , True , True ) [EOL] [EOL] url_list = [ x . get_link ( ) for x in galleries ] [EOL] [EOL] logger . info ( [string] [string] . format ( len ( url_list ) , start_date , end_date , [string] . join ( to_update_providers ) ) ) [EOL] [EOL] url_list . append ( [string] ) [EOL] [EOL] self . web_queue . enqueue_args_list ( url_list , override_options = current_settings ) [EOL] [EOL] self . update_last_run ( django_tz . now ( ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.int]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.int]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import threading [EOL] import logging [EOL] import typing [EOL] import builtins [EOL] import threading [EOL] import logging [EOL] [EOL] import django . utils . timezone as django_tz [EOL] from django . db import connection [EOL] [EOL] from core . workers . schedulers import BaseScheduler [EOL] from viewer . models import Attribute [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class TimedAutoWanted ( BaseScheduler ) : [EOL] [EOL] thread_name = [string] [EOL] [EOL] @ staticmethod def timer_to_seconds ( timer ) : [EOL] return timer * [number] * [number] [EOL] [EOL] def job ( self ) : [EOL] while not self . stop . is_set ( ) : [EOL] seconds_to_wait = self . wait_until_next_run ( ) [EOL] if self . stop . wait ( timeout = seconds_to_wait ) : [EOL] return [EOL] if self . settings . auto_wanted . enable : [EOL] logger . info ( [string] ) [EOL] connection . close ( ) [EOL] for provider_name in self . settings . auto_wanted . providers : [EOL] [EOL] attrs = Attribute . objects . filter ( provider__slug = provider_name ) [EOL] [EOL] for count , wanted_generator in enumerate ( self . settings . provider_context . get_wanted_generators ( provider_name ) ) : [EOL] [comment] [EOL] wanted_generator_thread = threading . Thread ( name = [string] . format ( self . thread_name , provider_name , count ) , target = wanted_generator , args = ( self . settings , attrs ) ) [EOL] wanted_generator_thread . daemon = True [EOL] wanted_generator_thread . start ( ) [EOL] [EOL] self . update_last_run ( django_tz . now ( ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List [EOL] import queue [EOL] import typing [EOL] import threading [EOL] import logging [EOL] import builtins [EOL] import threading [EOL] import queue [EOL] [EOL] import logging [EOL] import traceback [EOL] import typing [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from viewer . models import Archive [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class ImageWorker ( object ) : [EOL] [EOL] [docstring] [EOL] [EOL] def __init__ ( self , worker_number ) : [EOL] [EOL] self . worker_number = worker_number + [number] [EOL] self . web_queue = queue . Queue ( ) [EOL] [EOL] def thumbnails_worker ( self ) : [EOL] [EOL] while True : [EOL] try : [EOL] item = self . web_queue . get_nowait ( ) [EOL] except queue . Empty : [EOL] return [EOL] try : [EOL] item . generate_thumbnails ( ) [EOL] self . web_queue . task_done ( ) [EOL] except BaseException : [EOL] logger . critical ( traceback . format_exc ( ) ) [EOL] [EOL] def file_info_worker ( self ) : [EOL] [EOL] while True : [EOL] try : [EOL] item = self . web_queue . get_nowait ( ) [EOL] except queue . Empty : [EOL] return [EOL] try : [EOL] item . recalc_fileinfo ( ) [EOL] self . web_queue . task_done ( ) [EOL] except BaseException : [EOL] logger . critical ( traceback . format_exc ( ) ) [EOL] [EOL] def start_info_thread ( self ) : [EOL] [EOL] thread_array = [ ] [EOL] [EOL] for x in range ( [number] , self . worker_number ) : [EOL] file_info_thread = threading . Thread ( name = [string] + str ( x ) , target = self . file_info_worker ) [EOL] file_info_thread . daemon = True [EOL] file_info_thread . start ( ) [EOL] thread_array . append ( file_info_thread ) [EOL] [EOL] for thread in thread_array : [EOL] thread . join ( ) [EOL] [EOL] logger . info ( [string] ) [EOL] [EOL] def start_thumbs_thread ( self ) : [EOL] [EOL] thread_array = [ ] [EOL] [EOL] for x in range ( [number] , self . worker_number ) : [EOL] thumbnail_thread = threading . Thread ( name = [string] + str ( x ) , target = self . thumbnails_worker ) [EOL] thumbnail_thread . daemon = True [EOL] thumbnail_thread . start ( ) [EOL] thread_array . append ( thumbnail_thread ) [EOL] [EOL] for thread in thread_array : [EOL] thread . join ( ) [EOL] [EOL] logger . info ( [string] ) [EOL] [EOL] def enqueue_archive ( self , archive ) : [EOL] [EOL] self . web_queue . put ( archive ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $'Archive'$ 0 0 0 0 0 0 0 0 0 0 $'Archive'$ 0 0
from typing import Any , Callable , Iterable , Dict , Tuple , Optional , Set , Union , List [EOL] import typing [EOL] import viewer [EOL] import logging [EOL] import core [EOL] import django [EOL] import builtins [EOL] import copy [EOL] import json [EOL] import typing [EOL] from datetime import datetime , timezone [EOL] import time [EOL] from typing import List , Optional , Dict , Iterable , Tuple , Callable [EOL] [EOL] import django . utils . timezone as django_tz [EOL] import logging [EOL] [EOL] import traceback [EOL] [EOL] from collections import defaultdict [EOL] [EOL] from django . db . models import QuerySet , Q , Value , CharField , F [EOL] from django . db . models . functions import Concat , Replace [EOL] [EOL] from core . base import utilities [EOL] from core . base . utilities import send_pushover_notification , chunks [EOL] from core . base . types import GalleryData [EOL] from viewer . signals import wanted_gallery_found [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from core . downloaders . handlers import BaseDownloader [EOL] from core . base . setup import Settings [EOL] from viewer . models import Gallery , WantedGallery , Archive [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class BaseParser : [EOL] name = [string] [EOL] ignore = False [EOL] accepted_urls = [ ] [EOL] [EOL] def __init__ ( self , settings ) : [EOL] self . settings = settings [EOL] if self . name in settings . providers : [EOL] self . own_settings = settings . providers [ self . name ] [EOL] else : [EOL] self . own_settings = None [EOL] self . general_utils = utilities . GeneralUtils ( self . settings ) [EOL] self . downloaders = self . settings . provider_context . get_downloaders ( self . settings , self . general_utils , filter_name = self . name ) [EOL] self . last_used_downloader = [string] [EOL] self . archive_callback = None [EOL] self . gallery_callback = None [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] def fetch_gallery_data ( self , url ) : [EOL] return None [EOL] [EOL] def fetch_multiple_gallery_data ( self , url_list ) : [EOL] return None [EOL] [EOL] @ classmethod def filter_accepted_urls ( cls , urls ) : [EOL] return [ x for x in urls if any ( word in x for word in cls . accepted_urls ) ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] def discard_gallery_by_internal_checks ( self , gallery_id = None , link = [string] , gallery = None ) : [EOL] [EOL] if self . settings . update_metadata_mode : [EOL] return False , [string] . format ( ext_link = link , ) [EOL] if not gallery and ( gallery_id and self . settings . gallery_model ) : [EOL] gallery = self . settings . gallery_model . objects . filter_first ( gid = gallery_id , provider = self . name ) [EOL] if not gallery : [EOL] return False , [string] . format ( ext_link = link , ) [EOL] [EOL] if gallery . is_submitted ( ) : [EOL] message = [string] . format ( ext_link = gallery . get_link ( ) , link = gallery . get_absolute_url ( ) , title = gallery . title , ) [EOL] return False , message [EOL] [EOL] if not self . settings . retry_failed and ( [string] in gallery . dl_type ) : [EOL] message = [string] [string] . format ( ext_link = gallery . get_link ( ) , link = gallery . get_absolute_url ( ) , title = gallery . title , ) [EOL] return True , message [EOL] [EOL] if gallery . archive_set . all ( ) and not self . settings . redownload : [EOL] message = [string] [string] . format ( ext_link = gallery . get_link ( ) , link = gallery . get_absolute_url ( ) , title = gallery . title , dl_type = gallery . dl_type ) [EOL] return True , message [EOL] [EOL] if not gallery . archive_set . all ( ) and not self . settings . replace_metadata : [EOL] message = [string] . format ( ext_link = gallery . get_link ( ) , link = gallery . get_absolute_url ( ) , title = gallery . title , ) [EOL] return True , message [EOL] [EOL] if [string] in gallery . dl_type : [EOL] message = [string] . format ( ext_link = gallery . get_link ( ) , link = gallery . get_absolute_url ( ) , title = gallery . title , ) [EOL] return True , message [EOL] [EOL] if gallery . is_deleted ( ) : [EOL] message = [string] . format ( ext_link = gallery . get_link ( ) , link = gallery . get_absolute_url ( ) , title = gallery . title , ) [EOL] return True , message [EOL] [EOL] message = [string] . format ( ext_link = gallery . get_link ( ) , link = gallery . get_absolute_url ( ) , title = gallery . title , ) [EOL] return False , message [EOL] [EOL] [comment] [EOL] def compare_gallery_with_wanted_filters ( self , gallery , link , wanted_filters , gallery_wanted_lists ) : [EOL] [EOL] if not self . settings . found_gallery_model : [EOL] logger . error ( [string] ) [EOL] return [EOL] [EOL] if gallery . title or gallery . title_jpn : [EOL] q_objects = Q ( ) [EOL] q_objects_unwanted = Q ( ) [EOL] q_objects_regexp = Q ( ) [EOL] q_objects_unwanted_regexp = Q ( ) [EOL] if gallery . title : [EOL] wanted_filters = wanted_filters . annotate ( g_title = Value ( gallery . title , output_field = CharField ( ) ) ) [EOL] [EOL] q_objects . add ( Q ( g_title__ss = Concat ( Value ( [string] ) , Replace ( F ( [string] ) , Value ( [string] ) , Value ( [string] ) ) , Value ( [string] ) ) ) , Q . OR ) [EOL] q_objects_unwanted . add ( ~ Q ( g_title__ss = Concat ( Value ( [string] ) , Replace ( F ( [string] ) , Value ( [string] ) , Value ( [string] ) ) , Value ( [string] ) ) ) , Q . AND ) [EOL] [EOL] q_objects_regexp . add ( Q ( g_title__regex = F ( [string] ) ) , Q . OR ) [EOL] q_objects_unwanted_regexp . add ( ~ Q ( g_title__regex = F ( [string] ) ) , Q . AND ) [EOL] [EOL] if gallery . title_jpn : [EOL] wanted_filters = wanted_filters . annotate ( g_title_jpn = Value ( gallery . title_jpn , output_field = CharField ( ) ) ) [EOL] q_objects . add ( Q ( g_title_jpn__ss = Concat ( Value ( [string] ) , Replace ( F ( [string] ) , Value ( [string] ) , Value ( [string] ) ) , Value ( [string] ) ) ) , Q . OR ) [EOL] q_objects_unwanted . add ( ~ Q ( g_title_jpn__ss = Concat ( Value ( [string] ) , Replace ( F ( [string] ) , Value ( [string] ) , Value ( [string] ) ) , Value ( [string] ) ) ) , Q . AND ) [EOL] [EOL] q_objects_regexp . add ( Q ( g_title_jpn__regex = F ( [string] ) ) , Q . OR ) [EOL] q_objects_unwanted_regexp . add ( ~ Q ( g_title_jpn__regex = F ( [string] ) ) , Q . AND ) [EOL] [EOL] filtered_wanted = wanted_filters . filter ( Q ( search_title__isnull = True ) | Q ( search_title = [string] ) | Q ( Q ( regexp_search_title = False ) , q_objects ) | Q ( Q ( regexp_search_title = True ) , q_objects_regexp ) ) . filter ( Q ( unwanted_title__isnull = True ) | Q ( unwanted_title = [string] ) | Q ( Q ( regexp_unwanted_title = False ) , q_objects_unwanted ) | Q ( Q ( regexp_unwanted_title = True ) , q_objects_unwanted_regexp ) ) [EOL] [EOL] else : [EOL] filtered_wanted = wanted_filters . filter ( Q ( search_title__isnull = True ) | Q ( search_title = [string] ) ) . filter ( Q ( unwanted_title__isnull = True ) | Q ( unwanted_title = [string] ) ) [EOL] [EOL] for wanted_filter in filtered_wanted : [EOL] [comment] [EOL] already_found = self . settings . found_gallery_model . objects . filter ( wanted_gallery__pk = wanted_filter . pk , gallery__gid = gallery . gid , gallery__provider = self . name ) . first ( ) [EOL] [comment] [EOL] if already_found and not already_found . gallery . is_submitted ( ) : [EOL] continue [EOL] [comment] [EOL] if wanted_filter . provider and wanted_filter . provider != self . name : [EOL] continue [EOL] if wanted_filter . wanted_providers . count ( ) : [EOL] if not wanted_filter . wanted_providers . filter ( slug = self . name ) . first ( ) : [EOL] continue [EOL] accepted = True [EOL] if bool ( wanted_filter . wanted_tags . all ( ) ) : [EOL] if not set ( wanted_filter . wanted_tags_list ( ) ) . issubset ( set ( gallery . tags ) ) : [EOL] accepted = False [EOL] [comment] [EOL] if accepted & wanted_filter . wanted_tags_exclusive_scope : [EOL] accepted_tags = set ( wanted_filter . wanted_tags_list ( ) ) . intersection ( set ( gallery . tags ) ) [EOL] gallery_tags_scopes = [ x . split ( [string] , maxsplit = [number] ) [ [number] ] for x in gallery . tags if len ( x ) > [number] ] [EOL] wanted_gallery_tags_scopes = [ x . split ( [string] , maxsplit = [number] ) [ [number] ] for x in accepted_tags if len ( x ) > [number] ] [EOL] scope_count = { } [EOL] for scope_name in gallery_tags_scopes : [EOL] if scope_name in wanted_gallery_tags_scopes : [EOL] if scope_name not in scope_count : [EOL] scope_count [ scope_name ] = [number] [EOL] else : [EOL] scope_count [ scope_name ] += [number] [EOL] for scope , count in scope_count . items ( ) : [EOL] if count > [number] : [EOL] accepted = False [EOL] if accepted & bool ( wanted_filter . unwanted_tags . all ( ) ) : [EOL] if set ( wanted_filter . unwanted_tags_list ( ) ) . issubset ( set ( gallery . tags ) ) : [EOL] accepted = False [EOL] if accepted and wanted_filter . wanted_page_count_lower and gallery . filecount is not None and gallery . filecount : [EOL] accepted = gallery . filecount >= wanted_filter . wanted_page_count_lower [EOL] if accepted and wanted_filter . wanted_page_count_upper and gallery . filecount is not None and gallery . filecount : [EOL] accepted = gallery . filecount <= wanted_filter . wanted_page_count_upper [EOL] if accepted and wanted_filter . category and gallery . category is not None and gallery . category : [EOL] accepted = ( wanted_filter . category . lower ( ) == gallery . category . lower ( ) ) [EOL] [EOL] if accepted : [EOL] gallery_wanted_lists [ gallery . gid ] . append ( wanted_filter ) [EOL] wanted_filter . found = True [EOL] wanted_filter . date_found = django_tz . now ( ) [EOL] wanted_filter . save ( ) [EOL] if len ( gallery_wanted_lists [ gallery . gid ] ) > [number] : [EOL] logger . info ( [string] . format ( link , gallery . title , [string] . join ( [ x . get_absolute_url ( ) for x in gallery_wanted_lists [ gallery . gid ] ] ) ) ) [EOL] [EOL] notify_wanted_filters = [ [string] . format ( ( x . title or [string] ) , ( x . reason or [string] ) ) for x in gallery_wanted_lists [ gallery . gid ] if x . notify_when_found ] [EOL] [EOL] if notify_wanted_filters and self . settings . pushover . enable : [EOL] [EOL] message = [string] . format ( gallery . title , link , [string] . join ( notify_wanted_filters ) ) [EOL] [EOL] send_pushover_notification ( self . settings . pushover . user_key , self . settings . pushover . token , message , device = self . settings . pushover . device , sound = self . settings . pushover . sound , title = [string] ) [EOL] return [EOL] [EOL] @ staticmethod def id_from_url ( url ) : [EOL] pass [EOL] [EOL] @ classmethod def id_from_url_implemented ( cls ) : [EOL] if cls . id_from_url is not BaseParser . id_from_url : [EOL] return True [EOL] return False [EOL] [EOL] @ staticmethod def get_feed_urls ( ) : [EOL] pass [EOL] [EOL] def crawl_feed ( self , feed_url = [string] ) : [EOL] pass [EOL] [EOL] def feed_urls_implemented ( self ) : [EOL] if type ( self ) . crawl_feed is not BaseParser . crawl_feed and type ( self ) . get_feed_urls is not BaseParser . get_feed_urls : [EOL] return True [EOL] return False [EOL] [EOL] def crawl_urls_caller ( self , urls , wanted_filters = None , wanted_only = False ) : [EOL] try : [EOL] self . crawl_urls ( urls , wanted_filters = wanted_filters , wanted_only = wanted_only ) [EOL] except BaseException : [EOL] logger . critical ( traceback . format_exc ( ) ) [EOL] [EOL] def crawl_urls ( self , urls , wanted_filters = None , wanted_only = False ) : [EOL] pass [EOL] [EOL] def pass_gallery_data_to_downloaders ( self , gallery_data_list , gallery_wanted_lists ) : [EOL] gallery_count = len ( gallery_data_list ) [EOL] [EOL] if gallery_count == [number] : [EOL] logger . info ( [string] ) [EOL] return [EOL] else : [EOL] logger . info ( [string] . format ( gallery_count ) ) [EOL] [EOL] if not self . settings . update_metadata_mode : [EOL] downloaders_msg = [string] [EOL] [EOL] for downloader in self . downloaders : [EOL] downloaders_msg += [string] . format ( downloader [ [number] ] , downloader [ [number] ] ) [EOL] logger . info ( downloaders_msg ) [EOL] [EOL] for i , gallery in enumerate ( gallery_data_list , start = [number] ) : [EOL] if not self . last_used_downloader . endswith ( [string] ) and not self . last_used_downloader . endswith ( [string] ) : [EOL] if self . own_settings : [EOL] time . sleep ( self . own_settings . wait_timer ) [EOL] else : [EOL] time . sleep ( self . settings . wait_timer ) [EOL] logger . info ( [string] . format ( i , gallery_count ) ) [EOL] if self . settings . add_as_public : [EOL] gallery . public = True [EOL] self . work_gallery_data ( gallery , gallery_wanted_lists ) [EOL] [EOL] def work_gallery_data ( self , gallery , gallery_wanted_lists ) : [EOL] [EOL] if not self . settings . found_gallery_model : [EOL] logger . error ( [string] ) [EOL] return [EOL] [EOL] if gallery . title is not None : [EOL] logger . info ( [string] . format ( gallery . title , gallery . link ) ) [EOL] else : [EOL] logger . info ( [string] . format ( gallery . link ) ) [EOL] [EOL] for cnt , downloader in enumerate ( self . downloaders ) : [EOL] downloader [ [number] ] . init_download ( copy . deepcopy ( gallery ) ) [EOL] if downloader [ [number] ] . return_code == [number] : [EOL] self . last_used_downloader = str ( downloader [ [number] ] ) [EOL] if not downloader [ [number] ] . archive_only : [EOL] for wanted_gallery in gallery_wanted_lists [ gallery . gid ] : [EOL] self . settings . found_gallery_model . objects . get_or_create ( wanted_gallery = wanted_gallery , gallery = downloader [ [number] ] . gallery_db_entry ) [EOL] if wanted_gallery . add_as_hidden and downloader [ [number] ] . gallery_db_entry : [EOL] downloader [ [number] ] . gallery_db_entry . hidden = True [EOL] downloader [ [number] ] . gallery_db_entry . save ( ) [EOL] if downloader [ [number] ] . archive_db_entry and wanted_gallery . reason : [EOL] downloader [ [number] ] . archive_db_entry . reason = wanted_gallery . reason [EOL] downloader [ [number] ] . archive_db_entry . simple_save ( ) [EOL] [EOL] if len ( gallery_wanted_lists [ gallery . gid ] ) > [number] : [EOL] wanted_gallery_found . send ( sender = self . settings . gallery_model , gallery = downloader [ [number] ] . gallery_db_entry , wanted_gallery_list = gallery_wanted_lists [ gallery . gid ] ) [EOL] if downloader [ [number] ] . archive_db_entry : [EOL] if not downloader [ [number] ] . archive_only and downloader [ [number] ] . gallery_db_entry : [EOL] logger . info ( [string] . format ( downloader [ [number] ] , downloader [ [number] ] . archive_db_entry . get_absolute_url ( ) , downloader [ [number] ] . gallery_db_entry . get_absolute_url ( ) ) ) [EOL] if self . gallery_callback : [EOL] self . gallery_callback ( downloader [ [number] ] . gallery_db_entry , gallery . link , [string] ) [EOL] if self . archive_callback : [EOL] self . archive_callback ( downloader [ [number] ] . archive_db_entry , gallery . link , [string] ) [EOL] else : [EOL] logger . info ( [string] . format ( downloader [ [number] ] , downloader [ [number] ] . archive_db_entry . get_absolute_url ( ) , ) ) [EOL] if self . archive_callback : [EOL] self . archive_callback ( downloader [ [number] ] . archive_db_entry , gallery . link , [string] ) [EOL] elif downloader [ [number] ] . gallery_db_entry : [EOL] logger . info ( [string] . format ( downloader [ [number] ] , downloader [ [number] ] . gallery_db_entry . get_absolute_url ( ) ) ) [EOL] if self . gallery_callback : [EOL] self . gallery_callback ( downloader [ [number] ] . gallery_db_entry , gallery . link , [string] ) [EOL] return [EOL] elif downloader [ [number] ] . return_code == [number] and ( cnt + [number] ) == len ( self . downloaders ) : [EOL] self . last_used_downloader = [string] [EOL] if not downloader [ [number] ] . archive_only : [EOL] downloader [ [number] ] . original_gallery = gallery [EOL] downloader [ [number] ] . original_gallery . dl_type = [string] [EOL] downloader [ [number] ] . update_gallery_db ( ) [EOL] if downloader [ [number] ] . gallery_db_entry : [EOL] logger . warning ( [string] [string] . format ( downloader [ [number] ] , downloader [ [number] ] . gallery_db_entry . get_absolute_url ( ) ) ) [EOL] if self . gallery_callback : [EOL] self . gallery_callback ( downloader [ [number] ] . gallery_db_entry , gallery . link , [string] ) [EOL] for wanted_gallery in gallery_wanted_lists [ gallery . gid ] : [EOL] self . settings . found_gallery_model . objects . get_or_create ( wanted_gallery = wanted_gallery , gallery = downloader [ [number] ] . gallery_db_entry ) [EOL] else : [EOL] logger . warning ( [string] [string] . format ( downloader [ [number] ] ) ) [EOL] else : [EOL] logger . warning ( [string] [string] . format ( downloader [ [number] ] ) ) [EOL] if self . gallery_callback : [EOL] self . gallery_callback ( None , gallery . link , [string] ) [EOL] else : [EOL] logger . info ( [string] . format ( downloader [ [number] ] , ) ) [EOL] [EOL] [EOL] [comment] [EOL] class InternalParser ( BaseParser ) : [EOL] name = [string] [EOL] ignore = True [EOL] [EOL] def crawl_json ( self , json_string , wanted_filters = None , wanted_only = False ) : [EOL] [EOL] if not self . settings . gallery_model : [EOL] return [EOL] [EOL] dict_list = [ ] [EOL] json_decoded = json . loads ( json_string ) [EOL] [EOL] if type ( json_decoded ) == dict : [EOL] dict_list . append ( json_decoded ) [EOL] elif type ( json_decoded ) == list : [EOL] dict_list = json_decoded [EOL] [EOL] galleries_gids = [ ] [EOL] found_galleries = set ( ) [EOL] total_galleries_filtered = [ ] [EOL] gallery_wanted_lists = defaultdict ( list ) [EOL] [EOL] for gallery in dict_list : [EOL] galleries_gids . append ( gallery [ [string] ] ) [EOL] gallery [ [string] ] = datetime . fromtimestamp ( int ( gallery [ [string] ] ) , timezone . utc ) [EOL] gallery_data = GalleryData ( ** gallery ) [EOL] total_galleries_filtered . append ( gallery_data ) [EOL] [EOL] for galleries_gid_group in list ( chunks ( galleries_gids , [number] ) ) : [EOL] for found_gallery in self . settings . gallery_model . objects . filter ( gid__in = galleries_gid_group ) : [EOL] discard_approved , discard_message = self . discard_gallery_by_internal_checks ( gallery = found_gallery , link = found_gallery . get_link ( ) ) [EOL] [EOL] if discard_approved : [EOL] logger . info ( discard_message ) [EOL] found_galleries . add ( found_gallery . gid ) [EOL] [EOL] for count , gallery in enumerate ( total_galleries_filtered ) : [EOL] [EOL] if gallery . gid in found_galleries : [EOL] continue [EOL] [EOL] if self . general_utils . discard_by_tag_list ( gallery . tags ) : [EOL] logger . info ( [string] . format ( count , len ( total_galleries_filtered ) , gallery . title ) ) [EOL] continue [EOL] [EOL] if wanted_filters : [EOL] self . compare_gallery_with_wanted_filters ( gallery , gallery . link , wanted_filters , gallery_wanted_lists ) [EOL] if wanted_only and not gallery_wanted_lists [ gallery . gid ] : [EOL] continue [EOL] [EOL] logger . info ( [string] . format ( count , len ( total_galleries_filtered ) , gallery . title ) ) [EOL] [EOL] if gallery . thumbnail : [EOL] original_thumbnail_url = gallery . thumbnail_url [EOL] [EOL] gallery . thumbnail_url = gallery . thumbnail [EOL] [EOL] gallery_instance = self . settings . gallery_model . objects . update_or_create_from_values ( gallery ) [EOL] [EOL] gallery_instance . thumbnail_url = original_thumbnail_url [EOL] [EOL] gallery_instance . save ( ) [EOL] else : [EOL] self . settings . gallery_model . objects . update_or_create_from_values ( gallery ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.bool]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.GalleryData$ 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.bool$ 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 $django.db.models.QuerySet$ 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 $typing.List[typing.Any]$ 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 0 0 0 $django.db.models.QuerySet$ 0 0 0 0 0 0 0 0 0 0 0 0 $django.db.models.QuerySet$ 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 $builtins.bool$ 0 0 $typing.Dict[builtins.str,typing.List['WantedGallery']]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Type , Callable , Tuple , Optional , List [EOL] import typing [EOL] import types [EOL] import _importlib_modulespec [EOL] import logging [EOL] import core [EOL] import builtins [EOL] import importlib [EOL] import inspect [EOL] import logging [EOL] from operator import itemgetter [EOL] from types import ModuleType [EOL] from typing import List , Callable , Optional , Tuple , Union , Type [EOL] import typing [EOL] [EOL] from core . base . types import ProviderSettings [EOL] from core . base . utilities import GeneralUtils [EOL] from core . base . matchers import Matcher [EOL] from core . base . parsers import BaseParser [EOL] from core . downloaders . handlers import BaseDownloader [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from viewer import models [EOL] from core . base import setup [EOL] [EOL] [EOL] AcceptableModules = Union [ Type [ [string] ] , Type [ [string] ] , Type [ [string] ] ] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def _get_provider_submodule_api ( module_name , submodule_name ) : [EOL] sub_module = [string] . format ( module_name , submodule_name ) [EOL] try : [EOL] importlib . import_module ( module_name , package = [string] ) [EOL] except ImportError : [EOL] return [ ] [EOL] if importlib . util . find_spec ( sub_module ) : [comment] [EOL] site = importlib . import_module ( sub_module , package = module_name ) [EOL] if hasattr ( site , [string] ) : [EOL] return list ( getattr ( site , [string] ) ) [EOL] [EOL] return [ ] [EOL] [EOL] [EOL] def _get_provider_submodule_method ( module_name , submodule_name , method_name ) : [EOL] sub_module = [string] . format ( module_name , submodule_name ) [EOL] try : [EOL] importlib . import_module ( module_name , package = [string] ) [EOL] except ImportError : [EOL] return None [EOL] if importlib . util . find_spec ( sub_module ) : [comment] [EOL] site = importlib . import_module ( sub_module , package = module_name ) [EOL] if hasattr ( site , method_name ) : [EOL] obj = getattr ( site , method_name ) [EOL] if inspect . isfunction ( obj ) : [EOL] return obj [EOL] return None [EOL] [EOL] [EOL] def _get_provider_submodule ( module_name , submodule_name ) : [EOL] sub_module = [string] . format ( module_name , submodule_name ) [EOL] try : [EOL] importlib . import_module ( module_name , package = [string] ) [EOL] except ImportError : [EOL] return None [EOL] if importlib . util . find_spec ( sub_module ) : [comment] [EOL] site = importlib . import_module ( sub_module , package = module_name ) [EOL] return site [EOL] return None [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] class ProviderContext : [EOL] [EOL] parsers = [ ] [EOL] matchers = [ ] [EOL] downloaders = [ ] [EOL] resolvers = [ ] [EOL] settings_parsers = [ ] [EOL] wanted_generators = [ ] [EOL] constants = [ ] [EOL] [EOL] def register_providers ( self , module_name_list ) : [EOL] for module_name in module_name_list : [EOL] [EOL] self . register_provider ( module_name ) [EOL] [EOL] def register_provider ( self , module_name ) : [EOL] [comment] [EOL] [comment] [EOL] provider_name = module_name . split ( [string] ) [ - [number] ] [EOL] for member in _get_provider_submodule_api ( module_name , [string] ) : [EOL] if member not in self . parsers and issubclass ( member , BaseParser ) : [EOL] [comment] [EOL] self . register_parser ( member ) [EOL] for member in _get_provider_submodule_api ( module_name , [string] ) : [EOL] if member not in self . matchers and issubclass ( member , Matcher ) : [EOL] [comment] [EOL] self . register_matcher ( member ) [EOL] for member in _get_provider_submodule_api ( module_name , [string] ) : [EOL] if member not in self . downloaders and issubclass ( member , BaseDownloader ) : [EOL] [comment] [EOL] self . register_downloader ( member ) [EOL] resolver = _get_provider_submodule_method ( module_name , [string] , [string] ) [EOL] if resolver and ( provider_name , resolver ) not in self . resolvers : [EOL] [comment] [EOL] self . register_resolver ( provider_name , resolver ) [EOL] settings_parser = _get_provider_submodule_method ( module_name , [string] , [string] ) [EOL] if settings_parser and ( provider_name , settings_parser ) not in self . settings_parsers : [EOL] [comment] [EOL] self . register_settings_parser ( provider_name , settings_parser ) [EOL] wanted_generator = _get_provider_submodule_method ( module_name , [string] , [string] ) [EOL] if wanted_generator and ( provider_name , wanted_generator ) not in self . wanted_generators : [EOL] [comment] [EOL] self . register_wanted_generator ( provider_name , wanted_generator ) [EOL] constants_module = _get_provider_submodule ( module_name , [string] ) [EOL] if constants_module and ( provider_name , constants_module ) not in self . constants : [EOL] [comment] [EOL] self . register_constants ( provider_name , constants_module ) [EOL] [EOL] def register_parser ( self , obj ) : [EOL] if inspect . isclass ( obj ) : [EOL] if obj . name and not obj . ignore : [EOL] self . parsers . append ( obj ) [EOL] [EOL] def register_matcher ( self , obj ) : [EOL] if inspect . isclass ( obj ) : [EOL] if obj . provider and obj . name : [EOL] self . matchers . append ( obj ) [EOL] [EOL] def register_downloader ( self , obj ) : [EOL] if inspect . isclass ( obj ) : [EOL] if obj . provider and obj . type : [EOL] self . downloaders . append ( obj ) [EOL] [EOL] def register_resolver ( self , provider_name , obj ) : [EOL] self . resolvers . append ( ( provider_name , obj ) ) [EOL] [EOL] def register_settings_parser ( self , provider_name , obj ) : [EOL] self . settings_parsers . append ( ( provider_name , obj ) ) [EOL] [EOL] def register_wanted_generator ( self , provider_name , obj ) : [EOL] self . wanted_generators . append ( ( provider_name , obj ) ) [EOL] [EOL] def register_constants ( self , provider_name , obj ) : [EOL] self . constants . append ( ( provider_name , obj ) ) [EOL] [EOL] def get_parsers ( self , settings , filter_name = None , filter_names = None ) : [EOL] parsers_list = list ( ) [EOL] for parser in self . parsers : [EOL] parser_name = getattr ( parser , [string] ) [EOL] if filter_name : [EOL] if filter_name in parser_name : [EOL] parser_instance = parser ( settings ) [EOL] if parser_name == [string] : [EOL] parsers_list . append ( parser_instance ) [EOL] else : [EOL] parsers_list . insert ( [number] , parser_instance ) [EOL] elif filter_names : [EOL] for current_filter_name in filter_names : [EOL] if current_filter_name in parser_name : [EOL] parser_instance = parser ( settings ) [EOL] if parser_name == [string] : [EOL] parsers_list . append ( parser_instance ) [EOL] else : [EOL] parsers_list . insert ( [number] , parser_instance ) [EOL] else : [EOL] parser_instance = parser ( settings ) [EOL] if parser_name == [string] : [EOL] parsers_list . append ( parser_instance ) [EOL] else : [EOL] parsers_list . insert ( [number] , parser_instance ) [EOL] [EOL] return parsers_list [EOL] [EOL] def get_parsers_classes ( self , filter_name = None ) : [EOL] parsers_list = list ( ) [EOL] for parser in self . parsers : [EOL] parser_name = getattr ( parser , [string] ) [EOL] if filter_name : [EOL] if filter_name in parser_name : [EOL] if parser_name == [string] : [EOL] parsers_list . append ( parser ) [EOL] else : [EOL] parsers_list . insert ( [number] , parser ) [EOL] else : [EOL] if parser_name == [string] : [EOL] parsers_list . append ( parser ) [EOL] else : [EOL] parsers_list . insert ( [number] , parser ) [EOL] [EOL] return parsers_list [EOL] [EOL] def get_downloaders ( self , settings , general_utils , filter_name = None , force = False ) : [EOL] downloaders = list ( ) [EOL] for downloader in self . downloaders : [EOL] handler_name = str ( downloader ) [EOL] if filter_name : [EOL] if filter_name in handler_name : [EOL] if force : [EOL] downloader_instance = downloader ( settings , general_utils ) [EOL] downloaders . append ( ( downloader_instance , [number] ) ) [EOL] else : [EOL] if handler_name in settings . downloaders and settings . downloaders [ handler_name ] >= [number] : [EOL] downloader_instance = downloader ( settings , general_utils ) [EOL] downloaders . append ( ( downloader_instance , settings . downloaders [ handler_name ] ) ) [EOL] else : [EOL] if force : [EOL] downloader_instance = downloader ( settings , general_utils ) [EOL] downloaders . append ( ( downloader_instance , [number] ) ) [EOL] else : [EOL] if handler_name in settings . downloaders and settings . downloaders [ handler_name ] >= [number] : [EOL] downloader_instance = downloader ( settings , general_utils ) [EOL] downloaders . append ( ( downloader_instance , settings . downloaders [ handler_name ] ) ) [EOL] [EOL] return sorted ( downloaders , key = itemgetter ( [number] ) ) [EOL] [EOL] def get_downloaders_name_priority ( self , settings , filter_name = None ) : [EOL] downloaders = list ( ) [EOL] for downloader in self . downloaders : [EOL] handler_name = str ( downloader ) [EOL] if filter_name : [EOL] if filter_name in handler_name : [EOL] if handler_name in settings . downloaders : [EOL] downloaders . append ( ( handler_name , settings . downloaders [ handler_name ] ) ) [EOL] else : [EOL] downloaders . append ( ( handler_name , - [number] ) ) [EOL] else : [EOL] if handler_name in settings . downloaders : [EOL] downloaders . append ( ( handler_name , settings . downloaders [ handler_name ] ) ) [EOL] else : [EOL] downloaders . append ( ( handler_name , - [number] ) ) [EOL] [EOL] return sorted ( downloaders , key = itemgetter ( [number] ) , reverse = True ) [EOL] [EOL] def get_matchers ( self , settings , filter_name = None , force = False , matcher_type = [string] ) : [EOL] matchers_list = list ( ) [EOL] if matcher_type : [EOL] packages_filtered = [ x for x in self . matchers if x . type == matcher_type ] [EOL] else : [EOL] packages_filtered = self . matchers [EOL] for matcher in packages_filtered : [EOL] matcher_name = str ( matcher ) [EOL] if filter_name : [EOL] if filter_name in matcher_name : [EOL] if force : [EOL] matcher_instance = matcher ( settings ) [EOL] matchers_list . append ( ( matcher_instance , [number] ) ) [EOL] else : [EOL] if matcher_name in settings . matchers and settings . matchers [ matcher_name ] >= [number] : [EOL] matcher_instance = matcher ( settings ) [EOL] matchers_list . append ( ( matcher_instance , settings . matchers [ matcher_name ] ) ) [EOL] else : [EOL] if force : [EOL] matcher_instance = matcher ( settings ) [EOL] matchers_list . append ( ( matcher_instance , [number] ) ) [EOL] else : [EOL] if matcher_name in settings . matchers and settings . matchers [ matcher_name ] >= [number] : [EOL] matcher_instance = matcher ( settings ) [EOL] matchers_list . append ( ( matcher_instance , settings . matchers [ matcher_name ] ) ) [EOL] [EOL] return sorted ( matchers_list , key = itemgetter ( [number] ) ) [EOL] [EOL] def get_matchers_name_priority ( self , settings , filter_name = None , matcher_type = [string] ) : [EOL] matchers_list = list ( ) [EOL] if matcher_type : [EOL] packages_filtered = [ x for x in self . matchers if x . type == matcher_type ] [EOL] else : [EOL] packages_filtered = self . matchers [EOL] for matcher in packages_filtered : [EOL] matcher_name = str ( matcher ) [EOL] if filter_name : [EOL] if filter_name in matcher_name : [EOL] if matcher_name in settings . matchers : [EOL] matchers_list . append ( ( matcher_name , settings . matchers [ matcher_name ] ) ) [EOL] else : [EOL] matchers_list . append ( ( matcher_name , - [number] ) ) [EOL] else : [EOL] if matcher_name in settings . matchers : [EOL] matchers_list . append ( ( matcher_name , settings . matchers [ matcher_name ] ) ) [EOL] else : [EOL] matchers_list . append ( ( matcher_name , - [number] ) ) [EOL] [EOL] return sorted ( matchers_list , key = itemgetter ( [number] ) , reverse = True ) [EOL] [EOL] def resolve_all_urls ( self , gallery ) : [EOL] methods = self . get_resolve_methods ( gallery . provider ) [EOL] for method in methods : [EOL] return method ( gallery ) [EOL] return [string] [EOL] [EOL] def get_resolve_methods ( self , filter_name = None ) : [EOL] method_list = list ( ) [EOL] for method_tuple in self . resolvers : [EOL] method_name = method_tuple [ [number] ] [EOL] if filter_name : [EOL] if filter_name in method_name : [EOL] method_list . append ( method_tuple [ [number] ] ) [EOL] else : [EOL] method_list . append ( method_tuple [ [number] ] ) [EOL] [EOL] return method_list [EOL] [EOL] def get_wanted_generators ( self , filter_name = None ) : [EOL] method_list = list ( ) [EOL] for method_tuple in self . wanted_generators : [EOL] method_name = method_tuple [ [number] ] [EOL] if filter_name : [EOL] if method_name in filter_name : [EOL] method_list . append ( method_tuple [ [number] ] ) [EOL] else : [EOL] method_list . append ( method_tuple [ [number] ] ) [EOL] [EOL] return method_list [EOL] [EOL] def get_constants ( self , filter_name = None ) : [EOL] constants_list = list ( ) [EOL] for module_tuple in self . constants : [EOL] module_name = module_tuple [ [number] ] [EOL] if filter_name : [EOL] if module_name == filter_name : [EOL] constants_list . append ( module_tuple [ [number] ] ) [EOL] else : [EOL] constants_list . append ( module_tuple [ [number] ] ) [EOL] [EOL] return constants_list [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[AcceptableModules]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.Callable]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[types.ModuleType]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Type['BaseParser']]$ 0 0 0 0 $typing.List[typing.Type['Matcher']]$ 0 0 0 0 $typing.List[typing.Type['BaseDownloader']]$ 0 0 0 0 $typing.List[typing.Tuple[builtins.str,typing.Callable[[None],core.base.types.ProviderSettings]]]$ 0 0 0 0 $typing.List[typing.Tuple[builtins.str,typing.Callable]]$ 0 0 0 0 $typing.List[typing.Tuple[builtins.str,typing.Callable]]$ 0 0 0 0 $typing.List[typing.Tuple[builtins.str,types.ModuleType]]$ 0 0 0 0 0 0 $None$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.Callable[...,typing.Any]]$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $typing.Optional[typing.Callable[...,typing.Any]]$ 0 0 $builtins.str$ 0 $typing.Optional[typing.Callable[...,typing.Any]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $typing.Optional[typing.Callable[...,typing.Any]]$ 0 0 $typing.Optional[typing.Callable[...,typing.Any]]$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $typing.Optional[typing.Callable[...,typing.Any]]$ 0 0 $builtins.str$ 0 $typing.Optional[typing.Callable[...,typing.Any]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $typing.Optional[typing.Callable[...,typing.Any]]$ 0 0 $typing.Optional[typing.Callable[...,typing.Any]]$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $typing.Optional[typing.Callable[...,typing.Any]]$ 0 0 $builtins.str$ 0 $typing.Optional[typing.Callable[...,typing.Any]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $typing.Optional[typing.Callable[...,typing.Any]]$ 0 0 $typing.Optional[_importlib_modulespec.ModuleType]$ 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.Optional[_importlib_modulespec.ModuleType]$ 0 0 $builtins.str$ 0 $typing.Optional[_importlib_modulespec.ModuleType]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $typing.Optional[_importlib_modulespec.ModuleType]$ 0 0 0 0 $None$ 0 0 0 $typing.Type['BaseParser']$ 0 0 0 0 0 0 0 0 $typing.Type['BaseParser']$ 0 0 0 0 $typing.Type['BaseParser']$ 0 0 0 0 $typing.Type['BaseParser']$ 0 0 0 0 0 0 0 0 0 0 $typing.Type['BaseParser']$ 0 0 0 0 $None$ 0 0 0 $typing.Type['Matcher']$ 0 0 0 0 0 0 0 0 $typing.Type['Matcher']$ 0 0 0 0 $typing.Type['Matcher']$ 0 0 0 $typing.Type['Matcher']$ 0 0 0 0 0 0 0 0 0 0 $typing.Type['Matcher']$ 0 0 0 0 $None$ 0 0 0 $typing.Type['BaseDownloader']$ 0 0 0 0 0 0 0 0 $typing.Type['BaseDownloader']$ 0 0 0 0 $typing.Type['BaseDownloader']$ 0 0 0 $typing.Type['BaseDownloader']$ 0 0 0 0 0 0 0 0 0 0 $typing.Type['BaseDownloader']$ 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 $typing.Callable$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $typing.Callable$ 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 $typing.Callable$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $typing.Callable$ 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 $typing.Callable$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $typing.Callable$ 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 $types.ModuleType$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $types.ModuleType$ 0 0 0 0 0 $typing.List['BaseParser']$ 0 0 0 $'setup.Settings'$ 0 $typing.List[builtins.str]$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 $typing.List[builtins.str]$ 0 $typing.Any$ 0 0 $core.base.parsers.BaseParser$ 0 0 0 $'setup.Settings'$ 0 0 0 $typing.Any$ 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $core.base.parsers.BaseParser$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 $core.base.parsers.BaseParser$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 $typing.Any$ 0 0 $core.base.parsers.BaseParser$ 0 0 0 $'setup.Settings'$ 0 0 0 $typing.Any$ 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $core.base.parsers.BaseParser$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 $core.base.parsers.BaseParser$ 0 0 0 0 0 $core.base.parsers.BaseParser$ 0 0 0 $'setup.Settings'$ 0 0 0 $typing.Any$ 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $core.base.parsers.BaseParser$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 $core.base.parsers.BaseParser$ 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $typing.List[typing.Type['BaseParser']]$ 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $typing.List[typing.Tuple['BaseDownloader',builtins.int]]$ 0 0 0 $'setup.Settings'$ 0 $core.base.utilities.GeneralUtils$ 0 $builtins.str$ 0 0 0 $builtins.bool$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $builtins.bool$ 0 0 $core.downloaders.handlers.BaseDownloader$ 0 0 0 $'setup.Settings'$ 0 $core.base.utilities.GeneralUtils$ 0 0 $typing.List[typing.Any]$ 0 0 0 0 $core.downloaders.handlers.BaseDownloader$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $'setup.Settings'$ 0 $typing.List[typing.Any]$ 0 $'setup.Settings'$ 0 $typing.List[typing.Any]$ 0 $builtins.str$ 0 0 0 0 0 $core.downloaders.handlers.BaseDownloader$ 0 0 0 $'setup.Settings'$ 0 $core.base.utilities.GeneralUtils$ 0 0 $typing.List[typing.Any]$ 0 0 0 0 $core.downloaders.handlers.BaseDownloader$ 0 $'setup.Settings'$ 0 $typing.List[typing.Any]$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 $core.downloaders.handlers.BaseDownloader$ 0 0 0 $'setup.Settings'$ 0 $core.base.utilities.GeneralUtils$ 0 0 $typing.List[typing.Any]$ 0 0 0 0 $core.downloaders.handlers.BaseDownloader$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $'setup.Settings'$ 0 $typing.List[typing.Any]$ 0 $'setup.Settings'$ 0 $typing.List[typing.Any]$ 0 $builtins.str$ 0 0 0 0 0 $core.downloaders.handlers.BaseDownloader$ 0 0 0 $'setup.Settings'$ 0 $core.base.utilities.GeneralUtils$ 0 0 $typing.List[typing.Any]$ 0 0 0 0 $core.downloaders.handlers.BaseDownloader$ 0 $'setup.Settings'$ 0 $typing.List[typing.Any]$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.int]]$ 0 0 0 $'setup.Settings'$ 0 $builtins.str$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $builtins.str$ 0 $'setup.Settings'$ 0 $typing.List[typing.Any]$ 0 0 $typing.List[typing.Any]$ 0 0 0 0 $builtins.str$ 0 $'setup.Settings'$ 0 $typing.List[typing.Any]$ 0 $builtins.str$ 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $'setup.Settings'$ 0 $typing.List[typing.Any]$ 0 0 $typing.List[typing.Any]$ 0 0 0 0 $builtins.str$ 0 $'setup.Settings'$ 0 $typing.List[typing.Any]$ 0 $builtins.str$ 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple['Matcher',builtins.int]]$ 0 0 0 $'setup.Settings'$ 0 $builtins.str$ 0 0 0 $builtins.bool$ 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 $builtins.str$ 0 0 $typing.List[typing.Type[core.base.matchers.Matcher]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.List[typing.Type[core.base.matchers.Matcher]]$ 0 0 0 0 0 0 0 0 $typing.List[typing.Type[core.base.matchers.Matcher]]$ 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $builtins.bool$ 0 0 $core.base.matchers.Matcher$ 0 0 0 $'setup.Settings'$ 0 0 $typing.List[typing.Any]$ 0 0 0 0 $core.base.matchers.Matcher$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $'setup.Settings'$ 0 0 0 $'setup.Settings'$ 0 0 0 $builtins.str$ 0 0 0 0 0 $core.base.matchers.Matcher$ 0 0 0 $'setup.Settings'$ 0 0 $typing.List[typing.Any]$ 0 0 0 0 $core.base.matchers.Matcher$ 0 $'setup.Settings'$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 $core.base.matchers.Matcher$ 0 0 0 $'setup.Settings'$ 0 0 $typing.List[typing.Any]$ 0 0 0 0 $core.base.matchers.Matcher$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $'setup.Settings'$ 0 0 0 $'setup.Settings'$ 0 0 0 $builtins.str$ 0 0 0 0 0 $core.base.matchers.Matcher$ 0 0 0 $'setup.Settings'$ 0 0 $typing.List[typing.Any]$ 0 0 0 0 $core.base.matchers.Matcher$ 0 $'setup.Settings'$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.int]]$ 0 0 0 $'setup.Settings'$ 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 $builtins.str$ 0 0 $typing.List[typing.Type[core.base.matchers.Matcher]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.List[typing.Type[core.base.matchers.Matcher]]$ 0 0 0 0 0 0 0 0 $typing.List[typing.Type[core.base.matchers.Matcher]]$ 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $builtins.str$ 0 $'setup.Settings'$ 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 $builtins.str$ 0 $'setup.Settings'$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $'setup.Settings'$ 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 $builtins.str$ 0 $'setup.Settings'$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $'models.Gallery'$ 0 0 0 $typing.List[typing.Callable[...,typing.Any]]$ 0 0 0 0 0 $'models.Gallery'$ 0 0 0 0 0 0 0 $typing.List[typing.Callable[...,typing.Any]]$ 0 0 0 0 0 $'models.Gallery'$ 0 0 0 0 0 0 0 $typing.List[typing.Callable]$ 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $typing.List[typing.Callable]$ 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $typing.List[types.ModuleType]$ 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0
from typing import Any , Dict , Tuple , Optional , List [EOL] import core [EOL] import typing [EOL] import logging [EOL] import builtins [EOL] import os [EOL] import re [EOL] import logging [EOL] [EOL] import time [EOL] from typing import List , Tuple , Optional [EOL] import typing [EOL] [EOL] from core . base . comparison import get_gallery_closer_title_from_gallery_values , get_list_closer_gallery_titles_from_dict [EOL] from core . base . utilities import GeneralUtils [EOL] from core . base . types import GalleryData , DataDict [EOL] [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from core . base . setup import Settings [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class Meta ( type ) : [EOL] name = [string] [EOL] provider = [string] [EOL] [EOL] def __str__ ( self ) : [EOL] return [string] . format ( self . provider , self . name ) [EOL] [EOL] [EOL] class Matcher ( metaclass = Meta ) : [EOL] [EOL] name = [string] [EOL] provider = [string] [EOL] type = [string] [EOL] time_to_wait_after_compare = [number] [EOL] default_cutoff = [number] [EOL] [EOL] def __init__ ( self , settings ) : [EOL] self . settings = settings [EOL] self . own_settings = settings . providers [ self . provider ] [EOL] self . general_utils = GeneralUtils ( global_settings = settings ) [EOL] self . parser = self . settings . provider_context . get_parsers ( self . settings , filter_name = self . provider ) [ [number] ] [EOL] self . found_by = [string] [EOL] self . match_gid = None [EOL] self . match_link = None [EOL] self . values_array = [ ] [EOL] self . match_count = [number] [EOL] self . match_title = None [EOL] self . api_galleries = [ ] [EOL] self . crc32 = None [EOL] self . file_path = [string] [EOL] [comment] [EOL] self . return_code = [number] [EOL] self . gallery_links = [ ] [EOL] self . match_values = None [EOL] [EOL] def __str__ ( self ) : [EOL] return [string] . format ( self . provider , self . name ) [EOL] [EOL] def get_closer_match ( self , file_path ) : [EOL] [EOL] title_to_search = self . format_to_search_title ( file_path ) [EOL] [EOL] if self . search_method ( title_to_search ) : [EOL] if self . time_to_wait_after_compare > [number] : [EOL] time . sleep ( self . time_to_wait_after_compare ) [EOL] galleries_data = self . get_metadata_after_matching ( ) [EOL] if not galleries_data : [EOL] return [number] [EOL] galleries_data = [ x for x in galleries_data if not self . general_utils . discard_by_tag_list ( x . tags ) ] [EOL] if not galleries_data : [EOL] return [number] [EOL] result = get_gallery_closer_title_from_gallery_values ( self . format_to_compare_title ( file_path ) , galleries_data , self . default_cutoff ) [EOL] if result . match_title == [string] : [EOL] return [number] [EOL] self . match_link = result . match_link [EOL] self . match_count = len ( self . gallery_links ) [EOL] self . match_title = result . match_title [EOL] self . match_values = result . match_values [EOL] return [number] [EOL] else : [EOL] return [number] [EOL] [EOL] def create_closer_matches_values ( self , title , cutoff = None , max_matches = [number] ) : [EOL] [EOL] if cutoff is None : [EOL] cutoff = self . default_cutoff [EOL] [EOL] self . values_array = [ ] [EOL] results = [ ] [EOL] title_to_search = self . format_to_search_title ( title ) [EOL] [EOL] if self . search_method ( title_to_search ) : [EOL] if self . time_to_wait_after_compare > [number] : [EOL] time . sleep ( self . time_to_wait_after_compare ) [EOL] galleries_data = self . get_metadata_after_matching ( ) [EOL] if not galleries_data : [EOL] return results [EOL] galleries_data = [ x for x in galleries_data if not self . general_utils . discard_by_tag_list ( x . tags ) ] [EOL] logger . info ( [string] . format ( str ( self ) , len ( galleries_data ) ) ) [EOL] if galleries_data : [EOL] self . values_array = galleries_data [EOL] results = get_list_closer_gallery_titles_from_dict ( self . format_to_compare_title ( title ) , self . values_array , cutoff , max_matches ) [EOL] return results [EOL] [EOL] def get_metadata_after_matching ( self ) : [EOL] return self . parser . fetch_multiple_gallery_data ( self . gallery_links ) [EOL] [EOL] def format_match_values ( self ) : [EOL] raise NotImplementedError [EOL] [EOL] def format_to_search_title ( self , file_name ) : [EOL] raise NotImplementedError [EOL] [EOL] def format_to_compare_title ( self , file_name ) : [EOL] raise NotImplementedError [EOL] [EOL] def search_method ( self , title_to_search ) : [EOL] raise NotImplementedError [EOL] [EOL] def update_archive ( self ) : [EOL] [EOL] if not self . settings . archive_model : [EOL] logger . error ( [string] ) [EOL] return [EOL] [EOL] values = self . format_match_values ( ) [EOL] if values : [EOL] if self . settings . archive_reason : [EOL] values [ [string] ] = self . settings . archive_reason [EOL] if self . settings . archive_details : [EOL] values [ [string] ] = self . settings . archive_details [EOL] self . settings . archive_model . objects . update_or_create_by_values_and_gid ( values , ( self . match_gid , self . provider ) if self . match_gid else None , zipped = self . file_path ) [EOL] [EOL] def update_gallery_db ( self , gallery_data ) : [EOL] [EOL] if not self . settings . gallery_model : [EOL] logger . error ( [string] ) [EOL] return [EOL] [EOL] check_exists = self . settings . gallery_model . objects . exists_by_gid_provider ( gallery_data . gid , gallery_data . provider ) [EOL] if check_exists and self . settings . replace_metadata : [EOL] self . settings . gallery_model . objects . update_by_gid_provider ( gallery_data ) [EOL] elif not check_exists : [EOL] self . settings . gallery_model . objects . add_from_values ( gallery_data ) [EOL] [EOL] def start_match ( self , file_path , crc32 ) : [EOL] [EOL] self . file_path = file_path [EOL] [comment] [EOL] self . crc32 = crc32 [EOL] [EOL] self . api_galleries = [ ] [EOL] [EOL] self . return_code = self . get_closer_match ( file_path ) [EOL] [EOL] if self . return_code == [number] : [EOL] return False [EOL] [EOL] if self . match_values : [EOL] self . update_gallery_db ( self . match_values ) [EOL] [EOL] self . update_archive ( ) [EOL] return True [EOL] [EOL] @ staticmethod def get_title_from_path ( path ) : [EOL] return re . sub ( [string] , [string] , os . path . splitext ( os . path . basename ( path ) ) [ [number] ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,core.base.types.GalleryData,builtins.float]]$ 0 0 0 0 0 $builtins.float$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 $typing.List[typing.Tuple[builtins.str,core.base.types.GalleryData,builtins.float]]$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 $typing.List[typing.Tuple[builtins.str,core.base.types.GalleryData,builtins.float]]$ 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 $typing.List[core.base.types.GalleryData]$ 0 $typing.List[typing.Tuple[builtins.str,core.base.types.GalleryData,builtins.float]]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 $builtins.float$ 0 $builtins.int$ 0 0 0 $typing.List[typing.Tuple[builtins.str,core.base.types.GalleryData,builtins.float]]$ 0 0 0 $typing.Optional[typing.List[core.base.types.GalleryData]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[core.base.types.DataDict]$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.Dict[builtins.str,typing.Any]]$ 0 0 0 0 0 0 0 0 $typing.Optional[typing.Dict[builtins.str,typing.Any]]$ 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.Dict[builtins.str,typing.Any]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.Dict[builtins.str,typing.Any]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.Dict[builtins.str,typing.Any]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.GalleryData$ 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.GalleryData$ 0 0 0 0 $builtins.bool$ 0 0 0 $builtins.str$ 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 0 0 0 $typing.List[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0
from typing import Any , Type , Dict , Tuple , Optional , Union , List [EOL] import datetime [EOL] import core [EOL] import typing [EOL] import builtins [EOL] from datetime import datetime [EOL] import typing [EOL] from typing import Optional , List , Union , Dict , Any , Tuple [EOL] if typing . TYPE_CHECKING : [EOL] from core . base . setup import Settings [EOL] [EOL] [EOL] [comment] [EOL] class GalleryData : [EOL] def __init__ ( self , gid , provider , token = None , link = None , tags = None , title = None , title_jpn = None , comment = None , gallery_container_gid = None , category = None , posted = None , filesize = None , filecount = None , expunged = None , rating = None , fjord = None , hidden = None , uploader = None , thumbnail_url = None , dl_type = None , public = None , content = None , archiver_key = None , root = None , filename = None , queries = None , thumbnail = None , status = None , origin = None , reason = None , ** kwargs ) : [EOL] self . gid = gid [EOL] self . token = token [EOL] self . link = link [EOL] if tags : [EOL] self . tags = tags [EOL] else : [EOL] self . tags = [ ] [EOL] self . gallery_container_gid = gallery_container_gid [EOL] self . provider = provider [EOL] self . title = title [EOL] self . title_jpn = title_jpn [EOL] self . comment = comment [EOL] self . category = category [EOL] self . posted = posted [EOL] self . filesize = filesize [EOL] self . filecount = filecount [EOL] self . uploader = uploader [EOL] self . thumbnail = thumbnail [EOL] self . thumbnail_url = thumbnail_url [EOL] self . dl_type = dl_type [EOL] self . expunged = expunged [EOL] self . rating = rating [EOL] self . fjord = fjord [EOL] self . hidden = hidden [EOL] self . public = public [EOL] self . status = status [EOL] self . origin = origin [EOL] self . reason = reason [EOL] self . content = content [EOL] self . archiver_key = archiver_key [EOL] self . root = root [EOL] self . filename = filename [EOL] self . queries = queries [EOL] self . extra_data = { } [EOL] [EOL] def __str__ ( self ) : [EOL] return str ( self . __dict__ ) [EOL] [EOL] def __repr__ ( self ) : [EOL] return str ( self . __dict__ ) [EOL] [EOL] def __eq__ ( self , other ) : [EOL] if not isinstance ( other , GalleryData ) : [EOL] return False [EOL] return self . __dict__ == other . __dict__ [EOL] [EOL] [EOL] DataDict = Dict [ str , Any ] [EOL] [EOL] MatchesValues = Tuple [ str , GalleryData , float ] [EOL] [EOL] [EOL] class ProviderSettings : [EOL] def __init__ ( self , global_settings , config ) : [EOL] self . cookies = { } [EOL] self . proxy = [string] [EOL] self . proxies = { } [EOL] self . timeout_timer = global_settings . timeout_timer [EOL] self . autochecker_timer = global_settings . autochecker . cycle_timer [EOL] self . autochecker_enable = global_settings . autochecker . enable [EOL] self . wait_timer = global_settings . wait_timer [EOL] [EOL] if [string] in config : [EOL] self . cookies . update ( config [ [string] ] ) [EOL] if [string] in config : [EOL] if [string] in config [ [string] ] : [EOL] self . proxy = config [ [string] ] [ [string] ] [EOL] self . proxies = { [string] : config [ [string] ] [ [string] ] , [string] : config [ [string] ] [ [string] ] } [EOL] if [string] in config [ [string] ] : [EOL] self . timeout_timer = int ( config [ [string] ] [ [string] ] ) [EOL] if [string] in config [ [string] ] : [EOL] self . autochecker_timer = float ( config [ [string] ] [ [string] ] ) [EOL] if [string] in config [ [string] ] : [EOL] self . autochecker_enable = config [ [string] ] . getboolean ( [string] ) [EOL] if [string] in config [ [string] ] : [EOL] self . wait_timer = int ( config [ [string] ] [ [string] ] ) [EOL] if [string] in config : [EOL] self . proxies . update ( config [ [string] ] ) [EOL] [EOL] [EOL] class TorrentClient ( object ) : [EOL] [EOL] name = [string] [EOL] convert_to_base64 = False [EOL] send_url = False [EOL] type = [string] [EOL] [EOL] def __init__ ( self , address = [string] , port = [number] , user = [string] , password = [string] , secure = True ) : [EOL] self . address = address [EOL] self . port = str ( port ) [EOL] self . user = user [EOL] self . password = password [EOL] self . secure = secure [EOL] self . total_size = [number] [EOL] self . expected_torrent_name = [string] [EOL] self . set_expected = True [EOL] [EOL] def add_torrent ( self , torrent_data , download_dir = None ) : [EOL] pass [EOL] [EOL] def add_url ( self , url , download_dir = None ) : [EOL] pass [EOL] [EOL] def connect ( self ) : [EOL] pass [EOL] [EOL] [EOL] QueueItem = Dict [ str , Any ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.bool$ 0 0 0 $builtins.bool$ 0 0 0 $builtins.str$ 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $builtins.bool$ 0 $builtins.bool$ 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 $builtins.bool$ 0 0 0 $typing.Union[builtins.str,builtins.bytes]$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
	0
from typing import Optional , Any , Dict [EOL] import typing [EOL] import viewer [EOL] import logging [EOL] import core [EOL] import builtins [EOL] import copy [EOL] import logging [EOL] import os [EOL] import typing [EOL] from typing import Optional , Dict , Any [EOL] [EOL] from core . base . utilities import GeneralUtils , replace_illegal_name , get_base_filename_string_from_gallery_data [EOL] from core . base . types import GalleryData , TorrentClient , DataDict [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from core . base . setup import Settings [EOL] from viewer . models import Gallery , Archive [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class Meta ( type ) : [EOL] type = [string] [EOL] provider = [string] [EOL] [EOL] def __str__ ( self ) : [EOL] return [string] . format ( self . provider , self . type ) [EOL] [EOL] [EOL] class BaseDownloader ( metaclass = Meta ) : [EOL] [EOL] type = [string] [EOL] provider = [string] [EOL] archive_only = False [EOL] skip_if_hidden = False [EOL] [EOL] def __init__ ( self , settings , general_utils ) : [EOL] self . settings = settings [EOL] self . general_utils = general_utils [EOL] self . own_settings = settings . providers [ self . provider ] [EOL] self . fileDownloaded = [number] [EOL] self . return_code = [number] [EOL] self . gallery_db_entry = None [EOL] self . archive_db_entry = None [EOL] self . crc32 = [string] [EOL] self . original_gallery = None [EOL] self . gallery = None [EOL] [EOL] def __str__ ( self ) : [EOL] return [string] . format ( self . provider , self . type ) [EOL] [EOL] def is_generic ( self ) : [EOL] return self . provider == [string] [EOL] [EOL] def start_download ( self ) : [EOL] pass [EOL] [EOL] def update_archive_db ( self , default_values ) : [EOL] pass [EOL] [EOL] def update_gallery_db ( self ) : [EOL] if not self . original_gallery or not self . settings . gallery_model : [EOL] return [EOL] if self . settings . keep_dl_type and self . original_gallery . dl_type is not None : [EOL] self . original_gallery . dl_type = None [EOL] if self . type == [string] : [EOL] self . original_gallery . origin = self . settings . gallery_model . ORIGIN_SUBMITTED [EOL] if self . settings . gallery_reason : [EOL] self . original_gallery . reason = self . settings . gallery_reason [EOL] self . gallery_db_entry = self . settings . gallery_model . objects . update_or_create_from_values ( self . original_gallery ) [EOL] if self . gallery_db_entry : [EOL] for archive in self . gallery_db_entry . archive_set . all ( ) : [EOL] if archive . gallery : [EOL] archive . title = archive . gallery . title [EOL] archive . title_jpn = archive . gallery . title_jpn [EOL] archive . simple_save ( ) [EOL] archive . tags . set ( archive . gallery . tags . all ( ) ) [EOL] [EOL] def init_download ( self , gallery ) : [EOL] [EOL] self . original_gallery = copy . deepcopy ( gallery ) [EOL] self . gallery = gallery [EOL] [EOL] self . original_gallery . dl_type = self . type [EOL] self . start_download ( ) [EOL] [EOL] if self . return_code == [number] : [EOL] return [EOL] [EOL] if not self . archive_only : [EOL] self . update_gallery_db ( ) [EOL] [EOL] if self . fileDownloaded == [number] : [EOL] [EOL] default_values = { [string] : self . type , [string] : self . provider } [EOL] [EOL] if self . settings . archive_reason : [EOL] default_values [ [string] ] = self . settings . archive_reason [EOL] if self . settings . archive_details : [EOL] default_values [ [string] ] = self . settings . archive_details [EOL] if self . settings . archive_source : [EOL] default_values [ [string] ] = self . settings . archive_source [EOL] if self . settings . archive_user : [EOL] default_values [ [string] ] = self . settings . archive_user [EOL] [EOL] self . archive_db_entry = self . update_archive_db ( default_values ) [EOL] [EOL] [EOL] class BaseInfoDownloader ( BaseDownloader ) : [EOL] [EOL] type = [string] [EOL] [EOL] def start_download ( self ) : [EOL] [EOL] logger . info ( [string] . format ( self . provider ) ) [EOL] [EOL] self . return_code = [number] [EOL] [EOL] [EOL] class BaseFakeDownloader ( BaseDownloader ) : [EOL] [EOL] type = [string] [EOL] [EOL] def start_download ( self ) : [EOL] [EOL] if not self . original_gallery : [EOL] return [EOL] [EOL] self . original_gallery . hidden = True [EOL] [EOL] logger . info ( [string] . format ( self . provider ) ) [EOL] [EOL] self . fileDownloaded = [number] [EOL] self . return_code = [number] [EOL] [EOL] def update_archive_db ( self , default_values ) : [EOL] [EOL] if not self . gallery or not self . settings . archive_model : [EOL] return None [EOL] [EOL] values = { [string] : [string] , [string] : self . crc32 , } [EOL] if self . gallery . title is not None : [EOL] values [ [string] ] = self . gallery . title [EOL] if self . gallery . title_jpn is not None : [EOL] values [ [string] ] = self . gallery . title_jpn [EOL] if self . gallery . filesize is not None : [EOL] values [ [string] ] = self . gallery . filesize [EOL] if self . gallery . filecount is not None : [EOL] values [ [string] ] = self . gallery . filecount [EOL] default_values . update ( values ) [EOL] return self . settings . archive_model . objects . create_by_values_and_gid ( default_values , ( self . gallery . gid , self . gallery . provider ) , ) [EOL] [EOL] [EOL] class BaseTorrentDownloader ( BaseDownloader ) : [EOL] [EOL] type = [string] [EOL] [EOL] def __init__ ( self , * args , ** kwargs ) : [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] self . expected_torrent_name = [string] [EOL] [EOL] def connect_and_download ( self , client , torrent_link ) : [EOL] if not self . gallery : [EOL] return None [EOL] client . connect ( ) [EOL] if client . send_url : [EOL] result = client . add_url ( torrent_link , download_dir = self . settings . torrent [ [string] ] ) [EOL] else : [EOL] result = client . add_torrent ( self . general_utils . get_torrent ( torrent_link , self . own_settings . cookies , convert_to_base64 = client . convert_to_base64 ) , download_dir = self . settings . torrent [ [string] ] ) [EOL] if result : [EOL] if client . expected_torrent_name : [EOL] self . expected_torrent_name = [string] . format ( client . expected_torrent_name , self . gallery . gid ) [EOL] else : [EOL] [EOL] to_use_filename = get_base_filename_string_from_gallery_data ( self . gallery ) [EOL] [EOL] self . expected_torrent_name = [string] . format ( replace_illegal_name ( to_use_filename ) , self . gallery . gid ) [EOL] self . fileDownloaded = [number] [EOL] self . return_code = [number] [EOL] if client . total_size > [number] : [EOL] self . gallery . filesize = client . total_size [EOL] self . gallery . filename = os . path . join ( self . own_settings . torrent_dl_folder , replace_illegal_name ( self . expected_torrent_name ) + [string] ) [EOL] logger . info ( [string] . format ( self . expected_torrent_name , self . gallery . filename ) ) [EOL] else : [EOL] self . return_code = [number] [EOL] logger . error ( [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.bool$ 0 0 0 $builtins.bool$ 0 0 0 0 0 $None$ 0 0 0 $core.base.setup.Settings$ 0 $core.base.utilities.GeneralUtils$ 0 0 0 0 0 $core.base.setup.Settings$ 0 $core.base.setup.Settings$ 0 0 0 $core.base.utilities.GeneralUtils$ 0 $core.base.utilities.GeneralUtils$ 0 0 0 0 0 $core.base.setup.Settings$ 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $typing.Optional['Gallery']$ 0 0 0 0 0 $typing.Optional['Archive']$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 0 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 $typing.Optional['Archive']$ 0 0 0 $core.base.types.DataDict$ 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[viewer.models.Gallery]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[viewer.models.Gallery]$ 0 0 0 0 0 0 0 $typing.Optional[viewer.models.Gallery]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 0 0 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 0 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 $typing.Optional[core.base.types.GalleryData]$ 0 0 0 0 $typing.Optional[core.base.types.GalleryData]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[viewer.models.Archive]$ 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $typing.Optional['Archive']$ 0 0 0 $core.base.types.DataDict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.DataDict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.DataDict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.DataDict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.DataDict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.DataDict$ 0 0 0 0 0 0 0 0 0 0 $core.base.types.DataDict$ 0 0 0 $core.base.types.DataDict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.DataDict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $None$ 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 $None$ 0 0 0 $core.base.types.TorrentClient$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.TorrentClient$ 0 0 0 0 0 0 $core.base.types.TorrentClient$ 0 0 0 0 $builtins.bool$ 0 $core.base.types.TorrentClient$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 $core.base.types.TorrentClient$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $core.base.types.TorrentClient$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 $core.base.types.TorrentClient$ 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 $core.base.types.TorrentClient$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 $core.base.types.TorrentClient$ 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.types.TorrentClient$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0
from typing import Any , Callable , Iterable , Dict , Optional , Union , Match , List [EOL] import queue [EOL] import typing [EOL] import viewer [EOL] import threading [EOL] import ftplib [EOL] import logging [EOL] import core [EOL] import ssl [EOL] import builtins [EOL] import zipfile [EOL] import os [EOL] import queue [EOL] import shutil [EOL] import socket [EOL] import ssl [EOL] import time [EOL] import traceback [EOL] from ftplib import FTP_TLS , _SSLSocket [comment] [EOL] from tempfile import mkdtemp [EOL] from typing import Any , List , Dict , Callable , Iterable , Optional [EOL] from zipfile import ZipFile , BadZipFile [EOL] [EOL] import django . utils . timezone as django_tz [EOL] import threading [EOL] [EOL] import logging [EOL] from django . template . defaultfilters import filesizeformat [EOL] import re [EOL] [EOL] from core . base . setup import Settings [EOL] from core . base . types import DataDict [EOL] from core . base . utilities import ( calc_crc32 , get_zip_filesize , filecount_in_zip , convert_rar_to_zip , replace_illegal_name ) [EOL] from core . workers . schedulers import BaseScheduler [EOL] from viewer . models import Archive [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class PostDownloader ( object ) : [EOL] [EOL] def __init__ ( self , settings , web_queue = None ) : [EOL] self . settings = settings [EOL] self . web_queue = web_queue [EOL] self . ftps = None [EOL] self . current_ftp_dir = None [EOL] self . current_download = { [string] : [string] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , } [EOL] [EOL] def process_downloaded_archive ( self , archive ) : [EOL] if os . path . isfile ( archive . zipped . path ) : [EOL] except_at_open = False [EOL] return_error = None [EOL] try : [EOL] my_zip = ZipFile ( archive . zipped . path , [string] ) [EOL] return_error = my_zip . testzip ( ) [EOL] my_zip . close ( ) [EOL] except ( BadZipFile , NotImplementedError ) : [EOL] except_at_open = True [EOL] if except_at_open or return_error : [EOL] if archive . source_type and [string] in archive . source_type : [EOL] logger . error ( [string] [string] . format ( archive , archive . zipped . path ) ) [EOL] crc32 = calc_crc32 ( archive . zipped . path ) [EOL] Archive . objects . add_or_update_from_values ( { [string] : crc32 } , pk = archive . pk ) [EOL] if self . web_queue and archive . gallery : [EOL] temp_settings = Settings ( load_from_config = self . settings . config ) [EOL] temp_settings . allow_downloaders_only ( [ [string] ] , True , True , True ) [EOL] self . web_queue . enqueue_args_list ( ( archive . gallery . get_link ( ) , ) , override_options = temp_settings ) [EOL] return [EOL] else : [EOL] logger . warning ( [string] [string] . format ( archive , archive . zipped . path ) ) [EOL] crc32 = calc_crc32 ( archive . zipped . path ) [EOL] filesize = get_zip_filesize ( archive . zipped . path ) [EOL] filecount = filecount_in_zip ( archive . zipped . path ) [EOL] values = { [string] : crc32 , [string] : filesize , [string] : filecount , } [EOL] updated_archive = Archive . objects . add_or_update_from_values ( values , pk = archive . pk ) [EOL] if updated_archive . gallery and updated_archive . filesize != updated_archive . gallery . filesize : [EOL] if Archive . objects . filter ( gallery = updated_archive . gallery , filesize = updated_archive . gallery . filesize ) : [EOL] logger . info ( [string] [string] . format ( updated_archive ) ) [EOL] return [EOL] if archive . source_type and [string] in archive . source_type : [EOL] logger . info ( [string] [string] . format ( updated_archive ) ) [EOL] if self . web_queue : [EOL] temp_settings = Settings ( load_from_config = self . settings . config ) [EOL] temp_settings . allow_downloaders_only ( [ [string] ] , True , True , True ) [EOL] self . web_queue . enqueue_args_list ( ( updated_archive . gallery . get_link ( ) , ) , override_options = temp_settings ) [EOL] else : [EOL] logger . warning ( [string] . format ( archive ) ) [EOL] [EOL] def write_file_update_progress ( self , cmd , callback , filesize = [number] , blocksize = [number] , rest = None ) : [EOL] self . ftps . voidcmd ( [string] ) [comment] [EOL] with self . ftps . transfercmd ( cmd , rest ) as conn : [comment] [EOL] self . current_download [ [string] ] = filesize [EOL] self . current_download [ [string] ] = [number] [EOL] self . current_download [ [string] ] = cmd . replace ( [string] , [string] ) [EOL] start = time . perf_counter ( ) [EOL] while [number] : [EOL] data = conn . recv ( blocksize ) [EOL] if not data : [EOL] break [EOL] downloaded = len ( data ) [EOL] self . current_download [ [string] ] += downloaded [EOL] current = time . perf_counter ( ) [EOL] if current > start : [EOL] self . current_download [ [string] ] = self . current_download [ [string] ] / ( ( current - start ) * [number] ) [EOL] callback ( data ) [EOL] self . current_download [ [string] ] = [string] [EOL] self . current_download [ [string] ] = [number] [EOL] self . current_download [ [string] ] = [number] [EOL] [comment] [EOL] if _SSLSocket is not None and isinstance ( conn , _SSLSocket ) : [EOL] conn . unwrap ( ) [EOL] return self . ftps . voidresp ( ) [comment] [EOL] [EOL] def start_connection ( self ) : [EOL] if self . settings . ftps [ [string] ] : [EOL] context = ssl . SSLContext ( ssl . PROTOCOL_TLSv1_2 ) [EOL] context . verify_mode = ssl . CERT_NONE [EOL] context . check_hostname = False [EOL] else : [EOL] context = ssl . create_default_context ( ) [EOL] self . ftps = FTP_TLS ( host = self . settings . ftps [ [string] ] , user = self . settings . ftps [ [string] ] , passwd = self . settings . ftps [ [string] ] , context = context , source_address = self . settings . ftps [ [string] ] , timeout = self . settings . timeout_timer ) [EOL] [EOL] [comment] [EOL] self . ftps . prot_p ( ) [EOL] [EOL] def set_current_dir ( self , self_dir ) : [EOL] self . current_ftp_dir = self_dir [EOL] if not self . ftps : [EOL] return None [EOL] self . ftps . cwd ( self_dir ) [EOL] [EOL] def download_all_missing ( self , archives = None ) : [EOL] [EOL] files_torrent = [ ] [EOL] files_hath = [ ] [EOL] [EOL] if not archives : [EOL] found_archives = list ( Archive . objects . filter_by_dl_remote ( ) ) [EOL] else : [EOL] found_archives = archives [EOL] [EOL] if not found_archives : [EOL] return [EOL] [EOL] for archive in found_archives : [EOL] if archive . match_type : [EOL] if [string] in archive . match_type : [EOL] files_torrent . append ( archive ) [EOL] elif [string] in archive . match_type : [EOL] files_hath . append ( archive ) [EOL] [EOL] if len ( files_torrent ) + len ( files_hath ) == [number] : [EOL] return [EOL] [EOL] self . start_connection ( ) [EOL] [EOL] if not self . ftps : [EOL] logger . error ( [string] ) [EOL] return None [EOL] [EOL] [comment] [EOL] if len ( files_hath ) > [number] : [EOL] self . set_current_dir ( self . settings . providers [ [string] ] . remote_hath_dir ) [EOL] [comment] [EOL] [EOL] files_matched_hath = [ ] [EOL] for line in self . ftps . mlsd ( facts = [ [string] ] ) : [EOL] if line [ [number] ] [ [string] ] != [string] : [EOL] continue [EOL] m = re . search ( [string] , line [ [number] ] ) [EOL] if m : [EOL] for archive in files_hath : [EOL] if archive . gallery and archive . filesize and m . group ( [number] ) == archive . gallery . gid : [EOL] files_matched_hath . append ( ( line [ [number] ] , archive . zipped . path , int ( archive . filesize ) , archive ) ) [EOL] [EOL] for matched_file_hath in files_matched_hath : [EOL] total_remote_size = [number] [EOL] remote_ftp_tuples = [ ] [EOL] for img_file_tuple in self . ftps . mlsd ( path = matched_file_hath [ [number] ] , facts = [ [string] , [string] ] ) : [EOL] if img_file_tuple [ [number] ] [ [string] ] != [string] or img_file_tuple [ [number] ] == [string] : [EOL] continue [EOL] total_remote_size += int ( img_file_tuple [ [number] ] [ [string] ] ) [EOL] remote_ftp_tuples . append ( ( img_file_tuple [ [number] ] , img_file_tuple [ [number] ] [ [string] ] ) ) [EOL] if total_remote_size != matched_file_hath [ [number] ] : [EOL] logger . info ( [string] [string] . format ( archive = matched_file_hath [ [number] ] , folder = matched_file_hath [ [number] ] , current = filesizeformat ( total_remote_size ) , total = filesizeformat ( matched_file_hath [ [number] ] ) ) ) [EOL] continue [EOL] logger . info ( [string] [string] . format ( archive = matched_file_hath [ [number] ] , filename = matched_file_hath [ [number] ] , image_count = len ( remote_ftp_tuples ) ) ) [EOL] dir_path = mkdtemp ( ) [EOL] self . current_download [ [string] ] = len ( remote_ftp_tuples ) [EOL] for count , remote_file in enumerate ( sorted ( remote_ftp_tuples ) , start = [number] ) : [EOL] for retry_count in range ( [number] ) : [EOL] try : [EOL] with open ( os . path . join ( dir_path , remote_file [ [number] ] ) , [string] ) as file : [EOL] self . current_download [ [string] ] = count [EOL] self . write_file_update_progress ( [string] % ( str ( matched_file_hath [ [number] ] ) + [string] + remote_file [ [number] ] ) , file . write , int ( remote_file [ [number] ] ) ) [EOL] except ( ConnectionResetError , socket . timeout , TimeoutError ) : [EOL] logger . warning ( [string] . format ( count , len ( remote_ftp_tuples ) ) ) [EOL] self . ftps . close ( ) [EOL] self . start_connection ( ) [EOL] self . set_current_dir ( self . settings . providers [ [string] ] . remote_hath_dir ) [EOL] else : [EOL] break [EOL] with ZipFile ( os . path . join ( self . settings . MEDIA_ROOT , matched_file_hath [ [number] ] ) , [string] ) as archive_file : [EOL] for ( root_path , _ , file_names ) in os . walk ( dir_path ) : [EOL] for current_file in file_names : [EOL] archive_file . write ( os . path . join ( root_path , current_file ) , arcname = os . path . basename ( current_file ) ) [EOL] shutil . rmtree ( dir_path , ignore_errors = True ) [EOL] [EOL] self . process_downloaded_archive ( matched_file_hath [ [number] ] ) [EOL] [EOL] [comment] [EOL] if len ( files_torrent ) > [number] : [EOL] self . set_current_dir ( self . settings . ftps [ [string] ] ) [EOL] self . ftps . encoding = [string] [EOL] files_matched_torrent = [ ] [EOL] for line in self . ftps . mlsd ( facts = [ [string] , [string] ] ) : [EOL] if not line [ [number] ] : [EOL] continue [EOL] if [string] not in line [ [number] ] : [EOL] continue [EOL] if line [ [number] ] [ [string] ] != [string] and line [ [number] ] [ [string] ] != [string] : [EOL] continue [EOL] for archive in files_torrent : [EOL] if archive . gallery : [EOL] cleaned_torrent_name = os . path . splitext ( os . path . basename ( archive . zipped . path ) ) [ [number] ] . replace ( [string] + archive . gallery . gid + [string] , [string] ) [EOL] else : [EOL] cleaned_torrent_name = os . path . splitext ( os . path . basename ( archive . zipped . path ) ) [ [number] ] [EOL] if replace_illegal_name ( os . path . splitext ( line [ [number] ] ) [ [number] ] ) == cleaned_torrent_name : [EOL] if line [ [number] ] [ [string] ] == [string] : [EOL] files_matched_torrent . append ( ( line [ [number] ] , line [ [number] ] [ [string] ] , [number] , archive ) ) [EOL] else : [EOL] files_matched_torrent . append ( ( line [ [number] ] , line [ [number] ] [ [string] ] , int ( line [ [number] ] [ [string] ] ) , archive ) ) [EOL] for matched_file_torrent in files_matched_torrent : [EOL] if matched_file_torrent [ [number] ] == [string] : [EOL] dir_path = mkdtemp ( ) [EOL] remote_ftp_files = list ( self . ftps . mlsd ( path = matched_file_torrent [ [number] ] , facts = [ [string] , [string] ] ) ) [EOL] self . current_download [ [string] ] = len ( remote_ftp_files ) [EOL] logger . info ( [string] [string] . format ( archive = matched_file_torrent [ [number] ] , filename = matched_file_torrent [ [number] ] , image_count = len ( remote_ftp_files ) ) ) [EOL] for count , img_file_tuple in enumerate ( remote_ftp_files ) : [EOL] if img_file_tuple [ [number] ] [ [string] ] != [string] : [EOL] continue [EOL] for retry_count in range ( [number] ) : [EOL] try : [EOL] with open ( os . path . join ( dir_path , img_file_tuple [ [number] ] ) , [string] ) as file : [EOL] self . current_download [ [string] ] = count [EOL] self . write_file_update_progress ( [string] % ( str ( matched_file_torrent [ [number] ] ) + [string] + img_file_tuple [ [number] ] ) , file . write , int ( img_file_tuple [ [number] ] [ [string] ] ) ) [EOL] except ( ConnectionResetError , socket . timeout , TimeoutError ) : [EOL] logger . warning ( [string] ) [EOL] self . ftps . close ( ) [EOL] self . start_connection ( ) [EOL] self . set_current_dir ( self . settings . ftps [ [string] ] ) [EOL] else : [EOL] break [EOL] with ZipFile ( matched_file_torrent [ [number] ] . zipped . path , [string] ) as archive_file : [EOL] for ( root_path , _ , file_names ) in os . walk ( dir_path ) : [EOL] for current_file in file_names : [EOL] archive_file . write ( os . path . join ( root_path , current_file ) , arcname = os . path . basename ( current_file ) ) [EOL] shutil . rmtree ( dir_path , ignore_errors = True ) [EOL] else : [EOL] logger . info ( [string] . format ( archive = matched_file_torrent [ [number] ] , remote = matched_file_torrent [ [number] ] , local = matched_file_torrent [ [number] ] . zipped . path ) ) [EOL] self . current_download [ [string] ] = [number] [EOL] for retry_count in range ( [number] ) : [EOL] try : [EOL] with open ( matched_file_torrent [ [number] ] . zipped . path , [string] ) as file : [EOL] self . current_download [ [string] ] = [number] [EOL] self . write_file_update_progress ( [string] % matched_file_torrent [ [number] ] , file . write , matched_file_torrent [ [number] ] ) [EOL] except ( ConnectionResetError , socket . timeout , TimeoutError ) : [EOL] logger . warning ( [string] ) [EOL] self . ftps . close ( ) [EOL] self . start_connection ( ) [EOL] self . set_current_dir ( self . settings . ftps [ [string] ] ) [EOL] else : [EOL] break [EOL] if self . settings . convert_rar_to_zip and os . path . splitext ( matched_file_torrent [ [number] ] ) [ [number] ] . lower ( ) == [string] : [EOL] logger . info ( [string] . format ( matched_file_torrent [ [number] ] , matched_file_torrent [ [number] ] . zipped . path ) ) [EOL] convert_rar_to_zip ( matched_file_torrent [ [number] ] . zipped . path ) [EOL] [EOL] self . process_downloaded_archive ( matched_file_torrent [ [number] ] ) [EOL] [EOL] self . ftps . close ( ) [EOL] [EOL] def copy_all_missing ( self , mode , archives = None ) : [EOL] files_torrent = [ ] [EOL] files_hath = [ ] [EOL] [EOL] if not archives : [EOL] found_archives = list ( Archive . objects . filter_by_dl_remote ( ) ) [EOL] else : [EOL] found_archives = archives [EOL] [EOL] if not found_archives : [EOL] return [EOL] [EOL] for archive in found_archives : [EOL] if not os . path . isfile ( archive . zipped . path ) and archive . match_type : [EOL] if [string] in archive . match_type : [EOL] files_torrent . append ( archive ) [EOL] elif [string] in archive . match_type : [EOL] files_hath . append ( archive ) [EOL] [EOL] if len ( files_torrent ) + len ( files_hath ) == [number] : [EOL] return [EOL] [EOL] [comment] [EOL] if len ( files_hath ) > [number] : [EOL] files_matched_hath = [ ] [EOL] for matched_file in os . listdir ( self . settings . providers [ [string] ] . local_hath_folder ) : [EOL] if os . path . isfile ( os . path . join ( self . settings . providers [ [string] ] . local_hath_folder , matched_file ) ) : [EOL] continue [EOL] m = re . search ( [string] , matched_file ) [EOL] if m : [EOL] for archive in files_hath : [EOL] if archive . gallery and archive . filesize and m . group ( [number] ) == archive . gallery . gid : [EOL] files_matched_hath . append ( [ matched_file , archive . zipped . path , int ( archive . filesize ) , archive ] ) [EOL] [EOL] for img_dir in files_matched_hath : [EOL] total_remote_size = [number] [EOL] remote_files = [ ] [EOL] directory = os . path . join ( self . settings . providers [ [string] ] . local_hath_folder , img_dir [ [number] ] ) [EOL] for img_file in os . listdir ( directory ) : [EOL] if not os . path . isfile ( os . path . join ( directory , img_file ) ) or img_file == [string] : [EOL] continue [EOL] total_remote_size += os . stat ( os . path . join ( directory , img_file ) ) . st_size [EOL] remote_files . append ( os . path . join ( directory , img_file ) ) [EOL] if total_remote_size != img_dir [ [number] ] : [EOL] logger . info ( [string] [string] . format ( archive = img_dir [ [number] ] , folder = img_dir [ [number] ] , current = filesizeformat ( total_remote_size ) , total = filesizeformat ( img_dir [ [number] ] ) ) ) [EOL] continue [EOL] logger . info ( [string] [string] . format ( archive = img_dir [ [number] ] , filename = img_dir [ [number] ] , image_count = len ( remote_files ) ) ) [EOL] dir_path = mkdtemp ( ) [EOL] for img_file_original in remote_files : [EOL] img_file = os . path . split ( img_file_original ) [ [number] ] [EOL] if mode == [string] : [EOL] shutil . move ( img_file_original , os . path . join ( dir_path , img_file ) ) [EOL] else : [EOL] shutil . copy ( img_file_original , os . path . join ( dir_path , img_file ) ) [EOL] with ZipFile ( os . path . join ( self . settings . MEDIA_ROOT , img_dir [ [number] ] ) , [string] ) as archive_file : [EOL] for ( root_path , _ , file_names ) in os . walk ( dir_path ) : [EOL] for current_file in file_names : [EOL] archive_file . write ( os . path . join ( root_path , current_file ) , arcname = os . path . basename ( current_file ) ) [EOL] shutil . rmtree ( dir_path , ignore_errors = True ) [EOL] [EOL] self . process_downloaded_archive ( img_dir [ [number] ] ) [EOL] [EOL] [comment] [EOL] if len ( files_torrent ) > [number] : [EOL] files_matched_torrent = [ ] [EOL] for filename in os . listdir ( self . settings . torrent [ [string] ] ) : [EOL] for archive in files_torrent : [EOL] if archive . gallery : [EOL] cleaned_torrent_name = os . path . splitext ( os . path . basename ( archive . zipped . path ) ) [ [number] ] . replace ( [string] + archive . gallery . gid + [string] , [string] ) [EOL] else : [EOL] cleaned_torrent_name = os . path . splitext ( os . path . basename ( archive . zipped . path ) ) [ [number] ] [EOL] if replace_illegal_name ( os . path . splitext ( filename ) [ [number] ] ) == cleaned_torrent_name : [EOL] files_matched_torrent . append ( [ filename , not os . path . isfile ( os . path . join ( self . settings . torrent [ [string] ] , filename ) ) , archive ] ) [EOL] [EOL] for matched_file in files_matched_torrent : [EOL] target = os . path . join ( self . settings . torrent [ [string] ] , matched_file [ [number] ] ) [EOL] if matched_file [ [number] ] : [EOL] logger . info ( [string] . format ( archive = matched_file [ [number] ] , filename = matched_file [ [number] ] , ) ) [EOL] dir_path = mkdtemp ( ) [EOL] for img_file in os . listdir ( target ) : [EOL] if not os . path . isfile ( os . path . join ( target , img_file ) ) : [EOL] continue [EOL] if mode == [string] : [EOL] shutil . move ( os . path . join ( target , img_file ) , os . path . join ( dir_path , img_file ) ) [EOL] else : [EOL] shutil . copy ( os . path . join ( target , img_file ) , os . path . join ( dir_path , img_file ) ) [EOL] [EOL] with ZipFile ( matched_file [ [number] ] . zipped . path , [string] ) as archive_file : [EOL] for ( root_path , _ , file_names ) in os . walk ( dir_path ) : [EOL] for current_file in file_names : [EOL] archive_file . write ( os . path . join ( root_path , current_file ) , arcname = os . path . basename ( current_file ) ) [EOL] shutil . rmtree ( dir_path , ignore_errors = True ) [EOL] else : [EOL] logger . info ( [string] . format ( archive = matched_file [ [number] ] , filename = matched_file [ [number] ] , ) ) [EOL] if mode == [string] : [EOL] shutil . move ( target , matched_file [ [number] ] . zipped . path ) [EOL] else : [EOL] shutil . copy ( target , matched_file [ [number] ] . zipped . path ) [EOL] if self . settings . convert_rar_to_zip and os . path . splitext ( matched_file [ [number] ] ) [ [number] ] . lower ( ) == [string] : [EOL] logger . info ( [string] . format ( matched_file [ [number] ] , matched_file [ [number] ] . zipped . path ) ) [EOL] convert_rar_to_zip ( matched_file [ [number] ] . zipped . path ) [EOL] [EOL] self . process_downloaded_archive ( matched_file [ [number] ] ) [EOL] [EOL] def transfer_all_missing ( self , archives = None ) : [EOL] [EOL] if self . settings . download_handler . startswith ( [string] ) : [EOL] self . copy_all_missing ( self . settings . download_handler , archives ) [EOL] else : [EOL] for retry_count in range ( [number] ) : [EOL] try : [EOL] self . download_all_missing ( archives ) [EOL] except ( ConnectionResetError , socket . timeout , TimeoutError ) as e : [EOL] logger . warning ( [string] . format ( retry_count + [number] , e ) ) [EOL] else : [EOL] return [EOL] logger . error ( [string] ) [EOL] [EOL] [EOL] class TimedPostDownloader ( BaseScheduler ) : [EOL] [EOL] thread_name = [string] [EOL] [EOL] def __init__ ( self , * args , parallel_post_downloaders = [number] , ** kwargs ) : [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] self . post_downloader = { } [EOL] self . post_queue = queue . Queue ( ) [EOL] self . parallel_post_downloaders = parallel_post_downloaders [EOL] [EOL] @ staticmethod def timer_to_seconds ( timer ) : [EOL] return timer * [number] [EOL] [EOL] def job ( self ) : [EOL] while not self . stop . is_set ( ) : [EOL] seconds_to_wait = self . wait_until_next_run ( ) [EOL] if self . stop . wait ( timeout = seconds_to_wait ) : [EOL] self . post_downloader = { } [EOL] return [EOL] [EOL] found_archives = Archive . objects . filter_by_dl_remote ( ) [EOL] if found_archives : [EOL] [EOL] logger . info ( [string] . format ( len ( [ x for x in found_archives if [string] in x . match_type ] ) , len ( [ x for x in found_archives if [string] in x . match_type ] ) , ) ) [EOL] for archive in found_archives : [EOL] self . post_queue . put ( archive ) [EOL] thread_array = [ ] [EOL] [EOL] for x in range ( [number] , self . parallel_post_downloaders + [number] ) : [EOL] post_downloader = PostDownloader ( self . settings , web_queue = self . web_queue ) [EOL] self . post_downloader [ x ] = post_downloader [EOL] post_download_thread = threading . Thread ( name = [string] . format ( self . thread_name , x ) , target = self . start_post_downloader , args = ( post_downloader , ) ) [EOL] post_download_thread . daemon = True [EOL] post_download_thread . start ( ) [EOL] thread_array . append ( post_download_thread ) [EOL] [EOL] for thread in thread_array : [EOL] thread . join ( ) [EOL] [EOL] self . post_downloader = { } [EOL] logger . info ( [string] ) [EOL] [EOL] self . update_last_run ( django_tz . now ( ) ) [EOL] [EOL] def start_post_downloader ( self , post_downloader ) : [EOL] while True : [EOL] try : [EOL] item = self . post_queue . get_nowait ( ) [EOL] except queue . Empty : [EOL] return [EOL] try : [EOL] post_downloader . transfer_all_missing ( ( item , ) ) [EOL] self . post_queue . task_done ( ) [EOL] except BaseException : [EOL] logger . critical ( traceback . format_exc ( ) ) [EOL] [EOL] def current_download ( self ) : [EOL] return [ x . current_download for x in self . post_downloader . values ( ) ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $PostDownloader$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $PostDownloader$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Dict[builtins.str,typing.Any]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Dict , Union [EOL] import typing [EOL] import urllib [EOL] import core [EOL] import ssl [EOL] import builtins [EOL] from typing import Dict , Any , Union , Optional [EOL] [EOL] import transmissionrpc [EOL] import os [EOL] [EOL] from base64 import b64encode [EOL] from http . client import BadStatusLine [EOL] import sys [EOL] from urllib . error import HTTPError , URLError [EOL] from urllib . request import Request , build_opener , HTTPSHandler [EOL] import ssl [EOL] [EOL] [EOL] from transmissionrpc . error import HTTPHandlerError [EOL] [EOL] from core . base . types import TorrentClient , DataDict [EOL] [EOL] [EOL] class Transmission ( TorrentClient ) : [EOL] [EOL] name = [string] [EOL] convert_to_base64 = True [EOL] send_url = False [EOL] [EOL] def __init__ ( self , address = [string] , port = [number] , user = [string] , password = [string] , secure = True ) : [EOL] super ( ) . __init__ ( address = address , port = port , user = user , password = password , secure = secure ) [EOL] self . trans = None [EOL] self . error = [string] [EOL] [EOL] def __str__ ( self ) : [EOL] return self . name [EOL] [EOL] def add_url ( self , enc_torrent , download_dir = None ) : [EOL] result = self . add_torrent ( enc_torrent , download_dir = download_dir ) [EOL] if self . expected_torrent_name : [EOL] self . expected_torrent_name = os . path . splitext ( self . expected_torrent_name ) [ [number] ] [EOL] return result [EOL] [EOL] def add_torrent ( self , enc_torrent , download_dir = None ) : [EOL] [EOL] if not self . trans : [EOL] return False [EOL] self . total_size = [number] [EOL] [EOL] if self . set_expected : [EOL] self . expected_torrent_name = [string] [EOL] [EOL] try : [EOL] torr = self . trans . add_torrent ( enc_torrent , download_dir = download_dir , timeout = [number] ) [EOL] [EOL] if self . set_expected : [EOL] self . expected_torrent_name = torr . name [EOL] [EOL] c = self . trans . get_files ( torr . id ) [EOL] for file_t in c [ torr . id ] : [EOL] self . total_size += int ( c [ torr . id ] [ file_t ] [ [string] ] ) [EOL] if self . set_expected and torr . name == c [ torr . id ] [ file_t ] [ [string] ] : [EOL] self . expected_torrent_name = os . path . splitext ( self . expected_torrent_name ) [ [number] ] [EOL] [EOL] return True [EOL] [EOL] except transmissionrpc . TransmissionError as e : [EOL] self . error = e . message [EOL] if [string] in e . message : [EOL] return False [EOL] elif [string] in e . message : [EOL] return True [EOL] else : [EOL] return False [EOL] [EOL] def connect ( self ) : [EOL] try : [EOL] if [string] in self . address : [EOL] http_handler = TransmissionHTTPSHandler ( secure = self . secure ) [EOL] else : [EOL] http_handler = None [EOL] self . trans = transmissionrpc . Client ( address = self . address , user = self . user , password = self . password , http_handler = http_handler ) [EOL] except transmissionrpc . TransmissionError : [EOL] return False [EOL] return True [EOL] [EOL] [EOL] class TransmissionHTTPSHandler ( transmissionrpc . HTTPHandler ) : [EOL] [EOL] [docstring] [EOL] [EOL] def __init__ ( self , secure = True ) : [EOL] transmissionrpc . HTTPHandler . __init__ ( self ) [EOL] self . http_opener = build_opener ( ) [EOL] self . auth = { } [EOL] self . secure = secure [EOL] [EOL] def set_authentication ( self , uri , login , password ) : [EOL] if self . secure : [EOL] context = ssl . create_default_context ( ) [EOL] else : [EOL] context = ssl . SSLContext ( ssl . PROTOCOL_TLSv1_2 ) [EOL] context . verify_mode = ssl . CERT_NONE [EOL] context . check_hostname = False [EOL] self . http_opener = build_opener ( HTTPSHandler ( context = context ) ) [EOL] self . auth = { [string] : [string] % b64encode ( str . encode ( login + [string] + password ) ) . decode ( [string] ) } [EOL] [EOL] def request ( self , url , query , headers , timeout ) : [EOL] headers = { ** self . auth , ** headers } [EOL] request = Request ( url , query . encode ( [string] ) , headers ) [EOL] try : [EOL] if ( sys . version_info [ [number] ] == [number] and sys . version_info [ [number] ] > [number] ) or sys . version_info [ [number] ] > [number] : [EOL] response = self . http_opener . open ( request , timeout = timeout ) [EOL] else : [EOL] response = self . http_opener . open ( request ) [EOL] except HTTPError as http_error : [EOL] if http_error . fp is None : [comment] [EOL] raise HTTPHandlerError ( http_error . filename , http_error . code , http_error . msg , dict ( http_error . hdrs ) ) [comment] [EOL] else : [EOL] raise HTTPHandlerError ( http_error . filename , http_error . code , http_error . msg , dict ( http_error . hdrs ) , http_error . read ( ) ) [comment] [EOL] except URLError as url_error : [EOL] [comment] [EOL] [comment] [EOL] if hasattr ( url_error . reason , [string] ) and isinstance ( url_error . reason . args , tuple ) and len ( url_error . reason . args ) == [number] : [comment] [EOL] raise HTTPHandlerError ( httpcode = url_error . reason . args [ [number] ] , httpmsg = url_error . reason . args [ [number] ] ) [comment] [EOL] else : [EOL] raise HTTPHandlerError ( httpmsg = [string] % url_error . reason ) [comment] [EOL] except BadStatusLine as line_error : [EOL] raise HTTPHandlerError ( httpmsg = [string] % line_error . line ) [comment] [EOL] return response . read ( ) . decode ( [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $typing.Dict[typing.Any,typing.Any]$ 0 $builtins.int$ 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 $urllib.request.Request$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $urllib.request.Request$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $urllib.request.Request$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0
from typing import Any , Dict , Optional , Union , List [EOL] import _importlib_modulespec [EOL] import typing [EOL] import builtins [EOL] import core [EOL] import os [EOL] import sys [EOL] import pkgutil [EOL] import inspect [EOL] import types [EOL] from typing import Any , Dict , Optional , Union [EOL] [EOL] from core . base . types import TorrentClient [EOL] [EOL] [EOL] def get_torrent_client ( torrent_settings ) : [EOL] client = None [EOL] torrent_module = None [EOL] for module_name in modules_name : [EOL] if module_name == torrent_settings [ [string] ] : [EOL] if module_name not in sys . modules : [EOL] full_package_name = [string] % ( [string] , module_name ) [EOL] torrent_module = __import__ ( full_package_name , fromlist = [ module_name ] ) [EOL] else : [EOL] torrent_module = module_name [EOL] if not torrent_module : [EOL] return None [EOL] for _ , obj in inspect . getmembers ( torrent_module ) : [EOL] if inspect . isclass ( obj ) and hasattr ( obj , [string] ) and [string] in getattr ( obj , [string] ) : [EOL] client = obj ( torrent_settings [ [string] ] , torrent_settings [ [string] ] , torrent_settings [ [string] ] , torrent_settings [ [string] ] , secure = not torrent_settings [ [string] ] , ) [EOL] return client [EOL] [EOL] [EOL] modules_name = list ( ) [EOL] [EOL] for importer , package_name , is_pkg in pkgutil . iter_modules ( [ os . path . dirname ( __file__ ) ] ) : [EOL] modules_name . append ( package_name ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[core.base.types.TorrentClient]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0
	0
[comment] [EOL] from typing import List [EOL] import core [EOL] import typing [EOL] import logging [EOL] import builtins [EOL] import threading [EOL] [EOL] import logging [EOL] import traceback [EOL] import typing [EOL] [EOL] from core . web . crawler import WebCrawler [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from core . base . setup import Settings [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class CrawlerThread ( threading . Thread ) : [EOL] [EOL] def __init__ ( self , settings , argv ) : [EOL] [EOL] threading . Thread . __init__ ( self , name = [string] ) [EOL] self . settings = settings [EOL] self . argv = argv [EOL] [EOL] def run ( self ) : [EOL] try : [EOL] web_crawler = WebCrawler ( self . settings ) [EOL] web_crawler . start_crawling ( self . argv ) [EOL] except BaseException : [EOL] logger . critical ( traceback . format_exc ( ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $core.base.setup.Settings$ 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.setup.Settings$ 0 $core.base.setup.Settings$ 0 0 0 $typing.List[builtins.str]$ 0 $typing.List[builtins.str]$ 0 0 0 $None$ 0 0 0 0 0 0 0 0 $core.web.crawler.WebCrawler$ 0 0 0 0 0 0 0 0 $core.web.crawler.WebCrawler$ 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0
from typing import List [EOL] import core [EOL] import typing [EOL] import logging [EOL] import builtins [EOL] import threading [EOL] [EOL] import logging [EOL] import traceback [EOL] import typing [EOL] from typing import List [EOL] [EOL] from core . local . foldercrawler import FolderCrawler [EOL] [EOL] if typing . TYPE_CHECKING : [EOL] from core . base . setup import Settings [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class FolderCrawlerThread ( threading . Thread ) : [EOL] [EOL] def __init__ ( self , settings , argv ) : [EOL] threading . Thread . __init__ ( self , name = [string] ) [EOL] self . settings = settings [EOL] self . argv = argv [EOL] [EOL] def run ( self ) : [EOL] try : [EOL] folder_crawler = FolderCrawler ( self . settings ) [EOL] folder_crawler . start_crawling ( self . argv ) [EOL] except BaseException : [EOL] logger . critical ( traceback . format_exc ( ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $core.base.setup.Settings$ 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $core.base.setup.Settings$ 0 $core.base.setup.Settings$ 0 0 0 $typing.List[builtins.str]$ 0 $typing.List[builtins.str]$ 0 0 0 $None$ 0 0 0 0 0 0 0 0 $core.local.foldercrawler.FolderCrawler$ 0 0 0 0 0 0 0 0 $core.local.foldercrawler.FolderCrawler$ 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0
	0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any , OrderedDict , List [EOL] import collections [EOL] import typing [EOL] import builtins [EOL] from collections import OrderedDict [EOL] [EOL] [EOL] [comment] [EOL] TOKEN_INTEGER = [string] [EOL] [EOL] [comment] [EOL] TOKEN_LIST = [string] [EOL] [EOL] [comment] [EOL] TOKEN_DICT = [string] [EOL] [EOL] [comment] [EOL] TOKEN_END = [string] [EOL] [EOL] [comment] [EOL] TOKEN_STRING_SEPARATOR = [string] [EOL] [EOL] [EOL] class Decoder : [EOL] [docstring] [EOL] def __init__ ( self , data ) : [EOL] if not isinstance ( data , bytes ) : [EOL] raise TypeError ( [string] ) [EOL] self . _data = data [EOL] self . _index = [number] [EOL] [EOL] def decode ( self ) : [EOL] [docstring] [EOL] c = self . _peek ( ) [EOL] if c is None : [EOL] raise EOFError ( [string] ) [EOL] elif c == TOKEN_INTEGER : [EOL] self . _consume ( ) [comment] [EOL] return self . _decode_int ( ) [EOL] elif c == TOKEN_LIST : [EOL] self . _consume ( ) [comment] [EOL] return self . _decode_list ( ) [EOL] elif c == TOKEN_DICT : [EOL] self . _consume ( ) [comment] [EOL] return self . _decode_dict ( ) [EOL] elif c == TOKEN_END : [EOL] return None [EOL] elif c in [string] : [EOL] return self . _decode_string ( ) [EOL] else : [EOL] raise RuntimeError ( [string] . format ( str ( self . _index ) ) ) [EOL] [EOL] def _peek ( self ) : [EOL] [docstring] [EOL] if self . _index + [number] >= len ( self . _data ) : [EOL] return None [EOL] return self . _data [ self . _index : self . _index + [number] ] [EOL] [EOL] def _consume ( self ) : [EOL] [docstring] [EOL] self . _index += [number] [EOL] [EOL] def _read ( self , length ) : [EOL] [docstring] [EOL] if self . _index + length > len ( self . _data ) : [EOL] raise IndexError ( [string] . format ( str ( length ) , str ( self . _index ) ) ) [EOL] res = self . _data [ self . _index : self . _index + length ] [EOL] self . _index += length [EOL] return res [EOL] [EOL] def _read_until ( self , token ) : [EOL] [docstring] [EOL] try : [EOL] occurrence = self . _data . index ( token , self . _index ) [EOL] result = self . _data [ self . _index : occurrence ] [EOL] self . _index = occurrence + [number] [EOL] return result [EOL] except ValueError : [EOL] raise RuntimeError ( [string] . format ( str ( token ) ) ) [EOL] [EOL] def _decode_int ( self ) : [EOL] return int ( self . _read_until ( TOKEN_END ) ) [EOL] [EOL] def _decode_list ( self ) : [EOL] res = [ ] [EOL] [comment] [EOL] while self . _data [ self . _index : self . _index + [number] ] != TOKEN_END : [EOL] res . append ( self . decode ( ) ) [EOL] self . _consume ( ) [comment] [EOL] return res [EOL] [EOL] def _decode_dict ( self ) : [EOL] res = OrderedDict ( ) [EOL] while self . _data [ self . _index : self . _index + [number] ] != TOKEN_END : [EOL] key = self . decode ( ) [EOL] obj = self . decode ( ) [EOL] res [ key ] = obj [EOL] self . _consume ( ) [comment] [EOL] return res [EOL] [EOL] def _decode_string ( self ) : [EOL] bytes_to_read = int ( self . _read_until ( TOKEN_STRING_SEPARATOR ) ) [EOL] data = self . _read ( bytes_to_read ) [EOL] return data [EOL] [EOL] [EOL] class Encoder : [EOL] [docstring] [EOL] def __init__ ( self , data ) : [EOL] self . _data = data [EOL] [EOL] def encode ( self ) : [EOL] [docstring] [EOL] return self . encode_next ( self . _data ) [EOL] [EOL] def encode_next ( self , data ) : [EOL] if type ( data ) == str : [EOL] return self . _encode_string ( data ) [EOL] elif type ( data ) == int : [EOL] return self . _encode_int ( data ) [EOL] elif type ( data ) == list : [EOL] return self . _encode_list ( data ) [EOL] elif type ( data ) == dict or type ( data ) == OrderedDict : [EOL] return self . _encode_dict ( data ) [EOL] elif type ( data ) == bytes : [EOL] return self . _encode_bytes ( data ) [EOL] else : [EOL] return None [EOL] [EOL] def _encode_int ( self , value ) : [EOL] return str . encode ( [string] + str ( value ) + [string] ) [EOL] [EOL] def _encode_string ( self , value ) : [EOL] res = str ( len ( value ) ) + [string] + value [EOL] return str . encode ( res ) [EOL] [EOL] def _encode_bytes ( self , value ) : [EOL] result = bytearray ( ) [EOL] result += str . encode ( str ( len ( value ) ) ) [EOL] result += [string] [EOL] result += value [EOL] return result [EOL] [EOL] def _encode_list ( self , data ) : [EOL] result = bytearray ( [string] , [string] ) [EOL] result += [string] . join ( [ self . encode_next ( item ) for item in data ] ) [EOL] result += [string] [EOL] return result [EOL] [EOL] def _encode_dict ( self , data ) : [EOL] result = bytearray ( [string] , [string] ) [EOL] for k , v in data . items ( ) : [EOL] key = self . encode_next ( k ) [EOL] value = self . encode_next ( v ) [EOL] if key and value : [EOL] result += key [EOL] result += value [EOL] else : [EOL] raise RuntimeError ( [string] ) [EOL] result += [string] [EOL] return result [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bytearray$ 0 0 0 0 0 $builtins.bytearray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bytearray$ 0 0 0 $builtins.bytearray$ 0 0 0 0 $builtins.bytearray$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.bytearray$ 0 0 0 0 0 0 0 0 $builtins.bytearray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bytearray$ 0 0 0 0 $builtins.bytearray$ 0 0 0 $builtins.bytes$ 0 0 0 $builtins.dict$ 0 0 0 $builtins.bytearray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.dict$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 $builtins.bytearray$ 0 $typing.Any$ 0 $builtins.bytearray$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $builtins.bytearray$ 0 0 0 0 $builtins.bytearray$ 0