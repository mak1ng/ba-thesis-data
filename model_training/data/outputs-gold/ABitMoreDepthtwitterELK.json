from typing import Any , Dict , List [EOL] import builtins [EOL] import typing [EOL] [docstring] [EOL] [EOL] import json [EOL] from typing import Any , Dict , List [EOL] [EOL] from elasticsearch import Elasticsearch [EOL] import elasticsearch_dsl as es [EOL] [EOL] from ingress . utils import setup_mappings [EOL] [EOL] setup_mappings ( [string] , [string] ) [EOL] [EOL] client = Elasticsearch ( ) [EOL] [EOL] search = es . Search ( using = client ) [EOL] [EOL] geotagged_records = search . query ( [string] , geotagged = True ) [ [number] : [number] ] . execute ( ) [EOL] untagged_records = search . query ( [string] , geotagged = False ) [ [number] : [number] ] . execute ( ) [EOL] [EOL] combined_records = [ ] [EOL] combined_records . extend ( geotagged_records . hits ) [EOL] combined_records . extend ( untagged_records . hits ) [EOL] [EOL] geotagged_data = [ ] [EOL] [EOL] for hit in combined_records : [EOL] record = { } [EOL] for attr in dir ( hit ) : [EOL] attr_data = getattr ( hit , attr ) [EOL] if isinstance ( attr_data , es . AttrDict ) : [EOL] record [ attr ] = attr_data . to_dict ( ) [EOL] else : [EOL] record [ attr ] = attr_data [EOL] geotagged_data . append ( record ) [EOL] [EOL] with open ( [string] , [string] ) as sample_data : [EOL] for record in geotagged_data : [EOL] sample_data . write ( [string] . format ( json . dumps ( record ) ) ) [EOL] [EOL] print ( [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Dict[builtins.str,typing.Any]]$ 0 0 0 0 $typing.List[typing.Dict[builtins.str,typing.Any]]$ 0 0 0 $typing.Any$ 0 0 0 0 $typing.List[typing.Dict[builtins.str,typing.Any]]$ 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 $typing.List[typing.Dict[builtins.str,typing.Any]]$ 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 $typing.Any$ 0 $typing.List[typing.Any]$ 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0
from typing import Any , List [EOL] import typing [EOL] [docstring] [EOL] [EOL] from io import open [EOL] from typing import List [EOL] [EOL] from setuptools import find_packages , setup [EOL] [EOL] with open ( [string] , [string] ) as f : [EOL] for line in f : [EOL] if line . startswith ( [string] ) : [EOL] version = line . strip ( ) . split ( [string] ) [ [number] ] . strip ( [string] ) [EOL] break [EOL] else : [EOL] version = [string] [EOL] [EOL] with open ( [string] , [string] , encoding = [string] ) as f : [EOL] README = f . read ( ) [EOL] [EOL] REQUIRES = [ ] [EOL] [EOL] setup ( name = [string] , version = version , description = [string] , long_description = README , author = [string] , author_email = [string] , maintainer = [string] , maintainer_email = [string] , url = [string] , license = [string] , keywords = [ [string] , ] , entry_points = { [string] : [ [string] ] , } , classifiers = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , ] , install_requires = REQUIRES , tests_require = [ [string] , [string] , ] , packages = find_packages ( ) , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.List$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Type , Any , Generator , Dict [EOL] import builtins [EOL] import typing [EOL] import logging [EOL] [docstring] [EOL] [EOL] import logging [EOL] import inspect [EOL] [EOL] from typing import Any , Dict , Generator , Type [EOL] [EOL] import elasticsearch_dsl as es [EOL] [EOL] from ingress . structures import PluginBase , SINGLETON_CACHE [EOL] [EOL] LOG = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def get_singleton_instance ( obj_type , * args , ** kwargs ) : [EOL] [docstring] [EOL] LOG . debug ( [string] , obj_type ) [EOL] if obj_type not in SINGLETON_CACHE : [EOL] LOG . debug ( [string] , obj_type ) [EOL] object_instance = obj_type ( * args , ** kwargs ) [EOL] SINGLETON_CACHE [ obj_type ] = object_instance [EOL] else : [EOL] LOG . debug ( [string] , obj_type ) [EOL] object_instance = SINGLETON_CACHE [ obj_type ] [EOL] [EOL] return object_instance [EOL] [EOL] [EOL] def create_es_connection ( es_host ) : [EOL] [docstring] [EOL] es . connections . create_connection ( hosts = [ es_host ] ) [EOL] [EOL] [EOL] def setup_mappings ( twitter_index , es_host = None ) : [EOL] [docstring] [EOL] if es_host is None : [EOL] LOG . warning ( [string] ) [EOL] return [EOL] [EOL] create_es_connection ( es_host ) [EOL] mapping_dict = aggregate_data_schema ( PluginBase ) [EOL] tweet_mapping = es . Mapping ( [string] ) [EOL] for key , value in mapping_dict . items ( ) : [EOL] tweet_mapping . field ( key , value ) [EOL] [EOL] tweet_index = get_singleton_instance ( es . Index , twitter_index ) [EOL] LOG . info ( [string] , twitter_index ) [EOL] tweet_index . settings ( ** { [string] : [number] , [string] : [number] , [string] : [number] , } ) [EOL] [comment] [EOL] tweet_index . mapping ( tweet_mapping ) [EOL] LOG . info ( [string] , twitter_index ) [EOL] if not tweet_index . exists ( ) : [EOL] LOG . info ( [string] ) [EOL] tweet_index . create ( ) [EOL] else : [EOL] LOG . info ( [string] ) [EOL] tweet_index . save ( ) [EOL] [EOL] [EOL] def aggregate_data_schema ( base_class , include_defaults = True , ) : [EOL] [docstring] [EOL] mapping = { } [EOL] for subclass in find_subclasses ( base_class ) : [EOL] subclass_data_schema = None [EOL] try : [EOL] subclass_data_schema = getattr ( subclass , [string] ) [EOL] except AttributeError : [EOL] continue [EOL] if subclass_data_schema : [EOL] mapping . update ( subclass_data_schema ) [EOL] [EOL] if include_defaults : [EOL] mapping [ [string] ] = es . Object ( dynamic = True ) [EOL] mapping [ [string] ] = es . Date ( ) [EOL] [EOL] return mapping [EOL] [EOL] [EOL] def find_subclasses ( cls ) : [EOL] [docstring] [EOL] if not inspect . isclass ( cls ) : [EOL] raise TypeError ( [string] . format ( cls ) ) [EOL] [EOL] for class_ in cls . __subclasses__ ( ) : [EOL] yield class_ [EOL] for return_value in find_subclasses ( class_ ) : [EOL] yield return_value [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Generator[typing.Type,None,None]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Dict [EOL] import builtins [EOL] import typing [EOL] import logging [EOL] [docstring] [EOL] [EOL] import json [EOL] import logging [EOL] from copy import deepcopy [EOL] [EOL] import arrow [EOL] import tweepy [EOL] [EOL] [comment] [EOL] from ingress . celery import process_tweet [EOL] [EOL] LOG = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class QueueListener ( tweepy . StreamListener ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , twitter_index , ignore_retweets = False , * args , ** kwargs ) : [EOL] [docstring] [EOL] self . ignore_retweets = ignore_retweets [EOL] self . twitter_index = twitter_index [EOL] [EOL] super ( ) . __init__ ( * args , ** kwargs ) [EOL] [EOL] def on_data ( self , raw_data ) : [EOL] [docstring] [EOL] try : [EOL] tweet = { } [EOL] json_data = json . loads ( raw_data ) [EOL] if self . ignore_retweets and [string] in json_data : [EOL] LOG . info ( [string] ) [EOL] return [EOL] [EOL] tweet [ [string] ] = deepcopy ( json_data ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] tweet [ [string] ] = arrow . get ( int ( json_data . get ( [string] ) ) / [number] ) . datetime [EOL] except ( TypeError , json . JSONDecodeError ) : [EOL] LOG . error ( [string] ) [EOL] return [EOL] LOG . debug ( [string] , json_data . get ( [string] , None ) ) [EOL] process_tweet . delay ( twitter_index = self . twitter_index , tweet_data = tweet ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 $builtins.bool$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0
from typing import Any , List [EOL] import builtins [EOL] import typing [EOL] import logging [EOL] [docstring] [EOL] [EOL] import logging [EOL] import sys [EOL] [EOL] from os import environ [EOL] [EOL] import tweepy [EOL] [EOL] from ingress import ES_CONNECTION_STRING [EOL] from ingress . utils import get_singleton_instance , setup_mappings [EOL] from ingress . listeners import QueueListener [EOL] [EOL] LOG = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def shutdown ( exit_code = [number] ) : [EOL] [docstring] [EOL] LOG . info ( [string] ) [EOL] get_singleton_instance ( tweepy . Stream ) . disconnect ( ) [EOL] sys . exit ( exit_code ) [EOL] [EOL] [EOL] def main ( ) : [EOL] [docstring] [EOL] LOG . debug ( [string] ) [EOL] consumer_key = environ [ [string] ] [EOL] consumer_secret = environ [ [string] ] [EOL] oauth_key = environ [ [string] ] [EOL] oauth_secret = environ [ [string] ] [EOL] [EOL] if [string] in environ : [EOL] tweet_filters = environ [ [string] ] . split ( [string] ) [EOL] else : [EOL] tweet_filters = [ [string] , [string] , [string] ] [EOL] LOG . info ( [string] , tweet_filters ) [EOL] [EOL] index_suffix = [string] . join ( tweet_filters ) . lower ( ) . replace ( [string] , [string] ) [EOL] twitter_index = [string] . format ( index_suffix ) [EOL] [EOL] auth = tweepy . OAuthHandler ( consumer_key , consumer_secret ) [EOL] auth . set_access_token ( oauth_key , oauth_secret ) [EOL] [EOL] LOG . debug ( [string] ) [EOL] api = get_singleton_instance ( tweepy . Stream , auth = auth , listener = QueueListener ( ignore_retweets = True , twitter_index = twitter_index ) ) [EOL] [EOL] try : [EOL] setup_mappings ( index_suffix , ES_CONNECTION_STRING , ) [EOL] LOG . info ( [string] ) [EOL] api . filter ( track = tweet_filters , is_async = False ) [EOL] [EOL] except KeyboardInterrupt : [EOL] LOG . info ( [string] ) [EOL] shutdown ( ) [EOL] [EOL] except Exception : [comment] [EOL] LOG . error ( [string] , exc_info = True ) [EOL] shutdown ( [number] ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Mapping , Any , Dict , Union [EOL] import builtins [EOL] import typing [EOL] import queue [EOL] import logging [EOL] [docstring] [EOL] [EOL] import logging [EOL] from typing import Any , Dict , Mapping , Union [EOL] import sys [EOL] [comment] [EOL] [EOL] from importlib import import_module [EOL] from os import walk [EOL] from os . path import join , dirname , normpath [EOL] from queue import Queue [EOL] [EOL] LOG = logging . getLogger ( __name__ ) [EOL] [comment] [EOL] SINGLETON_CACHE = dict ( ) [EOL] DATA_QUEUE = Queue ( ) [EOL] [EOL] [EOL] class PluginBase : [EOL] [docstring] [EOL] [EOL] process_order = [number] [EOL] data_schema = { } [EOL] [EOL] def process_tweet ( self , tweet_json ) : [EOL] [docstring] [EOL] raise NotImplementedError [EOL] [EOL] @ staticmethod def import_subclasses ( ) : [EOL] [docstring] [EOL] plugin_path = normpath ( join ( dirname ( __file__ ) , [string] ) ) [EOL] LOG . debug ( [string] , plugin_path ) [EOL] for _ , _ , file_names in walk ( plugin_path ) : [EOL] for file_name in file_names : [EOL] LOG . debug ( [string] , file_name ) [EOL] if all ( ( file_name . endswith ( [string] ) , not file_name . startswith ( [string] ) , not file_name . startswith ( [string] ) , [string] not in file_name , ) ) : [EOL] module_path = [string] . format ( file_name ) . rstrip ( [string] ) [EOL] LOG . debug ( [string] , module_path , module_path in sys . modules ) [EOL] if module_path not in sys . modules : [EOL] try : [EOL] LOG . debug ( [string] , module_path ) [EOL] import_module ( module_path ) [EOL] except ImportError as error : [EOL] LOG . error ( str ( error ) , exc_info = True ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 $queue.Queue$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $typing.Mapping$ 0 0 0 0 0 0 $typing.Union[typing.Dict[builtins.str,typing.Any],None]$ 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Dict [EOL] import builtins [EOL] import typing [EOL] [docstring] [EOL] [EOL] from typing import Dict , Any [EOL] from queue import Queue [EOL] [EOL] from celery import Celery [EOL] [EOL] from ingress import ES_CONNECTION_STRING [EOL] from ingress . utils import get_singleton_instance , create_es_connection [EOL] from ingress . structures import PluginBase [EOL] from ingress . data_processing . processing import DataProcessor [EOL] [EOL] [EOL] CELERY = Celery ( [string] , broker = [string] , results = [string] , ) [EOL] [EOL] [EOL] create_es_connection ( ES_CONNECTION_STRING ) [EOL] PluginBase . import_subclasses ( ) [EOL] [EOL] [EOL] @ CELERY . task def process_tweet ( twitter_index , tweet_data ) : [EOL] [docstring] [EOL] data_processor = get_singleton_instance ( DataProcessor , twitter_index = twitter_index , queue = Queue ( ) ) [EOL] [comment] [EOL] [comment] [EOL] data_processor . process_data ( tweet_data ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] return True [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
import logging [EOL] [docstring] [EOL] import logging [EOL] from os import getenv [EOL] [EOL] __version__ = [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] LOG_FORMAT = ( [string] ) [EOL] [EOL] [EOL] def config_logging ( level = [string] ) : [EOL] [docstring] [EOL] try : [EOL] if level == [string] : [EOL] [comment] [EOL] logging . basicConfig ( format = LOG_FORMAT , level = logging . DEBUG ) [EOL] root_logger = logging . getLogger ( ) [EOL] root_logger . setLevel ( logging . DEBUG ) [EOL] root_logger . debug ( [string] ) [EOL] else : [EOL] logging . basicConfig ( format = LOG_FORMAT , level = logging . ERROR ) [EOL] [EOL] log = logging . getLogger ( __name__ ) [EOL] log . setLevel ( level ) [EOL] log . debug ( [string] , level ) [EOL] [EOL] except AttributeError : [EOL] [comment] [EOL] logging . basicConfig ( format = LOG_FORMAT , level = getattr ( logging , level ) ) [EOL] [EOL] log = logging . getLogger ( __file__ ) [EOL] log . error ( [string] ) [EOL] [EOL] [EOL] config_logging ( getenv ( [string] , [string] ) ) [EOL] ES_CONNECTION_STRING = [string] . format ( getenv ( [string] , [string] ) , getenv ( [string] , [number] ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Dict , List [EOL] import ingress [EOL] import logging [EOL] import typing [EOL] import builtins [EOL] import queue [EOL] [docstring] [EOL] [EOL] import logging [EOL] from queue import Queue , Empty [EOL] from typing import Any , Dict , List , cast [EOL] [EOL] import elasticsearch_dsl as es [EOL] [EOL] from ingress . utils import find_subclasses [EOL] from ingress . structures import PluginBase [EOL] [EOL] LOG = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class DataProcessor : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , twitter_index , queue ) : [EOL] [docstring] [EOL] self . running = False [EOL] [comment] [EOL] self . plugins = [ ] [EOL] self . twitter_index = twitter_index [EOL] self . queue = queue [EOL] [EOL] def _load_plugins ( self ) : [EOL] [docstring] [EOL] self . plugins = sorted ( [ plugin ( ) for plugin in find_subclasses ( PluginBase ) ] , key = lambda plugin : plugin . process_order , ) [EOL] LOG . debug ( [string] , self . plugins ) [EOL] [EOL] def start ( self ) : [EOL] [docstring] [EOL] LOG . info ( [string] ) [EOL] self . running = True [EOL] self . retrieve_data ( ) [EOL] [EOL] def stop ( self ) : [EOL] [docstring] [EOL] self . running = False [EOL] [EOL] def retrieve_data ( self , timeout = [number] ) : [EOL] [docstring] [EOL] while self . running : [EOL] try : [EOL] data = cast ( Dict [ str , Any ] , self . queue . get ( timeout = timeout ) ) [EOL] LOG . debug ( [string] ) [EOL] [EOL] self . process_data ( data ) [EOL] except Empty : [EOL] continue [EOL] [EOL] def process_data ( self , data ) : [EOL] [docstring] [EOL] if not self . plugins : [EOL] self . _load_plugins ( ) [EOL] [EOL] for plugin in self . plugins : [EOL] LOG . debug ( [string] , plugin ) [EOL] [comment] [EOL] data = cast ( Dict [ str , Any ] , plugin . process_tweet ( data ) ) [EOL] [EOL] if data : [EOL] LOG . debug ( [string] ) [EOL] self . store_data ( data ) [EOL] LOG . debug ( [string] ) [EOL] [EOL] def store_data ( self , data ) : [EOL] [docstring] [EOL] es_connection = es . connections . get_connection ( ) [EOL] es_connection . create ( body = data , doc_type = [string] , id = data [ [string] ] [ [string] ] , index = self . twitter_index , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 $typing.Any[typing.Any]$ 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 $typing.List[ingress.structures.PluginBase]$ 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $typing.Any[typing.Any]$ 0 $typing.Any[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[docstring] [EOL]	0 0
from typing import Type , Any , Dict [EOL] import builtins [EOL] import typing [EOL] import containers [EOL] import logging [EOL] [docstring] [EOL] import logging [EOL] from typing import Any , Dict [EOL] import warnings [EOL] [EOL] from carmen import get_resolver [EOL] from carmen . location import LocationEncoder [EOL] import elasticsearch_dsl as es [EOL] [EOL] from ingress . structures import PluginBase [EOL] [EOL] LOG = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class Location ( es . InnerDoc ) : [comment] [EOL] [docstring] [EOL] [EOL] city = es . Keyword ( doc_values = True ) [EOL] country = es . Keyword ( doc_values = True ) [EOL] county = es . Keyword ( doc_values = True ) [EOL] id = es . Text ( ) [EOL] latitude = es . Text ( ) [EOL] longitude = es . Text ( ) [EOL] resolution_method = es . Text ( ) [EOL] state = es . Keyword ( doc_values = True ) [EOL] [EOL] [EOL] class GeoCoding ( PluginBase ) : [EOL] [docstring] [EOL] [EOL] data_schema = { [string] : es . Boolean ( ) , [string] : es . Object ( Location ) , [string] : es . GeoPoint ( ) , } [EOL] [EOL] def __init__ ( self , * args , ** kwargs ) : [EOL] [docstring] [EOL] with warnings . catch_warnings ( ) : [EOL] [comment] [EOL] [comment] [EOL] warnings . simplefilter ( [string] ) [EOL] resolver_options = { [string] : { [string] : True } } [EOL] self . geotagger = get_resolver ( options = resolver_options ) [EOL] self . geotagger . load_locations ( ) [EOL] self . location_resolver = LocationEncoder ( ) [EOL] [EOL] super ( ) . __init__ ( * args , ** kwargs ) [comment] [EOL] [EOL] def process_tweet ( self , tweet_json ) : [EOL] [docstring] [EOL] LOG . debug ( [string] ) [EOL] tweet_location = self . geotagger . resolve_tweet ( tweet_json [ [string] ] ) [EOL] [EOL] tweet_json [ [string] ] = False [EOL] [EOL] if tweet_location : [EOL] LOG . debug ( [string] ) [EOL] tweet_json [ [string] ] = self . location_resolver . default ( tweet_location [ [number] ] ) [EOL] [EOL] if [string] in tweet_json [ [string] ] and [string] in tweet_json [ [string] ] : [EOL] tweet_json [ [string] ] = { [string] : tweet_json [ [string] ] [ [string] ] , [string] : tweet_json [ [string] ] [ [string] ] , } [EOL] [EOL] tweet_json [ [string] ] = True [EOL] LOG . debug ( [string] ) [EOL] [EOL] return tweet_json [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Dict[builtins.str,builtins.bool]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Dict[builtins.str,builtins.bool]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0
[docstring] [EOL]	0 0
from typing import Any , List , Tuple [EOL] import unittest [EOL] import typing [EOL] [docstring] [EOL] [EOL] from unittest . mock import create_autospec , call [EOL] [EOL] import pytest [EOL] [EOL] import ingress . structures as is_ [EOL] [EOL] [EOL] def test_plugin_base_import_subclasses ( monkeypatch ) : [EOL] [docstring] [EOL] mock_os_walk = create_autospec ( is_ . walk ) [EOL] sample_files = [ ( None , None , [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , ] , ) ] [EOL] mock_os_walk . return_value = iter ( sample_files ) [EOL] monkeypatch . setattr ( [string] , mock_os_walk ) [EOL] [EOL] mock_import_module = create_autospec ( is_ . import_module ) [EOL] monkeypatch . setattr ( [string] , mock_import_module ) [EOL] [EOL] is_ . PluginBase . import_subclasses ( ) [EOL] [EOL] print ( mock_import_module . call_args_list ) [EOL] expected_call_list = [ call ( [string] . format ( filename ) ) for filename in ( [string] , [string] , [string] , [string] ) ] [EOL] [EOL] assert mock_import_module . call_args_list == expected_call_list [EOL] [EOL] [EOL] def test_plugin_base_raises_process_tweet ( ) : [EOL] [docstring] [EOL] with pytest . raises ( NotImplementedError ) : [EOL] sample = is_ . PluginBase ( ) [EOL] sample . process_tweet ( [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Dict , Union [EOL] import typing [EOL] [docstring] [EOL] import json [EOL] [EOL] import arrow [EOL] import pytest [EOL] [EOL] import ingress . listeners as il [EOL] from ingress . structures import DATA_QUEUE [EOL] [EOL] [EOL] def test_listener_queue_push_happy ( ) : [EOL] [docstring] [EOL] listener = il . QueueListener ( ) [EOL] [EOL] time = arrow . get ( [string] ) [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] sample_data = { [string] : time . timestamp * [number] , [string] : { [string] : [string] } } [EOL] [EOL] expected_data = { [string] : sample_data , [string] : time . datetime } [EOL] [EOL] listener . on_data ( json . dumps ( sample_data ) ) [EOL] assert DATA_QUEUE . qsize ( ) == [number] [EOL] assert DATA_QUEUE . get ( ) == expected_data [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ None , [string] , [string] , ] , ) def test_listener_queue_push_bad_data ( input_data , caplog ) : [EOL] [docstring] [EOL] listener = il . QueueListener ( ) [EOL] [EOL] listener . on_data ( input_data ) [EOL] [EOL] assert [string] in caplog . text [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Type , Any , List [EOL] import typing [EOL] import containers [EOL] import logging [EOL] [docstring] [EOL] [EOL] import logging [EOL] import inspect [EOL] [EOL] import attr [EOL] import pytest [EOL] import elasticsearch_dsl as es [EOL] [EOL] import ingress . utils as iu [EOL] [EOL] LOG = logging . getLogger ( __name__ ) [EOL] LOG . setLevel ( logging . DEBUG ) [EOL] [EOL] [EOL] @ attr . s class SampleHappy : [comment] [EOL] [docstring] [EOL] [EOL] word = attr . ib ( ) [EOL] number_list = attr . ib ( ) [EOL] [EOL] [EOL] @ attr . s class SampleSad : [comment] [EOL] [docstring] [EOL] [EOL] word = attr . ib ( ) [EOL] number_list = attr . ib ( ) [EOL] [EOL] [EOL] def test_get_singleton_happy_case ( ) : [EOL] [docstring] [EOL] obj_one = iu . get_singleton_instance ( SampleHappy , [string] , ( [number] , [number] ) ) [EOL] obj_two = iu . get_singleton_instance ( SampleHappy , [string] , ( [number] , [number] ) ) [EOL] obj_three = iu . get_singleton_instance ( SampleHappy ) [EOL] [comment] [EOL] [comment] [EOL] obj_four = iu . get_singleton_instance ( SampleHappy , [string] ) [EOL] [EOL] assert obj_one is obj_two is obj_three is obj_four [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( TypeError , None , None ) , ( ValueError , int , [string] ) , ( TypeError , SampleSad , ( [number] , [number] , [number] , [number] , [number] , ) ) , ] , ) def test_singleton_invalid_inputs ( expected_error , input_class , input_args , caplog ) : [EOL] [docstring] [EOL] caplog . set_level ( logging . DEBUG ) [EOL] with pytest . raises ( expected_error ) : [EOL] iu . get_singleton_instance ( input_class , input_args ) [EOL] [EOL] [EOL] def test_find_subclasses_happy_case ( ) : [EOL] [docstring] [EOL] [comment] [EOL] class Base : [comment] [EOL] pass [EOL] [EOL] class Sub1 ( Base ) : [comment] [EOL] pass [EOL] [EOL] class Sub2 ( Base ) : [comment] [EOL] pass [EOL] [EOL] class SubSub1 ( Sub2 ) : [comment] [EOL] pass [EOL] [EOL] class SubSub2 ( Sub2 ) : [comment] [EOL] pass [EOL] [comment] [EOL] [EOL] assert inspect . isgenerator ( iu . find_subclasses ( Base ) ) [EOL] all_subclasses = list ( iu . find_subclasses ( Base ) ) [EOL] [EOL] assert all_subclasses == [ Sub1 , Sub2 , SubSub1 , SubSub2 ] [EOL] [EOL] [EOL] def test_find_subclasses_raises ( ) : [EOL] [docstring] [EOL] def dummy ( ) : [EOL] pass [EOL] [EOL] with pytest . raises ( TypeError ) : [EOL] list ( iu . find_subclasses ( dummy ) ) [EOL] [EOL] [EOL] def test_aggregate_data_schema ( ) : [EOL] [docstring] [EOL] class Base : [comment] [EOL] data_schema = { } [EOL] [EOL] class Sub1 ( Base ) : [comment] [EOL] data_schema = { [string] : True } [EOL] [EOL] class Sub2 ( Base ) : [comment] [EOL] data_schema = { [string] : True } [EOL] [EOL] class SubSub1 ( Sub2 ) : [comment] [EOL] data_schema = { [string] : True } [EOL] [EOL] class SubSub2 ( Sub2 ) : [comment] [EOL] data_schema = { [string] : True } [EOL] [EOL] aggregated_schema = iu . aggregate_data_schema ( Base , include_defaults = True ) [EOL] [EOL] assert aggregated_schema == { [string] : True , [string] : True , [string] : True , [string] : True , [string] : es . Object ( dynamic = True ) , [string] : es . Date ( ) } [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[containers.ingress.tests.test_utils.SampleHappy]$ 0 0 0 0 0 0 0 $typing.Type[containers.ingress.tests.test_utils.SampleHappy]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[containers.ingress.tests.test_utils.SampleSad]$ 0 0 0 0 0 0 0 $typing.Type[containers.ingress.tests.test_utils.SampleSad]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] [docstring] [EOL] [EOL] from unittest . mock import create_autospec [EOL] from collections import namedtuple [EOL] from pprint import pformat [EOL] [EOL] import pytest [EOL] import textblob . download_corpora as td [EOL] from textblob import TextBlob [EOL] [EOL] import ingress . data_processing . sentiment as ids [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ { [string] : { [string] : [string] , [string] : False , [string] : [string] , } } , { [string] : { [string] : [string] , [string] : { [string] : [string] , } , [string] : True , [string] : [string] , } } , { } , ] , ) def test_process_tweet_happy_case ( input_tweet , monkeypatch ) : [EOL] [docstring] [EOL] mock_download_all = create_autospec ( td . download_all ) [EOL] monkeypatch . setattr ( [string] , mock_download_all ) [EOL] [EOL] mock_text = [string] [EOL] mock_text_blob = create_autospec ( TextBlob ) [EOL] mock_text_blob ( mock_text ) . __len__ . return_value = len ( mock_text ) [EOL] mock_sentiment = namedtuple ( [string] , [ [string] , [string] ] ) [EOL] mock_text_blob ( mock_text ) . sentiment = mock_sentiment ( [number] , [number] ) [EOL] mock_text_blob ( mock_text ) . words = [ ] [EOL] monkeypatch . setattr ( [string] , mock_text_blob ) [EOL] [EOL] sentiment_analysis = ids . SentimentAnalysis ( ) [EOL] [EOL] processed_data = sentiment_analysis . process_tweet ( input_tweet ) [EOL] print ( [string] . format ( pformat ( input_tweet , indent = [number] ) ) ) [EOL] print ( [string] . format ( pformat ( processed_data , indent = [number] ) ) ) [EOL] if input_tweet : [EOL] assert processed_data [ [string] ] [ [string] ] == [number] [EOL] assert processed_data [ [string] ] [ [string] ] == [number] [EOL] assert processed_data [ [string] ] [ [string] ] == [number] [EOL] else : [EOL] assert processed_data == input_tweet [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[docstring] [EOL]	0 0
from typing import Optional , Any , Generator , Dict , List [EOL] import typing [EOL] [docstring] [EOL] [EOL] from copy import deepcopy [EOL] from queue import Queue [EOL] from unittest . mock import create_autospec [EOL] [EOL] import ingress . data_processing . processing as idp [EOL] [EOL] [EOL] def test_data_processor_start ( monkeypatch ) : [EOL] [docstring] [EOL] mock_retrieve_data = create_autospec ( idp . DataProcessor . retrieve_data ) [EOL] monkeypatch . setattr ( [string] , mock_retrieve_data ) [EOL] [EOL] data_processor = idp . DataProcessor ( [string] , Queue ( ) ) [EOL] [EOL] data_processor . start ( ) [EOL] [EOL] assert data_processor . running is True [EOL] [EOL] [EOL] def test_data_processor_stop ( ) : [EOL] [docstring] [EOL] data_processor = idp . DataProcessor ( [string] , Queue ( ) ) [EOL] data_processor . running = True [EOL] data_processor . stop ( ) [EOL] [EOL] assert data_processor . running is False [EOL] [EOL] [EOL] def test_data_processor_retrieve_data_stops ( monkeypatch ) : [EOL] [docstring] [EOL] stop = False [EOL] sample = { [string] : [string] } [EOL] sample_data = [ None , deepcopy ( sample ) , deepcopy ( sample ) , deepcopy ( sample ) ] [EOL] called_values = [ ] [EOL] [EOL] def mock_process_data ( self , data ) : [EOL] [docstring] [EOL] nonlocal called_values [EOL] nonlocal stop [EOL] [EOL] if stop : [EOL] self . stop ( ) [EOL] else : [EOL] called_values . append ( data ) [EOL] [EOL] monkeypatch . setattr ( [string] , mock_process_data ) [EOL] [EOL] queue = create_autospec ( Queue ( ) , instance = True ) [EOL] [EOL] sample_gen_data = ( item for item in sample_data ) [EOL] [EOL] def mock_queue_get ( * _ , ** __ ) : [EOL] [docstring] [EOL] nonlocal sample_gen_data [EOL] nonlocal stop [EOL] [EOL] data = None [EOL] [EOL] try : [EOL] data = next ( sample_gen_data ) [EOL] except StopIteration : [EOL] stop = True [EOL] [EOL] return data [EOL] [EOL] queue . get = mock_queue_get [EOL] [EOL] data_processor = idp . DataProcessor ( twitter_index = [string] , queue = queue ) [EOL] data_processor . running = True [EOL] data_processor . retrieve_data ( ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] assert data_processor . running is False [EOL] assert called_values == sample_data [EOL] [EOL] [EOL] def test_data_processor_process_data ( monkeypatch ) : [EOL] [docstring] [EOL] called_data = [ ] [EOL] [EOL] class MockPlugin ( idp . PluginBase ) : [EOL] [docstring] [EOL] [EOL] nonlocal called_data [EOL] [EOL] def process_tweet ( self , data ) : [EOL] [docstring] [EOL] nonlocal called_data [EOL] called_data . append ( data ) [EOL] [EOL] return data [EOL] [EOL] def mock_load_plugins ( self ) : [EOL] [docstring] [EOL] nonlocal MockPlugin [EOL] self . plugins = [ MockPlugin ( ) ] [EOL] [EOL] monkeypatch . setattr ( [string] , mock_load_plugins ) [EOL] [EOL] mock_store_data = create_autospec ( idp . DataProcessor . store_data ) [EOL] monkeypatch . setattr ( [string] , mock_store_data ) [EOL] [EOL] sample = { [string] : [string] } [EOL] data_processor = idp . DataProcessor ( [string] , None ) [EOL] [EOL] data_processor . process_data ( None ) [EOL] data_processor . process_data ( sample ) [EOL] data_processor . process_data ( sample ) [EOL] [EOL] assert called_data == [ None , sample , sample ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0