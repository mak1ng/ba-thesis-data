	0
from typing import Tuple , Union , Any , List , Optional , Set , Type [EOL] import typing [EOL] import textmetrics [EOL] import builtins [EOL] import argparse [EOL] [docstring] [EOL] [EOL] [comment] [EOL] import argparse [EOL] import code [EOL] from enum import Enum , auto [EOL] import os [EOL] import sys [EOL] import tempfile [EOL] from typing import Dict , Optional , List , Any , Union , Tuple [EOL] [EOL] [comment] [EOL] from mypy_extensions import TypedDict [EOL] from tabulate import tabulate [EOL] [EOL] [comment] [EOL] from textmetrics . bleu import bleu [EOL] from textmetrics . common import Corpus , CandidateCorpus , Candidates , References [EOL] from textmetrics . custom import ngrams [EOL] from textmetrics . meteor import meteor [EOL] from textmetrics . red import red [EOL] from textmetrics . utility import clean , storage [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] class Verbosity ( object ) : [EOL] SUMMARY = [number] [EOL] DETAIL = [number] [EOL] [EOL] [EOL] Cell = Union [ str , int , float ] [EOL] MetricWorklist = List [ Tuple [ int , str , List [ Any ] ] ] [EOL] [EOL] def k ( c , keys , default = [string] ) : [EOL] [docstring] [EOL] cur = c [EOL] for k in keys : [EOL] if cur is None or k not in cur : [EOL] return default [EOL] cur = cur [ k ] [comment] [EOL] return cur [comment] [EOL] [EOL] [EOL] def display_results ( candidates , comparative = True , intrinsic = True , verbosity = Verbosity . DETAIL ) : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] c_keys = list ( candidates [ [string] ] . keys ( ) ) [EOL] header = [ [string] ] + [ os . path . basename ( k ) for k in c_keys ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] comp_rows = [ ( Verbosity . SUMMARY , [string] , [ [string] , [string] ] ) , ( Verbosity . DETAIL , [string] , [ [string] , [string] ] ) , ( Verbosity . DETAIL , [string] , [ [string] , [string] ] ) , ( Verbosity . DETAIL , [string] , [ [string] , [string] ] ) , ( Verbosity . DETAIL , [string] , [ [string] , [string] ] ) , ( Verbosity . DETAIL , [string] , [ [string] , [string] ] ) , ( Verbosity . DETAIL , [string] , [ [string] , [string] ] ) , ( Verbosity . DETAIL , [string] , [ [string] , [string] ] ) , ( Verbosity . DETAIL , [string] , [ [string] , [string] , [string] ] ) , ( Verbosity . DETAIL , [string] , [ [string] , [string] , [string] ] ) , ( Verbosity . SUMMARY , [string] , [ [string] , [string] , [string] ] ) , ( Verbosity . SUMMARY , [string] , [ [string] , [string] ] ) , ] [EOL] intr_rows = [ ( Verbosity . SUMMARY , [string] , [ [string] , [string] , [number] ] ) , ( Verbosity . SUMMARY , [string] , [ [string] , [string] , [number] ] ) , ( Verbosity . SUMMARY , [string] , [ [string] , [string] , [number] ] ) , ( Verbosity . DETAIL , [string] , [ [string] , [string] , [number] ] ) , ( Verbosity . DETAIL , [string] , [ [string] , [string] , [number] ] ) , ( Verbosity . DETAIL , [string] , [ [string] , [string] , [number] ] ) , ( Verbosity . DETAIL , [string] , [ [string] , [string] , [number] ] ) , ( Verbosity . DETAIL , [string] , [ [string] , [string] , [number] ] ) , ( Verbosity . DETAIL , [string] , [ [string] , [string] , [number] ] ) , ( Verbosity . DETAIL , [string] , [ [string] , [string] , [number] ] ) , ( Verbosity . DETAIL , [string] , [ [string] , [string] , [number] ] ) , ( Verbosity . DETAIL , [string] , [ [string] , [string] , [number] ] ) , ( Verbosity . SUMMARY , [string] , [ [string] , [string] , [number] ] ) , ( Verbosity . SUMMARY , [string] , [ [string] , [string] , [number] ] ) , ( Verbosity . SUMMARY , [string] , [ [string] , [string] , [number] ] ) , ( Verbosity . DETAIL , [string] , [ [string] , [string] , [number] ] ) , ( Verbosity . DETAIL , [string] , [ [string] , [string] , [number] ] ) , ( Verbosity . DETAIL , [string] , [ [string] , [string] , [number] ] ) , ( Verbosity . DETAIL , [string] , [ [string] , [string] , [number] ] ) , ( Verbosity . DETAIL , [string] , [ [string] , [string] , [number] ] ) , ( Verbosity . DETAIL , [string] , [ [string] , [string] , [number] ] ) , ( Verbosity . DETAIL , [string] , [ [string] , [string] , [number] ] ) , ( Verbosity . DETAIL , [string] , [ [string] , [string] , [number] ] ) , ( Verbosity . DETAIL , [string] , [ [string] , [string] , [number] ] ) , ] [EOL] [EOL] [comment] [EOL] worklist = [ ] [EOL] if comparative : [EOL] worklist . extend ( comp_rows ) [EOL] if intrinsic : [EOL] worklist . extend ( intr_rows ) [EOL] [EOL] [comment] [EOL] rows = [ ] [EOL] for v , name , keys in worklist : [EOL] [comment] [EOL] if v > verbosity : [EOL] continue [EOL] row = [ name ] [EOL] for c_key in c_keys : [EOL] row . append ( k ( candidates [ [string] ] [ c_key ] , keys ) ) [EOL] rows . append ( row ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] print ( tabulate ( rows , headers = header ) ) [EOL] [EOL] [EOL] def main ( ) : [EOL] parser = argparse . ArgumentParser ( ) [EOL] [comment] [EOL] parser . add_argument ( [string] , type = argparse . FileType ( [string] ) , default = clean . DEFAULT_FILE , metavar = [string] , help = [string] . format ( clean . DEFAULT_FILE ) ) [EOL] parser . add_argument ( [string] , action = [string] , help = [string] ) [EOL] parser . add_argument ( [string] , action = [string] , help = [string] ) [EOL] parser . add_argument ( [string] , type = int , default = [number] , metavar = [string] , help = [string] ) [EOL] [comment] [EOL] parser . add_argument ( [string] , nargs = [string] , type = argparse . FileType ( [string] ) , metavar = [string] , help = [string] ) [EOL] parser . add_argument ( [string] , nargs = [string] , type = argparse . FileType ( [string] ) , help = [string] ) [EOL] args = parser . parse_args ( ) [EOL] [EOL] print ( [string] . format ( args . verbosity ) ) [EOL] [EOL] [comment] [EOL] if args . references is not None and len ( args . references ) > [number] : [EOL] print ( [string] ) [EOL] print ( [string] ) [EOL] sys . exit ( [number] ) [EOL] [EOL] [comment] [EOL] print ( [string] ) [EOL] references = None [EOL] if args . references is not None and not args . no_comparative : [EOL] references = { [string] : { r . name : { [string] : r . read ( ) , } for r in args . references } , [string] : None , } [EOL] [EOL] candidates = { [string] : { c . name : { [string] : c . read ( ) , } for c in args . candidates } , } [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] print ( [string] ) [EOL] removal = clean . load ( args . clean_tokens ) [EOL] worklist = list ( candidates [ [string] ] . values ( ) ) [EOL] if references is not None : [EOL] worklist += list ( references [ [string] ] . values ( ) ) [EOL] for corpus in worklist : [EOL] corpus [ [string] ] = clean . clean ( corpus [ [string] ] , removal ) [EOL] [EOL] [comment] [EOL] print ( [string] ) [EOL] storage . save ( references , candidates ) [EOL] [EOL] [comment] [EOL] if args . no_comparative : [EOL] [comment] [EOL] [comment] [EOL] print ( [string] ) [EOL] if references is not None : [EOL] [comment] [EOL] print ( [string] ) [EOL] bleu . bleu ( references , candidates ) [EOL] [EOL] [comment] [EOL] print ( [string] ) [EOL] red . red ( references , candidates ) [EOL] [EOL] [comment] [EOL] print ( [string] ) [EOL] meteor . meteor ( references , candidates ) [EOL] [EOL] [comment] [EOL] if args . no_intrinsic : [EOL] print ( [string] ) [EOL] else : [EOL] [comment] [EOL] print ( [string] ) [EOL] ngrams . ngrams ( candidates ) [EOL] [EOL] [comment] [EOL] print ( [string] ) [EOL] storage . cleanup ( references , candidates ) [EOL] [EOL] [comment] [EOL] print ( [string] ) [EOL] display_results ( candidates , not args . no_comparative , not args . no_intrinsic , args . verbosity ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[docstring] [EOL] [EOL] [comment] [EOL] from typing import Dict , List , Optional , Union [EOL] [EOL] [comment] [EOL] from mypy_extensions import TypedDict [EOL] [EOL] [comment] [EOL] [EOL] class BLEUResults ( TypedDict ) : [EOL] overall = ... [EOL] bleu1 = ... [EOL] bleu2 = ... [EOL] bleu3 = ... [EOL] bleu4 = ... [EOL] brevity_penalty = ... [EOL] length_ratio = ... [EOL] candidate_length = ... [EOL] reference_length = ... [EOL] [EOL] [EOL] class PRF ( TypedDict ) : [EOL] precision = ... [EOL] recall = ... [EOL] f1 = ... [EOL] [EOL] [EOL] class ROUGEResults ( TypedDict ) : [EOL] rouge1 = ... [EOL] rouge2 = ... [EOL] rougeL = ... [EOL] [EOL] [EOL] class METEORResults ( TypedDict ) : [EOL] overall = ... [EOL] [EOL] [EOL] [comment] [EOL] [EOL] class NgramResults ( TypedDict ) : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] perline_avg_unique = ... [EOL] perline_avg_total = ... [EOL] perline_avg_ratio = ... [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] overall_unique = ... [EOL] overall_total = ... [EOL] overall_ratio = ... [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] class Corpus ( TypedDict ) : [EOL] contents = ... [EOL] [EOL] [EOL] class ReferenceCorpus ( Corpus , total = False ) : [EOL] tmpfile = ... [EOL] [EOL] [EOL] class CandidateCorpus ( Corpus , total = False ) : [EOL] tmpfile = ... [EOL] tmpdir = ... [EOL] bleu = ... [EOL] rouge = ... [EOL] meteor = ... [EOL] ngrams = ... [EOL] [EOL] [EOL] [comment] [EOL] [EOL] class References ( TypedDict ) : [EOL] corpora = ... [EOL] tmpdir = ... [EOL] [EOL] class Candidates ( TypedDict ) : [EOL] corpora = ... [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 $PRF$ 0 0 0 $PRF$ 0 0 0 $PRF$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.int,builtins.float]$ 0 0 0 $typing.Dict[builtins.int,builtins.float]$ 0 0 0 $typing.Dict[builtins.int,builtins.float]$ 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.int,builtins.int]$ 0 0 0 $typing.Dict[builtins.int,builtins.int]$ 0 0 0 $typing.Dict[builtins.int,builtins.float]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $BLEUResults$ 0 0 0 $ROUGEResults$ 0 0 0 $METEORResults$ 0 0 0 $NgramResults$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,ReferenceCorpus]$ 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,CandidateCorpus]$ 0 0 0
	0
from typing import Any [EOL] import typing [EOL] import builtins [EOL] import textmetrics [EOL] [docstring] [EOL] [EOL] [comment] [EOL] import code [EOL] [EOL] [comment] [EOL] import rouge [EOL] [EOL] [comment] [EOL] from textmetrics . common import References , Candidates , ROUGEResults [EOL] [EOL] [EOL] def run_red ( reference_fn , candidate_fn ) : [EOL] r = rouge . FilesRouge ( candidate_fn , reference_fn ) [EOL] scores = r . get_scores ( avg = True ) [EOL] [EOL] return { [string] : { [string] : scores [ [string] ] [ [string] ] , [string] : scores [ [string] ] [ [string] ] , [string] : scores [ [string] ] [ [string] ] , } , [string] : { [string] : scores [ [string] ] [ [string] ] , [string] : scores [ [string] ] [ [string] ] , [string] : scores [ [string] ] [ [string] ] , } , [string] : { [string] : scores [ [string] ] [ [string] ] , [string] : scores [ [string] ] [ [string] ] , [string] : scores [ [string] ] [ [string] ] , } , } [EOL] [EOL] [EOL] def red ( references , candidates ) : [EOL] [comment] [EOL] if len ( references [ [string] ] ) > [number] : [EOL] print ( [string] ) [EOL] return [EOL] [EOL] [comment] [EOL] rCorpus = list ( references [ [string] ] . values ( ) ) [ [number] ] [EOL] [EOL] [comment] [EOL] for cCorpus in candidates [ [string] ] . values ( ) : [EOL] cCorpus [ [string] ] = run_red ( rCorpus [ [string] ] , cCorpus [ [string] ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $textmetrics.common.ROUGEResults$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[docstring] [EOL] [EOL] [comment] [EOL] import code [EOL] import unittest [EOL] [EOL] [comment] [EOL] from textmetrics . custom import ngrams [EOL] [EOL] [EOL] class TestNgrams ( unittest . TestCase ) : [EOL] [EOL] def test_uni ( self ) : [EOL] txt = [string] [EOL] expected = [number] [EOL] self . assertEqual ( len ( set ( txt . split ( ) ) ) , expected ) [comment] [EOL] unique_1grams = ngrams . run_ngrams ( txt , [ [number] ] ) [ [string] ] [ [number] ] [EOL] self . assertEqual ( unique_1grams , expected ) [EOL] [EOL] def test_bi ( self ) : [EOL] txt = [string] [EOL] expected = [number] [EOL] unique_2grams = ngrams . run_ngrams ( txt , [ [number] ] ) [ [string] ] [ [number] ] [EOL] self . assertEqual ( unique_2grams , expected ) [EOL] [EOL] def test_tri ( self ) : [EOL] txt = [string] [EOL] expected = [number] [EOL] unique_3grams = ngrams . run_ngrams ( txt , [ [number] ] ) [ [string] ] [ [number] ] [EOL] self . assertEqual ( unique_3grams , expected ) [EOL] [EOL] def test_quad ( self ) : [EOL] txt = [string] [EOL] expected = [number] [EOL] unique_4grams = ngrams . run_ngrams ( txt , [ [number] ] ) [ [string] ] [ [number] ] [EOL] self . assertEqual ( unique_4grams , expected ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] unittest . main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 $None$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 $None$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 $None$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
import builtins [EOL] import textmetrics [EOL] import subprocess [EOL] [docstring] [EOL] [EOL] [comment] [EOL] import code [EOL] import subprocess [EOL] [EOL] [comment] [EOL] from textmetrics . common import References , Candidates , METEORResults [EOL] [EOL] [EOL] def run_meteor ( reference_fn , candidate_fn , jar_fn = [string] ) : [EOL] res = subprocess . run ( [ [string] , [string] , [string] , jar_fn , candidate_fn , reference_fn , [string] , [string] , [string] , [string] ] , stderr = subprocess . PIPE , stdout = subprocess . PIPE , ) [EOL] return { [string] : float ( str ( res . stdout . strip ( ) ) [ [number] : - [number] ] ) } [EOL] [EOL] [EOL] def meteor ( references , candidates ) : [EOL] [comment] [EOL] [comment] [EOL] if len ( references [ [string] ] ) > [number] : [EOL] print ( [string] ) [EOL] return [EOL] [EOL] [comment] [EOL] rCorpus = list ( references [ [string] ] . values ( ) ) [ [number] ] [EOL] [EOL] [comment] [EOL] for cCorpus in candidates [ [string] ] . values ( ) : [EOL] cCorpus [ [string] ] = run_meteor ( rCorpus [ [string] ] , cCorpus [ [string] ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $textmetrics.common.METEORResults$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Set , Any , List [EOL] import typing [EOL] import builtins [EOL] import io [EOL] [docstring] [EOL] [EOL] import io [EOL] from typing import Set [EOL] [EOL] DEFAULT_FILE = [string] [EOL] [EOL] def load ( f ) : [EOL] [docstring] [EOL] return { line . strip ( ) for line in f . readlines ( ) } [EOL] [EOL] [EOL] def clean ( body , removal ) : [EOL] [docstring] [EOL] lines = [ ] [EOL] for line in body . split ( [string] ) : [EOL] lines . append ( [string] . join ( [ tkn for tkn in line . split ( [string] ) if tkn not in removal ] ) ) [EOL] return [string] . join ( lines ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.Set[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Optional , List [EOL] import typing [EOL] import textmetrics [EOL] [docstring] [EOL] [EOL] [comment] [EOL] import code [EOL] import shutil [EOL] import os [EOL] import tempfile [EOL] from typing import Optional [EOL] [EOL] [comment] [EOL] from textmetrics . common import References , Candidates [EOL] [EOL] [comment] [EOL] REF_LABELS = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] [EOL] [EOL] def save ( references , candidates ) : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] for cCorpus in candidates [ [string] ] . values ( ) : [EOL] cCorpus [ [string] ] = tempfile . mkdtemp ( ) [EOL] cCorpus [ [string] ] = os . path . join ( cCorpus [ [string] ] , [string] ) [EOL] with open ( cCorpus [ [string] ] , [string] ) as f : [EOL] f . write ( cCorpus [ [string] ] ) [EOL] [EOL] [comment] [EOL] if references is None : [EOL] return [EOL] references [ [string] ] = tempfile . mkdtemp ( ) [EOL] for i , rCorpus in enumerate ( references [ [string] ] . values ( ) ) : [EOL] rCorpus [ [string] ] = os . path . join ( references [ [string] ] , [string] . format ( REF_LABELS [ i ] ) ) [EOL] with open ( rCorpus [ [string] ] , [string] ) as f : [EOL] f . write ( rCorpus [ [string] ] ) [EOL] [EOL] [EOL] def cleanup ( references , candidates ) : [EOL] [comment] [EOL] for cCorpus in candidates [ [string] ] . values ( ) : [EOL] shutil . rmtree ( cCorpus [ [string] ] ) [EOL] [EOL] [comment] [EOL] if references is None or references [ [string] ] is None : [EOL] return [EOL] shutil . rmtree ( references [ [string] ] ) [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Counter , Tuple , List [EOL] import typing [EOL] import builtins [EOL] import textmetrics [EOL] import collections [EOL] [docstring] [EOL] [EOL] [comment] [EOL] from collections import Counter [EOL] import typing [EOL] from typing import List , Set , Tuple [EOL] [EOL] [comment] [EOL] from textmetrics . common import Candidates , NgramResults [EOL] [EOL] [EOL] def line_ngrams ( line , n ) : [EOL] [docstring] [EOL] grams = Counter ( ) [EOL] tkns = line . strip ( ) . split ( [string] ) [EOL] for start in range ( len ( tkns ) - n + [number] ) : [EOL] grams [ [string] . join ( tkns [ start : start + n ] ) ] += [number] [EOL] return grams [EOL] [EOL] [EOL] def get_ngram_stats ( txt , n ) : [EOL] [docstring] [EOL] [comment] [EOL] overall = Counter ( ) [EOL] [EOL] [comment] [EOL] perline_unique , perline_total , n_lines = [number] , [number] , [number] [EOL] [EOL] [comment] [EOL] for line in txt . splitlines ( ) : [EOL] [comment] [EOL] line_grams = line_ngrams ( line , n ) [EOL] [EOL] [comment] [EOL] overall += line_grams [EOL] [EOL] [comment] [EOL] perline_unique += len ( line_grams ) [EOL] perline_total += sum ( line_grams . values ( ) ) [EOL] n_lines += [number] [EOL] [EOL] [comment] [EOL] overall_unique = len ( overall ) [EOL] overall_total = sum ( overall . values ( ) ) [EOL] return ( perline_unique / n_lines , perline_total / n_lines , perline_unique / perline_total , overall_unique , overall_total , overall_unique / overall_total , ) [EOL] [EOL] [EOL] def run_ngrams ( txt , ns ) : [EOL] res = { [string] : { } , [string] : { } , [string] : { } , [string] : { } , [string] : { } , [string] : { } , } [EOL] for n in ns : [EOL] stats = get_ngram_stats ( txt , n ) [EOL] res [ [string] ] [ n ] = stats [ [number] ] [EOL] res [ [string] ] [ n ] = stats [ [number] ] [EOL] res [ [string] ] [ n ] = stats [ [number] ] [EOL] res [ [string] ] [ n ] = stats [ [number] ] [EOL] res [ [string] ] [ n ] = stats [ [number] ] [EOL] res [ [string] ] [ n ] = stats [ [number] ] [EOL] return res [EOL] [EOL] [EOL] def ngrams ( candidates , ns = [ [number] , [number] , [number] , [number] ] ) : [EOL] for corpus in candidates [ [string] ] . values ( ) : [EOL] corpus [ [string] ] = run_ngrams ( corpus [ [string] ] , ns ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.float,builtins.float,builtins.float,builtins.int,builtins.int,builtins.float]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $textmetrics.common.NgramResults$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import List [EOL] import typing [EOL] import builtins [EOL] import textmetrics [EOL] import subprocess [EOL] [docstring] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] import code [EOL] import os [EOL] import subprocess [EOL] from typing import List [EOL] [EOL] [comment] [EOL] from textmetrics . common import References , Candidates , BLEUResults [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] DEFAULT_BLEU_PERL = os . path . join ( os . path . dirname ( __file__ ) , [string] ) [EOL] [EOL] [EOL] def extract_res ( raw_output ) : [EOL] [docstring] [EOL] output = str ( raw_output , [string] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] s1 , s2 = output . split ( [string] ) [EOL] [EOL] [comment] [EOL] overall_section , ngram_section = s1 . split ( [string] ) [EOL] overall = float ( overall_section . split ( [string] ) [ [number] ] . strip ( ) ) [EOL] subscores = [ float ( s ) for s in ngram_section . strip ( ) . split ( [string] ) ] [EOL] [EOL] [comment] [EOL] s2_contents , _ = s2 . split ( [string] ) [EOL] s2_pieces = [ piece . strip ( ) for piece in s2_contents . split ( [string] ) ] [EOL] bp = float ( s2_pieces [ [number] ] . split ( [string] ) [ [number] ] ) [EOL] len_ratio = float ( s2_pieces [ [number] ] . split ( [string] ) [ [number] ] ) [EOL] can_len = int ( s2_pieces [ [number] ] . split ( [string] ) [ [number] ] ) [EOL] ref_len = int ( s2_pieces [ [number] ] . split ( [string] ) [ [number] ] ) [EOL] [EOL] return { [string] : overall , [string] : subscores [ [number] ] , [string] : subscores [ [number] ] , [string] : subscores [ [number] ] , [string] : subscores [ [number] ] , [string] : bp , [string] : len_ratio , [string] : can_len , [string] : ref_len , } [EOL] [EOL] [EOL] def run_bleu ( reference_fns , candidate_fn , script = DEFAULT_BLEU_PERL , ) : [EOL] [docstring] [EOL] with open ( candidate_fn , [string] ) as in_f : [EOL] res = subprocess . run ( [ [string] , script ] + reference_fns , stdin = in_f , stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) [EOL] [EOL] return extract_res ( res . stdout ) [EOL] [EOL] [EOL] def bleu ( references , candidates ) : [EOL] [docstring] [EOL] [comment] [EOL] ref_fns = [ ref [ [string] ] for ref in references [ [string] ] . values ( ) ] [EOL] for corpus in candidates [ [string] ] . values ( ) : [EOL] corpus [ [string] ] = run_bleu ( ref_fns , corpus [ [string] ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $textmetrics.common.BLEUResults$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $textmetrics.common.BLEUResults$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0