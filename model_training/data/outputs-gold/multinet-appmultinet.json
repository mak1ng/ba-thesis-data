from typing import List , Any [EOL] import typing [EOL] import devops [EOL] import builtins [EOL] from arango import ArangoClient [EOL] import getpass [EOL] import sys [EOL] [EOL] from mypy_extensions import TypedDict [EOL] [EOL] [EOL] HostAnalysis = TypedDict ( [string] , { [string] : str , [string] : str , [string] : int } ) [EOL] [EOL] [EOL] def analyze_host ( host ) : [EOL] if host [ : [number] ] == [string] : [EOL] protocol = [string] [EOL] elif host [ : [number] ] == [string] : [EOL] protocol = [string] [EOL] else : [EOL] print ( f" [string] { host }" , file = sys . stderr ) [EOL] raise RuntimeError [EOL] [EOL] parts = host [ len ( f"{ protocol } [string] " ) : ] . split ( [string] ) [EOL] hostname = parts [ [number] ] [EOL] [EOL] try : [EOL] port = int ( parts [ [number] ] ) [EOL] except IndexError : [EOL] port = [number] [EOL] except ValueError : [EOL] print ( f" [string] { parts [ [number] ] }" , file = sys . stderr ) [EOL] raise RuntimeError [EOL] [EOL] return { [string] : protocol , [string] : hostname , [string] : port } [EOL] [EOL] [EOL] def main ( ) : [EOL] if len ( sys . argv ) < [number] : [EOL] print ( [string] , file = sys . stderr ) [EOL] return [number] [EOL] [EOL] [comment] [EOL] try : [EOL] args = analyze_host ( sys . argv [ [number] ] ) [EOL] except RuntimeError : [EOL] return [number] [EOL] [EOL] [comment] [EOL] client = ArangoClient ( protocol = args [ [string] ] , host = args [ [string] ] , port = args [ [string] ] ) [EOL] [EOL] [comment] [EOL] password = getpass . getpass ( [string] ) [EOL] [EOL] [comment] [EOL] db = client . db ( name = [string] , password = password ) [EOL] coll = db . collection ( [string] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] for doc in coll . all ( ) : [EOL] if [string] not in doc : [EOL] doc [ [string] ] = { [string] : [string] , [string] : [ ] , [string] : [ ] , [string] : [ ] , [string] : True , } [EOL] [EOL] print ( f" [string] { doc [ [string] ] } [string] " , end = [string] ) [EOL] db . update_document ( doc ) [EOL] print ( [string] ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] sys . exit ( main ( ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $HostAnalysis$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import List , Any [EOL] import csv [EOL] import typing [EOL] [docstring] [EOL] [EOL] import csv [EOL] import json [EOL] import sys [EOL] [EOL] [EOL] def add_key ( rec , idx ) : [EOL] [docstring] [EOL] [EOL] rec [ [string] ] = idx [EOL] return rec [EOL] [EOL] [EOL] def convert_link ( link ) : [EOL] [docstring] [EOL] [EOL] return { [string] : f""" [string] { link [ [string] ] }""" , [string] : f""" [string] { link [ [string] ] }""" , [string] : link [ [string] ] , } [EOL] [EOL] [EOL] def write_csv ( data , fields , filename ) : [EOL] [docstring] [EOL] [EOL] with open ( filename , [string] ) as f : [EOL] writer = csv . DictWriter ( f , fieldnames = fields ) [EOL] [EOL] writer . writeheader ( ) [EOL] for row in data : [EOL] writer . writerow ( row ) [EOL] [EOL] [EOL] def main ( ) : [EOL] [docstring] [EOL] [EOL] data = json . loads ( sys . stdin . read ( ) ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] nodes = [ add_key ( record , index ) for ( index , record ) in enumerate ( data [ [string] ] ) ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] links = [ convert_link ( link ) for link in data [ [string] ] ] [EOL] [EOL] [comment] [EOL] write_csv ( nodes , [ [string] , [string] , [string] ] , [string] ) [EOL] write_csv ( links , [ [string] , [string] , [string] ] , [string] ) [EOL] [EOL] return [number] [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] sys . exit ( main ( ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Set [EOL] import csv [EOL] import typing [EOL] [docstring] [EOL] [EOL] import csv [EOL] import sys [EOL] [EOL] [EOL] def main ( ) : [EOL] [docstring] [EOL] [EOL] with open ( sys . argv [ [number] ] ) as nodes : [EOL] reader = csv . DictReader ( nodes ) [EOL] ids = { n [ [string] ] for n in reader } [EOL] [EOL] reader = csv . DictReader ( sys . stdin ) [EOL] writer = csv . DictWriter ( sys . stdout , reader . fieldnames ) [EOL] [EOL] writer . writeheader ( ) [EOL] for row in reader : [EOL] [comment] [EOL] if row [ [string] ] in ids and row [ [string] ] in ids : [EOL] [comment] [EOL] row [ [string] ] = f' [string] { row [ [string] ] }' [EOL] row [ [string] ] = f' [string] { row [ [string] ] }' [EOL] [EOL] writer . writerow ( row ) [EOL] [EOL] return [number] [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] sys . exit ( main ( ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] [docstring] [EOL] import pytest [EOL] from flask_cors import CORS [EOL] from multinet . util import regex_allowed_origins [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( { [string] } , [string] , [string] ) , ( { [string] , [string] } , [string] , [string] ) , ( { [string] } , [string] , [string] ) , ( { [string] } , [string] , None ) , ( { [string] } , [string] , None ) , ( { [string] } , [string] , [string] ) , ( { [string] } , [string] , [string] , ) , ( { [string] } , [string] , None ) , ( { [string] , [string] , [string] , [string] , [string] } , [string] , None ) , ( { [string] } , [string] , [string] ) , ] , ) def test_cors_matching ( app , server , managed_workspace , allowed , origin , expected ) : [EOL] [docstring] [EOL] [comment] [EOL] CORS ( app , origins = regex_allowed_origins ( allowed ) ) [EOL] [EOL] [comment] [EOL] resp = server . get ( f" [string] { managed_workspace }" , headers = { [string] : origin } ) [EOL] assert resp . headers . get ( [string] ) == expected [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , Any , Optional [EOL] import multinet [EOL] import typing [EOL] [docstring] [EOL] from uuid import uuid4 [EOL] from multinet . db import workspace_mapping [EOL] from multinet . db . models . workspace import Workspace [EOL] [EOL] [EOL] def test_present_workspace ( managed_workspace ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] assert workspace_mapping . __wrapped__ ( managed_workspace . name ) == workspace_mapping ( managed_workspace . name ) [EOL] workspace_mapping . cache_clear ( ) [EOL] [EOL] first_resp = workspace_mapping ( managed_workspace . name ) [EOL] second_resp = workspace_mapping ( managed_workspace . name ) [EOL] [EOL] [comment] [EOL] assert first_resp == second_resp [EOL] [EOL] [EOL] def test_absent_workspace ( ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] assert workspace_mapping . __wrapped__ ( uuid4 ( ) . hex ) is None [EOL] workspace_mapping . cache_clear ( ) [EOL] [EOL] workspace_name = uuid4 ( ) . hex [EOL] first_resp = workspace_mapping ( workspace_name ) [EOL] second_resp = workspace_mapping ( workspace_name ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] assert first_resp is None [EOL] assert second_resp is None [EOL] [EOL] [EOL] def test_workspace_create ( managed_user ) : [EOL] [docstring] [EOL] workspace_name = uuid4 ( ) . hex [EOL] [EOL] pre_create = workspace_mapping ( workspace_name ) [EOL] workspace = Workspace . create ( workspace_name , managed_user ) [EOL] [EOL] post_create = workspace_mapping ( workspace_name ) [EOL] post_create_exists = Workspace . exists ( workspace_name ) [EOL] [EOL] [comment] [EOL] workspace . delete ( ) [EOL] [EOL] [comment] [EOL] assert pre_create is None [EOL] assert post_create is not None [EOL] assert post_create_exists [EOL] [EOL] [EOL] def test_workspace_delete ( generated_workspace ) : [EOL] [docstring] [EOL] [EOL] pre_delete = workspace_mapping ( generated_workspace . name ) [EOL] generated_workspace . delete ( ) [EOL] [EOL] post_delete = workspace_mapping ( generated_workspace . name ) [EOL] exists_post_delete = Workspace . exists ( generated_workspace . name ) [EOL] [EOL] [comment] [EOL] assert pre_delete is not None [EOL] assert post_delete is None [EOL] assert not exists_post_delete [EOL] [EOL] [EOL] def test_workspace_rename ( generated_workspace ) : [EOL] [docstring] [EOL] new_workspace_name = uuid4 ( ) . hex [EOL] old_workspace_name = generated_workspace . name [EOL] pre_rename = workspace_mapping ( old_workspace_name ) [EOL] [EOL] generated_workspace . rename ( new_workspace_name ) [EOL] [EOL] post_rename_old = workspace_mapping ( old_workspace_name ) [EOL] post_rename_new = workspace_mapping ( new_workspace_name ) [EOL] [EOL] new_exists = Workspace . exists ( new_workspace_name ) [EOL] old_exists = Workspace . exists ( old_workspace_name ) [EOL] [EOL] [comment] [EOL] generated_workspace . delete ( ) [EOL] [EOL] [comment] [EOL] assert pre_rename is not None [EOL] assert post_rename_old is None [EOL] assert post_rename_new is not None [EOL] [EOL] assert new_exists [EOL] assert not old_exists [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Sequence [EOL] import typing [EOL] import multinet [EOL] [docstring] [EOL] import json [EOL] import os [EOL] from collections import OrderedDict [EOL] [EOL] from multinet . util import data_path [EOL] from multinet . uploaders . d3_json import ( validate_d3_json , InconsistentLinkKeys , InvalidLinkKeys , NodeDuplicates , ) [EOL] [EOL] TEST_DATA_DIR = os . path . abspath ( os . path . join ( os . path . dirname ( __file__ ) , [string] ) ) [EOL] [EOL] [EOL] def test_validate_d3_json ( ) : [EOL] [docstring] [EOL] [comment] [EOL] with open ( data_path ( [string] ) ) as f : [EOL] good_data = json . load ( f , object_pairs_hook = OrderedDict ) [EOL] with open ( data_path ( [string] ) ) as f : [EOL] dup_node_data = json . load ( f , object_pairs_hook = OrderedDict ) [EOL] with open ( data_path ( [string] ) ) as f : [EOL] incon_keys = json . load ( f , object_pairs_hook = OrderedDict ) [EOL] with open ( data_path ( [string] ) ) as f : [EOL] inval_keys = json . load ( f , object_pairs_hook = OrderedDict ) [EOL] [EOL] [comment] [EOL] outcome1 = validate_d3_json ( good_data ) [EOL] outcome2 = validate_d3_json ( dup_node_data ) [EOL] outcome3 = validate_d3_json ( incon_keys ) [EOL] outcome4 = validate_d3_json ( inval_keys ) [EOL] [EOL] [comment] [EOL] assert len ( outcome1 ) == [number] [EOL] [EOL] assert len ( outcome2 ) == [number] [EOL] assert outcome2 [ [number] ] == NodeDuplicates ( ) [EOL] [EOL] assert len ( outcome3 ) == [number] [EOL] assert outcome3 [ [number] ] == InconsistentLinkKeys ( ) [EOL] [EOL] assert len ( outcome4 ) == [number] [EOL] assert outcome4 [ [number] ] == InvalidLinkKeys ( ) [EOL] assert outcome4 [ [number] ] == InconsistentLinkKeys ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] [docstring] [EOL] import newick [EOL] import os [EOL] import pytest [EOL] [EOL] from multinet . errors import ValidationFailed , DecodeFailed [EOL] from multinet . validation import DuplicateKey [EOL] from multinet . uploaders . newick import validate_newick , decode_data [EOL] [EOL] TEST_DATA_DIR = os . path . abspath ( os . path . join ( os . path . dirname ( __file__ ) , [string] ) ) [EOL] [EOL] [EOL] def test_validate_newick ( ) : [EOL] [docstring] [EOL] duplicate_keys_file_path = os . path . join ( TEST_DATA_DIR , [string] ) [EOL] [EOL] [comment] [EOL] with open ( duplicate_keys_file_path ) as test_file : [EOL] test_file = test_file . read ( ) [EOL] [EOL] body = newick . loads ( test_file ) [EOL] [EOL] with pytest . raises ( ValidationFailed ) as v_error : [EOL] validate_newick ( body ) [EOL] [EOL] validation_resp = v_error . value . errors [EOL] assert DuplicateKey ( key = [string] ) . asdict ( ) in validation_resp [EOL] [EOL] [comment] [EOL] test_data = ( [string] [string] ) [EOL] pytest . raises ( DecodeFailed , decode_data , test_data ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import List , Any , Tuple , Dict [EOL] import typing [EOL] import requests [EOL] import pathlib [EOL] import builtins [EOL] [docstring] [EOL] [EOL] import os [EOL] import click [EOL] import requests [EOL] import json [EOL] [EOL] from pathlib import Path [EOL] from typing import List [EOL] [EOL] [EOL] DATA_DIR = Path ( __file__ ) . absolute ( ) . parents [ [number] ] / [string] [EOL] [EOL] DEFAULT_HOST = os . environ . get ( [string] , [string] ) [EOL] DEFAULT_PORT = os . environ . get ( [string] , [string] ) [EOL] DEFAULT_ADDRESS = f"{ DEFAULT_HOST } [string] { DEFAULT_PORT }" [EOL] [EOL] server_address = DEFAULT_ADDRESS [EOL] [EOL] [EOL] def root_api_endpoint ( ) : [EOL] [docstring] [EOL] return f" [string] { server_address } [string] " [EOL] [EOL] [EOL] def check_server_connection ( ) : [EOL] [docstring] [EOL] try : [EOL] requests . get ( f"{ root_api_endpoint ( ) } [string] " ) [EOL] return [EOL] except requests . exceptions . ConnectionError : [EOL] fatal ( f" [string] { server_address } [string] " ) [EOL] except requests . exceptions . InvalidURL : [EOL] fatal ( f" [string] { server_address } [string] " ) [EOL] [EOL] [EOL] def get_edge_tables ( workspace ) : [EOL] [docstring] [EOL] resp = requests . get ( f"{ root_api_endpoint ( ) } [string] { workspace } [string] " ) [EOL] [EOL] if resp . ok : [EOL] tables = json . loads ( resp . text ) [EOL] return tables [EOL] [EOL] return [ ] [EOL] [EOL] [EOL] def get_table_rows ( workspace , table ) : [EOL] [docstring] [EOL] resp = requests . get ( f"{ root_api_endpoint ( ) } [string] { workspace } [string] { table } [string] " ) [EOL] [EOL] if resp . ok : [EOL] rows = json . loads ( resp . text ) [EOL] return rows [EOL] [EOL] return [ ] [EOL] [EOL] [EOL] def check_workspace_exists ( workspace ) : [EOL] [docstring] [EOL] [EOL] resp = requests . get ( f"{ root_api_endpoint ( ) } [string] { workspace }" ) [EOL] [EOL] if resp . ok : [EOL] return True [EOL] [EOL] return False [EOL] [EOL] [EOL] def create_workspace ( workspace ) : [EOL] [docstring] [EOL] resp = requests . post ( f"{ root_api_endpoint ( ) } [string] { workspace }" ) [EOL] [EOL] if resp . ok : [EOL] return True [EOL] [EOL] return False [EOL] [EOL] [EOL] def create_graph ( workspace , graph_name , edge_table ) : [EOL] [docstring] [EOL] resp = requests . post ( f"{ root_api_endpoint ( ) } [string] { workspace } [string] { graph_name }" , params = { [string] : edge_table } , ) [EOL] [EOL] if resp . ok : [EOL] return True [EOL] [EOL] return False [EOL] [EOL] [EOL] def table_exists ( workspace , table ) : [EOL] [docstring] [EOL] resp = requests . get ( f"{ root_api_endpoint ( ) } [string] { workspace } [string] { table }" ) [EOL] [EOL] if resp . status_code == [number] : [EOL] return True [EOL] return False [EOL] [EOL] [EOL] def create_table ( workspace , table , data ) : [EOL] [docstring] [EOL] resp = requests . post ( f"{ root_api_endpoint ( ) } [string] { workspace } [string] { table }" , data = data . encode ( [string] ) ) [EOL] [EOL] if resp . ok : [EOL] return True [EOL] return False [EOL] [EOL] [EOL] def log ( text , indent = [number] , error = False , success = False ) : [EOL] [docstring] [EOL] [EOL] fg = None [EOL] if error : [EOL] fg = [string] [EOL] elif success : [EOL] fg = [string] [EOL] [EOL] text = click . wrap_text ( text , initial_indent = ( indent * [string] ) ) [EOL] click . echo ( click . style ( text , fg = fg ) ) [EOL] [EOL] [EOL] def fatal ( text , indent = [number] ) : [EOL] [docstring] [EOL] log ( text , indent , error = True ) [EOL] exit ( [number] ) [EOL] [EOL] [EOL] @ click . group ( ) def cli ( ) : [EOL] [docstring] [EOL] pass [EOL] [EOL] [EOL] @ cli . command ( [string] ) @ click . argument ( [string] , nargs = [number] , required = False ) def populate ( address ) : [EOL] [docstring] [EOL] global server_address [EOL] log_tabstop = [number] [EOL] log_indent = [number] [EOL] [EOL] if address is not None : [EOL] server_address = address [EOL] [EOL] check_server_connection ( ) [EOL] [EOL] log ( f" [string] { server_address } [string] " , indent = log_indent ) [EOL] [EOL] for path in DATA_DIR . iterdir ( ) : [EOL] workspace = path . name [EOL] [EOL] log ( f' [string] { workspace } [string] ' , indent = log_indent ) [EOL] log_indent += log_tabstop [EOL] [EOL] files = tuple ( path . glob ( [string] ) ) [EOL] [EOL] if check_workspace_exists ( workspace ) : [EOL] log ( f' [string] { workspace } [string] ' , indent = log_indent , ) [EOL] continue [EOL] [EOL] if not create_workspace ( workspace ) : [EOL] log ( f" [string] { workspace } [string] " , indent = log_indent ) [EOL] continue [EOL] [EOL] [comment] [EOL] for file in files : [EOL] table_name = file . stem [EOL] [EOL] if table_exists ( workspace , table_name ) : [EOL] fatal ( f' [string] { table_name } [string] ' [string] , indent = log_indent , ) [EOL] else : [EOL] with file . open ( mode = [string] ) as csv_file : [EOL] csv_data = csv_file . read ( ) [EOL] [EOL] if not create_table ( workspace , table_name , csv_data ) : [EOL] log ( f" [string] { table_name } [string] " , indent = log_indent ) [EOL] else : [EOL] log ( f" [string] { table_name } [string] " , indent = log_indent ) [EOL] [EOL] [comment] [EOL] edge_tables = get_edge_tables ( workspace ) [EOL] log ( f" [string] " , indent = log_indent ) [EOL] [EOL] for edge_table in edge_tables : [EOL] rows = get_table_rows ( workspace , edge_table ) [EOL] rows = [ { k : v for k , v in row . items ( ) if k == [string] or k == [string] } for row in rows ] [EOL] [EOL] create_graph ( workspace , workspace , edge_table ) [EOL] [EOL] log_indent -= log_tabstop [EOL] [EOL] script_complete_string = [string] [EOL] log ( [string] * len ( script_complete_string ) , indent = log_indent ) [EOL] log ( script_complete_string , indent = log_indent , success = True ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] cli ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pathlib.Path$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $pathlib.Path$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[docstring] [EOL]	0 0