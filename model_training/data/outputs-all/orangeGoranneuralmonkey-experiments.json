[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Tuple , Dict , Any , List [EOL] import typing [EOL] import sys [EOL] import os [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] sys . path . insert ( [number] , os . path . abspath ( [string] ) ) [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] extensions = [ [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] [EOL] [comment] [EOL] templates_path = [ [string] ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] source_suffix = [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] master_doc = [string] [EOL] [EOL] [comment] [EOL] project = [string] [EOL] copyright = [string] [EOL] author = [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] version = [string] [EOL] [comment] [EOL] release = [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] language = None [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] exclude_patterns = [ ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] pygments_style = [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] todo_include_todos = True [EOL] [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] import sphinx_rtd_theme [EOL] html_theme = [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] html_theme_path = [ sphinx_rtd_theme . get_html_theme_path ( ) ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] html_logo = [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] html_favicon = [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] html_static_path = [ [string] ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] htmlhelp_basename = [string] [EOL] [EOL] [comment] [EOL] [EOL] latex_elements = { } [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] latex_documents = [ ( master_doc , [string] , [string] , [string] , [string] ) , ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] man_pages = [ ( master_doc , [string] , [string] , [ author ] , [number] ) ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] texinfo_documents = [ ( master_doc , [string] , [string] , author , [string] , [string] , [string] ) , ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] def run_apidoc ( _ ) : [EOL] [EOL] cur_dir = os . path . abspath ( os . path . dirname ( __file__ ) ) [EOL] print ( cur_dir ) [EOL] module = os . path . abspath ( os . path . join ( cur_dir , [string] , [string] , [string] ) ) [EOL] print ( module ) [EOL] [EOL] from sphinx . apidoc import main [EOL] main ( [ [string] , [string] , cur_dir , module , [string] ] ) [EOL] [EOL] def setup ( app ) : [EOL] app . connect ( [string] , run_apidoc ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str,builtins.str,builtins.str,builtins.str]]$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str,builtins.str,typing.List[builtins.str],builtins.int]]$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str,builtins.str,builtins.str,builtins.str,builtins.str,builtins.str]]$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] from functools import wraps [EOL] [EOL] from neuralmonkey . model . model_part import ModelPart [EOL] [EOL] [EOL] def tensor ( func ) : [EOL] @ wraps ( func ) def decorate ( self , * args , ** kwargs ) : [EOL] attribute_name = [string] . format ( func . __name__ ) [EOL] if not hasattr ( self , attribute_name ) : [EOL] if isinstance ( self , ModelPart ) : [EOL] [comment] [EOL] with self . use_scope ( ) : [EOL] value = func ( self , * args , ** kwargs ) [EOL] else : [EOL] value = func ( self , * args , ** kwargs ) [EOL] setattr ( self , attribute_name , value ) [EOL] [EOL] return getattr ( self , attribute_name ) [EOL] return property ( decorate ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[docstring] [EOL]	0 0
from typing import Any , List [EOL] import typing [EOL] import argparse [EOL] [docstring] [EOL] [EOL] [comment] [EOL] import neuralmonkey . checkpython [EOL] [comment] [EOL] [EOL] import argparse [EOL] import os [EOL] import shlex [EOL] from shutil import copyfile [EOL] import sys [EOL] import traceback [EOL] [EOL] from neuralmonkey . logging import log , debug [EOL] from neuralmonkey . experiment import Experiment [EOL] [EOL] [EOL] [comment] [EOL] def _main ( ) : [EOL] parser = argparse . ArgumentParser ( description = __doc__ ) [EOL] parser . add_argument ( [string] , metavar = [string] , help = [string] ) [EOL] parser . add_argument ( [string] , [string] , type = str , metavar = [string] , action = [string] , dest = [string] , default = [ ] , help = [string] [string] ) [EOL] parser . add_argument ( [string] , [string] , type = str , metavar = [string] , default = [ ] , action = [string] , dest = [string] , help = [string] [string] ) [EOL] parser . add_argument ( [string] , [string] , dest = [string] , action = [string] , help = [string] [string] ) [EOL] parser . add_argument ( [string] , [string] , action = [string] , help = [string] [string] ) [EOL] args = parser . parse_args ( ) [EOL] [EOL] args . config_changes . extend ( [string] . format ( s ) for s in args . config_vars ) [EOL] [EOL] exp = Experiment ( config_path = args . config , config_changes = args . config_changes , train_mode = True , overwrite_output_dir = args . overwrite ) [EOL] [EOL] with open ( exp . get_path ( [string] , exp . cont_index + [number] ) , [string] ) as file : [EOL] print ( [string] . join ( shlex . quote ( a ) for a in sys . argv ) , file = file ) [EOL] [EOL] if args . init_only : [EOL] if exp . cont_index >= [number] : [EOL] log ( [string] , color = [string] ) [EOL] exit ( [number] ) [EOL] [EOL] exp . config . save_file ( exp . get_path ( [string] , [number] ) ) [EOL] copyfile ( args . config , exp . get_path ( [string] , [number] ) ) [EOL] [EOL] log ( [string] ) [EOL] [EOL] cmd = [ os . path . basename ( sys . argv [ [number] ] ) , [string] , exp . get_path ( [string] , [number] ) ] [EOL] log ( [string] . format ( [string] . join ( shlex . quote ( a ) for a in cmd ) ) ) [EOL] exit ( [number] ) [EOL] [EOL] try : [EOL] exp . train ( ) [EOL] except KeyboardInterrupt : [EOL] raise [EOL] except Exception : [comment] [EOL] log ( traceback . format_exc ( ) , color = [string] ) [EOL] exit ( [number] ) [EOL] [EOL] [EOL] def main ( ) : [EOL] try : [EOL] _main ( ) [EOL] except KeyboardInterrupt : [EOL] log ( [string] ) [EOL] debug ( traceback . format_exc ( ) ) [EOL] exit ( [number] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from . cross_entropy_trainer import CrossEntropyTrainer [EOL]	0 0 0 0 0 0
[comment] [EOL] [EOL] [EOL] from typing import Any , List [EOL] import typing [EOL] import unittest [EOL] [EOL] from neuralmonkey . evaluators . bleu import BLEUEvaluator [EOL] [EOL] [EOL] CORPUS_DECODED = [ [string] , [string] , [string] , [string] , [string] ] [EOL] [EOL] CORPUS_REFERENCE = [ [string] , [string] , [string] , [string] , [string] ] [EOL] [EOL] [EOL] DECODED = [ d . split ( ) for d in CORPUS_DECODED ] [EOL] REFERENCE = [ r . split ( ) for r in CORPUS_REFERENCE ] [EOL] [EOL] FUNC = BLEUEvaluator ( ) [EOL] [EOL] [EOL] class TestBLEU ( unittest . TestCase ) : [EOL] [EOL] def test_empty_decoded ( self ) : [EOL] self . assertEqual ( FUNC ( [ [ ] for _ in DECODED ] , REFERENCE ) , [number] ) [EOL] [EOL] def test_empty_reference ( self ) : [EOL] score = FUNC ( DECODED , [ [ ] for _ in REFERENCE ] ) [EOL] self . assertIsInstance ( score , float ) [EOL] [EOL] def test_identical ( self ) : [EOL] self . assertEqual ( FUNC ( REFERENCE , REFERENCE ) , [number] ) [EOL] [EOL] def test_empty_sentence ( self ) : [EOL] ref_empty = REFERENCE + [ [ ] ] [EOL] out_empty = DECODED + [ [ [string] ] ] [EOL] score = FUNC ( out_empty , ref_empty ) [EOL] self . assertAlmostEqual ( score , [number] , delta = [number] ) [EOL] [EOL] def test_bleu ( self ) : [EOL] score = FUNC ( DECODED , REFERENCE ) [EOL] self . assertAlmostEqual ( score , [number] , delta = [number] ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] unittest . main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.List[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 $typing.List[typing.List[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.List[typing.List[builtins.str]]$ 0 0 $typing.List[typing.List[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.List[typing.List[builtins.str]]$ 0 0 0 0 0 0 0 $typing.List[typing.List[builtins.str]]$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.List[typing.List[builtins.str]]$ 0 $typing.List[typing.List[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.List[typing.List[builtins.str]]$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.List[typing.List[builtins.str]]$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.List[typing.List[builtins.str]]$ 0 $typing.List[typing.List[builtins.str]]$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] from typing import Any [EOL] import typing [EOL] [docstring] [EOL] [EOL] import unittest [EOL] import tensorflow as tf [EOL] [EOL] from neuralmonkey . functions import piecewise_function [EOL] [EOL] [EOL] class TestPiecewiseFunction ( unittest . TestCase ) : [EOL] [EOL] def test_piecewise_constant ( self ) : [EOL] x = tf . placeholder ( dtype = tf . int32 ) [EOL] y = piecewise_function ( x , [ - [number] , [number] , [number] , [number] ] , [ - [number] , [number] , [number] ] , dtype = tf . float32 ) [EOL] [EOL] with tf . Session ( ) as sess : [EOL] self . assertAlmostEqual ( sess . run ( y , { x : - [number] } ) , - [number] ) [EOL] self . assertAlmostEqual ( sess . run ( y , { x : - [number] } ) , [number] ) [EOL] self . assertAlmostEqual ( sess . run ( y , { x : [number] } ) , [number] ) [EOL] self . assertAlmostEqual ( sess . run ( y , { x : [number] } ) , [number] ) [EOL] self . assertAlmostEqual ( sess . run ( y , { x : [number] } ) , [number] ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] unittest . main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] from typing import Any , Literal , Union , Dict , List [EOL] import typing_extensions [EOL] import typing [EOL] [docstring] [EOL] [EOL] import unittest [EOL] import copy [EOL] [EOL] from neuralmonkey . decoders . decoder import Decoder [EOL] from neuralmonkey . vocabulary import Vocabulary [EOL] [EOL] DECODER_PARAMS = dict ( encoders = [ ] , vocabulary = Vocabulary ( ) , data_id = [string] , name = [string] , max_output_len = [number] , dropout_keep_prob = [number] , embedding_size = [number] , rnn_size = [number] ) [EOL] [EOL] [EOL] class TestDecoder ( unittest . TestCase ) : [EOL] [EOL] def test_init ( self ) : [EOL] decoder = Decoder ( ** DECODER_PARAMS ) [EOL] self . assertIsNotNone ( decoder ) [EOL] [EOL] def test_max_output_len ( self ) : [EOL] dparams = copy . deepcopy ( DECODER_PARAMS ) [EOL] [EOL] dparams [ [string] ] = - [number] [EOL] with self . assertRaises ( ValueError ) : [EOL] Decoder ( ** dparams ) [EOL] [EOL] def test_dropout ( self ) : [EOL] dparams = copy . deepcopy ( DECODER_PARAMS ) [EOL] [EOL] dparams [ [string] ] = - [number] [EOL] with self . assertRaises ( ValueError ) : [EOL] Decoder ( ** dparams ) [EOL] [EOL] dparams [ [string] ] = [number] [EOL] with self . assertRaises ( ValueError ) : [EOL] Decoder ( ** dparams ) [EOL] [EOL] def test_embedding_size ( self ) : [EOL] dparams = copy . deepcopy ( DECODER_PARAMS ) [EOL] [EOL] dparams [ [string] ] = None [EOL] with self . assertRaises ( ValueError ) : [EOL] Decoder ( ** dparams ) [EOL] [EOL] dparams [ [string] ] = - [number] [EOL] with self . assertRaises ( ValueError ) : [EOL] Decoder ( ** dparams ) [EOL] [EOL] def test_tie_embeddings ( self ) : [EOL] dparams = copy . deepcopy ( DECODER_PARAMS ) [EOL] [EOL] dparams [ [string] ] = True [EOL] dparams [ [string] ] = [number] [EOL] dparams [ [string] ] = [number] [EOL] with self . assertRaises ( ValueError ) : [EOL] Decoder ( ** dparams ) [EOL] [EOL] def test_cell_type ( self ) : [EOL] dparams = copy . deepcopy ( DECODER_PARAMS ) [EOL] [EOL] dparams . update ( { [string] : [string] } ) [EOL] with self . assertRaises ( ValueError ) : [EOL] Decoder ( ** dparams ) [EOL] [EOL] for cell_type in ( [string] , [string] , [string] ) : [EOL] print ( dparams ) [EOL] dparams [ [string] ] = cell_type [EOL] dparams [ [string] ] = [string] . format ( cell_type ) [EOL] Decoder ( ** dparams ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] unittest . main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
	0
from typing import Any , List [EOL] import builtins [EOL] import neuralmonkey [EOL] import typing [EOL] from typing import Any , List [EOL] import numpy as np [EOL] [EOL] [EOL] class AccuracyEvaluator ( object ) : [EOL] [comment] [EOL] [EOL] def __init__ ( self , name = [string] ) : [EOL] self . name = name [EOL] [EOL] def __call__ ( self , decoded , references ) : [EOL] collected_info = [ d == r for dec , ref in zip ( decoded , references ) for d , r in zip ( dec , ref ) ] [EOL] if collected_info == [ ] : [EOL] mean = [number] [EOL] else : [EOL] mean = np . mean ( collected_info ) [EOL] return mean [EOL] [EOL] @ staticmethod def compare_scores ( score1 , score2 ) : [EOL] [comment] [EOL] return ( score1 > score2 ) - ( score1 < score2 ) [EOL] [EOL] [EOL] class AccuracySeqLevelEvaluator ( object ) : [EOL] [comment] [EOL] [EOL] def __init__ ( self , name = [string] ) : [EOL] self . name = name [EOL] [EOL] def __call__ ( self , decoded , references ) : [EOL] collected_info = [ dec == ref for dec , ref in zip ( decoded , references ) ] [EOL] [EOL] if collected_info == [ ] : [EOL] mean = [number] [EOL] else : [EOL] mean = np . mean ( collected_info ) [EOL] return mean [EOL] [EOL] @ staticmethod def compare_scores ( score1 , score2 ) : [EOL] [comment] [EOL] return ( score1 > score2 ) - ( score1 < score2 ) [EOL] [EOL] [EOL] [comment] [EOL] Accuracy = AccuracyEvaluator ( ) [EOL] AccuracySeqLevel = AccuracySeqLevelEvaluator ( ) [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $builtins.float$ 0 0 0 $typing.List[typing.List[typing.Any]]$ 0 $typing.List[typing.List[typing.Any]]$ 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.List[typing.Any]]$ 0 $typing.List[typing.List[typing.Any]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 $typing.List[typing.Any]$ 0 0 0 $typing.Any$ 0 0 0 0 0 $builtins.int$ 0 $builtins.float$ 0 $builtins.float$ 0 0 0 0 0 0 0 $builtins.float$ 0 $builtins.float$ 0 0 0 $builtins.float$ 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $builtins.float$ 0 0 0 $typing.List[typing.Any]$ 0 $typing.List[typing.Any]$ 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 $typing.List[typing.Any]$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 $typing.List[typing.Any]$ 0 0 0 $typing.Any$ 0 0 0 0 0 $builtins.int$ 0 $builtins.float$ 0 $builtins.float$ 0 0 0 0 0 0 0 $builtins.float$ 0 $builtins.float$ 0 0 0 $builtins.float$ 0 $builtins.float$ 0 0 0 0 0 0 $neuralmonkey.evaluators.accuracy.AccuracyEvaluator$ 0 0 0 0 0 $neuralmonkey.evaluators.accuracy.AccuracySeqLevelEvaluator$ 0 0 0 0 0 0 0
from typing import List [EOL] import builtins [EOL] import neuralmonkey [EOL] import typing [EOL] from typing import List [EOL] import numpy as np [EOL] [EOL] [EOL] class MeanSquaredErrorEvaluator ( object ) : [EOL] [comment] [EOL] [EOL] def __init__ ( self , name = [string] ) : [EOL] self . name = name [EOL] [EOL] def __call__ ( self , decoded , references ) : [EOL] return np . mean ( [ ( d - r ) ** [number] for dec , ref in zip ( decoded , references ) for d , r in zip ( dec , ref ) ] ) [EOL] [EOL] @ staticmethod def compare_scores ( score1 , score2 ) : [EOL] [comment] [EOL] return ( score1 < score2 ) - ( score1 > score2 ) [EOL] [EOL] [EOL] [comment] [EOL] MSE = MeanSquaredErrorEvaluator ( ) [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.float$ 0 $builtins.float$ 0 0 0 0 0 0 0 $builtins.float$ 0 $builtins.float$ 0 0 0 $builtins.float$ 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0
import builtins [EOL] import tensorflow [EOL] [docstring] [EOL] from abc import ABCMeta , abstractproperty [EOL] import tensorflow as tf [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] class Stateful ( metaclass = ABCMeta ) : [EOL] @ abstractproperty def output ( self ) : [EOL] [docstring] [EOL] raise NotImplementedError ( [string] ) [EOL] [comment] [EOL] [EOL] [EOL] class TemporalStateful ( metaclass = ABCMeta ) : [EOL] @ abstractproperty def temporal_states ( self ) : [EOL] [docstring] [EOL] raise NotImplementedError ( [string] ) [EOL] [EOL] @ abstractproperty def temporal_mask ( self ) : [EOL] [docstring] [EOL] raise NotImplementedError ( [string] ) [EOL] [EOL] @ property def lengths ( self ) : [EOL] [docstring] [EOL] return tf . to_int32 ( tf . reduce_sum ( self . temporal_mask , [number] ) ) [EOL] [EOL] @ property def dimension ( self ) : [EOL] [docstring] [EOL] return self . temporal_states . get_shape ( ) [ - [number] ] . value [EOL] [EOL] [EOL] class SpatialStateful ( metaclass = ABCMeta ) : [EOL] @ property def spatial_states ( self ) : [EOL] [docstring] [EOL] raise NotImplementedError ( [string] ) [EOL] [EOL] @ abstractproperty def spatial_mask ( self ) : [EOL] [docstring] [EOL] raise NotImplementedError ( [string] ) [EOL] [EOL] @ property def dimension ( self ) : [EOL] [docstring] [EOL] return self . spatial_states . get_shape ( ) [ - [number] ] . value [EOL] [EOL] [EOL] [comment] [EOL] class TemporalStatefulWithOutput ( Stateful , TemporalStateful ) : [EOL] pass [EOL] [EOL] [EOL] class SpatialStatefulWithOutput ( Stateful , SpatialStateful ) : [EOL] pass [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $tensorflow.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $tensorflow.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $tensorflow.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $tensorflow.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $tensorflow.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $tensorflow.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
	0
from . sequence_regressor import SequenceRegressor [EOL] from . beam_search_decoder import BeamSearchDecoder [EOL] from . classifier import Classifier [EOL] from . ctc_decoder import CTCDecoder [EOL] from . decoder import Decoder [EOL] from . sequence_labeler import SequenceLabeler [EOL] from . word_alignment_decoder import WordAlignmentDecoder [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import List [EOL] import builtins [EOL] import typing [EOL] from typing import List [EOL] [EOL] import numpy as np [EOL] [EOL] [EOL] def numpy_reader ( files ) : [EOL] if len ( files ) == [number] : [EOL] return np . load ( files [ [number] ] ) [EOL] [EOL] return np . concatenate ( [ np . load ( f ) for f in files ] , axis = [number] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Tuple , Optional , Any [EOL] import builtins [EOL] import neuralmonkey [EOL] import tensorflow [EOL] import typing [EOL] from typing import Optional , Tuple [EOL] [EOL] import tensorflow as tf [EOL] from typeguard import check_argument_types [EOL] [EOL] from neuralmonkey . attention . base_attention import ( BaseAttention , AttentionLoopStateTA , empty_attention_loop_state ) [EOL] from neuralmonkey . model . stateful import Stateful [EOL] from neuralmonkey . decorators import tensor [EOL] from neuralmonkey . model . model_part import InitializerSpecs [EOL] [EOL] [EOL] class StatefulContext ( BaseAttention ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , name , encoder , save_checkpoint = None , load_checkpoint = None , initializers = None ) : [EOL] check_argument_types ( ) [EOL] BaseAttention . __init__ ( self , name , save_checkpoint , load_checkpoint , initializers ) [EOL] [EOL] self . encoder = encoder [EOL] [EOL] @ tensor def attention_states ( self ) : [EOL] return tf . expand_dims ( self . encoder . output , [number] ) [EOL] [EOL] [comment] [EOL] @ tensor def attention_mask ( self ) : [EOL] return None [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] @ property def context_vector_size ( self ) : [EOL] return self . attention_states . get_shape ( ) [ [number] ] . value [EOL] [comment] [EOL] [EOL] @ property def state_size ( self ) : [EOL] return self . context_vector_size [EOL] [EOL] def attention ( self , query , decoder_prev_state , decoder_input , loop_state , step ) : [EOL] context = tf . reshape ( self . attention_states , [ - [number] , self . context_vector_size ] ) [EOL] weights = tf . ones ( shape = [ tf . shape ( context ) [ [number] ] ] ) [EOL] [EOL] next_loop_state = AttentionLoopStateTA ( contexts = loop_state . contexts . write ( step , context ) , weights = loop_state . weights . write ( step , weights ) ) [EOL] [EOL] return context , next_loop_state [EOL] [EOL] def initial_loop_state ( self ) : [EOL] return empty_attention_loop_state ( ) [EOL] [EOL] def finalize_loop ( self , key , last_loop_state ) : [EOL] pass [EOL] [EOL] def visualize_attention ( self , key ) : [EOL] pass [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 $neuralmonkey.model.stateful.Stateful$ 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $neuralmonkey.model.model_part.InitializerSpecs$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $neuralmonkey.model.model_part.InitializerSpecs$ 0 0 0 0 0 $neuralmonkey.model.stateful.Stateful$ 0 $neuralmonkey.model.stateful.Stateful$ 0 0 0 0 0 $tensorflow.Tensor$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[tensorflow.Tensor]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[tensorflow.Tensor,neuralmonkey.attention.base_attention.AttentionLoopStateTA]$ 0 0 0 $tensorflow.Tensor$ 0 $tensorflow.Tensor$ 0 $tensorflow.Tensor$ 0 $neuralmonkey.attention.base_attention.AttentionLoopStateTA$ 0 $tensorflow.Tensor$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $neuralmonkey.attention.base_attention.AttentionLoopStateTA$ 0 0 0 0 0 $tensorflow.Tensor$ 0 $typing.Any$ 0 0 $typing.Any$ 0 $neuralmonkey.attention.base_attention.AttentionLoopStateTA$ 0 $typing.Any$ 0 0 0 $tensorflow.Tensor$ 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 $neuralmonkey.attention.base_attention.AttentionLoopStateTA$ 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 $neuralmonkey.attention.base_attention.AttentionLoopStateTA$ 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 0 0 0 0
from . feed_forward import Attention [EOL] from . coverage import CoverageAttention [EOL] from . scaled_dot_product import ScaledDotProdAttention [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] import argparse [EOL] [docstring] [EOL] import argparse [EOL] [EOL] [EOL] def main ( ) : [EOL] [comment] [EOL] parser = argparse . ArgumentParser ( description = __doc__ ) [EOL] parser . add_argument ( [string] , metavar = [string] , type = argparse . FileType ( [string] ) , help = [string] ) [EOL] parser . add_argument ( [string] , nargs = [string] , metavar = [string] , type = argparse . FileType ( [string] ) , help = [string] ) [EOL] args = parser . parse_args ( ) [EOL] [EOL] for lines in zip ( * ( [ args . selector ] + args . input_files ) ) : [EOL] index = int ( lines [ [number] ] ) [EOL] print ( lines [ index + [number] ] . strip ( ) ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] from typing import Any , List [EOL] import typing [EOL] import argparse [EOL] [docstring] [EOL] [EOL] import argparse [EOL] import os [EOL] import re [EOL] [EOL] import numpy as np [EOL] import tensorflow as tf [EOL] [EOL] from neuralmonkey . logging import log [EOL] [EOL] [EOL] IGNORED_PATTERNS = [ [string] ] [EOL] [EOL] [EOL] def main ( ) : [EOL] parser = argparse . ArgumentParser ( description = __doc__ ) [EOL] parser . add_argument ( [string] , type = str , nargs = [string] , help = [string] ) [EOL] parser . add_argument ( [string] , type = str , help = [string] ) [EOL] args = parser . parse_args ( ) [EOL] [EOL] non_existing_chckpoints = [ ] [EOL] for ckpt in args . checkpoints : [EOL] if not os . path . exists ( [string] . format ( ckpt ) ) : [EOL] non_existing_chckpoints . append ( ckpt ) [EOL] if non_existing_chckpoints : [EOL] raise ValueError ( [string] . format ( [string] . join ( non_existing_chckpoints ) ) ) [EOL] [EOL] [comment] [EOL] log ( [string] ) [EOL] var_list = tf . contrib . framework . list_variables ( args . checkpoints [ [number] ] ) [EOL] var_values , var_dtypes = { } , { } [EOL] for ( name , shape ) in var_list : [EOL] if not any ( re . match ( pat , name ) for pat in IGNORED_PATTERNS ) : [EOL] var_values [ name ] = np . zeros ( shape ) [EOL] for checkpoint in args . checkpoints : [EOL] log ( [string] . format ( checkpoint ) ) [EOL] reader = tf . contrib . framework . load_checkpoint ( checkpoint ) [EOL] for name in var_values : [EOL] tensor = reader . get_tensor ( name ) [EOL] var_dtypes [ name ] = tensor . dtype [EOL] var_values [ name ] += tensor [EOL] for name in var_values : [comment] [EOL] var_values [ name ] /= len ( args . checkpoints ) [EOL] [EOL] tf_vars = [ tf . get_variable ( v , shape = var_values [ v ] . shape , dtype = var_dtypes [ name ] ) for v in var_values ] [EOL] placeholders = [ tf . placeholder ( v . dtype , shape = v . shape ) for v in tf_vars ] [EOL] assign_ops = [ tf . assign ( v , p ) for ( v , p ) in zip ( tf_vars , placeholders ) ] [EOL] global_step = tf . Variable ( [number] , name = [string] , trainable = False , dtype = tf . int64 ) [EOL] saver = tf . train . Saver ( ) [EOL] [EOL] [comment] [EOL] with tf . Session ( ) as sess : [EOL] sess . run ( tf . global_variables_initializer ( ) ) [EOL] for p , assign_op , ( name , value ) in zip ( placeholders , assign_ops , var_values . items ( ) ) : [EOL] sess . run ( assign_op , { p : value } ) [EOL] saver . save ( sess , args . output_path , global_step = global_step ) [EOL] [EOL] log ( [string] . format ( args . output_path ) ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] from typing import TextIO , Any , List [EOL] import typing [EOL] import sys [EOL] import codecs [EOL] import javabridge [EOL] [EOL] from tokenize_data import get_decompounder [EOL] [EOL] def main ( ) : [EOL] sys . stdin = codecs . getreader ( [string] ) ( sys . stdin ) [EOL] sys . stdout = codecs . getwriter ( [string] ) ( sys . stdout ) [EOL] sys . stderr = codecs . getwriter ( [string] ) ( sys . stderr ) [EOL] [EOL] try : [EOL] decompounder = get_decompounder ( ) [EOL] for line in sys . stdin : [EOL] tokens = [ ] [EOL] for token in line . rstrip ( ) . split ( [string] ) : [EOL] if not token : [EOL] continue [EOL] if token [ [number] ] . isupper ( ) : [EOL] decompounded = decompounder . splitWord ( token ) [EOL] if decompounded . size ( ) >= [number] : [EOL] parts = [ decompounded . get ( j ) for j in range ( decompounded . size ( ) ) ] [EOL] parts_with_hyphens = [ [string] if not p else p for p in parts ] [EOL] tokens . append ( [string] . join ( parts_with_hyphens ) ) [EOL] del decompounded [EOL] else : [EOL] tokens . append ( token ) [EOL] else : [EOL] tokens . append ( token ) [EOL] print ( [string] . join ( tokens ) ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] finally : [EOL] javabridge . kill_vm ( ) [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List [EOL] import scripts [EOL] import typing [EOL] import argparse [EOL] import argparse [EOL] import sys [EOL] import os [EOL] os . environ [ [string] ] = [string] [EOL] sys . path . append ( [string] ) [EOL] import caffe [EOL] import numpy as np [EOL] import skimage [EOL] [EOL] def crop_image ( x , target_height = [number] , target_width = [number] ) : [EOL] image = skimage . img_as_float ( skimage . io . imread ( x ) ) . astype ( np . float32 ) [EOL] [EOL] if len ( image . shape ) == [number] : [EOL] image = np . tile ( image [ : , : , None ] , [number] ) [EOL] elif len ( image . shape ) == [number] : [EOL] image = image [ : , : , : , [number] ] [EOL] [EOL] height , width , rgb = image . shape [EOL] if width == height : [EOL] resized_image = skimage . transform . resize ( image , ( target_height , target_width ) ) [EOL] [EOL] elif height < width : [EOL] resized_image = skimage . transform . resize ( image , ( int ( width * float ( target_height ) / height ) , target_width ) ) [EOL] cropping_length = int ( ( resized_image . shape [ [number] ] - target_height ) / [number] ) [EOL] resized_image = resized_image [ : , cropping_length : resized_image . shape [ [number] ] - cropping_length ] [EOL] [EOL] else : [EOL] resized_image = skimage . transform . resize ( image , ( target_height , int ( height * float ( target_width ) / width ) ) ) [EOL] cropping_length = int ( ( resized_image . shape [ [number] ] - target_width ) / [number] ) [EOL] resized_image = resized_image [ cropping_length : resized_image . shape [ [number] ] - cropping_length , : ] [EOL] [EOL] return skimage . transform . resize ( resized_image , ( target_height , target_width ) ) [EOL] [EOL] class CNN ( object ) : [EOL] [EOL] def __init__ ( self , deploy , model , mean , batch_size = [number] , width = [number] , height = [number] ) : [EOL] [EOL] self . deploy = deploy [EOL] self . model = model [EOL] self . mean = mean [EOL] [EOL] self . batch_size = batch_size [EOL] self . net , self . transformer = self . get_net ( ) [EOL] self . net . blobs [ [string] ] . reshape ( self . batch_size , [number] , height , width ) [EOL] [EOL] self . width = width [EOL] self . height = height [EOL] [EOL] def get_net ( self ) : [EOL] [comment] [EOL] net = caffe . Net ( self . deploy , self . model , caffe . TEST ) [EOL] [EOL] transformer = caffe . io . Transformer ( { [string] : net . blobs [ [string] ] . data . shape } ) [EOL] transformer . set_transpose ( [string] , ( [number] , [number] , [number] ) ) [EOL] transformer . set_mean ( [string] , np . load ( self . mean ) . mean ( [number] ) . mean ( [number] ) ) [EOL] transformer . set_raw_scale ( [string] , [number] ) [EOL] transformer . set_channel_swap ( [string] , ( [number] , [number] , [number] ) ) [EOL] [EOL] return net , transformer [EOL] [EOL] def get_features ( self , image_list , layers = [string] , layer_sizes = [ [number] ] ) : [EOL] iter_until = len ( image_list ) + self . batch_size [EOL] all_feats = np . zeros ( [ len ( image_list ) ] + layer_sizes , dtype = np . float32 ) [EOL] [EOL] for start , end in zip ( list ( range ( [number] , iter_until , self . batch_size ) ) , list ( range ( self . batch_size , iter_until , self . batch_size ) ) ) : [EOL] [EOL] image_batch_file = image_list [ start : end ] [EOL] image_batch = np . array ( [ crop_image ( x , target_width = self . width , target_height = self . height ) for x in image_batch_file ] ) [EOL] [EOL] caffe_in = np . zeros ( np . array ( image_batch . shape ) [ [ [number] , [number] , [number] , [number] ] ] , dtype = np . float32 ) [EOL] [EOL] for idx , in_ in enumerate ( image_batch ) : [EOL] caffe_in [ idx ] = self . transformer . preprocess ( [string] , in_ ) [EOL] [EOL] out = self . net . forward_all ( blobs = [ layers ] , ** { [string] : caffe_in } ) [EOL] feats = out [ layers ] [EOL] [EOL] all_feats [ start : end ] = feats [EOL] [EOL] return all_feats [EOL] [EOL] def shape ( string ) : [EOL] return [ int ( s ) for s in string . split ( [string] ) ] [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( description = [string] ) [EOL] parser . add_argument ( [string] , type = str , required = True ) [EOL] parser . add_argument ( [string] , type = str , required = True ) [EOL] parser . add_argument ( [string] , type = str , required = True ) [EOL] parser . add_argument ( [string] , type = str , required = True ) [EOL] parser . add_argument ( [string] , type = str , required = True ) [EOL] parser . add_argument ( [string] , type = argparse . FileType ( [string] ) , required = True ) [EOL] parser . add_argument ( [string] , type = argparse . FileType ( [string] ) , required = True ) [EOL] parser . add_argument ( [string] , type = shape , required = True ) [EOL] parser . add_argument ( [string] , type = shape , required = True ) [EOL] args = parser . parse_args ( ) [EOL] [EOL] cnn = CNN ( deploy = args . model_prototxt , model = args . model_parameters , mean = args . img_mean , batch_size = [number] , width = args . img_shape [ [number] ] , height = args . img_shape [ [number] ] ) [EOL] path_list = [ os . path . join ( args . image_directory , f . rstrip ( ) ) for f in args . image_list ] [EOL] features_shape = [ args . output_shape [ [number] ] ] + args . output_shape [ : [number] ] [EOL] features = cnn . get_features ( path_list , layers = args . feature_layer , layer_sizes = features_shape ) [EOL] [EOL] np . save ( args . output_file , features . transpose ( ( [number] , [number] , [number] , [number] ) ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.Namespace$ 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 $scripts.caffe_image_features.CNN$ 0 0 0 0 0 $argparse.Namespace$ 0 0 0 0 0 $argparse.Namespace$ 0 0 0 0 0 $argparse.Namespace$ 0 0 0 0 0 0 0 0 0 $argparse.Namespace$ 0 0 0 0 0 0 0 0 $argparse.Namespace$ 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 $argparse.Namespace$ 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.Namespace$ 0 0 0 0 $typing.List[typing.Any]$ 0 0 $argparse.Namespace$ 0 0 0 0 0 0 0 $argparse.Namespace$ 0 0 0 0 0 0 0 $typing.Any$ 0 $scripts.caffe_image_features.CNN$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 $argparse.Namespace$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 $argparse.Namespace$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] from typing import Any [EOL] import argparse [EOL] import typing [EOL] [docstring] [EOL] [EOL] import argparse [EOL] import numpy as np [EOL] from scipy . special import lambertw [EOL] [EOL] def main ( ) : [EOL] parser = argparse . ArgumentParser ( description = [string] ) [EOL] parser . add_argument ( [string] , type = float , required = True , help = [string] ) [EOL] parser . add_argument ( [string] , type = int , required = True , help = [string] ) [EOL] args = parser . parse_args ( ) [EOL] [EOL] x = args . step [EOL] c = args . value [EOL] [EOL] coeff = c * np . exp ( lambertw ( ( [number] - c ) / c * x ) ) / ( [number] - c ) [EOL] [EOL] print ( coeff . real ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] from typing import Union , Dict , Any , List [EOL] import builtins [EOL] import typing [EOL] import argparse [EOL] [docstring] [EOL] [EOL] import argparse [EOL] import os [EOL] from typing import Union [EOL] [EOL] import numpy as np [EOL] [EOL] from neuralmonkey . processors . speech import SpeechFeaturesPreprocessor [EOL] from neuralmonkey . readers . audio_reader import audio_reader [EOL] [EOL] [EOL] def try_parse_number ( str_value ) : [EOL] value = str_value [EOL] try : [EOL] value = float ( str_value ) [EOL] value = int ( str_value ) [EOL] except ValueError : [EOL] pass [EOL] [EOL] return value [EOL] [EOL] [EOL] def main ( ) : [EOL] parser = argparse . ArgumentParser ( description = __doc__ , formatter_class = argparse . RawDescriptionHelpFormatter ) [EOL] parser . add_argument ( [string] , help = [string] ) [EOL] parser . add_argument ( [string] , help = [string] ) [EOL] parser . add_argument ( [string] , [string] , default = [string] , help = [string] ) [EOL] parser . add_argument ( [string] , [string] , help = [string] [string] ) [EOL] parser . add_argument ( [string] , [string] , default = [string] , help = [string] ) [EOL] parser . add_argument ( [string] , [string] , nargs = [number] , action = [string] , default = [ ] , metavar = ( [string] , [string] ) , help = [string] ) [EOL] [EOL] args = parser . parse_args ( ) [EOL] [EOL] [EOL] prefix = args . prefix [EOL] if prefix is None : [EOL] prefix = os . path . dirname ( os . path . abspath ( args . input ) ) [EOL] [EOL] feats_kwargs = { k : try_parse_number ( v ) for k , v in args . option } [EOL] [EOL] read = audio_reader ( prefix = prefix , audio_format = args . format ) [EOL] process = SpeechFeaturesPreprocessor ( feature_type = args . type , ** feats_kwargs ) [EOL] [EOL] output = [ process ( audio ) for audio in read ( [ args . input ] ) ] [EOL] [EOL] np . save ( args . output , output ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Union[builtins.str,builtins.float,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0