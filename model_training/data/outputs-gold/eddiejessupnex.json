	0
from typing import Any , List [EOL] import typing [EOL] import string [EOL] from . utils import sp_to_pt [EOL] [EOL] printable_ascii_codes = list ( map ( ord , string . printable ) ) [EOL] [EOL] [EOL] def truncate_list ( ts , n = [number] ) : [EOL] [docstring] [EOL] k = [number] * n [EOL] lim = ( k - [number] ) // [number] [EOL] if len ( ts ) > k : [EOL] return list ( ts [ : lim ] ) + [ [string] ] + list ( ts [ - lim : ] ) [EOL] else : [EOL] return ts [EOL] [EOL] [EOL] def strep ( s ) : [EOL] [docstring] [EOL] return ( s . replace ( [string] , [string] ) . replace ( [string] , [string] ) . replace ( [string] , [string] ) ) [EOL] [EOL] [EOL] def csep ( args , str_func = repr ) : [EOL] [docstring] [EOL] sargs = [ ] [EOL] for arg in args : [EOL] if arg is None or arg == [string] : [EOL] continue [EOL] if isinstance ( arg , str ) : [EOL] sarg = arg [EOL] else : [EOL] sarg = str_func ( arg ) [EOL] sargs . append ( sarg ) [EOL] return [string] . join ( sargs ) [EOL] [EOL] [EOL] def clsn ( obj ) : [EOL] [docstring] [EOL] if isinstance ( obj , str ) : [EOL] return obj [EOL] else : [EOL] return obj . __class__ . __name__ [EOL] [EOL] [EOL] def drep ( obj , a ) : [EOL] [docstring] [EOL] return f'{ clsn ( obj ) } [string] { csep ( a ) } [string] ' [EOL] [EOL] [EOL] def dimrep ( d ) : [EOL] if isinstance ( d , int ) : [EOL] return [string] . format ( sp_to_pt ( d ) ) [EOL] else : [EOL] return d [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List [EOL] import typing [EOL] from . constants . codes import CatCode [EOL] [EOL] [EOL] def get_real_decimal_constant ( collection ) : [EOL] [comment] [EOL] assert collection . base == [number] [EOL] chars = [ t . value [ [string] ] for t in collection . digits ] [EOL] s = [string] . join ( chars ) [EOL] return float ( s ) [EOL] [EOL] [EOL] def get_integer_constant ( collection ) : [EOL] chars = [ t . value [ [string] ] for t in collection . digits ] [EOL] s = [string] . join ( chars ) [EOL] return int ( s , base = collection . base ) [EOL] [EOL] [EOL] def get_backtick_target_code ( target ) : [EOL] if target . type == [string] : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] return ord ( target . value [ [string] ] ) [EOL] elif target . type == [string] : [EOL] return ord ( target . value [ [string] ] ) [EOL] else : [EOL] raise ValueError ( f' [string] { target . type }' ) [EOL] [EOL] [EOL] def split_at ( s , inds ) : [EOL] inds = [ [number] ] + list ( inds ) + [ len ( s ) ] [EOL] return [ s [ inds [ i ] : inds [ i + [number] ] ] for i in range ( [number] , len ( inds ) - [number] ) ] [EOL] [EOL] [EOL] def split_hex_code ( n , hex_length , inds ) : [EOL] [comment] [EOL] n_hex = format ( n , [string] . format ( hex_length ) ) [EOL] [comment] [EOL] assert len ( n_hex ) == hex_length [EOL] [comment] [EOL] parts_hex = split_at ( n_hex , inds ) [EOL] [comment] [EOL] parts = [ int ( part , base = [number] ) for part in parts_hex ] [EOL] return parts [EOL] [EOL] [EOL] def evaluate_signs ( signs_token ) : [EOL] sign = [number] [EOL] for t in signs_token . value : [EOL] if t . value [ [string] ] == [string] and t . value [ [string] ] == CatCode . other : [EOL] sign *= - [number] [EOL] elif t . value [ [string] ] == [string] and t . value [ [string] ] == CatCode . other : [EOL] pass [EOL] else : [EOL] raise ValueError [EOL] return sign [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import List , Type , Any [EOL] import typing [EOL] import nex [EOL] from collections import namedtuple [EOL] [EOL] from . import box [EOL] [EOL] [EOL] HListRoute = namedtuple ( [string] , ( [string] , [string] ) ) [EOL] [EOL] [EOL] def break_at ( h_list , i ) : [EOL] break_item = h_list [ i ] [EOL] [comment] [EOL] [comment] [EOL] if isinstance ( break_item , box . Glue ) : [EOL] h_list_got = h_list [ : i ] [EOL] else : [EOL] h_list_got = h_list [ : i + [number] ] [EOL] [comment] [EOL] if i == len ( h_list ) - [number] : [EOL] h_list_after = [ ] [EOL] [comment] [EOL] else : [EOL] for j in range ( i + [number] , len ( h_list ) ) : [EOL] item_after = h_list [ j ] [EOL] [comment] [EOL] [comment] [EOL] if ( not item_after . discardable ) or box . is_break_point ( h_list , j ) : [EOL] break [EOL] h_list_after = h_list [ j : ] [EOL] return h_list_got , h_list_after , break_item [EOL] [EOL] [EOL] def get_best_route ( h_list , h_size , tolerance , line_penalty ) : [EOL] if not h_list : [EOL] return HListRoute ( sequence = [ ] , demerit = [number] ) [EOL] [EOL] child_routes = [ ] [EOL] for i in range ( len ( h_list ) ) : [EOL] if box . is_break_point ( h_list , i ) : [EOL] h_list_got , h_list_after , break_item = break_at ( h_list , i ) [EOL] h_box = box . HBox ( h_list_got , to = h_size , set_glue = False ) [EOL] if h_box . considerable_as_line ( tolerance , break_item ) : [EOL] got_demerit = h_box . demerit ( break_item , line_penalty ) [EOL] best_current_child_route = get_best_route ( h_list_after , h_size , tolerance , line_penalty ) [EOL] if best_current_child_route is not None : [EOL] rt = HListRoute ( sequence = [ h_list_got ] + best_current_child_route . sequence , demerit = got_demerit + best_current_child_route . demerit ) [EOL] child_routes . append ( rt ) [EOL] [EOL] [comment] [EOL] no_break_h_box = box . HBox ( h_list , to = h_size , set_glue = False ) [EOL] no_break_demerit = no_break_h_box . demerit ( break_item = None , line_penalty = line_penalty ) [EOL] child_routes . append ( HListRoute ( sequence = [ h_list ] , demerit = no_break_demerit ) ) [EOL] [EOL] if child_routes : [EOL] return min ( child_routes , key = lambda t : t . demerit ) [EOL] else : [EOL] return None [EOL] [EOL] [EOL] def get_best_h_lists ( h_list , h_size , tolerance , line_penalty ) : [EOL] best_route = get_best_route ( h_list , h_size , tolerance , line_penalty ) [EOL] if best_route is None : [EOL] raise Exception ( [string] ) [EOL] else : [EOL] return best_route . sequence [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[nex.paragraphs.HListRoute]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[nex.paragraphs.HListRoute]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[nex.paragraphs.HListRoute]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[nex.paragraphs.HListRoute]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] import nex [EOL] import subprocess [EOL] [EOL] from . constants . parameters import Parameters [EOL] from . dampf . dvi_document import DVIDocument [EOL] from . utils import LogicError [EOL] from . import box [EOL] [EOL] [EOL] def write_box_to_doc ( doc , item , horizontal = False ) : [EOL] if isinstance ( item , box . VBox ) : [EOL] doc . push ( ) [EOL] doc . right ( item . offset ) [EOL] [EOL] for sub_item in item . contents : [EOL] write_box_to_doc ( doc , sub_item , horizontal = False ) [EOL] [EOL] doc . pop ( ) [EOL] if horizontal : [EOL] doc . right ( item . width ) [EOL] else : [EOL] doc . down ( item . height ) [EOL] elif isinstance ( item , box . HBox ) : [EOL] doc . push ( ) [EOL] doc . down ( - item . offset ) [EOL] [EOL] for sub_item in item . contents : [EOL] write_box_to_doc ( doc , sub_item , horizontal = True ) [EOL] [EOL] doc . pop ( ) [EOL] if horizontal : [EOL] doc . right ( item . width ) [EOL] else : [EOL] doc . down ( item . height ) [EOL] elif isinstance ( item , box . FontDefinition ) : [EOL] doc . define_font ( item . font_nr , item . font_name , font_path = item . file_name ) [EOL] elif isinstance ( item , box . FontSelection ) : [EOL] doc . select_font ( item . font_nr ) [EOL] elif isinstance ( item , box . Character ) : [EOL] doc . put_char ( item . code ) [EOL] doc . right ( item . width ) [EOL] elif isinstance ( item , box . Glue ) and not item . is_set : [EOL] raise LogicError ( [string] ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] elif ( isinstance ( item , box . Kern ) or ( isinstance ( item , box . Glue ) and item . is_set ) ) : [EOL] amount = item . length [EOL] if horizontal : [EOL] doc . right ( amount ) [EOL] else : [EOL] doc . down ( amount ) [EOL] elif isinstance ( item , box . Rule ) : [EOL] doc . put_rule ( item . height , item . width ) [EOL] if horizontal : [EOL] doc . right ( item . width ) [EOL] else : [EOL] doc . down ( item . height ) [EOL] [comment] [EOL] elif isinstance ( item , box . Penalty ) : [EOL] pass [EOL] else : [EOL] raise NotImplementedError [EOL] [EOL] [EOL] def write_to_dvi_file ( state , out_stream , write_pdf = False ) : [EOL] magnification = state . parameters . get ( Parameters . mag ) [EOL] doc = DVIDocument ( magnification ) [EOL] for main_v_box in state . completed_pages : [EOL] doc . begin_new_page ( ) [EOL] for item in main_v_box . contents : [EOL] write_box_to_doc ( doc , item , horizontal = False ) [EOL] [EOL] doc . write ( out_stream ) [EOL] if write_pdf : [EOL] if not isinstance ( out_stream , str ) : [EOL] raise ValueError ( [string] ) [EOL] subprocess . run ( [ [string] , out_stream ] , check = True ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import List , Any [EOL] import typing [EOL] import uuid [EOL] import os [EOL] from os import path as opath [EOL] import base64 [EOL] import uuid [EOL] [EOL] from . pydvi . TeXUnit import pt2sp , sp2pt [EOL] [EOL] [EOL] def pt_to_sp ( pt ) : [EOL] return round ( pt2sp ( pt ) ) [EOL] [EOL] [EOL] def sp_to_pt ( pt ) : [EOL] return sp2pt ( pt ) [EOL] [EOL] [EOL] ascii_characters = [string] . join ( chr ( i ) for i in range ( [number] ) ) [EOL] [EOL] [EOL] def get_unique_id ( ) : [EOL] raw = uuid . uuid4 ( ) [EOL] compressed = base64 . urlsafe_b64encode ( raw . bytes ) . decode ( [string] ) [EOL] sanitised = compressed . rstrip ( [string] ) . replace ( [string] , [string] ) [EOL] return sanitised [EOL] [EOL] [EOL] def get_default_font_paths ( ) : [EOL] return [ os . getcwd ( ) , opath . join ( os . getcwd ( ) , [string] ) , ] [EOL] [EOL] [EOL] class InfiniteDimension : [EOL] [EOL] def __init__ ( self , factor , nr_fils ) : [EOL] self . factor = factor [EOL] self . nr_fils = nr_fils [EOL] [EOL] [EOL] def sum_infinities ( ds ) : [EOL] order_sums = [ [number] ] [EOL] for d in ds : [EOL] if isinstance ( d , int ) : [EOL] order_sums [ [number] ] += d [EOL] elif isinstance ( d , InfiniteDimension ) : [EOL] order = d . nr_fils [EOL] [comment] [EOL] new_length_needed = order + [number] - len ( order_sums ) [EOL] order_sums . extend ( [number] for _ in range ( new_length_needed ) ) [EOL] order_sums [ order ] += d . factor [EOL] return order_sums [EOL] [EOL] [EOL] def ensure_extension ( path , extension ) : [EOL] [docstring] [EOL] end = opath . extsep + extension [EOL] if not path . endswith ( end ) : [EOL] path += end [EOL] return path [EOL] [EOL] [EOL] def find_file ( file_name , search_paths = None ) : [EOL] [docstring] [EOL] [comment] [EOL] supplied_dirname = opath . dirname ( file_name ) [EOL] if supplied_dirname != [string] : [EOL] return file_name [EOL] [comment] [EOL] if search_paths is None : [EOL] search_paths = [ ] [EOL] for search_path in search_paths : [EOL] test_path = opath . join ( search_path , file_name ) [EOL] if opath . exists ( test_path ) : [EOL] return opath . abspath ( test_path ) [EOL] raise FileNotFoundError [EOL] [EOL] [EOL] def file_path_to_chars ( file_path ) : [EOL] [docstring] [EOL] with open ( file_path , [string] ) as f : [EOL] return [ chr ( b ) for b in f . read ( ) ] [EOL] [EOL] [EOL] [comment] [EOL] [EOL] [EOL] class LogicError ( Exception ) : [EOL] [docstring] [EOL] pass [EOL] [EOL] [EOL] class UserError ( Exception ) : [EOL] [docstring] [EOL] pass [EOL] [EOL] [EOL] def enums_to_values ( enums ) : [EOL] return tuple ( i . value for i in enums ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
class ParserGeneratorError ( Exception ) : [EOL] pass [EOL] [EOL] [EOL] class ParsingError ( Exception ) : [EOL] [docstring] [EOL] def __init__ ( self , message , source_pos ) : [EOL] self . message = message [EOL] self . source_pos = source_pos [EOL] [EOL] def getsourcepos ( self ) : [EOL] [docstring] [EOL] return self . source_pos [EOL] [EOL] [EOL] class ParserGeneratorWarning ( Warning ) : [EOL] pass [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List [EOL] import typing [EOL] import nex [EOL] from . errors import ParserGeneratorError [EOL] [EOL] [EOL] def rightmost_terminal ( symbols , terminals ) : [EOL] for sym in reversed ( symbols ) : [EOL] if sym in terminals : [EOL] return sym [EOL] return None [EOL] [EOL] [EOL] class Grammar ( object ) : [EOL] def __init__ ( self , terminals ) : [EOL] [comment] [EOL] self . productions = [ None ] [EOL] [comment] [EOL] [comment] [EOL] self . prod_names = { } [EOL] [comment] [EOL] [comment] [EOL] self . terminals = dict ( ( t , [ ] ) for t in terminals ) [EOL] self . terminals [ [string] ] = [ ] [EOL] [comment] [EOL] [comment] [EOL] self . nonterminals = { } [EOL] self . first = { } [EOL] self . follow = { } [EOL] self . precedence = { } [EOL] self . start = None [EOL] [EOL] def add_production ( self , prod_name , syms , func , precedence ) : [EOL] if prod_name in self . terminals : [EOL] raise ParserGeneratorError ( [string] % prod_name ) [EOL] [EOL] if precedence is None : [EOL] precname = rightmost_terminal ( syms , self . terminals ) [EOL] prod_prec = self . precedence . get ( precname , ( [string] , [number] ) ) [EOL] else : [EOL] try : [EOL] prod_prec = self . precedence [ precedence ] [EOL] except KeyError : [EOL] raise ParserGeneratorError ( [string] % precedence ) [EOL] [EOL] pnumber = len ( self . productions ) [EOL] self . nonterminals . setdefault ( prod_name , [ ] ) [EOL] [EOL] for t in syms : [EOL] if t in self . terminals : [EOL] self . terminals [ t ] . append ( pnumber ) [EOL] else : [EOL] self . nonterminals . setdefault ( t , [ ] ) . append ( pnumber ) [EOL] [EOL] p = Production ( pnumber , prod_name , syms , prod_prec , func ) [EOL] self . productions . append ( p ) [EOL] [EOL] self . prod_names . setdefault ( prod_name , [ ] ) . append ( p ) [EOL] [EOL] def set_precedence ( self , term , assoc , level ) : [EOL] if term in self . precedence : [EOL] raise ParserGeneratorError ( [string] % term ) [EOL] if assoc not in [ [string] , [string] , [string] ] : [EOL] raise ParserGeneratorError ( [string] % ( [EOL] assoc [EOL] ) ) [EOL] self . precedence [ term ] = ( assoc , level ) [EOL] [EOL] def set_start ( self , start = None ) : [EOL] if start is None : [EOL] start = self . productions [ [number] ] . name [EOL] self . productions [ [number] ] = Production ( [number] , [string] , [ start ] , ( [string] , [number] ) , None ) [EOL] self . nonterminals [ start ] . append ( [number] ) [EOL] self . start = start [EOL] [EOL] @ property def unused_terminals ( self ) : [EOL] return [ t for t , prods in self . terminals . items ( ) if not prods and t != [string] ] [EOL] [EOL] @ property def unused_productions ( self ) : [EOL] return [ p for p , prods in self . nonterminals . items ( ) if not prods ] [EOL] [EOL] def build_lritems ( self ) : [EOL] [docstring] [EOL] for p in self . productions : [EOL] last_lr_item = p [EOL] i = [number] [EOL] lr_items = [ ] [EOL] while True : [EOL] if i > len ( p ) : [EOL] lr_item = None [EOL] else : [EOL] try : [EOL] before = p . prod [ i - [number] ] [EOL] except IndexError : [EOL] before = None [EOL] try : [EOL] after = self . prod_names [ p . prod [ i ] ] [EOL] except ( IndexError , KeyError ) : [EOL] after = [ ] [EOL] lr_item = LRItem ( p , i , before , after ) [EOL] last_lr_item . lr_next = lr_item [EOL] if lr_item is None : [EOL] break [EOL] lr_items . append ( lr_item ) [EOL] last_lr_item = lr_item [EOL] i += [number] [EOL] p . lr_items = lr_items [EOL] [EOL] def _first ( self , beta ) : [EOL] result = [ ] [EOL] for x in beta : [EOL] x_produces_empty = False [EOL] for f in self . first [ x ] : [EOL] if f == [string] : [EOL] x_produces_empty = True [EOL] else : [EOL] if f not in result : [EOL] result . append ( f ) [EOL] if not x_produces_empty : [EOL] break [EOL] else : [EOL] result . append ( [string] ) [EOL] return result [EOL] [EOL] def compute_first ( self ) : [EOL] for t in self . terminals : [EOL] self . first [ t ] = [ t ] [EOL] [EOL] self . first [ [string] ] = [ [string] ] [EOL] [EOL] for n in self . nonterminals : [EOL] self . first [ n ] = [ ] [EOL] [EOL] changed = True [EOL] while changed : [EOL] changed = False [EOL] for n in self . nonterminals : [EOL] for p in self . prod_names [ n ] : [EOL] for f in self . _first ( p . prod ) : [EOL] if f not in self . first [ n ] : [EOL] self . first [ n ] . append ( f ) [EOL] changed = True [EOL] [EOL] def compute_follow ( self ) : [EOL] for k in self . nonterminals : [EOL] self . follow [ k ] = [ ] [EOL] [EOL] start = self . start [EOL] self . follow [ start ] = [ [string] ] [EOL] [EOL] added = True [EOL] while added : [EOL] added = False [EOL] for p in self . productions [ [number] : ] : [EOL] for i , B in enumerate ( p . prod ) : [EOL] if B in self . nonterminals : [EOL] fst = self . _first ( p . prod [ i + [number] : ] ) [EOL] has_empty = False [EOL] for f in fst : [EOL] if f != [string] and f not in self . follow [ B ] : [EOL] self . follow [ B ] . append ( f ) [EOL] added = True [EOL] if f == [string] : [EOL] has_empty = True [EOL] if has_empty or i == ( len ( p . prod ) - [number] ) : [EOL] for f in self . follow [ p . name ] : [EOL] if f not in self . follow [ B ] : [EOL] self . follow [ B ] . append ( f ) [EOL] added = True [EOL] [EOL] [EOL] class Production ( object ) : [EOL] def __init__ ( self , num , name , prod , precedence , func ) : [EOL] self . name = name [EOL] self . prod = prod [EOL] self . number = num [EOL] self . func = func [EOL] self . prec = precedence [EOL] [EOL] self . unique_syms = [ ] [EOL] for s in self . prod : [EOL] if s not in self . unique_syms : [EOL] self . unique_syms . append ( s ) [EOL] [EOL] self . lr_items = [ ] [EOL] self . lr_next = None [EOL] self . lr0_added = [number] [EOL] self . reduced = [number] [EOL] [EOL] def __repr__ ( self ) : [EOL] return [string] % ( self . name , [string] . join ( self . prod ) ) [EOL] [EOL] def __len__ ( self ) : [EOL] return len ( self . prod ) [EOL] [EOL] [EOL] class LRItem ( object ) : [EOL] def __init__ ( self , p , n , before , after ) : [EOL] self . name = p . name [EOL] self . prod = p . prod [ : ] [EOL] self . prod . insert ( n , [string] ) [EOL] self . number = p . number [EOL] self . lr_index = n [EOL] self . lookaheads = { } [EOL] self . unique_syms = p . unique_syms [EOL] self . lr_before = before [EOL] self . lr_after = after [EOL] [EOL] def __repr__ ( self ) : [EOL] return [string] % ( self . name , [string] . join ( self . prod ) ) [EOL] [EOL] def __len__ ( self ) : [EOL] return len ( self . prod ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $nex.rply.grammar.Production$ 0 0 0 $builtins.int$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $nex.rply.grammar.Production$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $nex.rply.grammar.Production$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $nex.rply.grammar.LRItem$ 0 0 0 $builtins.int$ 0 0 0 $nex.rply.grammar.LRItem$ 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 $nex.rply.grammar.LRItem$ 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 $nex.rply.grammar.LRItem$ 0 0 0 0 0 $builtins.int$ 0 $None$ 0 $typing.List[typing.Any]$ 0 0 $nex.rply.grammar.LRItem$ 0 0 0 $nex.rply.grammar.LRItem$ 0 0 $nex.rply.grammar.LRItem$ 0 0 0 0 0 0 $nex.rply.grammar.LRItem$ 0 0 0 $nex.rply.grammar.LRItem$ 0 0 $nex.rply.grammar.LRItem$ 0 $nex.rply.grammar.LRItem$ 0 $builtins.int$ 0 0 0 0 0 $nex.rply.grammar.LRItem$ 0 $nex.rply.grammar.LRItem$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from collections import MutableMapping [EOL] [EOL] [EOL] class IdentityDict ( MutableMapping ) : [EOL] def __init__ ( self ) : [EOL] self . _contents = { } [EOL] self . _keepalive = [ ] [EOL] [EOL] def __getitem__ ( self , key ) : [EOL] return self . _contents [ id ( key ) ] [ [number] ] [EOL] [EOL] def __setitem__ ( self , key , value ) : [EOL] idx = len ( self . _keepalive ) [EOL] self . _keepalive . append ( key ) [EOL] self . _contents [ id ( key ) ] = key , value , idx [EOL] [EOL] def __delitem__ ( self , key ) : [EOL] del self . _contents [ id ( key ) ] [EOL] for idx , obj in enumerate ( self . _keepalive ) : [EOL] if obj is key : [EOL] del self . _keepalive [ idx ] [EOL] break [EOL] [EOL] def __len__ ( self ) : [EOL] return len ( self . _contents ) [EOL] [EOL] def __iter__ ( self ) : [EOL] for key , _ , _ in self . _contents . values ( ) : [EOL] yield key [EOL] [EOL] [EOL] class Counter ( object ) : [EOL] def __init__ ( self ) : [EOL] self . value = [number] [EOL] [EOL] def incr ( self ) : [EOL] self . value += [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List [EOL] import typing [EOL] import nex [EOL] from . errors import ParsingError [EOL] [EOL] [EOL] class Token ( object ) : [EOL] [docstring] [EOL] def __init__ ( self , type_ , value ) : [EOL] self . type = type_ [EOL] self . value = value [EOL] [EOL] def __repr__ ( self ) : [EOL] return [string] % ( self . type , self . value ) [EOL] [EOL] [EOL] class LRParser ( object ) : [EOL] def __init__ ( self , lr_table , error_handler ) : [EOL] self . lr_table = lr_table [EOL] self . error_handler = error_handler [EOL] [EOL] def parse ( self , tokenizer , state = None ) : [EOL] lookahead = None [EOL] lookaheadstack = [ ] [EOL] [EOL] statestack = [ [number] ] [EOL] symstack = [ Token ( [string] , [string] ) ] [EOL] [EOL] current_state = [number] [EOL] while True : [EOL] if self . lr_table . default_reductions [ current_state ] : [EOL] t = self . lr_table . default_reductions [ current_state ] [EOL] current_state = self . _reduce_production ( t , symstack , statestack , state ) [EOL] continue [EOL] [EOL] if lookahead is None : [EOL] if lookaheadstack : [EOL] lookahead = lookaheadstack . pop ( ) [EOL] else : [EOL] try : [EOL] [comment] [EOL] lookahead = next ( tokenizer ) [EOL] except StopIteration : [EOL] lookahead = None [EOL] [EOL] if lookahead is None : [EOL] [comment] [EOL] could_only_end = len ( self . lr_table . lr_action [ current_state ] ) == [number] [EOL] lookahead = Token ( [string] , [string] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] if lookahead . type in self . lr_table . lr_action [ current_state ] : [EOL] [comment] [EOL] t = self . lr_table . lr_action [ current_state ] [ lookahead . type ] [EOL] [comment] [EOL] if t > [number] : [EOL] statestack . append ( t ) [EOL] current_state = t [EOL] symstack . append ( lookahead ) [EOL] lookahead = None [EOL] continue [EOL] [comment] [EOL] elif t < [number] : [EOL] current_state = self . _reduce_production ( t , symstack , statestack , state ) [EOL] continue [EOL] [comment] [EOL] [comment] [EOL] else : [EOL] [comment] [EOL] n = symstack [ - [number] ] [EOL] [comment] [EOL] [comment] [EOL] n . _could_only_end = could_only_end [EOL] return n [EOL] else : [EOL] self . sym_stack = symstack [EOL] self . state_stack = statestack [EOL] self . look_ahead = lookahead [EOL] self . look_ahead_stack = lookaheadstack [EOL] [comment] [EOL] if self . error_handler is not None : [EOL] if state is None : [EOL] self . error_handler ( lookahead ) [EOL] else : [EOL] self . error_handler ( state , lookahead ) [EOL] raise AssertionError ( [string] ) [EOL] else : [EOL] raise ParsingError ( None , lookahead . getsourcepos ( ) ) [EOL] [EOL] def _reduce_production ( self , t , symstack , statestack , state ) : [EOL] [comment] [EOL] p = self . lr_table . grammar . productions [ - t ] [EOL] pname = p . name [EOL] plen = len ( p ) [EOL] start = len ( symstack ) + ( - plen - [number] ) [EOL] assert start >= [number] [EOL] targ = symstack [ start + [number] : ] [EOL] start = len ( symstack ) + ( - plen ) [EOL] assert start >= [number] [EOL] del symstack [ start : ] [EOL] del statestack [ start : ] [EOL] if state is None : [EOL] value = p . func ( targ ) [EOL] else : [EOL] value = p . func ( state , targ ) [EOL] symstack . append ( value ) [EOL] current_state = self . lr_table . lr_goto [ statestack [ - [number] ] ] [ pname ] [EOL] statestack . append ( current_state ) [EOL] return current_state [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 0 $typing.List[nex.rply.parser.Token]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 $typing.List[nex.rply.parser.Token]$ 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 $None$ 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 $None$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.List[builtins.int]$ 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.List[nex.rply.parser.Token]$ 0 0 0 $None$ 0 0 $None$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 $typing.List[nex.rply.parser.Token]$ 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $nex.rply.parser.Token$ 0 $typing.List[nex.rply.parser.Token]$ 0 0 0 0 0 0 0 0 0 $nex.rply.parser.Token$ 0 0 0 0 0 0 $nex.rply.parser.Token$ 0 0 0 0 0 0 0 0 $typing.List[nex.rply.parser.Token]$ 0 0 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 0 $None$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $builtins.int$ 0 0 0 $typing.Any$ 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 $typing.Any$ 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0
from typing import Any , List [EOL] import typing [EOL] import io [EOL] from . . pydvi . Font . TfmParser import TfmParser [EOL] from . . pydvi . TeXUnit import pt2sp [EOL] [EOL] from . dvi_spec import ( get_set_char_instruction , get_set_rule_instruction , get_put_char_instruction , get_put_rule_instruction , get_no_op_instruction , get_begin_page_instruction , get_end_page_instruction , get_push_instruction , get_pop_instruction , get_right_instruction , get_right_w_instruction , get_set_w_then_right_w_instruction , get_right_x_instruction , get_set_x_then_right_x_instruction , get_down_instruction , get_down_y_instruction , get_set_y_then_down_y_instruction , get_down_z_instruction , get_set_z_then_down_z_instruction , get_define_font_nr_instruction , get_select_font_nr_instruction , get_do_special_instruction , get_preamble_instruction , get_postamble_instruction , get_post_postamble_instruction , ) [EOL] from . dvi_spec import EncodedOperation , EncodedInteger , EncodedString , OpCode [EOL] [EOL] numerator = int ( [number] ) [EOL] denominator = int ( [number] * [number] ** [number] ) [EOL] dvi_format = [number] [EOL] [EOL] [EOL] class DVIDocument : [EOL] [EOL] def __init__ ( self , magnification ) : [EOL] self . magnification = magnification [EOL] [EOL] self . preamble = get_preamble_instruction ( dvi_format = dvi_format , numerator = numerator , denominator = denominator , magnification = self . magnification , comment = [string] ) [EOL] self . mundane_instructions = [ ] [EOL] self . defined_fonts_info = { } [EOL] self . stack_depth = [number] [EOL] self . max_stack_depth = self . stack_depth [EOL] self . current_font_nr = None [EOL] [EOL] @ property def instructions ( self ) : [EOL] return [ self . preamble ] + self . mundane_instructions [EOL] [EOL] @ property def flat_instruction_parts ( self ) : [EOL] return [ p for inst in self . instructions for p in inst . op_and_args ] [EOL] [EOL] def op_code_pointers ( self , op_code ) : [EOL] byte_pointer = [number] [EOL] op_code_pointers = [ ] [EOL] for part in self . flat_instruction_parts : [EOL] byte_pointer += part . nr_bytes ( ) [EOL] if ( isinstance ( part , EncodedOperation ) [EOL] and part . op_code == op_code ) : [EOL] op_code_pointers . append ( byte_pointer - [number] ) [EOL] return op_code_pointers [EOL] [EOL] @ property def _begin_page_pointers ( self ) : [EOL] return self . op_code_pointers ( OpCode . begin_page ) [EOL] [EOL] @ property def last_begin_page_pointer ( self ) : [EOL] pointers = self . _begin_page_pointers [EOL] return pointers [ - [number] ] if pointers else - [number] [EOL] [EOL] @ property def nr_begin_page_pointers ( self ) : [EOL] return len ( self . _begin_page_pointers ) [EOL] [EOL] def begin_new_page ( self ) : [EOL] [comment] [EOL] if self . _begin_page_pointers : [EOL] self . _end_page ( ) [EOL] bop_args = list ( range ( [number] ) ) + [ self . last_begin_page_pointer ] [EOL] bop = get_begin_page_instruction ( * bop_args ) [EOL] self . mundane_instructions . append ( bop ) [EOL] if self . current_font_nr is not None : [EOL] self . select_font ( self . current_font_nr ) [EOL] [EOL] def _end_page ( self ) : [EOL] eop = get_end_page_instruction ( ) [EOL] self . mundane_instructions . append ( eop ) [EOL] [EOL] def define_font ( self , font_nr , font_name , font_path , scale_factor_ratio = [number] ) : [EOL] font_info = TfmParser . parse ( font_name , font_path ) [EOL] design_size = int ( pt2sp ( font_info . design_font_size ) ) [EOL] scale_factor = int ( design_size * scale_factor_ratio ) [EOL] font_path = font_info . font_name [EOL] define_font_nr_instr = get_define_font_nr_instruction ( font_nr , font_info . checksum , scale_factor , design_size , font_path ) [EOL] self . _define_font ( define_font_nr_instr ) [EOL] self . defined_fonts_info [ font_nr ] = { [string] : font_info , [string] : define_font_nr_instr } [EOL] [EOL] def _define_font ( self , define_font_nr_instr ) : [EOL] self . mundane_instructions . append ( define_font_nr_instr ) [EOL] [EOL] def select_font ( self , font_nr ) : [EOL] inst = get_select_font_nr_instruction ( font_nr ) [EOL] self . mundane_instructions . append ( inst ) [EOL] [comment] [EOL] self . current_font_nr = font_nr [EOL] [EOL] @ property def current_font_info ( self ) : [EOL] return self . defined_fonts_info [ self . current_font_nr ] [ [string] ] [EOL] [EOL] def _end_document ( self ) : [EOL] self . _do_postamble ( ) [EOL] [comment] [EOL] for font_nr , font_details in self . defined_fonts_info . items ( ) : [EOL] self . _define_font ( font_details [ [string] ] ) [EOL] self . _do_post_postamble ( ) [EOL] [EOL] def _do_postamble ( self ) : [EOL] [comment] [EOL] [comment] [EOL] max_page_height_plus_depth = [number] [EOL] max_page_width = [number] [EOL] post = get_postamble_instruction ( self . last_begin_page_pointer , numerator , denominator , self . magnification , max_page_height_plus_depth , max_page_width , self . max_stack_depth , self . nr_begin_page_pointers ) [EOL] self . mundane_instructions . append ( post ) [EOL] [EOL] def _do_post_postamble ( self ) : [EOL] postamble_pointers = self . op_code_pointers ( OpCode . postamble ) [EOL] assert len ( postamble_pointers ) == [number] [EOL] postamble_pointer = postamble_pointers [ - [number] ] [EOL] [EOL] post_post = get_post_postamble_instruction ( postamble_pointer , dvi_format ) [EOL] self . mundane_instructions . append ( post_post ) [EOL] [EOL] def push ( self ) : [EOL] [comment] [EOL] self . stack_depth += [number] [EOL] self . max_stack_depth = max ( self . stack_depth , self . max_stack_depth ) [EOL] self . mundane_instructions . append ( get_push_instruction ( ) ) [EOL] [EOL] def pop ( self ) : [EOL] self . stack_depth -= [number] [EOL] self . mundane_instructions . append ( get_pop_instruction ( ) ) [EOL] [EOL] def down ( self , a ) : [EOL] self . mundane_instructions . append ( get_down_instruction ( a ) ) [EOL] [EOL] def right ( self , a ) : [EOL] self . mundane_instructions . append ( get_right_instruction ( a ) ) [EOL] [EOL] def _encode ( self ) : [EOL] return [string] . join ( inst . encode ( ) for inst in self . instructions ) [EOL] [EOL] def set_char ( self , char ) : [EOL] self . mundane_instructions . append ( get_set_char_instruction ( char ) ) [EOL] [EOL] def put_char ( self , char ) : [EOL] self . mundane_instructions . append ( get_put_char_instruction ( char ) ) [EOL] [EOL] def pretty_print ( self ) : [EOL] [docstring] [EOL] [EOL] def bps ( bp ) : [EOL] [docstring] [EOL] return f' [string] { bp : [string] } [string] ' [EOL] [EOL] def bls ( nb ) : [EOL] [docstring] [EOL] return f' [string] { nb : [string] } [string] ' [EOL] [EOL] [comment] [EOL] bp = [number] [EOL] [comment] [EOL] g = [string] [EOL] [comment] [EOL] boring_count = [number] [EOL] boredom_thresh = [number] [EOL] for instr in self . instructions : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] if instr . op_code in ( OpCode . right_3_byte , OpCode . put_1_byte_char , OpCode . define_1_byte_font_nr ) : [EOL] boring_count += [number] [EOL] else : [EOL] if boring_count > [number] : [EOL] print ( [string] ) [EOL] boring_count = [number] [EOL] if boring_count > boredom_thresh : [EOL] if boring_count == boredom_thresh + [number] : [EOL] print ( [string] ) [EOL] continue [EOL] [EOL] [comment] [EOL] print ( f'{ bps ( bp ) } [string] { instr . op_code } [string] { g }{ bls ( instr . nr_bytes ( ) ) }' ) [EOL] print ( [string] ) [EOL] [EOL] [comment] [EOL] print ( f'{ bps ( bp ) } [string] { g }{ instr . encoded_op_code . value : [string] }{ g }{ g }{ bls ( instr . encoded_op_code . nr_bytes ( ) ) } [string] { instr . op_code } [string] ' ) [EOL] [comment] [EOL] bp += instr . encoded_op_code . nr_bytes ( ) [EOL] [EOL] [comment] [EOL] print ( [string] ) [EOL] for arg in instr . arguments : [EOL] if isinstance ( arg , EncodedInteger ) : [EOL] [comment] [EOL] [comment] [EOL] if arg . name == [string] : [EOL] v = f"{ arg . value : [string] } [string] { chr ( arg . value ) } [string] " [EOL] else : [EOL] v = f'{ arg . value : [string] }' [EOL] print ( f'{ bps ( bp ) } [string] { g }{ v }{ g }{ g }{ bls ( arg . nr_bytes ( ) ) } [string] { arg . name } [string] ' ) [EOL] [comment] [EOL] elif isinstance ( arg , EncodedString ) : [EOL] s = f' [string] { arg . value } [string] ' [EOL] d = [number] [EOL] s += [string] * max ( d - len ( s ) , [number] ) [EOL] print ( f'{ bps ( bp ) } [string] { g }{ s }{ g }{ g }{ bls ( arg . nr_bytes ( ) ) } [string] { arg . name } [string] ' ) [EOL] [comment] [EOL] bp += arg . nr_bytes ( ) [EOL] print ( [string] ) [EOL] [EOL] def write ( self , stream ) : [EOL] self . _end_page ( ) [EOL] self . _end_document ( ) [EOL] [EOL] [comment] [EOL] if isinstance ( stream , str ) : [EOL] stream = open ( stream , [string] ) [EOL] stream . write ( self . _encode ( ) ) [EOL] [EOL] def put_rule ( self , height , width ) : [EOL] inst = get_put_rule_instruction ( height , width ) [EOL] self . mundane_instructions . append ( inst ) [EOL] [EOL] def set_rule ( self , height , width ) : [EOL] inst = get_set_rule_instruction ( height , width ) [EOL] self . mundane_instructions . append ( inst ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $builtins.int$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $io.BufferedWriter$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $io.BufferedWriter$ 0 0 0 0 0 $io.BufferedWriter$ 0 0 0 $io.BufferedWriter$ 0 0 0 0 $io.BufferedWriter$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0
	0
from typing import Any [EOL] import typing [EOL] import builtins [EOL] import math [EOL] [EOL] [EOL] def is_signed_nr_expressible_in_n_bits ( n , nr_bits ) : [EOL] min_signed_val = - ( [number] ** ( nr_bits - [number] ) ) [EOL] max_signed_val = [number] ** ( nr_bits - [number] ) - [number] [EOL] return min_signed_val <= n <= max_signed_val [EOL] [EOL] [EOL] def get_bytes_needed ( n , signed , is_check_sum = False ) : [EOL] if n < [number] and not signed : [EOL] raise ValueError [EOL] if n == [number] : [EOL] return [number] [EOL] nr_bytes = int ( math . log ( abs ( n ) , [number] ) ) + [number] [EOL] [comment] [EOL] if nr_bytes == [number] : [EOL] signed = True [EOL] if signed : [EOL] nr_bits = [number] * nr_bytes [EOL] if not is_signed_nr_expressible_in_n_bits ( n , nr_bits ) : [EOL] nr_bytes += [number] [EOL] [comment] [EOL] if not [number] < nr_bytes <= [number] : [EOL] raise ValueError [EOL] return nr_bytes [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Any [EOL] import typing [EOL] import fractions [EOL] [docstring] [EOL] from typing import SupportsFloat , cast [EOL] [EOL] import fractions [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] big_point_in_inch = [number] [EOL] [comment] [EOL] didot_in_cicero = [number] [EOL] [comment] [EOL] didot_in_point = fractions . Fraction ( [number] , [number] ) [EOL] [comment] [EOL] mm_in_inch = fractions . Fraction ( [number] , [number] ) [EOL] [comment] [EOL] point_in_inch = fractions . Fraction ( [number] , [number] ) [EOL] [comment] [EOL] scaled_point_in_point = [number] ** [number] [EOL] [EOL] inch_in_mm = [number] / mm_in_inch [EOL] point_in_mm = point_in_inch * inch_in_mm [EOL] inch_in_point = [number] / point_in_inch [EOL] [EOL] mm_in_point = [number] / point_in_mm [EOL] pt_in_sp = fractions . Fraction ( [number] , scaled_point_in_point ) [EOL] [EOL] inch_in_mm_f = float ( cast ( SupportsFloat , inch_in_mm ) ) [EOL] inch_in_point_f = float ( inch_in_point ) [EOL] mm_in_inch_f = float ( mm_in_inch ) [EOL] mm_in_point_f = float ( mm_in_point ) [EOL] point_in_inch_f = float ( point_in_inch ) [EOL] pt_in_sp_f = float ( pt_in_sp ) [EOL] sp_in_pt_f = float ( scaled_point_in_point ) [EOL] [EOL] [EOL] def mm2in ( x ) : [EOL] [docstring] [EOL] return x * inch_in_mm_f [EOL] [EOL] [EOL] def in2mm ( x ) : [EOL] [docstring] [EOL] return x * mm_in_inch_f [EOL] [EOL] [EOL] def dpi2mm ( x ) : [EOL] [docstring] [EOL] return mm_in_inch_f / x [EOL] [EOL] [EOL] def in2pt ( x ) : [EOL] [docstring] [EOL] return x * point_in_inch_f [EOL] [EOL] [EOL] def pt2in ( x ) : [EOL] [docstring] [EOL] return x * inch_in_point_f [EOL] [EOL] [EOL] def pt2mm ( x ) : [EOL] [docstring] [EOL] return x * mm_in_point_f [EOL] [EOL] [EOL] def sp2pt ( x ) : [EOL] [docstring] [EOL] return x * pt_in_sp_f [EOL] [EOL] [EOL] def sp2in ( x ) : [EOL] [docstring] [EOL] return pt2in ( sp2pt ( x ) ) [EOL] [EOL] [EOL] def sp2mm ( x ) : [EOL] [docstring] [EOL] return pt2mm ( sp2pt ( x ) ) [EOL] [EOL] [EOL] def sp2dpi ( x ) : [EOL] [docstring] [EOL] return in2pt ( sp2pt ( x ) ) [EOL] [EOL] [EOL] def pt2sp ( x ) : [EOL] [docstring] [EOL] return x * sp_in_pt_f [EOL] [EOL] [EOL] def in2sp ( x ) : [EOL] [docstring] [EOL] return pt2sp ( in2pt ( x ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $fractions.Fraction$ 0 0 0 0 0 0 0 0 0 0 0 0 $fractions.Fraction$ 0 0 0 0 0 0 0 0 0 0 0 0 $fractions.Fraction$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $fractions.Fraction$ 0 0 0 $fractions.Fraction$ 0 $fractions.Fraction$ 0 $fractions.Fraction$ 0 $fractions.Fraction$ 0 $fractions.Fraction$ 0 0 0 $fractions.Fraction$ 0 0 $fractions.Fraction$ 0 0 0 $fractions.Fraction$ 0 $fractions.Fraction$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 $fractions.Fraction$ 0 0 0 $builtins.float$ 0 0 0 $fractions.Fraction$ 0 0 $builtins.float$ 0 0 0 $fractions.Fraction$ 0 0 $builtins.float$ 0 0 0 $fractions.Fraction$ 0 0 $builtins.float$ 0 0 0 $fractions.Fraction$ 0 0 $builtins.float$ 0 0 0 $fractions.Fraction$ 0 0 $builtins.float$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Any [EOL] import typing [EOL] import nex [EOL] [docstring] [EOL] from . . Tools . EnumFactory import EnumFactory [EOL] from . . Tools . FuncTools import repeat_call [EOL] from . . Tools . Stream import FileStream [EOL] from . Tfm import Tfm , TfmChar , TfmKern , TfmLigature , TfmExtensibleChar [EOL] [EOL] NO_TAG , LIG_TAG , LIST_TAG , EXT_TAG = list ( range ( [number] ) ) [EOL] [EOL] KERN_OPCODE = [number] [EOL] [EOL] [comment] [EOL] tables = EnumFactory ( [string] , ( [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , ) ) [EOL] [EOL] [EOL] class TfmParser ( object ) : [EOL] [EOL] [docstring] [EOL] [EOL] @ staticmethod def parse ( font_name , filename ) : [EOL] [docstring] [EOL] [EOL] tfm_parser = TfmParser ( font_name , filename ) [EOL] return tfm_parser ( ) [EOL] [EOL] def __init__ ( self , font_name , filename ) : [EOL] [EOL] self . font_name = font_name [EOL] self . filename = filename [EOL] self . stream = FileStream ( filename ) [EOL] [EOL] self . tfm = None [EOL] self . _read_lengths ( ) [EOL] self . _read_header ( ) [EOL] self . _read_font_parameters ( ) [EOL] self . _read_lig_kern_programs ( ) [EOL] self . _read_characters ( ) [EOL] [EOL] def __call__ ( self ) : [EOL] [EOL] return self . tfm [EOL] [EOL] @ staticmethod def word_ptr ( base , index ) : [EOL] [docstring] [EOL] [EOL] return base + [number] * index [EOL] [EOL] def _seek_to_table ( self , table ) : [EOL] [docstring] [EOL] [EOL] self . stream . seek ( self . table_pointers [ table ] ) [EOL] [EOL] def _position_in_table ( self , table , index ) : [EOL] [docstring] [EOL] [EOL] return self . word_ptr ( self . table_pointers [ table ] , index ) [EOL] [EOL] def _read_fix_word_in_table ( self , table , index ) : [EOL] [docstring] [EOL] [EOL] return self . stream . read_fix_word ( self . _position_in_table ( table , index ) ) [EOL] [EOL] def _read_four_byte_numbers_in_table ( self , table , index ) : [EOL] [docstring] [EOL] [EOL] return self . stream . read_four_byte_numbers ( self . _position_in_table ( table , index ) ) [EOL] [EOL] def _read_extensible_recipe ( self , index ) : [EOL] [docstring] [EOL] [EOL] return self . _read_four_byte_numbers_in_table ( tables . extensible_character , index ) [EOL] [EOL] def _read_lengths ( self ) : [EOL] [docstring] [EOL] [EOL] stream = self . stream [EOL] stream . seek ( [number] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] self . table_lengths = [ None ] * len ( tables ) [EOL] [EOL] ( self . entire_file_length , header_length , self . smallest_character_code , self . largest_character_code ) = repeat_call ( stream . read_unsigned_byte2 , [number] ) [EOL] [EOL] header_data_length_min = [number] [comment] [EOL] self . table_lengths [ tables . header ] = max ( header_data_length_min , header_length ) [EOL] [EOL] self . number_of_chars = self . largest_character_code - self . smallest_character_code + [number] [EOL] self . table_lengths [ tables . character_info ] = self . number_of_chars [EOL] [EOL] [comment] [EOL] for i in range ( tables . width , len ( tables ) ) : [EOL] self . table_lengths [ i ] = stream . read_unsigned_byte2 ( ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] self . table_pointers = [ None ] * len ( tables ) [EOL] [EOL] [comment] [EOL] self . table_pointers [ tables . header ] = [number] [EOL] [EOL] for table in range ( tables . header , tables . font_parameter ) : [EOL] self . table_pointers [ table + [number] ] = self . _position_in_table ( table , self . table_lengths [ table ] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] length = self . _position_in_table ( tables . font_parameter , self . table_lengths [ tables . font_parameter ] ) [EOL] if length != self . word_ptr ( [number] , self . entire_file_length ) : [EOL] raise NameError ( [string] ) [EOL] [EOL] def _read_header ( self ) : [EOL] [docstring] [EOL] [EOL] stream = self . stream [EOL] [EOL] self . _seek_to_table ( tables . header ) [EOL] [EOL] [comment] [EOL] checksum = stream . read_unsigned_byte4 ( ) [EOL] design_font_size = stream . read_fix_word ( ) [EOL] [EOL] [comment] [EOL] character_info_table_position = self . table_pointers [ tables . character_info ] [EOL] position = stream . tell ( ) [EOL] if position < character_info_table_position : [EOL] character_coding_scheme = stream . read_bcpl ( ) [EOL] else : [EOL] character_coding_scheme = None [EOL] [EOL] [comment] [EOL] character_coding_scheme_length = [number] [comment] [EOL] position += character_coding_scheme_length [EOL] if position < character_info_table_position : [EOL] family = stream . read_bcpl ( position ) [EOL] else : [EOL] family = None [EOL] [EOL] [comment] [EOL] family_length = [number] [comment] [EOL] position += family_length [EOL] if position < character_info_table_position : [EOL] seven_bit_safe_flag = stream . read_unsigned_byte1 ( position ) [EOL] stream . read_unsigned_byte2 ( ) [EOL] face = stream . read_unsigned_byte1 ( ) [EOL] [comment] [EOL] [EOL] [comment] [EOL] [EOL] self . tfm = Tfm ( self . font_name , self . filename , self . smallest_character_code , self . largest_character_code , checksum , design_font_size , character_coding_scheme , family ) [EOL] [EOL] def _read_font_parameters ( self ) : [EOL] [docstring] [EOL] [EOL] stream = self . stream [EOL] [EOL] self . _seek_to_table ( tables . font_parameter ) [EOL] [EOL] if self . tfm . character_coding_scheme == [string] : [EOL] [comment] [EOL] pass [EOL] else : [EOL] [comment] [EOL] self . tfm . set_font_parameters ( repeat_call ( stream . read_fix_word , [number] ) ) [EOL] [EOL] if self . tfm . character_coding_scheme == [string] : [EOL] [comment] [EOL] self . tfm . set_math_symbols_parameters ( repeat_call ( stream . read_fix_word , [number] ) ) [EOL] elif self . tfm . character_coding_scheme in ( [string] , [string] , ) : [EOL] [comment] [EOL] self . tfm . set_math_extension_parameters ( repeat_call ( stream . read_fix_word , [number] ) ) [EOL] [EOL] def _read_lig_kern_programs ( self ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] ( first_skip_byte , next_char , op_byte , remainder ) = self . _read_four_byte_numbers_in_table ( tables . lig_kern , [number] ) [EOL] if first_skip_byte == [number] : [EOL] right_boundary_char = next_char [EOL] raise NotImplementedError ( [string] ) [EOL] [EOL] [comment] [EOL] ( last_skip_byte , next_char , op_byte , remainder ) = self . _read_four_byte_numbers_in_table ( tables . lig_kern , self . table_lengths [ tables . lig_kern ] - [number] ) [EOL] if last_skip_byte == [number] : [EOL] left_boundary_char_program_index = [number] * op_byte + remainder [EOL] raise NotImplementedError ( [string] ) [EOL] [EOL] [comment] [EOL] first_instruction = True [EOL] for i in range ( self . table_lengths [ tables . lig_kern ] ) : [EOL] [EOL] ( skip_byte , next_char , op_byte , remainder ) = self . _read_four_byte_numbers_in_table ( tables . lig_kern , i ) [EOL] [EOL] [comment] [EOL] if first_instruction and skip_byte > [number] : [EOL] large_index = [number] * op_byte + remainder [EOL] ( skip_byte , next_char , op_byte , remainder ) = self . _read_four_byte_numbers_in_table ( tables . lig_kern , large_index ) [EOL] [EOL] [comment] [EOL] stop = skip_byte >= [number] [EOL] [EOL] if op_byte >= KERN_OPCODE : [EOL] [comment] [EOL] kern_index = [number] * ( op_byte - KERN_OPCODE ) + remainder [EOL] kern = self . _read_fix_word_in_table ( tables . kern , kern_index ) [EOL] [comment] [EOL] TfmKern ( self . tfm , i , stop , next_char , kern ) [EOL] [comment] [EOL] [EOL] else : [EOL] [comment] [EOL] number_of_chars_to_pass_over = op_byte >> [number] [EOL] current_char_is_deleted = ( op_byte & [number] ) == [number] [EOL] next_char_is_deleted = ( op_byte & [number] ) == [number] [EOL] ligature_char_code = remainder [EOL] [comment] [EOL] TfmLigature ( self . tfm , i , stop , next_char , ligature_char_code , number_of_chars_to_pass_over , current_char_is_deleted , next_char_is_deleted ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] first_instruction = stop == True [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [EOL] def _read_characters ( self ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] for c in range ( self . smallest_character_code , self . largest_character_code + [number] ) : [EOL] self . _process_char ( c ) [EOL] [EOL] def _process_char ( self , c ) : [EOL] [docstring] [EOL] [EOL] width_index , height_index , depth_index , italic_index , tag , remainder = self . _read_char_info ( c ) [EOL] [EOL] [comment] [EOL] if width_index != [number] : [EOL] width = self . _read_fix_word_in_table ( tables . width , width_index ) [EOL] else : [EOL] width = [number] [EOL] [comment] [EOL] [comment] [EOL] [EOL] if height_index != [number] : [EOL] height = self . _read_fix_word_in_table ( tables . height , height_index ) [EOL] else : [EOL] height = [number] [EOL] [EOL] if depth_index != [number] : [EOL] depth = self . _read_fix_word_in_table ( tables . depth , depth_index ) [EOL] else : [EOL] depth = [number] [EOL] [EOL] if italic_index != [number] : [EOL] italic_correction = self . _read_fix_word_in_table ( tables . italic_correction , italic_index ) [EOL] else : [EOL] italic_correction = [number] [EOL] [EOL] [comment] [EOL] lig_kern_program_index = None [EOL] next_larger_char = None [EOL] extensible_recipe = None [EOL] if tag == LIG_TAG : [EOL] lig_kern_program_index = remainder [EOL] elif tag == LIST_TAG : [EOL] next_larger_char = remainder [EOL] elif tag == EXT_TAG : [EOL] extensible_recipe = self . _read_extensible_recipe ( remainder ) [EOL] [EOL] if extensible_recipe is not None : [EOL] [comment] [EOL] TfmExtensibleChar ( self . tfm , c , width , height , depth , italic_correction , extensible_recipe , lig_kern_program_index , next_larger_char ) [EOL] [EOL] else : [EOL] [comment] [EOL] TfmChar ( self . tfm , c , width , height , depth , italic_correction , lig_kern_program_index , next_larger_char ) [EOL] [EOL] def _read_char_info ( self , c ) : [EOL] [docstring] [EOL] [EOL] index = c - self . smallest_character_code [EOL] bytes = self . _read_four_byte_numbers_in_table ( tables . character_info , index ) [EOL] [EOL] width_index = bytes [ [number] ] [EOL] height_index = bytes [ [number] ] >> [number] [EOL] depth_index = bytes [ [number] ] & [number] [EOL] italic_index = bytes [ [number] ] >> [number] [EOL] tag = bytes [ [number] ] & [number] [EOL] remainder = bytes [ [number] ] [EOL] [EOL] return width_index , height_index , depth_index , italic_index , tag , remainder [EOL] [EOL] def _print_summary ( self ) : [EOL] [EOL] string_format = [string] [EOL] [EOL] print ( string_format % ( self . font_name , self . entire_file_length , self . table_lengths [ tables . header ] , self . smallest_character_code , self . largest_character_code , self . table_lengths [ tables . width ] , self . table_lengths [ tables . height ] , self . table_lengths [ tables . depth ] , self . table_lengths [ tables . italic_correction ] , self . table_lengths [ tables . lig_kern ] , self . table_lengths [ tables . kern ] , self . table_lengths [ tables . extensible_character ] , self . table_lengths [ tables . font_parameter ] , ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $nex.pydvi.Font.TfmParser.TfmParser$ 0 0 0 0 0 0 0 0 0 $nex.pydvi.Font.TfmParser.TfmParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $nex.pydvi.Tools.Stream.FileStream$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $nex.pydvi.Tools.Stream.FileStream$ 0 0 0 $nex.pydvi.Tools.Stream.FileStream$ 0 $nex.pydvi.Tools.Stream.FileStream$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $nex.pydvi.Tools.Stream.FileStream$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $nex.pydvi.Tools.Stream.FileStream$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $nex.pydvi.Tools.Stream.FileStream$ 0 0 0 $nex.pydvi.Tools.Stream.FileStream$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $nex.pydvi.Tools.Stream.FileStream$ 0 0 0 0 0 $typing.Any$ 0 $nex.pydvi.Tools.Stream.FileStream$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 $nex.pydvi.Tools.Stream.FileStream$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 $None$ 0 $nex.pydvi.Tools.Stream.FileStream$ 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $typing.Any$ 0 $builtins.int$ 0 0 $typing.Any$ 0 $typing.Any$ 0 0 $None$ 0 $nex.pydvi.Tools.Stream.FileStream$ 0 0 0 $typing.Any$ 0 0 0 0 0 $None$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $typing.Any$ 0 $builtins.int$ 0 0 $typing.Any$ 0 $typing.Any$ 0 0 $typing.Any$ 0 $nex.pydvi.Tools.Stream.FileStream$ 0 0 0 $typing.Any$ 0 0 $nex.pydvi.Tools.Stream.FileStream$ 0 0 0 0 0 $typing.Any$ 0 $nex.pydvi.Tools.Stream.FileStream$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $None$ 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $nex.pydvi.Tools.Stream.FileStream$ 0 0 0 $nex.pydvi.Tools.Stream.FileStream$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $nex.pydvi.Tools.Stream.FileStream$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $nex.pydvi.Tools.Stream.FileStream$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $nex.pydvi.Tools.Stream.FileStream$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $builtins.int$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $typing.Any$ 0 $builtins.int$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $typing.Any$ 0 $builtins.int$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $typing.Any$ 0 $builtins.int$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $typing.Any$ 0 $builtins.int$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.int$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.int$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0
import builtins [EOL] from typing import Any , Type [EOL] import typing [EOL] import nex [EOL] [docstring] [EOL] import string [EOL] [EOL] from . . Tools . Logging import print_card [EOL] [EOL] [EOL] class TfmChar ( object ) : [EOL] [EOL] [docstring] [EOL] [EOL] [comment] [EOL] printable = string . digits + string . ascii_letters + string . punctuation [EOL] [EOL] def __init__ ( self , tfm , char_code , width , height , depth , italic_correction , lig_kern_program_index = None , next_larger_char = None ) : [EOL] [EOL] self . tfm = tfm [EOL] tfm [ char_code ] = self [EOL] [EOL] self . char_code = char_code [EOL] self . width = width [EOL] self . height = height [EOL] self . depth = depth [EOL] self . italic_correction = italic_correction [EOL] [EOL] self . lig_kern_program_index = lig_kern_program_index [EOL] self . next_larger_char = next_larger_char [EOL] [EOL] def scaled_width ( self , scale_factor ) : [EOL] [docstring] [EOL] [EOL] return int ( self . width * scale_factor ) [EOL] [EOL] def scaled_height ( self , scale_factor ) : [EOL] [docstring] [EOL] [EOL] return int ( self . height * scale_factor ) [EOL] [EOL] def scaled_depth ( self , scale_factor ) : [EOL] [docstring] [EOL] [EOL] return int ( self . depth * scale_factor ) [EOL] [EOL] def scaled_dimensions ( self , scale_factor ) : [EOL] [docstring] [EOL] [EOL] return [ int ( x * scale_factor ) for x in ( self . width , self . height , self . depth ) ] [EOL] [EOL] def next_larger_tfm_char ( self ) : [EOL] [docstring] [EOL] [EOL] if self . next_larger_char is not None : [EOL] return self . tfm [ self . next_larger_char ] [EOL] else : [EOL] return None [EOL] [EOL] def get_lig_kern_program ( self ) : [EOL] [docstring] [EOL] [EOL] if self . lig_kern_program_index is not None : [EOL] return self . tfm . get_lig_kern_program ( self . lig_kern_program_index ) [EOL] else : [EOL] return None [EOL] [EOL] def chr ( self ) : [EOL] [docstring] [EOL] [EOL] char = chr ( self . char_code ) [EOL] if char in self . printable : [EOL] return char [EOL] else : [EOL] return self . char_code [EOL] [EOL] def print_summary ( self ) : [EOL] [EOL] string_format = [string] [EOL] [EOL] message = string_format % ( self . char_code , self . chr ( ) , self . width , self . height , self . depth , self . italic_correction , str ( self . lig_kern_program_index ) , str ( self . next_larger_char ) , ) [EOL] [EOL] first_lig_kern = self . get_lig_kern_program ( ) [EOL] if first_lig_kern is not None : [EOL] for lig_kern in first_lig_kern : [EOL] message += [string] + str ( lig_kern ) [EOL] [EOL] print_card ( message ) [EOL] [EOL] [EOL] class TfmExtensibleChar ( TfmChar ) : [EOL] [EOL] [docstring] [EOL] [EOL] def __init__ ( self , tfm , char_code , width , height , depth , italic_correction , extensible_recipe , lig_kern_program_index = None , next_larger_char = None ) : [EOL] [EOL] super ( TfmExtensibleChar , self ) . __init__ ( tfm , char_code , width , height , depth , italic_correction , lig_kern_program_index , next_larger_char ) [EOL] [EOL] self . top , self . mid , self . bot , self . rep = extensible_recipe [EOL] [EOL] [EOL] class TfmLigKern ( object ) : [EOL] [EOL] [docstring] [EOL] [EOL] def __init__ ( self , tfm , index , stop , next_char ) : [EOL] [EOL] self . tfm = tfm [EOL] self . stop = stop [EOL] self . index = index [EOL] self . next_char = next_char [EOL] [EOL] self . tfm . add_lig_kern ( self ) [EOL] [EOL] def __iter__ ( self ) : [EOL] [docstring] [EOL] [EOL] i = self . index [EOL] while True : [EOL] lig_kern = self . tfm . get_lig_kern_program ( i ) [EOL] yield lig_kern [EOL] if lig_kern . stop : [EOL] break [EOL] else : [EOL] i += [number] [EOL] [EOL] [EOL] class TfmKern ( TfmLigKern ) : [EOL] [EOL] [docstring] [EOL] [EOL] def __init__ ( self , tfm , index , stop , next_char , kern ) : [EOL] [EOL] super ( TfmKern , self ) . __init__ ( tfm , index , stop , next_char ) [EOL] [EOL] self . kern = kern [EOL] [EOL] def __str__ ( self ) : [EOL] [EOL] return [string] % ( self . next_char , self . tfm [ self . next_char ] . chr ( ) , self . kern , ) [EOL] [EOL] [EOL] class TfmLigature ( TfmLigKern ) : [EOL] [EOL] [docstring] [EOL] [EOL] def __init__ ( self , tfm , index , stop , next_char , ligature_char_code , number_of_chars_to_pass_over , current_char_is_deleted , next_char_is_deleted ) : [EOL] [EOL] super ( TfmLigature , self ) . __init__ ( tfm , index , stop , next_char ) [EOL] [EOL] self . ligature_char_code = ligature_char_code [EOL] self . number_of_chars_to_pass_over = number_of_chars_to_pass_over [EOL] self . current_char_is_deleted = current_char_is_deleted [EOL] self . next_char_is_deleted = next_char_is_deleted [EOL] [EOL] def __str__ ( self ) : [EOL] [EOL] return [string] % ( self . next_char , self . tfm [ self . next_char ] . chr ( ) , self . ligature_char_code , ) [EOL] [EOL] [EOL] class Tfm ( object ) : [EOL] [EOL] [docstring] [EOL] [EOL] def __init__ ( self , font_name , filename , smallest_character_code , largest_character_code , checksum , design_font_size , character_coding_scheme , family ) : [EOL] [EOL] self . font_name = font_name [EOL] self . filename = filename [EOL] self . smallest_character_code = smallest_character_code [EOL] self . largest_character_code = largest_character_code [EOL] self . checksum = checksum [EOL] self . design_font_size = design_font_size [EOL] self . character_coding_scheme = character_coding_scheme [EOL] self . family = family [EOL] [EOL] self . _lig_kerns = [ ] [EOL] self . _chars = { } [EOL] [EOL] def __setitem__ ( self , char_code , value ) : [EOL] [docstring] [EOL] [EOL] self . _chars [ char_code ] = value [EOL] [EOL] def __getitem__ ( self , char_code ) : [EOL] [docstring] [EOL] [EOL] return self . _chars [ char_code ] [EOL] [EOL] def __len__ ( self ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] [EOL] return len ( self . _chars ) [EOL] [EOL] def set_font_parameters ( self , parameters ) : [EOL] [docstring] [EOL] [EOL] ( self . slant , self . spacing , self . space_stretch , self . space_shrink , self . x_height , self . quad , self . extra_space ) = parameters [EOL] [EOL] def set_math_symbols_parameters ( self , parameters ) : [EOL] [docstring] [EOL] [EOL] ( self . num1 , self . num2 , self . num3 , self . denom1 , self . denom2 , self . sup1 , self . sup2 , self . sup3 , self . sub1 , self . sub2 , self . supdrop , self . subdrop , self . delim1 , self . delim2 , self . axis_height ) = parameters [EOL] [EOL] def set_math_extension_parameters ( self , parameters ) : [EOL] [docstring] [EOL] [EOL] self . default_rule_thickness = parameters [ [number] ] [EOL] self . big_op_spacing = parameters [ [number] : ] [EOL] [EOL] def add_lig_kern ( self , obj ) : [EOL] [docstring] [EOL] [EOL] self . _lig_kerns . append ( obj ) [EOL] [EOL] def get_lig_kern_program ( self , i ) : [EOL] [docstring] [EOL] [EOL] return self . _lig_kerns [ i ] [EOL] [EOL] def print_summary ( self ) : [EOL] [EOL] string_format = [string] [EOL] [EOL] message = string_format % ( self . font_name , self . smallest_character_code , self . largest_character_code , self . checksum , self . design_font_size , self . character_coding_scheme , self . family , self . slant , self . spacing , self . space_stretch , self . space_shrink , self . x_height , self . quad , self . extra_space , ) [EOL] [EOL] print_card ( message ) [EOL] for char in list ( self . _chars . values ( ) ) : [EOL] char . print_summary ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Optional , Literal , Union [EOL] import typing [EOL] import typing_extensions [EOL] def remove_enclosing_new_line ( text ) : [EOL] [docstring] [EOL] [EOL] i_min = [number] if text [ [number] ] == [string] else [number] [EOL] i_max = - [number] if text [ - [number] ] == [string] else None [EOL] [EOL] return text [ i_min : i_max ] [EOL] [EOL] [EOL] def format_card ( text , centered = False , width = [number] , rule_char = [string] , newline = False , border = False , bottom_rule = True ) : [EOL] [docstring] [EOL] [EOL] formated_text = [string] [EOL] [EOL] rule_line = rule_char * width [EOL] [EOL] if border : [EOL] border_string = rule_char + [string] [EOL] else : [EOL] border_string = [string] [EOL] [EOL] def format_lines ( text ) : [EOL] [EOL] formated_text = [string] [EOL] for line in text . split ( [string] ) : [EOL] formated_text += format_line ( line ) + [string] [EOL] [EOL] return formated_text [EOL] [EOL] def format_line ( text ) : [EOL] [EOL] line = border_string [EOL] if centered : [EOL] line += text . center ( width ) [EOL] else : [EOL] line += text [EOL] [EOL] return line [EOL] [EOL] if newline : [EOL] formated_text += [string] [EOL] [EOL] formated_text += rule_line + [string] + border_string + [string] [EOL] [EOL] if isinstance ( text , list ) : [EOL] for item in text : [EOL] formated_text += format_lines ( item ) [EOL] else : [EOL] formated_text += format_lines ( text ) [EOL] [EOL] formated_text += border_string + [string] [EOL] [EOL] if bottom_rule : [EOL] formated_text += rule_line [EOL] [EOL] return formated_text [EOL] [EOL] [EOL] def print_card ( text , ** kwargs ) : [EOL] [docstring] [EOL] print ( format_card ( text , ** kwargs ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , Any [EOL] import typing [EOL] [docstring] [EOL] [EOL] [EOL] class ReadOnlyMetaClass ( type ) : [EOL] [EOL] [docstring] [EOL] [EOL] def __setattr__ ( self , name , value ) : [EOL] [EOL] raise NotImplementedError [EOL] [EOL] [EOL] class EnumMetaClass ( ReadOnlyMetaClass ) : [EOL] [EOL] [docstring] [EOL] [EOL] def __len__ ( self ) : [EOL] [EOL] return self . _size [EOL] [EOL] [EOL] def EnumFactory ( cls_name , constant_names ) : [EOL] [docstring] [EOL] [EOL] dict_ = { } [EOL] dict_ [ [string] ] = len ( constant_names ) [EOL] for index , name in enumerate ( constant_names ) : [EOL] dict_ [ str ( name ) ] = index [EOL] [EOL] return EnumMetaClass ( cls_name , ( ) , dict_ ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Any , Type [EOL] import typing [EOL] import nex [EOL] import mmap [EOL] import mmap [EOL] import os [EOL] [EOL] [EOL] FIX_WORD_SCALE = [number] ** - [number] [EOL] [EOL] [EOL] def to_fix_word ( x ) : [EOL] [docstring] [EOL] [EOL] return FIX_WORD_SCALE * x [EOL] [EOL] [EOL] class AbstractStream ( object ) : [EOL] [EOL] [docstring] [EOL] [EOL] def read ( self , number_of_bytes ) : [EOL] [docstring] [EOL] [EOL] raise NotImplementedError [EOL] [EOL] def seek ( self , postion , whence ) : [EOL] [docstring] [EOL] [EOL] raise NotImplementedError [EOL] [EOL] def tell ( self ) : [EOL] [docstring] [EOL] [EOL] raise NotImplementedError [EOL] [EOL] def read_bytes ( self , number_of_bytes , position = None ) : [EOL] [docstring] [EOL] [EOL] if position is not None : [EOL] self . seek ( position ) [EOL] [EOL] return self . read ( number_of_bytes ) [EOL] [EOL] def read_byte_numbers ( self , number_of_bytes , position = None ) : [EOL] [docstring] [EOL] [EOL] return list ( self . read_bytes ( number_of_bytes , position ) ) [EOL] [EOL] def read_three_byte_numbers ( self , position = None ) : [EOL] [docstring] [EOL] [EOL] return self . read_byte_numbers ( [number] , position ) [EOL] [EOL] def read_four_byte_numbers ( self , position = None ) : [EOL] [docstring] [EOL] [EOL] return self . read_byte_numbers ( [number] , position ) [EOL] [EOL] def read_big_endian_number ( self , number_of_bytes , signed = False , position = None ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] [EOL] bytes = self . read_byte_numbers ( number_of_bytes , position ) [EOL] [EOL] number = bytes [ [number] ] [EOL] if signed and number >= [number] : [EOL] number -= [number] [EOL] for i in range ( [number] , number_of_bytes ) : [EOL] number *= [number] [EOL] number += bytes [ i ] [EOL] [EOL] return number [EOL] [EOL] [comment] [EOL] [EOL] def read_signed_byte1 ( self , position = None ) : [EOL] [docstring] [EOL] return self . read_big_endian_number ( number_of_bytes = [number] , signed = True , position = position ) [EOL] [EOL] def read_signed_byte2 ( self , position = None ) : [EOL] [docstring] [EOL] return self . read_big_endian_number ( number_of_bytes = [number] , signed = True , position = position ) [EOL] [EOL] def read_signed_byte3 ( self , position = None ) : [EOL] [docstring] [EOL] return self . read_big_endian_number ( number_of_bytes = [number] , signed = True , position = position ) [EOL] [EOL] def read_signed_byte4 ( self , position = None ) : [EOL] [docstring] [EOL] return self . read_big_endian_number ( number_of_bytes = [number] , signed = True , position = position ) [EOL] [EOL] def read_unsigned_byte1 ( self , position = None ) : [EOL] [docstring] [EOL] return self . read_big_endian_number ( number_of_bytes = [number] , signed = False , position = position ) [EOL] [EOL] def read_unsigned_byte2 ( self , position = None ) : [EOL] [docstring] [EOL] return self . read_big_endian_number ( number_of_bytes = [number] , signed = False , position = position ) [EOL] [EOL] def read_unsigned_byte3 ( self , position = None ) : [EOL] [docstring] [EOL] return self . read_big_endian_number ( number_of_bytes = [number] , signed = False , position = position ) [EOL] [EOL] def read_unsigned_byte4 ( self , position = None ) : [EOL] [docstring] [EOL] return self . read_big_endian_number ( number_of_bytes = [number] , signed = False , position = position ) [EOL] [EOL] read_unsigned_byten = ( read_unsigned_byte1 , read_unsigned_byte2 , read_unsigned_byte3 , read_unsigned_byte4 ) [EOL] [docstring] [EOL] [EOL] read_signed_byten = ( read_signed_byte1 , read_signed_byte2 , read_signed_byte3 , read_signed_byte4 ) [EOL] [docstring] [EOL] [EOL] def read_fix_word ( self , position = None ) : [EOL] [docstring] [EOL] return to_fix_word ( self . read_signed_byte4 ( position ) ) [EOL] [EOL] def read_bcpl ( self , position = None ) : [EOL] [docstring] [EOL] return self . read_bytes ( self . read_unsigned_byte1 ( position ) ) . decode ( [string] ) [EOL] [EOL] [EOL] class StandardStream ( AbstractStream ) : [EOL] [EOL] [docstring] [EOL] [EOL] def read ( self , number_of_bytes ) : [EOL] [docstring] [EOL] [EOL] return bytearray ( self . stream . read ( number_of_bytes ) ) [EOL] [EOL] def seek ( self , postion , whence = os . SEEK_SET ) : [EOL] [docstring] [EOL] [EOL] self . stream . seek ( postion , whence ) [EOL] [EOL] def tell ( self ) : [EOL] [docstring] [EOL] [EOL] return self . stream . tell ( ) [EOL] [EOL] [EOL] class FileStream ( StandardStream ) : [EOL] [EOL] def __init__ ( self , filename ) : [EOL] [EOL] self . file = open ( filename , [string] ) [EOL] self . stream = mmap . mmap ( self . file . fileno ( ) , length = [number] , access = mmap . ACCESS_READ ) [EOL] self . seek ( [number] ) [EOL] [EOL] def __del__ ( self ) : [EOL] [EOL] self . stream . close ( ) [EOL] self . file . close ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $mmap.mmap$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
def repeat_call ( func , count ) : [EOL] [docstring] [EOL] return [ func ( ) for i in range ( count ) ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Any , Literal , Tuple [EOL] import typing [EOL] import nex [EOL] import typing_extensions [EOL] from . . constants . instructions import ( Instructions , message_instructions , hyphenation_instructions , register_instructions , h_add_glue_instructions , v_add_glue_instructions , short_hand_def_instructions , def_instructions , if_instructions ) [EOL] from . . utils import enums_to_values [EOL] [EOL] base_terminal_instructions = ( Instructions . relax , Instructions . begin_group , Instructions . end_group , Instructions . show_token , Instructions . show_box , Instructions . show_lists , Instructions . the , Instructions . show_the , Instructions . ship_out , Instructions . ignore_spaces , Instructions . after_assignment , Instructions . after_group , Instructions . open_input , Instructions . close_input , Instructions . open_output , Instructions . close_output , Instructions . write , Instructions . special , Instructions . add_penalty , Instructions . un_penalty , Instructions . un_kern , Instructions . un_glue , Instructions . mark , Instructions . insert , Instructions . v_adjust , Instructions . leaders , Instructions . centered_leaders , Instructions . expanded_leaders , Instructions . space , Instructions . indent , Instructions . no_indent , Instructions . par , Instructions . left_brace , Instructions . end , Instructions . dump , Instructions . control_space , Instructions . italic_correction , Instructions . discretionary , Instructions . discretionary_hyphen , Instructions . math_shift , Instructions . box_dimen_height , Instructions . box_dimen_width , Instructions . box_dimen_depth , Instructions . less_than , Instructions . greater_than , Instructions . equals , Instructions . plus_sign , Instructions . minus_sign , Instructions . zero , Instructions . one , Instructions . two , Instructions . three , Instructions . four , Instructions . five , Instructions . six , Instructions . seven , Instructions . eight , Instructions . nine , Instructions . single_quote , Instructions . double_quote , Instructions . backtick , Instructions . point , Instructions . comma , Instructions . a , Instructions . b , Instructions . c , Instructions . d , Instructions . e , Instructions . f , Instructions . misc_char_cat_pair , Instructions . integer_parameter , Instructions . dimen_parameter , Instructions . glue_parameter , Instructions . mu_glue_parameter , Instructions . token_parameter , Instructions . special_integer , Instructions . special_dimen , Instructions . char_def_token , Instructions . math_char_def_token , Instructions . count_def_token , Instructions . dimen_def_token , Instructions . skip_def_token , Instructions . mu_skip_def_token , Instructions . toks_def_token , Instructions . unexpanded_control_symbol , Instructions . accent , Instructions . cat_code , Instructions . math_code , Instructions . upper_case_code , Instructions . lower_case_code , Instructions . space_factor_code , Instructions . delimiter_code , Instructions . let , Instructions . advance , Instructions . immediate , Instructions . font , Instructions . skew_char , Instructions . hyphen_char , Instructions . font_dimen , Instructions . text_font , Instructions . script_font , Instructions . script_script_font , Instructions . global_mod , Instructions . long_mod , Instructions . outer_mod , Instructions . set_box , Instructions . box , Instructions . copy , Instructions . un_h_box , Instructions . un_h_copy , Instructions . un_v_box , Instructions . un_v_copy , Instructions . move_left , Instructions . move_right , Instructions . raise_box , Instructions . lower_box , Instructions . v_align , Instructions . h_align , Instructions . alignment_material , Instructions . last_penalty , Instructions . last_kern , Instructions . last_glue , Instructions . last_box , Instructions . v_split , Instructions . kern , Instructions . math_kern , Instructions . v_rule , Instructions . h_rule , Instructions . char , Instructions . right_brace , Instructions . font_def_token , Instructions . arbitrary_token , Instructions . parameter_text , Instructions . balanced_text_and_right_brace , Instructions . horizontal_mode_material_and_right_brace , Instructions . vertical_mode_material_and_right_brace , Instructions . h_box , Instructions . v_box , Instructions . v_top , Instructions . active_character , Instructions . unexpanded_control_word , Instructions . non_active_uncased_a , Instructions . non_active_uncased_b , Instructions . non_active_uncased_c , Instructions . non_active_uncased_d , Instructions . non_active_uncased_e , Instructions . non_active_uncased_f , Instructions . non_active_uncased_g , Instructions . non_active_uncased_h , Instructions . non_active_uncased_i , Instructions . non_active_uncased_j , Instructions . non_active_uncased_k , Instructions . non_active_uncased_l , Instructions . non_active_uncased_m , Instructions . non_active_uncased_n , Instructions . non_active_uncased_o , Instructions . non_active_uncased_p , Instructions . non_active_uncased_q , Instructions . non_active_uncased_r , Instructions . non_active_uncased_s , Instructions . non_active_uncased_t , Instructions . non_active_uncased_u , Instructions . non_active_uncased_v , Instructions . non_active_uncased_w , Instructions . non_active_uncased_x , Instructions . non_active_uncased_y , Instructions . non_active_uncased_z , ) [EOL] terminal_instructions = ( base_terminal_instructions + register_instructions + message_instructions + hyphenation_instructions + h_add_glue_instructions + v_add_glue_instructions + short_hand_def_instructions + def_instructions + if_instructions ) [EOL] terminal_types = enums_to_values ( terminal_instructions ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing_extensions.Literal[nex.constants.instructions.Instructions.relax],typing_extensions.Literal[nex.constants.instructions.Instructions.begin_group],typing_extensions.Literal[nex.constants.instructions.Instructions.end_group],typing_extensions.Literal[nex.constants.instructions.Instructions.show_token],typing_extensions.Literal[nex.constants.instructions.Instructions.show_box],typing_extensions.Literal[nex.constants.instructions.Instructions.show_lists],typing_extensions.Literal[nex.constants.instructions.Instructions.the],typing_extensions.Literal[nex.constants.instructions.Instructions.show_the],typing_extensions.Literal[nex.constants.instructions.Instructions.ship_out],typing_extensions.Literal[nex.constants.instructions.Instructions.ignore_spaces],typing_extensions.Literal[nex.constants.instructions.Instructions.after_assignment],typing_extensions.Literal[nex.constants.instructions.Instructions.after_group],typing_extensions.Literal[nex.constants.instructions.Instructions.open_input],typing_extensions.Literal[nex.constants.instructions.Instructions.close_input],typing_extensions.Literal[nex.constants.instructions.Instructions.open_output],typing_extensions.Literal[nex.constants.instructions.Instructions.close_output],typing_extensions.Literal[nex.constants.instructions.Instructions.write],typing_extensions.Literal[nex.constants.instructions.Instructions.special],typing_extensions.Literal[nex.constants.instructions.Instructions.add_penalty],typing_extensions.Literal[nex.constants.instructions.Instructions.un_penalty],typing_extensions.Literal[nex.constants.instructions.Instructions.un_kern],typing_extensions.Literal[nex.constants.instructions.Instructions.un_glue],typing_extensions.Literal[nex.constants.instructions.Instructions.mark],typing_extensions.Literal[nex.constants.instructions.Instructions.insert],typing_extensions.Literal[nex.constants.instructions.Instructions.v_adjust],typing_extensions.Literal[nex.constants.instructions.Instructions.leaders],typing_extensions.Literal[nex.constants.instructions.Instructions.centered_leaders],typing_extensions.Literal[nex.constants.instructions.Instructions.expanded_leaders],typing_extensions.Literal[nex.constants.instructions.Instructions.space],typing_extensions.Literal[nex.constants.instructions.Instructions.indent],typing_extensions.Literal[nex.constants.instructions.Instructions.no_indent],typing_extensions.Literal[nex.constants.instructions.Instructions.par],typing_extensions.Literal[nex.constants.instructions.Instructions.left_brace],typing_extensions.Literal[nex.constants.instructions.Instructions.end],typing_extensions.Literal[nex.constants.instructions.Instructions.dump],typing_extensions.Literal[nex.constants.instructions.Instructions.control_space],typing_extensions.Literal[nex.constants.instructions.Instructions.italic_correction],typing_extensions.Literal[nex.constants.instructions.Instructions.discretionary],typing_extensions.Literal[nex.constants.instructions.Instructions.discretionary_hyphen],typing_extensions.Literal[nex.constants.instructions.Instructions.math_shift],typing_extensions.Literal[nex.constants.instructions.Instructions.box_dimen_height],typing_extensions.Literal[nex.constants.instructions.Instructions.box_dimen_width],typing_extensions.Literal[nex.constants.instructions.Instructions.box_dimen_depth],typing_extensions.Literal[nex.constants.instructions.Instructions.less_than],typing_extensions.Literal[nex.constants.instructions.Instructions.greater_than],typing_extensions.Literal[nex.constants.instructions.Instructions.equals],typing_extensions.Literal[nex.constants.instructions.Instructions.plus_sign],typing_extensions.Literal[nex.constants.instructions.Instructions.minus_sign],typing_extensions.Literal[nex.constants.instructions.Instructions.zero],typing_extensions.Literal[nex.constants.instructions.Instructions.one],typing_extensions.Literal[nex.constants.instructions.Instructions.two],typing_extensions.Literal[nex.constants.instructions.Instructions.three],typing_extensions.Literal[nex.constants.instructions.Instructions.four],typing_extensions.Literal[nex.constants.instructions.Instructions.five],typing_extensions.Literal[nex.constants.instructions.Instructions.six],typing_extensions.Literal[nex.constants.instructions.Instructions.seven],typing_extensions.Literal[nex.constants.instructions.Instructions.eight],typing_extensions.Literal[nex.constants.instructions.Instructions.nine],typing_extensions.Literal[nex.constants.instructions.Instructions.single_quote],typing_extensions.Literal[nex.constants.instructions.Instructions.double_quote],typing_extensions.Literal[nex.constants.instructions.Instructions.backtick],typing_extensions.Literal[nex.constants.instructions.Instructions.point],typing_extensions.Literal[nex.constants.instructions.Instructions.comma],typing_extensions.Literal[nex.constants.instructions.Instructions.a],typing_extensions.Literal[nex.constants.instructions.Instructions.b],typing_extensions.Literal[nex.constants.instructions.Instructions.c],typing_extensions.Literal[nex.constants.instructions.Instructions.d],typing_extensions.Literal[nex.constants.instructions.Instructions.e],typing_extensions.Literal[nex.constants.instructions.Instructions.f],typing_extensions.Literal[nex.constants.instructions.Instructions.misc_char_cat_pair],typing_extensions.Literal[nex.constants.instructions.Instructions.integer_parameter],typing_extensions.Literal[nex.constants.instructions.Instructions.dimen_parameter],typing_extensions.Literal[nex.constants.instructions.Instructions.glue_parameter],typing_extensions.Literal[nex.constants.instructions.Instructions.mu_glue_parameter],typing_extensions.Literal[nex.constants.instructions.Instructions.token_parameter],typing_extensions.Literal[nex.constants.instructions.Instructions.special_integer],typing_extensions.Literal[nex.constants.instructions.Instructions.special_dimen],typing_extensions.Literal[nex.constants.instructions.Instructions.char_def_token],typing_extensions.Literal[nex.constants.instructions.Instructions.math_char_def_token],typing_extensions.Literal[nex.constants.instructions.Instructions.count_def_token],typing_extensions.Literal[nex.constants.instructions.Instructions.dimen_def_token],typing_extensions.Literal[nex.constants.instructions.Instructions.skip_def_token],typing_extensions.Literal[nex.constants.instructions.Instructions.mu_skip_def_token],typing_extensions.Literal[nex.constants.instructions.Instructions.toks_def_token],typing_extensions.Literal[nex.constants.instructions.Instructions.unexpanded_control_symbol],typing_extensions.Literal[nex.constants.instructions.Instructions.accent],typing_extensions.Literal[nex.constants.instructions.Instructions.cat_code],typing_extensions.Literal[nex.constants.instructions.Instructions.math_code],typing_extensions.Literal[nex.constants.instructions.Instructions.upper_case_code],typing_extensions.Literal[nex.constants.instructions.Instructions.lower_case_code],typing_extensions.Literal[nex.constants.instructions.Instructions.space_factor_code],typing_extensions.Literal[nex.constants.instructions.Instructions.delimiter_code],typing_extensions.Literal[nex.constants.instructions.Instructions.let],typing_extensions.Literal[nex.constants.instructions.Instructions.advance],typing_extensions.Literal[nex.constants.instructions.Instructions.immediate],typing_extensions.Literal[nex.constants.instructions.Instructions.font],typing_extensions.Literal[nex.constants.instructions.Instructions.skew_char],typing_extensions.Literal[nex.constants.instructions.Instructions.hyphen_char],typing_extensions.Literal[nex.constants.instructions.Instructions.font_dimen],typing_extensions.Literal[nex.constants.instructions.Instructions.text_font],typing_extensions.Literal[nex.constants.instructions.Instructions.script_font],typing_extensions.Literal[nex.constants.instructions.Instructions.script_script_font],typing_extensions.Literal[nex.constants.instructions.Instructions.global_mod],typing_extensions.Literal[nex.constants.instructions.Instructions.long_mod],typing_extensions.Literal[nex.constants.instructions.Instructions.outer_mod],typing_extensions.Literal[nex.constants.instructions.Instructions.set_box],typing_extensions.Literal[nex.constants.instructions.Instructions.box],typing_extensions.Literal[nex.constants.instructions.Instructions.copy],typing_extensions.Literal[nex.constants.instructions.Instructions.un_h_box],typing_extensions.Literal[nex.constants.instructions.Instructions.un_h_copy],typing_extensions.Literal[nex.constants.instructions.Instructions.un_v_box],typing_extensions.Literal[nex.constants.instructions.Instructions.un_v_copy],typing_extensions.Literal[nex.constants.instructions.Instructions.move_left],typing_extensions.Literal[nex.constants.instructions.Instructions.move_right],typing_extensions.Literal[nex.constants.instructions.Instructions.raise_box],typing_extensions.Literal[nex.constants.instructions.Instructions.lower_box],typing_extensions.Literal[nex.constants.instructions.Instructions.v_align],typing_extensions.Literal[nex.constants.instructions.Instructions.h_align],typing_extensions.Literal[nex.constants.instructions.Instructions.alignment_material],typing_extensions.Literal[nex.constants.instructions.Instructions.last_penalty],typing_extensions.Literal[nex.constants.instructions.Instructions.last_kern],typing_extensions.Literal[nex.constants.instructions.Instructions.last_glue],typing_extensions.Literal[nex.constants.instructions.Instructions.last_box],typing_extensions.Literal[nex.constants.instructions.Instructions.v_split],typing_extensions.Literal[nex.constants.instructions.Instructions.kern],typing_extensions.Literal[nex.constants.instructions.Instructions.math_kern],typing_extensions.Literal[nex.constants.instructions.Instructions.v_rule],typing_extensions.Literal[nex.constants.instructions.Instructions.h_rule],typing_extensions.Literal[nex.constants.instructions.Instructions.char],typing_extensions.Literal[nex.constants.instructions.Instructions.right_brace],typing_extensions.Literal[nex.constants.instructions.Instructions.font_def_token],typing_extensions.Literal[nex.constants.instructions.Instructions.arbitrary_token],typing_extensions.Literal[nex.constants.instructions.Instructions.parameter_text],typing_extensions.Literal[nex.constants.instructions.Instructions.balanced_text_and_right_brace],typing_extensions.Literal[nex.constants.instructions.Instructions.horizontal_mode_material_and_right_brace],typing_extensions.Literal[nex.constants.instructions.Instructions.vertical_mode_material_and_right_brace],typing_extensions.Literal[nex.constants.instructions.Instructions.h_box],typing_extensions.Literal[nex.constants.instructions.Instructions.v_box],typing_extensions.Literal[nex.constants.instructions.Instructions.v_top],typing_extensions.Literal[nex.constants.instructions.Instructions.active_character],typing_extensions.Literal[nex.constants.instructions.Instructions.unexpanded_control_word],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_a],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_b],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_c],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_d],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_e],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_f],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_g],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_h],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_i],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_j],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_k],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_l],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_m],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_n],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_o],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_p],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_q],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_r],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_s],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_t],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_u],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_v],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_w],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_x],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_y],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_z]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[nex.constants.instructions.Instructions,...]$ 0 0 $typing.Tuple[typing_extensions.Literal[nex.constants.instructions.Instructions.relax],typing_extensions.Literal[nex.constants.instructions.Instructions.begin_group],typing_extensions.Literal[nex.constants.instructions.Instructions.end_group],typing_extensions.Literal[nex.constants.instructions.Instructions.show_token],typing_extensions.Literal[nex.constants.instructions.Instructions.show_box],typing_extensions.Literal[nex.constants.instructions.Instructions.show_lists],typing_extensions.Literal[nex.constants.instructions.Instructions.the],typing_extensions.Literal[nex.constants.instructions.Instructions.show_the],typing_extensions.Literal[nex.constants.instructions.Instructions.ship_out],typing_extensions.Literal[nex.constants.instructions.Instructions.ignore_spaces],typing_extensions.Literal[nex.constants.instructions.Instructions.after_assignment],typing_extensions.Literal[nex.constants.instructions.Instructions.after_group],typing_extensions.Literal[nex.constants.instructions.Instructions.open_input],typing_extensions.Literal[nex.constants.instructions.Instructions.close_input],typing_extensions.Literal[nex.constants.instructions.Instructions.open_output],typing_extensions.Literal[nex.constants.instructions.Instructions.close_output],typing_extensions.Literal[nex.constants.instructions.Instructions.write],typing_extensions.Literal[nex.constants.instructions.Instructions.special],typing_extensions.Literal[nex.constants.instructions.Instructions.add_penalty],typing_extensions.Literal[nex.constants.instructions.Instructions.un_penalty],typing_extensions.Literal[nex.constants.instructions.Instructions.un_kern],typing_extensions.Literal[nex.constants.instructions.Instructions.un_glue],typing_extensions.Literal[nex.constants.instructions.Instructions.mark],typing_extensions.Literal[nex.constants.instructions.Instructions.insert],typing_extensions.Literal[nex.constants.instructions.Instructions.v_adjust],typing_extensions.Literal[nex.constants.instructions.Instructions.leaders],typing_extensions.Literal[nex.constants.instructions.Instructions.centered_leaders],typing_extensions.Literal[nex.constants.instructions.Instructions.expanded_leaders],typing_extensions.Literal[nex.constants.instructions.Instructions.space],typing_extensions.Literal[nex.constants.instructions.Instructions.indent],typing_extensions.Literal[nex.constants.instructions.Instructions.no_indent],typing_extensions.Literal[nex.constants.instructions.Instructions.par],typing_extensions.Literal[nex.constants.instructions.Instructions.left_brace],typing_extensions.Literal[nex.constants.instructions.Instructions.end],typing_extensions.Literal[nex.constants.instructions.Instructions.dump],typing_extensions.Literal[nex.constants.instructions.Instructions.control_space],typing_extensions.Literal[nex.constants.instructions.Instructions.italic_correction],typing_extensions.Literal[nex.constants.instructions.Instructions.discretionary],typing_extensions.Literal[nex.constants.instructions.Instructions.discretionary_hyphen],typing_extensions.Literal[nex.constants.instructions.Instructions.math_shift],typing_extensions.Literal[nex.constants.instructions.Instructions.box_dimen_height],typing_extensions.Literal[nex.constants.instructions.Instructions.box_dimen_width],typing_extensions.Literal[nex.constants.instructions.Instructions.box_dimen_depth],typing_extensions.Literal[nex.constants.instructions.Instructions.less_than],typing_extensions.Literal[nex.constants.instructions.Instructions.greater_than],typing_extensions.Literal[nex.constants.instructions.Instructions.equals],typing_extensions.Literal[nex.constants.instructions.Instructions.plus_sign],typing_extensions.Literal[nex.constants.instructions.Instructions.minus_sign],typing_extensions.Literal[nex.constants.instructions.Instructions.zero],typing_extensions.Literal[nex.constants.instructions.Instructions.one],typing_extensions.Literal[nex.constants.instructions.Instructions.two],typing_extensions.Literal[nex.constants.instructions.Instructions.three],typing_extensions.Literal[nex.constants.instructions.Instructions.four],typing_extensions.Literal[nex.constants.instructions.Instructions.five],typing_extensions.Literal[nex.constants.instructions.Instructions.six],typing_extensions.Literal[nex.constants.instructions.Instructions.seven],typing_extensions.Literal[nex.constants.instructions.Instructions.eight],typing_extensions.Literal[nex.constants.instructions.Instructions.nine],typing_extensions.Literal[nex.constants.instructions.Instructions.single_quote],typing_extensions.Literal[nex.constants.instructions.Instructions.double_quote],typing_extensions.Literal[nex.constants.instructions.Instructions.backtick],typing_extensions.Literal[nex.constants.instructions.Instructions.point],typing_extensions.Literal[nex.constants.instructions.Instructions.comma],typing_extensions.Literal[nex.constants.instructions.Instructions.a],typing_extensions.Literal[nex.constants.instructions.Instructions.b],typing_extensions.Literal[nex.constants.instructions.Instructions.c],typing_extensions.Literal[nex.constants.instructions.Instructions.d],typing_extensions.Literal[nex.constants.instructions.Instructions.e],typing_extensions.Literal[nex.constants.instructions.Instructions.f],typing_extensions.Literal[nex.constants.instructions.Instructions.misc_char_cat_pair],typing_extensions.Literal[nex.constants.instructions.Instructions.integer_parameter],typing_extensions.Literal[nex.constants.instructions.Instructions.dimen_parameter],typing_extensions.Literal[nex.constants.instructions.Instructions.glue_parameter],typing_extensions.Literal[nex.constants.instructions.Instructions.mu_glue_parameter],typing_extensions.Literal[nex.constants.instructions.Instructions.token_parameter],typing_extensions.Literal[nex.constants.instructions.Instructions.special_integer],typing_extensions.Literal[nex.constants.instructions.Instructions.special_dimen],typing_extensions.Literal[nex.constants.instructions.Instructions.char_def_token],typing_extensions.Literal[nex.constants.instructions.Instructions.math_char_def_token],typing_extensions.Literal[nex.constants.instructions.Instructions.count_def_token],typing_extensions.Literal[nex.constants.instructions.Instructions.dimen_def_token],typing_extensions.Literal[nex.constants.instructions.Instructions.skip_def_token],typing_extensions.Literal[nex.constants.instructions.Instructions.mu_skip_def_token],typing_extensions.Literal[nex.constants.instructions.Instructions.toks_def_token],typing_extensions.Literal[nex.constants.instructions.Instructions.unexpanded_control_symbol],typing_extensions.Literal[nex.constants.instructions.Instructions.accent],typing_extensions.Literal[nex.constants.instructions.Instructions.cat_code],typing_extensions.Literal[nex.constants.instructions.Instructions.math_code],typing_extensions.Literal[nex.constants.instructions.Instructions.upper_case_code],typing_extensions.Literal[nex.constants.instructions.Instructions.lower_case_code],typing_extensions.Literal[nex.constants.instructions.Instructions.space_factor_code],typing_extensions.Literal[nex.constants.instructions.Instructions.delimiter_code],typing_extensions.Literal[nex.constants.instructions.Instructions.let],typing_extensions.Literal[nex.constants.instructions.Instructions.advance],typing_extensions.Literal[nex.constants.instructions.Instructions.immediate],typing_extensions.Literal[nex.constants.instructions.Instructions.font],typing_extensions.Literal[nex.constants.instructions.Instructions.skew_char],typing_extensions.Literal[nex.constants.instructions.Instructions.hyphen_char],typing_extensions.Literal[nex.constants.instructions.Instructions.font_dimen],typing_extensions.Literal[nex.constants.instructions.Instructions.text_font],typing_extensions.Literal[nex.constants.instructions.Instructions.script_font],typing_extensions.Literal[nex.constants.instructions.Instructions.script_script_font],typing_extensions.Literal[nex.constants.instructions.Instructions.global_mod],typing_extensions.Literal[nex.constants.instructions.Instructions.long_mod],typing_extensions.Literal[nex.constants.instructions.Instructions.outer_mod],typing_extensions.Literal[nex.constants.instructions.Instructions.set_box],typing_extensions.Literal[nex.constants.instructions.Instructions.box],typing_extensions.Literal[nex.constants.instructions.Instructions.copy],typing_extensions.Literal[nex.constants.instructions.Instructions.un_h_box],typing_extensions.Literal[nex.constants.instructions.Instructions.un_h_copy],typing_extensions.Literal[nex.constants.instructions.Instructions.un_v_box],typing_extensions.Literal[nex.constants.instructions.Instructions.un_v_copy],typing_extensions.Literal[nex.constants.instructions.Instructions.move_left],typing_extensions.Literal[nex.constants.instructions.Instructions.move_right],typing_extensions.Literal[nex.constants.instructions.Instructions.raise_box],typing_extensions.Literal[nex.constants.instructions.Instructions.lower_box],typing_extensions.Literal[nex.constants.instructions.Instructions.v_align],typing_extensions.Literal[nex.constants.instructions.Instructions.h_align],typing_extensions.Literal[nex.constants.instructions.Instructions.alignment_material],typing_extensions.Literal[nex.constants.instructions.Instructions.last_penalty],typing_extensions.Literal[nex.constants.instructions.Instructions.last_kern],typing_extensions.Literal[nex.constants.instructions.Instructions.last_glue],typing_extensions.Literal[nex.constants.instructions.Instructions.last_box],typing_extensions.Literal[nex.constants.instructions.Instructions.v_split],typing_extensions.Literal[nex.constants.instructions.Instructions.kern],typing_extensions.Literal[nex.constants.instructions.Instructions.math_kern],typing_extensions.Literal[nex.constants.instructions.Instructions.v_rule],typing_extensions.Literal[nex.constants.instructions.Instructions.h_rule],typing_extensions.Literal[nex.constants.instructions.Instructions.char],typing_extensions.Literal[nex.constants.instructions.Instructions.right_brace],typing_extensions.Literal[nex.constants.instructions.Instructions.font_def_token],typing_extensions.Literal[nex.constants.instructions.Instructions.arbitrary_token],typing_extensions.Literal[nex.constants.instructions.Instructions.parameter_text],typing_extensions.Literal[nex.constants.instructions.Instructions.balanced_text_and_right_brace],typing_extensions.Literal[nex.constants.instructions.Instructions.horizontal_mode_material_and_right_brace],typing_extensions.Literal[nex.constants.instructions.Instructions.vertical_mode_material_and_right_brace],typing_extensions.Literal[nex.constants.instructions.Instructions.h_box],typing_extensions.Literal[nex.constants.instructions.Instructions.v_box],typing_extensions.Literal[nex.constants.instructions.Instructions.v_top],typing_extensions.Literal[nex.constants.instructions.Instructions.active_character],typing_extensions.Literal[nex.constants.instructions.Instructions.unexpanded_control_word],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_a],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_b],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_c],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_d],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_e],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_f],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_g],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_h],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_i],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_j],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_k],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_l],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_m],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_n],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_o],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_p],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_q],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_r],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_s],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_t],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_u],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_v],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_w],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_x],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_y],typing_extensions.Literal[nex.constants.instructions.Instructions.non_active_uncased_z]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Tuple[nex.constants.instructions.Instructions,...]$ 0 0
from typing import Dict , Tuple [EOL] import typing [EOL] import instructions [EOL] import builtins [EOL] [docstring] [EOL] from typing import Dict , Tuple [EOL] [EOL] from enum import Enum [EOL] [EOL] from . instructions import Instructions [EOL] from . . utils import enums_to_values [EOL] [EOL] [EOL] class Specials ( Enum ) : [EOL] space_factor = [string] [EOL] [comment] [EOL] [comment] [EOL] prev_graf = [string] [EOL] [comment] [EOL] dead_cycles = [string] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] insert_penalties = [string] [EOL] [EOL] [comment] [EOL] prev_depth = [string] [EOL] [comment] [EOL] page_depth = [string] [EOL] [comment] [EOL] page_goal = [string] [EOL] [comment] [EOL] page_total = [string] [EOL] [comment] [EOL] page_stretch = [string] [EOL] [comment] [EOL] page_fil_stretch = [string] [EOL] [comment] [EOL] page_fill_stretch = [string] [EOL] [comment] [EOL] page_filll_stretch = [string] [EOL] [comment] [EOL] page_shrink = [string] [EOL] [EOL] [EOL] special_to_instr = { Specials . space_factor : Instructions . special_integer , Specials . prev_graf : Instructions . special_integer , Specials . dead_cycles : Instructions . special_integer , Specials . insert_penalties : Instructions . special_integer , Specials . prev_depth : Instructions . special_dimen , Specials . page_depth : Instructions . special_dimen , Specials . page_goal : Instructions . special_dimen , Specials . page_total : Instructions . special_dimen , Specials . page_stretch : Instructions . special_dimen , Specials . page_fil_stretch : Instructions . special_dimen , Specials . page_fill_stretch : Instructions . special_dimen , Specials . page_filll_stretch : Instructions . special_dimen , Specials . page_shrink : Instructions . special_dimen , } [EOL] [EOL] special_to_type = { s : instr . value for s , instr in special_to_instr . items ( ) } [EOL] [EOL] special_instrs = ( Instructions . special_integer , Instructions . special_dimen , ) [EOL] [EOL] special_instr_types = enums_to_values ( special_instrs ) [EOL] [EOL] [EOL] def is_special_type ( type_ ) : [EOL] return type_ in special_instr_types [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.Dict[Specials,instructions.Instructions]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[Specials,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[Specials,instructions.Instructions]$ 0 0 0 0 0 0 0 $typing.Tuple[instructions.Instructions,...]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.str,...]$ 0 0 0 $typing.Tuple[instructions.Instructions,...]$ 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.str,...]$ 0
from typing import Literal , Tuple [EOL] import typing [EOL] import nex [EOL] import typing_extensions [EOL] [docstring] [EOL] from enum import Enum [EOL] [EOL] [EOL] class Instructions ( Enum ) : [EOL] [comment] [EOL] relax = [string] [EOL] right_brace = [string] [EOL] begin_group = [string] [EOL] end_group = [string] [EOL] show_token = [string] [EOL] show_box = [string] [EOL] show_lists = [string] [EOL] show_the = [string] [EOL] ship_out = [string] [EOL] ignore_spaces = [string] [EOL] after_assignment = [string] [EOL] after_group = [string] [EOL] upper_case = [string] [EOL] lower_case = [string] [EOL] message = [string] [EOL] error_message = [string] [EOL] immediate = [string] [EOL] open_input = [string] [EOL] close_input = [string] [EOL] open_output = [string] [EOL] close_output = [string] [EOL] [comment] [EOL] [comment] [EOL] read = [string] [EOL] write = [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] special = [string] [EOL] add_penalty = [string] [EOL] kern = [string] [EOL] math_kern = [string] [EOL] un_penalty = [string] [EOL] un_kern = [string] [EOL] un_glue = [string] [EOL] mark = [string] [EOL] insert = [string] [EOL] v_adjust = [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] leaders = [string] [EOL] centered_leaders = [string] [EOL] expanded_leaders = [string] [EOL] space = [string] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] box = [string] [EOL] [comment] [EOL] copy = [string] [EOL] [comment] [EOL] last_box = [string] [EOL] last_glue = [string] [EOL] last_kern = [string] [EOL] last_penalty = [string] [EOL] [comment] [EOL] [comment] [EOL] v_split = [string] [EOL] [comment] [EOL] h_box = [string] [EOL] v_box = [string] [EOL] [comment] [EOL] [comment] [EOL] v_top = [string] [EOL] [comment] [EOL] indent = [string] [EOL] no_indent = [string] [EOL] par = [string] [EOL] left_brace = [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] v_skip = [string] [EOL] v_fil = [string] [EOL] v_fill = [string] [EOL] v_stretch_or_shrink = [string] [EOL] v_fil_neg = [string] [EOL] [comment] [EOL] move_left = [string] [EOL] move_right = [string] [EOL] un_v_box = [string] [EOL] un_v_copy = [string] [EOL] h_rule = [string] [EOL] h_align = [string] [EOL] end = [string] [EOL] dump = [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] h_skip = [string] [EOL] h_fil = [string] [EOL] h_fill = [string] [EOL] h_stretch_or_shrink = [string] [EOL] h_fil_neg = [string] [EOL] [comment] [EOL] control_space = [string] [EOL] raise_box = [string] [EOL] lower_box = [string] [EOL] un_h_box = [string] [EOL] un_h_copy = [string] [EOL] v_rule = [string] [EOL] v_align = [string] [EOL] char = [string] [EOL] accent = [string] [EOL] italic_correction = [string] [EOL] discretionary = [string] [EOL] discretionary_hyphen = [string] [EOL] math_shift = [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] set_box = [string] [EOL] count = [string] [EOL] dimen = [string] [EOL] skip = [string] [EOL] mu_skip = [string] [EOL] toks = [string] [EOL] [comment] [EOL] char_def_token = [string] [EOL] math_char_def_token = [string] [EOL] count_def_token = [string] [EOL] dimen_def_token = [string] [EOL] skip_def_token = [string] [EOL] mu_skip_def_token = [string] [EOL] toks_def_token = [string] [EOL] [comment] [EOL] font_def_token = [string] [EOL] [comment] [EOL] box_dimen_height = [string] [EOL] box_dimen_width = [string] [EOL] box_dimen_depth = [string] [EOL] [comment] [EOL] integer_parameter = [string] [EOL] dimen_parameter = [string] [EOL] glue_parameter = [string] [EOL] mu_glue_parameter = [string] [EOL] token_parameter = [string] [EOL] [comment] [EOL] special_integer = [string] [EOL] special_dimen = [string] [EOL] [comment] [EOL] advance = [string] [EOL] multiply = [string] [EOL] divide = [string] [EOL] [comment] [EOL] cat_code = [string] [EOL] math_code = [string] [EOL] upper_case_code = [string] [EOL] lower_case_code = [string] [EOL] space_factor_code = [string] [EOL] delimiter_code = [string] [EOL] [comment] [EOL] let = [string] [EOL] future_let = [string] [EOL] [comment] [EOL] text_font = [string] [EOL] script_font = [string] [EOL] script_script_font = [string] [EOL] [comment] [EOL] par_shape = [string] [EOL] [comment] [EOL] font_dimen = [string] [EOL] hyphen_char = [string] [EOL] skew_char = [string] [EOL] [comment] [EOL] hyphenation = [string] [EOL] patterns = [string] [EOL] [comment] [EOL] error_stop_mode = [string] [EOL] scroll_mode = [string] [EOL] non_stop_mode = [string] [EOL] batch_mode = [string] [EOL] [comment] [EOL] def_ = [string] [EOL] g_def = [string] [EOL] e_def = [string] [EOL] x_def = [string] [EOL] [comment] [EOL] [comment] [EOL] char_def = [string] [EOL] math_char_def = [string] [EOL] [comment] [EOL] count_def = [string] [EOL] dimen_def = [string] [EOL] skip_def = [string] [EOL] mu_skip_def = [string] [EOL] toks_def = [string] [EOL] [comment] [EOL] global_mod = [string] [EOL] long_mod = [string] [EOL] outer_mod = [string] [EOL] [comment] [EOL] font = [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] if_num = [string] [EOL] [comment] [EOL] [comment] [EOL] if_dimen = [string] [EOL] if_odd = [string] [EOL] if_v_mode = [string] [EOL] if_h_mode = [string] [EOL] if_m_mode = [string] [EOL] if_inner_mode = [string] [EOL] if_char = [string] [EOL] if_cat = [string] [EOL] if_token = [string] [EOL] if_void = [string] [EOL] if_h_box = [string] [EOL] if_v_box = [string] [EOL] if_end_of_file = [string] [EOL] if_true = [string] [EOL] if_false = [string] [EOL] if_case = [string] [EOL] [comment] [EOL] [comment] [EOL] else_ = [string] [EOL] end_if = [string] [EOL] or_ = [string] [EOL] [EOL] [comment] [EOL] number = [string] [EOL] roman_numeral = [string] [EOL] string = [string] [EOL] job_name = [string] [EOL] font_name = [string] [EOL] meaning = [string] [EOL] cs_name = [string] [EOL] end_cs_name = [string] [EOL] expand_after = [string] [EOL] no_expand = [string] [EOL] top_mark = [string] [EOL] first_mark = [string] [EOL] bottom_mark = [string] [EOL] split_first_mark = [string] [EOL] split_bottom_mark = [string] [EOL] input = [string] [EOL] end_input = [string] [EOL] the = [string] [EOL] [EOL] cr = [string] [EOL] undefined = [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] less_than = [string] [EOL] greater_than = [string] [EOL] equals = [string] [EOL] plus_sign = [string] [EOL] minus_sign = [string] [EOL] single_quote = [string] [EOL] double_quote = [string] [EOL] backtick = [string] [EOL] point = [string] [EOL] comma = [string] [EOL] [comment] [EOL] zero = [string] [EOL] one = [string] [EOL] two = [string] [EOL] three = [string] [EOL] four = [string] [EOL] five = [string] [EOL] six = [string] [EOL] seven = [string] [EOL] eight = [string] [EOL] nine = [string] [EOL] [comment] [EOL] a = [string] [EOL] b = [string] [EOL] c = [string] [EOL] d = [string] [EOL] e = [string] [EOL] f = [string] [EOL] [comment] [EOL] non_active_uncased_a = [string] [EOL] non_active_uncased_b = [string] [EOL] non_active_uncased_c = [string] [EOL] non_active_uncased_d = [string] [EOL] non_active_uncased_e = [string] [EOL] non_active_uncased_f = [string] [EOL] non_active_uncased_g = [string] [EOL] non_active_uncased_h = [string] [EOL] non_active_uncased_i = [string] [EOL] non_active_uncased_j = [string] [EOL] non_active_uncased_k = [string] [EOL] non_active_uncased_l = [string] [EOL] non_active_uncased_m = [string] [EOL] non_active_uncased_n = [string] [EOL] non_active_uncased_o = [string] [EOL] non_active_uncased_p = [string] [EOL] non_active_uncased_q = [string] [EOL] non_active_uncased_r = [string] [EOL] non_active_uncased_s = [string] [EOL] non_active_uncased_t = [string] [EOL] non_active_uncased_u = [string] [EOL] non_active_uncased_v = [string] [EOL] non_active_uncased_w = [string] [EOL] non_active_uncased_x = [string] [EOL] non_active_uncased_y = [string] [EOL] non_active_uncased_z = [string] [EOL] [comment] [EOL] active_character = [string] [EOL] parameter = [string] [EOL] align_tab = [string] [EOL] superscript = [string] [EOL] subscript = [string] [EOL] [EOL] [comment] [EOL] macro = [string] [EOL] arbitrary_token = [string] [EOL] [comment] [EOL] unexpanded_control_symbol = [string] [EOL] unexpanded_control_word = [string] [EOL] [comment] [EOL] delimited_param = [string] [EOL] undelimited_param = [string] [EOL] param_number = [string] [EOL] parameter_text = [string] [EOL] balanced_text_and_right_brace = [string] [EOL] horizontal_mode_material_and_right_brace = [string] [EOL] vertical_mode_material_and_right_brace = [string] [EOL] alignment_material = [string] [EOL] misc_char_cat_pair = [string] [EOL] [EOL] [EOL] unexpanded_cs_instructions = ( Instructions . unexpanded_control_symbol , Instructions . unexpanded_control_word , ) [EOL] [EOL] message_instructions = ( Instructions . message , Instructions . error_message , ) [EOL] [EOL] hyphenation_instructions = ( Instructions . hyphenation , Instructions . patterns , ) [EOL] [EOL] h_add_glue_instructions = ( Instructions . h_skip , Instructions . h_fil , Instructions . h_fill , Instructions . h_stretch_or_shrink , Instructions . h_fil_neg , ) [EOL] [EOL] [EOL] v_add_glue_instructions = ( Instructions . v_skip , Instructions . v_fil , Instructions . v_fill , Instructions . v_stretch_or_shrink , Instructions . v_fil_neg , ) [EOL] [EOL] explicit_box_instructions = ( Instructions . h_box , Instructions . v_box , Instructions . v_top , ) [EOL] [EOL] register_instructions = ( Instructions . count , Instructions . dimen , Instructions . skip , Instructions . mu_skip , Instructions . toks , ) [EOL] [EOL] short_hand_def_instructions = ( Instructions . char_def , Instructions . math_char_def , Instructions . count_def , Instructions . dimen_def , Instructions . skip_def , Instructions . mu_skip_def , Instructions . toks_def , ) [EOL] [EOL] def_instructions = ( Instructions . def_ , Instructions . g_def , Instructions . e_def , Instructions . x_def , ) [EOL] [EOL] if_instructions = ( Instructions . if_num , Instructions . if_dimen , Instructions . if_odd , Instructions . if_v_mode , Instructions . if_h_mode , Instructions . if_m_mode , Instructions . if_inner_mode , Instructions . if_char , Instructions . if_cat , Instructions . if_token , Instructions . if_void , Instructions . if_h_box , Instructions . if_v_box , Instructions . if_end_of_file , Instructions . if_true , Instructions . if_false , Instructions . if_case , ) [EOL] [EOL] mark_instructions = ( Instructions . top_mark , Instructions . first_mark , Instructions . bottom_mark , Instructions . split_first_mark , Instructions . split_bottom_mark , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.Tuple[typing_extensions.Literal[nex.constants.instructions.Instructions.unexpanded_control_symbol],typing_extensions.Literal[nex.constants.instructions.Instructions.unexpanded_control_word]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing_extensions.Literal[nex.constants.instructions.Instructions.message],typing_extensions.Literal[nex.constants.instructions.Instructions.error_message]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing_extensions.Literal[nex.constants.instructions.Instructions.hyphenation],typing_extensions.Literal[nex.constants.instructions.Instructions.patterns]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing_extensions.Literal[nex.constants.instructions.Instructions.h_skip],typing_extensions.Literal[nex.constants.instructions.Instructions.h_fil],typing_extensions.Literal[nex.constants.instructions.Instructions.h_fill],typing_extensions.Literal[nex.constants.instructions.Instructions.h_stretch_or_shrink],typing_extensions.Literal[nex.constants.instructions.Instructions.h_fil_neg]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing_extensions.Literal[nex.constants.instructions.Instructions.v_skip],typing_extensions.Literal[nex.constants.instructions.Instructions.v_fil],typing_extensions.Literal[nex.constants.instructions.Instructions.v_fill],typing_extensions.Literal[nex.constants.instructions.Instructions.v_stretch_or_shrink],typing_extensions.Literal[nex.constants.instructions.Instructions.v_fil_neg]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing_extensions.Literal[nex.constants.instructions.Instructions.h_box],typing_extensions.Literal[nex.constants.instructions.Instructions.v_box],typing_extensions.Literal[nex.constants.instructions.Instructions.v_top]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing_extensions.Literal[nex.constants.instructions.Instructions.count],typing_extensions.Literal[nex.constants.instructions.Instructions.dimen],typing_extensions.Literal[nex.constants.instructions.Instructions.skip],typing_extensions.Literal[nex.constants.instructions.Instructions.mu_skip],typing_extensions.Literal[nex.constants.instructions.Instructions.toks]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing_extensions.Literal[nex.constants.instructions.Instructions.char_def],typing_extensions.Literal[nex.constants.instructions.Instructions.math_char_def],typing_extensions.Literal[nex.constants.instructions.Instructions.count_def],typing_extensions.Literal[nex.constants.instructions.Instructions.dimen_def],typing_extensions.Literal[nex.constants.instructions.Instructions.skip_def],typing_extensions.Literal[nex.constants.instructions.Instructions.mu_skip_def],typing_extensions.Literal[nex.constants.instructions.Instructions.toks_def]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing_extensions.Literal[nex.constants.instructions.Instructions.def_],typing_extensions.Literal[nex.constants.instructions.Instructions.g_def],typing_extensions.Literal[nex.constants.instructions.Instructions.e_def],typing_extensions.Literal[nex.constants.instructions.Instructions.x_def]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing_extensions.Literal[nex.constants.instructions.Instructions.if_num],typing_extensions.Literal[nex.constants.instructions.Instructions.if_dimen],typing_extensions.Literal[nex.constants.instructions.Instructions.if_odd],typing_extensions.Literal[nex.constants.instructions.Instructions.if_v_mode],typing_extensions.Literal[nex.constants.instructions.Instructions.if_h_mode],typing_extensions.Literal[nex.constants.instructions.Instructions.if_m_mode],typing_extensions.Literal[nex.constants.instructions.Instructions.if_inner_mode],typing_extensions.Literal[nex.constants.instructions.Instructions.if_char],typing_extensions.Literal[nex.constants.instructions.Instructions.if_cat],typing_extensions.Literal[nex.constants.instructions.Instructions.if_token],typing_extensions.Literal[nex.constants.instructions.Instructions.if_void],typing_extensions.Literal[nex.constants.instructions.Instructions.if_h_box],typing_extensions.Literal[nex.constants.instructions.Instructions.if_v_box],typing_extensions.Literal[nex.constants.instructions.Instructions.if_end_of_file],typing_extensions.Literal[nex.constants.instructions.Instructions.if_true],typing_extensions.Literal[nex.constants.instructions.Instructions.if_false],typing_extensions.Literal[nex.constants.instructions.Instructions.if_case]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing_extensions.Literal[nex.constants.instructions.Instructions.top_mark],typing_extensions.Literal[nex.constants.instructions.Instructions.first_mark],typing_extensions.Literal[nex.constants.instructions.Instructions.bottom_mark],typing_extensions.Literal[nex.constants.instructions.Instructions.split_first_mark],typing_extensions.Literal[nex.constants.instructions.Instructions.split_bottom_mark]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[docstring] [EOL] from enum import Enum [EOL] [EOL] [EOL] class Commands ( Enum ) : [EOL] assign = [string] [EOL] relax = [string] [EOL] left_brace = [string] [EOL] right_brace = [string] [EOL] begin_group = [string] [EOL] end_group = [string] [EOL] show_token = [string] [EOL] show_box = [string] [EOL] show_lists = [string] [EOL] show_the = [string] [EOL] ship_out = [string] [EOL] ignore_spaces = [string] [EOL] set_after_assignment_token = [string] [EOL] add_to_after_group_tokens = [string] [EOL] message = [string] [EOL] error_message = [string] [EOL] open_input = [string] [EOL] close_input = [string] [EOL] open_output = [string] [EOL] close_output = [string] [EOL] write = [string] [EOL] do_special = [string] [EOL] add_penalty = [string] [EOL] add_kern = [string] [EOL] add_math_kern = [string] [EOL] un_penalty = [string] [EOL] un_kern = [string] [EOL] un_glue = [string] [EOL] mark = [string] [EOL] insert = [string] [EOL] vertical_adjust = [string] [EOL] add_leaders = [string] [EOL] add_space = [string] [EOL] add_box = [string] [EOL] unpack_horizontal_box = [string] [EOL] unpack_vertical_box = [string] [EOL] indent = [string] [EOL] no_indent = [string] [EOL] par = [string] [EOL] add_horizontal_glue = [string] [EOL] add_vertical_glue = [string] [EOL] move_box_left = [string] [EOL] move_box_right = [string] [EOL] raise_box = [string] [EOL] lower_box = [string] [EOL] add_horizontal_rule = [string] [EOL] add_vertical_rule = [string] [EOL] horizontal_align = [string] [EOL] vertical_align = [string] [EOL] end = [string] [EOL] dump = [string] [EOL] add_control_space = [string] [EOL] add_character_explicit = [string] [EOL] add_character_code = [string] [EOL] add_character_token = [string] [EOL] add_accent = [string] [EOL] add_italic_correction = [string] [EOL] add_discretionary = [string] [EOL] add_discretionary_hyphen = [string] [EOL] do_math_shift = [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0
from typing import Dict , Tuple , Iterable [EOL] import typing [EOL] import instructions [EOL] import builtins [EOL] [docstring] [EOL] from typing import Dict , Tuple , Iterable [EOL] [EOL] from enum import Enum [EOL] [EOL] from . instructions import Instructions [EOL] from . . utils import enums_to_values [EOL] [EOL] [EOL] class Parameters ( Enum ) : [EOL] pre_tolerance = [string] [EOL] tolerance = [string] [EOL] h_badness = [string] [EOL] v_badness = [string] [EOL] line_penalty = [string] [EOL] hyphen_penalty = [string] [EOL] ex_hyphen_penalty = [string] [EOL] bin_op_penalty = [string] [EOL] rel_penalty = [string] [EOL] club_penalty = [string] [EOL] widow_penalty = [string] [EOL] display_widow_penalty = [string] [EOL] broken_penalty = [string] [EOL] pre_display_penalty = [string] [EOL] post_display_penalty = [string] [EOL] inter_line_penalty = [string] [EOL] floating_penalty = [string] [EOL] output_penalty = [string] [EOL] double_hyphen_demerits = [string] [EOL] final_hyphen_demerits = [string] [EOL] adj_demerits = [string] [EOL] looseness = [string] [EOL] pausing = [string] [EOL] holding_inserts = [string] [EOL] tracing_on_line = [string] [EOL] tracing_macros = [string] [EOL] tracing_stats = [string] [EOL] tracing_paragraphs = [string] [EOL] tracing_pages = [string] [EOL] tracing_output = [string] [EOL] tracing_lostchars = [string] [EOL] tracing_commands = [string] [EOL] tracing_restores = [string] [EOL] language = [string] [EOL] uc_hyph = [string] [EOL] left_hyphen_min = [string] [EOL] right_hyphen_min = [string] [EOL] global_defs = [string] [EOL] max_dead_cycles = [string] [EOL] hang_after = [string] [EOL] fam = [string] [EOL] mag = [string] [EOL] escape_char = [string] [EOL] default_hyphen_char = [string] [EOL] default_skew_char = [string] [EOL] end_line_char = [string] [EOL] new_line_char = [string] [EOL] delimiter_factor = [string] [EOL] [comment] [EOL] time = [string] [EOL] day = [string] [EOL] month = [string] [EOL] year = [string] [EOL] show_box_breadth = [string] [EOL] show_box_depth = [string] [EOL] error_context_lines = [string] [EOL] h_fuzz = [string] [EOL] v_fuzz = [string] [EOL] over_full_rule = [string] [EOL] h_size = [string] [EOL] v_size = [string] [EOL] max_depth = [string] [EOL] split_max_depth = [string] [EOL] box_max_depth = [string] [EOL] line_skip_limit = [string] [EOL] delimiter_short_fall = [string] [EOL] null_delimiter_space = [string] [EOL] script_space = [string] [EOL] math_surround = [string] [EOL] pre_display_size = [string] [EOL] display_width = [string] [EOL] display_indent = [string] [EOL] par_indent = [string] [EOL] hang_indent = [string] [EOL] h_offset = [string] [EOL] v_offset = [string] [EOL] base_line_skip = [string] [EOL] line_skip = [string] [EOL] par_skip = [string] [EOL] above_display_skip = [string] [EOL] above_display_short_skip = [string] [EOL] below_display_skip = [string] [EOL] below_display_short_skip = [string] [EOL] left_skip = [string] [EOL] right_skip = [string] [EOL] top_skip = [string] [EOL] split_top_skip = [string] [EOL] tab_skip = [string] [EOL] space_skip = [string] [EOL] x_space_skip = [string] [EOL] par_fill_skip = [string] [EOL] thin_mu_skip = [string] [EOL] med_mu_skip = [string] [EOL] thick_mu_skip = [string] [EOL] output = [string] [EOL] every_par = [string] [EOL] every_math = [string] [EOL] every_display = [string] [EOL] every_h_box = [string] [EOL] every_v_box = [string] [EOL] every_job = [string] [EOL] every_cr = [string] [EOL] err_help = [string] [EOL] [EOL] [EOL] param_to_instr = { Parameters . pre_tolerance : Instructions . integer_parameter , Parameters . tolerance : Instructions . integer_parameter , Parameters . h_badness : Instructions . integer_parameter , Parameters . v_badness : Instructions . integer_parameter , Parameters . line_penalty : Instructions . integer_parameter , Parameters . hyphen_penalty : Instructions . integer_parameter , Parameters . ex_hyphen_penalty : Instructions . integer_parameter , Parameters . bin_op_penalty : Instructions . integer_parameter , Parameters . rel_penalty : Instructions . integer_parameter , Parameters . club_penalty : Instructions . integer_parameter , Parameters . widow_penalty : Instructions . integer_parameter , Parameters . display_widow_penalty : Instructions . integer_parameter , Parameters . broken_penalty : Instructions . integer_parameter , Parameters . pre_display_penalty : Instructions . integer_parameter , Parameters . post_display_penalty : Instructions . integer_parameter , Parameters . inter_line_penalty : Instructions . integer_parameter , Parameters . floating_penalty : Instructions . integer_parameter , Parameters . output_penalty : Instructions . integer_parameter , Parameters . double_hyphen_demerits : Instructions . integer_parameter , Parameters . final_hyphen_demerits : Instructions . integer_parameter , Parameters . adj_demerits : Instructions . integer_parameter , Parameters . looseness : Instructions . integer_parameter , Parameters . pausing : Instructions . integer_parameter , Parameters . holding_inserts : Instructions . integer_parameter , Parameters . tracing_on_line : Instructions . integer_parameter , Parameters . tracing_macros : Instructions . integer_parameter , Parameters . tracing_stats : Instructions . integer_parameter , Parameters . tracing_paragraphs : Instructions . integer_parameter , Parameters . tracing_pages : Instructions . integer_parameter , Parameters . tracing_output : Instructions . integer_parameter , Parameters . tracing_lostchars : Instructions . integer_parameter , Parameters . tracing_commands : Instructions . integer_parameter , Parameters . tracing_restores : Instructions . integer_parameter , Parameters . language : Instructions . integer_parameter , Parameters . uc_hyph : Instructions . integer_parameter , Parameters . left_hyphen_min : Instructions . integer_parameter , Parameters . right_hyphen_min : Instructions . integer_parameter , Parameters . global_defs : Instructions . integer_parameter , Parameters . max_dead_cycles : Instructions . integer_parameter , Parameters . hang_after : Instructions . integer_parameter , Parameters . fam : Instructions . integer_parameter , Parameters . mag : Instructions . integer_parameter , Parameters . escape_char : Instructions . integer_parameter , Parameters . default_hyphen_char : Instructions . integer_parameter , Parameters . default_skew_char : Instructions . integer_parameter , Parameters . end_line_char : Instructions . integer_parameter , Parameters . new_line_char : Instructions . integer_parameter , Parameters . delimiter_factor : Instructions . integer_parameter , Parameters . time : Instructions . integer_parameter , Parameters . day : Instructions . integer_parameter , Parameters . month : Instructions . integer_parameter , Parameters . year : Instructions . integer_parameter , Parameters . show_box_breadth : Instructions . integer_parameter , Parameters . show_box_depth : Instructions . integer_parameter , Parameters . error_context_lines : Instructions . integer_parameter , Parameters . h_fuzz : Instructions . dimen_parameter , Parameters . v_fuzz : Instructions . dimen_parameter , Parameters . over_full_rule : Instructions . dimen_parameter , Parameters . h_size : Instructions . dimen_parameter , Parameters . v_size : Instructions . dimen_parameter , Parameters . max_depth : Instructions . dimen_parameter , Parameters . split_max_depth : Instructions . dimen_parameter , Parameters . box_max_depth : Instructions . dimen_parameter , Parameters . line_skip_limit : Instructions . dimen_parameter , Parameters . delimiter_short_fall : Instructions . dimen_parameter , Parameters . null_delimiter_space : Instructions . dimen_parameter , Parameters . script_space : Instructions . dimen_parameter , Parameters . math_surround : Instructions . dimen_parameter , Parameters . pre_display_size : Instructions . dimen_parameter , Parameters . display_width : Instructions . dimen_parameter , Parameters . display_indent : Instructions . dimen_parameter , Parameters . par_indent : Instructions . dimen_parameter , Parameters . hang_indent : Instructions . dimen_parameter , Parameters . h_offset : Instructions . dimen_parameter , Parameters . v_offset : Instructions . dimen_parameter , Parameters . base_line_skip : Instructions . glue_parameter , Parameters . line_skip : Instructions . glue_parameter , Parameters . par_skip : Instructions . glue_parameter , Parameters . above_display_skip : Instructions . glue_parameter , Parameters . above_display_short_skip : Instructions . glue_parameter , Parameters . below_display_skip : Instructions . glue_parameter , Parameters . below_display_short_skip : Instructions . glue_parameter , Parameters . left_skip : Instructions . glue_parameter , Parameters . right_skip : Instructions . glue_parameter , Parameters . top_skip : Instructions . glue_parameter , Parameters . split_top_skip : Instructions . glue_parameter , Parameters . tab_skip : Instructions . glue_parameter , Parameters . space_skip : Instructions . glue_parameter , Parameters . x_space_skip : Instructions . glue_parameter , Parameters . par_fill_skip : Instructions . glue_parameter , Parameters . thin_mu_skip : Instructions . mu_glue_parameter , Parameters . med_mu_skip : Instructions . mu_glue_parameter , Parameters . thick_mu_skip : Instructions . mu_glue_parameter , Parameters . output : Instructions . token_parameter , Parameters . every_par : Instructions . token_parameter , Parameters . every_math : Instructions . token_parameter , Parameters . every_display : Instructions . token_parameter , Parameters . every_h_box : Instructions . token_parameter , Parameters . every_v_box : Instructions . token_parameter , Parameters . every_job : Instructions . token_parameter , Parameters . every_cr : Instructions . token_parameter , Parameters . err_help : Instructions . token_parameter , } [EOL] [EOL] param_to_type = { p : instr . value for p , instr in param_to_instr . items ( ) } [EOL] [EOL] param_instrs = ( Instructions . integer_parameter , Instructions . dimen_parameter , Instructions . glue_parameter , Instructions . mu_glue_parameter , Instructions . token_parameter , ) [EOL] [EOL] parameter_instr_types = enums_to_values ( param_instrs ) [EOL] [EOL] [EOL] def param_instr_subset ( instr ) : [EOL] return ( p for p in Parameters if param_to_instr [ p ] == instr ) [EOL] [EOL] [EOL] def is_parameter_instr ( instr ) : [EOL] return instr in param_instrs [EOL] [EOL] [EOL] def is_parameter_type ( type_ ) : [EOL] return type_ in parameter_instr_types [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.Dict[Parameters,instructions.Instructions]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[Parameters,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[Parameters,instructions.Instructions]$ 0 0 0 0 0 0 0 $typing.Tuple[instructions.Instructions,...]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.str,...]$ 0 0 0 $typing.Tuple[instructions.Instructions,...]$ 0 0 0 0 0 $typing.Iterable[Parameters]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[Parameters,instructions.Instructions]$ 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 $typing.Tuple[instructions.Instructions,...]$ 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.str,...]$ 0
from typing import Dict [EOL] import typing [EOL] import builtins [EOL] [docstring] [EOL] from typing import Dict [EOL] [EOL] from enum import Enum [EOL] [EOL] [EOL] class Unit ( Enum ) : [EOL] point = [string] [EOL] pica = [string] [EOL] inch = [string] [EOL] big_point = [string] [EOL] centimetre = [string] [EOL] millimetre = [string] [EOL] didot_point = [string] [EOL] cicero = [string] [EOL] scaled_point = [string] [EOL] fil = [string] [EOL] [EOL] [EOL] class MuUnit ( Enum ) : [EOL] mu = [string] [EOL] [EOL] [EOL] class InternalUnit ( Enum ) : [EOL] em = [string] [EOL] ex = [string] [EOL] [EOL] [EOL] units_in_sp = { } [EOL] units_in_sp [ Unit . scaled_point ] = [number] [EOL] units_in_sp [ Unit . point ] = [number] * units_in_sp [ Unit . scaled_point ] [EOL] units_in_sp [ Unit . pica ] = [number] * units_in_sp [ Unit . point ] [EOL] units_in_sp [ Unit . inch ] = round ( [number] * units_in_sp [ Unit . point ] ) [EOL] units_in_sp [ Unit . big_point ] = round ( ( [number] / [number] ) * units_in_sp [ Unit . inch ] ) [EOL] units_in_sp [ Unit . centimetre ] = round ( ( [number] / [number] ) * units_in_sp [ Unit . inch ] ) [EOL] units_in_sp [ Unit . millimetre ] = round ( [number] * units_in_sp [ Unit . centimetre ] ) [EOL] units_in_sp [ Unit . didot_point ] = round ( ( [number] / [number] ) * units_in_sp [ Unit . point ] ) [EOL] units_in_sp [ Unit . cicero ] = [number] * units_in_sp [ Unit . didot_point ] [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] MAX_DIMEN = [number] ** [number] - [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.Dict[Unit,builtins.int]$ 0 0 0 0 $typing.Dict[Unit,builtins.int]$ 0 0 0 0 0 0 0 0 $typing.Dict[Unit,builtins.int]$ 0 0 0 0 0 0 0 0 $typing.Dict[Unit,builtins.int]$ 0 0 0 0 0 0 $typing.Dict[Unit,builtins.int]$ 0 0 0 0 0 0 0 0 $typing.Dict[Unit,builtins.int]$ 0 0 0 0 0 0 $typing.Dict[Unit,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 $typing.Dict[Unit,builtins.int]$ 0 0 0 0 0 0 0 $typing.Dict[Unit,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[Unit,builtins.int]$ 0 0 0 0 0 0 0 $typing.Dict[Unit,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[Unit,builtins.int]$ 0 0 0 0 0 0 0 $typing.Dict[Unit,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 $typing.Dict[Unit,builtins.int]$ 0 0 0 0 0 0 0 $typing.Dict[Unit,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[Unit,builtins.int]$ 0 0 0 0 0 0 0 $typing.Dict[Unit,builtins.int]$ 0 0 0 0 0 0 0 0 $typing.Dict[Unit,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0
from typing import Dict [EOL] import builtins [EOL] import parameters [EOL] import instructions [EOL] import typing [EOL] import specials [EOL] [docstring] [EOL] from typing import Dict [EOL] [EOL] from . instructions import Instructions [EOL] from . parameters import Parameters [EOL] from . specials import Specials [EOL] [EOL] [EOL] [comment] [EOL] primitive_control_sequences = { [string] : Instructions . relax , [string] : Instructions . begin_group , [string] : Instructions . end_group , [string] : Instructions . show_token , [string] : Instructions . show_box , [string] : Instructions . show_lists , [string] : Instructions . show_the , [string] : Instructions . ship_out , [string] : Instructions . ignore_spaces , [string] : Instructions . after_assignment , [string] : Instructions . after_group , [string] : Instructions . upper_case , [string] : Instructions . lower_case , [string] : Instructions . message , [string] : Instructions . error_message , [string] : Instructions . immediate , [string] : Instructions . open_input , [string] : Instructions . close_input , [string] : Instructions . open_output , [string] : Instructions . close_output , [string] : Instructions . read , [string] : Instructions . write , [string] : Instructions . special , [string] : Instructions . add_penalty , [string] : Instructions . kern , [string] : Instructions . math_kern , [string] : Instructions . un_penalty , [string] : Instructions . un_kern , [string] : Instructions . un_glue , [string] : Instructions . mark , [string] : Instructions . insert , [string] : Instructions . v_adjust , [string] : Instructions . v_skip , [string] : Instructions . v_fil , [string] : Instructions . v_fill , [string] : Instructions . v_stretch_or_shrink , [string] : Instructions . v_fil_neg , [string] : Instructions . leaders , [string] : Instructions . centered_leaders , [string] : Instructions . expanded_leaders , [string] : Instructions . box , [string] : Instructions . copy , [string] : Instructions . last_box , [string] : Instructions . v_split , [string] : Instructions . h_box , [string] : Instructions . v_box , [string] : Instructions . v_top , [string] : Instructions . move_left , [string] : Instructions . move_right , [string] : Instructions . un_v_box , [string] : Instructions . un_v_copy , [string] : Instructions . h_rule , [string] : Instructions . h_align , [string] : Instructions . indent , [string] : Instructions . no_indent , [string] : Instructions . par , [string] : Instructions . end , [string] : Instructions . dump , [string] : Instructions . h_skip , [string] : Instructions . h_fil , [string] : Instructions . h_fill , [string] : Instructions . h_stretch_or_shrink , [string] : Instructions . h_fil_neg , [string] : Instructions . control_space , [string] : Instructions . raise_box , [string] : Instructions . lower_box , [string] : Instructions . un_h_box , [string] : Instructions . un_h_copy , [string] : Instructions . v_rule , [string] : Instructions . char , [string] : Instructions . accent , [string] : Instructions . italic_correction , [string] : Instructions . discretionary , [string] : Instructions . discretionary_hyphen , [string] : Instructions . set_box , [string] : Instructions . count , [string] : Instructions . dimen , [string] : Instructions . skip , [string] : Instructions . mu_skip , [string] : Instructions . toks , [string] : Instructions . box_dimen_height , [string] : Instructions . box_dimen_width , [string] : Instructions . box_dimen_depth , [string] : Instructions . advance , [string] : Instructions . multiply , [string] : Instructions . divide , [string] : Instructions . cat_code , [string] : Instructions . math_code , [string] : Instructions . upper_case_code , [string] : Instructions . lower_case_code , [string] : Instructions . space_factor_code , [string] : Instructions . delimiter_code , [string] : Instructions . let , [string] : Instructions . future_let , [string] : Instructions . text_font , [string] : Instructions . script_font , [string] : Instructions . script_script_font , [string] : Instructions . par_shape , [string] : Instructions . font_dimen , [string] : Instructions . hyphen_char , [string] : Instructions . skew_char , [string] : Instructions . hyphenation , [string] : Instructions . patterns , [string] : Instructions . error_stop_mode , [string] : Instructions . scroll_mode , [string] : Instructions . non_stop_mode , [string] : Instructions . batch_mode , [string] : Instructions . def_ , [string] : Instructions . g_def , [string] : Instructions . e_def , [string] : Instructions . x_def , [string] : Instructions . char_def , [string] : Instructions . math_char_def , [string] : Instructions . count_def , [string] : Instructions . dimen_def , [string] : Instructions . skip_def , [string] : Instructions . mu_skip_def , [string] : Instructions . toks_def , [string] : Instructions . global_mod , [string] : Instructions . long_mod , [string] : Instructions . outer_mod , [string] : Instructions . font , [string] : Instructions . if_num , [string] : Instructions . if_dimen , [string] : Instructions . if_odd , [string] : Instructions . if_v_mode , [string] : Instructions . if_h_mode , [string] : Instructions . if_m_mode , [string] : Instructions . if_inner_mode , [string] : Instructions . if_char , [string] : Instructions . if_cat , [string] : Instructions . if_token , [string] : Instructions . if_void , [string] : Instructions . if_h_box , [string] : Instructions . if_v_box , [string] : Instructions . if_end_of_file , [string] : Instructions . if_true , [string] : Instructions . if_false , [string] : Instructions . if_case , [string] : Instructions . else_ , [string] : Instructions . end_if , [string] : Instructions . or_ , [string] : Instructions . number , [string] : Instructions . roman_numeral , [string] : Instructions . string , [string] : Instructions . job_name , [string] : Instructions . font_name , [string] : Instructions . meaning , [string] : Instructions . cs_name , [string] : Instructions . end_cs_name , [string] : Instructions . expand_after , [string] : Instructions . no_expand , [string] : Instructions . top_mark , [string] : Instructions . first_mark , [string] : Instructions . bottom_mark , [string] : Instructions . split_first_mark , [string] : Instructions . split_bottom_mark , [string] : Instructions . input , [string] : Instructions . end_input , [string] : Instructions . the , [string] : Instructions . cr , [string] : Instructions . undefined , } [EOL] [EOL] [comment] [EOL] param_control_sequences = { [string] : Parameters . pre_tolerance , [string] : Parameters . tolerance , [string] : Parameters . h_badness , [string] : Parameters . v_badness , [string] : Parameters . line_penalty , [string] : Parameters . hyphen_penalty , [string] : Parameters . ex_hyphen_penalty , [string] : Parameters . bin_op_penalty , [string] : Parameters . rel_penalty , [string] : Parameters . club_penalty , [string] : Parameters . widow_penalty , [string] : Parameters . display_widow_penalty , [string] : Parameters . broken_penalty , [string] : Parameters . pre_display_penalty , [string] : Parameters . post_display_penalty , [string] : Parameters . inter_line_penalty , [string] : Parameters . floating_penalty , [string] : Parameters . output_penalty , [string] : Parameters . double_hyphen_demerits , [string] : Parameters . final_hyphen_demerits , [string] : Parameters . adj_demerits , [string] : Parameters . looseness , [string] : Parameters . pausing , [string] : Parameters . holding_inserts , [string] : Parameters . tracing_on_line , [string] : Parameters . tracing_macros , [string] : Parameters . tracing_stats , [string] : Parameters . tracing_paragraphs , [string] : Parameters . tracing_pages , [string] : Parameters . tracing_output , [string] : Parameters . tracing_lostchars , [string] : Parameters . tracing_commands , [string] : Parameters . tracing_restores , [string] : Parameters . language , [string] : Parameters . uc_hyph , [string] : Parameters . left_hyphen_min , [string] : Parameters . right_hyphen_min , [string] : Parameters . global_defs , [string] : Parameters . max_dead_cycles , [string] : Parameters . hang_after , [string] : Parameters . fam , [string] : Parameters . mag , [string] : Parameters . escape_char , [string] : Parameters . default_hyphen_char , [string] : Parameters . default_skew_char , [string] : Parameters . end_line_char , [string] : Parameters . new_line_char , [string] : Parameters . delimiter_factor , [string] : Parameters . time , [string] : Parameters . day , [string] : Parameters . month , [string] : Parameters . year , [string] : Parameters . show_box_breadth , [string] : Parameters . show_box_depth , [string] : Parameters . error_context_lines , [string] : Parameters . h_fuzz , [string] : Parameters . v_fuzz , [string] : Parameters . over_full_rule , [string] : Parameters . h_size , [string] : Parameters . v_size , [string] : Parameters . max_depth , [string] : Parameters . split_max_depth , [string] : Parameters . box_max_depth , [string] : Parameters . line_skip_limit , [string] : Parameters . delimiter_short_fall , [string] : Parameters . null_delimiter_space , [string] : Parameters . script_space , [string] : Parameters . math_surround , [string] : Parameters . pre_display_size , [string] : Parameters . display_width , [string] : Parameters . display_indent , [string] : Parameters . par_indent , [string] : Parameters . hang_indent , [string] : Parameters . h_offset , [string] : Parameters . v_offset , [string] : Parameters . base_line_skip , [string] : Parameters . line_skip , [string] : Parameters . par_skip , [string] : Parameters . above_display_skip , [string] : Parameters . above_display_short_skip , [string] : Parameters . below_display_skip , [string] : Parameters . below_display_short_skip , [string] : Parameters . left_skip , [string] : Parameters . right_skip , [string] : Parameters . top_skip , [string] : Parameters . split_top_skip , [string] : Parameters . tab_skip , [string] : Parameters . space_skip , [string] : Parameters . x_space_skip , [string] : Parameters . par_fill_skip , [string] : Parameters . thin_mu_skip , [string] : Parameters . med_mu_skip , [string] : Parameters . thick_mu_skip , [string] : Parameters . output , [string] : Parameters . every_par , [string] : Parameters . every_math , [string] : Parameters . every_display , [string] : Parameters . every_h_box , [string] : Parameters . every_v_box , [string] : Parameters . every_job , [string] : Parameters . every_cr , [string] : Parameters . err_help , } [EOL] [EOL] [comment] [EOL] special_control_sequences = { [string] : Specials . space_factor , [string] : Specials . prev_graf , [string] : Specials . dead_cycles , [string] : Specials . insert_penalties , [string] : Specials . prev_depth , [string] : Specials . page_goal , [string] : Specials . page_total , [string] : Specials . page_stretch , [string] : Specials . page_fil_stretch , [string] : Specials . page_fill_stretch , [string] : Specials . page_filll_stretch , [string] : Specials . page_shrink , [string] : Specials . page_depth , } [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,instructions.Instructions]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,parameters.Parameters]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,specials.Specials]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Any [EOL] import typing [EOL] from nex . state import GlobalState [EOL] from nex import nex [EOL] [EOL] from common import test_runnable_file_name , test_file_dir_path [EOL] [EOL] [EOL] def test_make_input_chain ( ) : [EOL] state = GlobalState . from_defaults ( ) [EOL] nex . make_input_chain ( state ) [EOL] [EOL] [EOL] def test_run_file ( ) : [EOL] nex . run_files ( input_paths = [ test_runnable_file_name ] , font_search_paths = [ test_file_dir_path ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
import nex [EOL] from nex . dampf . dvi_document import DVIDocument [EOL] from nex import box , box_writer [EOL] [EOL] [EOL] def test_glue_flex ( ) : [EOL] h_box = box . HBox ( contents = [ box . Glue ( dimen = [number] , stretch = [number] , shrink = [number] ) , box . Glue ( dimen = [number] , stretch = [number] , shrink = [number] ) , box . Kern ( dimen = [number] ) ] , set_glue = False ) [EOL] assert h_box . stretch == [ [number] + [number] ] [EOL] assert h_box . shrink == [ [number] + [number] ] [EOL] assert h_box . natural_length == [number] + [number] + [number] [EOL] [EOL] [EOL] def test_kern ( ) : [EOL] kern = box . Kern ( dimen = [number] ) [EOL] assert kern . length == [number] [EOL] [EOL] [EOL] def test_glue_flex_set ( ) : [EOL] h_box = box . HBox ( contents = [ box . Glue ( dimen = [number] , stretch = [number] , shrink = [number] ) , box . Glue ( dimen = [number] , stretch = [number] , shrink = [number] ) ] , set_glue = True ) [EOL] assert h_box . stretch == [ [number] ] [EOL] assert h_box . shrink == [ [number] ] [EOL] [EOL] [EOL] def test_box_writer ( ) : [EOL] doc = DVIDocument ( magnification = [number] ) [EOL] v_box = box . VBox ( [ box . Rule ( [number] , [number] , [number] ) , box . Glue ( [number] , [number] , [number] ) , box . HBox ( [ box . Glue ( [number] , [number] , [number] ) , box . Rule ( [number] , [number] , [number] ) , ] ) , ] ) [EOL] box_writer . write_box_to_doc ( doc , v_box ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from nex . utils import ensure_extension , file_path_to_chars [EOL] [EOL] from common import ( test_file_name , test_chars ) [EOL] [EOL] [EOL] def test_ensure_extension ( ) : [EOL] [docstring] [EOL] assert ( ensure_extension ( [string] , [string] ) == ensure_extension ( [string] , [string] ) ) [EOL] assert ( ensure_extension ( [string] , [string] ) == ensure_extension ( [string] , [string] ) ) [EOL] assert ( ensure_extension ( [string] , [string] ) == ensure_extension ( [string] , [string] ) ) [EOL] [EOL] [EOL] def test_file_to_chars ( ) : [EOL] [docstring] [EOL] assert file_path_to_chars ( test_file_name ) == test_chars [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import List , Any [EOL] import typing [EOL] import nex [EOL] import pytest [EOL] [EOL] from nex . reader import Reader , ReaderBuffer [EOL] [EOL] from common import ( test_not_here_file_name , test_file_name , test_chars , test_2_chars ) [EOL] [EOL] [EOL] def test_buffer_init ( ) : [EOL] [docstring] [EOL] r = ReaderBuffer ( test_chars ) [EOL] assert r . i == - [number] [EOL] assert r . chars == test_chars [EOL] [EOL] [EOL] def test_next_char ( ) : [EOL] [docstring] [EOL] r = Reader ( ) [EOL] r . insert_chars ( test_chars ) [EOL] cs = [ r . advance_loc ( ) for _ in range ( [number] ) ] [EOL] assert cs == test_chars [EOL] with pytest . raises ( EOFError ) : [EOL] r . advance_loc ( ) [EOL] [EOL] [EOL] def test_init_missing_file ( ) : [EOL] [docstring] [EOL] r = Reader ( ) [EOL] with pytest . raises ( IOError ) : [EOL] r . insert_file ( test_not_here_file_name ) [EOL] [EOL] [EOL] def test_init_file ( ) : [EOL] [docstring] [EOL] r_direct = Reader ( ) [EOL] r_direct . insert_chars ( test_chars ) [EOL] r_file = Reader ( ) [EOL] r_file . insert_file ( test_file_name ) [EOL] assert list ( r_direct . advance_to_end ( ) ) == list ( r_file . advance_to_end ( ) ) [EOL] [EOL] [EOL] def test_insert_start ( ) : [EOL] [docstring] [EOL] r = Reader ( ) [EOL] r . insert_chars ( test_chars ) [EOL] r . insert_chars ( test_2_chars ) [EOL] assert list ( r . advance_to_end ( ) ) == test_2_chars + test_chars [EOL] [EOL] [EOL] def test_insert_middle ( ) : [EOL] [docstring] [EOL] r = Reader ( ) [EOL] r . insert_chars ( test_chars ) [EOL] cs = [ r . advance_loc ( ) ] [EOL] r . insert_chars ( test_2_chars ) [EOL] cs . extend ( list ( r . advance_to_end ( ) ) ) [EOL] assert cs == [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] [EOL] [EOL] def test_insert_end ( ) : [EOL] [docstring] [EOL] r = Reader ( ) [EOL] r . insert_chars ( test_chars ) [EOL] cs = list ( r . advance_to_end ( ) ) [EOL] r . insert_chars ( test_2_chars ) [EOL] cs . extend ( list ( r . advance_to_end ( ) ) ) [EOL] assert cs == test_chars + test_2_chars [EOL] [EOL] [EOL] def test_peek ( ) : [EOL] [docstring] [EOL] r = Reader ( ) [EOL] r . insert_chars ( test_chars ) [EOL] [comment] [EOL] with pytest . raises ( ValueError ) : [EOL] r . peek_ahead ( n = [number] ) [EOL] r . advance_loc ( ) [EOL] assert r . current_char == [string] [EOL] [comment] [EOL] with pytest . raises ( ValueError ) : [EOL] r . peek_ahead ( n = - [number] ) [EOL] [comment] [EOL] assert [ r . peek_ahead ( n = i ) for i in range ( [number] ) ] == test_chars [EOL] [comment] [EOL] with pytest . raises ( ValueError ) : [EOL] r . peek_ahead ( n = [number] ) [EOL] r . advance_loc ( ) [EOL] assert r . current_char == [string] [EOL] [comment] [EOL] with pytest . raises ( EOFError ) : [EOL] r . peek_ahead ( n = [number] ) [EOL] [EOL] [EOL] def test_advance ( ) : [EOL] [docstring] [EOL] r = Reader ( ) [EOL] r . insert_chars ( test_chars ) [EOL] cs = [ ] [EOL] for _ in range ( [number] ) : [EOL] r . advance_loc ( ) [EOL] cs . append ( r . peek_ahead ( [number] ) ) [EOL] assert cs == test_chars [EOL] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Dict [EOL] import typing [EOL] from string import ascii_letters [EOL] [EOL] from nex . constants . codes import CatCode [EOL] from nex . constants . instructions import Instructions [EOL] from nex . router import Instructioner [EOL] from nex . utils import ascii_characters [EOL] from nex . parsing import parsing [EOL] [EOL] from common import ITok [EOL] [EOL] parser = parsing . get_parser ( start = [string] , chunking = False ) [EOL] [EOL] [EOL] char_to_cat = { } [EOL] for c in ascii_characters : [EOL] char_to_cat [ c ] = CatCode . other [EOL] for c in ascii_letters : [EOL] char_to_cat [ c ] = CatCode . letter [EOL] char_to_cat . update ( { [string] : CatCode . escape , [string] : CatCode . space , [string] : CatCode . begin_group , [string] : CatCode . end_group , [string] : CatCode . end_of_line , [string] : CatCode . math_shift , } ) [EOL] [EOL] [EOL] cs_map = { [string] : ITok ( Instructions . relax ) , [string] : ITok ( Instructions . h_rule ) , [string] : ITok ( Instructions . v_rule ) , [string] : ITok ( Instructions . accent ) , [string] : ITok ( Instructions . un_h_box ) , [string] : ITok ( Instructions . un_h_copy ) , [string] : ITok ( Instructions . un_v_box ) , [string] : ITok ( Instructions . un_v_copy ) , [string] : ITok ( Instructions . h_box ) , [string] : ITok ( Instructions . v_box ) , [string] : ITok ( Instructions . horizontal_mode_material_and_right_brace ) , [string] : ITok ( Instructions . vertical_mode_material_and_right_brace ) , [string] : ITok ( Instructions . after_assignment ) , [string] : ITok ( Instructions . after_group ) , [string] : ITok ( Instructions . right_brace ) , [string] : ITok ( Instructions . begin_group ) , [string] : ITok ( Instructions . end_group ) , [string] : ITok ( Instructions . show_lists ) , [string] : ITok ( Instructions . open_input ) , [string] : ITok ( Instructions . open_output ) , [string] : ITok ( Instructions . close_input ) , [string] : ITok ( Instructions . close_output ) , [string] : ITok ( Instructions . write ) , [string] : ITok ( Instructions . message ) , [string] : ITok ( Instructions . error_message ) , [string] : ITok ( Instructions . balanced_text_and_right_brace ) , [string] : ITok ( Instructions . arbitrary_token ) , [string] : ITok ( Instructions . ship_out ) , [string] : ITok ( Instructions . kern ) , [string] : ITok ( Instructions . math_kern ) , [string] : ITok ( Instructions . un_penalty ) , [string] : ITok ( Instructions . un_kern ) , [string] : ITok ( Instructions . un_glue ) , [string] : ITok ( Instructions . h_skip ) , [string] : ITok ( Instructions . v_skip ) , [string] : ITok ( Instructions . space ) , [string] : ITok ( Instructions . control_space ) , [string] : ITok ( Instructions . indent ) , [string] : ITok ( Instructions . no_indent ) , [string] : ITok ( Instructions . par ) , [string] : ITok ( Instructions . end ) , [string] : ITok ( Instructions . dump ) , [string] : ITok ( Instructions . italic_correction ) , [string] : ITok ( Instructions . discretionary ) , [string] : ITok ( Instructions . discretionary_hyphen ) , [string] : ITok ( Instructions . ignore_spaces ) , [string] : ITok ( Instructions . special ) , [string] : ITok ( Instructions . add_penalty ) , [string] : ITok ( Instructions . mark ) , [string] : ITok ( Instructions . insert ) , [string] : ITok ( Instructions . v_adjust ) , [string] : ITok ( Instructions . leaders ) , [string] : ITok ( Instructions . centered_leaders ) , [string] : ITok ( Instructions . expanded_leaders ) , [string] : ITok ( Instructions . move_left ) , [string] : ITok ( Instructions . move_right ) , [string] : ITok ( Instructions . h_align ) , [string] : ITok ( Instructions . v_align ) , [string] : ITok ( Instructions . alignment_material ) , [string] : ITok ( Instructions . raise_box ) , [string] : ITok ( Instructions . lower_box ) , [string] : ITok ( Instructions . show_box ) , [string] : ITok ( Instructions . show_token ) , } [EOL] [EOL] [EOL] def process ( s ) : [EOL] [docstring] [EOL] def resolve_cs ( name , * args , ** kwargs ) : [EOL] return cs_map [ name ] [EOL] instrs = Instructioner . from_string ( s = s , resolve_cs_func = resolve_cs , get_cat_code_func = char_to_cat . get , ) [EOL] return instrs . advance_to_end ( expand = True ) [EOL] [EOL] [EOL] def test_relax ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_right_brace ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_delimit_group ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_show_token ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_show_box ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_show_lists ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_ship_out ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_after_assignment ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_after_group ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_message ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_open_io ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_close_io ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_write ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_special ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_penalty ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_kern ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_mark ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_insert ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_v_adjust ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_un_stuff ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] parser . parse ( process ( [string] ) ) [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_glue ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_space ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_add_leaders ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] parser . parse ( process ( [string] ) ) [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_box_literal ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_un_box ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] parser . parse ( process ( [string] ) ) [EOL] parser . parse ( process ( [string] ) ) [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_indent ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_par ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_left_brace ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_rule ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_shift_box ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] parser . parse ( process ( [string] ) ) [EOL] parser . parse ( process ( [string] ) ) [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_align ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_endings ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_character ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_accent ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_italic_correction ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_discretionary ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_discretionary_hyphen ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_math_shift ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL] [EOL] [EOL] def test_ignore_spaces ( ) : [EOL] parser . parse ( process ( [string] ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0
from typing import Dict , List , Any [EOL] import typing [EOL] import nex [EOL] import pytest [EOL] [EOL] from nex . constants . instructions import Instructions [EOL] from nex . accessors import Registers , NotInScopeError [EOL] from nex . box import HBox [EOL] [EOL] [EOL] def test_registers_empty ( ) : [EOL] rmap = { Instructions . count . value : { } , } [EOL] r = Registers ( rmap ) [EOL] [EOL] [comment] [EOL] for test_i in ( [number] , None , [number] , - [number] ) : [EOL] with pytest . raises ( ValueError ) : [EOL] r . get ( Instructions . count . value , test_i ) [EOL] for test_val in ( [number] , [number] ) : [EOL] with pytest . raises ( ValueError ) : [EOL] r . set ( Instructions . count . value , test_i , test_val ) [EOL] [comment] [EOL] for test_type in ( [string] , None ) : [EOL] with pytest . raises ( ValueError ) : [EOL] r . get ( test_type , test_i ) [EOL] [EOL] [EOL] def test_registers_uninitialized ( ) : [EOL] rmap = { Instructions . count . value : { [number] : None } , } [EOL] r = Registers ( rmap ) [EOL] [EOL] [comment] [EOL] with pytest . raises ( NotInScopeError ) : [EOL] r . get ( Instructions . count . value , [number] ) [EOL] [comment] [EOL] test_val = [number] [EOL] r . set ( Instructions . count . value , [number] , test_val ) [EOL] assert r . get ( Instructions . count . value , [number] ) == test_val [EOL] [EOL] [EOL] def test_register_types ( ) : [EOL] rmap = { Instructions . count . value : { [number] : None } , Instructions . dimen . value : { [number] : None } , Instructions . skip . value : { [number] : None } , Instructions . mu_skip . value : { [number] : None } , Instructions . toks . value : { [number] : None } , Instructions . set_box . value : { [number] : None } , } [EOL] r = Registers ( rmap ) [EOL] tokens = [ [string] ] [EOL] dct = { [string] : [number] } [EOL] int_val = [number] [EOL] box = HBox ( contents = [ ] ) [EOL] for type_ in ( Instructions . count . value , Instructions . dimen . value ) : [EOL] [comment] [EOL] r . set ( type_ , [number] , int_val ) [EOL] [comment] [EOL] with pytest . raises ( TypeError ) : [EOL] r . set ( type_ , [number] , dct ) [EOL] with pytest . raises ( TypeError ) : [EOL] r . set ( type_ , [number] , tokens ) [EOL] for type_ in ( Instructions . skip . value , Instructions . mu_skip . value ) : [EOL] [comment] [EOL] r . set ( type_ , [number] , dct ) [EOL] [comment] [EOL] with pytest . raises ( TypeError ) : [EOL] r . set ( type_ , [number] , int_val ) [EOL] with pytest . raises ( TypeError ) : [EOL] r . set ( type_ , [number] , tokens ) [EOL] [comment] [EOL] r . set ( Instructions . toks . value , [number] , tokens ) [EOL] [comment] [EOL] with pytest . raises ( TypeError ) : [EOL] r . set ( Instructions . toks . value , [number] , int_val ) [EOL] with pytest . raises ( TypeError ) : [EOL] r . set ( Instructions . toks . value , [number] , dct ) [EOL] [comment] [EOL] r . set ( Instructions . set_box . value , [number] , box ) [EOL] [comment] [EOL] with pytest . raises ( TypeError ) : [EOL] r . set ( Instructions . set_box . value , [number] , int_val ) [EOL] with pytest . raises ( TypeError ) : [EOL] r . set ( Instructions . set_box . value , [number] , dct ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List [EOL] import typing [EOL] import tests [EOL] from nex . constants . codes import CatCode [EOL] from nex . accessors import Codes [EOL] from nex . lexer import Lexer [EOL] [EOL] [EOL] class DummyCatCodeGetter : [EOL] [EOL] def __init__ ( self ) : [EOL] self . char_to_cat = Codes . default_initial_cat_codes ( ) [EOL] [EOL] def get ( self , char ) : [EOL] return self . char_to_cat [ char ] [EOL] [EOL] [EOL] def lex_string_to_tokens ( s ) : [EOL] cat_code_getter = DummyCatCodeGetter ( ) [EOL] lex = Lexer . from_string ( s , get_cat_code_func = cat_code_getter . get ) [EOL] return list ( lex . advance_to_end ( ) ) [EOL] [EOL] [EOL] def test_trioing ( ) : [EOL] [docstring] [EOL] test_input = [string] [EOL] [EOL] [comment] [EOL] correct_code_nrs = [ ord ( [string] ) , ord ( [string] ) , ord ( [string] ) , ord ( [string] ) , ord ( [string] ) - [number] , ord ( [string] ) + [number] ] [EOL] [EOL] [comment] [EOL] for trio_char in [ [string] , [string] , [string] ] : [EOL] cat_code_getter = DummyCatCodeGetter ( ) [EOL] [comment] [EOL] [comment] [EOL] cat_code_getter . char_to_cat [ trio_char ] = CatCode . superscript [EOL] [comment] [EOL] lex = Lexer . from_string ( test_input . replace ( [string] , trio_char ) , cat_code_getter . get ) [EOL] [EOL] tokens = list ( lex . advance_to_end ( ) ) [EOL] [EOL] [comment] [EOL] assert len ( tokens ) == [number] [EOL] [comment] [EOL] assert [ ord ( t . value [ [string] ] ) for t in tokens ] == correct_code_nrs [EOL] [EOL] [EOL] def test_comments ( ) : [EOL] [docstring] [EOL] tokens = lex_string_to_tokens ( [string] ) [EOL] assert [ t . value [ [string] ] for t in tokens ] == list ( [string] ) [EOL] [EOL] [EOL] def test_skipping_blanks ( ) : [EOL] [docstring] [EOL] toks_single = lex_string_to_tokens ( [string] ) [EOL] toks_triple = lex_string_to_tokens ( [string] ) [EOL] [comment] [EOL] assert ( [ t . value [ [string] ] for t in toks_single ] == [ t . value [ [string] ] for t in toks_triple ] ) [EOL] assert ( [ t . value [ [string] ] for t in toks_single ] == [ t . value [ [string] ] for t in toks_triple ] ) [EOL] [EOL] [EOL] def test_control_sequence ( ) : [EOL] [docstring] [EOL] tokens = lex_string_to_tokens ( [string] ) [EOL] assert len ( tokens ) == [number] [EOL] [EOL] assert tokens [ [number] ] . value [ [string] ] == [string] [EOL] assert tokens [ [number] ] . value == [string] [EOL] assert tokens [ [number] ] . value == [string] [EOL] [comment] [EOL] [comment] [EOL] tokens_single = lex_string_to_tokens ( [string] ) [EOL] assert tokens_single [ [number] ] . value == [string] and len ( tokens_single ) == [number] [EOL] [EOL] [EOL] def test_control_sequence_spacing ( ) : [EOL] [docstring] [EOL] tokens_close = lex_string_to_tokens ( [string] ) [EOL] tokens_spaced = lex_string_to_tokens ( [string] ) [EOL] tokens_super_spaced = lex_string_to_tokens ( [string] ) [EOL] assert len ( tokens_close ) == len ( tokens_spaced ) == len ( tokens_super_spaced ) [EOL] [EOL] [EOL] def test_new_lines ( ) : [EOL] [docstring] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] tokens = lex_string_to_tokens ( [string] ) [EOL] assert len ( tokens ) == [number] and tokens [ [number] ] . value [ [string] ] == [string] [EOL] [comment] [EOL] tokens = lex_string_to_tokens ( [string] ) [EOL] assert ( len ( tokens ) == [number] and tokens [ [number] ] . value [ [string] ] == [string] and tokens [ [number] ] . value == [string] ) [EOL] [comment] [EOL] [comment] [EOL] tokens = lex_string_to_tokens ( [string] ) [EOL] assert len ( tokens ) == [number] and tokens [ [number] ] . value [ [string] ] == [string] [EOL] [EOL] [EOL] def test_tokenise ( ) : [EOL] [docstring] [EOL] s = [string] [EOL] tokens = lex_string_to_tokens ( s ) [EOL] assert len ( tokens ) == [number] [EOL] [comment] [EOL] [comment] [EOL] for c , t in zip ( s , tokens ) : [EOL] assert t . value [ [string] ] == c [EOL] assert t . value [ [string] ] == CatCode . other [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
import nex [EOL] import pytest [EOL] [EOL] from nex . fonts import GlobalFontState [EOL] [EOL] [EOL] def test_skew_char ( ) : [EOL] gfs = GlobalFontState ( ) [EOL] gfs . set_skew_char ( [number] , [number] ) [EOL] with pytest . raises ( KeyError ) : [EOL] gfs . set_skew_char ( [number] , [number] ) [EOL] [EOL] [EOL] def test_hyphen_char ( ) : [EOL] gfs = GlobalFontState ( ) [EOL] gfs . set_hyphen_char ( [number] , [number] ) [EOL] with pytest . raises ( KeyError ) : [EOL] gfs . set_hyphen_char ( [number] , [number] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] import pytest [EOL] [EOL] from nex . parsing import parsing [EOL] [EOL] from common import str_to_lit_str , str_to_toks [EOL] [EOL] [EOL] @ pytest . fixture ( scope = [string] ) def parser ( ) : [EOL] return parsing . get_parser ( start = [string] , chunking = False ) [EOL] [EOL] [EOL] def test_if_num ( parser ) : [EOL] parser . parse ( iter ( str_to_toks ( [string] ) ) ) [EOL] [EOL] [EOL] def test_if_dimen ( parser ) : [EOL] unit_str = str_to_lit_str ( [string] ) [EOL] tstr = f' [string] { unit_str } [string] { unit_str } [string] ' [EOL] parser . parse ( iter ( str_to_toks ( tstr ) ) ) [EOL] [EOL] [EOL] def test_if_bool ( parser ) : [EOL] parser . parse ( iter ( str_to_toks ( [string] ) ) ) [EOL] parser . parse ( iter ( str_to_toks ( [string] ) ) ) [EOL] [EOL] [EOL] def test_if_odd ( parser ) : [EOL] parser . parse ( iter ( str_to_toks ( [string] ) ) ) [EOL] [EOL] [EOL] def test_if_modes ( parser ) : [EOL] parser . parse ( iter ( str_to_toks ( [string] ) ) ) [EOL] parser . parse ( iter ( str_to_toks ( [string] ) ) ) [EOL] [EOL] [EOL] def test_if_case ( parser ) : [EOL] parser . parse ( iter ( str_to_toks ( [string] ) ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import List , Type , Any [EOL] import typing [EOL] import tests [EOL] import os [EOL] from enum import Enum [EOL] [EOL] from nex . tokens import InstructionToken , BaseToken [EOL] from nex . parsing import utils as pu [EOL] from nex . fonts import GlobalFontState [EOL] from nex . router import make_char_cat_pair_instruction_token_direct [EOL] [EOL] test_dir_path = os . path . dirname ( os . path . realpath ( __file__ ) ) [EOL] test_file_dir_path = os . path . join ( test_dir_path , [string] ) [EOL] test_file_name = os . path . join ( test_file_dir_path , [string] ) [EOL] test_not_here_file_name = os . path . join ( test_file_dir_path , [string] ) [EOL] test_runnable_file_name = os . path . join ( test_file_dir_path , [string] ) [EOL] [EOL] test_chars = list ( [string] ) [EOL] test_2_chars = list ( [string] ) [EOL] [EOL] [EOL] def char_instr_tok ( char , cat ) : [EOL] return make_char_cat_pair_instruction_token_direct ( char , cat , parents = None ) [EOL] [EOL] [EOL] def ITok ( * args , ** kwargs ) : [EOL] return InstructionToken ( * args , ** kwargs , parents = None , value = None ) [EOL] [EOL] [EOL] class DummyInstructions ( Enum ) : [EOL] test = [string] [EOL] [EOL] [EOL] class DummyCommands ( Enum ) : [EOL] verb = [string] [EOL] [EOL] [EOL] class DummyParameters ( Enum ) : [EOL] ptest = [string] [EOL] [EOL] [EOL] [comment] [EOL] [EOL] [EOL] def str_to_toks ( s ) : [EOL] return [ BaseToken ( part ) for part in s . split ( ) ] [EOL] [EOL] [EOL] def str_to_lit_strs ( s ) : [EOL] return list ( pu . str_to_char_types ( s ) ) [EOL] [EOL] [EOL] def str_to_lit_str ( s ) : [EOL] return [string] . join ( str_to_lit_strs ( s ) ) [EOL] [EOL] [EOL] class DummyFontInfo : [EOL] [EOL] def __init__ ( self , file_name , file_path , at_clause ) : [EOL] self . font_name = file_name [EOL] self . file_name = file_name [EOL] self . file_path = file_path [EOL] self . at_clause = at_clause [EOL] self . width = lambda code : [number] [EOL] self . height = lambda code : [number] [EOL] self . depth = lambda code : [number] [EOL] self . x_height = [number] [EOL] [EOL] [EOL] class DummyGlobalFontState ( GlobalFontState ) : [EOL] [EOL] FontInfo = DummyFontInfo [EOL] [EOL] def define_new_font ( self , file_name , at_clause ) : [EOL] font_info = DummyFontInfo ( file_name = file_name , file_path = f' [string] { file_name }' , at_clause = at_clause ) [EOL] font_id = max ( self . fonts . keys ( ) ) + [number] [EOL] self . fonts [ font_id ] = font_info [EOL] [comment] [EOL] return font_id [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[tests.common.DummyFontInfo]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $tests.common.DummyFontInfo$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $tests.common.DummyFontInfo$ 0 0 0 0 $typing.Any$ 0
from typing import Any [EOL] import typing [EOL] import tests [EOL] import nex [EOL] import pytest [EOL] [EOL] from nex . constants . instructions import Instructions [EOL] from nex . constants . commands import Commands [EOL] from nex . constants . specials import Specials [EOL] from nex . state import Mode , GlobalState [EOL] from nex import box [EOL] from nex . box_writer import write_to_dvi_file [EOL] from nex . state import ExecuteCommandError [EOL] from nex . utils import UserError [EOL] from nex . tokens import BuiltToken , CommandToken [EOL] from nex . fonts import GlobalFontState [EOL] [EOL] from common import DummyCommands , DummyGlobalFontState , ITok [EOL] [EOL] [EOL] do_output = False [EOL] font_path = [string] [EOL] [EOL] [EOL] def CTok ( command , value ) : [EOL] return CommandToken ( command = command , value = value , parents = None ) [EOL] [EOL] [EOL] def BTok ( type_ , value ) : [EOL] return BuiltToken ( type_ = type_ , value = value , parents = None ) [EOL] [EOL] [EOL] @ pytest . fixture ( ) def state ( ) : [EOL] if do_output : [EOL] global_font_state = GlobalFontState ( search_paths = [ font_path ] ) [EOL] else : [EOL] global_font_state = DummyGlobalFontState ( ) [EOL] state = GlobalState . from_defaults ( global_font_state = global_font_state ) [EOL] font_id = state . load_new_font ( file_name = [string] , at_clause = None ) [EOL] state . _select_font ( is_global = True , font_id = font_id ) [EOL] return state [EOL] [EOL] [EOL] def write ( state , file_name ) : [EOL] if do_output : [EOL] write_to_dvi_file ( state , file_name , write_pdf = True ) [EOL] [EOL] [EOL] def nr_tok ( n ) : [EOL] v = BTok ( type_ = [string] , value = n ) [EOL] return BTok ( type_ = [string] , value = v ) [EOL] [EOL] [EOL] class DummyTokenQueue : [EOL] [EOL] def replace_tokens_on_input ( self , tokens ) : [EOL] pass [EOL] [EOL] [EOL] def test_single_letter ( state ) : [EOL] state . do_indent ( ) [EOL] state . add_character_char ( [string] ) [EOL] state . do_paragraph ( ) [EOL] assert len ( state . modes ) == [number] [EOL] assert state . mode == Mode . vertical [EOL] lst = state . current_page [EOL] assert len ( lst ) == [number] [EOL] assert isinstance ( lst [ [number] ] , box . FontDefinition ) [EOL] assert isinstance ( lst [ [number] ] , box . FontSelection ) [EOL] assert isinstance ( lst [ [number] ] , box . HBox ) [EOL] hbox = lst [ [number] ] [EOL] assert isinstance ( hbox . contents [ [number] ] , box . HBox ) [EOL] assert isinstance ( hbox . contents [ [number] ] , box . Character ) [EOL] write ( state , [string] ) [EOL] [EOL] [EOL] def test_solo_accent ( state ) : [EOL] state . do_indent ( ) [EOL] state . do_accent ( accent_code = [number] , target_code = None ) [EOL] state . do_paragraph ( ) [EOL] write ( state , [string] ) [EOL] [EOL] [EOL] def test_paired_accent ( state ) : [EOL] state . do_indent ( ) [EOL] state . do_accent ( accent_code = [number] , target_code = ord ( [string] ) ) [EOL] state . do_accent ( accent_code = [number] , target_code = ord ( [string] ) ) [EOL] state . add_character_char ( [string] ) [EOL] state . add_character_char ( [string] ) [EOL] state . do_paragraph ( ) [EOL] write ( state , [string] ) [EOL] [EOL] [EOL] def test_v_rule ( state ) : [EOL] state . push_mode ( Mode . horizontal ) [EOL] state . add_v_rule ( width = int ( [number] ) , height = int ( [number] ) , depth = [number] ) [EOL] state . add_v_rule ( width = int ( [number] ) , height = int ( [number] ) , depth = int ( [number] ) ) [EOL] state . do_paragraph ( ) [EOL] assert len ( state . modes ) == [number] [EOL] assert state . mode == Mode . vertical [EOL] lst = state . current_page [EOL] assert isinstance ( lst [ [number] ] , box . HBox ) [EOL] h_box = lst [ [number] ] [EOL] assert isinstance ( h_box . contents [ [number] ] , box . Rule ) [EOL] assert isinstance ( h_box . contents [ [number] ] , box . Rule ) [EOL] write ( state , [string] ) [EOL] [EOL] [EOL] def test_if_num ( state ) : [EOL] assert state . evaluate_if_num ( [number] , [number] , [string] ) [EOL] assert state . evaluate_if_num ( [number] , [number] , [string] ) [EOL] assert not state . evaluate_if_num ( - [number] , - [number] , [string] ) [EOL] [EOL] [EOL] def test_if_dimen ( state ) : [EOL] assert state . evaluate_if_dim ( [number] , [number] , [string] ) [EOL] assert state . evaluate_if_dim ( [number] , [number] , [string] ) [EOL] assert not state . evaluate_if_dim ( - [number] , - [number] , [string] ) [EOL] [EOL] [EOL] def test_if_odd ( state ) : [EOL] assert not state . evaluate_if_odd ( [number] ) [EOL] assert state . evaluate_if_odd ( [number] ) [EOL] assert not state . evaluate_if_odd ( - [number] ) [EOL] assert state . evaluate_if_odd ( - [number] ) [EOL] assert not state . evaluate_if_odd ( [number] ) [EOL] [EOL] [EOL] def test_if_mode ( state ) : [EOL] assert state . evaluate_if_v_mode ( ) [EOL] assert not state . evaluate_if_h_mode ( ) [EOL] assert not state . evaluate_if_m_mode ( ) [EOL] assert not state . evaluate_if_inner_mode ( ) [EOL] state . do_indent ( ) [EOL] assert not state . evaluate_if_v_mode ( ) [EOL] assert state . evaluate_if_h_mode ( ) [EOL] assert not state . evaluate_if_m_mode ( ) [EOL] assert not state . evaluate_if_inner_mode ( ) [EOL] [EOL] [EOL] def test_if_case ( state ) : [EOL] assert state . evaluate_if_case ( [number] ) == [number] [EOL] assert state . evaluate_if_case ( [number] ) == [number] [EOL] with pytest . raises ( ValueError ) : [EOL] state . evaluate_if_case ( - [number] ) [EOL] [EOL] [EOL] def test_set_box ( state ) : [EOL] box_item = box . HBox ( contents = [ ] ) [EOL] state . set_box_register ( token_source = None , i = [number] , item = box_item , is_global = False ) [EOL] state . append_register_box ( i = [number] , copy = False ) [EOL] lst = state . current_page [EOL] assert lst [ - [number] ] . contents is box_item . contents [EOL] [EOL] [EOL] def test_set_box_void ( state ) : [EOL] nr_elems_before = len ( state . current_page ) [EOL] state . append_register_box ( i = [number] , copy = False ) [EOL] nr_elems_after = len ( state . current_page ) [EOL] assert nr_elems_before == nr_elems_after [EOL] [EOL] [EOL] def test_unbox ( state ) : [EOL] box_item = box . VBox ( [ box . HBox ( [ box . Glue ( [number] ) , ] ) , box . Glue ( [number] ) , ] ) [EOL] [EOL] i_reg = [number] [EOL] state . set_box_register ( token_source = None , i = i_reg , item = box_item , is_global = False ) [EOL] nr_elems_before = len ( state . current_page ) [EOL] state . append_unboxed_register_v_box ( i = i_reg , copy = True ) [EOL] nr_elems_after = len ( state . current_page ) [EOL] assert nr_elems_after == nr_elems_before + [number] [EOL] unboxed_contents = state . get_unboxed_register_box ( i = i_reg , copy = False , horizontal = False ) [EOL] inner_glue = unboxed_contents [ [number] ] . contents [ [number] ] [EOL] assert isinstance ( inner_glue , box . Glue ) [EOL] assert inner_glue . is_set [EOL] [EOL] outer_glue = unboxed_contents [ [number] ] [EOL] assert isinstance ( outer_glue , box . Glue ) [EOL] assert not outer_glue . is_set [EOL] [EOL] [comment] [EOL] assert state . get_register_box ( i = i_reg , copy = False ) is None [EOL] [EOL] [EOL] def test_unbox_bad_box_type ( state ) : [EOL] box_item = box . HBox ( contents = [ box . Rule ( [number] , [number] , [number] ) , box . Rule ( [number] , [number] , [number] ) ] ) [EOL] state . set_box_register ( token_source = None , i = [number] , item = box_item , is_global = False ) [EOL] with pytest . raises ( UserError ) : [EOL] state . append_unboxed_register_v_box ( i = [number] , copy = False ) [EOL] [EOL] [EOL] def test_get_box_dimen ( state ) : [EOL] box_item = box . HBox ( contents = [ ] , to = [number] ) [EOL] state . set_box_register ( token_source = None , i = [number] , item = box_item , is_global = False ) [EOL] b = state . get_box_dimen ( i = [number] , type_ = Instructions . box_dimen_width . value ) [EOL] assert b == [number] [EOL] [EOL] [EOL] def test_space_factor ( state ) : [EOL] state . do_indent ( ) [EOL] a_sf = [number] [EOL] state . codes . set ( code_type = Instructions . space_factor_code . value , char = [string] , code = a_sf , is_global = False ) [EOL] state . codes . set ( code_type = Instructions . space_factor_code . value , char = [string] , code = [number] , is_global = False ) [EOL] [comment] [EOL] assert state . specials . get ( Specials . space_factor ) == [number] [EOL] [comment] [EOL] state . add_character_char ( [string] ) [EOL] assert state . specials . get ( Specials . space_factor ) == a_sf [EOL] [comment] [EOL] state . add_character_char ( [string] ) [EOL] assert state . specials . get ( Specials . space_factor ) == [number] [EOL] [comment] [EOL] [comment] [EOL] state . add_character_char ( [string] ) [EOL] state . add_v_rule ( [number] , [number] , [number] ) [EOL] assert state . specials . get ( Specials . space_factor ) == [number] [EOL] [EOL] [EOL] def test_after_group ( state ) : [EOL] [comment] [EOL] [EOL] state . start_local_group ( ) [EOL] t_sp = ITok ( Instructions . space ) [EOL] state . push_to_after_group_queue ( t_sp ) [EOL] assert list ( state . after_group_queue ) == [ t_sp ] [EOL] [EOL] t_a = ITok ( Instructions . a ) [EOL] state . push_to_after_group_queue ( t_a ) [EOL] assert list ( state . after_group_queue ) == [ t_sp , t_a ] [EOL] [EOL] tok_source = DummyTokenQueue ( ) [EOL] [EOL] state . end_group ( tok_source ) [EOL] assert not state . after_group_queue [EOL] [EOL] [EOL] def test_after_group_scoped ( state ) : [EOL] [comment] [EOL] [EOL] state . start_local_group ( ) [EOL] t_sp = ITok ( Instructions . space ) [EOL] state . push_to_after_group_queue ( t_sp ) [EOL] assert list ( state . after_group_queue ) == [ t_sp ] [EOL] [EOL] [comment] [EOL] tok_source = DummyTokenQueue ( ) [EOL] [EOL] state . start_local_group ( ) [EOL] t_a = ITok ( Instructions . a ) [EOL] state . push_to_after_group_queue ( t_a ) [EOL] assert list ( state . after_group_queue ) == [ t_a ] [EOL] state . end_group ( tok_source ) [EOL] assert list ( state . after_group_queue ) == [ t_sp ] [EOL] [EOL] state . end_group ( tok_source ) [EOL] assert not state . after_group_queue [EOL] [EOL] [EOL] def test_token_executor ( state ) : [EOL] tok = CTok ( command = DummyCommands . verb , value = None ) [EOL] with pytest . raises ( ExecuteCommandError ) : [EOL] state . execute_command_token ( tok , banisher = None ) [EOL] with pytest . raises ( ExecuteCommandError ) : [EOL] state . execute_command_tokens ( iter ( [ tok ] ) , banisher = None ) [EOL] [EOL] [EOL] def test_command_token_set_box ( state ) : [EOL] i_reg = [number] [EOL] box_tok = BTok ( type_ = [string] , value = BTok ( type_ = [string] , value = { [string] : Instructions . h_box . value , [string] : [ ] , [string] : None } ) ) [EOL] set_box_tok = CTok ( command = Commands . assign , value = BTok ( type_ = Instructions . set_box . value , value = { [string] : box_tok , [string] : nr_tok ( i_reg ) , [string] : True , } ) ) [EOL] state . execute_command_token ( set_box_tok , banisher = None ) [EOL] [EOL] [EOL] def test_command_token_get_box ( state ) : [EOL] i_reg = [number] [EOL] [comment] [EOL] box_item = box . HBox ( contents = [ ] ) [EOL] state . set_box_register ( token_source = None , i = i_reg , item = box_item , is_global = False ) [EOL] [EOL] get_box_tok = CTok ( command = Commands . add_box , value = BTok ( type_ = [string] , value = { [string] : Instructions . box . value , [string] : nr_tok ( i_reg ) , } ) ) [EOL] state . execute_command_token ( get_box_tok , banisher = None ) [EOL] lst = state . current_page [EOL] assert lst [ - [number] ] . contents is box_item . contents [EOL] state . get_register_box ( i = i_reg , copy = False ) is None [EOL] [EOL] [EOL] def test_command_token_add_h_rule ( state ) : [EOL] add_h_rule_tok = CTok ( command = Commands . add_horizontal_rule , value = { [string] : None , [string] : None , [string] : None } ) [EOL] state . execute_command_token ( add_h_rule_tok , banisher = None ) [EOL] lst = state . current_page [EOL] assert len ( lst ) == [number] [EOL] assert isinstance ( lst [ [number] ] , box . Rule ) [EOL] rule = lst [ [number] ] [EOL] assert rule . width == [number] [EOL] assert rule . depth == [number] [EOL] assert rule . height > [number] [EOL] [EOL] [EOL] def test_command_token_code_assignment ( state ) : [EOL] sf_variable = BTok ( type_ = Instructions . space_factor_code . value , value = nr_tok ( ord ( [string] ) ) ) [EOL] set_sf_tok = CTok ( command = Commands . assign , value = BTok ( type_ = [string] , value = { [string] : sf_variable , [string] : nr_tok ( [number] ) , [string] : True } ) ) [EOL] state . execute_command_token ( set_sf_tok , banisher = None ) [EOL] assert state . codes . get_space_factor_code ( [string] ) == [number] [EOL] [EOL] [EOL] def test_command_token_unbox ( state ) : [EOL] i_reg = [number] [EOL] box_item = box . VBox ( contents = [ box . Rule ( [number] , [number] , [number] ) , box . Rule ( [number] , [number] , [number] ) ] ) [EOL] state . set_box_register ( token_source = None , i = i_reg , item = box_item , is_global = False ) [EOL] nr_elems_before = len ( state . current_page ) [EOL] [EOL] get_box_tok = CTok ( command = Commands . unpack_vertical_box , value = { [string] : nr_tok ( i_reg ) , [string] : Instructions . un_v_copy } ) [EOL] state . execute_command_token ( get_box_tok , banisher = None ) [EOL] nr_elems_after = len ( state . current_page ) [EOL] assert nr_elems_after == nr_elems_before + [number] [EOL] [comment] [EOL] state . get_register_box ( i = i_reg , copy = False ) [EOL] [EOL] [EOL] def test_command_token_message ( state ) : [EOL] message_tok = CTok ( command = Commands . message , value = { [string] : [ ] } ) [EOL] err_message_tok = CTok ( command = Commands . error_message , value = { [string] : [ ] } ) [EOL] state . execute_command_token ( message_tok , banisher = None ) [EOL] state . execute_command_token ( err_message_tok , banisher = None ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List [EOL] import typing [EOL] import pytest [EOL] [EOL] from nex . parsing import parsing [EOL] [EOL] from common import str_to_toks as stoks , str_to_lit_str [EOL] [EOL] [EOL] def test_numbers ( ) : [EOL] parser = parsing . get_parser ( start = [string] , chunking = False ) [EOL] [EOL] def p ( s ) : [EOL] return parser . parse ( iter ( stoks ( s ) ) ) [EOL] [EOL] def basic_check ( r ) : [EOL] assert r . type == [string] [EOL] sgns , sz = r . value [ [string] ] , r . value [ [string] ] [EOL] assert sz . type == [string] [EOL] return sgns , sz [EOL] [EOL] r = p ( [string] ) [EOL] sgns , sz = basic_check ( r ) [EOL] assert len ( sgns . value ) == [number] [EOL] szv = sz . value [EOL] assert szv . type == [string] [EOL] dig_collect = szv . value [EOL] assert dig_collect . base == [number] [EOL] [EOL] number_makers = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] [EOL] for number_maker in number_makers : [EOL] r = p ( number_maker ) [EOL] basic_check ( r ) [EOL] [EOL] s = [string] [EOL] for number_maker in number_makers : [EOL] cs = [string] . join ( [ s , number_maker ] ) [EOL] r = p ( cs ) [EOL] basic_check ( r ) [EOL] [EOL] [EOL] def test_dimens ( ) : [EOL] parser = parsing . get_parser ( start = [string] , chunking = False ) [EOL] parser . parse ( iter ( stoks ( f' [string] { str_to_lit_str ( [string] ) }' ) ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Set [EOL] import typing [EOL] import pytest [EOL] [EOL] from nex . dampf . utils import ( get_bytes_needed , is_signed_nr_expressible_in_n_bits ) [EOL] [EOL] [EOL] max_bits_we_can_use = [number] * [number] [EOL] [EOL] [comment] [EOL] [comment] [EOL] test_ints = list ( range ( [number] ** [number] ) ) [EOL] [comment] [EOL] test_ints += [ [number] ** i for i in range ( max_bits_we_can_use + [number] ) ] [EOL] [comment] [EOL] test_ints += [ n + [number] for n in test_ints ] + [ n - [number] for n in test_ints ] [EOL] [comment] [EOL] test_ints += [ - n for n in test_ints ] [EOL] [comment] [EOL] test_ints = set ( test_ints ) [EOL] [EOL] [EOL] def _test ( signed , n ) : [EOL] [comment] [EOL] if not is_signed_nr_expressible_in_n_bits ( n , max_bits_we_can_use ) : [EOL] with pytest . raises ( ValueError ) : [EOL] get_bytes_needed ( n , signed ) [EOL] [comment] [EOL] elif not signed and n < [number] : [EOL] with pytest . raises ( ValueError ) : [EOL] get_bytes_needed ( n , signed ) [EOL] [comment] [EOL] else : [EOL] nr_bytes = get_bytes_needed ( n , signed ) [EOL] n . to_bytes ( length = nr_bytes , byteorder = [string] , signed = signed ) [EOL] [EOL] if nr_bytes > [number] : [EOL] nr_bytes_one_smaller = nr_bytes - [number] [EOL] with pytest . raises ( OverflowError ) : [EOL] n . to_bytes ( length = nr_bytes_one_smaller , byteorder = [string] , signed = signed ) [EOL] [EOL] [EOL] def test_bytes_needed ( ) : [EOL] for signed in ( True , False ) : [EOL] for n in test_ints : [EOL] _test ( signed , n ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $typing.Set[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Set[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 $typing.Set[builtins.int]$ 0 0 0 0 0 0 0 0 $typing.Set[builtins.int]$ 0 0 0 0 0 0 0 0 0 $typing.Set[builtins.int]$ 0 0 0 0 $typing.Set[builtins.int]$ 0 0 0 0 0 0 0 $typing.Set[builtins.int]$ 0 0 0 0 $typing.Set[builtins.int]$ 0 0 0 $typing.Set[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Set[builtins.int]$ 0 0 0 0 0 0 0 0 0
	0
from typing import Dict , List , Any , Tuple [EOL] import typing [EOL] import nex [EOL] import pytest [EOL] [EOL] from nex . constants . codes import CatCode [EOL] from nex . constants . instructions import Instructions [EOL] from nex . router import ( CSRouter , NoSuchControlSequence , make_unexpanded_control_sequence_instruction ) [EOL] [EOL] from common import DummyInstructions , DummyParameters , ITok , char_instr_tok [EOL] [EOL] dummy_token = make_unexpanded_control_sequence_instruction ( [string] , parents = None ) [EOL] [EOL] [EOL] def test_undefined_control_sequence ( ) : [EOL] r = CSRouter ( param_control_sequences = { } , special_control_sequences = { } , primitive_control_sequences = { } , enclosing_scope = None ) [EOL] with pytest . raises ( NoSuchControlSequence ) : [EOL] r . lookup_control_sequence ( name = [string] , parents = None ) [EOL] with pytest . raises ( NoSuchControlSequence ) : [EOL] r . do_let_assignment ( target_token = dummy_token , new_name = [string] ) [EOL] [EOL] [EOL] def test_primitive_resolution ( ) : [EOL] r = CSRouter ( param_control_sequences = { } , special_control_sequences = { } , primitive_control_sequences = { [string] : DummyInstructions . test } , enclosing_scope = None ) [EOL] t = r . lookup_control_sequence ( [string] , parents = None ) [EOL] assert t . value [ [string] ] == [string] [EOL] assert t . instruction == DummyInstructions . test [EOL] [EOL] [EOL] def test_parameter_resolution ( ) : [EOL] pcs = { [string] : ( DummyParameters . ptest , DummyInstructions . test ) } [EOL] r = CSRouter ( param_control_sequences = pcs , special_control_sequences = { } , primitive_control_sequences = { } , enclosing_scope = None ) [EOL] t = r . lookup_control_sequence ( [string] , parents = None ) [EOL] assert t . value [ [string] ] == [string] [EOL] assert t . value [ [string] ] == DummyParameters . ptest [EOL] assert t . instruction == DummyInstructions . test [EOL] [EOL] [EOL] def test_macro_definition ( ) : [EOL] r = CSRouter ( param_control_sequences = { } , special_control_sequences = { } , primitive_control_sequences = { } , enclosing_scope = None ) [EOL] repl = [ ITok ( DummyInstructions . test ) ] [EOL] r . set_macro ( name = [string] , replacement_text = repl , parameter_text = [ ] , def_type = None , prefixes = None , parents = None ) [EOL] t = r . lookup_control_sequence ( [string] , parents = None ) [EOL] assert t . value [ [string] ] == [string] [EOL] assert t . value [ [string] ] == repl [EOL] assert len ( t . value [ [string] ] ) == [number] [EOL] assert isinstance ( t . value [ [string] ] , set ) [EOL] [EOL] [EOL] def test_short_hand_macro_definition ( ) : [EOL] r = CSRouter ( param_control_sequences = { } , special_control_sequences = { } , primitive_control_sequences = { } , enclosing_scope = None ) [EOL] code = [number] [EOL] r . do_short_hand_definition ( [string] , def_type = Instructions . char_def . value , code = code , cmd_parents = None , target_parents = None ) [EOL] t = r . lookup_control_sequence ( [string] , parents = None ) [EOL] assert t . value [ [string] ] == [string] [EOL] assert t . value [ [string] ] == [string] [EOL] assert len ( t . value [ [string] ] ) == [number] [EOL] tok = t . value [ [string] ] [ [number] ] [EOL] assert tok . value == code [EOL] assert tok . instruction == Instructions . char_def_token [EOL] [EOL] [EOL] def test_let_to_macro ( ) : [EOL] r = CSRouter ( param_control_sequences = { } , special_control_sequences = { } , primitive_control_sequences = { } , enclosing_scope = None ) [EOL] code = [number] [EOL] r . do_short_hand_definition ( [string] , def_type = Instructions . char_def . value , code = code , cmd_parents = None , target_parents = None ) [EOL] t = r . lookup_control_sequence ( [string] , parents = None ) [EOL] r . do_let_assignment ( [string] , t ) [EOL] t_let = r . lookup_control_sequence ( [string] , parents = None ) [EOL] [EOL] assert t . value [ [string] ] == [string] [EOL] assert t_let . value [ [string] ] == [string] [EOL] assert t_let . instruction == t . instruction [EOL] assert t_let . value [ [string] ] is t . value [ [string] ] [EOL] [EOL] [comment] [EOL] r . do_let_assignment ( [string] , t_let ) [EOL] t_even_newer = r . lookup_control_sequence ( [string] , parents = None ) [EOL] assert t_even_newer . value [ [string] ] == [string] [EOL] assert t_even_newer . instruction == t . instruction [EOL] assert t_even_newer . value [ [string] ] is t . value [ [string] ] [EOL] [EOL] [EOL] def test_let_to_primitive ( ) : [EOL] r = CSRouter ( param_control_sequences = { } , special_control_sequences = { } , primitive_control_sequences = { [string] : DummyInstructions . test } , enclosing_scope = None ) [EOL] t = r . lookup_control_sequence ( [string] , parents = None ) [EOL] r . do_let_assignment ( [string] , t ) [EOL] t_let = r . lookup_control_sequence ( [string] , parents = None ) [EOL] assert t . value [ [string] ] == [string] [EOL] assert t_let . value [ [string] ] == [string] [EOL] assert t_let . instruction == t . instruction [EOL] [EOL] [EOL] def test_let_to_parameter ( ) : [EOL] pcs = { [string] : ( DummyParameters . ptest , DummyInstructions . test ) } [EOL] r = CSRouter ( param_control_sequences = pcs , special_control_sequences = { } , primitive_control_sequences = { } , enclosing_scope = None ) [EOL] t = r . lookup_control_sequence ( [string] , parents = None ) [EOL] r . do_let_assignment ( [string] , t ) [EOL] t_let = r . lookup_control_sequence ( [string] , parents = None ) [EOL] assert t . value [ [string] ] == [string] [EOL] assert t_let . value [ [string] ] == [string] [EOL] assert t_let . instruction == t . instruction [EOL] assert t_let . value [ [string] ] == t . value [ [string] ] [EOL] [EOL] [EOL] def test_let_to_character ( ) : [EOL] r = CSRouter ( param_control_sequences = { } , special_control_sequences = { } , primitive_control_sequences = { } , enclosing_scope = None ) [EOL] targ = char_instr_tok ( [string] , CatCode . letter ) [EOL] r . do_let_assignment ( [string] , targ ) [EOL] t_let = r . lookup_control_sequence ( [string] , parents = None ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Dict , List [EOL] import typing [EOL] import tests [EOL] import nex [EOL] from string import ascii_letters [EOL] [EOL] import pytest [EOL] [EOL] from nex . pydvi . TeXUnit import pt2sp [EOL] from nex . constants . codes import CatCode [EOL] from nex . constants . parameters import Parameters [EOL] from nex . constants . instructions import Instructions [EOL] from nex . banisher import ( Banisher , get_token_representation_integer , get_str_representation_dimension , get_token_representation_dimension ) [EOL] from nex . router import ( Instructioner , make_unexpanded_control_sequence_instruction , make_macro_token ) [EOL] from nex . utils import ascii_characters , UserError [EOL] [EOL] from common import DummyInstructions , ITok , char_instr_tok [EOL] [EOL] [EOL] test_char_to_cat = { } [EOL] for c in ascii_characters : [EOL] test_char_to_cat [ c ] = CatCode . other [EOL] for c in ascii_letters : [EOL] test_char_to_cat [ c ] = CatCode . letter [EOL] test_char_to_cat . update ( { [string] : CatCode . escape , [string] : CatCode . space , [string] : CatCode . begin_group , [string] : CatCode . end_group , [string] : CatCode . end_of_line , } ) [EOL] [EOL] [EOL] class DummyCodes : [EOL] def __init__ ( self , char_to_cat ) : [EOL] if char_to_cat is None : [EOL] self . char_to_cat = test_char_to_cat . copy ( ) [EOL] else : [EOL] self . char_to_cat = char_to_cat [EOL] [EOL] def get_cat_code ( self , char ) : [EOL] return self . char_to_cat [ char ] [EOL] [EOL] def get_lower_case_code ( self , c ) : [EOL] return c . lower ( ) [EOL] [EOL] def get_upper_case_code ( self , c ) : [EOL] return c . upper ( ) [EOL] [EOL] [EOL] class DummyRouter : [EOL] [EOL] def __init__ ( self , cs_map ) : [EOL] self . cs_map = cs_map [EOL] [EOL] def lookup_control_sequence ( self , name , * args , ** kwargs ) : [EOL] canon_token = self . cs_map [ name ] [EOL] return canon_token . copy ( * args , ** kwargs ) [EOL] [EOL] def name_means_start_condition ( self , name ) : [EOL] return name in ( [string] , [string] ) [EOL] [EOL] def name_means_end_condition ( self , name ) : [EOL] return name == [string] [EOL] [EOL] def name_means_delimit_condition ( self , name ) : [EOL] return name in ( [string] , [string] ) [EOL] [EOL] [EOL] class DummyParameters : [EOL] [EOL] def __init__ ( self , param_map ) : [EOL] self . param_map = param_map [EOL] [EOL] def get ( self , name , * args , ** kwargs ) : [EOL] return self . param_map [ name ] [EOL] [EOL] [EOL] class DummyState : [EOL] [EOL] def __init__ ( self , char_to_cat , cs_map , param_map = None ) : [EOL] self . router = DummyRouter ( cs_map ) [EOL] self . parameters = DummyParameters ( param_map ) [EOL] self . codes = DummyCodes ( char_to_cat ) [EOL] [EOL] def evaluate_if_token_to_block ( self , tok ) : [EOL] if tok . type == Instructions . if_true . value : [EOL] return [number] [EOL] elif tok . type == Instructions . if_false . value : [EOL] return [number] [EOL] else : [EOL] raise Exception [EOL] [EOL] [EOL] def string_to_banisher ( s , cs_map , char_to_cat = None , param_map = None ) : [EOL] state = DummyState ( cs_map = cs_map , param_map = param_map , char_to_cat = char_to_cat ) [EOL] instructions = Instructioner . from_string ( resolve_cs_func = state . router . lookup_control_sequence , s = s , get_cat_code_func = state . codes . get_cat_code ) [EOL] return Banisher ( instructions , state , instructions . lexer . reader ) [EOL] [EOL] [EOL] def test_resolver ( ) : [EOL] cs_map = { [string] : ITok ( DummyInstructions . test ) , } [EOL] b = string_to_banisher ( [string] , cs_map ) [EOL] out = b . get_next_output_list ( ) [EOL] assert len ( out ) == [number] and out [ [number] ] . matches ( cs_map [ [string] ] ) [EOL] [EOL] [EOL] def test_empty_macro ( ) : [EOL] cs_map = { [string] : make_macro_token ( name = [string] , replacement_text = [ ] , parameter_text = [ ] , parents = None ) , } [EOL] b = string_to_banisher ( [string] , cs_map ) [EOL] out = b . _iterate ( ) [EOL] assert out is None [EOL] assert list ( b . instructions . advance_to_end ( ) ) == [ ] [EOL] [EOL] [EOL] def test_short_hand_def ( ) : [EOL] cs_map = { [string] : ITok ( Instructions . count_def ) , } [EOL] b = string_to_banisher ( [string] , cs_map ) [EOL] out = b . get_next_output_list ( ) [EOL] assert len ( out ) == [number] [EOL] assert out [ [number] ] . matches ( cs_map [ [string] ] ) [EOL] assert out [ [number] ] . value [ [string] ] == [string] [EOL] [EOL] [EOL] def test_def ( ) : [EOL] cs_map = { [string] : ITok ( Instructions . def_ ) , } [EOL] b = string_to_banisher ( [string] , cs_map ) [EOL] out = b . _iterate ( ) [EOL] assert len ( out ) == [number] [EOL] [EOL] [EOL] def test_let ( ) : [EOL] cs_map = { [string] : ITok ( Instructions . let ) , } [EOL] b_minimal = string_to_banisher ( [string] , cs_map ) [EOL] out_minimal = b_minimal . _iterate ( ) [EOL] assert len ( out_minimal ) == [number] [EOL] [EOL] b_equals = string_to_banisher ( [string] , cs_map ) [EOL] out_equals = b_equals . _iterate ( ) [EOL] assert len ( out_equals ) == [number] [EOL] [EOL] b_maximal = string_to_banisher ( [string] , cs_map ) [EOL] out_maximal = b_maximal . _iterate ( ) [EOL] assert len ( out_maximal ) == [number] [EOL] [EOL] [EOL] def test_toks_def_balanced ( ) : [EOL] cs_map = { [string] : ITok ( Instructions . token_parameter ) , } [EOL] b = string_to_banisher ( [string] , cs_map ) [EOL] out = b . _iterate ( ) [EOL] [comment] [EOL] [comment] [EOL] assert len ( out ) == [number] [EOL] [comment] [EOL] out = b . _iterate ( ) [EOL] assert len ( out ) == [number] [EOL] assert out [ - [number] ] . instruction == Instructions . balanced_text_and_right_brace [EOL] assert len ( out [ - [number] ] . value ) == [number] [EOL] [EOL] [EOL] def test_toks_assign_literal ( ) : [EOL] cs_map = { [string] : ITok ( Instructions . token_parameter ) , } [EOL] b = string_to_banisher ( [string] , cs_map ) [EOL] out = b . _iterate ( ) [EOL] [comment] [EOL] [comment] [EOL] assert len ( out ) == [number] [EOL] [comment] [EOL] out = b . _iterate ( ) [EOL] assert len ( out ) == [number] [EOL] assert out [ - [number] ] . instruction == Instructions . balanced_text_and_right_brace [EOL] assert len ( out [ - [number] ] . value ) == [number] [EOL] [EOL] [EOL] def test_toks_assign_variable ( ) : [EOL] cs_map = { [string] : ITok ( Instructions . token_parameter ) , [string] : ITok ( Instructions . token_parameter ) , } [EOL] b = string_to_banisher ( [string] , cs_map ) [EOL] out = b . _iterate ( ) [EOL] [comment] [EOL] [comment] [EOL] assert len ( out ) == [number] [EOL] [comment] [EOL] out = b . _iterate ( ) [EOL] assert len ( out ) == [number] [EOL] assert out [ - [number] ] . instruction == Instructions . token_parameter [EOL] [EOL] [EOL] def test_expand_after ( ) : [EOL] def_target = make_unexpanded_control_sequence_instruction ( [string] , parents = None ) [EOL] cs_map = { [string] : ITok ( Instructions . expand_after ) , [string] : ITok ( Instructions . count_def ) , [string] : make_macro_token ( name = [string] , replacement_text = [ def_target ] , parameter_text = [ ] , parents = None ) , } [EOL] [comment] [EOL] [comment] [EOL] b = string_to_banisher ( [string] , cs_map ) [EOL] out = b . get_next_output_list ( ) [EOL] assert len ( out ) == [number] [EOL] assert out [ [number] ] . matches ( cs_map [ [string] ] ) [EOL] assert out [ [number] ] . matches ( def_target ) [EOL] [EOL] [EOL] def test_string_control_sequence ( ) : [EOL] cs_map = { [string] : ITok ( Instructions . string ) , } [EOL] param_map = { Parameters . escape_char : ord ( [string] ) , } [EOL] b = string_to_banisher ( [string] , cs_map , param_map = param_map ) [EOL] out = b . get_next_output_list ( ) [EOL] assert all ( t . value [ [string] ] == CatCode . other for t in out ) [EOL] assert [string] . join ( t . value [ [string] ] for t in out ) == [string] [EOL] [EOL] [EOL] def test_string_character ( ) : [EOL] cs_map = { [string] : ITok ( Instructions . string ) , } [EOL] param_map = { Parameters . escape_char : ord ( [string] ) , } [EOL] b = string_to_banisher ( [string] , cs_map , param_map = param_map ) [EOL] out = b . get_next_output_list ( ) [EOL] assert all ( t . value [ [string] ] == CatCode . other for t in out ) [EOL] assert [string] . join ( t . value [ [string] ] for t in out ) == [string] [EOL] [EOL] [EOL] def test_string_control_sequence_containing_space ( ) : [EOL] cs_map = { [string] : ITok ( Instructions . string ) , } [EOL] param_map = { Parameters . escape_char : ord ( [string] ) , } [EOL] char_to_cat_weird = test_char_to_cat . copy ( ) [EOL] char_to_cat_weird [ [string] ] = CatCode . letter [EOL] [EOL] b = string_to_banisher ( [string] , cs_map , char_to_cat = char_to_cat_weird , param_map = param_map ) [EOL] out = b . get_next_output_list ( ) [EOL] for t in out : [EOL] if t . value [ [string] ] == [string] : [EOL] correct_cat = CatCode . space [EOL] else : [EOL] correct_cat = CatCode . other [EOL] assert t . value [ [string] ] == correct_cat [EOL] assert [string] . join ( t . value [ [string] ] for t in out ) == [string] [EOL] [EOL] [EOL] def test_string_control_sequence_no_escape ( ) : [EOL] cs_map = { [string] : ITok ( Instructions . string ) , } [EOL] param_map = { Parameters . escape_char : - [number] , } [EOL] [EOL] b = string_to_banisher ( [string] , cs_map , param_map = param_map ) [EOL] out = b . get_next_output_list ( ) [EOL] assert all ( t . value [ [string] ] == CatCode . other for t in out ) [EOL] assert [string] . join ( t . value [ [string] ] for t in out ) == [string] [EOL] [EOL] [EOL] def test_cs_name ( ) : [EOL] char = [string] [EOL] a_token = char_instr_tok ( char , CatCode . letter ) [EOL] make_A_token = make_macro_token ( name = [string] , replacement_text = [ a_token ] , parameter_text = [ ] , parents = None ) [EOL] cs_map = { [string] : ITok ( Instructions . cs_name ) , [string] : ITok ( Instructions . end_cs_name ) , [string] : make_A_token , } [EOL] [EOL] b = string_to_banisher ( [string] , cs_map ) [EOL] [comment] [EOL] [comment] [EOL] out = b . get_next_output_list ( ) [EOL] assert len ( out ) == [number] [EOL] assert out [ [number] ] . matches ( a_token ) [EOL] [EOL] [EOL] def test_cs_name_end_by_expansion ( ) : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] char = [string] [EOL] F_token = char_instr_tok ( char , CatCode . letter ) [EOL] cs_name = [string] [EOL] the_F_then_end_token = make_macro_token ( name = [string] , replacement_text = ( [ char_instr_tok ( c , CatCode . letter ) for c in cs_name ] + [ ITok ( Instructions . end_cs_name ) ] ) , parameter_text = [ ] , parents = None , ) [EOL] make_F_token = make_macro_token ( name = [string] , replacement_text = [ F_token ] , parameter_text = [ ] , parents = None ) [EOL] cs_map = { [string] : ITok ( Instructions . cs_name ) , [string] : the_F_then_end_token , [string] : make_F_token , } [EOL] [EOL] b = string_to_banisher ( [string] , cs_map ) [EOL] [comment] [EOL] [comment] [EOL] out = b . get_next_output_list ( ) [EOL] assert len ( out ) == [number] [EOL] assert out [ [number] ] . matches ( F_token ) [EOL] [EOL] [EOL] def test_cs_name_containing_non_char ( ) : [EOL] cs_map = { [string] : ITok ( Instructions . cs_name ) , [string] : ITok ( Instructions . end_cs_name ) , [string] : ITok ( DummyInstructions . test ) , } [EOL] [EOL] b = string_to_banisher ( [string] , cs_map ) [EOL] with pytest . raises ( UserError ) : [EOL] b . get_next_output_list ( ) [EOL] [EOL] [EOL] def test_change_case ( ) : [EOL] B_token = char_instr_tok ( [string] , CatCode . letter ) [EOL] make_B_token = make_macro_token ( name = [string] , replacement_text = [ B_token ] , parameter_text = [ ] , parents = None ) [EOL] y_token = char_instr_tok ( [string] , CatCode . letter ) [EOL] make_y_token = make_macro_token ( name = [string] , replacement_text = [ y_token ] , parameter_text = [ ] , parents = None ) [EOL] [EOL] cs_map = { [string] : ITok ( Instructions . upper_case ) , [string] : ITok ( Instructions . lower_case ) , [string] : make_B_token , [string] : make_y_token , } [EOL] [EOL] b = string_to_banisher ( [string] , cs_map ) [EOL] out = b . advance_to_end ( ) [EOL] assert [string] . join ( t . value [ [string] ] for t in out ) == [string] [EOL] [EOL] b = string_to_banisher ( [string] , cs_map ) [EOL] out = b . advance_to_end ( ) [EOL] assert [string] . join ( t . value [ [string] ] for t in out ) == [string] [EOL] [EOL] b = string_to_banisher ( [string] , cs_map ) [EOL] out = b . advance_to_end ( ) [EOL] assert [string] . join ( t . value [ [string] ] for t in out ) == [string] [EOL] [EOL] b = string_to_banisher ( [string] , cs_map ) [EOL] out = b . advance_to_end ( ) [EOL] assert [string] . join ( t . value [ [string] ] for t in out ) == [string] [EOL] [EOL] [EOL] def test_if ( ) : [EOL] cs_map = { [string] : ITok ( Instructions . if_true ) , [string] : ITok ( Instructions . if_false ) , [string] : ITok ( Instructions . else_ ) , [string] : ITok ( Instructions . end_if ) , } [EOL] [EOL] b = string_to_banisher ( [string] , cs_map ) [EOL] out = b . advance_to_end ( ) [EOL] assert [string] . join ( t . value [ [string] ] for t in out ) == [string] [EOL] [EOL] b = string_to_banisher ( [string] , cs_map ) [EOL] out = b . advance_to_end ( ) [EOL] assert [string] . join ( t . value [ [string] ] for t in out ) == [string] [EOL] [EOL] [EOL] def test_afters ( ) : [EOL] cs_map = { [string] : ITok ( Instructions . after_assignment ) , [string] : ITok ( Instructions . after_group ) , } [EOL] for cs in cs_map : [EOL] b = string_to_banisher ( f' [string] { cs } [string] ' , cs_map ) [EOL] out = b . get_next_output_list ( ) [EOL] assert len ( out ) == [number] [EOL] assert out [ [number] ] . matches ( cs_map [ cs ] ) [EOL] assert out [ [number] ] . instruction == Instructions . arbitrary_token [EOL] target_tok = out [ [number] ] . value [EOL] assert target_tok . value [ [string] ] == [string] [EOL] [EOL] [EOL] def test_input ( ) : [EOL] cs_map = { [string] : ITok ( Instructions . input ) , } [EOL] b = string_to_banisher ( [string] , cs_map ) [EOL] out = list ( b . advance_to_end ( ) ) [EOL] print ( out ) [EOL] [EOL] [EOL] def test_integer_tokenize ( ) : [EOL] ts = get_token_representation_integer ( - [number] , parents = None ) [EOL] assert len ( ts ) == [number] [EOL] assert ts [ [number] ] . value [ [string] ] == [string] and ts [ [number] ] . value [ [string] ] == CatCode . other [EOL] assert ts [ [number] ] . value [ [string] ] == [string] and ts [ [number] ] . value [ [string] ] == CatCode . other [EOL] assert ts [ [number] ] . value [ [string] ] == [string] and ts [ [number] ] . value [ [string] ] == CatCode . other [EOL] [EOL] [EOL] def test_dimension_tokenize ( ) : [EOL] ts = get_token_representation_dimension ( pt2sp ( - [number] ) , parents = None ) [EOL] assert len ( ts ) == [number] [EOL] assert [string] . join ( t . value [ [string] ] for t in ts ) == [string] [EOL] assert all ( t . value [ [string] ] == CatCode . other for t in ts ) [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $tests.test_banisher.DummyRouter$ 0 0 0 0 0 0 0 0 $tests.test_banisher.DummyParameters$ 0 0 0 0 0 0 0 0 $tests.test_banisher.DummyCodes$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0