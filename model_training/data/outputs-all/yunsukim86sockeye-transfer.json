[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from contrib . sacrebleu . sacrebleu import raw_corpus_bleu , compute_bleu , corpus_chrf , CHRF_ORDER , CHRF_BETA , sentence_bleu , sentence_chrf	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] __version__ = [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Tuple , Literal , Any , Dict [EOL] import typing [EOL] import io [EOL] import argparse [EOL] import typing_extensions [EOL] [docstring] [EOL] import argparse [EOL] import os [EOL] [EOL] try : [comment] [EOL] from PIL import Image [comment] [EOL] except ImportError as e : [EOL] raise RuntimeError ( [string] ) [EOL] [EOL] try : [comment] [EOL] import matplotlib [comment] [EOL] except ImportError as e : [EOL] raise RuntimeError ( [string] ) [EOL] matplotlib . use ( [string] ) [EOL] import matplotlib . pyplot as plt [EOL] [EOL] [EOL] def format_text_for_visualization ( c , n ) : [EOL] c = c . split ( [string] ) [EOL] c [ [number] ] = c [ [number] ] . title ( ) [EOL] out = [string] [EOL] for j in range ( [number] , len ( c ) ) : [EOL] out += c [ j ] [EOL] if j == len ( c ) - [number] : [EOL] out += [string] [EOL] else : [EOL] if ( j + [number] ) % n == [number] : [EOL] out += [string] [EOL] else : [EOL] out += [string] [EOL] return out [EOL] [EOL] def main ( ) : [EOL] params = argparse . ArgumentParser ( description = [string] [string] ) [EOL] params . add_argument ( [string] , [string] , help = [string] [string] ) [EOL] params . add_argument ( [string] , [string] , help = [string] [string] ) [EOL] params . add_argument ( [string] , [string] , help = [string] [string] ) [EOL] params . add_argument ( [string] , [string] , default = None , help = [string] [string] ) [EOL] params . add_argument ( [string] , [string] , default = None , help = [string] ) [EOL] params . add_argument ( [string] , [string] , default = [number] , help = [string] ) [EOL] params . add_argument ( [string] , [string] , default = [number] , help = [string] [string] ) [EOL] args = params . parse_args ( ) [EOL] [EOL] skip = args . skip_images [EOL] N = M = args . number_of_columns [EOL] [EOL] [comment] [EOL] len_newline = [number] [EOL] fontsize = [number] [EOL] figsize = ( [number] , [number] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] fs = open ( args . source ) [EOL] fc = open ( args . prediction ) [EOL] predictions = { } [EOL] for s , c in zip ( fs . readlines ( ) , fc . readlines ( ) ) : [EOL] predictions [ s ] = c [comment] [EOL] fs . close ( ) [EOL] fc . close ( ) [EOL] [comment] [EOL] ground_truth = { } [EOL] if args . ground_truth is not None : [EOL] fgt = open ( args . ground_truth ) [EOL] fs = open ( args . source ) [EOL] for s , gt in zip ( fs . readlines ( ) , fgt . readlines ( ) ) : [EOL] if s in ground_truth : [EOL] ground_truth [ s ] . append ( gt ) [EOL] else : [EOL] ground_truth [ s ] = [ gt ] [EOL] fgt . close ( ) [EOL] fs . close ( ) [EOL] [EOL] [comment] [EOL] if args . save_to_folder is not None : [EOL] fontsize = [number] [EOL] if not os . path . exists ( args . save_to_folder ) : [EOL] os . makedirs ( args . save_to_folder ) [EOL] [EOL] [comment] [EOL] plt . ioff ( ) [EOL] fig , axs = plt . subplots ( N , M , figsize = figsize ) [EOL] fig . tight_layout ( ) [EOL] i = [number] [EOL] ii = [number] [EOL] for s in predictions . keys ( ) : [comment] [EOL] if ii % skip == [number] : [comment] [EOL] c = predictions [ s ] [EOL] if len ( ground_truth ) > [number] : [EOL] gts = ground_truth [ s ] [comment] [EOL] s = s . split ( [string] ) [ [number] ] [EOL] c = c . split ( [string] ) [ [number] ] [EOL] [comment] [EOL] image = Image . open ( os . path . join ( args . image_root , s ) ) [EOL] if [string] not in image . mode : [EOL] axs [ i // N % M , i % N ] . imshow ( image , cmap = [string] ) [EOL] else : [EOL] axs [ i // N % M , i % N ] . imshow ( image ) [EOL] [comment] [EOL] axs [ i // N % M , i % N ] . axis ( [string] ) [EOL] axs [ ( i + [number] ) // N % M , ( i + [number] ) % N ] . text ( [number] , [number] , format_text_for_visualization ( c , len_newline ) , fontsize = fontsize , bbox = { [string] : [string] , [string] : [number] , [string] : [number] } ) [EOL] [comment] [EOL] if len ( ground_truth ) > [number] : [EOL] gt_vis = [string] [EOL] for j , gt in enumerate ( gts ) : [EOL] gt = gt . split ( [string] ) [ [number] ] [EOL] gt_vis += [string] + format_text_for_visualization ( gt , len_newline ) + [string] [EOL] axs [ ( i + [number] ) // N % M , ( i + [number] ) % N ] . text ( [number] , [number] , gt_vis , fontsize = fontsize , bbox = { [string] : [string] , [string] : [number] , [string] : [number] } ) [EOL] axs [ ( i + [number] ) // N % M , ( i + [number] ) % N ] . axis ( [string] ) [EOL] i += [number] [EOL] [EOL] [comment] [EOL] if i % ( N * M ) == [number] : [EOL] if args . save_to_folder is None : [EOL] plt . show ( ) [EOL] else : [EOL] plt . savefig ( os . path . join ( args . save_to_folder , str ( ii ) . zfill ( [number] ) + [string] ) , bbox_inches = [string] ) [EOL] i = [number] [EOL] [comment] [EOL] for k in range ( N ) : [EOL] for j in range ( M ) : [EOL] axs [ k , j ] . cla ( ) [EOL] axs [ k , j ] . axis ( [string] ) [EOL] ii += [number] [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL] [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import logging [EOL] import logging [EOL] import random [EOL] [EOL] import pytest [EOL] [EOL] import sockeye . constants as C [EOL] from test . common import tmp_digits_dataset , run_train_translate [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] _TRAIN_LINE_COUNT = [number] [EOL] _DEV_LINE_COUNT = [number] [EOL] _LINE_MAX_LENGTH = [number] [EOL] _TEST_LINE_COUNT = [number] [EOL] _TEST_LINE_COUNT_EMPTY = [number] [EOL] _TEST_MAX_LENGTH = [number] [EOL] _SEED_TRAIN_DATA = [number] [EOL] _SEED_DEV_DATA = [number] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] seed = random . randint ( [number] , [number] ) [EOL] [EOL] [EOL] COMMON_TRAINING_PARAMS = [string] [string] [string] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [string] , [string] [string] [string] [string] [string] [string] [string] + COMMON_TRAINING_PARAMS , [string] , True , [number] , [number] ) , ( [string] , [string] [string] [string] [string] [string] + COMMON_TRAINING_PARAMS , [string] , False , [number] , [number] ) , ( [string] , [string] [string] [string] [string] [string] + COMMON_TRAINING_PARAMS , [string] , True , [number] , [number] ) , ( [string] , [string] [string] [string] [string] [string] [string] + COMMON_TRAINING_PARAMS , [string] , False , [number] , [number] ) , ( [string] , [string] [string] [string] [string] [string] [string] + COMMON_TRAINING_PARAMS , [string] , True , [number] , [number] ) , ( [string] , [string] [string] [string] [string] [string] + COMMON_TRAINING_PARAMS , [string] , False , [number] , [number] ) , ( [string] , [string] [string] [string] [string] + COMMON_TRAINING_PARAMS , [string] , True , [number] , [number] ) ] ) def test_seq_copy ( name , train_params , translate_params , use_prepared_data , perplexity_thresh , bleu_thresh ) : [EOL] [docstring] [EOL] with tmp_digits_dataset ( [string] , _TRAIN_LINE_COUNT , _LINE_MAX_LENGTH , _DEV_LINE_COUNT , _LINE_MAX_LENGTH , _TEST_LINE_COUNT , _TEST_LINE_COUNT_EMPTY , _TEST_MAX_LENGTH , seed_train = _SEED_TRAIN_DATA , seed_dev = _SEED_DEV_DATA ) as data : [EOL] [comment] [EOL] perplexity , bleu , bleu_restrict , chrf = run_train_translate ( train_params = train_params , translate_params = translate_params , translate_params_equiv = None , train_source_path = data [ [string] ] , train_target_path = data [ [string] ] , dev_source_path = data [ [string] ] , dev_target_path = data [ [string] ] , test_source_path = data [ [string] ] , test_target_path = data [ [string] ] , use_prepared_data = use_prepared_data , max_seq_len = _LINE_MAX_LENGTH + C . SPACE_FOR_XOS , restrict_lexicon = True , work_dir = data [ [string] ] , seed = seed ) [EOL] logger . info ( [string] , name ) [EOL] logger . info ( [string] , perplexity , bleu , bleu_restrict , chrf ) [EOL] assert perplexity <= perplexity_thresh [EOL] assert bleu >= bleu_thresh [EOL] assert bleu_restrict >= bleu_thresh [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [string] , [string] [string] [string] [string] [string] + COMMON_TRAINING_PARAMS , [string] , True , False , [number] , [number] ) , ( [string] , [string] [string] [string] [string] [string] + COMMON_TRAINING_PARAMS , [string] , False , False , [number] , [number] ) , ( [string] , [string] [string] [string] [string] [string] [string] [string] [string] + COMMON_TRAINING_PARAMS , [string] , True , False , [number] , [number] ) , ( [string] , [string] [string] [string] [string] [string] [string] [string] + COMMON_TRAINING_PARAMS , [string] , False , False , [number] , [number] ) , ( [string] , [string] [string] [string] [string] [string] [string] + COMMON_TRAINING_PARAMS , [string] , True , False , [number] , [number] ) , ( [string] , [string] [string] [string] [string] [string] [string] [string] + COMMON_TRAINING_PARAMS , [string] , True , True , [number] , [number] ) , ( [string] , [string] [string] [string] [string] + COMMON_TRAINING_PARAMS , [string] , False , False , [number] , [number] ) ] ) def test_seq_sort ( name , train_params , translate_params , use_prepared_data , use_source_factor , perplexity_thresh , bleu_thresh ) : [EOL] [docstring] [EOL] with tmp_digits_dataset ( [string] , _TRAIN_LINE_COUNT , _LINE_MAX_LENGTH , _DEV_LINE_COUNT , _LINE_MAX_LENGTH , _TEST_LINE_COUNT , _TEST_LINE_COUNT_EMPTY , _TEST_MAX_LENGTH , sort_target = True , seed_train = _SEED_TRAIN_DATA , seed_dev = _SEED_DEV_DATA , with_source_factors = use_source_factor ) as data : [EOL] [comment] [EOL] perplexity , bleu , bleu_restrict , chrf = run_train_translate ( train_params = train_params , translate_params = translate_params , translate_params_equiv = None , train_source_path = data [ [string] ] , train_target_path = data [ [string] ] , dev_source_path = data [ [string] ] , dev_target_path = data [ [string] ] , test_source_path = data [ [string] ] , test_target_path = data [ [string] ] , train_source_factor_paths = data . get ( [string] ) , dev_source_factor_paths = data . get ( [string] ) , test_source_factor_paths = data . get ( [string] ) , use_prepared_data = use_prepared_data , max_seq_len = _LINE_MAX_LENGTH + C . SPACE_FOR_XOS , restrict_lexicon = True , work_dir = data [ [string] ] , seed = seed ) [EOL] logger . info ( [string] , name ) [EOL] logger . info ( [string] , perplexity , bleu , bleu_restrict , chrf ) [EOL] assert perplexity <= perplexity_thresh [EOL] assert bleu >= bleu_thresh [EOL] assert bleu_restrict >= bleu_thresh [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] from typing import Tuple , Literal , List , Any [EOL] import typing [EOL] import typing_extensions [EOL] from unittest . mock import patch [EOL] [EOL] import mxnet as mx [EOL] import numpy as np [EOL] import pytest [EOL] import sockeye . coverage [EOL] from test . common import gaussian_vector , integer_vector , uniform_vector [EOL] [EOL] activation_types = [ [string] , [string] , [string] , [string] ] [EOL] [EOL] [EOL] def setup_module ( ) : [EOL] [comment] [EOL] _mask_with_one . original_sequence_mask = mx . sym . SequenceMask [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , activation_types ) def test_activation_coverage ( act_type ) : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] _patch_sequence_mask ( lambda : _test_activation_coverage ( act_type ) ) [EOL] [EOL] [EOL] def test_gru_coverage ( ) : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] _patch_sequence_mask ( lambda : _test_gru_coverage ( ) ) [EOL] [EOL] [EOL] def _test_activation_coverage ( act_type ) : [EOL] config_coverage = sockeye . coverage . CoverageConfig ( type = act_type , num_hidden = [number] , layer_normalization = False ) [EOL] encoder_num_hidden , decoder_num_hidden , source_seq_len , batch_size = [number] , [number] , [number] , [number] [EOL] [comment] [EOL] source = mx . sym . Variable ( [string] ) [EOL] [comment] [EOL] source_length = mx . sym . Variable ( [string] ) [EOL] [comment] [EOL] prev_hidden = mx . sym . Variable ( [string] ) [EOL] [comment] [EOL] prev_coverage = mx . sym . Variable ( [string] ) [EOL] [comment] [EOL] attention_scores = mx . sym . Variable ( [string] ) [EOL] source_shape = ( batch_size , source_seq_len , encoder_num_hidden ) [EOL] source_length_shape = ( batch_size , ) [EOL] prev_hidden_shape = ( batch_size , decoder_num_hidden ) [EOL] attention_scores_shape = ( batch_size , source_seq_len ) [EOL] prev_coverage_shape = ( batch_size , source_seq_len , config_coverage . num_hidden ) [EOL] source_data = gaussian_vector ( shape = source_shape ) [EOL] source_length_data = integer_vector ( shape = source_length_shape , max_value = source_seq_len ) [EOL] prev_hidden_data = gaussian_vector ( shape = prev_hidden_shape ) [EOL] prev_coverage_data = gaussian_vector ( shape = prev_coverage_shape ) [EOL] attention_scores_data = uniform_vector ( shape = attention_scores_shape ) [EOL] attention_scores_data = attention_scores_data / np . sum ( attention_scores_data ) [EOL] [EOL] coverage = sockeye . coverage . get_coverage ( config_coverage ) [EOL] coverage_func = coverage . on ( source , source_length , source_seq_len ) [EOL] updated_coverage = coverage_func ( prev_hidden , attention_scores , prev_coverage ) [EOL] executor = updated_coverage . simple_bind ( ctx = mx . cpu ( ) , source = source_shape , source_length = source_length_shape , prev_hidden = prev_hidden_shape , prev_coverage = prev_coverage_shape , attention_scores = attention_scores_shape ) [EOL] executor . arg_dict [ [string] ] [ : ] = source_data [EOL] executor . arg_dict [ [string] ] [ : ] = source_length_data [EOL] executor . arg_dict [ [string] ] [ : ] = prev_hidden_data [EOL] executor . arg_dict [ [string] ] [ : ] = prev_coverage_data [EOL] executor . arg_dict [ [string] ] [ : ] = attention_scores_data [EOL] result = executor . forward ( ) [EOL] new_coverage = result [ [number] ] . asnumpy ( ) [EOL] assert new_coverage . shape == prev_coverage_shape [EOL] [comment] [EOL] modulated = mx . nd . Activation ( mx . nd . zeros ( ( [number] , [number] ) ) , act_type = act_type ) . asnumpy ( ) [EOL] assert ( np . sum ( np . sum ( np . isclose ( new_coverage , modulated , atol = [number] ) , axis = [number] ) != [number] , axis = [number] ) == source_length_data ) . all ( ) [EOL] [EOL] [EOL] def _test_gru_coverage ( ) : [EOL] config_coverage = sockeye . coverage . CoverageConfig ( type = [string] , num_hidden = [number] , layer_normalization = False ) [EOL] encoder_num_hidden , decoder_num_hidden , source_seq_len , batch_size = [number] , [number] , [number] , [number] [EOL] [comment] [EOL] source = mx . sym . Variable ( [string] ) [EOL] [comment] [EOL] source_length = mx . sym . Variable ( [string] ) [EOL] [comment] [EOL] prev_hidden = mx . sym . Variable ( [string] ) [EOL] [comment] [EOL] prev_coverage = mx . sym . Variable ( [string] ) [EOL] [comment] [EOL] attention_scores = mx . sym . Variable ( [string] ) [EOL] source_shape = ( batch_size , source_seq_len , encoder_num_hidden ) [EOL] source_length_shape = ( batch_size , ) [EOL] prev_hidden_shape = ( batch_size , decoder_num_hidden ) [EOL] attention_scores_shape = ( batch_size , source_seq_len ) [EOL] prev_coverage_shape = ( batch_size , source_seq_len , config_coverage . num_hidden ) [EOL] source_data = gaussian_vector ( shape = source_shape ) [EOL] source_length_data = integer_vector ( shape = source_length_shape , max_value = source_seq_len ) [EOL] prev_hidden_data = gaussian_vector ( shape = prev_hidden_shape ) [EOL] prev_coverage_data = gaussian_vector ( shape = prev_coverage_shape ) [EOL] attention_scores_data = uniform_vector ( shape = attention_scores_shape ) [EOL] attention_scores_data = attention_scores_data / np . sum ( attention_scores_data ) [EOL] coverage = sockeye . coverage . get_coverage ( config_coverage ) [EOL] coverage_func = coverage . on ( source , source_length , source_seq_len ) [EOL] updated_coverage = coverage_func ( prev_hidden , attention_scores , prev_coverage ) [EOL] executor = updated_coverage . simple_bind ( ctx = mx . cpu ( ) , source = source_shape , source_length = source_length_shape , prev_hidden = prev_hidden_shape , prev_coverage = prev_coverage_shape , attention_scores = attention_scores_shape ) [EOL] executor . arg_dict [ [string] ] [ : ] = source_data [EOL] executor . arg_dict [ [string] ] [ : ] = source_length_data [EOL] executor . arg_dict [ [string] ] [ : ] = prev_hidden_data [EOL] executor . arg_dict [ [string] ] [ : ] = prev_coverage_data [EOL] executor . arg_dict [ [string] ] [ : ] = attention_scores_data [EOL] result = executor . forward ( ) [EOL] new_coverage = result [ [number] ] . asnumpy ( ) [EOL] assert new_coverage . shape == prev_coverage_shape [EOL] assert ( np . sum ( np . sum ( new_coverage != [number] , axis = [number] ) != [number] , axis = [number] ) == source_length_data ) . all ( ) [EOL] [EOL] [EOL] def _mask_with_one ( data , axis , use_sequence_length , sequence_length ) : [EOL] return _mask_with_one . original_sequence_mask ( data = data , axis = axis , use_sequence_length = use_sequence_length , sequence_length = sequence_length , value = [number] ) [EOL] [EOL] [EOL] def _patch_sequence_mask ( test ) : [EOL] [comment] [EOL] with patch . object ( mx , [string] , wraps = mx . sym ) as mxnet_mock : [EOL] [comment] [EOL] mxnet_mock . SequenceMask = _mask_with_one [EOL] test ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Any [EOL] import typing [EOL] import numpy as np [EOL] import pytest [EOL] [EOL] import sockeye . rerank as rerank [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [ [string] , [string] ] , [string] , [ [string] , [string] ] , [string] ) , ( [ [string] , [string] ] , [string] , [ [string] , [string] ] , [string] ) , ( [ [string] , [string] ] , [string] , [ [string] , [string] ] , [string] ) ] ) def test_rerank_hypotheses ( hypotheses , reference , expected_output , metric ) : [EOL] reranker = rerank . Reranker ( metric = metric , return_score = False ) [EOL] [EOL] reranked = reranker . rerank_hypotheses ( hypotheses , reference ) [EOL] actual_list = reranked . hypotheses [EOL] [EOL] assert actual_list == expected_output [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [ [string] , [string] ] , [string] , [ [number] , [number] , ] ) ] ) def test_rerank_return_score ( hypotheses , reference , expected_scores ) : [EOL] reranker = rerank . Reranker ( metric = [string] , return_score = True ) [EOL] [EOL] reranked_with_scores = reranker . rerank_hypotheses ( hypotheses , reference ) [EOL] [EOL] actual_scores = reranked_with_scores . scores [EOL] [EOL] assert np . allclose ( actual_scores , expected_scores ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [ [string] , [string] ] , [string] , [string] ) ] ) def test_rerank_top1 ( hypotheses , reference , expected_best ) : [EOL] reranker = rerank . Reranker ( metric = [string] , return_score = False ) [EOL] [EOL] reranked = reranker . rerank_top1 ( hypotheses , reference ) [EOL] [EOL] assert len ( reranked . hypotheses ) == [number] , [string] [EOL] actual_hypothesis = reranked . hypotheses [ [number] ] [EOL] [EOL] assert actual_hypothesis == expected_best [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [ [string] , [string] ] , [string] , [string] , [number] ) ] ) def test_rerank_top1_score ( hypotheses , reference , expected_best , expected_score ) : [EOL] reranker = rerank . Reranker ( metric = [string] , return_score = True ) [EOL] [EOL] reranked_with_scores = reranker . rerank_top1 ( hypotheses , reference ) [EOL] [EOL] assert len ( reranked_with_scores . hypotheses ) == [number] , [string] [EOL] actual_hypothesis = reranked_with_scores . hypotheses [ [number] ] [EOL] actual_score = reranked_with_scores . scores [ [number] ] [EOL] [EOL] assert actual_hypothesis == expected_best [EOL] assert np . isclose ( actual_score , expected_score ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import List , Any [EOL] import typing [EOL] import os [EOL] from tempfile import TemporaryDirectory [EOL] [EOL] import numpy as np [EOL] from PIL import Image [EOL] [EOL] import sockeye . image_captioning . utils as utils [EOL] [EOL] [EOL] def test_copy_mx_model_to ( ) : [EOL] model_path = [string] [EOL] model_epoch = [number] [EOL] [EOL] with TemporaryDirectory ( ) as work_dir : [EOL] [comment] [EOL] model_path = os . path . join ( work_dir , model_path ) [EOL] json_name = model_path + [string] [EOL] params_name = model_path + [string] % model_epoch [EOL] open ( json_name , [string] ) . close ( ) [EOL] open ( params_name , [string] ) . close ( ) [EOL] [EOL] with TemporaryDirectory ( ) as output_folder : [EOL] target_path = utils . copy_mx_model_to ( model_path , model_epoch , output_folder ) [EOL] assert os . path . exists ( target_path + [string] ) [EOL] assert os . path . exists ( target_path + [string] % model_epoch ) [EOL] [EOL] [EOL] def test_crop_resize_image ( ) : [EOL] image_size = [ [number] , [number] ] [EOL] imarray = np . random . rand ( [number] , [number] , [number] ) * [number] [EOL] image = Image . fromarray ( imarray . astype ( [string] ) ) [EOL] image_o = utils . crop_resize_image ( image , image_size ) [EOL] image_o = np . asarray ( image_o ) [EOL] [EOL] np . testing . assert_equal ( image_o . shape [ : [number] ] , image_size ) [EOL] [EOL] [EOL] def test_load_preprocess_images ( ) : [EOL] image_size = [ [number] , [number] , [number] ] [EOL] image_paths = [ [string] , [string] , [string] ] [EOL] [comment] [EOL] with TemporaryDirectory ( ) as work_dir : [EOL] filenames = [ ] [EOL] for s in image_paths : [EOL] filename = os . path . join ( work_dir , s ) [EOL] imarray = np . random . rand ( [number] , [number] , [number] ) * [number] [EOL] im = Image . fromarray ( imarray . astype ( [string] ) ) [EOL] im . save ( filename ) [EOL] filenames . append ( filename ) [EOL] [EOL] images = utils . load_preprocess_images ( filenames , image_size ) [EOL] assert len ( images ) == [number] [EOL] for img in images : [EOL] np . testing . assert_equal ( img . shape , image_size ) [EOL] [EOL] [EOL] def test_load_features ( ) : [EOL] feature_size = [ [number] , [number] ] [EOL] filenames = [ [string] , [string] , [string] , [string] ] [EOL] [comment] [EOL] with TemporaryDirectory ( ) as work_dir : [EOL] paths = [ ] [EOL] for s in filenames : [EOL] filename = os . path . join ( work_dir , s ) [EOL] data = np . random . rand ( * feature_size ) [EOL] np . save ( filename , data ) [EOL] paths . append ( filename ) [EOL] [EOL] feats = utils . load_features ( paths , feature_size ) [EOL] assert len ( feats ) == [number] [EOL] for f in feats : [EOL] np . testing . assert_equal ( f . shape , feature_size ) [EOL] [EOL] [EOL] def test_save_features ( ) : [EOL] feature_size = [ [number] , [number] ] [EOL] filenames = [ [string] , [string] , [string] ] [EOL] [comment] [EOL] datas = [ ] [EOL] for i in range ( len ( filenames ) ) : [EOL] datas . append ( np . random . rand ( * feature_size ) ) [EOL] [EOL] with TemporaryDirectory ( ) as work_dir : [EOL] paths = [ os . path . join ( work_dir , s ) for s in filenames ] [EOL] fnames = utils . save_features ( paths , datas ) [EOL] for i , f in enumerate ( fnames ) : [EOL] assert os . path . exists ( f ) > [number] [EOL] data = utils . load_feature ( f , feature_size ) [EOL] np . testing . assert_almost_equal ( datas [ i ] , data ) [EOL] [EOL] [comment] [EOL] with TemporaryDirectory ( ) as work_dir : [EOL] paths = [ os . path . join ( work_dir , s ) for s in filenames ] [EOL] fnames = utils . save_features ( paths , datas , compressed = True ) [EOL] for i , f in enumerate ( fnames ) : [EOL] assert os . path . exists ( f ) > [number] [EOL] data = utils . load_feature ( f , feature_size ) [EOL] np . testing . assert_almost_equal ( datas [ i ] , data ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Tuple , List [EOL] import typing [EOL] import builtins [EOL] [docstring] [EOL] [EOL] import pytest [EOL] import random [EOL] [EOL] import sockeye . constants as C [EOL] from test . common import run_train_translate , tmp_digits_dataset [EOL] [EOL] _TRAIN_LINE_COUNT = [number] [EOL] _DEV_LINE_COUNT = [number] [EOL] _TEST_LINE_COUNT = [number] [EOL] _TEST_LINE_COUNT_EMPTY = [number] [EOL] _LINE_MAX_LENGTH = [number] [EOL] _TEST_MAX_LENGTH = [number] [EOL] [EOL] ENCODER_DECODER_SETTINGS = [ ( [string] [string] [string] [string] [string] , [number] , [number] ) , ( [string] [string] [string] [string] [string] [string] [string] [string] , [number] , [number] ) ] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , ENCODER_DECODER_SETTINGS ) def test_constraints ( train_params , beam_size , batch_size ) : [EOL] [docstring] [EOL] [EOL] with tmp_digits_dataset ( prefix = [string] , train_line_count = _TRAIN_LINE_COUNT , train_max_length = _LINE_MAX_LENGTH , dev_line_count = _DEV_LINE_COUNT , dev_max_length = _LINE_MAX_LENGTH , test_line_count = _TEST_LINE_COUNT , test_line_count_empty = _TEST_LINE_COUNT_EMPTY , test_max_length = _TEST_MAX_LENGTH , sort_target = False ) as data : [EOL] [EOL] translate_params = [string] . format ( batch_size , beam_size ) [EOL] [EOL] [comment] [EOL] run_train_translate ( train_params = train_params , translate_params = translate_params , translate_params_equiv = None , train_source_path = data [ [string] ] , train_target_path = data [ [string] ] , dev_source_path = data [ [string] ] , dev_target_path = data [ [string] ] , test_source_path = data [ [string] ] , test_target_path = data [ [string] ] , max_seq_len = _LINE_MAX_LENGTH + C . SPACE_FOR_XOS , work_dir = data [ [string] ] , use_prepared_data = False , restrict_lexicon = False , use_target_constraints = True ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.int,builtins.int]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.int,builtins.int]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Tuple , List , Any [EOL] import typing [EOL] import builtins [EOL] import pytest [EOL] import random [EOL] [EOL] import sockeye . constants as C [EOL] from test . common import run_train_translate , tmp_digits_dataset [EOL] [EOL] _TRAIN_LINE_COUNT = [number] [EOL] _DEV_LINE_COUNT = [number] [EOL] _TEST_LINE_COUNT = [number] [EOL] _TEST_LINE_COUNT_EMPTY = [number] [EOL] _LINE_MAX_LENGTH = [number] [EOL] _TEST_MAX_LENGTH = [number] [EOL] [EOL] ENCODER_DECODER_SETTINGS = [ ( [string] [string] [string] [string] [string] , [string] , True , False , False ) , ( [string] [string] [string] [string] [string] , [string] , True , False , False ) , ( [string] [string] [string] [string] [string] [string] [string] [string] [string] [string] , [string] , False , True , True ) , ( [string] [string] [string] [string] [string] , [string] , False , False , False ) , ( [string] [string] [string] [string] [string] [string] [string] , [string] , False , True , False ) , ( [string] [string] [string] [string] [string] , [string] , False , True , False ) , ( [string] [string] [string] [string] [string] [string] [string] [string] , [string] , True , False , False ) , ( [string] [string] [string] [string] [string] [string] [string] , [string] , True , False , True ) , ( [string] [string] [string] [string] , [string] , True , False , False ) , ( [string] [string] [string] [string] [string] , [string] , True , False , False ) , ( [string] [string] [string] [string] [string] [string] [string] [string] , [string] , True , False , False ) ] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , ENCODER_DECODER_SETTINGS ) def test_seq_copy ( train_params , translate_params , restrict_lexicon , use_prepared_data , use_source_factors ) : [EOL] [docstring] [EOL] [EOL] with tmp_digits_dataset ( prefix = [string] , train_line_count = _TRAIN_LINE_COUNT , train_max_length = _LINE_MAX_LENGTH , dev_line_count = _DEV_LINE_COUNT , dev_max_length = _LINE_MAX_LENGTH , test_line_count = _TEST_LINE_COUNT , test_line_count_empty = _TEST_LINE_COUNT_EMPTY , test_max_length = _TEST_MAX_LENGTH , sort_target = False , with_source_factors = use_source_factors ) as data : [EOL] [EOL] [comment] [EOL] train_source_factor_paths , dev_source_factor_paths , test_source_factor_paths = None , None , None [EOL] if use_source_factors : [EOL] train_source_factor_paths = [ data [ [string] ] ] [EOL] dev_source_factor_paths = [ data [ [string] ] ] [EOL] test_source_factor_paths = [ data [ [string] ] ] [EOL] [EOL] [comment] [EOL] translate_params_batch = translate_params + [string] [EOL] [EOL] [comment] [EOL] run_train_translate ( train_params = train_params , translate_params = translate_params , translate_params_equiv = translate_params_batch , train_source_path = data [ [string] ] , train_target_path = data [ [string] ] , dev_source_path = data [ [string] ] , dev_target_path = data [ [string] ] , test_source_path = data [ [string] ] , test_target_path = data [ [string] ] , train_source_factor_paths = train_source_factor_paths , dev_source_factor_paths = dev_source_factor_paths , test_source_factor_paths = test_source_factor_paths , max_seq_len = _LINE_MAX_LENGTH + C . SPACE_FOR_XOS , restrict_lexicon = restrict_lexicon , work_dir = data [ [string] ] , use_prepared_data = use_prepared_data , use_target_constraints = False ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str,builtins.bool,builtins.bool,builtins.bool]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str,builtins.bool,builtins.bool,builtins.bool]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Tuple , Literal , List , Any [EOL] import typing [EOL] import builtins [EOL] import typing_extensions [EOL] import random [EOL] import string [EOL] [EOL] import pytest [EOL] [EOL] from test . common_image_captioning import run_extract_features_captioning , tmp_img_captioning_dataset [EOL] [EOL] IMAGE_ENCODER_SETTINGS = [ ( [string] ) , ( [string] ) , ] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , IMAGE_ENCODER_SETTINGS ) def test_caption_random_features ( layer ) : [EOL] source_image_size = ( [number] , [number] , [number] ) [EOL] batch_size = [number] [EOL] extract_params = [string] [string] . format ( s1 = source_image_size [ [number] ] , s2 = source_image_size [ [number] ] , s3 = source_image_size [ [number] ] , batch_size = batch_size , layer = layer ) [EOL] [EOL] [comment] [EOL] source_list = [ [string] . join ( random . choice ( string . ascii_uppercase ) for _ in range ( [number] ) ) for i in range ( [number] ) ] [EOL] prefix = [string] [EOL] use_features = False [EOL] with tmp_img_captioning_dataset ( source_list , prefix , train_max_length = [number] , dev_max_length = [number] , test_max_length = [number] , use_features = use_features ) as data : [EOL] source_files = [ data [ [string] ] , data [ [string] ] , data [ [string] ] ] [EOL] run_extract_features_captioning ( source_image_size = source_image_size , batch_size = batch_size , extract_params = extract_params , source_files = source_files , image_root = data [ [string] ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0