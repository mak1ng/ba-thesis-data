from typing import Any [EOL] import typing [EOL] import configparser [EOL] import zipfile [EOL] import pyspark [EOL] import builtins [EOL] import os [EOL] import zipfile [EOL] import configparser [EOL] from pyspark . sql import SQLContext [EOL] from pyspark . sql import SparkSession [EOL] from pyspark . sql import functions as F [EOL] from pyspark . sql import types as T [EOL] [EOL] from column_names import users , artists , songs [EOL] [EOL] config = configparser . ConfigParser ( ) [EOL] config . read ( [string] ) [EOL] [EOL] os . environ [ [string] ] = config [ [string] ] [ [string] ] [EOL] os . environ [ [string] ] = config [ [string] ] [ [string] ] [EOL] [EOL] [EOL] def create_spark_session ( ) : [EOL] spark = SparkSession . builder . config ( [string] , [string] ) . getOrCreate ( ) [EOL] return spark [EOL] [EOL] [EOL] def process_song_data ( spark , input_data , output_data ) : [EOL] [docstring] [EOL] [comment] [EOL] song_data = input_data + [string] [EOL] [EOL] [comment] [EOL] raw_song_df = spark . read . json ( song_data ) [EOL] print ( [string] ) [EOL] raw_song_df . printSchema ( ) [EOL] raw_song_df . show ( [number] , truncate = False ) [EOL] [EOL] [comment] [EOL] print ( [string] ) [EOL] print ( songs ) [EOL] songs_pyspark_df = raw_song_df . select ( [ col for col in songs . values ( ) ] ) [EOL] [EOL] [comment] [EOL] songs_pyspark_df = songs_pyspark_df . dropDuplicates ( [ [string] ] ) [EOL] print ( [string] ) [EOL] songs_pyspark_df . show ( ) [EOL] [EOL] [comment] [EOL] songs_pyspark_df . write . mode ( [string] ) . partitionBy ( [string] , [string] ) . parquet ( output_data + [string] ) [EOL] [EOL] [comment] [EOL] print ( [string] ) [EOL] print ( artists ) [EOL] artists_pyspark_df = raw_song_df . select ( [ col for col in artists . values ( ) ] ) [EOL] [EOL] [comment] [EOL] artists_pyspark_df = artists_pyspark_df . dropDuplicates ( [ [string] ] ) [EOL] print ( [string] ) [EOL] artists_pyspark_df . show ( ) [EOL] [EOL] [comment] [EOL] artists_pyspark_df . write . mode ( [string] ) . parquet ( output_data + [string] ) [EOL] [EOL] [EOL] def process_log_data ( spark , input_data , output_data ) : [EOL] sqlContext = SQLContext ( spark ) [EOL] [docstring] [EOL] [comment] [EOL] log_data = input_data + [string] [EOL] [EOL] [comment] [EOL] raw_log_df = spark . read . json ( log_data ) [EOL] print ( [string] ) [EOL] raw_log_df . printSchema ( ) [EOL] raw_log_df . show ( [number] , truncate = False ) [EOL] [EOL] [comment] [EOL] songplay_log_pyspark_df = raw_log_df . filter ( F . col ( [string] ) == [string] ) [EOL] songplay_log_pyspark_df . show ( ) [EOL] [EOL] [comment] [EOL] users_pyspark_df = raw_log_df . select ( [ col for col in users . values ( ) ] ) [EOL] [EOL] [comment] [EOL] users_pyspark_df = users_pyspark_df . dropDuplicates ( [ [string] ] ) [EOL] print ( [string] ) [EOL] users_pyspark_df . show ( [number] , truncate = False ) [EOL] [EOL] [comment] [EOL] users_pyspark_df . write . mode ( [string] ) . parquet ( output_data + [string] ) [EOL] [EOL] [comment] [EOL] tsFormat = [string] [EOL] [comment] [EOL] time_table = songplay_log_pyspark_df . withColumn ( [string] , F . to_timestamp ( F . date_format ( ( songplay_log_pyspark_df . ts / [number] ) . cast ( dataType = T . TimestampType ( ) ) , tsFormat ) , tsFormat ) ) [EOL] print ( [string] ) [EOL] time_table . printSchema ( ) [EOL] [EOL] [comment] [EOL] time_table = time_table . select ( F . col ( [string] ) . alias ( [string] ) , F . year ( F . col ( [string] ) ) . alias ( [string] ) , F . month ( F . col ( [string] ) ) . alias ( [string] ) , F . weekofyear ( F . col ( [string] ) ) . alias ( [string] ) , F . dayofmonth ( F . col ( [string] ) ) . alias ( [string] ) , F . hour ( F . col ( [string] ) ) . alias ( [string] ) ) [EOL] [EOL] [comment] [EOL] time_table = time_table . dropDuplicates ( [ [string] ] ) [EOL] print ( [string] ) [EOL] time_table . printSchema ( ) [EOL] time_table . show ( [number] ) [EOL] [EOL] [comment] [EOL] time_table . write . mode ( [string] ) . partitionBy ( [string] , [string] ) . parquet ( output_data + [string] ) [EOL] [EOL] [comment] [EOL] song_data = input_data + [string] [EOL] song_pyspark_df = spark . read . json ( song_data ) [EOL] print ( [string] ) [EOL] song_pyspark_df . printSchema ( ) [EOL] [EOL] [comment] [EOL] songs_pyspark_df = sqlContext . read . parquet ( [string] ) [EOL] artists_pyspark_df = sqlContext . read . parquet ( [string] ) [EOL] [EOL] [comment] [EOL] songplay_log_pyspark_df = songplay_log_pyspark_df . withColumn ( [string] , F . to_timestamp ( F . date_format ( ( F . col ( [string] ) / [number] ) . cast ( dataType = T . TimestampType ( ) ) , tsFormat ) , tsFormat ) ) [EOL] [EOL] [comment] [EOL] songplay_log_pyspark_df . createOrReplaceTempView ( [string] ) [EOL] songs_pyspark_df . createOrReplaceTempView ( [string] ) [EOL] artists_pyspark_df . createOrReplaceTempView ( [string] ) [EOL] time_table . createOrReplaceTempView ( [string] ) [EOL] [EOL] [comment] [EOL] songplays_table = spark . sql ( [string] ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] songplays_table . write . mode ( [string] ) . partitionBy ( [string] , [string] ) . parquet ( output_data + [string] ) [EOL] [EOL] [EOL] def main ( ) : [EOL] spark = create_spark_session ( ) [EOL] [EOL] [comment] [EOL] zip_ref = zipfile . ZipFile ( [string] , [string] ) [EOL] zip_ref . extractall ( [string] ) [EOL] zip_ref = zipfile . ZipFile ( [string] , [string] ) [EOL] zip_ref . extractall ( [string] ) [EOL] zip_ref . close ( ) [EOL] [EOL] input_data = [string] [EOL] output_data = [string] [EOL] [EOL] process_song_data ( spark , input_data , output_data ) [EOL] process_log_data ( spark , input_data , output_data ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $configparser.ConfigParser$ 0 0 0 0 0 0 0 $configparser.ConfigParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $configparser.ConfigParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $configparser.ConfigParser$ 0 0 0 0 0 0 0 0 0 0 $pyspark.sql.SparkSession$ 0 0 0 0 0 0 0 0 0 0 $configparser.ConfigParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] from typing import Dict [EOL] import typing [EOL] users = { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] } [EOL] [EOL] [comment] [EOL] songs = { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] } [EOL] [EOL] [comment] [EOL] artists = { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] } [EOL]	0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0