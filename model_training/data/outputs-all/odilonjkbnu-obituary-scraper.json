[comment] [EOL] from typing import Any , List , Type [EOL] import bnu_obituary_scraper [EOL] import typing [EOL] import scrapy [EOL] from scrapy . spiders import CrawlSpider , Rule [EOL] from scrapy . linkextractors import LinkExtractor [EOL] [EOL] [EOL] class BnuObituaryScraperSpider ( CrawlSpider ) : [EOL] name = [string] [EOL] [EOL] allowed_domains = [ [string] ] [EOL] start_urls = [ [string] ] [EOL] [EOL] rules = ( Rule ( LinkExtractor ( restrict_xpaths = ( [string] ) ) ) , Rule ( LinkExtractor ( restrict_css = ( [string] ) ) ) , Rule ( LinkExtractor ( restrict_xpaths = ( [string] ) ) , callback = [string] ) ) [EOL] [EOL] def parse_new ( self , response ) : [EOL] content = response . xpath ( [string] ) [EOL] [EOL] name = content . xpath ( [string] ) . get ( ) [EOL] info = content . xpath ( [string] ) . getall ( ) [EOL] age = info [ [number] ] . strip ( ) . split ( [string] ) [ [number] ] [EOL] death_date = info [ [number] ] . strip ( ) [EOL] burial_date = info [ [number] ] . strip ( ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] yield { [string] : name , [string] : age , [string] : death_date , [string] : burial_date } [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0