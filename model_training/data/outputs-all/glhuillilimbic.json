from setuptools import find_packages , setup [EOL] [EOL] setup ( name = [string] , version = [string] , description = [string] , long_description = open ( [string] ) . read ( ) , url = [string] , author = [string] , author_email = [string] , license = [string] , packages = find_packages ( ) , package_data = { [string] : [ [string] , [string] , [string] ] } , zip_safe = False , install_requires = [ x . strip ( ) for x in open ( [string] ) . readlines ( ) ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[EOL] [comment] [EOL] [comment] [EOL] from typing import List [EOL] import typing [EOL] AFFECT_INTENSITY_EMOTIONS = [ [string] , [string] , [string] , [string] ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Any , Dict , List , NamedTuple , Optional , Set [EOL] [EOL] from keras_preprocessing . text import Tokenizer as KerasTokenizer [EOL] [EOL] [EOL] class Emotion ( NamedTuple ) : [EOL] category = ... [EOL] value = ... [EOL] term = ... [EOL] [EOL] [EOL] class EmotionValue ( NamedTuple ) : [EOL] category = ... [EOL] value = ... [EOL] [EOL] [EOL] class TimeEmotion ( NamedTuple ) : [EOL] seconds = ... [EOL] emotion = ... [EOL] [EOL] [EOL] class Lexicon ( NamedTuple ) : [EOL] emotion_mapping = ... [EOL] categories = ... [EOL] [EOL] [EOL] class ProcessParams ( NamedTuple ) : [EOL] lexicon = ... [EOL] terms_mapping = ... [EOL] [EOL] [EOL] class TfModelParams ( NamedTuple ) : [EOL] model = ... [comment] [EOL] tokenizer = ... [EOL] max_len = ... [EOL] emotions = ... [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.float$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $Emotion$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.List[Emotion]]$ 0 0 0 $typing.Set[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 $Lexicon$ 0 0 0 $typing.Optional[typing.Dict[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $keras_preprocessing.text.Tokenizer$ 0 0 0 $builtins.int$ 0 0 0 $typing.List[builtins.str]$ 0 0 0
from typing import List , Any [EOL] import builtins [EOL] import typing [EOL] from typing import List [EOL] [EOL] import spacy [EOL] [EOL] nlp = spacy . load ( [string] ) [EOL] [EOL] [EOL] def get_negated_words ( sentence ) : [EOL] [docstring] [EOL] doc = nlp ( sentence ) [EOL] negation_tokens = [ token for token in doc if token . dep_ == [string] ] [EOL] attr_tokens = [ token for token in doc if token . dep_ == [string] ] [EOL] negation_head_tokens = [ token . head for token in negation_tokens ] [EOL] negated_words = [ ] [EOL] for token in negation_head_tokens : [EOL] if token . dep_ == [string] : [EOL] negated_words . append ( token . text ) [EOL] negated_words . append ( token . head . text ) [EOL] if token . dep_ == [string] and token . head . pos_ == [string] : [EOL] negated_words . append ( token . text ) [EOL] for token_ in set ( attr_tokens ) . intersection ( set ( token . children ) ) : [EOL] negated_words . append ( token_ ) [EOL] return [ str ( x ) for x in negated_words ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Dict , Iterable , List , Optional [EOL] import builtins [EOL] import typing [EOL] import re [EOL] from typing import Dict , Iterable , List , Optional [EOL] [EOL] _STOPWORDS = frozenset ( { [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] } ) [EOL] [EOL] [EOL] def _clean_text ( text ) : [EOL] [docstring] [EOL] if not text : [comment] [EOL] return [string] [EOL] if [string] in text or [string] in text : [comment] [EOL] return [string] [EOL] text = text . lower ( ) [EOL] text = text . replace ( [string] , [string] ) [comment] [EOL] text = text . replace ( [string] , [string] ) [comment] [EOL] [EOL] text = re . sub ( [string] , [string] , text ) [comment] [EOL] text = re . sub ( [string] , [string] , text ) [comment] [EOL] text = re . sub ( [string] , [string] , text ) [comment] [EOL] text = re . sub ( [string] , [string] , text ) [comment] [EOL] text = re . sub ( [string] , [string] , text ) . strip ( ) [comment] [EOL] if text . count ( [string] ) > [number] : [EOL] text = re . sub ( [string] , [string] , text ) [EOL] return text [EOL] [EOL] [EOL] def _tokenizer ( sentence ) : [EOL] [docstring] [EOL] yield from sentence . split ( [string] ) [EOL] [EOL] [EOL] def _remove_stopwords ( sentence_tokens ) : [EOL] [docstring] [EOL] yield from [ x for x in sentence_tokens if x . lower ( ) not in _STOPWORDS ] [EOL] [EOL] [EOL] def process_content ( sentence , terms_mapping = None ) : [EOL] [docstring] [EOL] if terms_mapping : [EOL] for term , mapping in terms_mapping . items ( ) : [EOL] sentence = re . sub ( rf' [string] { term } [string] ' , mapping , sentence , flags = re . I ) [EOL] return list ( _remove_stopwords ( _tokenizer ( _clean_text ( sentence ) ) ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterable[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterable[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , List , Any , Optional [EOL] import requests [EOL] import builtins [EOL] import typing [EOL] import json [EOL] import os [EOL] import time [EOL] from collections import defaultdict [EOL] from typing import Any , Dict , List , Optional [EOL] [EOL] import requests [EOL] from bs4 import BeautifulSoup [EOL] from tqdm import tqdm [EOL] [EOL] _OMDB_API_KEY = os . environ [ [string] ] [EOL] _OMDB_API_BASE_URL = [string] [EOL] _OMDB_API_WAIT_TIME = [number] [EOL] _IMDB_BASE_URL = [string] [EOL] [EOL] [EOL] def get_imdb_data ( show_imdb_id , num_seasons , output_path ) : [EOL] [docstring] [EOL] seasons_episodes = _get_episodes_imdb_ids ( show_imdb_id , num_seasons ) [EOL] seasons_data = _get_imdb_data ( seasons_episodes ) [EOL] if output_path : [EOL] with open ( output_path , [string] ) as imdb_file : [EOL] json . dump ( seasons_data , imdb_file ) [EOL] return seasons_data [EOL] [EOL] [EOL] def _get_episodes_imdb_ids ( show_imdb_id , seasons ) : [EOL] [docstring] [EOL] base_url = f'{ _IMDB_BASE_URL }{ show_imdb_id } [string] ' [EOL] seasons_episodes = defaultdict ( list ) [EOL] for i in tqdm ( range ( [number] , seasons + [number] ) ) : [EOL] season_url = base_url + f' [string] { i }' [EOL] soup = BeautifulSoup ( requests . get ( season_url ) . content , [string] ) [EOL] for element in soup . find_all ( [string] ) : [EOL] if [string] in element [ [string] ] and [string] not in element [ [string] ] and element . get ( [string] ) == [string] : [EOL] seasons_episodes [ i ] . append ( element [ [string] ] . split ( [string] ) [ [number] ] ) [EOL] return seasons_episodes [EOL] [EOL] [EOL] def _get_imdb_data ( seasons_episodes ) : [EOL] [docstring] [EOL] seasons_data = defaultdict ( list ) [EOL] for season , episodes in seasons_episodes . items ( ) : [EOL] for episode_id in episodes : [EOL] get_request = requests . get ( _OMDB_API_BASE_URL , params = { [string] : _OMDB_API_KEY , [string] : episode_id } ) [EOL] seasons_data [ season ] . append ( json . loads ( get_request . content . decode ( [string] ) ) ) [EOL] time . sleep ( _OMDB_API_WAIT_TIME ) [EOL] return seasons_data [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.float$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 $typing.Dict[builtins.int,typing.List[typing.Any]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.int,typing.List[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.int,typing.List[typing.Any]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0
	0
	0
[comment] [EOL] [comment] [EOL] [comment] [EOL] from typing import Dict [EOL] import typing [EOL] _ECSTASY = [string] [EOL] _ADMIRATION = [string] [EOL] _TERROR = [string] [EOL] _AMAZEMENT = [string] [EOL] _GRIEF = [string] [EOL] _LOATHING = [string] [EOL] _RAGE = [string] [EOL] _VIGILANCE = [string] [EOL] [EOL] _JOY = [string] [EOL] _TRUST = [string] [EOL] _FEAR = [string] [EOL] _SURPRISE = [string] [EOL] _SADNESS = [string] [EOL] _DISGUST = [string] [EOL] _ANGER = [string] [EOL] _ANTICIPATION = [string] [EOL] [EOL] _SERENITY = [string] [EOL] _ACCEPTANCE = [string] [EOL] _APPREHENSION = [string] [EOL] _DISTRACTION = [string] [EOL] _PENSIVENESS = [string] [EOL] _BOREDOM = [string] [EOL] _ANNOYANCE = [string] [EOL] _INTEREST = [string] [EOL] [EOL] _POSITIVE = [string] [EOL] _NEGATIVE = [string] [EOL] [EOL] PLUTCHIK_EMOTIONS_OPPOSITE_MAPPING = { _ECSTASY : _GRIEF , _GRIEF : _ECSTASY , _ADMIRATION : _LOATHING , _LOATHING : _ADMIRATION , _TERROR : _RAGE , _RAGE : _TERROR , _AMAZEMENT : _VIGILANCE , _VIGILANCE : _AMAZEMENT , _JOY : _SADNESS , _SADNESS : _JOY , _TRUST : _DISGUST , _DISGUST : _TRUST , _FEAR : _ANGER , _ANGER : _FEAR , _SURPRISE : _ANTICIPATION , _ANTICIPATION : _SURPRISE , _SERENITY : _PENSIVENESS , _PENSIVENESS : _SERENITY , _ACCEPTANCE : _BOREDOM , _BOREDOM : _ACCEPTANCE , _APPREHENSION : _ANNOYANCE , _ANNOYANCE : _APPREHENSION , _DISTRACTION : _INTEREST , _INTEREST : _DISTRACTION , _POSITIVE : _NEGATIVE , _NEGATIVE : _POSITIVE } [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 0
from typing import Dict , List , Any , Set [EOL] import builtins [EOL] import typing [EOL] import limbic [EOL] from collections import defaultdict [EOL] from typing import Dict , List [EOL] [EOL] from limbic . limbic_types import Emotion , Lexicon [EOL] from limbic . emotion . utils import load_lexicon [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] class NotValidNRCLexiconException ( Exception ) : [EOL] pass [EOL] [EOL] [EOL] def load_nrc_lexicon ( lexicon_path , lexicon_type ) : [EOL] if lexicon_type == [string] : [EOL] return _load_nrc_emotion ( lexicon_path ) [EOL] elif lexicon_type == [string] : [EOL] return _load_nrc_affect_intensity ( lexicon_path ) [EOL] elif lexicon_type == [string] : [EOL] return _load_nrc_vad ( lexicon_path ) [EOL] raise NotValidNRCLexiconException [EOL] [EOL] [EOL] def _load_nrc_emotion ( lexicon_file_path ) : [EOL] return load_lexicon ( lexicon_file_path ) [EOL] [EOL] [EOL] def _load_nrc_affect_intensity ( lexicon_file_path ) : [EOL] [docstring] [EOL] data = defaultdict ( list ) [EOL] categories = set ( ) [EOL] skip = True [comment] [EOL] with open ( lexicon_file_path , [string] ) as intensity_file : [EOL] for idx , line in enumerate ( intensity_file . readlines ( ) ) : [EOL] if skip : [EOL] if line == [string] : [EOL] skip = False [EOL] continue [EOL] term , score , affect_dimension = line . strip ( ) . split ( [string] ) [EOL] data [ term ] . append ( Emotion ( value = float ( score ) , category = affect_dimension , term = term ) ) [EOL] categories . add ( affect_dimension ) [EOL] return Lexicon ( emotion_mapping = data , categories = categories ) [EOL] [EOL] [EOL] def _load_nrc_vad ( lexicon_file_path ) : [EOL] [docstring] [EOL] data = defaultdict ( list ) [EOL] with open ( lexicon_file_path , [string] ) as vad_file : [EOL] for idx , line in enumerate ( vad_file . readlines ( ) ) : [EOL] if idx > [number] : [EOL] term , valence , arousal , dominance = line . strip ( ) . split ( [string] ) [EOL] data [ term ] . append ( Emotion ( value = float ( valence ) , category = [string] , term = term ) ) [EOL] data [ term ] . append ( Emotion ( value = float ( arousal ) , category = [string] , term = term ) ) [EOL] data [ term ] . append ( Emotion ( value = float ( dominance ) , category = [string] , term = term ) ) [EOL] return Lexicon ( emotion_mapping = data , categories = { [string] , [string] , [string] } ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $limbic.limbic_types.Lexicon$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $limbic.limbic_types.Lexicon$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $limbic.limbic_types.Lexicon$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $limbic.limbic_types.Lexicon$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , List , Any , Set [EOL] import builtins [EOL] import typing [EOL] import limbic [EOL] from collections import defaultdict [EOL] from typing import Dict , List [EOL] [EOL] from limbic . limbic_types import Emotion , Lexicon [EOL] [EOL] [EOL] def load_lexicon ( lexicon_path ) : [EOL] [docstring] [EOL] data = defaultdict ( list ) [EOL] categories = set ( ) [EOL] with open ( lexicon_path , [string] ) as emotion_file : [EOL] for line in emotion_file . readlines ( ) : [EOL] if line . strip ( ) : [EOL] term , emotion , score = line . strip ( ) . split ( [string] ) [EOL] data [ term ] . append ( Emotion ( value = float ( score ) , category = emotion , term = term ) ) [EOL] categories . add ( emotion ) [EOL] return Lexicon ( emotion_mapping = data , categories = categories ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $limbic.limbic_types.Lexicon$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Dict , List , Any , Optional [EOL] import builtins [EOL] import limbic [EOL] import typing [EOL] from typing import Dict , List , Optional [EOL] [EOL] from limbic . utils . nlp import get_negated_words [EOL] from limbic . utils . text import process_content [EOL] from limbic . limbic_types import Emotion , Lexicon , ProcessParams [EOL] from limbic . emotion . plutchik_wheel import PLUTCHIK_EMOTIONS_OPPOSITE_MAPPING [EOL] [EOL] [EOL] class LexiconLimbicModel : [EOL] [EOL] def __init__ ( self , lexicon , terms_mapping = None ) : [EOL] self . lexicon = lexicon [EOL] self . terms_mapping = terms_mapping or { } [EOL] self . process_params = ProcessParams ( lexicon = self . lexicon , terms_mapping = terms_mapping ) [EOL] [EOL] def get_term_emotions ( self , term , is_negated = False ) : [EOL] [docstring] [EOL] term = term . lower ( ) . strip ( ) [EOL] emotions = self . process_params . lexicon . emotion_mapping . get ( term , [ ] ) [EOL] if is_negated : [EOL] negated_emotions = [ ] [EOL] for emotion in emotions : [EOL] if emotion . category in PLUTCHIK_EMOTIONS_OPPOSITE_MAPPING : [EOL] negated_emotions . append ( Emotion ( category = PLUTCHIK_EMOTIONS_OPPOSITE_MAPPING [ emotion . category ] , value = emotion . value , term = f' [string] { term }' ) ) [EOL] return negated_emotions [EOL] return emotions [EOL] [EOL] def get_sentence_emotions ( self , sentence ) : [EOL] [docstring] [EOL] sentence_emotions = [ ] [EOL] negated_terms = get_negated_words ( sentence ) [EOL] for term in process_content ( sentence , self . process_params . terms_mapping ) : [EOL] for emotion in self . get_term_emotions ( term , is_negated = term in negated_terms ) : [EOL] sentence_emotions . append ( emotion ) [EOL] return sentence_emotions [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $limbic.limbic_types.Lexicon$ 0 0 0 0 0 0 0 0 0 $limbic.limbic_types.Lexicon$ 0 $limbic.limbic_types.Lexicon$ 0 0 0 0 0 0 0 0 0 0 0 0 $limbic.limbic_types.ProcessParams$ 0 0 0 $limbic.limbic_types.Lexicon$ 0 0 0 $limbic.limbic_types.Lexicon$ 0 0 0 0 0 0 0 0 $typing.List[limbic.limbic_types.Emotion]$ 0 0 0 $builtins.str$ 0 $builtins.bool$ 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $typing.List[limbic.limbic_types.Emotion]$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.bool$ 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 $typing.List[limbic.limbic_types.Emotion]$ 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 $typing.List[limbic.limbic_types.Emotion]$ 0 0 0 $typing.List[limbic.limbic_types.Emotion]$ 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0
from limbic . emotion . models . lexicon_limbic_model import LexiconLimbicModel [EOL] from limbic . emotion . models . tf_limbic_model import TfLimbicModel [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import List , Any , Optional [EOL] import builtins [EOL] import limbic [EOL] import typing [EOL] from typing import List , Optional [EOL] [EOL] import numpy as np [EOL] import tensorflow as tf [EOL] [EOL] from limbic . limbic_constants import AFFECT_INTENSITY_EMOTIONS [EOL] from limbic . limbic_types import EmotionValue , TfModelParams [EOL] from limbic . emotion . models . tf_limbic_model . utils import load_model [EOL] [EOL] [EOL] _VERSION = [string] [EOL] [comment] [EOL] _MAX_LEN = [number] [EOL] [EOL] [EOL] class TfLimbicModel : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , model_params = None ) : [EOL] if model_params : [EOL] self . tokenizer = model_params . tokenizer [EOL] self . model = model_params . model [EOL] self . max_len = model_params . max_len [EOL] self . emotions = model_params . emotions [EOL] else : [EOL] self . model , self . tokenizer = load_model ( _VERSION ) [EOL] self . max_len = _MAX_LEN [EOL] [EOL] [comment] [EOL] [comment] [EOL] self . emotions = AFFECT_INTENSITY_EMOTIONS [EOL] [EOL] def _process_input ( self , sentence ) : [EOL] tokenized_sentence = self . tokenizer . texts_to_sequences ( [ sentence ] ) [EOL] padded_tokens = tf . keras . preprocessing . sequence . pad_sequences ( tokenized_sentence , maxlen = self . max_len ) [ [number] ] [EOL] return np . expand_dims ( padded_tokens , [number] ) [EOL] [EOL] def predict ( self , sentence ) : [EOL] [docstring] [EOL] return self . model . predict ( self . _process_input ( sentence ) ) [ [number] ] [EOL] [EOL] def get_sentence_emotions ( self , sentence ) : [EOL] [docstring] [EOL] prediction = self . predict ( sentence ) [EOL] return [ EmotionValue ( category = k , value = v ) for ( k , v ) in zip ( self . emotions , prediction ) ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $typing.Optional[limbic.limbic_types.TfModelParams]$ 0 0 0 0 0 0 $typing.Optional[limbic.limbic_types.TfModelParams]$ 0 0 0 0 0 0 $typing.Optional[limbic.limbic_types.TfModelParams]$ 0 0 0 0 0 0 0 $typing.Optional[limbic.limbic_types.TfModelParams]$ 0 0 0 0 0 0 0 $typing.Optional[limbic.limbic_types.TfModelParams]$ 0 0 0 0 0 0 0 $typing.Optional[limbic.limbic_types.TfModelParams]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $typing.List[limbic.limbic_types.EmotionValue]$ 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0
from limbic . emotion . models . tf_limbic_model . tf_limbic_model import TfLimbicModel [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Optional , Set , Dict , List , Counter , Union [EOL] import builtins [EOL] import limbic [EOL] import typing [EOL] from collections import Counter , defaultdict [EOL] from random import shuffle [EOL] from typing import Counter as CounterType , Dict , List , Optional , Set [EOL] [EOL] import matplotlib . pyplot as plt [EOL] from nltk . stem import PorterStemmer [EOL] from wordcloud import WordCloud [EOL] [EOL] from limbic . limbic_types import TimeEmotion [EOL] [EOL] [EOL] def plot_emotions_wordclouds ( emotions , categories , unique = False , weighted = False ) : [EOL] fig = plt . figure ( ) [EOL] unique_terms = _unique_terms_for_categories ( emotions , categories ) if unique else { } [EOL] for idx , emotion in enumerate ( categories ) : [EOL] if unique : [EOL] title_prefix = [string] [EOL] emotion_terms = _weighted_emotions_terms ( emotions , emotion , unique_terms [ emotion ] ) [EOL] else : [EOL] if weighted : [EOL] title_prefix = [string] [EOL] emotion_terms = _weighted_emotions_terms ( emotions , emotion ) [EOL] else : [EOL] title_prefix = [string] [EOL] emotion_terms = [string] . join ( [ x . emotion . term for x in emotions if x . emotion . category == emotion ] ) [EOL] ax = fig . add_subplot ( [number] , [number] , idx + [number] ) [EOL] ax . set_title ( f'{ title_prefix } [string] { emotion } [string] ' , fontsize = [number] ) [EOL] fig . set_figheight ( [number] ) [EOL] fig . set_figwidth ( [number] ) [EOL] word_cloud = WordCloud ( background_color = [string] , max_words = [number] , max_font_size = [number] , scale = [number] , random_state = [number] ) . generate ( emotion_terms ) [EOL] ax . imshow ( word_cloud ) [EOL] ax . axis ( [string] ) [EOL] plt . show ( ) [EOL] [EOL] [EOL] def _weighted_emotions_terms ( emotions , category , unique_terms = None ) : [EOL] porter = PorterStemmer ( ) [EOL] total_emotion_per_term = defaultdict ( float ) [EOL] for e in emotions : [EOL] if [string] in e . emotion . term : [EOL] continue [EOL] term_stem = porter . stem ( e . emotion . term ) [EOL] if unique_terms : [EOL] if term_stem not in unique_terms : [EOL] continue [EOL] if e . emotion . category == category : [EOL] total_emotion_per_term [ term_stem ] += e . emotion . value [EOL] else : [EOL] if e . emotion . category == category : [EOL] total_emotion_per_term [ term_stem ] += e . emotion . value [EOL] weighted_terms = [ ] [EOL] for term , total_emotion in total_emotion_per_term . items ( ) : [EOL] for _ in range ( [number] , int ( total_emotion ) ) : [EOL] weighted_terms . append ( term ) [EOL] shuffle ( weighted_terms ) [EOL] return [string] . join ( [ x . strip ( ) for x in weighted_terms ] ) [EOL] [EOL] [EOL] def _unique_terms_for_categories ( emotions , categories ) : [EOL] porter = PorterStemmer ( ) [EOL] emotion_terms = defaultdict ( set ) [EOL] for category in categories : [EOL] for e in emotions : [EOL] if e . emotion . category == category and [string] not in e . emotion . term : [EOL] emotion_terms [ category ] . add ( porter . stem ( e . emotion . term ) ) [EOL] all_terms_c = Counter ( ) [EOL] for terms in emotion_terms . values ( ) : [EOL] all_terms_c . update ( terms ) [EOL] repeated_terms = { x for x , y in all_terms_c . items ( ) if y > [number] } [EOL] emotion_unique_term_stems = defaultdict ( set ) [EOL] for category in categories : [EOL] for e in emotions : [EOL] if e . emotion . category == category and [string] not in e . emotion . term : [EOL] term_stem = porter . stem ( e . emotion . term ) [EOL] if term_stem not in repeated_terms : [EOL] emotion_unique_term_stems [ category ] . add ( term_stem ) [EOL] return emotion_unique_term_stems [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Set[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Tuple , Any , List [EOL] import builtins [EOL] import limbic [EOL] import numpy [EOL] import typing [EOL] from typing import List , Tuple [EOL] [EOL] import numpy as np [EOL] [EOL] from limbic . limbic_types import TimeEmotion [EOL] [EOL] [comment] [EOL] [EOL] [EOL] def get_total ( emotions , category ) : [EOL] return sum ( [ e . emotion . value for e in emotions if e . emotion . category == category ] ) [EOL] [EOL] [EOL] def get_mean ( emotions , category ) : [EOL] values = [ ] [EOL] for e in emotions : [EOL] if e . emotion . category == category : [EOL] values . append ( e . emotion . value ) [EOL] else : [EOL] values . append ( [number] ) [EOL] return np . mean ( values ) [EOL] [EOL] [EOL] def moving_window ( emotions , category , step = [number] , window = [number] ) : [EOL] window_start = [number] [EOL] current_window_total = [number] [EOL] windows_total = [ ] [EOL] while window_start + window < max ( [ x . seconds for x in emotions ] ) : [EOL] for e in emotions : [EOL] if window_start <= e . seconds <= window_start + window : [EOL] if e . emotion . category == category : [EOL] current_window_total += e . emotion . value [EOL] elif e . seconds > window_start + window : [EOL] windows_total . append ( current_window_total ) [EOL] current_window_total = [number] [EOL] window_start += step [EOL] break [EOL] return windows_total [EOL] [EOL] [EOL] def get_max_delta ( emotions , category , step = [number] , window = [number] ) : [EOL] window_totals = moving_window ( emotions , category , step = step , window = window ) [EOL] previous_window_total = [number] [EOL] max_delta = [number] [EOL] time_max_delta = [number] [EOL] for idx , current_window_total in enumerate ( window_totals ) : [EOL] delta = current_window_total - previous_window_total [EOL] if delta > [number] and delta > max_delta : [EOL] max_delta = delta [EOL] time_max_delta = idx * step [EOL] previous_window_total = current_window_total [EOL] return max_delta , time_max_delta [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.float]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.float,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , List , Any [EOL] import pandas [EOL] import builtins [EOL] import limbic [EOL] import typing [EOL] from collections import defaultdict [EOL] from typing import Any , Dict , List [EOL] [EOL] import pandas as pd [EOL] [EOL] from limbic . limbic_types import TimeEmotion [EOL] from limbic . analysis import get_max_delta , get_mean , get_total , moving_window [EOL] [EOL] [EOL] def all_moving_windows ( seasons_episodes_subtitles_emotions , categories , window = [number] ) : [EOL] data = { [string] : [ ] , [string] : [ ] , [string] : [ ] , [string] : [ ] , [string] : [ ] } [EOL] for season in seasons_episodes_subtitles_emotions . keys ( ) : [EOL] for category in categories : [EOL] for episode , emotions in seasons_episodes_subtitles_emotions [ season ] . items ( ) : [EOL] episode_name = f' [string] { season } [string] { episode }' if season < [number] else f' [string] { season } [string] { episode }' [EOL] mw = moving_window ( emotions , category ) [EOL] for idx , v in enumerate ( mw ) : [EOL] data [ [string] ] . append ( v ) [EOL] data [ [string] ] . append ( episode_name ) [EOL] data [ [string] ] . append ( category ) [EOL] data [ [string] ] . append ( idx * window ) [EOL] data [ [string] ] . append ( season ) [EOL] return pd . DataFrame . from_dict ( data ) [EOL] [EOL] [EOL] def get_features ( seasons_episodes_subtitles_emotions , imdb_data , categories , min_threshold = [number] , max_threshold = [number] ) : [EOL] seasons_episodes_data = defaultdict ( list ) [EOL] for season , season_episodes in seasons_episodes_subtitles_emotions . items ( ) : [EOL] for episode , episode_subtitle_emotions in season_episodes . items ( ) : [EOL] features = _get_emotions_features ( episode_subtitle_emotions , season , episode , categories ) [EOL] ratings = _get_rating ( imdb_data , season , episode ) [EOL] votes = _get_votes ( imdb_data , season , episode ) [EOL] _add_data ( seasons_episodes_data , features , ratings , votes ) [EOL] df = pd . DataFrame . from_dict ( seasons_episodes_data ) [EOL] df [ [string] ] = df . apply ( lambda row : _rating_to_category ( row [ [string] ] , min_threshold , max_threshold ) , axis = [number] ) [EOL] return df [EOL] [EOL] [EOL] def _add_data ( episodes_data , features , ratings , votes ) : [EOL] for k , v in features . items ( ) : [EOL] episodes_data [ k ] . append ( v ) [EOL] episodes_data [ [string] ] . append ( ratings ) [EOL] episodes_data [ [string] ] . append ( votes ) [EOL] [EOL] [EOL] def _get_rating ( imdb_data , season , episode ) : [EOL] return float ( imdb_data [ str ( season ) ] [ episode - [number] ] [ [string] ] ) [EOL] [EOL] [EOL] def _get_votes ( imdb_data , season , episode ) : [EOL] return int ( imdb_data [ str ( season ) ] [ episode - [number] ] [ [string] ] ) [EOL] [EOL] [EOL] def _rating_to_category ( rating , min_threshold , max_threshold ) : [EOL] [docstring] [EOL] if rating > max_threshold : [EOL] return [string] [EOL] if min_threshold < rating <= max_threshold : [EOL] return [string] [EOL] return [string] [EOL] [EOL] [EOL] def _get_emotions_features ( subtitles_emotions , season , episode , categories ) : [EOL] [comment] [EOL] data = { [string] : season , [string] : episode } [EOL] for e in categories : [EOL] data [ f' [string] { e }' ] = get_total ( subtitles_emotions , e ) [EOL] data [ f' [string] { e }' ] = get_mean ( subtitles_emotions , e ) [EOL] max_delta , time_max_delta = get_max_delta ( subtitles_emotions , e ) [EOL] data [ f' [string] { e }' ] = max_delta [EOL] data [ f' [string] { e }' ] = time_max_delta [EOL] data [ [string] ] = get_total ( subtitles_emotions , [string] ) - get_total ( subtitles_emotions , [string] ) [EOL] data [ [string] ] = get_total ( subtitles_emotions , [string] ) - get_total ( subtitles_emotions , [string] ) [EOL] return data [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pandas.DataFrame$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.float]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , List , Any [EOL] import builtins [EOL] import typing [EOL] from typing import Any , Dict , List [EOL] [EOL] import matplotlib . pyplot as plt [EOL] import pandas as pd [EOL] import seaborn as sns [EOL] [EOL] from limbic . analysis import moving_window [EOL] [EOL] [EOL] def plot_emotion_all_episodes ( subtitles_emotions , category ) : [EOL] df_category_moving_window = _seasons_episodes_category_moving_window ( subtitles_emotions , category ) [EOL] sns . set ( style = [string] ) [EOL] pal = sns . color_palette ( ) [EOL] g = sns . FacetGrid ( df_category_moving_window , row = [string] , col = [string] , hue = [string] , aspect = [number] , height = [number] , palette = pal ) [EOL] g . map ( plt . plot , [string] , f' [string] { category }' ) [EOL] g . map ( plt . axhline , y = [number] , lw = [number] , clip_on = False ) [EOL] g . fig . subplots_adjust ( hspace = - [number] ) [EOL] g . set_titles ( [string] ) [EOL] g . set_xlabels ( [string] ) [EOL] g . despine ( bottom = True , left = True ) [EOL] plt . show ( ) [EOL] [EOL] [EOL] def _seasons_episodes_category_moving_window ( seasons_episodes_subtitles_emotions , category ) : [EOL] data = { [string] : [ ] , [string] : [ ] , f' [string] { category }' : [ ] , [string] : [ ] } [EOL] max_mw = [number] [EOL] for season in seasons_episodes_subtitles_emotions . keys ( ) : [EOL] for episode , emotions in seasons_episodes_subtitles_emotions [ season ] . items ( ) : [EOL] mw = moving_window ( emotions , category ) [EOL] for idx , v in enumerate ( mw ) : [EOL] data [ f' [string] { category }' ] . append ( v ) [EOL] data [ [string] ] . append ( f' [string] { episode }' ) [EOL] data [ [string] ] . append ( f' [string] { season }' ) [EOL] data [ [string] ] . append ( idx * [number] ) [EOL] if max_mw < len ( mw ) : [EOL] max_mw = len ( mw ) [EOL] return pd . DataFrame . from_dict ( data ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0