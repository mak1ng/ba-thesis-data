[comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] from typing import Any , Dict , List [EOL] import typing [EOL] import datetime [EOL] import builtins [EOL] import datetime [EOL] import isodate [EOL] import unittest [EOL] from pathlib import Path [EOL] from typing import List [EOL] [EOL] from scrape_schema_recipe import load , loads , scrape , scrape_url [EOL] from scrape_schema_recipe import example_output , __version__ [EOL] [EOL] DISABLE_NETWORK_TESTS = False [EOL] [EOL] [EOL] def lists_are_equal ( lst1 , lst2 ) : [EOL] lst1 . sort ( ) [EOL] lst2 . sort ( ) [EOL] [EOL] if lst1 != lst2 : [EOL] print ( [string] ) [EOL] print ( [string] . format ( lst1 ) ) [EOL] print ( [string] . format ( lst2 ) ) [EOL] return lst1 == lst2 [EOL] [EOL] [EOL] class TestParsingFileMicroData ( unittest . TestCase ) : [EOL] @ classmethod def setUpClass ( cls ) : [EOL] cls . recipes = load ( [string] ) [EOL] cls . recipe = cls . recipes [ [number] ] [EOL] [EOL] def test_recipe_keys ( self ) : [EOL] input_keys = list ( self . recipe . keys ( ) ) [EOL] [EOL] expectated_output = [ [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] [EOL] assert lists_are_equal ( expectated_output , input_keys ) [EOL] [EOL] def test_name ( self ) : [EOL] assert self . recipe [ [string] ] == [string] [EOL] [EOL] def test_recipe_yield ( self ) : [EOL] assert self . recipe [ [string] ] == [string] [EOL] [EOL] def test_num_recipes ( self ) : [EOL] assert len ( self . recipes ) == [number] [EOL] [EOL] [EOL] [comment] [EOL] class TestParsingFileMicroData2 ( unittest . TestCase ) : [EOL] @ classmethod def setUpClass ( cls ) : [EOL] cls . recipes = scrape ( [string] , python_objects = True ) [EOL] cls . recipe = cls . recipes [ [number] ] [EOL] [EOL] def test_recipe_keys ( self ) : [EOL] input_keys = list ( self . recipe . keys ( ) ) [EOL] [EOL] expectated_output = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] [EOL] assert lists_are_equal ( expectated_output , input_keys ) [EOL] [EOL] def test_name ( self ) : [EOL] assert self . recipe [ [string] ] == [string] [EOL] [EOL] def test_recipe_yield ( self ) : [EOL] assert self . recipe [ [string] ] == [string] [EOL] [EOL] def test_num_recipes ( self ) : [EOL] assert len ( self . recipes ) == [number] [EOL] [EOL] def test_totalTime_sum ( self ) : [EOL] r = self . recipe [EOL] assert r [ [string] ] + r [ [string] ] == r [ [string] ] [EOL] [EOL] [EOL] class TestParsingFileLDJSON ( unittest . TestCase ) : [EOL] @ classmethod def setUpClass ( cls ) : [EOL] cls . recipes = scrape ( [string] ) [EOL] cls . recipe = cls . recipes [ [number] ] [EOL] [EOL] def test_category ( self ) : [EOL] assert self . recipe [ [string] ] == [string] [EOL] [EOL] def test_duration ( self ) : [EOL] assert self . recipe [ [string] ] == [string] [EOL] [EOL] def test_ingredients ( self ) : [EOL] ingredients = [ [string] , [string] , [string] , [string] ] [EOL] [EOL] assert lists_are_equal ( ingredients , self . recipe [ [string] ] ) [EOL] [EOL] [comment] [EOL] def test_instructions ( self ) : [EOL] expected_str = [string] [EOL] [EOL] assert self . recipe [ [string] ] == expected_str [EOL] [EOL] def test_recipe_keys ( self ) : [EOL] input_keys = list ( self . recipe . keys ( ) ) [EOL] expected_output = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] [EOL] assert lists_are_equal ( expected_output , input_keys ) [EOL] [EOL] def test_name ( self ) : [EOL] assert self . recipe [ [string] ] == [string] [EOL] [EOL] def test_num_recipes ( self ) : [EOL] assert len ( self . recipes ) == [number] [EOL] [EOL] [EOL] class TestTimeDelta ( unittest . TestCase ) : [EOL] @ classmethod def setUpClass ( cls ) : [EOL] cls . recipes = scrape ( [string] , python_objects = True ) [EOL] cls . recipe = cls . recipes [ [number] ] [EOL] [EOL] def test_timedelta ( self ) : [EOL] td = datetime . timedelta ( minutes = [number] ) [EOL] assert self . recipe [ [string] ] == td [EOL] [EOL] def test_totalTime_sum ( self ) : [EOL] r = self . recipe [EOL] assert r [ [string] ] + r [ [string] ] == r [ [string] ] [EOL] [EOL] [EOL] class TestDateTime ( unittest . TestCase ) : [EOL] @ classmethod def setUpClass ( cls ) : [EOL] cls . recipes = load ( [string] , python_objects = True ) [EOL] cls . recipe = cls . recipes [ [number] ] [EOL] [EOL] [comment] [EOL] upload_date = cls . recipe [ [string] ] [ [number] ] [ [string] ] [EOL] cls . datetime_test = isodate . parse_datetime ( upload_date ) [EOL] [EOL] def test_publish_date_python_obj ( self ) : [EOL] assert self . recipe [ [string] ] == datetime . date ( [number] , [number] , [number] ) [EOL] [EOL] def test_datetime_tz_python_obj_isodate ( self ) : [EOL] tz8 = isodate . FixedOffset ( offset_hours = [number] ) [EOL] expected = datetime . datetime ( [number] , [number] , [number] , [number] , [number] , tzinfo = tz8 ) [EOL] assert self . datetime_test == expected [EOL] [EOL] def test_datetime_tz_python_obj ( self ) : [EOL] tz8 = datetime . timezone ( datetime . timedelta ( hours = [number] ) ) [EOL] expected = datetime . datetime ( [number] , [number] , [number] , [number] , [number] , tzinfo = tz8 ) [EOL] assert self . datetime_test == expected [EOL] [EOL] [EOL] [comment] [EOL] class TestLoads ( unittest . TestCase ) : [EOL] def test_loads ( self ) : [EOL] with open ( [string] ) as fp : [EOL] s = fp . read ( ) [EOL] [EOL] recipes = loads ( s ) [EOL] recipe = recipes [ [number] ] [EOL] assert recipe [ [string] ] == [string] [EOL] [EOL] [EOL] [comment] [EOL] class BadTypes ( unittest . TestCase ) : [EOL] def test_load ( self ) : [EOL] with self . assertRaises ( TypeError ) : [EOL] load ( [number] ) [EOL] [EOL] def test_loads ( self ) : [EOL] with self . assertRaises ( TypeError ) : [EOL] loads ( [number] ) [EOL] [EOL] def test_scrape ( self ) : [EOL] with self . assertRaises ( TypeError ) : [EOL] scrape ( [number] ) [EOL] [EOL] def test_scrape_url ( self ) : [EOL] with self . assertRaises ( TypeError ) : [EOL] scrape_url ( [number] ) [EOL] [EOL] [EOL] class TestURL ( unittest . TestCase ) : [EOL] @ classmethod def setUpClass ( cls ) : [EOL] cls . url = [string] [EOL] [EOL] @ unittest . skipIf ( DISABLE_NETWORK_TESTS is True , [string] ) def test_scrape_url ( self ) : [EOL] self . recipes = scrape_url ( self . url ) [EOL] self . recipe = self . recipes [ [number] ] [EOL] assert self . recipe [ [string] ] == [string] [EOL] [EOL] @ unittest . skipIf ( DISABLE_NETWORK_TESTS is True , [string] ) def test_scrape ( self ) : [EOL] self . recipes = scrape ( self . url ) [EOL] self . recipe = self . recipes [ [number] ] [EOL] assert self . recipe [ [string] ] == [string] [EOL] [EOL] [EOL] [comment] [EOL] class TestUnMigratedSchema ( unittest . TestCase ) : [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] def test_recipe1 ( self ) : [EOL] recipes = load ( [string] , migrate_old_schema = False ) [EOL] recipe = recipes [ [number] ] [EOL] [EOL] input_keys = list ( recipe . keys ( ) ) [EOL] [comment] [EOL] [comment] [EOL] expectated_output = [ [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] [EOL] assert lists_are_equal ( expectated_output , input_keys ) [EOL] [EOL] def test_recipe2 ( self ) : [EOL] recipes = scrape ( [string] , python_objects = True , migrate_old_schema = False ) [EOL] recipe = recipes [ [number] ] [EOL] [EOL] input_keys = list ( recipe . keys ( ) ) [EOL] [EOL] expectated_output = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] [EOL] assert lists_are_equal ( expectated_output , input_keys ) [EOL] [EOL] [EOL] class TestExampleOutput ( unittest . TestCase ) : [EOL] def test_example_output ( self ) : [EOL] name = example_output ( [string] ) [ [number] ] [ [string] ] [EOL] assert name == [string] [EOL] [EOL] [EOL] class TestVersion ( unittest . TestCase ) : [EOL] def test_version_not_null ( self ) : [EOL] assert __version__ is not None [EOL] [EOL] def test_version_is_type_string ( self ) : [EOL] assert isinstance ( __version__ , str ) [EOL] [EOL] [EOL] class TestPythonObjects ( unittest . TestCase ) : [EOL] @ classmethod def setUpClass ( cls ) : [EOL] [comment] [EOL] cls . true = example_output ( [string] , python_objects = True ) [ [number] ] [EOL] cls . false = example_output ( [string] , python_objects = False ) [ [number] ] [EOL] cls . duration = example_output ( [string] , python_objects = [ datetime . timedelta ] ) [ [number] ] [EOL] cls . dates = example_output ( [string] , python_objects = [ datetime . date ] ) [ [number] ] [EOL] [EOL] def testDurationTypes ( self ) : [EOL] assert isinstance ( self . duration [ [string] ] , datetime . timedelta ) [EOL] assert isinstance ( self . duration [ [string] ] , datetime . timedelta ) [EOL] assert isinstance ( self . duration [ [string] ] , datetime . timedelta ) [EOL] [EOL] def testDurationEqual ( self ) : [EOL] assert self . duration [ [string] ] == self . true [ [string] ] [EOL] assert self . duration [ [string] ] == self . true [ [string] ] [EOL] assert self . duration [ [string] ] == self . true [ [string] ] [EOL] [EOL] def testDateTypes ( self ) : [EOL] assert isinstance ( self . dates [ [string] ] , datetime . date ) [EOL] [comment] [EOL] [EOL] def testDatesEqual ( self ) : [EOL] assert self . dates [ [string] ] == self . true [ [string] ] [EOL] [EOL] [EOL] class TestGraph ( unittest . TestCase ) : [EOL] [comment] [EOL] def test_graph ( self ) : [EOL] recipes_old = load ( [string] , python_objects = True ) [EOL] recipes_graph = load ( Path ( [string] ) , python_objects = True ) [EOL] [EOL] r_old = recipes_old [ [number] ] [EOL] r_graph = recipes_graph [ [number] ] [EOL] [EOL] assert r_old [ [string] ] == r_graph [ [string] ] [EOL] assert r_old [ [string] ] == r_graph [ [string] ] [EOL] assert r_old [ [string] ] == r_graph [ [string] ] [EOL] assert r_old [ [string] ] == r_graph [ [string] ] [EOL] assert r_old [ [string] ] == r_graph [ [string] ] [EOL] assert r_old [ [string] ] == r_graph [ [string] ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] assert r_old [ [string] ] != r_graph [ [string] ] [EOL] [EOL] [comment] [EOL] r_graph [ [string] ] == datetime . date ( [number] , [number] , [number] ) [EOL] assert [string] not in r_old . keys ( ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] unittest . main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $datetime.timedelta$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $datetime.timedelta$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $datetime.datetime$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $datetime.datetime$ 0 0 0 0 0 0 0 0 0 $datetime.timezone$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $datetime.datetime$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $datetime.timezone$ 0 0 0 0 0 0 0 $datetime.datetime$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 $builtins.str$ 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Dict[typing.Any,typing.Any]]$ 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Dict[typing.Any,typing.Any]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 $typing.List[typing.Dict[typing.Any,typing.Any]]$ 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 $typing.List[typing.Dict[typing.Any,typing.Any]]$ 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from setuptools import setup [EOL] [EOL] [comment] [EOL] setup ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from typing import Dict , IO , Optional , Tuple , Any , List , Callable , Union , Set [EOL] import typing [EOL] import requests [EOL] import datetime [EOL] import pathlib [EOL] import builtins [EOL] import datetime [EOL] from pathlib import Path [EOL] import sys [EOL] [comment] [EOL] from typing import Callable , Dict , IO , List , Optional , Tuple , Union [EOL] [EOL] [comment] [EOL] import extruct [EOL] import isodate [EOL] import requests [EOL] import validators [EOL] [EOL] [EOL] _PACKAGE_PATH = Path ( __file__ ) . resolve ( ) . parent [EOL] [EOL] [comment] [EOL] __version__ = ( _PACKAGE_PATH / [string] ) . read_text ( ) . strip ( ) [EOL] [EOL] [EOL] [comment] [EOL] USER_AGENT_STR = [string] . format ( __version__ , requests . __version__ ) [EOL] [EOL] [EOL] def scrape ( location , python_objects = False , nonstandard_attrs = False , migrate_old_schema = True , user_agent_str = None ) : [EOL] [docstring] [EOL] [EOL] data = { } [comment] [EOL] [EOL] if not user_agent_str : [EOL] user_agent_str = USER_AGENT_STR [EOL] [EOL] [comment] [EOL] url = None [EOL] if isinstance ( location , str ) : [EOL] [comment] [EOL] if validators . url ( location ) : [EOL] return scrape_url ( location , python_objects = python_objects , nonstandard_attrs = nonstandard_attrs , user_agent_str = user_agent_str ) [EOL] [EOL] [comment] [EOL] elif len ( location ) > [number] : [EOL] data = extruct . extract ( location ) [EOL] [EOL] [comment] [EOL] else : [EOL] with open ( location ) as f : [EOL] data = extruct . extract ( f . read ( ) ) [EOL] elif hasattr ( location , [string] ) : [EOL] [comment] [EOL] data = extruct . extract ( location . read ( ) ) [EOL] else : [EOL] raise TypeError ( [string] [string] . format ( type ( location ) ) ) [EOL] [EOL] scrapings = _convert_to_scrapings ( data , nonstandard_attrs , url = url ) [EOL] [EOL] if migrate_old_schema is True : [EOL] scrapings = _migrate_old_schema ( scrapings ) [EOL] [EOL] if python_objects is not False : [EOL] scrapings = _pythonize_objects ( scrapings , python_objects ) [EOL] [EOL] return scrapings [EOL] [EOL] [EOL] def load ( fp , python_objects = False , nonstandard_attrs = False , migrate_old_schema = True ) : [EOL] [docstring] [EOL] [EOL] data = { } [comment] [EOL] [EOL] if isinstance ( fp , str ) : [EOL] with open ( fp ) as f : [EOL] data = extruct . extract ( f . read ( ) ) [EOL] elif isinstance ( fp , Path ) : [EOL] data = extruct . extract ( fp . read_text ( ) ) [EOL] elif hasattr ( fp , [string] ) : [EOL] [comment] [EOL] data = extruct . extract ( fp . read ( ) ) [EOL] else : [EOL] err_msg = [string] [string] . format ( type ( fp ) ) [EOL] raise TypeError ( err_msg ) [EOL] [EOL] scrapings = _convert_to_scrapings ( data , nonstandard_attrs ) [EOL] [EOL] if migrate_old_schema is True : [EOL] scrapings = _migrate_old_schema ( scrapings ) [EOL] [EOL] if python_objects is not False : [EOL] scrapings = _pythonize_objects ( scrapings , python_objects ) [EOL] [EOL] return scrapings [EOL] [EOL] [EOL] def loads ( string , python_objects = False , nonstandard_attrs = False , migrate_old_schema = True ) : [EOL] [docstring] [EOL] [EOL] if not isinstance ( string , str ) : [EOL] raise TypeError ( [string] [string] . format ( type ( string ) ) ) [EOL] [EOL] data = { } [comment] [EOL] data = extruct . extract ( string ) [EOL] scrapings = _convert_to_scrapings ( data , nonstandard_attrs ) [EOL] [EOL] if migrate_old_schema is True : [EOL] scrapings = _migrate_old_schema ( scrapings ) [EOL] [EOL] if python_objects is not False : [EOL] scrapings = _pythonize_objects ( scrapings , python_objects ) [EOL] [EOL] return scrapings [EOL] [EOL] [EOL] def scrape_url ( url , python_objects = False , nonstandard_attrs = False , migrate_old_schema = True , user_agent_str = None ) : [EOL] [docstring] [EOL] [EOL] if not isinstance ( url , str ) : [EOL] raise TypeError ( [string] [string] . format ( type ( url ) ) ) [EOL] [EOL] data = { } [comment] [EOL] if not user_agent_str : [EOL] user_agent_str = USER_AGENT_STR [EOL] [EOL] r = requests . get ( url , headers = { [string] : user_agent_str } ) [EOL] r . raise_for_status ( ) [EOL] data = extruct . extract ( r . text , r . url ) [EOL] url = r . url [EOL] [EOL] scrapings = _convert_to_scrapings ( data , nonstandard_attrs , url = url ) [EOL] [EOL] if migrate_old_schema is True : [EOL] scrapings = _migrate_old_schema ( scrapings ) [EOL] [EOL] if python_objects is not False : [EOL] scrapings = _pythonize_objects ( scrapings , python_objects ) [EOL] [EOL] return scrapings [EOL] [EOL] [EOL] def _convert_json_ld_recipe ( rec , nonstandard_attrs = False , url = None ) : [EOL] [docstring] [EOL] [comment] [EOL] d = rec . copy ( ) [EOL] if nonstandard_attrs is True : [EOL] d [ [string] ] = [string] [EOL] [comment] [EOL] if url : [EOL] if d . get ( [string] ) and d . get ( [string] ) != url and nonstandard_attrs is True : [EOL] d [ [string] ] = url [EOL] else : [EOL] d [ [string] ] = url [EOL] return d [EOL] [EOL] [EOL] def _convert_to_scrapings ( data , nonstandard_attrs = False , url = None ) : [EOL] [docstring] [EOL] out = [ ] [EOL] if data [ [string] ] != [ ] : [EOL] for rec in data [ [string] ] : [EOL] if rec . get ( [string] ) == [string] : [EOL] d = _convert_json_ld_recipe ( rec , nonstandard_attrs , url ) [EOL] out . append ( d ) [EOL] [EOL] if rec . get ( [string] ) == [string] and [string] in rec . keys ( ) : [EOL] [comment] [EOL] for subrec in rec [ [string] ] : [EOL] if subrec [ [string] ] == [string] : [EOL] d = _convert_json_ld_recipe ( subrec , nonstandard_attrs , url ) [EOL] out . append ( d ) [EOL] [EOL] if data [ [string] ] != [ ] : [EOL] for rec in data [ [string] ] : [EOL] if rec [ [string] ] in ( [string] , [string] ) : [EOL] d = rec [ [string] ] . copy ( ) [EOL] if nonstandard_attrs is True : [EOL] d [ [string] ] = [string] [EOL] [comment] [EOL] [comment] [EOL] if rec [ [string] ] [ : [number] ] == [string] : [EOL] d [ [string] ] = [string] [EOL] else : [EOL] d [ [string] ] = [string] [EOL] d [ [string] ] = [string] [EOL] [EOL] [comment] [EOL] if url : [EOL] if d . get ( [string] ) and nonstandard_attrs is True : [EOL] d [ [string] ] = url [EOL] else : [EOL] d [ [string] ] = url [EOL] [EOL] for key in d . keys ( ) : [EOL] if isinstance ( d [ key ] , dict ) and [string] in d [ key ] : [EOL] type_ = d [ key ] . pop ( [string] ) [EOL] d [ key ] [ [string] ] = type_ . split ( [string] ) [ [number] ] [EOL] [EOL] out . append ( d ) [EOL] [EOL] return out [EOL] [EOL] [EOL] [comment] [EOL] DATETIME_PROPERTIES = frozenset ( [ [string] , [string] , [string] , [string] ] ) [EOL] DURATION_PROPERTIES = frozenset ( [ [string] , [string] , [string] , [string] , [string] ] ) [EOL] [EOL] [EOL] def _parse_determine_date_datetime ( s ) : [EOL] [docstring] [EOL] if sys . version_info >= ( [number] , [number] ) : [EOL] [comment] [EOL] if [string] in s : [EOL] return datetime . datetime . fromisoformat ( s ) [EOL] else : [EOL] return datetime . date . fromisoformat ( s ) [EOL] else : [EOL] [comment] [EOL] if [string] in s : [EOL] return isodate . parse_datetime ( s ) [EOL] else : [EOL] return isodate . parse_date ( s ) [EOL] [EOL] [EOL] [comment] [EOL] def _have_matching_items ( lst1 , lst2 ) : [EOL] if isinstance ( lst1 , bool ) : [EOL] return lst1 [EOL] [EOL] if isinstance ( lst2 , bool ) : [EOL] return lst2 [EOL] [EOL] s = set ( lst1 ) . intersection ( lst2 ) [EOL] return len ( s ) > [number] [EOL] [EOL] [EOL] def _pythonize_objects ( scrapings , python_objects ) : [EOL] [EOL] if python_objects is False : [EOL] [comment] [EOL] return scrapings [EOL] [EOL] [comment] [EOL] if python_objects is True or datetime . timedelta in python_objects : [comment] [EOL] [comment] [EOL] scrapings = _convert_properties_scrape ( scrapings , DURATION_PROPERTIES , isodate . parse_duration ) [EOL] [EOL] if python_objects is True or _have_matching_items ( ( datetime . date , datetime . datetime ) , python_objects ) : [EOL] [comment] [EOL] scrapings = _convert_properties_scrape ( scrapings , DATETIME_PROPERTIES , _parse_determine_date_datetime ) [EOL] [EOL] return scrapings [EOL] [EOL] [EOL] def _convert_properties_scrape ( recipes , properties , function ) : [EOL] for i in range ( len ( recipes ) ) : [EOL] key_set = set ( recipes [ i ] . keys ( ) ) [EOL] for p in key_set . intersection ( properties ) : [EOL] try : [EOL] recipes [ i ] [ p ] = function ( recipes [ i ] [ p ] ) [EOL] except ( isodate . ISO8601Error , ValueError ) : [EOL] [comment] [EOL] pass [EOL] [EOL] return recipes [EOL] [EOL] [EOL] def _migrate_old_schema ( recipes ) : [EOL] [docstring] [EOL] for i in range ( len ( recipes ) ) : [EOL] [comment] [EOL] if [string] in recipes [ i ] : [EOL] recipes [ i ] [ [string] ] = recipes [ i ] . pop ( [string] ) [EOL] [EOL] return recipes [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Dict]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Dict]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Dict]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Dict]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Dict]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Union[datetime.datetime,datetime.date]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Dict]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Dict]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Dict]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from . scrape import __version__ , load , loads , scrape , scrape_url [EOL] from . example_output import example_names , example_output [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , Union , Tuple , List [EOL] import pathlib [EOL] import typing [EOL] import builtins [EOL] from . scrape import load [EOL] [EOL] from pathlib import Path [EOL] from typing import Dict , List , Tuple , Union [EOL] [EOL] [comment] [EOL] _PACKAGE_PATH = Path ( __file__ ) . resolve ( ) . parent [EOL] [EOL] _TEST_DATA_PATH = [string] [EOL] [EOL] example_names = ( [string] , [string] , [string] , [string] , [string] ) [EOL] [EOL] _ex_name_filename = { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] } [EOL] [EOL] [EOL] def example_output ( name , python_objects = False , nonstandard_attrs = False , migrate_old_schema = True ) : [EOL] [docstring] [EOL] if name not in example_names : [EOL] raise ( ValueError ( [string] . format ( name ) ) ) [EOL] [EOL] return load ( _PACKAGE_PATH / _TEST_DATA_PATH / _ex_name_filename [ name ] , python_objects = python_objects , nonstandard_attrs = nonstandard_attrs , migrate_old_schema = migrate_old_schema ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pathlib.Path$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $typing.Tuple[builtins.str,builtins.str,builtins.str,builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Dict]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.str,builtins.str,builtins.str,builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pathlib.Path$ 0 $builtins.str$ 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0