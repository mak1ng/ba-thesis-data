from typing import Any , List [EOL] import typing [EOL] import datetime [EOL] from datetime import datetime , timedelta [EOL] [EOL] from aw_client import ActivityWatchClient [EOL] [EOL] from aw_transform import filter_period_intersect [EOL] [EOL] [EOL] def _check_nonoverlapping ( events ) : [EOL] events = sorted ( events , key = lambda e : e . timestamp ) [EOL] last_end = None [EOL] for e in events : [EOL] end = e . timestamp + e . duration [EOL] if last_end : [EOL] assert last_end <= end [EOL] last_end = end [EOL] [EOL] [EOL] def merge ( events1 , events2 ) : [EOL] result = ... [EOL] _check_nonoverlapping ( result ) [EOL] return result [EOL] [EOL] [EOL] def all_active_webactivity ( ) : [EOL] [docstring] [EOL] awapi = ActivityWatchClient ( [string] , testing = True ) [EOL] [EOL] start = datetime . now ( ) - timedelta ( days = [number] ) [EOL] tabevents = awapi . get_events ( [string] , start = start ) [EOL] afkevents = awapi . get_events ( [string] , start = start ) [EOL] [EOL] afkevents_notafk = list ( filter ( lambda e : e . data [ [string] ] == [string] , afkevents ) ) [EOL] tabevents_audible = list ( filter ( lambda e : [string] in e . data and e . data [ [string] ] , tabevents ) ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] activeevents = afkevents_notafk + tabevents_audible [EOL] [EOL] return filter_period_intersect ( tabevents , activeevents ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] from pprint import pprint [EOL] [EOL] pprint ( all_active_webactivity ( ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] from datetime import datetime , timedelta [EOL] [EOL] import pandas as pd [EOL] [EOL] from aw_client import ActivityWatchClient [EOL] [EOL] [EOL] def get_events ( bid ) : [EOL] return ActivityWatchClient ( [string] , testing = True ) . get_events ( bid , start = datetime . now ( ) - timedelta ( days = [number] ) , limit = - [number] ) [EOL] [EOL] [EOL] def to_dataframe ( events ) : [EOL] return pd . DataFrame ( dict ( timestamp = e . timestamp , duration = e . duration , ** e . data ) for e in events ) . set_index ( [string] ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] events = get_events ( [string] ) [EOL] df = to_dataframe ( events ) [EOL] print ( df . tail ( [number] ) ) [EOL] print ( df . groupby ( [string] ) . sum ( ) . drop ( [string] , axis = [number] ) . sort_values ( [string] , ascending = False ) ) [EOL] [EOL] print ( df . groupby ( [string] , as_index = True ) . resample ( [string] ) . agg ( { [string] : [string] } ) . reset_index ( ) . set_index ( [ [string] , [string] ] ) . sort_index ( ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List , Set [EOL] import typing [EOL] [docstring] [EOL] [EOL] [comment] [EOL] [EOL] import re [EOL] [EOL] from aw_client import ActivityWatchClient [EOL] [EOL] [EOL] def main ( dryrun = True ) : [EOL] [comment] [EOL] sensitive_words = [ [string] ] [EOL] [EOL] aw = ActivityWatchClient ( testing = True ) [EOL] [EOL] re_word = [string] [EOL] [EOL] buckets = aw . get_buckets ( ) [EOL] for bid in buckets . keys ( ) : [EOL] if [string] not in bid : [EOL] continue [EOL] [EOL] print ( [string] . format ( bid ) ) [EOL] [EOL] events = aw . get_events ( bid , limit = - [number] ) [EOL] old_matches = set ( ) [EOL] for event in events : [EOL] for key , val in event . data . items ( ) : [EOL] if isinstance ( val , str ) : [EOL] matches = [ re . findall ( re_word . format ( word ) , val . lower ( ) ) for word in sensitive_words ] [EOL] matches = set ( sum ( matches , [ ] ) ) [EOL] if matches : [EOL] event . data [ key ] = [string] [EOL] if val not in old_matches : [EOL] print ( f"{ [string] if dryrun else [string] } [string] { matches } [string] { val }" ) [EOL] old_matches . add ( val ) [EOL] if not dryrun : [EOL] aw . insert_event ( bid , event ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List [EOL] import typing [EOL] from datetime import timedelta [EOL] from copy import deepcopy [EOL] from difflib import SequenceMatcher [EOL] [EOL] [EOL] def similar ( a , b ) : [EOL] return SequenceMatcher ( None , a , b ) . ratio ( ) [EOL] [EOL] [EOL] def merge_close_and_similar ( events , pulsetime = [number] ) : [EOL] [docstring] [EOL] events = deepcopy ( events ) [EOL] events = sorted ( events , key = lambda e : e . timestamp ) [EOL] [EOL] merged_events = [ events [ [number] ] ] [EOL] [EOL] for i in range ( [number] , len ( events ) ) : [EOL] e1 = merged_events [ - [number] ] [EOL] e2 = events [ i ] [EOL] [EOL] merged = False [EOL] [EOL] if e1 . data [ [string] ] == e2 . data [ [string] ] : [EOL] gap = e2 . timestamp - ( e1 . timestamp + e1 . duration ) [EOL] assert gap >= timedelta ( [number] ) [EOL] [EOL] [comment] [EOL] if gap <= timedelta ( seconds = pulsetime ) : [EOL] simscore = similar ( e1 . data [ [string] ] , e2 . data [ [string] ] ) [EOL] if simscore > [number] : [EOL] e1 . duration = ( e2 . timestamp + e2 . duration ) - e1 . timestamp [EOL] merged = True [EOL] [EOL] if not merged : [EOL] merged_events . append ( e2 ) [EOL] [EOL] return merged_events [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from . import redact [EOL] from . import merge [EOL] from . util import ( split_event_on_time , next_hour , split_event_on_hour , start_of_day , end_of_day , get_week_start , is_in_same_week , split_into_weeks , split_into_days , verify_no_overlap , categorytime_per_day , categorytime_during_day , ) [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List [EOL] import typing [EOL] [docstring] [EOL] [EOL] import numpy as np [EOL] import matplotlib . pyplot as plt [EOL] [EOL] [EOL] def sunburst ( nodes , total = np . pi * [number] , offset = [number] , level = [number] , ax = None ) : [EOL] ax = ax or plt . subplot ( [number] , projection = [string] ) [EOL] [EOL] if level == [number] and len ( nodes ) == [number] : [EOL] label , value , subnodes = nodes [ [number] ] [EOL] ax . bar ( [ [number] ] , [ [number] ] , [ np . pi * [number] ] ) [EOL] ax . text ( [number] , [number] , label , ha = [string] , va = [string] ) [EOL] sunburst ( subnodes , total = value , level = level + [number] , ax = ax ) [EOL] elif nodes : [EOL] d = np . pi * [number] / total [EOL] labels = [ ] [EOL] widths = [ ] [EOL] local_offset = offset [EOL] for label , value , subnodes in nodes : [EOL] labels . append ( label ) [EOL] widths . append ( value * d ) [EOL] sunburst ( subnodes , total = total , offset = local_offset , level = level + [number] , ax = ax ) [EOL] local_offset += value [EOL] values = np . cumsum ( [ offset * d ] + widths [ : - [number] ] ) [EOL] heights = [ [number] ] * len ( nodes ) [EOL] bottoms = np . zeros ( len ( nodes ) ) + level - [number] [EOL] rects = ax . bar ( values , heights , widths , bottoms , linewidth = [number] , edgecolor = [string] , align = [string] , ) [EOL] for rect , label in zip ( rects , labels ) : [EOL] x = rect . get_x ( ) + rect . get_width ( ) / [number] [EOL] y = rect . get_y ( ) + rect . get_height ( ) / [number] [EOL] rotation = ( [number] + ( [number] - np . degrees ( x ) % [number] ) ) % [number] [EOL] ax . text ( x , y , label , rotation = rotation , ha = [string] , va = [string] ) [EOL] [EOL] if level == [number] : [EOL] ax . set_theta_direction ( - [number] ) [EOL] ax . set_theta_zero_location ( [string] ) [EOL] ax . set_axis_off ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List [EOL] import typing [EOL] import logging [EOL] import aw_core [EOL] import builtins [EOL] import logging [EOL] from typing import List [EOL] [EOL] from aw_core . models import Event [EOL] from aw_client import ActivityWatchClient [EOL] [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def filter_short ( events , threshold = [number] ) : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] return [ e for e in events if e . duration . total_seconds ( ) > threshold ] [EOL] [EOL] [EOL] def filter_datafields ( events , fields ) : [EOL] [docstring] [EOL] for e in events : [EOL] for field in fields : [EOL] if field in e . data : [EOL] e . data . pop ( field ) [EOL] return events [EOL] [EOL] [EOL] def test_filter_data ( ) : [EOL] awapi = ActivityWatchClient ( [string] , testing = True ) [EOL] events = awapi . get_events ( [string] , limit = - [number] ) [EOL] events = filter_datafields ( events , [ [string] ] ) [EOL] assert [string] not in events [ [number] ] . data [EOL] [EOL] [EOL] def test_filter_short ( ) : [EOL] [comment] [EOL] awapi = ActivityWatchClient ( [string] , testing = True ) [EOL] events = awapi . get_events ( [string] , limit = - [number] ) [EOL] filter_short ( events , threshold = [number] ) [EOL] [EOL] events = awapi . get_events ( [string] , limit = - [number] ) [EOL] filter_short ( events , threshold = [number] ) [EOL] [EOL] events = awapi . get_events ( [string] , limit = - [number] ) [EOL] filter_short ( events , threshold = [number] ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] test_filter_data ( ) [EOL] test_filter_short ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Optional , Dict , List , Union [EOL] import typing [EOL] import logging [EOL] import builtins [EOL] import os [EOL] import logging [EOL] from typing import List [EOL] [EOL] try : [EOL] import Algorithmia [EOL] except ImportError : [EOL] pass [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] API_KEY = ( os . environ [ [string] ] if [string] in os . environ else None ) [EOL] [EOL] [EOL] def _assert_api_key ( ) : [EOL] if API_KEY is None : [EOL] raise Exception ( [string] ) [EOL] [EOL] [EOL] def run_sentiment ( docs ) : [EOL] _assert_api_key ( ) [EOL] payload = [ { [string] : doc } for doc in docs ] [EOL] client = Algorithmia . client ( API_KEY ) [EOL] algo = client . algo ( [string] ) [EOL] return algo . pipe ( payload ) [EOL] [EOL] [EOL] def run_LDA ( docs ) : [EOL] _assert_api_key ( ) [EOL] payload = { [string] : docs , [string] : [string] , [string] : [ [string] ] , } [EOL] client = Algorithmia . client ( API_KEY ) [EOL] algo = client . algo ( [string] ) [EOL] return algo . pipe ( payload ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
import aw_research . main [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] aw_research . main . main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Tuple , List , DefaultDict [EOL] import logging [EOL] import datetime [EOL] import builtins [EOL] import argparse [EOL] import typing [EOL] import logging [EOL] import argparse [EOL] from typing import List , Pattern [EOL] from pprint import pprint [EOL] from collections import defaultdict [EOL] from datetime import timedelta [EOL] [EOL] from aw_transform import heartbeat_reduce [EOL] from aw_transform . flood import flood [EOL] from aw_transform . simplify import simplify_string [EOL] [EOL] from aw_client import ActivityWatchClient [EOL] [EOL] from aw_research . redact import redact_words [EOL] from aw_research . algorithmia import run_sentiment , run_LDA [EOL] from aw_research . merge import merge_close_and_similar [EOL] from aw_research . classify import _main as _main_classify [EOL] from aw_research . classify import _build_argparse as _build_argparse_classify [EOL] [EOL] logging . basicConfig ( level = logging . INFO ) [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def assert_no_overlap ( events ) : [EOL] overlap = False [EOL] events = sorted ( events , key = lambda e : e . timestamp ) [EOL] for e1 , e2 in zip ( events [ : - [number] ] , events [ [number] : ] ) : [EOL] e1_end = e1 . timestamp + e1 . duration [EOL] gap = e2 . timestamp - e1_end [EOL] if gap < timedelta ( [number] ) : [EOL] logger . warning ( [string] . format ( gap ) ) [EOL] overlap = True [EOL] assert not overlap [EOL] [EOL] [EOL] def _get_window_events ( n = [number] ) : [EOL] client = ActivityWatchClient ( [string] , testing = True ) [EOL] buckets = client . get_buckets ( ) [EOL] [EOL] bucket_id = None [EOL] for _bid in buckets . keys ( ) : [EOL] if [string] in _bid and [string] not in _bid : [EOL] bucket_id = _bid [EOL] [EOL] if bucket_id : [EOL] return client . get_events ( bucket_id , limit = n ) [EOL] else : [EOL] print ( [string] ) [EOL] return [ ] [EOL] [EOL] [EOL] def _main_redact ( pattern , ignore_case ) : [EOL] logger . info ( [string] ) [EOL] events = _get_window_events ( ) [EOL] [EOL] logger . info ( [string] + pattern ) [EOL] events = redact_words ( events , pattern , ignore_case = ignore_case ) [EOL] [EOL] print ( [string] ) [EOL] [EOL] [EOL] def _main_analyse ( ) : [EOL] logger . info ( [string] ) [EOL] events = _get_window_events ( ) [EOL] [EOL] logger . info ( [string] ) [EOL] titles = list ( { e . data [ [string] ] for e in events } ) [EOL] out = run_LDA ( titles ) [EOL] pprint ( out . result ) [EOL] [EOL] out = run_sentiment ( titles ) [EOL] pprint ( [ r for r in out . result if r [ [string] ] != [number] ] ) [EOL] [EOL] out = run_sentiment ( [string] . join ( titles ) ) [EOL] pprint ( [ r for r in out . result if r [ [string] ] != [number] ] ) [EOL] [EOL] [EOL] def _main_merge ( ) : [EOL] logger . info ( [string] ) [EOL] events = _get_window_events ( n = [number] ) [EOL] events = simplify_string ( events ) [EOL] [EOL] merged_events = merge_close_and_similar ( events ) [EOL] print ( [string] . format ( len ( events ) , len ( merged_events ) ) ) [EOL] [EOL] [comment] [EOL] assert_no_overlap ( events ) [EOL] assert_no_overlap ( merged_events ) [EOL] print_most_common_titles ( events ) [EOL] print_most_common_titles ( merged_events ) [EOL] [EOL] [EOL] def _main_heartbeat_reduce ( ) : [EOL] logger . info ( [string] ) [EOL] events = _get_window_events ( ) [EOL] events = simplify_string ( events ) [EOL] [EOL] logger . info ( [string] ) [EOL] merged_events = heartbeat_reduce ( events , pulsetime = [number] ) [EOL] [EOL] [comment] [EOL] assert_no_overlap ( events ) [EOL] assert_no_overlap ( merged_events ) [EOL] print_most_common_titles ( events ) [EOL] print_most_common_titles ( merged_events ) [EOL] [EOL] [EOL] def _main_flood ( ) : [EOL] logger . info ( [string] ) [EOL] events = _get_window_events ( ) [EOL] events = simplify_string ( events ) [EOL] [EOL] logger . info ( [string] ) [EOL] merged_events = flood ( events ) [EOL] [EOL] [comment] [EOL] assert_no_overlap ( events ) [EOL] assert_no_overlap ( merged_events ) [EOL] print_most_common_titles ( events ) [EOL] print_most_common_titles ( merged_events ) [EOL] [EOL] [EOL] def print_most_common_titles ( events ) : [EOL] counter = defaultdict ( lambda : timedelta ( [number] ) ) [EOL] for e in events : [EOL] counter [ e . data [ [string] ] ] += e . duration [EOL] [EOL] print ( [string] * [number] ) [EOL] [EOL] def total_duration ( events ) : [EOL] return sum ( ( e . duration for e in events ) , timedelta ( [number] ) ) [EOL] [EOL] print ( [string] . format ( total_duration ( events ) ) ) [EOL] [EOL] pairs = sorted ( zip ( counter . values ( ) , counter . keys ( ) ) , reverse = True ) [EOL] for duration , title in pairs [ : [number] ] : [EOL] print ( [string] . format ( str ( duration ) , title ) ) [EOL] [EOL] print ( [string] * [number] ) [EOL] [EOL] [EOL] def main ( ) : [EOL] parser = argparse . ArgumentParser ( ) [EOL] subparsers = parser . add_subparsers ( dest = [string] ) [EOL] redact = subparsers . add_parser ( [string] ) [EOL] redact . add_argument ( [string] , help = [string] , ) [EOL] redact . add_argument ( [string] , action = [string] , help = [string] , ) [EOL] subparsers . add_parser ( [string] ) [EOL] subparsers . add_parser ( [string] ) [EOL] subparsers . add_parser ( [string] ) [EOL] subparsers . add_parser ( [string] ) [EOL] classify = subparsers . add_parser ( [string] ) [EOL] _build_argparse_classify ( classify ) [EOL] [EOL] args = parser . parse_args ( ) [EOL] [EOL] if args . cmd == [string] : [EOL] _main_redact ( args . pattern , args . ignore_case ) [EOL] elif args . cmd == [string] : [EOL] _main_analyse ( ) [EOL] elif args . cmd == [string] : [EOL] _main_merge ( ) [EOL] elif args . cmd == [string] : [EOL] _main_flood ( ) [EOL] elif args . cmd == [string] : [EOL] _main_heartbeat_reduce ( ) [EOL] elif args . cmd == [string] : [EOL] _main_classify ( args ) [EOL] else : [EOL] parser . print_usage ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] from typing import Callable , List , Tuple , Pattern [EOL] import typing [EOL] import logging [EOL] import aw_core [EOL] import builtins [EOL] import re [EOL] import logging [EOL] from typing import List , Callable , Tuple , Pattern , Any [EOL] from pprint import pprint [EOL] [EOL] from aw_core . models import Event [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def _redact_full ( event ) : [EOL] for key in event . data : [EOL] event . data [ key ] = [string] [EOL] return event [EOL] [EOL] [EOL] def _redact ( events , f ) : [EOL] n = [number] [EOL] for i , event in enumerate ( events ) : [EOL] for key in event . data : [EOL] if f ( event . data [ key ] ) : [EOL] n += [number] [EOL] logger . debug ( [string] . format ( event . data [ key ] ) ) [EOL] events [ i ] = _redact_full ( event ) [EOL] break [EOL] return events , n [EOL] [EOL] [EOL] def redact_words ( events , pattern , ignore_case = False ) : [EOL] r = re . compile ( pattern . lower ( ) if ignore_case else pattern ) [EOL] events , n_redacted = _redact ( events , lambda s : bool ( r . search ( s . lower ( ) if ignore_case else s ) ) ) [EOL] [EOL] percent = round ( [number] * n_redacted / len ( events ) , [number] ) [EOL] logger . info ( [string] . format ( len ( events ) , n_redacted , percent ) ) [EOL] [EOL] return events [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[typing.List[aw_core.models.Event],builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] from typing import Any , Dict , List [EOL] import typing [EOL] import datetime [EOL] import csv [EOL] import csv [EOL] from datetime import datetime , timedelta , timezone [EOL] import secrets [EOL] import json [EOL] [EOL] from tabulate import tabulate [EOL] [EOL] from aw_core . models import Event [EOL] import aw_client [EOL] [EOL] [EOL] def parse ( filepath ) : [EOL] events = [ ] [EOL] with open ( filepath , [string] ) as f : [EOL] c = csv . DictReader ( f ) [EOL] for r in c : [EOL] [comment] [EOL] dt = datetime . fromtimestamp ( float ( r [ [string] ] ) / [number] ) [EOL] tz_h , tz_m = map ( int , r [ [string] ] . split ( [string] ) [ [number] ] . split ( ) [ [number] ] . split ( [string] ) ) [EOL] dt = dt . replace ( tzinfo = timezone ( timedelta ( hours = tz_h , minutes = tz_m ) ) ) [EOL] td = timedelta ( milliseconds = float ( r [ [string] ] ) ) [EOL] e = Event ( timestamp = dt , duration = td , data = { [string] : r [ [string] ] , [string] : r [ [string] ] , [string] : r [ [string] ] , [string] : r [ [string] ] , } , ) [EOL] events . append ( e ) [EOL] return events [EOL] [EOL] [EOL] def import_as_bucket ( filepath ) : [EOL] events = parse ( filepath ) [EOL] end = max ( e . timestamp + e . duration for e in events ) [EOL] bucket = { [string] : f" [string] { end . date ( ) } [string] { secrets . token_hex ( [number] ) }" , [string] : datetime . now ( ) , [string] : [string] , [string] : [string] , [string] : [string] , [string] : { [string] : True , } , [string] : events , } [EOL] return bucket [EOL] [EOL] [EOL] def print_info ( bucket ) : [EOL] events = bucket [ [string] ] [EOL] rows = [ ] [EOL] for a in [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , ] : [EOL] rows . append ( [ a , sum ( ( e . duration for e in events if a in e . data [ [string] ] ) , timedelta ( [number] ) , ) , ] ) [EOL] rows = sorted ( rows , key = lambda r : - r [ [number] ] ) [EOL] print ( tabulate ( rows , [ [string] , [string] ] ) ) [EOL] [EOL] [EOL] def default ( o ) : [EOL] if hasattr ( o , [string] ) : [EOL] return o . isoformat ( ) [EOL] elif hasattr ( o , [string] ) : [EOL] return o . total_seconds ( ) [EOL] else : [EOL] raise NotImplementedError [EOL] [EOL] [EOL] def save_bucket ( bucket ) : [EOL] filename = bucket [ [string] ] + [string] [EOL] with open ( filename , [string] ) as f : [EOL] json . dump ( bucket , f , indent = True , default = default ) [EOL] print ( f" [string] { filename }" ) [EOL] [EOL] [EOL] def import_to_awserver ( bucket ) : [EOL] awc = aw_client . ActivityWatchClient ( [string] , testing = True ) [EOL] buckets = json . loads ( json . dumps ( { [string] : [ bucket ] } , default = default ) ) [EOL] awc . _post ( [string] , buckets ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] import sys [EOL] [EOL] assert len ( sys . argv ) > [number] [EOL] filename = sys . argv . pop ( ) [EOL] bucket = import_as_bucket ( filename ) [EOL] save_bucket ( bucket ) [EOL] [comment] [EOL] print_info ( bucket ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $builtins.str$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $builtins.str$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0
from aw_research import * [EOL] [EOL] [EOL] def test_imports ( ) : [EOL] pass [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] from aw_core . models import Event [EOL] [EOL] from aw_research . redact import redact_words [EOL] [EOL] [EOL] def test_redact_word ( ) : [EOL] e = Event ( data = { [string] : [string] , [string] : [string] } ) [EOL] e = redact_words ( [ e ] , [string] ) [ [number] ] [EOL] assert [string] not in e . data [ [string] ] [EOL] assert [string] in e . data [ [string] ] [EOL] assert [string] in e . data [ [string] ] [EOL] [EOL] e = redact_words ( [ e ] , [string] , ignore_case = True ) [ [number] ] [EOL] assert [string] not in e . data [ [string] ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0