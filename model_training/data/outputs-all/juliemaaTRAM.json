[comment] [EOL] from typing import Dict , Any [EOL] import argparse [EOL] import typing [EOL] [docstring] [EOL] [EOL] import sys [EOL] from os . path import exists , splitext [EOL] import argparse [EOL] import textwrap [EOL] import lib . db as db [EOL] import lib . blast as blast [EOL] import lib . util as util [EOL] [EOL] [EOL] def create_fasta_files ( args ) : [EOL] [docstring] [EOL] if not exists ( db . get_db_name ( args [ [string] ] ) ) : [EOL] sys . exit ( [string] ) [EOL] [EOL] with db . connect ( args [ [string] ] , check_version = True ) as cxn : [EOL] try : [EOL] files = open_fasta_files ( args , cxn ) [EOL] [EOL] for rec in db . get_all_sequences ( cxn ) : [EOL] util . write_fasta_record ( files [ rec [ [number] ] ] , rec [ [number] ] , rec [ [number] ] , rec [ [number] ] ) [EOL] [EOL] finally : [EOL] close_fasta_files ( files ) [EOL] [EOL] [EOL] def open_fasta_files ( args , cxn ) : [EOL] [docstring] [EOL] files = { } [EOL] for end in [ e [ [number] ] for e in db . get_sequence_ends ( cxn ) ] : [EOL] name = [string] . format ( args [ [string] ] , end , args [ [string] ] ) [EOL] files [ end ] = open ( name , [string] ) [EOL] return files [EOL] [EOL] [EOL] def close_fasta_files ( files ) : [EOL] [docstring] [EOL] for file in files . values ( ) : [EOL] file . close ( ) [EOL] [EOL] [EOL] def parse_command_line ( ) : [EOL] [docstring] [EOL] description = [string] [EOL] parser = argparse . ArgumentParser ( fromfile_prefix_chars = [string] , formatter_class = argparse . RawDescriptionHelpFormatter , description = textwrap . dedent ( description ) ) [EOL] [EOL] parser . add_argument ( [string] , action = [string] , version = [string] . format ( db . ATRAM_VERSION ) ) [EOL] [EOL] parser . add_argument ( [string] , [string] , [string] , [string] , [string] , required = True , metavar = [string] , help = [string] ) [EOL] [EOL] parser . add_argument ( [string] , [string] , required = True , help = [string] ) [EOL] [EOL] args = vars ( parser . parse_args ( ) ) [EOL] [EOL] args [ [string] ] = blast . touchup_blast_db_names ( [ args [ [string] ] ] ) [ [number] ] [EOL] [EOL] ( args [ [string] ] , args [ [string] ] ) = splitext ( args [ [string] ] ) [EOL] args [ [string] ] = args [ [string] ] if args [ [string] ] else [string] [EOL] [EOL] return args [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] ARGS = parse_command_line ( ) [EOL] create_fasta_files ( ARGS ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0
[comment] [EOL] from typing import Dict , List , Any [EOL] import typing [EOL] import argparse [EOL] [docstring] [EOL] [EOL] import argparse [EOL] import os [EOL] import textwrap [EOL] from datetime import date [EOL] from glob import glob [EOL] from itertools import chain [EOL] from os . path import join [EOL] [EOL] import lib . blast as blast [EOL] import lib . db as db [EOL] import lib . util as util [EOL] from lib . core_preprocessor import preprocess [EOL] [EOL] [EOL] def parse_command_line ( ) : [EOL] [docstring] [EOL] description = [string] [EOL] [EOL] parser = argparse . ArgumentParser ( fromfile_prefix_chars = [string] , description = textwrap . dedent ( description ) ) [EOL] [EOL] parser . add_argument ( [string] , action = [string] , version = [string] . format ( db . ATRAM_VERSION ) ) [EOL] [EOL] parser . add_argument ( [string] , [string] , metavar = [string] , action = [string] , help = [string] ) [EOL] [EOL] parser . add_argument ( [string] , [string] , metavar = [string] , action = [string] , help = [string] ) [EOL] [EOL] parser . add_argument ( [string] , [string] , metavar = [string] , action = [string] , help = [string] ) [EOL] [EOL] parser . add_argument ( [string] , [string] , metavar = [string] , action = [string] , help = [string] ) [EOL] [EOL] group = parser . add_argument_group ( [string] ) [EOL] [EOL] blast_db = join ( [string] , [string] + date . today ( ) . isoformat ( ) ) [EOL] group . add_argument ( [string] , [string] , [string] , default = blast_db , metavar = [string] , help = [string] . format ( blast_db ) ) [EOL] [EOL] cpus = min ( [number] , os . cpu_count ( ) - [number] if os . cpu_count ( ) > [number] else [number] ) [EOL] group . add_argument ( [string] , [string] , [string] , type = int , default = cpus , help = [string] . format ( cpus ) ) [EOL] [EOL] group . add_argument ( [string] , [string] , metavar = [string] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , action = [string] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , [string] , help = [string] ) [EOL] group . add_argument ( [string] , choices = [ [string] , [string] , [string] , [string] ] , default = [string] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , [string] , [string] , type = int , metavar = [string] , dest = [string] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , action = [string] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , action = [string] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , action = [string] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , action = [string] , help = [string] ) [EOL] [EOL] args = vars ( parser . parse_args ( ) ) [EOL] [EOL] [comment] [EOL] if args [ [string] ] : [EOL] os . environ [ [string] ] = [string] . format ( args [ [string] ] , os . environ [ [string] ] ) [EOL] [EOL] all_files = [ ] [EOL] for ends in [ [string] , [string] , [string] , [string] ] : [EOL] if args . get ( ends ) : [EOL] end_files = [ glob ( p ) for p in args [ ends ] ] [EOL] end_files = sorted ( list ( chain . from_iterable ( end_files ) ) ) [EOL] args [ ends ] = end_files [EOL] all_files . extend ( end_files ) [EOL] [EOL] args [ [string] ] = blast . default_shard_count ( args , all_files ) [EOL] [EOL] blast . make_blast_output_dir ( args [ [string] ] ) [EOL] [EOL] blast . find_program ( [string] ) [EOL] [EOL] util . temp_dir_exists ( args [ [string] ] ) [EOL] [EOL] return args [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] ARGS = parse_command_line ( ) [EOL] preprocess ( ARGS ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0
[comment] [EOL] from typing import Dict , Tuple , Literal , Match , Optional , Union , Any [EOL] import typing [EOL] import typing_extensions [EOL] [docstring] [EOL] [EOL] import re [EOL] import sys [EOL] import subprocess [EOL] from functools import reduce [EOL] from distutils . version import LooseVersion [EOL] from shutil import which [EOL] [EOL] [EOL] RESULTS = { } [EOL] [EOL] [EOL] def test_format ( name , value ) : [EOL] [docstring] [EOL] RESULTS [ name ] = value [EOL] value = [string] if value else [string] [EOL] print ( name . ljust ( [number] , [string] ) , value ) [EOL] [EOL] [EOL] def parse_requirements ( requirements ) : [EOL] [docstring] [EOL] reqs = { } [EOL] for req in requirements . split ( ) : [EOL] match = re . match ( [string] , req ) [EOL] module = match . group ( [number] ) [EOL] compare = match . group ( [number] ) [EOL] version = LooseVersion ( match . group ( [number] ) ) . version [EOL] reqs [ module ] = { [string] : compare , [string] : version } [EOL] return reqs [EOL] [EOL] [EOL] def check_modules ( ) : [EOL] [docstring] [EOL] modules = subprocess . check_output ( [ sys . executable , [string] , [string] , [string] ] ) [EOL] installed_list = parse_requirements ( modules . decode ( [string] ) ) [EOL] [EOL] with open ( [string] ) as requirements : [EOL] required_list = parse_requirements ( requirements . read ( ) ) [EOL] [EOL] for module , required in required_list . items ( ) : [EOL] installed = installed_list [ module ] [EOL] [EOL] cmp = required [ [string] ] [EOL] i_version = installed [ [string] ] [EOL] r_version = required [ [string] ] [EOL] [EOL] if cmp == [string] and i_version != r_version : [EOL] test_format ( module , False ) [EOL] elif cmp == [string] and i_version > r_version : [EOL] test_format ( module , True ) [EOL] elif i_version < r_version : [EOL] test_format ( module , False ) [EOL] [EOL] [EOL] def check_programs ( ) : [EOL] [docstring] [EOL] test_format ( [string] , which ( [string] ) ) [EOL] test_format ( [string] , which ( [string] ) ) [EOL] test_format ( [string] , which ( [string] ) ) [EOL] test_format ( [string] , which ( [string] ) ) [EOL] test_format ( [string] , which ( [string] ) ) [EOL] test_format ( [string] , which ( [string] ) and which ( [string] ) ) [EOL] test_format ( [string] , which ( [string] ) ) [EOL] test_format ( [string] , which ( [string] ) ) [EOL] test_format ( [string] , which ( [string] ) ) [EOL] test_format ( [string] , which ( [string] ) ) [EOL] [EOL] [EOL] def requires ( module , because , program = None ) : [EOL] [docstring] [EOL] if not program : [EOL] program = [string] [EOL] if not RESULTS [ module ] : [EOL] print ( [string] . format ( program , because ) ) [EOL] [EOL] [EOL] def assembler ( module , but ) : [EOL] [docstring] [EOL] if not RESULTS [ module ] : [EOL] print ( [string] . format ( but ) ) [EOL] [EOL] [EOL] def report_results ( ) : [EOL] [docstring] [EOL] print ( [string] ) [EOL] [EOL] if reduce ( lambda a , b : a and b , RESULTS . values ( ) ) : [EOL] print ( [string] ) [EOL] return [EOL] [EOL] requires ( [string] , [string] ) [EOL] requires ( [string] , [string] ) [EOL] requires ( [string] , [string] ) [EOL] requires ( [string] , [string] ) [EOL] requires ( [string] , [string] ) [EOL] requires ( [string] , [string] ) [EOL] requires ( [string] , [string] ) [EOL] requires ( [string] , [string] , [string] ) [EOL] [EOL] assembler ( [string] , [string] ) [EOL] assembler ( [string] , [string] ) [EOL] assembler ( [string] , [string] ) [EOL] assembler ( [string] , [string] ) [EOL] assembler ( [string] , [string] ) [EOL] assembler ( [string] , ( [string] [string] ) ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] test_format ( [string] , sys . version_info . major == [number] and sys . version_info . minor >= [number] ) [EOL] [EOL] check_programs ( ) [EOL] check_modules ( ) [EOL] report_results ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] from typing import Match , Optional [EOL] import typing [EOL] [docstring] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import re [EOL] from setuptools import setup , find_packages [EOL] [EOL] [EOL] def readme ( ) : [EOL] [docstring] [EOL] with open ( [string] , [string] ) as f : [EOL] return f . read ( ) [EOL] [EOL] [EOL] def license_ ( ) : [EOL] [docstring] [EOL] with open ( [string] , [string] ) as f : [EOL] return f . read ( ) [EOL] [EOL] [EOL] def find_version ( ) : [EOL] [docstring] [EOL] regex = [string] [EOL] with open ( [string] , [string] ) as f : [EOL] match = re . search ( regex , f . read ( ) , re . M ) [EOL] if match : [EOL] return match . group ( [number] ) [EOL] [EOL] raise RuntimeError ( [string] ) [EOL] [EOL] [EOL] def find_requirements ( ) : [EOL] [docstring] [EOL] with open ( [string] , [string] ) as f : [EOL] return f . read ( ) . splitlines ( ) [EOL] [EOL] [EOL] setup ( name = [string] , version = find_version ( ) , packages = find_packages ( ) , install_requires = find_requirements ( ) , description = [string] , long_description = readme ( ) , license = license_ ( ) , url = [string] , python_requires = [string] , scripts = [ [string] , [string] , [string] , [string] , ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] from typing import Any [EOL] import argparse [EOL] import typing [EOL] [docstring] [EOL] [EOL] import argparse [EOL] import textwrap [EOL] from datetime import date [EOL] from os . path import join [EOL] [EOL] import lib . core_framer as framer [EOL] import lib . db as db [EOL] import lib . util as util [EOL] [EOL] [EOL] def parse_command_line ( ) : [EOL] [docstring] [EOL] description = [string] [EOL] [EOL] parser = argparse . ArgumentParser ( fromfile_prefix_chars = [string] , description = textwrap . dedent ( description ) ) [EOL] [EOL] parser . add_argument ( [string] , action = [string] , version = [string] . format ( db . ATRAM_VERSION ) ) [EOL] [EOL] parser . add_argument ( [string] , [string] , metavar = [string] , required = True , help = [string] ) [EOL] [EOL] parser . add_argument ( [string] , [string] , [string] , metavar = [string] , required = True , help = [string] ) [EOL] [EOL] parser . add_argument ( [string] , [string] , metavar = [string] , required = True , help = [string] ) [EOL] [EOL] parser . add_argument ( [string] , [string] , metavar = [string] , default = [number] , type = int , help = [string] ) [EOL] [EOL] parser . add_argument ( [string] , [string] , metavar = [string] , help = [string] ) [EOL] [EOL] parser . add_argument ( [string] , action = [string] , help = [string] ) [EOL] [EOL] parser . add_argument ( [string] , [string] , help = [string] ) [EOL] parser . add_argument ( [string] , choices = [ [string] , [string] , [string] , [string] ] , default = [string] , help = [string] ) [EOL] [EOL] parser . add_argument ( [string] , [string] , help = [string] ) [EOL] [EOL] parser . add_argument ( [string] , [string] , default = [string] , help = [string] ) [EOL] [EOL] parser . add_argument ( [string] , action = [string] , help = [string] ) [EOL] [EOL] parser . add_argument ( [string] , type = float , default = [number] , help = [string] ) [EOL] [EOL] args = parser . parse_args ( ) [EOL] [EOL] util . temp_dir_exists ( args . temp_dir ) [EOL] [EOL] if not args . output_prefix : [EOL] args . output_prefix = join ( [string] , [string] + date . today ( ) . isoformat ( ) ) [EOL] [EOL] return args [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] ARGS = parse_command_line ( ) [EOL] framer . frame ( ARGS ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0
[comment] [EOL] from typing import Dict , Any [EOL] import argparse [EOL] import lib [EOL] import typing [EOL] [docstring] [EOL] [EOL] import argparse [EOL] import os [EOL] import textwrap [EOL] [EOL] import lib . assembler as assembly [EOL] import lib . bio as bio [EOL] import lib . blast as blast [EOL] import lib . db as db [EOL] import lib . util as util [EOL] from lib . core_atram import assemble [EOL] from lib . log import Logger [EOL] [EOL] [EOL] def parse_command_line ( ) : [EOL] [docstring] [EOL] description = [string] [EOL] parser = argparse . ArgumentParser ( fromfile_prefix_chars = [string] , description = textwrap . dedent ( description ) ) [EOL] [EOL] parser . add_argument ( [string] , action = [string] , version = [string] . format ( db . ATRAM_VERSION ) ) [EOL] [EOL] group = parser . add_argument_group ( [string] ) [EOL] [EOL] group . add_argument ( [string] , [string] , [string] , [string] , [string] , required = True , metavar = [string] , nargs = [string] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , [string] , [string] , [string] , required = False , nargs = [string] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , [string] , [string] , required = False , nargs = [string] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , [string] , required = True , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , [string] , default = [string] , choices = [ [string] , [string] , [string] , [string] , [string] ] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , [string] , type = int , default = [number] , metavar = [string] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , [string] , action = [string] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , type = float , default = [number] , help = [string] ) [EOL] [EOL] cpus = min ( [number] , os . cpu_count ( ) - [number] if os . cpu_count ( ) > [number] else [number] ) [EOL] group . add_argument ( [string] , [string] , [string] , type = int , default = cpus , help = [string] . format ( cpus , os . cpu_count ( ) ) ) [EOL] [EOL] group . add_argument ( [string] , help = [string] ) [EOL] group . add_argument ( [string] , choices = [ [string] , [string] , [string] , [string] ] , default = [string] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , [string] , metavar = [string] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , action = [string] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , [string] , metavar = [string] , default = [number] , type = int , help = [string] ) [EOL] [EOL] group = parser . add_argument_group ( [string] ) [EOL] [EOL] group . add_argument ( [string] , action = [string] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , type = float , default = [number] , metavar = [string] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , [string] , type = int , default = [number] , help = [string] ) [EOL] [EOL] blast . command_line_args ( parser ) [EOL] assembly . command_line_args ( parser ) [EOL] [EOL] args = vars ( parser . parse_args ( ) ) [EOL] [EOL] log = Logger ( args . get ( [string] ) , args . get ( [string] ) ) [EOL] [EOL] check_query_args ( args , log ) [EOL] blast . check_args ( args ) [EOL] [EOL] [comment] [EOL] args [ [string] ] = assembly . default_cov_cutoff ( log , args [ [string] ] ) [EOL] args [ [string] ] = blast . touchup_blast_db_names ( args [ [string] ] ) [EOL] args [ [string] ] = assembly . default_kmer ( args [ [string] ] , args [ [string] ] ) [EOL] args [ [string] ] = blast . default_max_target_seqs ( log , args [ [string] ] , args [ [string] ] , args [ [string] ] ) [EOL] [EOL] [comment] [EOL] args [ [string] ] = max ( [number] , args [ [string] ] ) [EOL] if not ( args [ [string] ] ) : [EOL] args [ [string] ] = None [EOL] [EOL] setup_blast_args ( args ) [EOL] set_protein_arg ( args ) [EOL] setup_path_arg ( args ) [EOL] find_programs ( args ) [EOL] util . temp_dir_exists ( args [ [string] ] , args . get ( [string] ) ) [EOL] util . set_blast_batch_size ( args [ [string] ] ) [EOL] [EOL] return args [EOL] [EOL] [EOL] def setup_path_arg ( args ) : [EOL] [docstring] [EOL] if args [ [string] ] : [EOL] os . environ [ [string] ] = [string] . format ( args [ [string] ] , os . environ [ [string] ] ) [EOL] [EOL] [EOL] def setup_blast_args ( args ) : [EOL] [docstring] [EOL] if args [ [string] ] : [EOL] args [ [string] ] = [number] [EOL] args [ [string] ] = [number] [EOL] [EOL] [EOL] def check_query_args ( args , log ) : [EOL] [docstring] [EOL] if not args . get ( [string] ) and not args . get ( [string] ) : [EOL] err = [string] [EOL] log . fatal ( err ) [EOL] [EOL] [EOL] def set_protein_arg ( args ) : [EOL] [docstring] [EOL] if not args [ [string] ] and args [ [string] ] : [EOL] args [ [string] ] = bio . fasta_file_has_protein ( args [ [string] ] ) [EOL] [EOL] [EOL] def find_programs ( args ) : [EOL] [docstring] [EOL] blast . find_program ( [string] ) [EOL] blast . find_program ( [string] ) [EOL] blast . find_program ( [string] ) [EOL] [EOL] assembly . find_program ( [string] , [string] , args [ [string] ] , not args [ [string] ] ) [EOL] [EOL] assembly . find_program ( [string] , [string] , args [ [string] ] ) [EOL] assembly . find_program ( [string] , [string] , args [ [string] ] , args [ [string] ] ) [EOL] [EOL] assembly . find_program ( [string] , [string] , args [ [string] ] ) [EOL] assembly . find_program ( [string] , [string] , args [ [string] ] ) [EOL] [EOL] assembly . find_program ( [string] , [string] , args [ [string] ] ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] ARGS = parse_command_line ( ) [EOL] assemble ( ARGS ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0
from typing import Dict , Tuple , Set , Any , DefaultDict [EOL] import _csv [EOL] import lib [EOL] import typing [EOL] [docstring] [EOL] [EOL] import csv [EOL] from collections import defaultdict [EOL] from itertools import product [EOL] [EOL] from . import bio , db_stitcher as db , exonerate , util [EOL] from . log import Logger [EOL] [EOL] [EOL] def frame ( args ) : [EOL] [docstring] [EOL] log = Logger ( args . log_file , args . log_level ) [EOL] log . header ( ) [EOL] [EOL] iteration = [number] [EOL] [EOL] with util . make_temp_dir ( where = args . temp_dir , prefix = [string] , keep = args . keep_temp_dir ) as temp_dir : [EOL] with db . connect ( temp_dir , [string] ) as cxn : [EOL] cxn . row_factory = lambda c , r : { col [ [number] ] : r [ idx ] for idx , col in enumerate ( c . description ) } [EOL] exonerate . create_tables ( cxn ) [EOL] [EOL] taxon_names = exonerate . get_taxa ( args , log ) [EOL] exonerate . insert_reference_genes ( args , temp_dir , cxn , log ) [EOL] exonerate . check_file_counts ( args , cxn , log , taxon_names ) [EOL] exonerate . create_reference_files ( cxn , log ) [EOL] [EOL] iteration += [number] [EOL] exonerate . get_contigs_from_fasta ( args , temp_dir , cxn , log , taxon_names , iteration ) [EOL] exonerate . contig_file_write ( cxn , log ) [EOL] exonerate . run_exonerate ( temp_dir , cxn , log , iteration ) [EOL] [EOL] output_contigs ( args , cxn , log ) [EOL] [EOL] log . info ( [string] ) [EOL] output_summary_per_gene ( args , cxn , taxon_names ) [EOL] output_summary_per_taxon ( args , cxn , taxon_names ) [EOL] [EOL] log . info ( [string] ) [EOL] [EOL] [EOL] def output_contigs ( args , cxn , log ) : [EOL] [docstring] [EOL] log . info ( [string] ) [EOL] [EOL] for ref in db . select_reference_genes ( cxn ) : [EOL] ref_name = ref [ [string] ] [EOL] ref_len = len ( ref [ [string] ] ) * bio . CODON_LEN [EOL] [EOL] names_seen = defaultdict ( int ) [EOL] [EOL] out_path = util . prefix_file ( args . output_prefix , [string] . format ( ref_name ) ) [EOL] [EOL] with open ( out_path , [string] ) as out_file : [EOL] [EOL] for contig in db . select_exonerate_ref_gene ( cxn , ref_name , args . min_length ) : [EOL] [EOL] contig_name = exonerate . handle_duplicate_name ( contig [ [string] ] , names_seen ) [EOL] [EOL] seq = [string] * ( contig [ [string] ] * bio . CODON_LEN ) [EOL] seq += contig [ [string] ] [EOL] seq += [string] * ( ref_len - len ( seq ) ) [EOL] util . write_fasta_record ( out_file , contig_name , seq ) [EOL] [EOL] [EOL] def output_summary_per_gene ( args , cxn , taxon_names ) : [EOL] [docstring] [EOL] longest = max ( db . select_longest ( cxn ) , [number] ) [EOL] lengths = db . select_seq_lengths ( cxn ) [EOL] [EOL] counts = { t : { [string] : set ( ) , [string] : set ( ) } for t in taxon_names } [EOL] [EOL] for length in lengths : [EOL] taxon_name = length [ [string] ] [EOL] ref_name = length [ [string] ] [EOL] counts [ taxon_name ] [ [string] ] . add ( ref_name ) [EOL] fraction = length [ [string] ] / longest [EOL] if fraction >= args . long_contig : [EOL] counts [ taxon_name ] [ [string] ] . add ( ref_name ) [EOL] [EOL] out_path = util . prefix_file ( args . output_prefix , [string] ) [EOL] with open ( out_path , [string] ) as out_file : [EOL] writer = csv . writer ( out_file ) [EOL] writer . writerow ( [ [string] , [string] , [string] . format ( args . long_contig ) ] ) [EOL] for taxon , count in counts . items ( ) : [EOL] writer . writerow ( [ taxon , len ( count [ [string] ] ) , len ( count [ [string] ] ) ] ) [EOL] [EOL] [EOL] def output_summary_per_taxon ( args , cxn , taxon_names ) : [EOL] [docstring] [EOL] longest = max ( db . select_longest ( cxn ) , [number] ) [EOL] lengths = db . select_seq_lengths ( cxn ) [EOL] ref_names = [ r [ [string] ] for r in db . select_reference_genes ( cxn ) ] [EOL] [EOL] counts = { c : { [string] : [number] , [string] : [number] } for c in product ( taxon_names , ref_names ) } [EOL] [EOL] for length in lengths : [EOL] taxon_name = length [ [string] ] [EOL] ref_name = length [ [string] ] [EOL] key = ( taxon_name , ref_name ) [EOL] counts [ key ] [ [string] ] += [number] [EOL] fraction = length [ [string] ] / longest [EOL] if fraction >= args . long_contig : [EOL] counts [ key ] [ [string] ] += [number] [EOL] [EOL] out_path = util . prefix_file ( args . output_prefix , [string] ) [EOL] with open ( out_path , [string] ) as out_file : [EOL] writer = csv . writer ( out_file ) [EOL] writer . writerow ( [ [string] , [string] , [string] , [string] . format ( args . long_contig ) ] ) [EOL] for key , count in counts . items ( ) : [EOL] writer . writerow ( [ key [ [number] ] , key [ [number] ] , count [ [string] ] , count [ [string] ] ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , List , Any [EOL] import typing [EOL] import multiprocessing [EOL] import lib [EOL] [docstring] [EOL] [EOL] import os [EOL] import re [EOL] from multiprocessing import Pool [EOL] from os . path import basename , join , split , splitext [EOL] [EOL] from Bio import SeqIO [EOL] [EOL] from . import assembler as assembly , bio , blast , db , db_atram , util [EOL] from . log import Logger [EOL] [EOL] [EOL] def assemble ( args ) : [EOL] [docstring] [EOL] with util . make_temp_dir ( where = args [ [string] ] , prefix = [string] , keep = args [ [string] ] ) as temp_dir : [EOL] util . update_temp_dir ( temp_dir , args ) [EOL] [EOL] queries = split_queries ( args ) [EOL] [EOL] for blast_db in args [ [string] ] : [EOL] with db . connect ( blast_db , check_version = True ) as cxn : [EOL] for query in queries : [EOL] db . aux_db ( cxn , args [ [string] ] , blast_db , query ) [EOL] clean_database ( cxn ) [EOL] [EOL] log = Logger ( args [ [string] ] , args [ [string] ] ) [EOL] log . header ( ) [EOL] [EOL] assembler = assembly . factory ( args , cxn , log ) [EOL] [EOL] try : [EOL] assembly_loop ( args , log , assembler , blast_db , query ) [EOL] except ( TimeoutError , RuntimeError ) : [EOL] pass [EOL] except Exception as err : [comment] [EOL] log . error ( [string] . format ( err ) ) [EOL] finally : [EOL] assembler . write_final_output ( blast_db , query ) [EOL] [EOL] db . aux_detach ( cxn ) [EOL] [EOL] [EOL] def assembly_loop ( args , log , assembler , blast_db , query ) : [EOL] [docstring] [EOL] for iteration in range ( [number] , assembler . args [ [string] ] + [number] ) : [EOL] log . info ( [string] . format ( blast_db , split ( query ) [ [number] ] , iteration ) ) [EOL] [EOL] assembler . init_iteration ( blast_db , query , iteration ) [EOL] [EOL] with util . make_temp_dir ( where = args [ [string] ] , prefix = assembler . file_prefix ( ) , keep = args [ [string] ] ) as iter_dir : [EOL] [EOL] assembler . setup_files ( iter_dir ) [EOL] [EOL] query = assembly_loop_iteration ( args , log , assembler ) [EOL] [EOL] if not query : [EOL] break [EOL] [EOL] else : [EOL] log . info ( [string] ) [EOL] [EOL] [EOL] def assembly_loop_iteration ( args , log , assembler ) : [EOL] [docstring] [EOL] blast_query_against_all_shards ( log , assembler ) [EOL] [EOL] count = assembler . count_blast_hits ( ) [EOL] if assembler . blast_only or count == [number] : [EOL] return False [EOL] [EOL] assembler . write_input_files ( ) [EOL] [EOL] assembler . run ( ) [EOL] [EOL] if assembler . nothing_assembled ( ) : [EOL] return False [EOL] [EOL] high_score = filter_contigs ( log , assembler ) [EOL] [EOL] count = assembler . assembled_contigs_count ( high_score ) [EOL] [EOL] if not count : [EOL] return False [EOL] [EOL] if assembler . no_new_contigs ( count ) : [EOL] return False [EOL] [EOL] return create_query_from_contigs ( args , log , assembler ) [EOL] [EOL] [EOL] def split_queries ( args ) : [EOL] [docstring] [EOL] if not args . get ( [string] ) : [EOL] return args [ [string] ] [ : ] [EOL] [EOL] queries = [ ] [EOL] [EOL] path = join ( args [ [string] ] , [string] ) [EOL] os . makedirs ( path , exist_ok = True ) [EOL] [EOL] for query_path in args [ [string] ] : [EOL] [EOL] query_name = splitext ( basename ( query_path ) ) [ [number] ] [EOL] [EOL] with open ( query_path ) as query_file : [EOL] for i , rec in enumerate ( SeqIO . parse ( query_file , [string] ) , [number] ) : [EOL] [EOL] query_id = re . sub ( [string] , [string] , rec . id ) [EOL] [EOL] query_file = join ( path , [string] . format ( query_name , query_id , i ) ) [EOL] [EOL] write_query_seq ( query_file , rec . id , str ( rec . seq ) ) [EOL] [EOL] queries . append ( query_file ) [EOL] [EOL] if not args . get ( [string] ) : [EOL] args [ [string] ] = bio . fasta_file_has_protein ( queries ) [EOL] [EOL] return queries [EOL] [EOL] [EOL] def write_query_seq ( file_name , seq_id , seq ) : [EOL] [docstring] [EOL] with open ( file_name , [string] ) as query_file : [EOL] util . write_fasta_record ( query_file , seq_id , seq ) [EOL] [EOL] [EOL] def clean_database ( cxn ) : [EOL] [docstring] [EOL] db_atram . create_sra_blast_hits_table ( cxn ) [EOL] db_atram . create_contig_blast_hits_table ( cxn ) [EOL] db_atram . create_assembled_contigs_table ( cxn ) [EOL] [EOL] [EOL] def blast_query_against_all_shards ( log , assembler ) : [EOL] [docstring] [EOL] log . info ( [string] . format ( assembler . state [ [string] ] ) ) [EOL] [EOL] all_shards = shard_fraction ( log , assembler ) [EOL] [EOL] with Pool ( processes = assembler . args [ [string] ] ) as pool : [EOL] results = [ pool . apply_async ( blast_query_against_one_shard , ( assembler . args , assembler . simple_state ( ) , shard ) ) for shard in all_shards ] [EOL] all_results = [ result . get ( ) for result in results ] [EOL] [EOL] insert_blast_results ( all_shards , assembler . args , assembler . simple_state ( ) , log ) [EOL] log . info ( [string] . format ( len ( all_results ) ) ) [EOL] [EOL] [EOL] def insert_blast_results ( all_shards , args , state , log ) : [EOL] [docstring] [EOL] with db . connect ( state [ [string] ] ) as cxn : [EOL] db . aux_db ( cxn , args [ [string] ] , state [ [string] ] , state [ [string] ] ) [EOL] [EOL] for shard in all_shards : [EOL] shard = basename ( shard ) [EOL] [EOL] batch = [ ] [EOL] output_file = blast . output_file_name ( state [ [string] ] , shard ) [EOL] [EOL] hits = blast . hits ( log , output_file ) [EOL] is_single_end = db . is_single_end ( cxn ) [EOL] for hit in hits : [EOL] seq_name , seq_end = blast . parse_blast_title ( hit [ [string] ] , is_single_end ) [EOL] batch . append ( ( state [ [string] ] , seq_end , seq_name , shard ) ) [EOL] db_atram . insert_blast_hit_batch ( cxn , batch ) [EOL] [EOL] db . aux_detach ( cxn ) [EOL] [EOL] [EOL] def blast_query_against_one_shard ( args , state , shard ) : [EOL] [docstring] [EOL] log = Logger ( args [ [string] ] , args [ [string] ] ) [EOL] output_file = blast . output_file_name ( state [ [string] ] , shard ) [EOL] blast . against_sra ( args , log , state , output_file , shard ) [EOL] [EOL] [EOL] def shard_fraction ( log , assembler ) : [EOL] [docstring] [EOL] all_shards = blast . all_shard_paths ( log , assembler . state [ [string] ] ) [EOL] last_index = int ( len ( all_shards ) * assembler . args [ [string] ] ) [EOL] return all_shards [ : last_index ] [EOL] [EOL] [EOL] def filter_contigs ( log , assembler ) : [EOL] [docstring] [EOL] log . info ( [string] . format ( assembler . state [ [string] ] ) ) [EOL] [EOL] blast_db = blast . temp_db_name ( assembler . state [ [string] ] , assembler . state [ [string] ] ) [EOL] [EOL] hits_file = blast . output_file_name ( assembler . state [ [string] ] , assembler . state [ [string] ] ) [EOL] [EOL] blast . create_db ( log , assembler . state [ [string] ] , assembler . file [ [string] ] , blast_db ) [EOL] [EOL] blast . against_contigs ( log , blast_db , assembler . state [ [string] ] , hits_file , protein = assembler . args [ [string] ] , db_gencode = assembler . args [ [string] ] , temp_dir = assembler . args [ [string] ] , timeout = assembler . args [ [string] ] ) [EOL] [EOL] save_blast_against_contigs ( log , assembler , hits_file ) [EOL] [EOL] all_hits = { row [ [string] ] : row for row in db_atram . get_contig_blast_hits ( assembler . state [ [string] ] , assembler . state [ [string] ] ) } [EOL] [EOL] return save_contigs ( assembler , all_hits ) [EOL] [EOL] [EOL] def save_blast_against_contigs ( log , assembler , hits_file ) : [EOL] [docstring] [EOL] batch = [ ] [EOL] [EOL] for hit in blast . hits ( log , hits_file ) : [EOL] contig_id = assembler . parse_contig_id ( hit [ [string] ] ) [EOL] batch . append ( ( assembler . state [ [string] ] , contig_id , hit [ [string] ] , hit [ [string] ] , hit [ [string] ] , hit [ [string] ] , hit [ [string] ] , hit . get ( [string] , [string] ) , hit [ [string] ] , hit [ [string] ] , hit . get ( [string] , [string] ) ) ) [EOL] [EOL] db_atram . insert_contig_hit_batch ( assembler . state [ [string] ] , batch ) [EOL] [EOL] [EOL] def save_contigs ( assembler , all_hits ) : [EOL] [docstring] [EOL] batch = [ ] [EOL] high_score = [number] [EOL] with open ( assembler . file [ [string] ] ) as in_file : [EOL] for contig in SeqIO . parse ( in_file , [string] ) : [EOL] contig_id = assembler . parse_contig_id ( contig . description ) [EOL] if contig_id in all_hits : [EOL] hit = all_hits [ contig_id ] [EOL] batch . append ( ( assembler . state [ [string] ] , contig . id , str ( contig . seq ) , contig . description , hit [ [string] ] , hit [ [string] ] , hit [ [string] ] , hit [ [string] ] , hit [ [string] ] , hit [ [string] ] , hit [ [string] ] , hit [ [string] ] ) ) [EOL] db_atram . insert_assembled_contigs_batch ( assembler . state [ [string] ] , batch ) [EOL] [EOL] return high_score [EOL] [EOL] [EOL] def create_query_from_contigs ( args , log , assembler ) : [EOL] [docstring] [EOL] log . info ( [string] . format ( assembler . state [ [string] ] ) ) [EOL] [EOL] query_dir = join ( args [ [string] ] , [string] ) [EOL] os . makedirs ( query_dir , exist_ok = True ) [EOL] [EOL] query_file = assembler . file_prefix ( ) + [string] [EOL] query = join ( query_dir , query_file ) [EOL] assembler . file [ [string] ] = query [EOL] [EOL] with open ( query , [string] ) as query_file : [EOL] for row in db_atram . get_assembled_contigs ( assembler . state [ [string] ] , assembler . state [ [string] ] , assembler . args [ [string] ] , assembler . args [ [string] ] ) : [EOL] util . write_fasta_record ( query_file , row [ [number] ] , row [ [number] ] ) [EOL] [EOL] return query [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , List , Any [EOL] import _csv [EOL] import lib [EOL] import typing [EOL] [docstring] [EOL] [EOL] import csv [EOL] from os . path import abspath , join [EOL] [EOL] from . import bio , db_stitcher as db , exonerate , util [EOL] from . log import Logger [EOL] [EOL] [EOL] def stitch ( args ) : [EOL] [docstring] [EOL] log = Logger ( args . log_file , args . log_level ) [EOL] log . header ( ) [EOL] [EOL] iteration = [number] [EOL] [EOL] with util . make_temp_dir ( where = args . temp_dir , prefix = [string] , keep = args . keep_temp_dir ) as temp_dir : [EOL] with db . connect ( temp_dir , [string] ) as cxn : [EOL] cxn . row_factory = lambda c , r : { col [ [number] ] : r [ idx ] for idx , col in enumerate ( c . description ) } [EOL] [EOL] exonerate . create_tables ( cxn ) [EOL] [EOL] taxon_names = exonerate . get_taxa ( args , log ) [EOL] exonerate . insert_reference_genes ( args , temp_dir , cxn , log ) [EOL] exonerate . check_file_counts ( args , cxn , log , taxon_names ) [EOL] exonerate . create_reference_files ( cxn , log ) [EOL] [EOL] [comment] [EOL] iteration += [number] [EOL] exonerate . get_contigs_from_fasta ( args , temp_dir , cxn , log , taxon_names , iteration ) [EOL] exonerate . contig_file_write ( cxn , log ) [EOL] exonerate . run_exonerate ( temp_dir , cxn , log , iteration ) [EOL] early_exit_check ( cxn , log ) [EOL] [EOL] [comment] [EOL] for _ in range ( [number] , args . iterations ) : [EOL] stitch_everything ( args , cxn , log , iteration ) [EOL] [EOL] iteration += [number] [EOL] get_contigs_from_previous_stitch ( temp_dir , cxn , log , taxon_names , iteration ) [EOL] exonerate . contig_file_write ( cxn , log ) [EOL] exonerate . run_exonerate ( temp_dir , cxn , log , iteration ) [EOL] [EOL] [comment] [EOL] stitch_with_gaps ( args , cxn , log , taxon_names , iteration ) [EOL] [EOL] log . info ( [string] ) [EOL] output_stitched_genes ( args , cxn , taxon_names , iteration ) [EOL] output_summary_per_gene ( args , cxn , iteration ) [EOL] output_summary_per_taxon ( args , cxn , iteration ) [EOL] [EOL] log . info ( [string] ) [EOL] [EOL] [EOL] def get_contigs_from_previous_stitch ( temp_dir , cxn , log , taxon_names , iteration ) : [EOL] [docstring] [EOL] log . info ( [string] . format ( util . as_word ( iteration ) ) ) [EOL] [EOL] batch = [ ] [EOL] [EOL] for ref in db . select_reference_genes ( cxn ) : [EOL] ref_name = ref [ [string] ] [EOL] [EOL] for taxon_name in taxon_names : [EOL] [EOL] seqs = [ ] [EOL] contig_name = [string] . format ( ref_name , taxon_name ) [EOL] contig_file = [string] . format ( contig_name ) [EOL] contig_file = abspath ( join ( temp_dir , contig_file ) ) [EOL] [EOL] for contig in db . select_stitched_contigs ( cxn , ref_name , taxon_name , iteration = iteration - [number] ) : [EOL] [EOL] seqs . append ( contig [ [string] ] ) [EOL] [EOL] batch . append ( { [string] : ref_name , [string] : taxon_name , [string] : contig_name , [string] : [string] . join ( seqs ) , [string] : contig_file , [string] : [number] , [string] : iteration } ) [EOL] [EOL] db . insert_contigs ( cxn , batch ) [EOL] [EOL] [EOL] def early_exit_check ( cxn , log ) : [EOL] [docstring] [EOL] if db . select_exonerate_count ( cxn ) : [EOL] return [EOL] log . fatal ( util . shorten ( [string] ) ) [EOL] [EOL] [EOL] def stitch_everything ( args , cxn , log , iteration ) : [EOL] [docstring] [EOL] log . info ( [string] . format ( util . as_word ( iteration ) ) ) [EOL] [EOL] for thread in db . select_stitch ( cxn , iteration = iteration ) : [EOL] contigs = [ ] [EOL] position = [number] [EOL] prev_contig = { [string] : - [number] } [EOL] curr_contig = None [EOL] [EOL] while prev_contig : [EOL] [EOL] if prev_contig [ [string] ] > [number] : [EOL] curr_contig = db . select_overlap ( cxn , thread [ [string] ] , thread [ [string] ] , prev_contig [ [string] ] + [number] , prev_contig [ [string] ] - args . overlap , prev_contig [ [string] ] , iteration = iteration ) [EOL] [EOL] if not curr_contig : [EOL] curr_contig = db . select_next ( cxn , thread [ [string] ] , thread [ [string] ] , beg = prev_contig [ [string] ] - args . overlap , iteration = iteration ) [EOL] [EOL] if curr_contig : [EOL] curr_contig = dict ( curr_contig ) [EOL] position += [number] [EOL] contigs . append ( { [string] : thread [ [string] ] , [string] : thread [ [string] ] , [string] : curr_contig [ [string] ] , [string] : position , [string] : iteration , [string] : curr_contig [ [string] ] } ) [EOL] [EOL] prev_contig = curr_contig [EOL] [EOL] db . insert_stitched_genes ( cxn , contigs ) [EOL] [EOL] [EOL] def stitch_with_gaps ( args , cxn , log , taxon_names , iteration ) : [EOL] [docstring] [EOL] for ref in db . select_reference_genes ( cxn ) : [EOL] ref_name = ref [ [string] ] [EOL] ref_len = len ( ref [ [string] ] ) * bio . CODON_LEN [EOL] [EOL] log . info ( [string] . format ( util . as_word ( iteration ) , ref_name ) ) [EOL] [EOL] for taxon_name in taxon_names : [EOL] [EOL] contigs = [ ] [EOL] position = [number] [EOL] prev_contig = { [string] : - [number] } [EOL] curr_contig = None [EOL] first_time = True [EOL] [EOL] while prev_contig : [EOL] seq = [string] [EOL] [EOL] if not first_time : [EOL] curr_contig = db . select_overlap ( cxn , ref_name , taxon_name , prev_contig [ [string] ] + [number] , prev_contig [ [string] ] - args . overlap , prev_contig [ [string] ] , iteration = iteration ) [EOL] if curr_contig : [EOL] curr_contig = dict ( curr_contig ) [EOL] beg = prev_contig [ [string] ] - curr_contig [ [string] ] - [number] [EOL] seq = curr_contig [ [string] ] [ beg * bio . CODON_LEN : ] [EOL] [EOL] if not curr_contig : [EOL] curr_contig = db . select_next ( cxn , ref_name , taxon_name , beg = prev_contig [ [string] ] - args . overlap , iteration = iteration ) [EOL] if curr_contig : [EOL] curr_contig = dict ( curr_contig ) [EOL] seq = curr_contig [ [string] ] [EOL] gap = curr_contig [ [string] ] - [number] [EOL] gap -= max ( - [number] , prev_contig [ [string] ] ) [EOL] if gap > [number] : [EOL] position += [number] [EOL] contigs . append ( { [string] : ref_name , [string] : taxon_name , [string] : None , [string] : position , [string] : iteration , [string] : [string] * ( gap * bio . CODON_LEN ) } ) [EOL] [EOL] if curr_contig : [EOL] position += [number] [EOL] contigs . append ( { [string] : ref_name , [string] : taxon_name , [string] : curr_contig [ [string] ] , [string] : position , [string] : iteration , [string] : seq } ) [EOL] [EOL] prev_contig = curr_contig [EOL] first_time = False [EOL] [EOL] [comment] [EOL] stitch_len = sum ( len ( x [ [string] ] ) for x in contigs ) [EOL] missing = ref_len - stitch_len [EOL] if missing > [number] : [EOL] position += [number] [EOL] contigs . append ( { [string] : ref_name , [string] : taxon_name , [string] : None , [string] : position , [string] : iteration , [string] : [string] * missing } ) [EOL] db . insert_stitched_genes ( cxn , contigs ) [EOL] [EOL] [EOL] def output_stitched_genes ( args , cxn , taxon_names , iteration ) : [EOL] [docstring] [EOL] for ref in db . select_reference_genes ( cxn ) : [EOL] ref_name = ref [ [string] ] [EOL] [EOL] out_path = util . prefix_file ( args . output_prefix , [string] . format ( ref_name ) ) [EOL] [EOL] with open ( out_path , [string] ) as out_file : [EOL] [EOL] for taxon_name in taxon_names : [EOL] seqs = [ ] [EOL] [EOL] hits = db . select_stitched_contig_count ( cxn , ref_name , taxon_name , iteration = iteration ) [EOL] [EOL] if not hits : [EOL] continue [EOL] [EOL] for contig in db . select_stitched_contigs ( cxn , ref_name , taxon_name , iteration = iteration ) : [EOL] [EOL] seqs . append ( contig [ [string] ] ) [EOL] [EOL] header = taxon_name [EOL] if args . reference_name : [EOL] header = [string] . format ( ref_name , taxon_name ) [EOL] [EOL] util . write_fasta_record ( out_file , header , [string] . join ( seqs ) ) [EOL] [EOL] [EOL] def output_summary_per_gene ( args , cxn , iteration ) : [EOL] [docstring] [EOL] out_path = util . prefix_file ( args . output_prefix , [string] ) [EOL] with open ( out_path , [string] ) as out_file : [EOL] writer = csv . writer ( out_file ) [EOL] writer . writerow ( [ [string] , [string] , [string] , [string] ] ) [EOL] [EOL] for stats in db . select_per_gene_stats ( cxn , iteration ) : [EOL] writer . writerow ( [ stats [ [string] ] , stats [ [string] ] , stats [ [string] ] , stats [ [string] ] ] ) [EOL] [EOL] [EOL] def output_summary_per_taxon ( args , cxn , iteration ) : [EOL] [docstring] [EOL] out_path = util . prefix_file ( args . output_prefix , [string] ) [EOL] with open ( out_path , [string] ) as out_file : [EOL] writer = csv . writer ( out_file ) [EOL] writer . writerow ( [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] ] ) [EOL] [EOL] for stats in db . select_per_taxon_stats ( cxn , iteration ) : [EOL] writer . writerow ( [ stats [ [string] ] , stats [ [string] ] , stats [ [string] ] , stats [ [string] ] , stats [ [string] ] , stats [ [string] ] , stats [ [string] ] , stats [ [string] ] , stats [ [string] ] ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict [EOL] import typing [EOL] [docstring] [EOL] [EOL] from datetime import datetime [EOL] import subprocess [EOL] import sys [EOL] import tempfile [EOL] [EOL] from . import db [EOL] [EOL] [EOL] DEBUG = [number] [EOL] INFO = [number] [EOL] ERROR = [number] [EOL] FATAL = [number] [EOL] [EOL] LEVEL = { [string] : DEBUG , [string] : INFO , [string] : ERROR , [string] : FATAL , } [EOL] [EOL] [EOL] class Logger : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , log_file , log_level ) : [EOL] self . log_file = log_file [EOL] self . log_level = LEVEL [ log_level ] [EOL] self . file_handle = open ( log_file , [string] ) if log_file else None [EOL] [EOL] def __del__ ( self ) : [EOL] if self . file_handle : [EOL] self . file_handle . close ( ) [EOL] [EOL] def header ( self ) : [EOL] [docstring] [EOL] self . info ( [string] * [number] ) [EOL] self . info ( [string] . format ( db . ATRAM_VERSION ) ) [EOL] self . info ( [string] . format ( [string] . join ( sys . version . split ( ) ) ) ) [EOL] self . info ( [string] . join ( sys . argv [ : ] ) ) [EOL] [EOL] def subcommand ( self , cmd , temp_dir , timeout = None ) : [EOL] [docstring] [EOL] self . debug ( cmd ) [EOL] [EOL] with tempfile . NamedTemporaryFile ( mode = [string] , dir = temp_dir ) as log_output : [EOL] try : [EOL] subprocess . check_call ( cmd , shell = True , timeout = timeout , stdout = log_output , stderr = log_output ) [EOL] except Exception as err : [comment] [EOL] self . error ( [string] . format ( err ) ) [EOL] finally : [EOL] with open ( log_output . name ) as log_input : [EOL] for line in log_input : [EOL] line = line . strip ( ) [EOL] if line : [EOL] self . debug ( line ) [EOL] [EOL] def _output ( self , msg , level ) : [EOL] timestamp = datetime . now ( ) . strftime ( [string] ) [EOL] msg = [string] . format ( timestamp , level , msg ) [EOL] print ( msg ) [EOL] if self . file_handle : [EOL] self . file_handle . write ( msg ) [EOL] self . file_handle . write ( [string] ) [EOL] self . file_handle . flush ( ) [EOL] [EOL] def debug ( self , msg ) : [EOL] [docstring] [EOL] if self . log_level <= DEBUG : [EOL] self . _output ( msg , [string] ) [EOL] [EOL] def info ( self , msg ) : [EOL] [docstring] [EOL] if self . log_level <= INFO : [EOL] self . _output ( msg , [string] ) [EOL] [EOL] def error ( self , msg ) : [EOL] [docstring] [EOL] if self . log_level <= ERROR : [EOL] self . _output ( msg , [string] ) [EOL] [EOL] def fatal ( self , msg ) : [EOL] [docstring] [EOL] if self . log_level <= FATAL : [EOL] self . _output ( msg , [string] ) [EOL] sys . exit ( [number] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 $typing.Dict[builtins.str,builtins.int]$ 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , Pattern , Optional [EOL] import typing [EOL] [docstring] [EOL] [EOL] import re [EOL] [EOL] from Bio import SeqIO [EOL] [EOL] CODON_LEN = [number] [EOL] [EOL] COMPLEMENT = str . maketrans ( [string] , [string] ) [EOL] [EOL] IS_PROTEIN = re . compile ( [string] , re . IGNORECASE ) [EOL] [EOL] [EOL] def reverse_complement ( seq ) : [EOL] [docstring] [EOL] return seq . translate ( COMPLEMENT ) [ : : - [number] ] [EOL] [EOL] [EOL] def is_protein ( seq ) : [EOL] [docstring] [EOL] return IS_PROTEIN . search ( seq ) [EOL] [EOL] [EOL] def fasta_file_has_protein ( query_files ) : [EOL] [docstring] [EOL] for query_file in query_files : [EOL] with open ( query_file ) as in_file : [EOL] for query in SeqIO . parse ( in_file , [string] ) : [EOL] if is_protein ( str ( query . seq ) ) : [EOL] return True [EOL] [EOL] return False [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $typing.Dict[builtins.int,typing.Optional[builtins.int]]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Pattern[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.int,typing.Optional[builtins.int]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Pattern[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import sqlite3 [EOL] import typing [EOL] [docstring] [EOL] [EOL] import os [EOL] import sqlite3 [EOL] import sys [EOL] from os . path import basename , exists , join [EOL] [EOL] ATRAM_VERSION = [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] DB_VERSION = [string] [EOL] [EOL] BATCH_SIZE = [number] [comment] [EOL] [EOL] [EOL] def connect ( blast_db , check_version = False , clean = False ) : [EOL] [docstring] [EOL] db_name = get_db_name ( blast_db ) [EOL] [EOL] if clean and exists ( db_name ) : [EOL] os . remove ( db_name ) [EOL] [EOL] if check_version and not exists ( db_name ) : [EOL] err = [string] . format ( db_name ) [EOL] sys . exit ( err ) [EOL] [EOL] if check_version : [EOL] with db_setup ( db_name ) as cxn : [EOL] check_versions ( cxn ) [EOL] [EOL] return db_setup ( db_name ) [EOL] [EOL] [EOL] def get_db_name ( db_prefix ) : [EOL] [docstring] [EOL] return [string] . format ( db_prefix ) [EOL] [EOL] [EOL] def aux_db ( cxn , temp_dir , blast_db , query_name ) : [EOL] [docstring] [EOL] db_dir = join ( temp_dir , [string] ) [EOL] os . makedirs ( db_dir , exist_ok = True ) [EOL] [EOL] db_name = [string] . format ( basename ( blast_db ) , basename ( query_name ) ) [EOL] db_name = join ( db_dir , db_name ) [EOL] [EOL] sql = [string] . format ( db_name ) [EOL] cxn . execute ( sql ) [EOL] [EOL] [EOL] def aux_detach ( cxn ) : [EOL] [docstring] [EOL] cxn . execute ( [string] ) [EOL] [EOL] [EOL] def temp_db ( temp_dir , db_prefix ) : [EOL] [docstring] [EOL] db_name = join ( temp_dir , get_db_name ( db_prefix ) ) [EOL] return db_setup ( db_name ) [EOL] [EOL] [EOL] def db_setup ( db_name ) : [EOL] [docstring] [EOL] cxn = sqlite3 . connect ( db_name , timeout = [number] ) [EOL] cxn . execute ( [string] . format ( [number] ** [number] ) ) [EOL] cxn . execute ( [string] ) [EOL] return cxn [EOL] [EOL] [EOL] [comment] [EOL] [EOL] def check_versions ( cxn ) : [EOL] [docstring] [EOL] version = get_version ( cxn ) [EOL] if version != DB_VERSION : [EOL] err = ( [string] [string] [string] ) . format ( version , DB_VERSION ) [EOL] sys . exit ( err ) [EOL] [EOL] [EOL] [comment] [EOL] [EOL] def get_metadata ( cxn , key , default = [string] ) : [EOL] [docstring] [EOL] sql = [string] [EOL] try : [EOL] result = cxn . execute ( sql , ( key , ) ) [EOL] result = result . fetchone ( ) [EOL] return default if not result else result [ [number] ] [EOL] except sqlite3 . OperationalError : [EOL] return default [EOL] [EOL] [EOL] def get_version ( cxn ) : [EOL] [docstring] [EOL] return get_metadata ( cxn , [string] , default = [string] ) [EOL] [EOL] [EOL] def is_single_end ( cxn ) : [EOL] [docstring] [EOL] result = get_metadata ( cxn , [string] ) [EOL] return result != [string] [EOL] [EOL] [EOL] [comment] [EOL] [EOL] def get_sequence_ends ( cxn ) : [EOL] [docstring] [EOL] return cxn . execute ( [string] ) [EOL] [EOL] [EOL] def get_all_sequences ( cxn ) : [EOL] [docstring] [EOL] return cxn . execute ( [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[docstring] [EOL] [EOL] import os [EOL] from os . path import join [EOL] [EOL] from . db import DB_VERSION [EOL] [EOL] [EOL] def aux_db ( cxn , temp_dir ) : [EOL] [docstring] [EOL] db_dir = join ( temp_dir , [string] ) [EOL] os . makedirs ( db_dir , exist_ok = True ) [EOL] [EOL] db_name = join ( db_dir , [string] ) [EOL] [EOL] sql = [string] . format ( db_name ) [EOL] cxn . execute ( sql ) [EOL] [EOL] [EOL] def aux_detach ( cxn ) : [EOL] [docstring] [EOL] cxn . execute ( [string] ) [EOL] [EOL] [EOL] [comment] [EOL] [EOL] def create_metadata_table ( cxn , args ) : [EOL] [docstring] [EOL] cxn . executescript ( [string] ) [EOL] [EOL] with cxn : [EOL] sql = [string] [EOL] cxn . execute ( sql , ( [string] , DB_VERSION ) ) [EOL] cxn . execute ( sql , ( [string] , bool ( args . get ( [string] ) ) ) ) [EOL] [EOL] [EOL] [comment] [EOL] [EOL] def create_sequences_table ( cxn ) : [EOL] [docstring] [EOL] cxn . executescript ( [string] ) [EOL] [EOL] [EOL] def create_sequences_index ( cxn ) : [EOL] [docstring] [EOL] cxn . executescript ( [string] ) [EOL] [EOL] [EOL] def insert_sequences_batch ( cxn , batch ) : [EOL] [docstring] [EOL] sql = [string] [EOL] if batch : [EOL] with cxn : [EOL] cxn . executemany ( sql , batch ) [EOL] [EOL] [EOL] [comment] [EOL] [EOL] def create_seq_names_table ( cxn ) : [EOL] [docstring] [EOL] cxn . executescript ( [string] ) [EOL] [EOL] [EOL] def get_sequences_in_shard ( cxn , shard_count , shard_index ) : [EOL] [docstring] [EOL] sql = [string] [EOL] return cxn . execute ( sql , ( shard_count , shard_index ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , Type , Any , Union [EOL] import lib [EOL] import typing [EOL] [docstring] [EOL] [EOL] import sys [EOL] import textwrap [EOL] from shutil import which [EOL] [EOL] import psutil [EOL] [EOL] from . assemblers . abyss import AbyssAssembler [EOL] from . assemblers . none import NoneAssembler [EOL] from . assemblers . spades import SpadesAssembler [EOL] from . assemblers . trinity import TrinityAssembler [EOL] from . assemblers . velvet import VelvetAssembler [EOL] [EOL] ASSEMBLERS = { [string] : AbyssAssembler , [string] : TrinityAssembler , [string] : VelvetAssembler , [string] : SpadesAssembler , [string] : NoneAssembler } [EOL] [EOL] [EOL] def factory ( args , cxn , log ) : [EOL] [docstring] [EOL] name = args [ [string] ] . lower ( ) [EOL] assembler = ASSEMBLERS [ name ] [EOL] return assembler ( args , cxn , log ) [EOL] [EOL] [EOL] def command_line_args ( parser ) : [EOL] [docstring] [EOL] group = parser . add_argument_group ( [string] ) [EOL] [EOL] group . add_argument ( [string] , action = [string] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , type = int , default = [number] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , action = [string] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , action = [string] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , action = [string] , help = [string] ) [EOL] [EOL] total_mem = psutil . virtual_memory ( ) . available >> [number] [EOL] max_mem = max ( [number] , total_mem >> [number] ) [EOL] group . add_argument ( [string] , default = max_mem , metavar = [string] , type = int , help = [string] . format ( max_mem , total_mem ) ) [EOL] [EOL] group . add_argument ( [string] , [string] , type = int , default = [number] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , type = int , default = [number] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , type = int , default = [number] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , action = [string] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , default = [string] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , type = int , help = [string] ) [EOL] [EOL] [EOL] def default_kmer ( kmer , assembler ) : [EOL] [docstring] [EOL] if assembler == [string] and kmer > [number] : [EOL] kmer = [number] [EOL] [EOL] return kmer [EOL] [EOL] [EOL] def default_cov_cutoff ( log , cov_cutoff ) : [EOL] [docstring] [EOL] if cov_cutoff in [ [string] , [string] ] : [EOL] return cov_cutoff [EOL] [EOL] err = ( [string] [string] ) [EOL] value = None [EOL] try : [EOL] value = float ( cov_cutoff ) [EOL] except ValueError : [EOL] log . fatal ( err ) [EOL] [EOL] if value < [number] : [EOL] log . fatal ( err ) [EOL] [EOL] return cov_cutoff [EOL] [EOL] [EOL] def find_program ( assembler_name , program , assembler_arg , option = True ) : [EOL] [docstring] [EOL] if assembler_arg == assembler_name and option and not which ( program ) : [EOL] err = ( textwrap . dedent ( [string] ) ) . format ( program ) [EOL] sys . exit ( err ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Type[typing.Union[lib.assemblers.abyss.AbyssAssembler,lib.assemblers.none.NoneAssembler,lib.assemblers.spades.SpadesAssembler,lib.assemblers.trinity.TrinityAssembler,lib.assemblers.velvet.VelvetAssembler]]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Type[typing.Union[lib.assemblers.abyss.AbyssAssembler,lib.assemblers.none.NoneAssembler,lib.assemblers.spades.SpadesAssembler,lib.assemblers.trinity.TrinityAssembler,lib.assemblers.velvet.VelvetAssembler]]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] [docstring] [EOL] [EOL] from . db import temp_db [EOL] [EOL] [EOL] def connect ( temp_dir , db_prefix ) : [EOL] [docstring] [EOL] cxn = temp_db ( temp_dir , db_prefix ) [EOL] return cxn [EOL] [EOL] [EOL] [comment] [EOL] [EOL] def create_reference_genes_table ( cxn ) : [EOL] [docstring] [EOL] cxn . executescript ( [string] ) [EOL] [EOL] [EOL] def insert_reference_genes ( cxn , batch ) : [EOL] [docstring] [EOL] sql = [string] [EOL] if batch : [EOL] with cxn : [EOL] cxn . executemany ( sql , batch ) [EOL] [EOL] [EOL] def select_reference_genes ( cxn ) : [EOL] [docstring] [EOL] return cxn . execute ( [string] ) [EOL] [EOL] [EOL] [comment] [EOL] [EOL] def create_contigs_table ( cxn ) : [EOL] [docstring] [EOL] cxn . executescript ( [string] ) [EOL] [EOL] [EOL] def insert_contigs ( cxn , batch ) : [EOL] [docstring] [EOL] sql = [string] [EOL] if batch : [EOL] with cxn : [EOL] cxn . executemany ( sql , batch ) [EOL] [EOL] [EOL] def select_all_contigs ( cxn ) : [EOL] [docstring] [EOL] sql = [string] [EOL] return cxn . execute ( sql ) [EOL] [EOL] [EOL] def select_contig_files ( cxn , iteration = [number] ) : [EOL] [docstring] [EOL] sql = [string] [EOL] return cxn . execute ( sql , ( iteration , ) ) [EOL] [EOL] [EOL] def select_contigs_in_file ( cxn , contig_file , iteration = [number] ) : [EOL] [docstring] [EOL] return cxn . execute ( [string] , ( contig_file , iteration ) ) [EOL] [EOL] [EOL] def select_contigs ( cxn , ref_name , iteration = [number] ) : [EOL] [docstring] [EOL] return cxn . execute ( [string] , ( ref_name , iteration ) ) [EOL] [EOL] [EOL] [comment] [EOL] [EOL] def create_exonerate_table ( cxn ) : [EOL] [docstring] [EOL] cxn . executescript ( [string] ) [EOL] [EOL] [EOL] def select_exonerate_ref_gene ( cxn , ref_name , min_len ) : [EOL] [docstring] [EOL] return cxn . execute ( [string] , ( ref_name , min_len ) ) [EOL] [EOL] [EOL] def select_exonerate_count ( cxn ) : [EOL] [docstring] [EOL] result = cxn . execute ( [string] ) [EOL] return result . fetchone ( ) [ [string] ] [EOL] [EOL] [EOL] def select_stitch ( cxn , iteration = [number] ) : [EOL] [docstring] [EOL] return cxn . execute ( [string] , ( iteration , ) ) [EOL] [EOL] [EOL] def insert_exonerate_results ( cxn , batch ) : [EOL] [docstring] [EOL] sql = [string] [EOL] if batch : [EOL] with cxn : [EOL] cxn . executemany ( sql , batch ) [EOL] [EOL] [EOL] def select_next ( cxn , ref_name , taxon_name , beg = - [number] , iteration = [number] ) : [EOL] [docstring] [EOL] sql = [string] [EOL] result = cxn . execute ( sql , ( ref_name , taxon_name , beg , iteration ) ) [EOL] return result . fetchone ( ) [EOL] [EOL] [EOL] def select_longest ( cxn ) : [EOL] [docstring] [EOL] sql = [string] [EOL] result = cxn . execute ( sql ) [EOL] return result . fetchone ( ) [ [string] ] [EOL] [EOL] [EOL] def select_seq_lengths ( cxn ) : [EOL] [docstring] [EOL] sql = [string] [EOL] return cxn . execute ( sql ) [EOL] [EOL] [EOL] def select_overlap ( cxn , ref_name , taxon_name , beg_lo , beg_hi , end , iteration = [number] ) : [EOL] [docstring] [EOL] sql = [string] [EOL] result = cxn . execute ( sql , ( ref_name , taxon_name , iteration , end , beg_lo , beg_hi ) ) [EOL] return result . fetchone ( ) [EOL] [EOL] [EOL] [comment] [EOL] def create_stitch_table ( cxn ) : [EOL] [docstring] [EOL] cxn . executescript ( [string] ) [EOL] [EOL] [EOL] def insert_stitched_genes ( cxn , batch ) : [EOL] [docstring] [EOL] sql = [string] [EOL] if batch : [EOL] with cxn : [EOL] cxn . executemany ( sql , batch ) [EOL] [EOL] [EOL] def select_stitched_contigs ( cxn , ref_name , taxon_name , iteration = [number] ) : [EOL] [docstring] [EOL] return cxn . execute ( [string] , ( ref_name , taxon_name , iteration ) ) [EOL] [EOL] [EOL] def select_stitched_contig_count ( cxn , ref_name , taxon_name , iteration = [number] ) : [EOL] [docstring] [EOL] result = cxn . execute ( [string] , ( ref_name , taxon_name , iteration ) ) [EOL] return result . fetchone ( ) [ [string] ] [EOL] [EOL] [EOL] def select_per_gene_stats ( cxn , iteration ) : [EOL] [docstring] [EOL] return cxn . execute ( [string] , ( iteration , ) ) [EOL] [EOL] [EOL] def select_per_taxon_stats ( cxn , iteration ) : [EOL] [docstring] [EOL] return cxn . execute ( [string] , ( iteration , ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , List , Type , Pattern , Any , DefaultDict [EOL] import lib [EOL] import typing [EOL] [docstring] [EOL] [EOL] import os [EOL] import re [EOL] from collections import defaultdict , namedtuple [EOL] from glob import glob [EOL] from os . path import abspath , basename , join [EOL] from pathlib import Path [EOL] [EOL] from Bio . SeqIO . FastaIO import SimpleFastaParser [EOL] [EOL] from . import db_stitcher as db , util [EOL] [EOL] [EOL] def run_exonerate ( temp_dir , cxn , log , iteration ) : [EOL] [docstring] [EOL] for ref in db . select_reference_genes ( cxn ) : [EOL] log . info ( [string] . format ( ref [ [string] ] ) ) [EOL] [EOL] results_file = abspath ( join ( temp_dir , [string] . format ( ref [ [string] ] , iteration ) ) ) [EOL] [EOL] Path ( results_file ) . touch ( ) [EOL] [EOL] for contig_file in db . select_contigs ( cxn , ref [ [string] ] , iteration = iteration ) : [EOL] [EOL] if util . fasta_file_is_empty ( contig_file [ [string] ] ) : [EOL] continue [EOL] [EOL] exonerate_command ( temp_dir , log , ref , contig_file , results_file ) [EOL] [EOL] insert_exonerate_results ( cxn , iteration , results_file ) [EOL] [EOL] [EOL] def exonerate_command ( temp_dir , log , ref , contig_file , results_file ) : [EOL] [docstring] [EOL] cmd = util . shorten ( [string] ) . format ( ref_file = ref [ [string] ] , contig_file = contig_file [ [string] ] , ref_name = ref [ [string] ] , taxon_name = contig_file [ [string] ] , results_file = results_file ) [EOL] [EOL] log . subcommand ( cmd , temp_dir ) [EOL] [EOL] [EOL] def insert_exonerate_results ( cxn , iteration , results_file ) : [EOL] [docstring] [EOL] ExonerateHeader = namedtuple ( [string] , [ [string] , [string] , [string] , [string] , [string] ] ) [EOL] [EOL] batch = [ ] [EOL] with open ( results_file ) as results_fasta : [EOL] for header , seq in SimpleFastaParser ( results_fasta ) : [EOL] header = header . split ( [string] ) [EOL] field = ExonerateHeader ( * header ) [EOL] result = { [string] : field . ref_name , [string] : field . taxon_name , [string] : field . contig_name , [string] : field . beg , [string] : field . end , [string] : iteration , [string] : seq } [EOL] batch . append ( result ) [EOL] [EOL] db . insert_exonerate_results ( cxn , batch ) [EOL] [EOL] [EOL] def create_tables ( cxn ) : [EOL] [docstring] [EOL] db . create_reference_genes_table ( cxn ) [EOL] db . create_exonerate_table ( cxn ) [EOL] db . create_contigs_table ( cxn ) [EOL] db . create_stitch_table ( cxn ) [EOL] [EOL] [EOL] def get_taxa ( args , log ) : [EOL] [docstring] [EOL] log . info ( [string] ) [EOL] with open ( args . taxa ) as taxa : [EOL] taxon_names = [ n . strip ( ) for n in taxa ] [EOL] return sorted ( taxon_names ) [EOL] [EOL] [EOL] def insert_reference_genes ( args , temp_dir , cxn , log ) : [EOL] [docstring] [EOL] batch = [ ] [EOL] [EOL] ref_genes = args . reference_genes [EOL] [EOL] log . info ( [string] . format ( ref_genes ) ) [EOL] [EOL] with open ( ref_genes ) as ref_in : [EOL] [EOL] for ref_name , ref_seq in SimpleFastaParser ( ref_in ) : [EOL] [EOL] ref_name = util . clean_name ( ref_name ) [EOL] [EOL] ref_file = abspath ( join ( temp_dir , [string] . format ( ref_name ) ) ) [EOL] [EOL] batch . append ( { [string] : ref_name , [string] : ref_seq , [string] : ref_file } ) [EOL] [EOL] db . insert_reference_genes ( cxn , batch ) [EOL] [EOL] [EOL] def create_reference_files ( cxn , log ) : [EOL] [docstring] [EOL] log . info ( [string] ) [EOL] for ref in db . select_reference_genes ( cxn ) : [EOL] with open ( ref [ [string] ] , [string] ) as ref_file : [EOL] util . write_fasta_record ( ref_file , ref [ [string] ] , ref [ [string] ] ) [EOL] [EOL] [EOL] def check_file_counts ( args , cxn , log , taxon_names ) : [EOL] [docstring] [EOL] ref_names = set ( x [ [string] ] for x in db . select_reference_genes ( cxn ) ) [EOL] [EOL] pattern = join ( args . assemblies_dir , args . file_filter ) [EOL] contig_files = sorted ( glob ( pattern ) ) [EOL] [EOL] counts = defaultdict ( list ) [EOL] for contig_file in contig_files : [EOL] ref_name , taxon_name = parse_contig_file_name ( ref_names , taxon_names , contig_file ) [EOL] if not ref_name or not taxon_name : [EOL] continue [EOL] counts [ ( ref_name , taxon_name ) ] . append ( contig_file ) [EOL] [EOL] counts = { k : v for k , v in counts . items ( ) if len ( v ) > [number] } [EOL] [EOL] if not counts : [EOL] return [EOL] [EOL] msg = [ ] [EOL] for key , contig_files in counts . items ( ) : [EOL] msg . append ( [string] . format ( * key ) ) [EOL] msg += contig_files [EOL] [EOL] log . fatal ( [string] . join ( msg ) ) [EOL] [EOL] [EOL] def parse_contig_file_name ( ref_names , taxon_names , contig_file ) : [EOL] [docstring] [EOL] sep = [string] [EOL] [EOL] ref_names = [ ( x , re . sub ( sep , sep , x ) + sep ) for x in ref_names ] [EOL] ref_names = sorted ( ref_names , key = lambda x : ( len ( x [ [number] ] ) , x ) , reverse = True ) [EOL] [EOL] taxon_names = [ ( x , re . sub ( sep , sep , x ) + sep ) for x in taxon_names ] [EOL] taxon_names = sorted ( taxon_names , key = lambda x : ( len ( x [ [number] ] ) , x ) , reverse = True ) [EOL] [EOL] ref_name = [ x [ [number] ] for x in ref_names if re . search ( x [ [number] ] , contig_file ) ] [EOL] taxon_name = [ x [ [number] ] for x in taxon_names if re . search ( x [ [number] ] , contig_file ) ] [EOL] [EOL] ref_name += [ None ] [EOL] taxon_name += [ None ] [EOL] [EOL] return ref_name [ [number] ] , taxon_name [ [number] ] [EOL] [EOL] [EOL] def get_contigs_from_fasta ( args , temp_dir , cxn , log , taxon_names , iteration ) : [EOL] [docstring] [EOL] log . info ( [string] . format ( util . as_word ( iteration ) , args . assemblies_dir ) ) [EOL] [EOL] batch = [ ] [EOL] names_seen = defaultdict ( int ) [EOL] [EOL] ref_names = set ( x [ [string] ] for x in db . select_reference_genes ( cxn ) ) [EOL] [EOL] pattern = join ( args . assemblies_dir , args . file_filter ) [EOL] for contig_path in sorted ( glob ( pattern ) ) : [EOL] [EOL] if os . stat ( contig_path ) . st_size == [number] : [EOL] continue [EOL] [EOL] with open ( contig_path ) as contig_old : [EOL] for i , ( header , contig_seq ) in enumerate ( SimpleFastaParser ( contig_old ) ) : [EOL] [EOL] contig_file = basename ( contig_path ) [EOL] ref_name , taxon_name = parse_contig_file_name ( ref_names , taxon_names , contig_file ) [EOL] [EOL] if ref_name not in ref_names or taxon_name not in taxon_names : [EOL] continue [EOL] [EOL] contig_name = name_contig ( taxon_name , ref_name , header , names_seen ) [EOL] contig_file = abspath ( join ( temp_dir , contig_name + [string] ) ) [EOL] [EOL] batch . append ( { [string] : ref_name , [string] : taxon_name , [string] : contig_name , [string] : contig_seq , [string] : contig_file , [string] : i , [string] : iteration } ) [EOL] [EOL] db . insert_contigs ( cxn , batch ) [EOL] [EOL] [EOL] def contig_file_write ( cxn , log ) : [EOL] [docstring] [EOL] log . info ( [string] ) [EOL] [EOL] for contig in db . select_all_contigs ( cxn ) : [EOL] with open ( contig [ [string] ] , [string] ) as fasta_file : [EOL] util . write_fasta_record ( fasta_file , contig [ [string] ] , contig [ [string] ] ) [EOL] [EOL] [EOL] DEFAULT = [number] [EOL] ITERATION = re . compile ( [string] , re . IGNORECASE ) [EOL] COVERAGE = re . compile ( [string] , re . IGNORECASE ) [EOL] SCORE = re . compile ( [string] , re . IGNORECASE ) [EOL] [EOL] [EOL] def name_contig ( taxon_name , ref_name , header , names_seen ) : [EOL] [docstring] [EOL] global DEFAULT [comment] [EOL] DEFAULT += [number] [EOL] [EOL] match = ITERATION . search ( header ) [EOL] iteration = [string] . format ( match [ [number] ] ) if match else [string] [EOL] [EOL] match = COVERAGE . search ( header ) [EOL] coverage = [string] . format ( round ( float ( match [ [number] ] ) ) ) if match else [string] [EOL] [EOL] match = SCORE . search ( header ) [EOL] score = [string] . format ( round ( float ( match [ [number] ] ) ) ) if match else [string] [EOL] [EOL] contig = [string] . format ( iteration , coverage , score ) [EOL] contig = contig if contig else str ( DEFAULT ) [EOL] [EOL] name = [string] . format ( taxon_name , ref_name , contig ) [EOL] name = re . sub ( [string] , [string] , name . strip ( ) ) [EOL] [EOL] name = handle_duplicate_name ( name , names_seen ) [EOL] [EOL] return name [EOL] [EOL] [EOL] def handle_duplicate_name ( contig_name , names_seen ) : [EOL] [docstring] [EOL] name = re . sub ( [string] , [string] , contig_name , re . IGNORECASE ) [EOL] [EOL] names_seen [ name ] += [number] [EOL] [EOL] if names_seen [ name ] > [number] : [EOL] name += [string] . format ( names_seen [ name ] ) [EOL] [EOL] return name [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $typing.Pattern[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Pattern[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Pattern[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 $builtins.int$ 0 0 0 0 0 0 $typing.Pattern[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Pattern[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Pattern[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , Union , Any , Literal [EOL] import io [EOL] import typing [EOL] import typing_extensions [EOL] [docstring] [EOL] [EOL] import bz2 [EOL] import gzip [EOL] import io [EOL] import os [EOL] import re [EOL] import sys [EOL] from contextlib import contextmanager [EOL] from os . path import exists , getsize , join , split [EOL] from shutil import rmtree [EOL] from tempfile import mkdtemp [EOL] [EOL] from Bio . SeqIO . FastaIO import SimpleFastaParser [EOL] [EOL] [EOL] def shorten ( text ) : [EOL] [docstring] [EOL] return [string] . join ( text . split ( ) ) [EOL] [EOL] [EOL] def set_blast_batch_size ( batch_size ) : [EOL] [docstring] [EOL] if batch_size : [EOL] os . environ [ [string] ] = str ( batch_size ) [EOL] [EOL] [EOL] def write_fasta_record ( out_file , seq_name , seq , seq_end = None ) : [EOL] [docstring] [EOL] out_file . write ( [string] ) [EOL] out_file . write ( seq_name ) [EOL] if seq_end : [EOL] out_file . write ( [string] ) [EOL] out_file . write ( seq_end ) [EOL] out_file . write ( [string] ) [EOL] [EOL] out_file . write ( seq ) [EOL] out_file . write ( [string] ) [EOL] [EOL] [EOL] def temp_dir_exists ( temp_dir , debug_dir = None ) : [EOL] [docstring] [EOL] if temp_dir and not exists ( temp_dir ) : [EOL] sys . exit ( [string] ) [EOL] if debug_dir and not exists ( debug_dir ) : [EOL] sys . exit ( [string] ) [EOL] [EOL] [EOL] def update_temp_dir ( temp_dir , args ) : [EOL] [docstring] [EOL] args [ [string] ] = str ( temp_dir ) [EOL] os . environ [ [string] ] = temp_dir [EOL] [EOL] [EOL] @ contextmanager def make_temp_dir ( where = None , prefix = None , keep = False ) : [EOL] [docstring] [EOL] temp_dir = mkdtemp ( prefix = prefix , dir = where ) [EOL] try : [EOL] yield temp_dir [EOL] finally : [EOL] if not keep or not where : [EOL] rmtree ( temp_dir ) [EOL] [EOL] [EOL] @ contextmanager def open_file ( args , file_name ) : [EOL] [docstring] [EOL] if args . get ( [string] ) : [EOL] stream = gzip . open ( file_name , [string] ) [EOL] elif args . get ( [string] ) : [EOL] stream = bz2 . open ( file_name , [string] ) [EOL] else : [EOL] stream = open ( file_name ) [EOL] [EOL] try : [EOL] yield stream [EOL] finally : [EOL] stream . close ( ) [EOL] [EOL] [EOL] def clean_name ( name ) : [EOL] [docstring] [EOL] return re . sub ( [string] , [string] , name . strip ( ) ) [EOL] [EOL] [EOL] def as_word ( number ) : [EOL] [docstring] [EOL] ordinal = { [number] : [string] , [number] : [string] , [number] : [string] } [EOL] return ordinal . get ( number , [string] . format ( number ) ) [EOL] [EOL] [EOL] def fasta_file_is_empty ( fasta_path ) : [EOL] [docstring] [EOL] if os . stat ( fasta_path ) . st_size == [number] : [EOL] return True [EOL] [EOL] with open ( fasta_path ) as fasta_file : [EOL] _ , seq = next ( SimpleFastaParser ( fasta_file ) ) [EOL] [EOL] if not seq : [EOL] return True [EOL] [EOL] return False [EOL] [EOL] [EOL] def is_fastq_file ( args , file_name ) : [EOL] [docstring] [EOL] if args . get ( [string] ) : [EOL] return False [EOL] if args . get ( [string] ) : [EOL] return True [EOL] [EOL] parts = file_name . lower ( ) . split ( [string] ) [EOL] index = - [number] if re . search ( [string] , parts [ - [number] ] ) and len ( parts ) > [number] else - [number] [EOL] return parts [ index ] . startswith ( [string] ) and parts [ index ] . endswith ( [string] ) [EOL] [EOL] [EOL] def shard_file_size ( args , file_name ) : [EOL] [docstring] [EOL] file_size = getsize ( file_name ) [EOL] [EOL] if args . get ( [string] ) : [EOL] with gzip . open ( file_name , [string] ) as zippy : [EOL] file_size = zippy . seek ( [number] , io . SEEK_END ) [EOL] elif args . get ( [string] ) : [EOL] with bz2 . open ( file_name , [string] ) as zippy : [EOL] file_size = zippy . seek ( [number] , io . SEEK_END ) [EOL] [EOL] if is_fastq_file ( args , file_name ) : [EOL] file_size /= [number] [comment] [EOL] [EOL] return file_size [EOL] [EOL] [EOL] def prefix_file ( prefix , name ) : [EOL] [docstring] [EOL] dir_ , file_ = split ( prefix ) [EOL] file_ += [string] if file_ and file_ [ - [number] ] != [string] else [string] [EOL] return join ( dir_ , file_ + name ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import List , Any [EOL] import lib [EOL] import typing [EOL] [docstring] [EOL] [EOL] import multiprocessing [EOL] import sys [EOL] from os . path import basename , join , splitext [EOL] [EOL] from Bio . SeqIO . FastaIO import SimpleFastaParser [EOL] from Bio . SeqIO . QualityIO import FastqGeneralIterator [EOL] [EOL] from . import blast , db , db_preprocessor , util [EOL] from . log import Logger [EOL] [EOL] [EOL] def preprocess ( args ) : [EOL] [docstring] [EOL] log = Logger ( args [ [string] ] , args [ [string] ] ) [EOL] log . header ( ) [EOL] [EOL] with util . make_temp_dir ( where = args [ [string] ] , prefix = [string] , keep = args [ [string] ] ) as temp_dir : [EOL] util . update_temp_dir ( temp_dir , args ) [EOL] [EOL] with db . connect ( args [ [string] ] , clean = True ) as cxn : [EOL] db_preprocessor . create_metadata_table ( cxn , args ) [EOL] [EOL] db_preprocessor . create_sequences_table ( cxn ) [EOL] load_seqs ( args , cxn , log ) [EOL] [EOL] log . info ( [string] ) [EOL] db_preprocessor . create_sequences_index ( cxn ) [EOL] [EOL] create_all_blast_shards ( args , cxn , log , args [ [string] ] ) [EOL] [EOL] [EOL] def load_seqs ( args , cxn , log ) : [EOL] [docstring] [EOL] [comment] [EOL] for ( ends , clamp ) in [ ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) ] : [EOL] if args . get ( ends ) : [EOL] for file_name in args [ ends ] : [EOL] load_one_file ( args , cxn , log , file_name , ends , clamp ) [EOL] [EOL] [EOL] def load_one_file ( args , cxn , log , file_name , ends , seq_end_clamp = [string] ) : [EOL] [docstring] [EOL] log . info ( [string] . format ( file_name ) ) [EOL] [EOL] parser = get_parser ( args , file_name ) [EOL] [EOL] with util . open_file ( args , file_name ) as sra_file : [EOL] batch = [ ] [EOL] [EOL] for rec in parser ( sra_file ) : [EOL] title = rec [ [number] ] . strip ( ) [EOL] seq = rec [ [number] ] [EOL] seq_name , seq_end = blast . parse_fasta_title ( title , ends , seq_end_clamp ) [EOL] [EOL] batch . append ( ( seq_name , seq_end , seq ) ) [EOL] [EOL] if len ( batch ) >= db . BATCH_SIZE : [EOL] db_preprocessor . insert_sequences_batch ( cxn , batch ) [EOL] batch = [ ] [EOL] [EOL] db_preprocessor . insert_sequences_batch ( cxn , batch ) [EOL] [EOL] [EOL] def get_parser ( args , file_name ) : [EOL] [docstring] [EOL] is_fastq = util . is_fastq_file ( args , file_name ) [EOL] return FastqGeneralIterator if is_fastq else SimpleFastaParser [EOL] [EOL] [EOL] def create_all_blast_shards ( args , cxn , log , shard_count ) : [EOL] [docstring] [EOL] log . info ( [string] ) [EOL] db_preprocessor . aux_db ( cxn , args [ [string] ] ) [EOL] db_preprocessor . create_seq_names_table ( cxn ) [EOL] [EOL] with multiprocessing . Pool ( processes = args [ [string] ] ) as pool : [EOL] results = [ ] [EOL] for shard_idx in range ( shard_count ) : [EOL] fasta_path = fill_blast_fasta ( args , cxn , shard_count , shard_idx ) [EOL] results . append ( pool . apply_async ( create_one_blast_shard , ( args , fasta_path , shard_idx ) ) ) [EOL] [EOL] all_results = [ result . get ( ) for result in results ] [EOL] db_preprocessor . aux_detach ( cxn ) [EOL] log . info ( [string] . format ( len ( all_results ) ) ) [EOL] [EOL] [EOL] def fill_blast_fasta ( args , cxn , shard_count , shard_index ) : [EOL] [docstring] [EOL] exe_name , _ = splitext ( basename ( sys . argv [ [number] ] ) ) [EOL] fasta_name = [string] . format ( exe_name , shard_index + [number] ) [EOL] fasta_path = join ( args [ [string] ] , fasta_name ) [EOL] [EOL] with open ( fasta_path , [string] ) as fasta_file : [EOL] for row in db_preprocessor . get_sequences_in_shard ( cxn , shard_count , shard_index ) : [EOL] util . write_fasta_record ( fasta_file , row [ [number] ] , row [ [number] ] , row [ [number] ] ) [EOL] [EOL] return fasta_path [EOL] [EOL] [EOL] def create_one_blast_shard ( args , fasta_path , shard_index ) : [EOL] [docstring] [EOL] log = Logger ( args [ [string] ] , args [ [string] ] ) [EOL] shard = [string] . format ( args [ [string] ] , shard_index + [number] ) [EOL] blast . create_db ( log , args [ [string] ] , fasta_path , shard ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] [docstring] [EOL] [EOL] import sqlite3 [EOL] [EOL] [EOL] [comment] [EOL] [EOL] def create_sra_blast_hits_table ( cxn ) : [EOL] [docstring] [EOL] cxn . executescript ( [string] ) [EOL] [EOL] [EOL] def insert_blast_hit_batch ( cxn , batch ) : [EOL] [docstring] [EOL] sql = [string] [EOL] if batch : [EOL] with cxn : [EOL] cxn . executemany ( sql , batch ) [EOL] [EOL] [EOL] def sra_blast_hits_count ( cxn , iteration ) : [EOL] [docstring] [EOL] sql = [string] [EOL] [EOL] result = cxn . execute ( sql , ( iteration , ) ) [EOL] return result . fetchone ( ) [ [number] ] [EOL] [EOL] [EOL] def get_sra_blast_hits ( cxn , iteration ) : [EOL] [docstring] [EOL] sql = [string] [EOL] [EOL] cxn . row_factory = sqlite3 . Row [EOL] return cxn . execute ( sql , ( iteration , ) ) [EOL] [EOL] [EOL] def get_blast_hits_by_end_count ( cxn , iteration , end_count ) : [EOL] [docstring] [EOL] sql = [string] [EOL] [EOL] cxn . row_factory = sqlite3 . Row [EOL] return cxn . execute ( sql , ( iteration , end_count ) ) [EOL] [EOL] [EOL] def get_blast_hits ( cxn , iteration ) : [EOL] [docstring] [EOL] sql = [string] [EOL] [EOL] cxn . row_factory = sqlite3 . Row [EOL] return cxn . execute ( sql , ( iteration , ) ) [EOL] [EOL] [EOL] [comment] [EOL] [EOL] def create_contig_blast_hits_table ( cxn ) : [EOL] [docstring] [EOL] cxn . executescript ( [string] ) [EOL] [EOL] [EOL] def insert_contig_hit_batch ( cxn , batch ) : [EOL] [docstring] [EOL] sql = [string] [EOL] if batch : [EOL] with cxn : [EOL] cxn . executemany ( sql , batch ) [EOL] [EOL] [EOL] def get_contig_blast_hits ( cxn , iteration ) : [EOL] [docstring] [EOL] sql = [string] [EOL] [EOL] cxn . row_factory = sqlite3 . Row [EOL] return cxn . execute ( sql , ( iteration , ) ) [EOL] [EOL] [EOL] [comment] [EOL] [EOL] def create_assembled_contigs_table ( cxn ) : [EOL] [docstring] [EOL] cxn . executescript ( [string] ) [EOL] [EOL] [EOL] def assembled_contigs_count ( cxn , iteration , bit_score , length ) : [EOL] [docstring] [EOL] sql = [string] [EOL] [EOL] result = cxn . execute ( sql , ( iteration , bit_score , length ) ) [EOL] return result . fetchone ( ) [ [number] ] [EOL] [EOL] [EOL] def iteration_overlap_count ( cxn , iteration , bit_score , length ) : [EOL] [docstring] [EOL] sql = [string] [EOL] result = cxn . execute ( sql , ( iteration , bit_score , bit_score , length ) ) [EOL] return result . fetchone ( ) [ [number] ] [EOL] [EOL] [EOL] def insert_assembled_contigs_batch ( cxn , batch ) : [EOL] [docstring] [EOL] sql = [string] [EOL] if batch : [EOL] with cxn : [EOL] cxn . executemany ( sql , batch ) [EOL] [EOL] [EOL] def get_assembled_contigs ( cxn , iteration , bit_score , length ) : [EOL] [docstring] [EOL] sql = [string] [EOL] return cxn . execute ( sql , ( iteration , bit_score , length ) ) [EOL] [EOL] [EOL] def get_all_assembled_contigs ( cxn , bit_score = [number] , length = [number] ) : [EOL] [docstring] [EOL] sql = [string] [EOL] [EOL] cxn . row_factory = sqlite3 . Row [EOL] return cxn . execute ( sql , ( bit_score , length ) ) [EOL] [EOL] [EOL] def all_assembled_contigs_count ( cxn , bit_score = [number] , length = [number] ) : [EOL] [docstring] [EOL] sql = [string] [EOL] [EOL] result = cxn . execute ( sql , ( bit_score , length ) ) [EOL] return result . fetchone ( ) [ [number] ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , List , Match , Optional , Pattern , Any [EOL] import typing [EOL] [docstring] [EOL] [EOL] import glob [EOL] import json [EOL] import os [EOL] import re [EOL] import sys [EOL] from os . path import basename , dirname , join [EOL] from shutil import which [EOL] [EOL] from . import util [EOL] [EOL] [EOL] def create_db ( log , temp_dir , fasta_file , shard ) : [EOL] [docstring] [EOL] cmd = [string] [EOL] cmd = cmd . format ( fasta_file , shard ) [EOL] log . subcommand ( cmd , temp_dir ) [EOL] [EOL] [EOL] def against_sra ( args , log , state , hits_file , shard ) : [EOL] [docstring] [EOL] cmd = [ ] [EOL] [EOL] if args [ [string] ] and state [ [string] ] == [number] : [EOL] cmd . append ( [string] ) [EOL] cmd . append ( [string] . format ( args [ [string] ] ) ) [EOL] else : [EOL] cmd . append ( [string] ) [EOL] [EOL] cmd . append ( [string] . format ( args [ [string] ] ) ) [EOL] cmd . append ( [string] ) [EOL] cmd . append ( [string] . format ( args [ [string] ] ) ) [EOL] cmd . append ( [string] . format ( hits_file ) ) [EOL] cmd . append ( [string] . format ( shard ) ) [EOL] cmd . append ( [string] . format ( state [ [string] ] ) ) [EOL] [EOL] if args [ [string] ] : [EOL] cmd . append ( [string] . format ( args [ [string] ] ) ) [EOL] [EOL] command = [string] . join ( cmd ) [EOL] log . subcommand ( command , args [ [string] ] , timeout = args [ [string] ] ) [EOL] [EOL] [EOL] def against_contigs ( log , blast_db , query_file , hits_file , ** kwargs ) : [EOL] [docstring] [EOL] cmd = [ ] [EOL] [EOL] if kwargs [ [string] ] : [EOL] cmd . append ( [string] ) [EOL] cmd . append ( [string] . format ( kwargs [ [string] ] ) ) [EOL] else : [EOL] cmd . append ( [string] ) [EOL] [EOL] cmd . append ( [string] . format ( blast_db ) ) [EOL] cmd . append ( [string] . format ( query_file ) ) [EOL] cmd . append ( [string] . format ( hits_file ) ) [EOL] cmd . append ( [string] ) [EOL] [EOL] command = [string] . join ( cmd ) [EOL] log . subcommand ( command , kwargs [ [string] ] , timeout = kwargs [ [string] ] ) [EOL] [EOL] [EOL] def all_shard_paths ( log , blast_db ) : [EOL] [docstring] [EOL] pattern = [string] . format ( blast_db ) [EOL] [EOL] files = glob . glob ( pattern ) [EOL] if not files : [EOL] err = ( [string] [string] ) . format ( pattern [ : - [number] ] ) [EOL] log . fatal ( err ) [EOL] [EOL] return sorted ( f [ : - [number] ] for f in files ) [EOL] [EOL] [EOL] def output_file_name ( temp_dir , shrd_path ) : [EOL] [docstring] [EOL] shard_name = basename ( shrd_path ) [EOL] file_name = [string] . format ( shard_name ) [EOL] return join ( temp_dir , file_name ) [EOL] [EOL] [EOL] def temp_db_name ( temp_dir , blast_db ) : [EOL] [docstring] [EOL] file_name = basename ( blast_db ) [EOL] return join ( temp_dir , file_name ) [EOL] [EOL] [EOL] def get_raw_hits ( log , json_file ) : [EOL] [docstring] [EOL] with open ( json_file ) as blast_file : [EOL] raw = blast_file . read ( ) [EOL] [EOL] [comment] [EOL] if not raw : [EOL] return [ ] [EOL] [EOL] [comment] [EOL] try : [EOL] obj = json . loads ( raw ) [EOL] except json . decoder . JSONDecodeError : [EOL] err = ( [string] [string] ) [EOL] log . fatal ( err ) [EOL] [EOL] return obj [ [string] ] [ [number] ] [ [string] ] [ [string] ] [ [string] ] . get ( [string] , [ ] ) [EOL] [EOL] [EOL] def hits ( log , json_file ) : [EOL] [docstring] [EOL] hits_list = [ ] [EOL] raw_hits = get_raw_hits ( log , json_file ) [EOL] [EOL] for raw in raw_hits : [EOL] for i , desc in enumerate ( raw [ [string] ] ) : [EOL] hit = dict ( desc ) [EOL] hit [ [string] ] = raw [ [string] ] [EOL] hit . update ( raw [ [string] ] [ i ] ) [EOL] hits_list . append ( hit ) [EOL] [EOL] return hits_list [EOL] [EOL] [EOL] def command_line_args ( parser ) : [EOL] [docstring] [EOL] group = parser . add_argument_group ( [string] ) [EOL] [EOL] group . add_argument ( [string] , type = int , default = [number] , metavar = [string] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , type = float , default = [number] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , type = int , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , type = int , default = [number] , metavar = [string] , help = [string] ) [EOL] [EOL] group . add_argument ( [string] , type = int , help = [string] ) [EOL] [EOL] [EOL] def check_args ( args ) : [EOL] [docstring] [EOL] if args [ [string] ] and args [ [string] ] < [number] : [EOL] sys . exit ( [string] ) [EOL] [EOL] [EOL] def default_max_target_seqs ( log , max_target_seqs , blast_db , max_memory ) : [EOL] [docstring] [EOL] if not max_target_seqs : [EOL] all_shards = all_shard_paths ( log , blast_db ) [EOL] max_target_seqs = int ( [number] * max_memory / len ( all_shards ) ) * [number] [EOL] return max_target_seqs [EOL] [EOL] [EOL] def default_shard_count ( args , sra_files ) : [EOL] [docstring] [EOL] shard_count = args [ [string] ] [EOL] if not shard_count : [EOL] total_fasta_size = [number] [EOL] for file_name in sra_files : [EOL] total_fasta_size += util . shard_file_size ( args , file_name ) [EOL] shard_count = int ( total_fasta_size / [number] ) [EOL] shard_count = shard_count if shard_count else [number] [EOL] [EOL] return shard_count [EOL] [EOL] [EOL] def make_blast_output_dir ( blast_db ) : [EOL] [docstring] [EOL] output_dir = dirname ( blast_db ) [EOL] if output_dir and output_dir not in [ [string] , [string] ] : [EOL] os . makedirs ( output_dir , exist_ok = True ) [EOL] [EOL] [EOL] def touchup_blast_db_names ( blast_dbs ) : [EOL] [docstring] [EOL] pattern = re . compile ( [string] [string] [string] [string] , re . I | re . X ) [EOL] [EOL] db_names = [ ] [EOL] [EOL] for blast_db in blast_dbs : [EOL] db_names . append ( re . sub ( pattern , [string] , blast_db ) ) [EOL] [EOL] return db_names [EOL] [EOL] [EOL] def find_program ( program ) : [EOL] [docstring] [EOL] if not ( which ( [string] ) and which ( [string] ) and which ( [string] ) ) : [EOL] err = ( [string] [string] [string] [string] ) . format ( program ) [EOL] sys . exit ( err ) [EOL] [EOL] [EOL] def parse_fasta_title ( title , ends , seq_end_clamp ) : [EOL] [docstring] [EOL] parts = title . split ( ) [EOL] if not parts : [EOL] parts = [ [string] ] [EOL] match = re . match ( [string] , parts [ [number] ] ) [EOL] if match : [EOL] [comment] [EOL] seq_name = parts [ [number] ] if ends == [string] else match . group ( [number] ) [EOL] seq_end = match . group ( [number] ) if ends == [string] else seq_end_clamp [EOL] elif len ( parts ) > [number] and re . match ( [string] , parts [ [number] ] ) : [EOL] [comment] [EOL] seq_name = [string] . join ( parts [ : [number] ] ) if ends == [string] else parts [ [number] ] [EOL] seq_end = parts [ [number] ] if ends == [string] else seq_end_clamp [EOL] else : [EOL] seq_name = parts [ [number] ] [EOL] seq_end = seq_end_clamp [EOL] return seq_name , seq_end [EOL] [EOL] [EOL] def parse_blast_title ( title , is_single_end ) : [EOL] [docstring] [EOL] seq_name , seq_end = title , [string] [EOL] match = re . match ( [string] , title ) [EOL] if match and not is_single_end : [EOL] seq_name , seq_end = match . group ( [number] ) , match . group ( [number] ) [EOL] return seq_name , seq_end [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Any [EOL] import typing [EOL] [docstring] [EOL] [EOL] from . base import BaseAssembler [EOL] from . . import db_atram , util [EOL] [EOL] [EOL] class NoneAssembler ( BaseAssembler ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , args , cxn , log ) : [EOL] [docstring] [EOL] super ( ) . __init__ ( args , cxn , log ) [EOL] self . steps = [ ] [EOL] self . blast_only = True [comment] [EOL] [EOL] def write_final_output ( self , blast_db , query ) : [EOL] [docstring] [EOL] prefix = self . final_output_prefix ( blast_db , query ) [EOL] [EOL] file_name = [string] . format ( prefix ) [EOL] [EOL] with open ( file_name , [string] ) as output_file : [EOL] for row in db_atram . get_sra_blast_hits ( self . state [ [string] ] , [number] ) : [EOL] util . write_fasta_record ( output_file , row [ [string] ] , row [ [string] ] , row [ [string] ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import List , Any [EOL] import typing [EOL] [docstring] [EOL] [EOL] import shutil [EOL] [EOL] from . base import BaseAssembler [EOL] [EOL] [EOL] class VelvetAssembler ( BaseAssembler ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , args , cxn , log ) : [EOL] [docstring] [EOL] super ( ) . __init__ ( args , cxn , log ) [EOL] self . steps = [ self . velveth , self . velvetg ] [EOL] [EOL] @ staticmethod def parse_contig_id ( header ) : [EOL] [docstring] [EOL] return header [EOL] [EOL] def velveth ( self ) : [comment] [EOL] [docstring] [EOL] cmd = [ [string] , [string] . format ( self . work_path ( ) ) , [string] . format ( self . args [ [string] ] ) , [string] ] [EOL] [EOL] if self . file [ [string] ] : [EOL] cmd . append ( [string] . format ( self . file [ [string] ] , self . file [ [string] ] ) ) [EOL] [EOL] single_ends = [ ] [EOL] if self . file [ [string] ] : [EOL] single_ends . append ( [string] . format ( self . file [ [string] ] ) ) [EOL] if self . file [ [string] ] : [EOL] single_ends . append ( [string] . format ( self . file [ [string] ] ) ) [EOL] if self . file [ [string] ] : [EOL] single_ends . append ( [string] . format ( self . file [ [string] ] ) ) [EOL] if single_ends : [EOL] cmd . append ( [string] . format ( [string] . join ( single_ends ) ) ) [EOL] [EOL] if self . file [ [string] ] and not self . args [ [string] ] : [EOL] cmd . append ( [string] . format ( self . file [ [string] ] ) ) [EOL] [EOL] return [string] . join ( cmd ) [EOL] [EOL] def velvetg ( self ) : [EOL] [docstring] [EOL] cmd = [ [string] , [string] . format ( self . work_path ( ) ) , [string] . format ( self . args [ [string] ] ) , [string] . format ( self . args [ [string] ] ) , [string] . format ( self . args [ [string] ] ) ] [EOL] [EOL] return [string] . join ( cmd ) [EOL] [EOL] def post_assembly ( self ) : [EOL] [docstring] [EOL] src = self . iter_file ( [string] ) [EOL] shutil . move ( src , self . file [ [string] ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0
from typing import List , Any [EOL] import typing [EOL] [docstring] [EOL] [EOL] from os . path import join [EOL] from shutil import move [EOL] [EOL] from . base import BaseAssembler [EOL] [EOL] [EOL] class TrinityAssembler ( BaseAssembler ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , args , cxn , log ) : [EOL] [docstring] [EOL] super ( ) . __init__ ( args , cxn , log ) [EOL] self . steps = [ self . trinity ] [EOL] [EOL] def work_path ( self ) : [EOL] [docstring] [EOL] return join ( self . state [ [string] ] , [string] ) [EOL] [EOL] def trinity ( self ) : [EOL] [docstring] [EOL] cmd = [ [string] , [string] , [string] . format ( self . args [ [string] ] ) , [string] . format ( self . args [ [string] ] ) , [string] . format ( self . work_path ( ) ) , [string] ] [EOL] [EOL] if not self . args [ [string] ] : [EOL] cmd . append ( [string] ) [EOL] [EOL] if self . file [ [string] ] : [EOL] cmd . append ( [string] . format ( self . file [ [string] ] ) ) [EOL] cmd . append ( [string] . format ( self . file [ [string] ] ) ) [EOL] else : [EOL] single_ends = self . get_single_ends ( ) [EOL] if single_ends : [EOL] cmd . append ( [string] . format ( [string] . join ( single_ends ) ) ) [EOL] [EOL] if self . file [ [string] ] and not self . args [ [string] ] : [EOL] cmd . append ( [string] . format ( self . file [ [string] ] ) ) [EOL] [EOL] return [string] . join ( cmd ) [EOL] [EOL] def post_assembly ( self ) : [EOL] [docstring] [EOL] src = join ( self . state [ [string] ] , [string] ) [EOL] move ( src , self . file [ [string] ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0
	0
from typing import List , Any [EOL] import io [EOL] import typing [EOL] [docstring] [EOL] [EOL] import datetime [EOL] from os . path import abspath , basename , exists , getsize , join , splitext [EOL] from subprocess import CalledProcessError [EOL] [EOL] from . . import bio , db_atram , util [EOL] [EOL] [EOL] class BaseAssembler : [comment] [EOL] [docstring] [EOL] [EOL] def __init__ ( self , args , cxn , log ) : [EOL] [docstring] [EOL] self . args = args [comment] [EOL] self . blast_only = False [comment] [EOL] self . steps = [ ] [comment] [EOL] self . file = { } [comment] [EOL] self . log = log [EOL] [EOL] [comment] [EOL] [comment] [EOL] self . state = { [string] : [number] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : cxn } [comment] [EOL] [EOL] def init_iteration ( self , blast_db , query_file , iteration ) : [EOL] [docstring] [EOL] self . state [ [string] ] = blast_db [EOL] self . state [ [string] ] = query_file [EOL] self . state [ [string] ] = iteration [EOL] if iteration == [number] : [EOL] self . state [ [string] ] = query_file [EOL] [EOL] def setup_files ( self , iter_dir ) : [EOL] [docstring] [EOL] self . state [ [string] ] = iter_dir [EOL] self . file [ [string] ] = [string] [comment] [EOL] [EOL] names = [string] . split ( ) [EOL] for name in names : [EOL] self . file [ name ] = self . iter_file ( name + [string] ) [EOL] [EOL] [comment] [EOL] for name in [string] . split ( ) : [EOL] self . file [ name + [string] ] = [number] [EOL] [EOL] def file_prefix ( self ) : [EOL] [docstring] [EOL] return [string] . format ( basename ( self . state [ [string] ] ) , basename ( self . state [ [string] ] ) , self . state [ [string] ] ) [EOL] [EOL] def iter_file ( self , file_name ) : [EOL] [docstring] [EOL] rel_path = join ( self . state [ [string] ] , file_name ) [EOL] [comment] [EOL] return abspath ( rel_path ) [EOL] [EOL] def work_path ( self ) : [EOL] [docstring] [EOL] return self . state [ [string] ] [EOL] [EOL] def run ( self ) : [EOL] [docstring] [EOL] try : [EOL] self . log . info ( [string] . format ( self . args [ [string] ] , self . state [ [string] ] ) ) [EOL] self . assemble ( ) [EOL] except TimeoutError : [EOL] msg = [string] . format ( datetime . timedelta ( seconds = self . args [ [string] ] ) ) [EOL] self . log . error ( msg ) [EOL] raise TimeoutError ( msg ) [EOL] except CalledProcessError as cpe : [EOL] msg = [string] + str ( cpe ) [EOL] self . log . error ( msg ) [EOL] raise RuntimeError ( msg ) [EOL] [EOL] def count_blast_hits ( self ) : [EOL] [docstring] [EOL] count = db_atram . sra_blast_hits_count ( self . state [ [string] ] , self . state [ [string] ] ) [EOL] self . log . info ( [string] . format ( count , self . state [ [string] ] ) ) [EOL] return count [EOL] [EOL] def nothing_assembled ( self ) : [EOL] [docstring] [EOL] if not exists ( self . file [ [string] ] ) or not getsize ( self . file [ [string] ] ) : [EOL] self . log . info ( [string] . format ( self . state [ [string] ] ) ) [EOL] return True [EOL] return False [EOL] [EOL] def assembled_contigs_count ( self , high_score ) : [EOL] [docstring] [EOL] count = db_atram . assembled_contigs_count ( self . state [ [string] ] , self . state [ [string] ] , self . args [ [string] ] , self . args [ [string] ] ) [EOL] [EOL] if not count : [EOL] self . log . info ( [string] [string] [string] . format ( self . args [ [string] ] , self . args [ [string] ] , self . state [ [string] ] , high_score ) ) [EOL] return count [EOL] [EOL] def no_new_contigs ( self , count ) : [EOL] [docstring] [EOL] if count == db_atram . iteration_overlap_count ( self . state [ [string] ] , self . state [ [string] ] , self . args [ [string] ] , self . args [ [string] ] ) : [EOL] self . log . info ( [string] . format ( self . state [ [string] ] ) ) [EOL] return True [EOL] return False [EOL] [EOL] def assemble ( self ) : [EOL] [docstring] [EOL] for step in self . steps : [EOL] cmd = step ( ) [EOL] self . log . subcommand ( cmd , self . args [ [string] ] , self . args [ [string] ] ) [EOL] self . post_assembly ( ) [EOL] [EOL] def post_assembly ( self ) : [EOL] [docstring] [EOL] [EOL] @ staticmethod def parse_contig_id ( header ) : [EOL] [docstring] [EOL] return header . split ( ) [ [number] ] [EOL] [EOL] def write_input_files ( self ) : [EOL] [docstring] [EOL] self . log . info ( [string] . format ( self . state [ [string] ] ) ) [EOL] self . write_paired_input_files ( ) [EOL] self . write_single_input_files ( ) [EOL] [EOL] def write_paired_input_files ( self ) : [EOL] [docstring] [EOL] with open ( self . file [ [string] ] , [string] ) as end_1 , open ( self . file [ [string] ] , [string] ) as end_2 : [EOL] [EOL] for row in db_atram . get_blast_hits_by_end_count ( self . state [ [string] ] , self . state [ [string] ] , [number] ) : [EOL] [EOL] self . file [ [string] ] += [number] [EOL] out_file = end_1 if row [ [string] ] == [string] else end_2 [EOL] [EOL] util . write_fasta_record ( out_file , row [ [string] ] , row [ [string] ] , row [ [string] ] ) [EOL] [EOL] def write_single_input_files ( self ) : [EOL] [docstring] [EOL] with open ( self . file [ [string] ] , [string] ) as end_1 , open ( self . file [ [string] ] , [string] ) as end_2 , open ( self . file [ [string] ] , [string] ) as end_any : [EOL] [EOL] rows = db_atram . get_blast_hits_by_end_count ( self . state [ [string] ] , self . state [ [string] ] , [number] ) [EOL] [EOL] for row in rows : [EOL] if row [ [string] ] == [string] : [EOL] out_file = end_1 [EOL] seq_end = [string] [EOL] self . file [ [string] ] += [number] [EOL] elif row [ [string] ] == [string] : [EOL] out_file = end_2 [EOL] seq_end = [string] [EOL] self . file [ [string] ] += [number] [EOL] else : [EOL] out_file = end_any [EOL] seq_end = [string] [EOL] self . file [ [string] ] += [number] [EOL] [EOL] util . write_fasta_record ( out_file , row [ [string] ] , row [ [string] ] , seq_end ) [EOL] [EOL] def final_output_prefix ( self , blast_db , query ) : [EOL] [docstring] [EOL] blast_db = basename ( blast_db ) [EOL] query = splitext ( basename ( query ) ) [ [number] ] [EOL] return util . prefix_file ( self . args [ [string] ] , [string] . format ( blast_db , query ) ) [EOL] [EOL] def write_final_output ( self , blast_db , query ) : [EOL] [docstring] [EOL] prefix = self . final_output_prefix ( blast_db , query ) [EOL] [EOL] self . write_filtered_contigs ( prefix ) [EOL] self . write_all_contigs ( prefix ) [EOL] [EOL] def write_filtered_contigs ( self , prefix ) : [EOL] [docstring] [EOL] if self . args [ [string] ] : [EOL] return [EOL] [EOL] count = db_atram . all_assembled_contigs_count ( self . state [ [string] ] , self . args [ [string] ] , self . args [ [string] ] ) [EOL] if not count : [EOL] return [EOL] [EOL] file_name = [string] . format ( prefix , [string] ) [EOL] [EOL] contigs = db_atram . get_all_assembled_contigs ( self . state [ [string] ] , self . args [ [string] ] , self . args [ [string] ] ) [EOL] [EOL] with open ( file_name , [string] ) as output_file : [EOL] for contig in contigs : [EOL] self . output_assembled_contig ( output_file , contig ) [EOL] [EOL] def write_all_contigs ( self , prefix ) : [EOL] [docstring] [EOL] count = db_atram . all_assembled_contigs_count ( self . state [ [string] ] ) [EOL] if not count : [EOL] return [EOL] [EOL] file_name = [string] . format ( prefix , [string] ) [EOL] [EOL] contigs = db_atram . get_all_assembled_contigs ( self . state [ [string] ] ) [EOL] [EOL] with open ( file_name , [string] ) as output_file : [EOL] for contig in contigs : [EOL] self . output_assembled_contig ( output_file , contig ) [EOL] [EOL] @ staticmethod def output_assembled_contig ( output_file , contig ) : [EOL] [docstring] [EOL] seq = contig [ [string] ] [EOL] suffix = [string] [EOL] [EOL] if contig [ [string] ] and contig [ [string] ] and contig [ [string] ] != contig [ [string] ] : [EOL] seq = bio . reverse_complement ( seq ) [EOL] suffix = [string] [EOL] [EOL] header = [string] . format ( contig [ [string] ] , contig [ [string] ] , suffix , contig [ [string] ] , contig [ [string] ] , contig [ [string] ] ) [EOL] [EOL] util . write_fasta_record ( output_file , header , seq ) [EOL] [EOL] def get_single_ends ( self ) : [EOL] [docstring] [EOL] single_ends = [ ] [EOL] if self . file [ [string] ] : [EOL] single_ends . append ( self . file [ [string] ] ) [EOL] if self . file [ [string] ] : [EOL] single_ends . append ( self . file [ [string] ] ) [EOL] if self . file [ [string] ] : [EOL] single_ends . append ( self . file [ [string] ] ) [EOL] return single_ends [EOL] [EOL] def simple_state ( self ) : [EOL] [docstring] [EOL] return { [string] : self . state [ [string] ] , [string] : self . state [ [string] ] , [string] : self . state [ [string] ] , [string] : self . state [ [string] ] , [string] : self . state [ [string] ] } [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $io.TextIOWrapper$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $io.TextIOWrapper$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $io.TextIOWrapper$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $io.TextIOWrapper$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $io.TextIOWrapper$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $io.TextIOWrapper$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import List , Any [EOL] import typing [EOL] [docstring] [EOL] [EOL] from os . path import realpath [EOL] from shutil import copyfile [EOL] [EOL] from . base import BaseAssembler [EOL] [EOL] [EOL] class AbyssAssembler ( BaseAssembler ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , args , cxn , log ) : [EOL] [docstring] [EOL] super ( ) . __init__ ( args , cxn , log ) [EOL] self . steps = [ self . abyss ] [EOL] [EOL] def abyss ( self ) : [EOL] [docstring] [EOL] cmd = [ [string] , [string] . format ( self . work_path ( ) ) , [string] , [string] . format ( self . args [ [string] ] ) ] [EOL] [EOL] if self . args . get ( [string] ) is not None : [EOL] cmd . append ( [string] . format ( self . args [ [string] ] ) ) [EOL] [EOL] cmd . append ( [string] . format ( self . file [ [string] ] ) ) [EOL] [EOL] if self . args [ [string] ] : [EOL] cmd . append ( [string] . format ( self . args [ [string] ] ) ) [EOL] [EOL] if self . args . get ( [string] ) : [EOL] if self . file [ [string] ] : [EOL] cmd . append ( [string] . format ( self . file [ [string] ] , self . file [ [string] ] ) ) [EOL] single_ends = self . get_single_ends ( ) [EOL] if single_ends : [EOL] cmd . append ( [string] . format ( [string] . join ( single_ends ) ) ) [EOL] else : [EOL] in_files = [ ] [EOL] if self . file [ [string] ] : [EOL] in_files += [ self . file [ [string] ] , self . file [ [string] ] ] [EOL] in_files += self . get_single_ends ( ) [EOL] cmd . append ( [string] . format ( [string] . join ( in_files ) ) ) [EOL] [EOL] if self . file [ [string] ] and not self . args [ [string] ] : [EOL] cmd . append ( [string] ) [EOL] cmd . append ( [string] . format ( self . file [ [string] ] ) ) [EOL] [EOL] return [string] . join ( cmd ) [EOL] [EOL] def post_assembly ( self ) : [EOL] [docstring] [EOL] src = realpath ( self . file [ [string] ] + [string] ) [EOL] [EOL] copyfile ( src , self . file [ [string] ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0
from typing import List [EOL] import typing [EOL] [docstring] [EOL] [EOL] import shutil [EOL] from os . path import join [EOL] [EOL] from . base import BaseAssembler [EOL] [EOL] [EOL] class SpadesAssembler ( BaseAssembler ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , args , cxn , log ) : [EOL] [docstring] [EOL] super ( ) . __init__ ( args , cxn , log ) [EOL] self . steps = [ self . spades ] [EOL] [EOL] def work_path ( self ) : [EOL] [docstring] [EOL] return join ( self . state [ [string] ] , [string] ) [EOL] [EOL] def spades ( self ) : [EOL] [docstring] [EOL] cmd = [ [string] , [string] , [string] . format ( self . args [ [string] ] ) , [string] . format ( self . args [ [string] ] ) , [string] . format ( self . args [ [string] ] ) , [string] . format ( self . work_path ( ) ) ] [EOL] [EOL] if self . args [ [string] ] : [EOL] cmd . append ( [string] ) [EOL] [EOL] if self . file [ [string] ] : [EOL] cmd . append ( [string] . format ( self . file [ [string] ] ) ) [EOL] cmd . append ( [string] . format ( self . file [ [string] ] ) ) [EOL] [EOL] if self . file [ [string] ] : [EOL] cmd . append ( [string] . format ( self . file [ [string] ] ) ) [EOL] if self . file [ [string] ] : [EOL] cmd . append ( [string] . format ( self . file [ [string] ] ) ) [EOL] if self . file [ [string] ] : [EOL] cmd . append ( [string] . format ( self . file [ [string] ] ) ) [EOL] [EOL] return [string] . join ( cmd ) [EOL] [EOL] def post_assembly ( self ) : [EOL] [docstring] [EOL] src = join ( self . work_path ( ) , [string] ) [EOL] shutil . move ( src , self . file [ [string] ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0
[docstring] [EOL] [EOL] import sys [EOL] from os . path import dirname , abspath , join [EOL] [EOL] [EOL] ROOT_DIR = join ( dirname ( dirname ( abspath ( __file__ ) ) ) , [string] , [string] ) [EOL] sys . path . append ( ROOT_DIR ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0
	0
	0
import sqlite3 [EOL] [docstring] [EOL] [EOL] import sqlite3 [EOL] import lib . db as db [EOL] import lib . db_atram as db_atram [EOL] import lib . db_preprocessor as db_preprocessor [EOL] [EOL] [EOL] CXN = sqlite3 . connect ( [string] ) [EOL] [EOL] [EOL] def setUpModule ( ) : [EOL] [docstring] [EOL] CXN . execute ( [string] ) [EOL] db_preprocessor . create_metadata_table ( CXN , { } ) [EOL] db_preprocessor . create_sequences_table ( CXN ) [EOL] db_atram . create_sra_blast_hits_table ( CXN ) [EOL] db_atram . create_contig_blast_hits_table ( CXN ) [EOL] db_atram . create_assembled_contigs_table ( CXN ) [EOL] [EOL] [EOL] def test_get_db_name_01 ( ) : [EOL] [docstring] [EOL] assert db . get_db_name ( [string] ) == [string] [EOL] [EOL] [EOL] def test_get_version_01 ( ) : [EOL] [docstring] [EOL] assert db . get_version ( CXN ) == [string] [EOL] [EOL] [EOL] def test_get_version_02 ( ) : [EOL] [docstring] [EOL] CXN . execute ( [string] ) [EOL] assert db . get_version ( CXN ) == [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $sqlite3.dbapi2.Connection$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $sqlite3.dbapi2.Connection$ 0 0 0 0 0 0 0 0 0 0 $sqlite3.dbapi2.Connection$ 0 0 0 0 0 0 0 0 0 $sqlite3.dbapi2.Connection$ 0 0 0 0 0 0 $sqlite3.dbapi2.Connection$ 0 0 0 0 0 0 $sqlite3.dbapi2.Connection$ 0 0 0 0 0 0 $sqlite3.dbapi2.Connection$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $sqlite3.dbapi2.Connection$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $sqlite3.dbapi2.Connection$ 0 0 0 0 0 0 0 0 0 0 0 $sqlite3.dbapi2.Connection$ 0 0 0 0
[docstring] [EOL] [EOL] import lib . blast as blast [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] def test_parse_fasta_title_01 ( ) : [EOL] [docstring] [EOL] actual_seq_name , actual_seq_end = blast . parse_fasta_title ( [string] , [string] , [string] ) [EOL] assert actual_seq_name == [string] [EOL] assert actual_seq_end == [string] [EOL] [EOL] [EOL] def test_parse_fasta_title_02 ( ) : [EOL] [docstring] [EOL] seq_name , seq_end = blast . parse_fasta_title ( [string] , [string] , [string] ) [EOL] assert seq_name == [string] [EOL] assert seq_end == [string] [EOL] [EOL] [EOL] def test_parse_fasta_title_03 ( ) : [EOL] [docstring] [EOL] seq_name , seq_end = blast . parse_fasta_title ( [string] , [string] , [string] ) [EOL] assert seq_name == [string] [EOL] assert seq_end == [string] [EOL] [EOL] [EOL] def test_parse_fasta_title_04 ( ) : [EOL] [docstring] [EOL] seq_name , seq_end = blast . parse_fasta_title ( [string] , [string] , [string] ) [EOL] assert seq_name == [string] [EOL] assert seq_end == [string] [EOL] [EOL] [EOL] def test_parse_fasta_title_05 ( ) : [EOL] [docstring] [EOL] seq_name , seq_end = blast . parse_fasta_title ( [string] , [string] , [string] ) [EOL] assert seq_name == [string] [EOL] assert seq_end == [string] [EOL] [EOL] [EOL] def test_parse_fasta_title_06 ( ) : [EOL] [docstring] [EOL] seq_name , seq_end = blast . parse_fasta_title ( [string] , [string] , [string] ) [EOL] assert seq_name == [string] [EOL] assert seq_end == [string] [EOL] [EOL] [EOL] def test_parse_fasta_title_07 ( ) : [EOL] [docstring] [EOL] seq_name , seq_end = blast . parse_fasta_title ( [string] , [string] , [string] ) [EOL] assert seq_name == [string] [EOL] assert seq_end == [string] [EOL] [EOL] [EOL] def test_parse_fasta_title_08 ( ) : [EOL] [docstring] [EOL] seq_name , seq_end = blast . parse_fasta_title ( [string] , [string] , [string] ) [EOL] assert seq_name == [string] [EOL] assert seq_end == [string] [EOL] [EOL] [EOL] def test_parse_fasta_title_09 ( ) : [EOL] [docstring] [EOL] seq_name , seq_end = blast . parse_fasta_title ( [string] , [string] , [string] ) [EOL] assert seq_name == [string] [EOL] assert seq_end == [string] [EOL] [EOL] [EOL] def test_parse_fasta_title_10 ( ) : [EOL] [docstring] [EOL] seq_name , seq_end = blast . parse_fasta_title ( [string] , [string] , [string] ) [EOL] assert seq_name == [string] [EOL] assert seq_end == [string] [EOL] [EOL] [EOL] def test_parse_fasta_title_11 ( ) : [EOL] [docstring] [EOL] seq_name , seq_end = blast . parse_fasta_title ( [string] , [string] , [string] ) [EOL] assert seq_name == [string] [EOL] assert seq_end == [string] [EOL] [EOL] [EOL] def test_parse_fasta_title_12 ( ) : [EOL] [docstring] [EOL] seq_name , seq_end = blast . parse_fasta_title ( [string] , [string] , [string] ) [EOL] assert seq_name == [string] [EOL] assert seq_end == [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] [docstring] [EOL] [EOL] import lib . bio as bio [EOL] [EOL] [EOL] def test_reverse_complement_01 ( ) : [EOL] [docstring] [EOL] seq = [string] [EOL] actual = bio . reverse_complement ( seq ) [EOL] assert actual == [string] [ : : - [number] ] [EOL] [EOL] [EOL] def test_reverse_complement_02 ( ) : [EOL] [docstring] [EOL] seq = [string] [EOL] actual = bio . reverse_complement ( bio . reverse_complement ( seq ) ) [EOL] assert actual == [string] [EOL] [EOL] [EOL] def test_is_protein_no ( ) : [EOL] [docstring] [EOL] seq = [string] [EOL] assert not bio . is_protein ( seq ) [EOL] [EOL] [EOL] def test_is_protein_yes ( ) : [EOL] [docstring] [EOL] seq = [string] [EOL] assert bio . is_protein ( seq ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0