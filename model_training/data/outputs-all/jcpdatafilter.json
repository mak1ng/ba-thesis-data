[comment] [EOL] [comment] [EOL] [EOL] from typing import Dict , Any [EOL] import typing [EOL] import os [EOL] import shutil [EOL] import sys [EOL] [EOL] from io import open [EOL] from setuptools import find_packages , setup [EOL] [EOL] [EOL] if sys . argv [ - [number] ] == [string] : [EOL] os . system ( [string] ) [EOL] os . system ( [string] ) [EOL] shutil . rmtree ( [string] ) [EOL] shutil . rmtree ( [string] ) [EOL] shutil . rmtree ( [string] ) [EOL] sys . exit ( ) [EOL] [EOL] here = os . path . abspath ( os . path . dirname ( __file__ ) ) [EOL] [EOL] about = { } [EOL] with open ( os . path . join ( here , [string] ) , [string] , encoding = [string] ) as f : [EOL] exec ( f . read ( ) , about ) [EOL] [EOL] with open ( [string] , [string] , encoding = [string] ) as f : [EOL] readme = f . read ( ) [EOL] [EOL] setup ( name = about [ [string] ] , author = about [ [string] ] , author_email = about [ [string] ] , description = about [ [string] ] , include_package_data = True , license = about [ [string] ] , long_description = readme , long_description_content_type = [string] , packages = find_packages ( exclude = [ [string] ] ) , python_requires = [string] , url = about [ [string] ] , version = about [ [string] ] , zip_safe = False , classifiers = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , ] , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] [EOL] from typing import List [EOL] import typing [EOL] DIGITS = [string] [EOL] [EOL] PUNCTUATION = [string] [EOL] [EOL] WHITESPACE = [string] [EOL] [EOL] TRANSLATIONS = [ DIGITS , PUNCTUATION , WHITESPACE ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $typing.List[builtins.str]$ 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 0
[comment] [EOL] [EOL] from typing import Any , Optional , Dict , Literal , Tuple , Union , List [EOL] import builtins [EOL] import typing_extensions [EOL] import typing [EOL] from abc import ABC , abstractmethod [EOL] from typing import Any , Dict , List , Optional , Tuple , Union [EOL] [EOL] from . config import TRANSLATIONS [EOL] [EOL] [EOL] class Base ( ABC ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , tokens , translations = None , bidirectional = True , caseinsensitive = True , ) : [EOL] self . tokens = tokens [EOL] self . translations = TRANSLATIONS if translations is None else translations [EOL] self . bidirectional = bidirectional [EOL] self . caseinsensitive = caseinsensitive [EOL] self . trans = self . maketrans ( ) [EOL] self . normalized_tokens = [ self . normalize ( x ) for x in self . tokens ] [EOL] [EOL] @ abstractmethod def results ( self ) : [EOL] [docstring] [EOL] pass [comment] [EOL] [EOL] def maketrans ( self ) : [EOL] [docstring] [EOL] z = [string] . join ( self . translations ) [EOL] trans = str . maketrans ( [string] , [string] , z ) [EOL] return trans [EOL] [EOL] def normalize ( self , data ) : [EOL] [docstring] [EOL] sep = [string] if type ( data ) is str else [string] [EOL] val = sep . join ( data ) [EOL] val = val . translate ( self . trans ) [EOL] val = val . lower ( ) if self . caseinsensitive else val [EOL] return data , val [EOL] [EOL] def parse ( self , data ) : [EOL] [docstring] [EOL] detected = [ ] [EOL] frequency = { } [EOL] do , dn = self . normalize ( data ) [EOL] [EOL] for to , tn in self . normalized_tokens : [EOL] frequency [ to ] = [number] [EOL] [EOL] if tn in dn or self . bidirectional and tn in dn [ : : - [number] ] : [EOL] detected . append ( to ) [EOL] frequency [ to ] += dn . count ( tn ) + dn [ : : - [number] ] . count ( tn ) [EOL] [EOL] return { [string] : do , [string] : True if detected else False , [string] : { [string] : { [string] : detected , [string] : len ( detected ) , [string] : frequency , } } , } [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Union[typing.Tuple[typing.List[builtins.str],builtins.str],typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 $typing.Union[typing.List[builtins.str],builtins.str]$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Union[typing.List[builtins.str],builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0
[comment] [EOL] [EOL] from typing import List [EOL] import typing [EOL] from datafilter . filters import CSV , Text , TextFile [EOL] [EOL] [docstring] [EOL] [EOL] __title__ = [string] [EOL] __description__ = [string] [EOL] __url__ = [string] [EOL] __package_name__ = [string] [EOL] __version__ = [string] [EOL] __author__ = [string] [EOL] __author_email__ = [string] [EOL] __license__ = [string] [EOL] __copyright__ = [string] [EOL] [EOL] VERSION = __version__ [EOL] [EOL] [EOL] __all__ = [ [string] , [string] , [string] ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] from typing import Any , Optional , Dict , Iterator , List , Union [EOL] import _csv [EOL] import builtins [EOL] import typing [EOL] import csv [EOL] import re [EOL] from typing import Any , Dict , Iterator , List , Optional , Union [EOL] [EOL] from . base import Base [EOL] from . mixins import Save [EOL] [EOL] [EOL] class CSV ( Base ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , path , tokens , translations = None , bidirectional = True , caseinsensitive = True , ) : [EOL] super ( ) . __init__ ( tokens , translations , bidirectional , caseinsensitive ) [EOL] self . path = path [EOL] [EOL] Iterator [ Dict [ str , Dict [ str , Union [ List [ str ] , str , bool ] ] ] ] [EOL] [EOL] def results ( self ) : [EOL] [docstring] [EOL] with open ( self . path , newline = [string] ) as f : [EOL] for row in csv . reader ( f ) : [EOL] yield self . parse ( row ) [EOL] [EOL] def save ( self , path ) : [EOL] [docstring] [EOL] with open ( path , [string] , newline = [string] ) as f : [EOL] writer = csv . writer ( f ) [EOL] for row in self . results ( ) : [EOL] if not row [ [string] ] : [EOL] writer . writerow ( row [ [string] ] ) [EOL] [EOL] [EOL] class Text ( Base , Save ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , text , tokens , re_split = None , translations = None , bidirectional = True , caseinsensitive = True , ) : [EOL] super ( ) . __init__ ( tokens , translations , bidirectional , caseinsensitive ) [EOL] self . text = text [EOL] self . re_split = re_split [EOL] [EOL] if not isinstance ( self . text , str ) : [EOL] raise TypeError ( [string] ) [EOL] [EOL] def results ( self ) : [EOL] [docstring] [EOL] text = [ self . text ] [EOL] if self . re_split : [EOL] text = re . split ( self . re_split , text [ [number] ] ) [EOL] [EOL] for data in text : [EOL] yield self . parse ( data ) [EOL] [EOL] [EOL] class TextFile ( Base , Save ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , path , tokens , re_split = None , translations = None , bidirectional = True , caseinsensitive = True , ) : [EOL] super ( ) . __init__ ( tokens , translations , bidirectional , caseinsensitive ) [EOL] self . path = path [EOL] self . re_split = re_split [EOL] [EOL] def results ( self ) : [EOL] [docstring] [EOL] with open ( self . path , newline = [string] ) as f : [EOL] text = f . readlines ( ) [EOL] if self . re_split : [EOL] text = re . split ( self . re_split , text [ [number] ] ) [EOL] [EOL] for data in text : [EOL] yield self . parse ( data ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $_csv._writer$ 0 0 0 $_csv._writer$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $_csv._writer$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 $typing.List[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 0 0 $typing.Optional[typing.List[builtins.str]]$ 0 0 0 $builtins.bool$ 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 $typing.Optional[typing.List[builtins.str]]$ 0 $builtins.bool$ 0 $builtins.bool$ 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterator[typing.Dict[builtins.str,typing.Union[typing.List[builtins.str],builtins.bool,typing.Dict[builtins.str,typing.Any]]]]$ 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 $typing.List[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 0 0 $typing.Optional[typing.List[builtins.str]]$ 0 0 0 $builtins.bool$ 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 $typing.Optional[typing.List[builtins.str]]$ 0 $builtins.bool$ 0 $builtins.bool$ 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $typing.Optional[builtins.str]$ 0 $typing.Optional[builtins.str]$ 0 0 0 $typing.Iterator[typing.Dict[builtins.str,typing.Union[typing.List[builtins.str],builtins.bool,typing.Dict[builtins.str,typing.Any]]]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] [EOL] import builtins [EOL] class Save : [EOL] [docstring] [EOL] [EOL] def save ( self , path , endofline = [string] ) : [EOL] [docstring] [EOL] with open ( path , [string] , newline = [string] ) as f : [EOL] for row in self . results ( ) : [EOL] if not row [ [string] ] : [EOL] f . write ( f"{ row [ [string] ] }{ endofline }" ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
[comment] [EOL] [EOL] from typing import List , Any [EOL] import typing [EOL] import datafilter [EOL] import os [EOL] [EOL] import pytest [EOL] [EOL] from datafilter import CSV , Text , TextFile [EOL] [EOL] [EOL] def test_csv_results ( ) : [EOL] path = os . path . dirname ( os . path . abspath ( __file__ ) ) [EOL] filepath = os . path . join ( path , [string] ) [EOL] obj = CSV ( filepath , tokens = [ [string] , [string] ] ) [EOL] assert [ x [ [string] ] for x in obj . results ( ) ] == [ True , False , False , True , False ] [EOL] assert sum ( [ x [ [string] ] [ [string] ] [ [string] ] for x in obj . results ( ) ] ) == [number] [EOL] [EOL] [EOL] def test_csv_save ( tmpdir ) : [EOL] tmp = tmpdir . mkdir ( [string] ) [EOL] tmpfile = f"{ tmp } [string] " [EOL] tokens = [ [string] , [string] ] [EOL] path = os . path . dirname ( os . path . abspath ( __file__ ) ) [EOL] filepath = os . path . join ( path , [string] ) [EOL] obj = CSV ( filepath , tokens = [ [string] , [string] ] ) [EOL] obj . save ( tmpfile ) [EOL] tmp_obj = CSV ( tmpfile , tokens = tokens ) [EOL] assert [ x [ [string] ] for x in tmp_obj . results ( ) ] == [ False , False , False ] [EOL] [EOL] [EOL] def test_text_type_error ( ) : [EOL] with pytest . raises ( TypeError ) as exc_info : [EOL] Text ( text = [number] , tokens = [ [string] ] ) [EOL] [EOL] exc_info . match ( [string] ) [EOL] [EOL] [EOL] def test_text_results ( ) : [EOL] text = [string] [EOL] obj = Text ( text , tokens = [ [string] ] ) [EOL] assert next ( obj . results ( ) ) [ [string] ] [ [string] ] [ [string] ] == [number] [EOL] [EOL] [EOL] def test_text_results_re_split ( ) : [EOL] text = [string] [EOL] obj = Text ( text , tokens = [ [string] ] , re_split = [string] ) [EOL] assert sum ( [number] for _ in obj . results ( ) ) == len ( text . split ( [string] ) ) [EOL] [EOL] [EOL] def test_text_save ( tmpdir ) : [EOL] tmp = tmpdir . mkdir ( [string] ) [EOL] tmpfile = f"{ tmp } [string] " [EOL] text = [string] [EOL] obj = Text ( text , tokens = [ [string] ] , re_split = [string] ) [EOL] obj . save ( tmpfile ) [EOL] [EOL] with open ( tmpfile , newline = [string] ) as f : [EOL] text = f . readlines ( ) [EOL] assert text [ [number] ] . startswith ( [string] ) [EOL] [EOL] [EOL] def test_textfile_results ( ) : [EOL] path = os . path . dirname ( os . path . abspath ( __file__ ) ) [EOL] filepath = os . path . join ( path , [string] ) [EOL] obj = TextFile ( filepath , tokens = [ [string] , [string] ] ) [EOL] assert next ( obj . results ( ) ) [ [string] ] [ [string] ] [ [string] ] == [number] [EOL] [EOL] [EOL] def test_textfile_results_re_split ( ) : [EOL] path = os . path . dirname ( os . path . abspath ( __file__ ) ) [EOL] filepath = os . path . join ( path , [string] ) [EOL] obj = TextFile ( filepath , tokens = [ [string] ] , re_split = [string] ) [EOL] assert sum ( [number] for _ in obj . results ( ) ) == [number] [EOL] [EOL] [EOL] def test_textfile_save ( tmpdir ) : [EOL] tmp = tmpdir . mkdir ( [string] ) [EOL] tmpfile = f"{ tmp } [string] " [EOL] tokens = [ [string] , [string] ] [EOL] path = os . path . dirname ( os . path . abspath ( __file__ ) ) [EOL] filepath = os . path . join ( path , [string] ) [EOL] obj = TextFile ( filepath , tokens = tokens , re_split = [string] ) [EOL] obj . save ( tmpfile ) [EOL] [EOL] with open ( tmpfile , newline = [string] ) as f : [EOL] text = f . readlines ( ) [EOL] assert text [ [number] ] . startswith ( [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] from typing import Dict , List , Any [EOL] import tests [EOL] import typing [EOL] import pytest [EOL] [EOL] from datafilter . base import Base [EOL] [EOL] [EOL] class InvalidBase ( Base ) : [EOL] [docstring] [EOL] [EOL] pass [EOL] [EOL] [EOL] class ValidBase ( Base ) : [EOL] [docstring] [EOL] [EOL] def results ( self ) : [EOL] pass [EOL] [EOL] [EOL] def test_instantiation_with_invalid_base ( ) : [EOL] with pytest . raises ( TypeError ) as exc_info : [EOL] InvalidBase ( ) [EOL] [EOL] assert exc_info . match ( [string] ) [EOL] [EOL] [EOL] def test_makelower_caseinsensitive_true ( ) : [EOL] data = [string] [EOL] obj = ValidBase ( tokens = [ [string] ] , caseinsensitive = True ) [EOL] _ , results = obj . normalize ( data ) [EOL] assert results == [string] [EOL] [EOL] [EOL] def test_makelower_caseinsensitive_false ( ) : [EOL] data = [string] [EOL] obj = ValidBase ( tokens = [ [string] ] , caseinsensitive = False ) [EOL] _ , results = obj . normalize ( data ) [EOL] assert data == results [EOL] [EOL] [EOL] def test_maketrans ( ) : [EOL] obj = ValidBase ( tokens = [ [string] ] , translations = [ [string] ] ) [EOL] z = [string] . join ( obj . translations ) [EOL] assert obj . maketrans ( ) == str . maketrans ( [string] , [string] , z ) [EOL] assert obj . trans == str . maketrans ( [string] , [string] , z ) [EOL] [EOL] [EOL] def test_normalize ( ) : [EOL] data = [ [string] , [string] ] [EOL] obj = ValidBase ( tokens = [ [string] ] ) [EOL] assert obj . normalize ( data ) == ( [ [string] , [string] ] , [string] ) [EOL] [EOL] [EOL] def test_normalize_bidirectional_true ( ) : [EOL] data = [string] [EOL] obj = ValidBase ( tokens = [ [string] ] , bidirectional = True ) [EOL] results = obj . parse ( data ) [EOL] assert results [ [string] ] [ [string] ] [ [string] ] == [number] [EOL] [EOL] [EOL] def test_normalize_bidirectional_false ( ) : [EOL] data = [string] [EOL] obj = ValidBase ( tokens = [ [string] ] , bidirectional = False ) [EOL] results = obj . parse ( data ) [EOL] assert results [ [string] ] [ [string] ] [ [string] ] == [number] [EOL] [EOL] [EOL] def test_normalized_token_attribute ( ) : [EOL] obj = ValidBase ( tokens = [ [string] ] ) [EOL] assert list ( obj . normalized_tokens ) == [ ( [string] , [string] ) ] [EOL] [EOL] [EOL] def test_parse_flagged_true ( ) : [EOL] data = [string] [EOL] obj = ValidBase ( tokens = [ [string] ] ) [EOL] assert obj . parse ( data ) [ [string] ] is True [EOL] [EOL] [EOL] def test_parse_flagged_false ( ) : [EOL] data = [string] [EOL] obj = ValidBase ( tokens = [ [string] ] ) [EOL] assert obj . parse ( data ) [ [string] ] is False [EOL] [EOL] [EOL] def test_parse_return ( ) : [EOL] data = [string] [EOL] obj = ValidBase ( tokens = [ [string] ] ) [EOL] assert obj . parse ( data ) == { [string] : [string] , [string] : True , [string] : { [string] : { [string] : [ [string] ] , [string] : [number] , [string] : { [string] : [number] } } } , } [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0