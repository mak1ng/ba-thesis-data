[comment] [EOL] [comment] [EOL] from typing import Any , Dict , List [EOL] import typing [EOL] import batch_test_tpot [EOL] import pandas as pd [EOL] import numpy as np [EOL] import random [EOL] import os [EOL] from copy import copy [EOL] from sklearn . ensemble import RandomForestClassifier [EOL] from lib . execute import Executor [EOL] from tools . mylogger import logger [EOL] from lib . select_funcs import drop_useless , drop_by_iv [EOL] from lib . judge_funcs import judge_auc_mean_std [EOL] from lib . utils import getReport [EOL] from tpot import TPOTClassifier [EOL] [EOL] [EOL] [EOL] class MyExecutor ( Executor ) : [EOL] def feature_select ( self , sub_train_set , y ) : [EOL] logger . info ( [string] . format ( len ( sub_train_set . columns ) ) ) [EOL] tmp1 = drop_useless ( sub_train_set , [string] , [string] , [string] ) [EOL] return tmp1 [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] def judge_function_model ( self , result , n_var ) : [EOL] [docstring] [EOL] result = [ i for i in result ] [EOL] model_score = [ ] [EOL] for i in result : [EOL] current_auc_list = np . array ( i ) [ : , [number] ] [EOL] score = judge_auc_mean_std ( current_auc_list . mean ( ) , current_auc_list . std ( ) ) [EOL] model_score . append ( score ) [EOL] model_score_sum = sum ( model_score ) [EOL] model_weight = list ( map ( lambda x : round ( x / model_score_sum , [number] ) , model_score ) ) [EOL] var_weight_collection = [ ] [EOL] for mw , single_res in zip ( model_weight , result ) : [EOL] single_var_res = self . get_variable_cnt ( single_res [ [number] ] ) [EOL] single_var_res [ [string] ] = single_var_res [ [string] ] * mw [EOL] var_weight_collection . append ( single_var_res ) [EOL] var_weight_collection = pd . concat ( var_weight_collection ) [EOL] [EOL] var_weight_result = [ ] [EOL] for ss in var_weight_collection . groupby ( by = [string] ) : [EOL] tmp = { [string] : ss [ [number] ] , [string] : ss [ [number] ] [ [string] ] . sum ( ) } [EOL] var_weight_result . append ( copy ( tmp ) ) [EOL] var_weight_result = pd . DataFrame ( var_weight_result ) . sort_values ( by = [string] , ascending = False ) [EOL] return var_weight_result [ [string] ] [ [number] : n_var ] [EOL] [EOL] [EOL] def main ( kwargs ) : [EOL] df = pd . read_csv ( [string] , encoding = [string] ) [EOL] trainSet = df [ df [ [string] ] . isin ( [ [string] , [string] , [string] ] ) ] . reset_index ( drop = True ) [EOL] testSet = df [ df [ [string] ] == [string] ] . reset_index ( drop = True ) [EOL] [EOL] logger . info ( [string] ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] clf = kwargs [ [string] ] [EOL] myexe = MyExecutor ( df , [string] , clf ) [EOL] leftVaris = myexe . get_result ( kwargs [ [string] ] ) [EOL] print ( [string] ) [EOL] print ( leftVaris ) [EOL] print ( [string] ) [EOL] X_train = trainSet [ leftVaris ] . copy ( ) [EOL] y_train = trainSet [ [string] ] . copy ( ) [EOL] X_test = testSet [ leftVaris ] . copy ( ) [EOL] y_test = testSet [ [string] ] . copy ( ) [EOL] [comment] [EOL] pipeline_optimizer = TPOTClassifier ( generations = int ( kwargs [ [string] ] ) , population_size = int ( kwargs [ [string] ] ) , scoring = kwargs [ [string] ] , cv = int ( kwargs [ [string] ] ) , subsample = float ( kwargs [ [string] ] ) , n_jobs = int ( kwargs [ [string] ] ) , max_eval_time_mins = int ( kwargs [ [string] ] ) , random_state = random . randint ( [number] , [number] ) ) [EOL] pipeline_optimizer . fit ( X_train , y_train ) [EOL] trainKS , testKS , abs_trainKS_testKS , trainAUC , testAUC , abs_trainAUC_testAUC = getReport ( pipeline_optimizer , trainSet , X_train , y_train , testSet , X_test , y_test ) [EOL] [EOL] [comment] [EOL] if kwargs [ [string] ] is os . listdir ( [string] ) : [EOL] os . removedirs ( [string] . format ( kwargs [ [string] ] ) ) [EOL] os . mkdir ( [string] . format ( kwargs [ [string] ] ) ) [EOL] pipeline_optimizer . export ( [string] . format ( kwargs [ [string] ] ) ) [EOL] with open ( [string] . format ( kwargs [ [string] ] ) , [string] ) as f1 : [EOL] f1 . write ( str ( leftVaris ) ) [EOL] report = pd . DataFrame ( [ { [string] : trainKS , [string] : testKS , [string] : abs_trainKS_testKS , [string] : trainAUC , [string] : testAUC , [string] : abs_trainAUC_testAUC } , ] ) [EOL] report . to_csv ( [string] . format ( kwargs [ [string] ] ) , index = False , encoding = [string] ) [EOL] [EOL] [EOL] def batch_run ( ) : [EOL] prama_df = pd . read_csv ( [string] , encoding = [string] ) [EOL] feature_model = RandomForestClassifier ( n_estimators = [number] , max_features = [number] , max_depth = [number] , min_samples_split = [number] , ) [EOL] for i in range ( len ( prama_df ) ) : [EOL] tmp = dict ( prama_df . iloc [ i ] ) [EOL] for j in tmp . keys ( ) : [EOL] if pd . isna ( tmp [ j ] ) : [EOL] tmp [ j ] = None [EOL] tmp [ [string] ] = feature_model [EOL] print ( tmp ) [EOL] main ( tmp ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] batch_run ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 $typing.List[typing.Any]$ 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 $typing.List[typing.Any]$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] from typing import Any , Dict , List [EOL] import typing [EOL] import rocket_autosk [EOL] import pandas as pd [EOL] import numpy as np [EOL] [comment] [EOL] from xgboost import XGBClassifier [EOL] from lib . execute import Executor [EOL] from tools . mylogger import logger [EOL] from lib . select_funcs import drop_useless , drop_by_iv [EOL] from lib . judge_funcs import judge_auc_mean_std [EOL] from lib . utils import getReport [EOL] import autosklearn . classification [EOL] from autosklearn . metrics import * [EOL] from sklearn import metrics [EOL] [EOL] [EOL] class MyExecutor ( Executor ) : [EOL] def feature_select ( self , sub_train_set , y ) : [EOL] logger . info ( [string] . format ( len ( sub_train_set . columns ) ) ) [EOL] tmp1 = drop_useless ( sub_train_set , [string] , [string] , [string] ) [EOL] sub_train_set = sub_train_set [ tmp1 ] [EOL] tmp2 = drop_by_iv ( sub_train_set , [string] , [number] ) [EOL] logger . info ( [string] . format ( len ( tmp2 ) ) ) [EOL] return tmp2 [EOL] [EOL] def judge_function_model ( self , result , n_var ) : [EOL] [docstring] [EOL] result = [ i for i in result ] [EOL] model_score = [ ] [EOL] for i in result : [EOL] current_auc_list = np . array ( i ) [ : , [number] ] [EOL] score = judge_auc_mean_std ( current_auc_list . mean ( ) , current_auc_list . std ( ) ) [EOL] model_score . append ( score ) [EOL] model_score_sum = sum ( model_score ) [EOL] model_weight = list ( map ( lambda x : round ( x / model_score_sum , [number] ) , model_score ) ) [EOL] var_weight_collection = [ ] [EOL] for mw , single_res in zip ( model_weight , result ) : [EOL] single_var_res = self . get_variable_cnt ( single_res [ [number] ] ) [EOL] single_var_res [ [string] ] = single_var_res [ [string] ] * mw [EOL] var_weight_collection . append ( single_var_res ) [EOL] var_weight_collection = pd . concat ( var_weight_collection ) [EOL] [EOL] print ( var_weight_collection . columns ) [EOL] var_weight_collection . to_csv ( [string] ) [EOL] var_weight_result = [ ] [EOL] for ss in var_weight_collection . groupby ( by = [string] ) : [EOL] tmp = { [string] : ss [ [number] ] , [string] : ss [ [number] ] [ [string] ] . sum ( ) } [EOL] var_weight_result . append ( copy ( tmp ) ) [EOL] var_weight_result = pd . DataFrame ( var_weight_result ) . sort_values ( by = [string] , ascending = False ) [EOL] var_weight_result . to_csv ( [string] , index = False ) [EOL] return var_weight_result [ [string] ] [ [number] : n_var ] [EOL] [EOL] [EOL] def main ( ) : [EOL] df = pd . read_csv ( [string] , encoding = [string] ) [EOL] trainSet = df [ df [ [string] ] . isin ( [ [string] , [string] , [string] ] ) ] . reset_index ( drop = True ) [EOL] testSet = df [ df [ [string] ] == [string] ] . reset_index ( drop = True ) [EOL] [EOL] logger . info ( [string] ) [EOL] clf = XGBClassifier ( n_estimators = [number] , max_features = [number] , max_depth = [number] , min_samples_split = [number] , ) [EOL] myexe = MyExecutor ( df , [string] , clf ) [EOL] leftVaris = myexe . get_result ( ) [EOL] leftVaris = leftVaris [ leftVaris . values > [number] ] . keys ( ) [EOL] X_train = trainSet [ leftVaris ] . copy ( ) [EOL] y_train = trainSet [ [string] ] . copy ( ) [EOL] X_test = testSet [ leftVaris ] . copy ( ) [EOL] y_test = testSet [ [string] ] . copy ( ) [EOL] [comment] [EOL] cls = autosklearn . classification . AutoSklearnClassifier ( time_left_for_this_task = [number] , per_run_time_limit = [number] , include_estimators = [ [string] ] , resampling_strategy = [string] , resampling_strategy_arguments = { [string] : [number] } ) [EOL] getReport ( cls , trainSet , X_train , y_train , testSet , X_test , y_test ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 $typing.List[typing.Any]$ 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 $typing.List[typing.Any]$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment]	0
[comment]	0
[comment]	0
[comment] [EOL] from typing import Any [EOL] import typing [EOL] import os [EOL] import pandas as pd [EOL] [EOL] [EOL] os . chdir ( [string] ) [EOL] df = pd . read_csv ( [string] ) [EOL] [EOL] [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] from typing import Any , Dict , List [EOL] import typing [EOL] import os [EOL] import pandas as pd [EOL] import math [EOL] import numpy as np [EOL] from copy import copy [EOL] from sklearn import tree [EOL] [EOL] [EOL] def smbinning_test ( df , Y , x ) : [EOL] y = df [ Y ] [EOL] x_test = df [ [ x , ] ] [EOL] mytree = tree . DecisionTreeClassifier ( max_features = [number] , min_weight_fraction_leaf = [number] , min_samples_split = [number] , criterion = [string] , max_leaf_nodes = [number] ) [EOL] mytree . fit ( x_test , y ) [EOL] cutpoint = mytree . tree_ . threshold [EOL] print ( x ) [EOL] print ( cutpoint ) [EOL] print ( [string] ) [EOL] cutpoint = cutpoint [ cutpoint != - [number] ] [EOL] cutpoint . sort ( ) [EOL] return cutpoint [EOL] [EOL] [EOL] def calc_columns ( single_result , tmp , Y , df ) : [EOL] single_result [ [string] ] = len ( tmp ) [EOL] [comment] [EOL] single_result [ [string] ] = len ( tmp [ tmp [ Y ] == [number] ] ) [EOL] single_result [ [string] ] = len ( tmp [ tmp [ Y ] == [number] ] ) [EOL] single_result [ [string] ] = round ( ( single_result [ [string] ] / len ( df [ df [ Y ] == [number] ] ) ) , [number] ) [EOL] single_result [ [string] ] = round ( ( single_result [ [string] ] / len ( df [ df [ Y ] == [number] ] ) ) , [number] ) [EOL] single_result [ [string] ] = round ( ( len ( tmp ) / len ( df ) ) , [number] ) [EOL] try : [EOL] single_result [ [string] ] = round ( ( single_result [ [string] ] / single_result [ [string] ] ) , [number] ) [EOL] except : [EOL] single_result [ [string] ] = None [EOL] try : [EOL] single_result [ [string] ] = round ( ( single_result [ [string] ] / single_result [ [string] ] ) , [number] ) [EOL] except : [EOL] single_result [ [string] ] = None [EOL] try : [EOL] single_result [ [string] ] = round ( math . log ( single_result [ [string] ] / single_result [ [string] ] ) , [number] ) [EOL] except : [EOL] single_result [ [string] ] = None [EOL] try : [EOL] single_result [ [string] ] = round ( ( single_result [ [string] ] - single_result [ [string] ] ) * single_result [ [string] ] , [number] ) [EOL] except : [EOL] single_result [ [string] ] = None [EOL] return copy ( single_result ) [EOL] [EOL] [EOL] def calc_iv ( df , Y , x , cuts ) : [EOL] [comment] [EOL] cuts = list ( cuts ) [EOL] cuts . sort ( ) [EOL] single_sample = df [ [ Y , x ] ] [EOL] single_sample = pd . DataFrame ( single_sample ) [EOL] result = [ ] [EOL] base_single_result = dict . fromkeys ( [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] ] , None ) [EOL] [EOL] for i in cuts : [EOL] single_result = copy ( base_single_result ) [EOL] if i == min ( cuts ) : [EOL] tmp = single_sample . dropna ( ) [EOL] single_result [ [string] ] = [string] . format ( i ) [EOL] tmp = tmp [ tmp [ x ] <= i ] [EOL] else : [EOL] tmp = single_sample . dropna ( ) [EOL] single_result [ [string] ] = [string] . format ( i ) [EOL] tmp = tmp [ ( tmp [ x ] > cuts [ cuts . index ( i ) - [number] ] ) & ( tmp [ x ] <= i ) ] [EOL] result . append ( calc_columns ( single_result , tmp , Y , df ) ) [EOL] [EOL] tmp_max = single_sample . dropna ( ) [EOL] tmp_max = tmp_max [ tmp_max [ x ] > max ( cuts ) ] [EOL] single_result_max = calc_columns ( copy ( base_single_result ) , tmp_max , Y , df ) [EOL] single_result_max [ [string] ] = [string] . format ( max ( cuts ) ) [EOL] result . append ( single_result_max ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] tmp_missing = single_sample [ pd . isnull ( single_sample [ x ] ) ] [EOL] single_result_missing = calc_columns ( copy ( base_single_result ) , tmp_missing , Y , df ) [EOL] single_result_missing [ [string] ] = [string] [EOL] result . append ( single_result_missing ) [EOL] [comment] [EOL] result = pd . DataFrame ( result ) [EOL] tmp_total = single_sample [EOL] single_result_total = calc_columns ( copy ( base_single_result ) , tmp_total , Y , df ) [EOL] single_result_total [ [string] ] = [string] [EOL] single_result_total [ [string] ] = round ( result [ [string] ] . sum ( ) , [number] ) [EOL] print ( x , [string] , single_result_total [ [string] ] ) [EOL] result = result . append ( pd . DataFrame ( [ single_result_total , ] ) ) [ [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] ] ] [EOL] return result [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] os . chdir ( [string] ) [EOL] df = pd . read_csv ( [string] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] print ( smbinning_test ( df , [string] , [string] ) ) [EOL] [EOL] [EOL] res = calc_iv ( df , [string] , [string] , [ [number] , [number] , [number] , [number] ] ) [EOL] [EOL] [EOL] [EOL] [EOL] [EOL] [EOL] [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] from typing import Any , List [EOL] import typing [EOL] import pandas as pd [EOL] from copy import copy [EOL] from xgboost . sklearn import XGBClassifier [EOL] from lib . utils import getReport [EOL] from sklearn . pipeline import make_pipeline [EOL] from sklearn . preprocessing import MaxAbsScaler [EOL] from xgboost import XGBClassifier [EOL] [EOL] [EOL] [EOL] [EOL] [EOL] [EOL] [EOL] [EOL] [EOL] import numpy as np [EOL] import pandas as pd [EOL] from xgboost import XGBClassifier [EOL] from sklearn . cross_validation import KFold [EOL] from sklearn . grid_search import GridSearchCV [EOL] from sklearn . metrics import accuracy_score [EOL] from scipy import stats [EOL] [EOL] def ks_score ( model , X_train , y_train ) : [EOL] X_pred = model . predict_proba ( X_train ) [EOL] X_train [ [string] ] = X_pred [ : , [number] ] [EOL] good = X_train [ X_train [ [string] ] == [number] ] [EOL] bad = X_train [ X_train [ [string] ] == [number] ] [EOL] trainKS = stats . ks_2samp ( good [ [string] ] , bad [ [string] ] ) . statistic [EOL] return trainKS [EOL] [EOL] [EOL] [EOL] [EOL] [EOL] [EOL] def run ( ) : [EOL] df = pd . read_csv ( [string] , encoding = [string] ) [EOL] trainSet = df [ df [ [string] ] . isin ( [ [string] , [string] , [string] ] ) ] . reset_index ( drop = True ) [EOL] testSet = df [ df [ [string] ] == [string] ] . reset_index ( drop = True ) [EOL] leftVaris = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] X_train = trainSet [ leftVaris ] . copy ( ) [EOL] y_train = trainSet [ [string] ] . copy ( ) [EOL] X_test = testSet [ leftVaris ] . copy ( ) [EOL] y_test = testSet [ [string] ] . copy ( ) [EOL] [EOL] [comment] [EOL] model = XGBClassifier ( learning_rate = [number] , max_depth = [number] , n_estimators = [number] , subsample = [number] ) [EOL] [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] [comment] [EOL] [EOL] model . fit ( X_train , y_train ) [EOL] getReport ( model , trainSet , X_train , y_train , testSet , X_test , y_test ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] [comment] [EOL] run ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] from typing import Any [EOL] import typing [EOL] import numpy as np [EOL] from timeit import default_timer as timer [EOL] from numba import vectorize [EOL] [EOL] @ vectorize ( [ [string] ] , target = [string] ) def vectorAdd ( a , b ) : [EOL] return a + b [EOL] [EOL] def main ( ) : [EOL] N = [number] [EOL] [EOL] A = np . ones ( N , dtype = np . float32 ) [EOL] B = np . ones ( N , dtype = np . float32 ) [EOL] C = np . zeros ( N , dtype = np . float32 ) [EOL] [EOL] start = timer ( ) [EOL] C = vectorAdd ( A , B ) [EOL] vectorAdd_time = timer ( ) - start [EOL] [EOL] print ( [string] + str ( C [ : [number] ] ) ) [EOL] print ( [string] + str ( C [ - [number] : ] ) ) [EOL] [EOL] print ( [string] % vectorAdd_time ) [EOL] [EOL] if __name__ == [string] : [EOL] main ( )	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [docstring] [EOL] import numpy as np [EOL] from sklearn . utils . multiclass import type_of_target [EOL] [EOL] [EOL] class WeightOfEvidence : [EOL] [docstring] [EOL] [EOL] def __init__ ( self ) : [EOL] self . woe = None [EOL] self . iv = None [EOL] [EOL] def _posibility ( self , x , tag , event = [number] ) : [EOL] [docstring] [EOL] if type_of_target ( tag ) not in [ [string] ] : [EOL] raise AttributeError ( [string] ) [EOL] if type_of_target ( x ) in [ [string] ] : [EOL] raise AttributeError ( [string] ) [EOL] tag = np . array ( tag ) [EOL] x = np . array ( x ) [EOL] event_total = ( tag == event ) . sum ( ) [EOL] non_event_total = tag . shape [ - [number] ] - event_total [EOL] x_labels = np . unique ( x ) [EOL] pos_dic = { } [EOL] for x1 in x_labels : [EOL] y1 = tag [ np . where ( x == x1 ) [ [number] ] ] [EOL] event_count = ( y1 == event ) . sum ( ) [EOL] non_event_count = y1 . shape [ - [number] ] - event_count [EOL] rate_event = [number] * event_count / event_total [EOL] rate_non_event = [number] * non_event_count / non_event_total [EOL] pos_dic [ x1 ] = ( rate_event , rate_non_event ) [EOL] return pos_dic [EOL] [EOL] def fit ( self , x , y , * , event = [number] , woe_min = - [number] , woe_max = [number] ) : [EOL] [docstring] [EOL] woe_dict = { } [EOL] iv = [number] [EOL] pos_dic = self . _posibility ( x = x , tag = y , event = event ) [EOL] for l , ( rate_event , rate_non_event ) in pos_dic . items ( ) : [EOL] if rate_event == [number] : [EOL] woe1 = woe_min [EOL] elif rate_non_event == [number] : [EOL] woe1 = woe_max [EOL] else : [EOL] woe1 = np . log ( rate_event / rate_non_event ) [comment] [EOL] iv += ( rate_event - rate_non_event ) * woe1 [EOL] woe_dict [ str ( l ) ] = woe1 [EOL] self . woe = woe_dict [EOL] self . iv = iv [EOL] [EOL] def transform ( self , X ) : [EOL] [docstring] [EOL] return np . array ( [ self . woe . get ( i ) for i in X ] )	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] import gevent [EOL] def test1 ( ) : [EOL] print ( [number] ) [EOL] gevent . sleep ( [number] ) [EOL] print ( [number] ) [EOL] [EOL] [EOL] def test2 ( ) : [EOL] print ( [number] ) [EOL] gevent . sleep ( [number] ) [EOL] print ( [number] ) [EOL] [EOL] [EOL] gevent . joinall ( [ gevent . spawn ( test1 ) , gevent . spawn ( test2 ) , ] )	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] from typing import Any , List [EOL] import typing [EOL] import test [EOL] import pandas as pd [EOL] import numpy as np [EOL] [comment] [EOL] from xgboost import XGBClassifier [EOL] from lib . execute import Executor [EOL] from tools . mylogger import logger [EOL] from lib . select_funcs import drop_useless , drop_by_iv [EOL] from lib . judge_funcs import judge_auc_mean_std [EOL] from lib . utils import getReport [EOL] from tpot import TPOTClassifier [EOL] [EOL] [EOL] class MyExecutor ( Executor ) : [EOL] def feature_select ( self , sub_train_set , y ) : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] tmp2 = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] return tmp2 [EOL] [EOL] def judge_function_model ( self , result ) : [EOL] result = [ i for i in result ] [EOL] model_score = [ ] [EOL] for i in result : [EOL] current_auc_list = np . array ( i ) [ : , [number] ] [EOL] score = judge_auc_mean_std ( current_auc_list . mean ( ) , current_auc_list . std ( ) ) [EOL] model_score . append ( score ) [EOL] best_model_index = pd . Series ( model_score ) . idxmax ( ) [EOL] return result [ best_model_index ] [EOL] [EOL] [EOL] def main ( ) : [EOL] df = pd . read_csv ( [string] , encoding = [string] ) [EOL] df [ [string] ] = pd . to_datetime ( df [ [string] ] ) [EOL] trainSet = df [ ( df [ [string] ] >= [string] ) & ( df [ [string] ] <= [string] ) ] . reset_index ( drop = True ) [EOL] testSet = df [ ( df [ [string] ] >= [string] ) & ( df [ [string] ] <= [string] ) ] . reset_index ( drop = True ) [EOL] logger . info ( [string] ) [EOL] clf = XGBClassifier ( learning_rate = [number] , max_depth = [number] , min_child_weight = [number] , n_estimators = [number] , nthread = [number] , subsample = [number] ) [EOL] myexe = MyExecutor ( df , [string] , clf ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] leftVaris = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] [EOL] X_train = trainSet [ leftVaris ] . copy ( ) [EOL] y_train = trainSet [ [string] ] . copy ( ) [EOL] X_test = testSet [ leftVaris ] . copy ( ) [EOL] y_test = testSet [ [string] ] . copy ( ) [EOL] [comment] [EOL] pipeline_optimizer = TPOTClassifier ( generations = [number] , population_size = [number] , cv = [number] , random_state = [number] , verbosity = [number] ) [EOL] pipeline_optimizer . fit ( X_train , y_train ) [EOL] [comment] [EOL] pipeline_optimizer . export ( [string] ) [EOL] getReport ( pipeline_optimizer , trainSet , X_train , y_train , testSet , X_test , y_test ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] from typing import Any [EOL] import typing [EOL] from sklearn import cross_validation , metrics [EOL] from sklearn import svm [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import numpy as np [EOL] from sklearn import metrics [EOL] [EOL] y = np . array ( [ [number] , [number] , [number] , [number] ] ) [EOL] pred = np . array ( [ [number] , [number] , [number] , [number] ] ) [EOL] fpr , tpr , thresholds = metrics . roc_curve ( y , pred , pos_label = [number] ) [EOL] print ( metrics . auc ( fpr , tpr ) )	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment]	0
[EOL] def setUpModule ( ) : [EOL] print ( [string] ) [EOL] [EOL] [EOL] def tearDownModule ( ) : [EOL] print ( [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] import unittest [EOL] import unittest [EOL] import numpy as np [EOL] try : [EOL] from binningpy . unsupervised . constant_width import ConstantWidthBinning [EOL] except : [EOL] import sys [EOL] from pathlib import Path [EOL] path = str ( Path ( __file__ ) . absolute ( ) . parent . parent ) [EOL] if path not in sys . path : [EOL] sys . path . append ( path ) [EOL] from binningpy . unsupervised . constant_width import ConstantWidthBinning [EOL] [EOL] [EOL] def setUpModule ( ) : [EOL] print ( [string] ) [EOL] [EOL] [EOL] def tearDownModule ( ) : [EOL] print ( [string] ) [EOL] [EOL] [EOL] class TestConstantWidthBinning ( unittest . TestCase ) : [EOL] @ classmethod def setUpClass ( cls ) : [EOL] print ( [string] ) [EOL] [EOL] @ classmethod def tearDownClass ( cls ) : [EOL] print ( [string] ) [EOL] [EOL] def setUp ( self ) : [EOL] print ( [string] ) [EOL] [EOL] def tearDown ( self ) : [EOL] print ( [string] ) [EOL] [EOL] def test_confined_transform ( self ) : [EOL] bb = ConstantWidthBinning ( [number] ) [EOL] bb . fit ( np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) . reshape ( - [number] , [number] ) ) [EOL] print ( bb . _bins ) [EOL] result = bb . transform ( np . array ( [ [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] , [number] ] ) . reshape ( - [number] , [number] ) ) [EOL] target_result = np . array ( [ [ [number] ] , [ [number] ] , [ [number] ] , [ [number] ] , [ [number] ] , [ [number] ] , [ [number] ] , [ [number] ] , [ [number] ] , [ [number] ] , [ [number] ] , [ [number] ] ] ) [EOL] print ( result ) [EOL] assert all ( map ( lambda x : x [ [number] ] [ [number] ] == x [ [number] ] [ [number] ] , zip ( result , target_result ) ) ) [EOL] [EOL] [EOL] def BinningBase_suite ( ) : [EOL] suite = unittest . TestSuite ( ) [EOL] suite . addTest ( TestConstantWidthBinning ( [string] ) ) [EOL] return suite [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] runner = unittest . TextTestRunner ( verbosity = [number] ) [EOL] test_suite = BinningBase_suite ( ) [EOL] runner . run ( test_suite ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $unittest.runner.TextTestRunner$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $unittest.runner.TextTestRunner$ 0 0 0 $typing.Any$ 0 0
from typing import Any , List [EOL] import typing [EOL] import builtins [EOL] import numpy as np [EOL] from sklearn . base import BaseEstimator , TransformerMixin [EOL] from sklearn . utils import check_array [EOL] from sklearn . utils . validation import ( FLOAT_DTYPES , check_is_fitted ) [EOL] [EOL] [EOL] class BinningBase ( BaseEstimator , TransformerMixin ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , bin_nbr = [number] , confined = True , copy = True ) : [EOL] if not isinstance ( bin_nbr , int ) : [EOL] raise AttributeError ( [string] ) [EOL] if confined and bin_nbr <= [number] : [EOL] raise AttributeError ( [string] ) [EOL] if not confined and bin_nbr <= [number] : [EOL] raise AttributeError ( [string] ) [EOL] [EOL] self . bin_nbr = bin_nbr [EOL] self . confined = confined [EOL] self . copy = copy [EOL] [EOL] def _transform_item ( self , item , features_line ) : [EOL] bins = self . _bins [ features_line ] [EOL] for i in range ( len ( bins ) - [number] ) : [EOL] if self . confined : [EOL] if bins [ i ] <= item < bins [ i + [number] ] : [EOL] return i [EOL] else : [EOL] continue [EOL] else : [EOL] if bins [ i ] <= item < bins [ i + [number] ] : [EOL] return i + [number] [EOL] else : [EOL] continue [EOL] else : [EOL] if self . confined : [EOL] raise AttributeError ( f"{ item } [string] " ) [EOL] else : [EOL] if item >= bins [ - [number] ] : [EOL] return len ( bins ) [EOL] if item < bins [ [number] ] : [EOL] return [number] [EOL] [EOL] def _transform ( self , x , features_line ) : [EOL] for i , value in enumerate ( x ) : [EOL] x [ i ] = self . _transform_item ( value , features_line ) [EOL] return x [EOL] [EOL] def transform ( self , X ) : [EOL] [docstring] [EOL] check_is_fitted ( self , [string] ) [EOL] [EOL] X = check_array ( X , copy = self . copy , dtype = FLOAT_DTYPES ) [EOL] result = [ ] [EOL] for features_line , x in enumerate ( X . T ) : [EOL] result . append ( self . _transform ( x , features_line ) ) [EOL] return np . array ( result , dtype = int ) . T [EOL] [EOL] def _inverse_transform_item ( self , item , features_line ) : [EOL] bins = self . _bins [ features_line ] [EOL] [comment] [EOL] if self . confined : [EOL] return ( bins [ item ] , bins [ item + [number] ] ) [EOL] else : [EOL] if item == [number] : [EOL] return ( - np . inf , bins [ item ] ) [EOL] elif item == len ( bins ) : [EOL] return ( bins [ - [number] ] , np . inf ) [EOL] else : [EOL] return ( bins [ item - [number] ] , bins [ item ] ) [EOL] [EOL] [EOL] def _inverse_transform ( self , x , features_line ) : [EOL] result = [ ] [EOL] for i , value in enumerate ( x ) : [EOL] result . append ( self . _inverse_transform_item ( value , features_line ) ) [EOL] return result [EOL] [EOL] def inverse_transform ( self , X ) : [EOL] [docstring] [EOL] check_is_fitted ( self , [string] ) [EOL] [EOL] X = check_array ( X , copy = self . copy ) [EOL] result = [ ] [EOL] for features_line , x in enumerate ( X . T ) : [EOL] result . append ( self . _inverse_transform ( x , features_line ) ) [EOL] return result [EOL] [EOL] def fit ( self , X , y = None ) : [EOL] [docstring] [EOL] raise NotImplemented [EOL] [EOL] [EOL] __all__ = [ [string] ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
	0
	0
	0
	0
	0
[comment]	0
[comment]	0
[comment] [EOL] import logging [EOL] import logging [EOL] [EOL] [comment] [EOL] logging . basicConfig ( level = logging . INFO , format = [string] ) [EOL] logging . basicConfig ( level = logging . WARNING , format = [string] ) [EOL] logging . basicConfig ( level = logging . ERROR , format = [string] ) [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0
[comment]	0
[comment] [EOL] from typing import Any , List [EOL] import typing [EOL] [docstring] [EOL] import pandas as pd [EOL] from tools . mylogger import logger [EOL] [EOL] [EOL] def judge_function_v1 ( result ) : [EOL] [docstring] [EOL] [comment] [EOL] calc_res = [ ] [EOL] for model_res in result : [EOL] current_auc = model_res [ [number] ] [EOL] logger . info ( current_auc ) [EOL] var_importance = model_res [ [number] ] [EOL] var_importance [ [string] ] = var_importance [ [string] ] * current_auc [EOL] calc_res . append ( var_importance ) [EOL] return pd . concat ( calc_res ) [EOL] [EOL] [EOL] def judge_auc_mean_std ( auc_mean , auc_std ) : [EOL] [docstring] [EOL] return round ( auc_mean / auc_std , [number] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0