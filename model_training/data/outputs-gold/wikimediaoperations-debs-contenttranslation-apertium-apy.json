[comment] [EOL] [EOL] from typing import Dict , Any , Tuple [EOL] import typing [EOL] import html . parser [EOL] import json [EOL] import socket [EOL] import sys [EOL] import urllib . error [EOL] import urllib . parse [EOL] import urllib . request [EOL] [EOL] unescape = html . parser . HTMLParser ( ) . unescape [comment] [EOL] [EOL] TIMEOUT = [number] [EOL] tests = { [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , [string] : ( [string] , [string] ) , } [EOL] [EOL] [EOL] def test_pair ( pair , host ) : [EOL] intext = urllib . parse . quote_plus ( tests [ pair ] [ [number] ] . strip ( ) ) [EOL] if not intext : [EOL] print ( [string] % ( pair , ) ) [EOL] return False [EOL] expected = tests [ pair ] [ [number] ] . strip ( ) [EOL] langpair = pair . replace ( [string] , [string] ) [EOL] try : [EOL] response = urllib . request . urlopen ( [string] % ( host , langpair , intext ) , timeout = TIMEOUT ) . read ( ) . decode ( [string] ) [EOL] except urllib . error . HTTPError as e : [EOL] print ( [string] % ( pair , e . code , e . reason ) ) [EOL] return False [EOL] except socket . timeout as e : [EOL] print ( [string] % ( pair , e ) ) [EOL] return False [EOL] js = json . loads ( response ) [EOL] translation_raw = js [ [string] ] [ [string] ] [EOL] translation = unescape ( urllib . parse . unquote_plus ( translation_raw ) ) . strip ( ) [EOL] if translation != expected : [EOL] print ( [string] % ( pair , expected , translation , intext ) ) [EOL] return False [EOL] else : [EOL] return True [EOL] [EOL] [EOL] def missing_tests ( host ) : [EOL] try : [EOL] response = urllib . request . urlopen ( [string] % ( host , ) , timeout = TIMEOUT ) . read ( ) . decode ( [string] ) [EOL] except urllib . error . HTTPError as e : [EOL] print ( [string] % ( e . code , e . reason ) ) [EOL] return False [EOL] except socket . timeout as e : [EOL] print ( [string] % ( e , ) ) [EOL] return False [EOL] js = json . loads ( response ) [EOL] allgood = True [EOL] for pair in js [ [string] ] : [EOL] pairstr = [string] % ( pair [ [string] ] , pair [ [string] ] ) [EOL] if pairstr not in tests : [EOL] print ( [string] % ( pairstr , ) ) [EOL] allgood = False [EOL] return allgood [EOL] [EOL] [EOL] def dot ( ) : [EOL] sys . stdout . write ( [string] ) [EOL] sys . stdout . flush ( ) [EOL] [EOL] [EOL] def test_all ( host ) : [EOL] missing_tests ( host ) [EOL] dot ( ) [EOL] total = len ( tests ) [EOL] good = [number] [EOL] for pair in tests : [EOL] if test_pair ( pair , host ) : [EOL] good += [number] [EOL] dot ( ) [EOL] print ( [string] % ( good , total ) ) [EOL] print ( [string] ) [EOL] if good != total : [EOL] exit ( [number] ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] if len ( sys . argv ) != [number] : [EOL] print ( [string] ) [EOL] sys . exit ( [number] ) [EOL] else : [EOL] test_all ( sys . argv [ [number] ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $typing.Dict[builtins.str,typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Generator , Any , Iterator [EOL] import typing [EOL] from datetime import timedelta [EOL] [EOL] from tornado import gen [EOL] [EOL] try : [EOL] import cld2full as cld2 [comment] [EOL] except ImportError : [EOL] cld2 = None [EOL] [EOL] from apertium_apy . handlers . base import BaseHandler [EOL] from apertium_apy . utils import get_coverages , to_alpha3_code [EOL] [EOL] [EOL] class IdentifyLangHandler ( BaseHandler ) : [EOL] @ gen . coroutine def get ( self ) : [EOL] text = self . get_argument ( [string] ) [EOL] if not text : [EOL] return self . send_error ( [number] , explanation = [string] ) [EOL] [EOL] if cld2 : [EOL] cld_results = cld2 . detect ( text ) [EOL] if cld_results [ [number] ] : [EOL] possible_langs = filter ( lambda x : x [ [number] ] != [string] , cld_results [ [number] ] ) [EOL] self . send_response ( { to_alpha3_code ( possible_lang [ [number] ] ) : possible_lang [ [number] ] for possible_lang in possible_langs } ) [EOL] else : [EOL] self . send_response ( { [string] : [number] } ) [comment] [EOL] else : [EOL] try : [EOL] coverages = yield gen . with_timeout ( timedelta ( seconds = self . timeout ) , get_coverages ( text , self . analyzers , penalize = True ) , ) [EOL] self . send_response ( coverages ) [EOL] [EOL] except gen . TimeoutError : [EOL] self . send_error ( [number] , explanation = [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 $typing.Any$ 0 $None$ 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Iterator[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterator[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Generator[typing.Any,None,None]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Generator[typing.Any,None,None]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Set , Dict , Generator , Any , List [EOL] import multiprocessing [EOL] import typing [EOL] import subprocess [EOL] import re [EOL] from multiprocessing import Pool [EOL] from subprocess import Popen , PIPE [EOL] [EOL] from tornado import gen [EOL] [EOL] from apertium_apy . handlers . base import BaseHandler [EOL] from apertium_apy . utils import apertium , run_async_thread , remove_dot_from_deformat , to_alpha3_code [EOL] [EOL] [EOL] def bilingual_translate ( to_translate , mode_dir , mode ) : [EOL] p1 = Popen ( [ [string] , to_translate ] , stdout = PIPE ) [EOL] p2 = Popen ( [ [string] , [string] , mode ] , stdin = p1 . stdout , stdout = PIPE , cwd = mode_dir ) [EOL] p1 . stdout . close ( ) [EOL] output = p2 . communicate ( ) [ [number] ] . decode ( [string] ) [EOL] return output [EOL] [EOL] [EOL] def strip_tags ( analysis ) : [EOL] if [string] in analysis : [EOL] return analysis [ : analysis . index ( [string] ) ] [EOL] else : [EOL] return analysis [EOL] [EOL] [EOL] def process_per_word ( analyzers , taggers , lang , modes , query ) : [EOL] outputs = { } [EOL] morph_lexical_units = None [EOL] tagger_lexical_units = None [EOL] lexical_unit_re = [string] [EOL] [EOL] if [string] in modes or [string] in modes : [EOL] if lang in analyzers : [EOL] mode_info = analyzers [ lang ] [EOL] analysis = apertium ( query , mode_info [ [number] ] , mode_info [ [number] ] ) [EOL] morph_lexical_units = remove_dot_from_deformat ( query , re . findall ( lexical_unit_re , analysis ) ) [EOL] outputs [ [string] ] = [ lu . split ( [string] ) [ [number] : ] for lu in morph_lexical_units ] [EOL] outputs [ [string] ] = [ strip_tags ( lu . split ( [string] ) [ [number] ] ) for lu in morph_lexical_units ] [EOL] else : [EOL] return [EOL] [EOL] if [string] in modes or [string] in modes or [string] in modes : [EOL] if lang in taggers : [EOL] mode_info = taggers [ lang ] [EOL] analysis = apertium ( query , mode_info [ [number] ] , mode_info [ [number] ] ) [EOL] tagger_lexical_units = remove_dot_from_deformat ( query , re . findall ( lexical_unit_re , analysis ) ) [EOL] outputs [ [string] ] = [ lu . split ( [string] ) [ [number] : ] if [string] in lu else lu for lu in tagger_lexical_units ] [EOL] outputs [ [string] ] = [ strip_tags ( lu . split ( [string] ) [ [number] ] ) for lu in tagger_lexical_units ] [EOL] else : [EOL] return [EOL] [EOL] if [string] in modes : [EOL] if morph_lexical_units : [EOL] outputs [ [string] ] = [ ] [EOL] for lu in morph_lexical_units : [EOL] split_unit = lu . split ( [string] ) [EOL] forms = split_unit [ [number] : ] if len ( split_unit ) > [number] else split_unit [EOL] raw_translations = bilingual_translate ( [string] . join ( [ [string] % form for form in forms ] ) , mode_info [ [number] ] , lang + [string] ) [EOL] translations = re . findall ( lexical_unit_re , raw_translations ) [EOL] outputs [ [string] ] . append ( list ( map ( lambda x : [string] . join ( x . split ( [string] ) [ [number] : ] ) , translations ) ) ) [EOL] outputs [ [string] ] = outputs [ [string] ] [EOL] else : [EOL] return [EOL] [EOL] if [string] in modes : [EOL] if tagger_lexical_units : [EOL] outputs [ [string] ] = [ ] [EOL] for lu in tagger_lexical_units : [EOL] split_unit = lu . split ( [string] ) [EOL] forms = split_unit [ [number] : ] if len ( split_unit ) > [number] else split_unit [EOL] raw_translations = bilingual_translate ( [string] . join ( [ [string] % form for form in forms ] ) , mode_info [ [number] ] , lang + [string] ) [EOL] translations = re . findall ( lexical_unit_re , raw_translations ) [EOL] outputs [ [string] ] . append ( list ( map ( lambda x : [string] . join ( x . split ( [string] ) [ [number] : ] ) , translations ) ) ) [EOL] outputs [ [string] ] = outputs [ [string] ] [EOL] else : [EOL] return [EOL] [EOL] return outputs , tagger_lexical_units , morph_lexical_units [EOL] [EOL] [EOL] class PerWordHandler ( BaseHandler ) : [EOL] @ gen . coroutine def get ( self ) : [EOL] lang = to_alpha3_code ( self . get_argument ( [string] ) ) [EOL] modes = set ( self . get_argument ( [string] ) . split ( [string] ) ) [EOL] query = self . get_argument ( [string] ) [EOL] [EOL] if not modes <= { [string] , [string] , [string] , [string] , [string] } : [EOL] self . send_error ( [number] , explanation = [string] ) [EOL] return [EOL] [EOL] def handle_output ( output ) : [EOL] [docstring] [EOL] [EOL] if output is None : [EOL] self . send_error ( [number] , explanation = [string] ) [EOL] return [EOL] elif not output : [EOL] self . send_error ( [number] , explanation = [string] ) [EOL] return [EOL] else : [EOL] outputs , tagger_lexical_units , morph_lexical_units = output [EOL] [EOL] to_return = [ ] [EOL] [EOL] for ( index , lexical_unit ) in enumerate ( tagger_lexical_units if tagger_lexical_units else morph_lexical_units ) : [EOL] unit_to_return = { } [EOL] unit_to_return [ [string] ] = strip_tags ( lexical_unit . split ( [string] ) [ [number] ] ) [EOL] for mode in modes : [EOL] unit_to_return [ mode ] = outputs [ mode ] [ index ] [EOL] to_return . append ( unit_to_return ) [EOL] [EOL] if self . get_argument ( [string] , default = None ) : [EOL] requested_pos = int ( self . get_argument ( [string] ) ) - [number] [EOL] current_pos = [number] [EOL] for unit in to_return : [EOL] input = unit [ [string] ] [EOL] current_pos += len ( input . split ( [string] ) ) [EOL] if requested_pos < current_pos : [EOL] self . send_response ( unit ) [EOL] return [EOL] else : [EOL] self . send_response ( to_return ) [EOL] [EOL] pool = Pool ( processes = [number] ) [EOL] result = pool . apply_async ( process_per_word , ( self . analyzers , self . taggers , lang , modes , query ) ) [EOL] pool . close ( ) [EOL] [EOL] @ run_async_thread def worker ( callback ) : [EOL] try : [EOL] callback ( result . get ( timeout = self . timeout ) ) [EOL] except TimeoutError : [EOL] pool . terminate ( ) [EOL] callback ( None ) [EOL] [EOL] output = yield gen . Task ( worker ) [EOL] handle_output ( output ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 $typing.Any$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $multiprocessing.pool.Pool$ 0 0 0 0 0 0 0 0 $multiprocessing.pool.ApplyResult[typing.Any]$ 0 $multiprocessing.pool.Pool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Set[typing.Any]$ 0 $typing.Any$ 0 0 0 $multiprocessing.pool.Pool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Generator[typing.Any,None,None]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Generator[typing.Any,None,None]$ 0 0
from typing import Any [EOL] import typing [EOL] from tornado import gen [EOL] from tornado . escape import utf8 [EOL] [EOL] from apertium_apy . handlers . translate import TranslateHandler [EOL] [EOL] [EOL] class TranslateRawHandler ( TranslateHandler ) : [EOL] [docstring] [EOL] def send_response ( self , data ) : [EOL] translated_text = data . get ( [string] , { } ) . get ( [string] , { } ) [EOL] if translated_text == { } : [EOL] super ( ) . send_response ( data ) [EOL] else : [EOL] self . log_vmsize ( ) [EOL] translated_text = data . get ( [string] , { } ) . get ( [string] , { } ) [EOL] self . set_header ( [string] , [string] ) [EOL] self . _write_buffer . append ( utf8 ( translated_text ) ) [EOL] self . finish ( ) [EOL] [EOL] @ gen . coroutine def get ( self ) : [EOL] pair = self . get_pair_or_error ( self . get_argument ( [string] ) , len ( self . get_argument ( [string] , strip = False ) ) ) [EOL] if pair is not None : [EOL] pipeline = self . get_pipeline ( pair ) [EOL] yield self . translate_and_respond ( pair , pipeline , self . get_argument ( [string] , strip = False ) , self . get_argument ( [string] , default = [string] ) , nosplit = False , deformat = self . get_argument ( [string] , default = True ) , reformat = False ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Generator , Any [EOL] import typing [EOL] from tornado import gen [EOL] [EOL] from apertium_apy . handlers . base import BaseHandler [EOL] from apertium_apy . utils import to_alpha3_code [EOL] from apertium_apy . utils . translation import parse_mode_file , translate_pipeline [EOL] [EOL] [EOL] class PipeDebugHandler ( BaseHandler ) : [EOL] @ gen . coroutine def get ( self ) : [EOL] to_translate = self . get_argument ( [string] ) [EOL] [EOL] try : [EOL] l1 , l2 = map ( to_alpha3_code , self . get_argument ( [string] ) . split ( [string] ) ) [EOL] except ValueError : [EOL] self . send_error ( [number] , explanation = [string] ) [EOL] [EOL] mode_path = self . pairs [ [string] % ( l1 , l2 ) ] [EOL] try : [EOL] _ , commands = parse_mode_file ( mode_path ) [EOL] except Exception : [EOL] self . send_error ( [number] ) [EOL] return [EOL] [EOL] res = yield translate_pipeline ( to_translate , commands ) [EOL] if self . get_status ( ) != [number] : [EOL] self . send_error ( self . get_status ( ) ) [EOL] return [EOL] [EOL] output , pipeline = res [EOL] [EOL] self . send_response ( { [string] : { [string] : output , [string] : pipeline } , [string] : None , [string] : [number] , } ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Generator[typing.Any,None,None]$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Generator[typing.Any,None,None]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] import builtins [EOL] from typing import List , Set , Any , Tuple [EOL] import typing [EOL] import sqlite3 [EOL] import argparse [EOL] import argparse [EOL] import os [EOL] import re [EOL] import sqlite3 [EOL] import subprocess [EOL] import sys [EOL] import textwrap [EOL] [EOL] from lxml import etree [EOL] [EOL] sys . path . append ( os . path . join ( os . path . abspath ( os . path . dirname ( __file__ ) ) , [string] ) ) [EOL] from util import to_alpha2_code [comment] [EOL] [EOL] html_tools_languages = set ( map ( to_alpha2_code , { [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , } ) ) [EOL] [EOL] apertium_languages = html_tools_languages | { [string] , [string] , [string] } [comment] [EOL] [EOL] [EOL] def get_apertium_languages ( ) : [EOL] dirs = [ ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ( [string] , [string] ) , ] [EOL] for ( dir_path , dir_regex ) in dirs : [EOL] svn_data = str ( subprocess . check_output ( [string] % dir_path , stderr = subprocess . STDOUT , shell = True ) , [string] ) [EOL] for lang_codes in re . findall ( dir_regex , svn_data , re . DOTALL ) : [EOL] apertium_languages . update ( convert_iso_code ( lang_code ) [ [number] ] for lang_code in lang_codes if lang_code and not lang_code == [string] ) [EOL] [EOL] print ( [string] % ( len ( apertium_languages ) , [string] . join ( apertium_languages ) ) ) [EOL] return apertium_languages [EOL] [EOL] [EOL] def convert_iso_code ( code ) : [EOL] return ( code , to_alpha2_code ( code ) ) [EOL] [EOL] [EOL] def populate_database ( args ) : [EOL] conn = sqlite3 . connect ( args . database ) [EOL] c = conn . cursor ( ) [EOL] c . execute ( textwrap . dedent ( [string] ) ) [EOL] for locale in args . languages : [EOL] locale = convert_iso_code ( locale ) [EOL] try : [EOL] tree = etree . parse ( [string] % locale [ [number] ] ) [EOL] languages = tree . xpath ( [string] ) [EOL] scraped = set ( ) [EOL] for language in languages : [EOL] if language . text : [EOL] if not args . apertium_names or ( args . apertium_names and language . get ( [string] ) in apertium_languages ) : [EOL] c . execute ( [string] , ( None , locale [ [number] ] , language . get ( [string] ) , language . text ) ) [EOL] scraped . add ( language . get ( [string] ) ) [EOL] [EOL] print ( [string] % ( len ( scraped ) , locale [ [number] ] if locale [ [number] ] == locale [ [number] ] else [string] % locale , len ( apertium_languages ) - len ( scraped ) if args . apertium_names else [number] , [string] . join ( apertium_languages - scraped if args . apertium_names else set ( ) ) , ) ) [EOL] except ( KeyboardInterrupt , SystemExit ) : [EOL] raise [EOL] except Exception as e : [EOL] print ( [string] % ( locale [ [number] ] , e ) ) [EOL] [EOL] conn . commit ( ) [EOL] c . close ( ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( description = [string] ) [EOL] parser . add_argument ( [string] , nargs = [string] , help = [string] ) [EOL] parser . add_argument ( [string] , [string] , help = [string] , default = [string] ) [EOL] parser . add_argument ( [string] , [string] , help = [string] , action = [string] , default = False ) [EOL] parser . add_argument ( [string] , [string] , help = [string] , action = [string] , default = False ) [EOL] args = parser . parse_args ( ) [EOL] [EOL] if not ( len ( args . languages ) or args . apertium_names or args . apertium_langs ) : [EOL] parser . print_help ( ) [EOL] [EOL] if args . apertium_names or args . apertium_langs : [EOL] get_apertium_languages ( ) [EOL] [EOL] if args . apertium_langs : [EOL] args . languages = apertium_languages [EOL] [EOL] populate_database ( args ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] from typing import Pattern , Optional , Any , Match [EOL] import typing [EOL] import argparse [EOL] import argparse [EOL] import urllib . request [EOL] import re [EOL] import sys [EOL] [EOL] sil_names = [string] [EOL] tsv_format = re . compile ( [string] ) [comment] [EOL] insert_template = [string] [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( description = [string] ) [EOL] parser . add_argument ( [string] , [string] , help = [string] , default = [string] ) [EOL] args = parser . parse_args ( ) [EOL] [EOL] print ( [string] ) [EOL] [EOL] sil_tsv = urllib . request . urlopen ( sil_names ) . read ( ) . decode ( [string] ) [comment] [EOL] tsv_contents = sil_tsv . splitlines ( ) [EOL] for tsv_line in tsv_contents [ [number] : ] : [comment] [EOL] matches = tsv_format . match ( tsv_line ) [EOL] [EOL] if matches : [EOL] iso639_3 = matches . group ( [string] ) [EOL] iso639_1 = matches . group ( [string] ) [EOL] iso639 = iso639_1 or iso639_3 [EOL] [EOL] name = matches . group ( [string] ) [EOL] [EOL] if iso639 and name : [EOL] print ( insert_template % ( args . table , [string] , iso639 , name ) ) [EOL] else : [EOL] sys . stdout . write ( [string] % repr ( tsv_line ) ) [EOL] else : [EOL] sys . stdout . write ( [string] % repr ( tsv_line ) ) [EOL] [EOL] print ( [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.Pattern[builtins.str]$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.Namespace$ 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 $typing.Pattern[builtins.str]$ 0 0 0 0 0 0 0 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 $builtins.str$ 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 $builtins.str$ 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $builtins.str$ 0 0 $builtins.str$ 0 $typing.Optional[typing.Match[builtins.str]]$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 $argparse.Namespace$ 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0