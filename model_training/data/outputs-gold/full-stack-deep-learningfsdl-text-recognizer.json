from typing import Union , List , Any , Dict , Tuple [EOL] import typing [EOL] import builtins [EOL] import subprocess [EOL] [docstring] [EOL] import os [EOL] import signal [EOL] import subprocess [EOL] import sys [EOL] import json [EOL] from typing import Tuple [EOL] from ast import literal_eval [EOL] [EOL] DEFAULT_CONFIG = { [string] : [string] , [string] : { [string] : [number] } , [string] : [string] , [string] : [string] , [string] : { [string] : [number] , [string] : [number] } , } [EOL] [EOL] [EOL] def args_to_json ( default_config , preserve_args = ( [string] , [string] ) ) : [EOL] [docstring] [EOL] args = [ ] [EOL] config = default_config . copy ( ) [EOL] key , val = None , None [EOL] for arg in sys . argv [ [number] : ] : [EOL] if [string] in arg : [EOL] key , val = arg . split ( [string] ) [EOL] elif key : [EOL] val = arg [EOL] else : [EOL] key = arg [EOL] if key and val : [EOL] parsed_key = key . lstrip ( [string] ) . split ( [string] ) [EOL] if parsed_key [ [number] ] in preserve_args : [EOL] args . append ( [string] . format ( parsed_key [ [number] ] , val ) ) [EOL] else : [EOL] nested = config [EOL] for level in parsed_key [ : - [number] ] : [EOL] nested [ level ] = config . get ( level , { } ) [EOL] nested = nested [ level ] [EOL] try : [EOL] [comment] [EOL] val = literal_eval ( val ) [EOL] except ValueError : [EOL] pass [EOL] nested [ parsed_key [ - [number] ] ] = val [EOL] key , val = None , None [EOL] return config , args [EOL] [EOL] [EOL] def main ( ) : [EOL] config , args = args_to_json ( DEFAULT_CONFIG ) [EOL] env = { k : v for k , v in os . environ . items ( ) if k not in ( [string] , [string] ) } [EOL] [comment] [EOL] run = subprocess . Popen ( [ [string] , [string] , * args , json . dumps ( config ) ] , env = env , preexec_fn = os . setsid , ) [comment] [EOL] signal . signal ( signal . SIGTERM , lambda * args : run . terminate ( ) ) [EOL] run . wait ( ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Union[typing.Dict[builtins.str,builtins.float],typing.Dict[builtins.str,builtins.int],builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.dict,builtins.list]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Union[typing.Dict[builtins.str,builtins.float],typing.Dict[builtins.str,builtins.int],builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Any [EOL] import typing [EOL] import flask [EOL] import text_recognizer [EOL] [docstring] [EOL] import os [EOL] [EOL] from flask import Flask , request , jsonify [EOL] import tensorflow . keras . backend as K [EOL] [EOL] from text_recognizer . line_predictor import LinePredictor [EOL] import text_recognizer . util as util [EOL] [EOL] os . environ [ [string] ] = [string] [comment] [EOL] [EOL] app = Flask ( __name__ ) [comment] [EOL] [EOL] [EOL] @ app . route ( [string] ) def index ( ) : [EOL] [docstring] [EOL] return [string] [EOL] [EOL] [EOL] @ app . route ( [string] , methods = [ [string] , [string] ] ) def predict ( ) : [EOL] [docstring] [EOL] K . clear_session ( ) [EOL] predictor = LinePredictor ( ) [EOL] image = _load_image ( ) [EOL] pred , conf = predictor . predict ( image ) [EOL] print ( [string] . format ( conf ) ) [EOL] print ( [string] . format ( image . mean ( ) ) ) [EOL] print ( [string] . format ( pred ) ) [EOL] return jsonify ( { [string] : str ( pred ) , [string] : float ( conf ) } ) [EOL] [EOL] [EOL] def _load_image ( ) : [EOL] if request . method == [string] : [EOL] data = request . get_json ( ) [EOL] if data is None : [EOL] return [string] [EOL] return util . read_b64_image ( data [ [string] ] , grayscale = True ) [EOL] if request . method == [string] : [EOL] image_url = request . args . get ( [string] ) [EOL] if image_url is None : [EOL] return [string] [EOL] print ( [string] . format ( image_url ) ) [EOL] return util . read_image ( image_url , grayscale = True ) [EOL] raise ValueError ( [string] ) [EOL] [EOL] [EOL] def main ( ) : [EOL] [docstring] [EOL] app . run ( host = [string] , port = [number] , debug = False ) [comment] [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $flask.app.Flask$ 0 0 0 0 0 0 0 0 0 0 $flask.app.Flask$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $flask.app.Flask$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $flask.app.Flask$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Tuple , Union [EOL] import typing [EOL] import numpy [EOL] import builtins [EOL] [docstring] [EOL] from typing import Tuple , Union [EOL] [EOL] import numpy as np [EOL] [EOL] from text_recognizer . models import LineModelCtc [EOL] from text_recognizer . datasets import EmnistLinesDataset [EOL] import text_recognizer . util as util [EOL] [EOL] [EOL] class LinePredictor : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , dataset_cls = EmnistLinesDataset ) : [EOL] self . model = LineModelCtc ( dataset_cls = dataset_cls ) [EOL] self . model . load_weights ( ) [EOL] [EOL] def predict ( self , image_or_filename ) : [EOL] [docstring] [EOL] if isinstance ( image_or_filename , str ) : [EOL] image = util . read_image ( image_or_filename , grayscale = True ) [EOL] else : [EOL] image = image_or_filename [EOL] return self . model . predict_on_image ( image ) [EOL] [EOL] def evaluate ( self , dataset ) : [EOL] [docstring] [EOL] return self . model . evaluate ( dataset . x_test , dataset . y_test ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.str,builtins.float]$ 0 0 0 $typing.Union[numpy.ndarray,builtins.str]$ 0 0 0 0 0 0 0 0 $typing.Union[numpy.ndarray,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Union[numpy.ndarray,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Union[numpy.ndarray,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Any , Tuple [EOL] import typing [EOL] import tensorflow [EOL] import builtins [EOL] [docstring] [EOL] from typing import Tuple [EOL] [EOL] import tensorflow as tf [EOL] from tensorflow . keras . layers import Conv2D , Dropout , MaxPooling2D , Reshape , Lambda , Permute [EOL] from tensorflow . keras . models import Sequential [EOL] from tensorflow . keras . models import Model as KerasModel [EOL] [EOL] [EOL] def line_cnn_all_conv ( input_shape , output_shape , window_width = [number] , window_stride = [number] , ) : [EOL] image_height , image_width = input_shape [EOL] output_length , num_classes = output_shape [EOL] [comment] [EOL] [EOL] model = Sequential ( ) [EOL] model . add ( Reshape ( ( image_height , image_width , [number] ) , input_shape = input_shape ) ) [EOL] model . add ( Conv2D ( [number] , kernel_size = ( [number] , [number] ) , activation = [string] , padding = [string] ) ) [EOL] model . add ( Conv2D ( [number] , ( [number] , [number] ) , activation = [string] , padding = [string] ) ) [EOL] model . add ( MaxPooling2D ( pool_size = ( [number] , [number] ) , padding = [string] ) ) [EOL] model . add ( Dropout ( [number] ) ) [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] new_height = image_height // [number] [EOL] new_width = image_width // [number] [EOL] new_window_width = window_width // [number] [EOL] new_window_stride = window_stride // [number] [EOL] [EOL] [comment] [EOL] model . add ( Conv2D ( [number] , ( new_height , new_window_width ) , ( new_height , new_window_stride ) , activation = [string] , padding = [string] ) ) [EOL] model . add ( Dropout ( [number] ) ) [EOL] [comment] [EOL] [comment] [EOL] num_windows = new_width // new_window_stride [EOL] [EOL] model . add ( Permute ( ( [number] , [number] , [number] ) ) ) [comment] [EOL] [comment] [EOL] [EOL] final_classifier_width = num_windows // output_length [EOL] model . add ( Conv2D ( num_classes , ( final_classifier_width , [number] ) , ( final_classifier_width , [number] ) , activation = [string] , padding = [string] ) ) [EOL] [comment] [EOL] [EOL] model . add ( Lambda ( lambda x : tf . squeeze ( x , [number] ) ) ) [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] return model [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $tensorflow.keras.models.Model$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[docstring] [EOL] from . mlp import mlp [EOL] from . lenet import lenet [EOL] [EOL] [comment] [EOL] from . line_cnn_all_conv import line_cnn_all_conv [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from . line_lstm_ctc import line_lstm_ctc [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from . fcn import fcn [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[docstring] [EOL] from . emnist_dataset import EmnistDataset [EOL] [EOL] [comment] [EOL] from . emnist_lines_dataset import EmnistLinesDataset [EOL] [EOL] [comment] [EOL] [comment] [EOL] from . iam_lines_dataset import IamLinesDataset [EOL] [EOL] [comment] [EOL] [comment] [EOL] from . iam_dataset import IamDataset [EOL] from . iam_paragraphs_dataset import IamParagraphsDataset [EOL] [EOL] [comment] [EOL] [comment] [EOL] from . fsdl_handwriting_dataset import FsdlHandwritingDataset [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Dict , DefaultDict , List [EOL] import builtins [EOL] import pathlib [EOL] import text_recognizer [EOL] import numpy [EOL] import typing [EOL] [docstring] [EOL] from collections import defaultdict [EOL] from pathlib import Path [EOL] [EOL] import h5py [EOL] import numpy as np [EOL] from tensorflow . keras . utils import to_categorical [EOL] [EOL] from text_recognizer . datasets . dataset import Dataset [EOL] from text_recognizer . datasets . emnist_dataset import EmnistDataset [EOL] [EOL] [EOL] DATA_DIRNAME = Dataset . data_dirname ( ) / [string] / [string] [EOL] ESSENTIALS_FILENAME = Path ( __file__ ) . parents [ [number] ] . resolve ( ) / [string] [EOL] [EOL] [EOL] class EmnistLinesDataset ( Dataset ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , max_length = [number] , min_overlap = [number] , max_overlap = [number] , num_train = [number] , num_test = [number] , ) : [EOL] self . emnist = EmnistDataset ( ) [EOL] self . mapping = self . emnist . mapping [EOL] self . max_length = max_length [EOL] self . min_overlap = min_overlap [EOL] self . max_overlap = max_overlap [EOL] self . num_classes = len ( self . mapping ) [EOL] self . input_shape = ( self . emnist . input_shape [ [number] ] , self . emnist . input_shape [ [number] ] * self . max_length , ) [EOL] self . output_shape = ( self . max_length , self . num_classes ) [EOL] self . num_train = num_train [EOL] self . num_test = num_test [EOL] self . x_train = None [EOL] self . y_train = None [EOL] self . x_test = None [EOL] self . y_test = None [EOL] [EOL] @ property def data_filename ( self ) : [EOL] return ( DATA_DIRNAME / f" [string] { self . max_length } [string] { self . min_overlap } [string] { self . max_overlap } [string] { self . num_train } [string] { self . num_test } [string] " ) [EOL] [EOL] def load_or_generate_data ( self ) : [EOL] np . random . seed ( [number] ) [EOL] [EOL] if not self . data_filename . exists ( ) : [EOL] self . _generate_data ( [string] ) [EOL] self . _generate_data ( [string] ) [EOL] self . _load_data ( ) [EOL] [EOL] def __repr__ ( self ) : [EOL] return ( [string] f" [string] { self . max_length } [string] " f" [string] { self . min_overlap } [string] " f" [string] { self . max_overlap } [string] " f" [string] { self . num_classes } [string] " f" [string] { self . input_shape } [string] " f" [string] { self . x_train . shape } [string] { self . y_train . shape } [string] " f" [string] { self . x_test . shape } [string] { self . y_test . shape } [string] " ) [EOL] [EOL] def _load_data ( self ) : [EOL] print ( [string] ) [EOL] with h5py . File ( self . data_filename , [string] ) as f : [EOL] self . x_train = f [ [string] ] [ : ] [EOL] self . y_train = f [ [string] ] [ : ] [EOL] self . x_test = f [ [string] ] [ : ] [EOL] self . y_test = f [ [string] ] [ : ] [EOL] [EOL] def _generate_data ( self , split ) : [EOL] print ( [string] ) [EOL] [EOL] [comment] [EOL] from text_recognizer . datasets . sentence_generator import SentenceGenerator [EOL] [EOL] sentence_generator = SentenceGenerator ( self . max_length ) [EOL] [EOL] emnist = self . emnist [EOL] emnist . load_or_generate_data ( ) [EOL] if split == [string] : [EOL] samples_by_char = get_samples_by_char ( emnist . x_train , emnist . y_train_int , emnist . mapping ) [EOL] else : [EOL] samples_by_char = get_samples_by_char ( emnist . x_test , emnist . y_test_int , emnist . mapping ) [EOL] [EOL] num = self . num_train if split == [string] else self . num_test [EOL] [EOL] DATA_DIRNAME . mkdir ( parents = True , exist_ok = True ) [EOL] with h5py . File ( self . data_filename , [string] ) as f : [EOL] x , y = create_dataset_of_images ( num , samples_by_char , sentence_generator , self . min_overlap , self . max_overlap ) [EOL] y = convert_strings_to_categorical_labels ( y , emnist . inverse_mapping ) [EOL] f . create_dataset ( f" [string] { split }" , data = x , dtype = [string] , compression = [string] ) [EOL] f . create_dataset ( f" [string] { split }" , data = y , dtype = [string] , compression = [string] ) [EOL] [EOL] [EOL] def get_samples_by_char ( samples , labels , mapping ) : [EOL] samples_by_char = defaultdict ( list ) [EOL] for sample , label in zip ( samples , labels . flatten ( ) ) : [EOL] samples_by_char [ mapping [ label ] ] . append ( sample ) [EOL] return samples_by_char [EOL] [EOL] [EOL] def select_letter_samples_for_string ( string , samples_by_char ) : [EOL] zero_image = np . zeros ( ( [number] , [number] ) , np . uint8 ) [EOL] sample_image_by_char = { } [EOL] for char in string : [EOL] if char in sample_image_by_char : [EOL] continue [EOL] samples = samples_by_char [ char ] [EOL] sample = samples [ np . random . choice ( len ( samples ) ) ] if samples else zero_image [EOL] sample_image_by_char [ char ] = sample . reshape ( [number] , [number] ) [EOL] return [ sample_image_by_char [ char ] for char in string ] [EOL] [EOL] [EOL] def construct_image_from_string ( string , samples_by_char , min_overlap , max_overlap ) : [EOL] overlap = np . random . uniform ( min_overlap , max_overlap ) [EOL] sampled_images = select_letter_samples_for_string ( string , samples_by_char ) [EOL] N = len ( sampled_images ) [EOL] H , W = sampled_images [ [number] ] . shape [EOL] next_overlap_width = W - int ( overlap * W ) [EOL] concatenated_image = np . zeros ( ( H , W * N ) , np . uint8 ) [EOL] x = [number] [EOL] for image in sampled_images : [EOL] concatenated_image [ : , x : ( x + W ) ] += image [EOL] x += next_overlap_width [EOL] return np . minimum ( [number] , concatenated_image ) [EOL] [EOL] [EOL] def create_dataset_of_images ( N , samples_by_char , sentence_generator , min_overlap , max_overlap ) : [EOL] sample_label = sentence_generator . generate ( ) [EOL] sample_image = construct_image_from_string ( sample_label , samples_by_char , [number] , [number] ) [comment] [EOL] images = np . zeros ( ( N , sample_image . shape [ [number] ] , sample_image . shape [ [number] ] ) , np . uint8 , ) [EOL] labels = [ ] [EOL] for n in range ( N ) : [EOL] label = None [EOL] for _ in range ( [number] ) : [comment] [EOL] try : [EOL] label = sentence_generator . generate ( ) [EOL] break [EOL] except Exception : [comment] [EOL] pass [EOL] if label is None : [EOL] raise RuntimeError ( [string] ) [EOL] images [ n ] = construct_image_from_string ( label , samples_by_char , min_overlap , max_overlap ) [EOL] labels . append ( label ) [EOL] return images , labels [EOL] [EOL] [EOL] def convert_strings_to_categorical_labels ( labels , mapping ) : [EOL] return np . array ( [ to_categorical ( [ mapping [ c ] for c in label ] , num_classes = len ( mapping ) ) for label in labels ] ) [EOL] [EOL] [EOL] def main ( ) : [EOL] dataset = EmnistLinesDataset ( ) [EOL] dataset . load_or_generate_data ( ) [EOL] print ( dataset ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $pathlib.Path$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.float$ 0 0 0 $builtins.float$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 $builtins.float$ 0 $builtins.float$ 0 0 0 $builtins.float$ 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $builtins.int$ 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
[docstring] [EOL] from . character_model import CharacterModel [EOL] [EOL] [comment] [EOL] from . line_model import LineModel [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from . line_model_ctc import LineModelCtc [EOL] [EOL] [comment] [EOL] [EOL] [comment] [EOL] from . line_detector_model import LineDetectorModel [EOL] [EOL] [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] from typing import Any , List [EOL] import typing [EOL] import pathlib [EOL] import argparse [EOL] [docstring] [EOL] from pathlib import Path [EOL] import argparse [EOL] import os [EOL] import glob [EOL] import re [EOL] import shutil [EOL] [EOL] import yaml [EOL] [EOL] MAX_LAB_NUMBER = [number] [comment] [EOL] REPO_DIRNAME = Path ( __file__ ) . resolve ( ) . parents [ [number] ] [EOL] INFO_FILENAME = REPO_DIRNAME / [string] / [string] / [string] [EOL] SOLUTION_VERSION_LABS = True [EOL] [EOL] [EOL] def _filter_your_code_blocks ( lines , lab_number ) : [EOL] [docstring] [EOL] if lab_number == MAX_LAB_NUMBER : [EOL] lab_numbers_to_strip = str ( lab_number ) [EOL] else : [EOL] lab_numbers_to_strip = f" [string] { [string] . join ( str ( num ) for num in range ( lab_number , MAX_LAB_NUMBER ) ) } [string] " [EOL] beginning_comment = f" [string] { lab_numbers_to_strip } [string] " [EOL] ending_comment = f" [string] { lab_numbers_to_strip } [string] " [EOL] filtered_lines = [ ] [EOL] filtering = False [EOL] for line in lines : [EOL] if not filtering : [EOL] filtered_lines . append ( line ) [EOL] if re . search ( beginning_comment , line ) : [EOL] filtering = True [EOL] filtered_lines . append ( [string] ) [EOL] if re . search ( ending_comment , line ) : [EOL] filtered_lines . append ( line ) [EOL] filtering = False [EOL] return filtered_lines [EOL] [EOL] [EOL] def _filter_hidden_blocks ( lines , lab_number ) : [EOL] if lab_number == MAX_LAB_NUMBER : [EOL] return lines [EOL] if lab_number + [number] == MAX_LAB_NUMBER : [EOL] lab_numbers_to_hide = str ( MAX_LAB_NUMBER ) [EOL] else : [EOL] lab_numbers_to_hide = f" [string] { [string] . join ( str ( num ) for num in range ( lab_number + [number] , MAX_LAB_NUMBER ) ) } [string] " [EOL] beginning_comment = f" [string] { lab_numbers_to_hide }" [EOL] ending_comment = f" [string] { lab_numbers_to_hide }" [EOL] filtered_lines = [ ] [EOL] filtering = False [EOL] for line in lines : [EOL] if re . search ( beginning_comment , line ) : [EOL] filtering = True [EOL] if re . search ( ending_comment , line ) : [EOL] filtering = False [EOL] continue [EOL] if not filtering : [EOL] filtered_lines . append ( line ) [EOL] return filtered_lines [EOL] [EOL] [EOL] def _replace_data_dirname ( lines ) : [EOL] filtered_lines = [ ] [EOL] for line in lines : [EOL] if line == [string] : [EOL] line = [string] [EOL] filtered_lines . append ( line ) [EOL] return filtered_lines [EOL] [EOL] [EOL] def _copy_files_for_lab ( info , lab_number , lab_output_dir ) : [EOL] selected_paths = sum ( [ info . get ( number , [ ] ) for number in range ( lab_number + [number] ) ] , [ ] ) [EOL] new_paths = [ ] [EOL] for path in selected_paths : [EOL] new_path = lab_output_dir / path [EOL] new_path . parents [ [number] ] . mkdir ( parents = True , exist_ok = True ) [EOL] shutil . copy ( path , new_path ) [EOL] new_paths . append ( new_path ) [EOL] return new_paths [EOL] [EOL] [EOL] def _process_new_files ( new_paths , lab_number , filter_your_code = True , filter_hidden = True , replace_data_dirname = True ) : [EOL] for path in new_paths : [EOL] if path . suffix != [string] : [EOL] continue [EOL] [EOL] with open ( path ) as f : [EOL] lines = f . read ( ) . split ( [string] ) [EOL] [EOL] if filter_your_code : [EOL] lines = _filter_your_code_blocks ( lines , lab_number ) [EOL] if filter_hidden : [EOL] lines = _filter_hidden_blocks ( lines , lab_number ) [EOL] if replace_data_dirname : [EOL] lines = _replace_data_dirname ( lines ) [EOL] [EOL] with open ( path , [string] ) as f : [EOL] f . write ( [string] . join ( lines ) ) [EOL] [EOL] [EOL] def subset_repo ( info , output_dirname ) : [EOL] [docstring] [EOL] output_dir = Path ( output_dirname ) [EOL] if output_dir . exists ( ) : [EOL] for directory in glob . glob ( f"{ str ( output_dir ) } [string] " ) : [EOL] shutil . rmtree ( directory ) [EOL] if os . path . exists ( output_dir / [string] ) : [EOL] shutil . rmtree ( output_dir / [string] ) [EOL] [EOL] output_dir . mkdir ( parents = True , exist_ok = True ) [EOL] shutil . copytree ( REPO_DIRNAME / [string] , output_dir / [string] ) [EOL] [EOL] shutil . copy ( [string] , output_dir ) [EOL] shutil . copy ( [string] , output_dir ) [EOL] shutil . copy ( [string] , output_dir ) [EOL] shutil . copy ( [string] , output_dir ) [EOL] shutil . copy ( [string] , output_dir ) [EOL] shutil . copy ( [string] , output_dir ) [EOL] shutil . copy ( [string] , output_dir ) [EOL] shutil . copy ( [string] , output_dir ) [EOL] [EOL] [comment] [EOL] for lab_number in info . keys ( ) : [EOL] lab_output_dir = output_dir / f" [string] { lab_number }" [EOL] lab_output_dir . mkdir ( parents = True ) [EOL] new_paths = _copy_files_for_lab ( info , lab_number , lab_output_dir ) [EOL] _process_new_files ( new_paths , lab_number , filter_your_code = ( not SOLUTION_VERSION_LABS ) ) [EOL] shutil . copy ( f" [string] { lab_number } [string] " , output_dir / f" [string] { lab_number }" / [string] ) [EOL] [EOL] ( output_dir / [string] ) . mkdir ( exist_ok = True ) [EOL] shutil . copy ( [string] , output_dir / [string] / [string] ) [EOL] [EOL] if not SOLUTION_VERSION_LABS : [EOL] os . remove ( output_dir / [string] ) [EOL] os . remove ( output_dir / [string] ) [EOL] os . remove ( output_dir / [string] ) [EOL] os . remove ( output_dir / [string] ) [EOL] [EOL] [EOL] def main ( ) : [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] , default = [string] , help = [string] ) [EOL] args = parser . parse_args ( ) [EOL] [EOL] with open ( INFO_FILENAME ) as f : [EOL] info = yaml . full_load ( f . read ( ) ) [EOL] [EOL] subset_repo ( info , args . output_dirname ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $pathlib.Path$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pathlib.Path$ 0 $pathlib.Path$ 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pathlib.Path$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $pathlib.Path$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Tuple , List [EOL] import typing [EOL] import jinja2 [EOL] [docstring] [EOL] from jinja2 import Template [EOL] [EOL] [EOL] PARAGRAPHS = [ ( [string] , [string] , ) , ( [string] , [string] , ) , ( [string] , [string] , ) , ( [string] , [string] , ) , ( [string] , [string] , ) , ( [string] , [string] , ) , ( [string] , [string] , ) , ( [string] , [string] , ) , ( [string] , [string] , ) , ( [string] , [string] , ) , ( [string] , [string] , ) , ( [string] , [string] , ) , ( [string] , [string] , ) , ( [string] , [string] , ) , ] [EOL] [EOL] [EOL] def main ( ) : [EOL] with open ( [string] , [string] ) as f : [EOL] template = Template ( f . read ( ) ) [EOL] [EOL] for ind , paragraph in enumerate ( PARAGRAPHS ) : [EOL] with open ( f" [string] { ind } [string] " , [string] ) as f : [EOL] f . write ( template . render ( text = paragraph [ [number] ] , source = paragraph [ [number] ] ) ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] from typing import Any , List [EOL] import typing [EOL] import base64 [EOL] import glob [EOL] [EOL] import grequests [EOL] [EOL] NUM_CALLS = [number] [comment] [EOL] TIMEOUT = [number] [EOL] LOCAL_IMAGE_GLOB = [string] [EOL] ENDPOINTS_FILE = [string] [EOL] IMAGE_URLS_FILE = [string] [EOL] [EOL] [EOL] def url_for_get ( api_url , img_url ) : [EOL] [docstring] [EOL] return [string] % ( api_url . strip ( [string] ) , img_url ) [EOL] [EOL] [EOL] def data_for_post ( api_url , img_path ) : [EOL] [docstring] [EOL] with open ( img_path , [string] ) as f : [EOL] text = base64 . b64encode ( f . read ( ) ) . decode ( [string] ) [EOL] return { [string] : [string] % text } [EOL] [EOL] [EOL] def build_get_calls ( api_url , img_urls ) : [EOL] [docstring] [EOL] return [ grequests . get ( url_for_get ( api_url , img_url ) , timeout = TIMEOUT ) for img_url in img_urls ] [EOL] [EOL] [EOL] def build_post_calls ( api_url , local_images ) : [EOL] [docstring] [EOL] return [ grequests . post ( api_url , data = data_for_post ( api_url , img_path ) , timeout = TIMEOUT ) for img_path in local_images ] [EOL] [EOL] [EOL] def main ( ) : [EOL] [docstring] [EOL] with open ( ENDPOINTS_FILE ) as endpoints_file : [EOL] endpoints = [ x . strip ( ) for x in endpoints_file . readlines ( ) ] [EOL] with open ( IMAGE_URLS_FILE ) as image_urls_file : [EOL] remote_image_urls = [ x . strip ( ) for x in image_urls_file . readlines ( ) ] [EOL] local_images = glob . glob ( LOCAL_IMAGE_GLOB ) [EOL] [EOL] [comment] [EOL] stuff = [ ] [EOL] for url in endpoints : [EOL] stuff . extend ( build_get_calls ( url , remote_image_urls ) ) [EOL] stuff . extend ( build_post_calls ( url , local_images ) ) [EOL] stuff *= int ( [number] / len ( stuff ) ) [EOL] [EOL] good = [number] [EOL] total = [number] [EOL] while True : [EOL] responses = grequests . map ( stuff ) [EOL] total += len ( stuff ) [EOL] good += len ( stuff ) - responses . count ( None ) [EOL] b = [string] % ( good , total ) [EOL] print ( b , end = [string] ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 $builtins.float$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.float$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List [EOL] import typing [EOL] import sys [EOL] [EOL] with open ( [string] ) as endpoints_file : [EOL] endpoints = [ x . strip ( ) for x in endpoints_file . readlines ( ) ] [EOL] with open ( sys . argv [ [number] ] ) as image_urls_file : [EOL] remote_image_urls = [ x . strip ( ) for x in image_urls_file . readlines ( ) ] [EOL] [EOL] paths = [ ] [EOL] for endpoint in endpoints : [EOL] for rem in remote_image_urls : [EOL] s = [string] . format ( endpoint , rem ) [EOL] paths . append ( s ) [EOL] print ( s ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0