from setuptools import setup [EOL] [EOL] setup ( name = [string] , packages = [ [string] ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Set , Union , List , Any , Dict , Tuple [EOL] from collections import deque [EOL] import typing [EOL] import logging [EOL] import collections [EOL] import kglm_data [EOL] from collections import deque [EOL] import json [EOL] import logging [EOL] import os [EOL] import unittest [EOL] import sys [EOL] [EOL] from spacy . tokens import Doc , Token [EOL] [EOL] from kglm_data . annotate import Annotator [EOL] from kglm_data . util import flatten_tokens [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] [comment] [EOL] ALIAS_DB = { [string] : [ [string] ] , [string] : [ [string] , [string] ] , [string] : [ [string] ] , [string] : [ [string] ] } [EOL] [EOL] WIKI_DB = { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] } [EOL] [EOL] RELATION_DB = { [string] : [ ( [string] , { [string] : [string] , [string] : { [string] : [string] } } ) , ( [string] , { [string] : [string] , [string] : { [string] : [string] } } ) ] , [string] : [ ( [string] , { [string] : [string] , [string] : { [string] : [string] } } ) ] , [string] : [ ] } [EOL] [EOL] [EOL] class TestStandardAnnotator ( unittest . TestCase ) : [EOL] [EOL] def setUp ( self ) : [EOL] self . alias_db = ALIAS_DB [EOL] self . relation_db = RELATION_DB [EOL] self . wiki_db = WIKI_DB [EOL] self . annotator = Annotator ( alias_db = self . alias_db , relation_db = self . relation_db , wiki_db = self . wiki_db ) [EOL] [EOL] with open ( [string] , [string] ) as f : [EOL] test_line = f . readline ( ) [EOL] self . json_data = json . loads ( test_line . strip ( ) ) [EOL] tokens = flatten_tokens ( self . json_data [ [string] ] ) [EOL] doc = Doc ( self . annotator . _nlp . vocab , words = tokens ) [EOL] for _ , pipe in self . annotator . _nlp . pipeline : [EOL] doc = pipe ( doc ) [EOL] self . doc = doc [EOL] [EOL] logging . basicConfig ( level = logging . DEBUG , stream = sys . stdout ) [EOL] [EOL] def test_reset ( self ) : [EOL] [docstring] [EOL] [comment] [EOL] self . annotator . _add_aliases ( [string] ) [EOL] self . annotator . _add_relations ( [string] ) [EOL] [comment] [EOL] self . annotator . _reset ( ) [EOL] self . assertEqual ( self . annotator . _last_seen , { } ) [EOL] self . assertEqual ( self . annotator . _parents , { } ) [EOL] self . assertEqual ( len ( self . annotator . _alias_lookup . _root ) , [number] ) [EOL] [EOL] def test_add_wikilinks ( self ) : [EOL] [docstring] [EOL] self . annotator . _add_wikilinks ( self . doc , self . json_data [ [string] ] ) [EOL] self . assertEqual ( self . doc [ [number] ] . _ . id , [string] ) [EOL] self . assertEqual ( self . doc [ [number] ] . _ . id , [string] ) [EOL] [EOL] def test_add_nel ( self ) : [EOL] [docstring] [EOL] self . annotator . _add_nel ( self . doc , self . json_data [ [string] ] ) [EOL] [comment] [EOL] [comment] [EOL] self . assertEqual ( self . doc [ [number] ] . _ . id , [string] ) [EOL] self . assertEqual ( self . doc [ [number] ] . _ . id , [string] ) [EOL] [comment] [EOL] self . assertNotEqual ( self . doc [ [number] ] . _ . id , [string] ) [EOL] [comment] [EOL] self . assertEqual ( self . doc [ [number] ] . _ . id , [string] ) [EOL] self . assertEqual ( self . doc [ [number] ] . _ . id , [string] ) [EOL] [EOL] def test_add_nel_avoids_overwriting_wikilinks ( self ) : [EOL] [docstring] [EOL] self . annotator . _add_wikilinks ( self . doc , self . json_data [ [string] ] ) [EOL] self . annotator . _add_nel ( self . doc , self . json_data [ [string] ] ) [EOL] [comment] [EOL] self . assertEqual ( self . doc [ [number] ] . _ . source , [string] ) [EOL] self . assertEqual ( self . doc [ [number] ] . _ . source , [string] ) [EOL] [comment] [EOL] self . assertEqual ( self . doc [ [number] ] . _ . source , [string] ) [EOL] self . assertEqual ( self . doc [ [number] ] . _ . source , [string] ) [EOL] [EOL] def test_detect_cluster_ids ( self ) : [EOL] [docstring] [EOL] self . annotator . _add_wikilinks ( self . doc , self . json_data [ [string] ] ) [EOL] self . annotator . _add_nel ( self . doc , self . json_data [ [string] ] ) [EOL] [comment] [EOL] cluster = [ [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] ] [EOL] cluster_ids = self . annotator . _detect_cluster_ids ( self . doc , cluster ) [EOL] self . assertSetEqual ( cluster_ids , { [string] , [string] } ) [EOL] [EOL] def test_prune_cluster ( self ) : [EOL] [comment] [EOL] [comment] [EOL] cluster = [ [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] ] [EOL] alias_token_set = { [string] , [string] } [EOL] cluster = self . annotator . _prune_cluster ( self . doc , cluster , alias_token_set ) [EOL] self . assertListEqual ( cluster , [ [ [number] , [number] ] , [ [number] , [number] ] ] ) [EOL] [EOL] def test_propagate_ids ( self ) : [EOL] [docstring] [EOL] [comment] [EOL] self . annotator . _add_wikilinks ( self . doc , self . json_data [ [string] ] ) [EOL] self . annotator . _add_nel ( self . doc , self . json_data [ [string] ] ) [EOL] self . annotator . _propagate_ids ( self . doc , self . json_data [ [string] ] ) [EOL] self . assertEqual ( self . doc [ [number] ] . _ . id , [string] ) [EOL] [EOL] def test_dont_propagate_ids ( self ) : [EOL] [comment] [EOL] bad_clusters = [ [ [ [number] , [number] ] , [ [number] , [number] ] , [ [number] , [number] ] ] ] [EOL] self . annotator . _add_wikilinks ( self . doc , self . json_data [ [string] ] ) [EOL] self . annotator . _add_nel ( self . doc , self . json_data [ [string] ] ) [EOL] self . annotator . _propagate_ids ( self . doc , bad_clusters ) [EOL] self . assertIsNone ( self . doc [ [number] ] . _ . id ) [EOL] [EOL] def test_json_to_doc ( self ) : [EOL] [docstring] [EOL] doc = self . annotator . _json_to_doc ( self . json_data , root_id = [string] ) [EOL] self . assertEqual ( doc [ [number] ] . _ . id , [string] ) [EOL] self . assertEqual ( doc [ [number] ] . _ . source , [string] ) [EOL] self . assertEqual ( doc [ [number] ] . _ . id , [string] ) [EOL] self . assertEqual ( doc [ [number] ] . _ . source , [string] ) [EOL] self . assertEqual ( doc [ [number] ] . _ . id , [string] ) [EOL] self . assertEqual ( doc [ [number] ] . _ . source , [string] ) [EOL] [EOL] def test_add_aliases ( self ) : [EOL] [docstring] [EOL] self . annotator . _add_aliases ( [string] ) [EOL] good_alias_0 = [ x . text for x in self . annotator . _nlp . tokenizer ( [string] ) ] [EOL] self . assertIn ( good_alias_0 , self . annotator . _alias_lookup ) [EOL] good_alias_1 = [ x . text for x in self . annotator . _nlp . tokenizer ( [string] ) ] [EOL] self . assertIn ( good_alias_1 , self . annotator . _alias_lookup ) [EOL] [EOL] def test_add_relations ( self ) : [EOL] [docstring] [EOL] self . annotator . _add_relations ( [string] ) [EOL] self . assertIn ( [string] , self . annotator . _parents ) [EOL] [EOL] def test_expand ( self ) : [EOL] [docstring] [EOL] loc = [number] [EOL] self . annotator . _expand ( [string] , loc ) [EOL] self . assertIn ( [string] , self . annotator . _last_seen ) [EOL] self . assertEqual ( self . annotator . _last_seen [ [string] ] , loc ) [EOL] self . assertIn ( [string] , self . annotator . _parents ) [EOL] [EOL] def test_existing_id ( self ) : [EOL] [docstring] [EOL] doc = self . annotator . _json_to_doc ( self . json_data , root_id = [string] ) [EOL] token_stack = deque ( reversed ( doc ) ) [EOL] start_length = len ( token_stack ) [EOL] active = token_stack . pop ( ) [EOL] match_stack = self . annotator . _existing_id ( active , token_stack ) [EOL] expected = deque ( ( ( doc [ [number] ] , [string] ) , ( doc [ [number] ] , [string] ) ) ) [EOL] self . assertEqual ( match_stack , expected ) [EOL] self . assertEqual ( len ( token_stack ) , start_length - [number] ) [EOL] [EOL] def test_unknown_id_no_match ( self ) : [EOL] [docstring] [EOL] doc = self . annotator . _json_to_doc ( self . json_data , root_id = [string] ) [EOL] token_stack = deque ( reversed ( doc ) ) [EOL] token_stack . pop ( ) [comment] [EOL] token_stack . pop ( ) [comment] [EOL] [comment] [EOL] start_length = len ( token_stack ) [EOL] active = token_stack . pop ( ) [EOL] match_stack = self . annotator . _unknown_id ( active , token_stack ) [EOL] expected = deque ( ( ( doc [ [number] ] , None ) , ) ) [EOL] self . assertEqual ( match_stack , expected ) [EOL] self . assertEqual ( len ( token_stack ) , start_length - [number] ) [EOL] [EOL] def test_unknown_id_alias_match ( self ) : [EOL] [comment] [EOL] self . annotator . _add_aliases ( [string] ) [EOL] self . annotator . _add_aliases ( [string] ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] tokens = [ [string] , [string] , [string] , [string] ] [EOL] doc = Doc ( self . annotator . _nlp . vocab , words = tokens ) [EOL] token_stack = deque ( reversed ( doc ) ) [EOL] active = token_stack . pop ( ) [EOL] match_stack = self . annotator . _unknown_id ( active , token_stack ) [EOL] expected = deque ( ( ( doc [ [number] ] , None ) , ( doc [ [number] ] , [string] ) , ( doc [ [number] ] , None ) , ( doc [ [number] ] , [string] ) ) ) [EOL] self . assertEqual ( match_stack , expected ) [EOL] self . assertEqual ( len ( token_stack ) , [number] ) [EOL] [EOL] def test_annotate_tokens ( self ) : [EOL] doc = self . annotator . _json_to_doc ( self . json_data , root_id = [string] ) [EOL] self . annotator . _annotate_tokens ( doc ) [EOL] self . assertEqual ( doc [ [number] ] . _ . id , [string] ) [EOL] self . assertEqual ( doc [ [number] ] . _ . source , [string] ) [EOL] self . assertEqual ( doc [ [number] ] . _ . parent_id , [ [string] ] ) [EOL] self . assertEqual ( doc [ [number] ] . _ . relation , [ [string] ] ) [EOL] self . assertEqual ( doc [ [number] ] . _ . id , [string] ) [EOL] self . assertEqual ( doc [ [number] ] . _ . source , [string] ) [EOL] self . assertEqual ( doc [ [number] ] . _ . parent_id , [ [string] ] ) [EOL] self . assertEqual ( doc [ [number] ] . _ . relation , [ [string] ] ) [EOL] self . assertEqual ( doc [ [number] ] . _ . id , [string] ) [EOL] self . assertEqual ( doc [ [number] ] . _ . source , [string] ) [EOL] self . assertEqual ( doc [ [number] ] . _ . parent_id , [ [string] ] ) [EOL] self . assertEqual ( doc [ [number] ] . _ . relation , [ [string] ] ) [EOL] [EOL] def test_serialize_annotations ( self ) : [EOL] doc = self . annotator . _json_to_doc ( self . json_data , root_id = [string] ) [EOL] self . annotator . _annotate_tokens ( doc ) [EOL] annotations = self . annotator . _serialize_annotations ( doc ) [EOL] expected = [ { [string] : [string] , [string] : [string] , [string] : [ [string] ] , [string] : [ [string] ] , [string] : [ [number] , [number] ] } , { [string] : [string] , [string] : [string] , [string] : [ [string] ] , [string] : [ [string] ] , [string] : [ [number] , [number] ] } , { [string] : [string] , [string] : [string] , [string] : [ [string] ] , [string] : [ [string] ] , [string] : [ [number] , [number] ] } ] [EOL] self . assertEqual ( annotations , expected ) [EOL] [EOL] def test_add_wikilinks_match_aliases ( self ) : [EOL] [docstring] [EOL] [comment] [EOL] annotator = Annotator ( alias_db = self . alias_db , relation_db = self . relation_db , wiki_db = self . wiki_db , match_aliases = True ) [EOL] tokens = flatten_tokens ( self . json_data [ [string] ] ) [EOL] doc = Doc ( annotator . _nlp . vocab , words = tokens ) [EOL] [EOL] [comment] [EOL] annotator . _add_wikilinks ( doc , self . json_data [ [string] ] ) [EOL] self . assertIn ( [ [string] , [string] ] , annotator . _alias_lookup ) [EOL] [EOL] def test_add_nel_unmatch ( self ) : [EOL] [comment] [EOL] annotator = Annotator ( alias_db = self . alias_db , relation_db = self . relation_db , wiki_db = self . wiki_db , unmatch = True ) [EOL] tokens = flatten_tokens ( self . json_data [ [string] ] ) [EOL] doc = Doc ( annotator . _nlp . vocab , words = tokens ) [EOL] wiki_ids = { [string] } [EOL] [EOL] [comment] [EOL] annotator . _add_nel ( doc , self . json_data [ [string] ] , wiki_ids ) [EOL] [comment] [EOL] self . assertNotEqual ( doc [ [number] ] . _ . id , [string] ) [EOL] self . assertNotEqual ( doc [ [number] ] . _ . id , [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.List[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Union[typing.List[typing.Any],typing.List[typing.Tuple[builtins.str,typing.Dict[builtins.str,typing.Union[typing.Dict[builtins.str,builtins.str],builtins.str]]]]]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.List[builtins.str]]$ 0 0 0 0 0 $typing.Dict[builtins.str,typing.Union[typing.List[typing.Any],typing.List[typing.Tuple[builtins.str,typing.Dict[builtins.str,typing.Union[typing.Dict[builtins.str,builtins.str],builtins.str]]]]]]$ 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 $kglm_data.annotate.Annotator$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $kglm_data.annotate.Annotator$ 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 $kglm_data.annotate.Annotator$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.List[builtins.int]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Set[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.List[builtins.int]]$ 0 0 0 0 0 0 $typing.Set[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.List[builtins.int]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Set[builtins.str]$ 0 0 0 0 0 0 0 $typing.List[typing.List[builtins.int]]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.List[builtins.int]]$ 0 $typing.Set[builtins.str]$ 0 0 0 0 0 0 $typing.List[typing.List[builtins.int]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.List[typing.List[builtins.int]]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.List[typing.List[builtins.int]]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.list$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.list$ 0 0 0 0 0 0 0 0 $typing.list$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.list$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $collections.deque[typing.Any]$ 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $collections.deque[typing.Any]$ 0 0 $typing.Any$ 0 $collections.deque[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $collections.deque[typing.Any]$ 0 0 $collections.deque[typing.Tuple[typing.Any,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $collections.deque[typing.Tuple[typing.Any,builtins.str]]$ 0 0 0 0 0 0 0 0 $collections.deque[typing.Any]$ 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $collections.deque[typing.Any]$ 0 0 0 0 0 0 0 0 0 $collections.deque[typing.Any]$ 0 0 0 0 0 0 $collections.deque[typing.Any]$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $collections.deque[typing.Any]$ 0 0 $typing.Any$ 0 $collections.deque[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $collections.deque[typing.Any]$ 0 0 $collections.deque[typing.Tuple[typing.Any,None]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $collections.deque[typing.Tuple[typing.Any,None]]$ 0 0 0 0 0 0 0 0 $collections.deque[typing.Any]$ 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 $collections.deque[typing.Any]$ 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 $collections.deque[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $collections.deque[typing.Any]$ 0 0 $collections.deque[typing.Union[typing.Tuple[typing.Any,None],typing.Tuple[typing.Any,builtins.str]]]$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $collections.deque[typing.Union[typing.Tuple[typing.Any,None],typing.Tuple[typing.Any,builtins.str]]]$ 0 0 0 0 0 0 0 0 $collections.deque[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Dict[builtins.str,typing.Union[typing.List[builtins.int],typing.List[builtins.str],builtins.str]]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Dict[builtins.str,typing.Union[typing.List[builtins.int],typing.List[builtins.str],builtins.str]]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $kglm_data.annotate.Annotator$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $kglm_data.annotate.Annotator$ 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 $kglm_data.annotate.Annotator$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $kglm_data.annotate.Annotator$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $kglm_data.annotate.Annotator$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $kglm_data.annotate.Annotator$ 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 $typing.Set[builtins.str]$ 0 0 0 0 0 0 0 0 $kglm_data.annotate.Annotator$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Set[builtins.str]$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Set , Union , List , Any , Tuple [EOL] import typing [EOL] import logging [EOL] import logging [EOL] import unittest [EOL] [EOL] from kglm_data . realm_coref import _window , _add_offset , _merge_clusters [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class TestRealmCorefFcts ( unittest . TestCase ) : [EOL] def test_window ( self ) : [EOL] x = [ [number] , [number] , [number] , [number] ] [EOL] actual = list ( _window ( x , size = [number] ) ) [EOL] expected = [ [ [number] , [number] , [number] ] , [ [number] , [number] , [number] ] ] [EOL] self . assertListEqual ( actual , expected ) [EOL] [EOL] def test_add_offset ( self ) : [EOL] x = [ [ [number] , [number] ] , [ [number] , [ [number] ] ] ] [EOL] offset = [number] [EOL] actual = _add_offset ( x , offset ) [EOL] expected = [ [ [number] , [number] ] , [ [number] , [ [number] ] ] ] [EOL] self . assertListEqual ( actual , expected ) [EOL] [EOL] def test_merge_clusters ( self ) : [EOL] clusters_a = [ [ [ [number] , [number] ] , [ [number] , [number] ] ] , [ [ [number] , [number] ] ] ] [EOL] clusters_b = [ [ [ [number] , [number] ] , [ [number] , [number] ] ] , [ [ [number] , [number] ] , [ [number] , [number] ] ] ] [EOL] all_clusters = [ clusters_a , clusters_b ] [EOL] actual = _merge_clusters ( all_clusters ) [EOL] expected = [ ( ( [number] , [number] ) , ( [number] , [number] ) , ( [number] , [number] ) ) , ( ( [number] , [number] ) , ( [number] , [number] ) ) ] [EOL] [comment] [EOL] [comment] [EOL] actual_sets = [ set ( x ) for x in actual ] [EOL] expected_sets = [ set ( x ) for x in expected ] [EOL] failed = False [EOL] for cluster in actual_sets : [EOL] match = False [EOL] for expected_cluster in expected_sets : [EOL] if cluster == expected_cluster : [EOL] match = True [EOL] self . assertTrue ( match ) [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 0 $typing.List[typing.List[builtins.int]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 $typing.List[typing.List[builtins.int]]$ 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Union[typing.List[builtins.int],typing.List[typing.Union[typing.List[builtins.int],builtins.int]]]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $typing.Any$ 0 0 0 $typing.List[typing.Union[typing.List[builtins.int],typing.List[typing.Union[typing.List[builtins.int],builtins.int]]]]$ 0 $builtins.int$ 0 0 $typing.List[typing.Union[typing.List[builtins.int],typing.List[typing.Union[typing.List[builtins.int],builtins.int]]]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.List[typing.Union[typing.List[builtins.int],typing.List[typing.Union[typing.List[builtins.int],builtins.int]]]]$ 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.List[typing.List[builtins.int]]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.List[typing.List[builtins.int]]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.List[typing.List[typing.List[builtins.int]]]]$ 0 0 $typing.List[typing.List[typing.List[builtins.int]]]$ 0 $typing.List[typing.List[typing.List[builtins.int]]]$ 0 0 $typing.Any$ 0 0 0 $typing.List[typing.List[typing.List[typing.List[builtins.int]]]]$ 0 0 $typing.List[typing.Union[typing.Tuple[typing.Tuple[builtins.int,builtins.int],typing.Tuple[builtins.int,builtins.int]],typing.Tuple[typing.Tuple[builtins.int,builtins.int],typing.Tuple[builtins.int,builtins.int],typing.Tuple[builtins.int,builtins.int]]]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Set[typing.Any]]$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.List[typing.Set[typing.Tuple[builtins.int,builtins.int]]]$ 0 0 0 0 0 0 0 0 0 $typing.List[typing.Union[typing.Tuple[typing.Tuple[builtins.int,builtins.int],typing.Tuple[builtins.int,builtins.int]],typing.Tuple[typing.Tuple[builtins.int,builtins.int],typing.Tuple[builtins.int,builtins.int],typing.Tuple[builtins.int,builtins.int]]]]$ 0 0 $builtins.str$ 0 0 0 0 0 0 $typing.List[typing.Set[typing.Any]]$ 0 0 $builtins.str$ 0 0 0 0 0 0 $typing.List[typing.Set[typing.Tuple[builtins.int,builtins.int]]]$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0
from typing import List [EOL] import typing [EOL] import logging [EOL] import kglm_data [EOL] import logging [EOL] import unittest [EOL] [EOL] from kglm_data . prefix_tree import PrefixTree , TreeNode [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class TestTreeNode ( unittest . TestCase ) : [EOL] def test_is_dict ( self ) : [EOL] node = TreeNode ( ) [EOL] node [ [string] ] = [string] [EOL] self . assertEqual ( node [ [string] ] , [string] ) [EOL] [EOL] def test_id ( self ) : [EOL] node = TreeNode ( [string] ) [EOL] self . assertEqual ( node . id , [string] ) [EOL] [EOL] def test_is_terminal ( self ) : [EOL] node_a = TreeNode ( ) [EOL] self . assertFalse ( node_a . is_terminal ) [EOL] node_b = TreeNode ( [string] ) [EOL] self . assertTrue ( node_b . is_terminal ) [EOL] [EOL] [EOL] class TestPrefixTree ( unittest . TestCase ) : [EOL] def test_add ( self ) : [EOL] tree = PrefixTree ( ) [EOL] seq = [ [string] , [string] , [string] ] [EOL] id = [string] [EOL] tree . add ( seq , id ) [EOL] assert seq in tree [EOL] for elt in seq : [EOL] out = tree . step ( elt ) [EOL] self . assertEqual ( out , id ) [EOL] [EOL] def test_terminal ( self ) : [EOL] tree = PrefixTree ( ) [EOL] seq = [ [string] , [string] , [string] ] [EOL] id = [string] [EOL] tree . add ( seq , id ) [EOL] with self . assertRaises ( IndexError ) as context : [EOL] tree . step ( [string] ) [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $kglm_data.prefix_tree.TreeNode$ 0 0 0 0 0 $kglm_data.prefix_tree.TreeNode$ 0 0 0 0 0 0 0 0 0 0 $kglm_data.prefix_tree.TreeNode$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $kglm_data.prefix_tree.TreeNode$ 0 0 0 0 0 0 0 0 0 0 $kglm_data.prefix_tree.TreeNode$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $kglm_data.prefix_tree.TreeNode$ 0 0 0 0 0 0 0 0 0 $kglm_data.prefix_tree.TreeNode$ 0 0 0 0 $kglm_data.prefix_tree.TreeNode$ 0 0 0 0 0 0 0 0 0 0 $kglm_data.prefix_tree.TreeNode$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $kglm_data.prefix_tree.PrefixTree$ 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $kglm_data.prefix_tree.PrefixTree$ 0 0 0 $typing.List[builtins.str]$ 0 $builtins.str$ 0 0 0 $typing.List[builtins.str]$ 0 $kglm_data.prefix_tree.PrefixTree$ 0 0 0 0 $typing.List[builtins.str]$ 0 0 $builtins.str$ 0 $kglm_data.prefix_tree.PrefixTree$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $kglm_data.prefix_tree.PrefixTree$ 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $kglm_data.prefix_tree.PrefixTree$ 0 0 0 $typing.List[builtins.str]$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $kglm_data.prefix_tree.PrefixTree$ 0 0 0 0 0 0 0
from typing import Set , Any [EOL] import typing [EOL] import argparse [EOL] [docstring] [EOL] import argparse [EOL] import json [EOL] [EOL] def main ( _ ) : [EOL] entities = set ( ) [EOL] with open ( FLAGS . input , [string] ) as f : [EOL] for line in f : [EOL] data = json . loads ( line ) [EOL] for entity , * _ in data [ [string] ] : [EOL] entities . add ( entity ) [EOL] for entity in entities : [EOL] print ( entity ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] , type = str ) [EOL] FLAGS , _ = parser . parse_known_args ( ) [EOL] [EOL] main ( _ ) [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Set , List , Any , Dict , Tuple [EOL] import threading [EOL] import builtins [EOL] import requests [EOL] import kglm_data [EOL] import logging [EOL] import argparse [EOL] import typing [EOL] import queue [EOL] [docstring] [EOL] from typing import Any , Dict , List [EOL] [EOL] import argparse [EOL] from itertools import accumulate [EOL] import json [EOL] import logging [EOL] from queue import Queue [EOL] from threading import Thread [EOL] [EOL] import requests [EOL] from simplejson . errors import JSONDecodeError [EOL] from tqdm import tqdm [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def _window ( l , size = [number] ) : [EOL] n = len ( l ) [EOL] for i in range ( n - size + [number] ) : [EOL] yield l [ i : i + size ] [EOL] [EOL] [EOL] def _add_offset ( x , offset ) : [EOL] if isinstance ( x , int ) : [EOL] return x + offset [EOL] elif isinstance ( x , list ) : [EOL] updated = [ ] [EOL] for element in x : [EOL] updated . append ( _add_offset ( element , offset ) ) [EOL] return updated [EOL] else : [EOL] raise TypeError ( [string] [string] ) [EOL] [EOL] [EOL] def _tuplify_set ( x ) : [EOL] if not isinstance ( x , set ) : [EOL] return x [EOL] else : [EOL] return tuple ( _tuplify_set ( elt ) for elt in x ) [EOL] [EOL] [EOL] def _min_span ( cluster ) : [EOL] return min ( x [ [number] ] for x in cluster ) [EOL] [EOL] def _merge_clusters ( all_clusters ) : [EOL] mapping = dict ( ) [EOL] for clusters in all_clusters : [EOL] for cluster in clusters : [EOL] cluster = set ( tuple ( x ) for x in cluster ) [EOL] [comment] [EOL] for span in cluster . copy ( ) : [EOL] if span in mapping : [EOL] cluster . update ( mapping [ span ] ) [EOL] [comment] [EOL] for span in cluster : [EOL] mapping [ span ] = cluster [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] unique_clusters = list ( set ( _tuplify_set ( x ) for x in mapping . values ( ) ) ) [EOL] unique_clusters = sorted ( unique_clusters , key = _min_span ) [EOL] return list ( unique_clusters ) [EOL] [EOL] [EOL] class CoreNLPCorefPredictor : [EOL] def __init__ ( self , address = [string] , n_threads = [number] ) : [EOL] self . _address = address [EOL] self . _params = { [string] : [string] [string] } [EOL] self . _headers = { [string] : [string] } [EOL] self . _n_threads = n_threads [EOL] [EOL] def predict_json ( self , inputs ) : [EOL] queue = Queue ( ) [EOL] offset = [number] [EOL] logger . debug ( [string] ) [EOL] for token_window in _window ( inputs [ [string] ] ) : [EOL] logger . debug ( [string] , offset , token_window ) [EOL] queue . put ( ( token_window , offset ) ) [EOL] offset += len ( token_window [ [number] ] ) [EOL] [EOL] logger . debug ( [string] ) [EOL] threads = [ ] [EOL] clusters = [ ] [EOL] for _ in range ( self . _n_threads ) : [EOL] thread = Thread ( target = self . predict_instance , args = ( queue , clusters ) ) [EOL] threads . append ( thread ) [EOL] for thread in threads : [EOL] thread . start ( ) [EOL] [EOL] for thread in threads : [EOL] thread . join ( ) [EOL] logger . debug ( [string] ) [EOL] [EOL] inputs [ [string] ] = _merge_clusters ( clusters ) [EOL] [EOL] return inputs [EOL] [EOL] def predict_instance ( self , queue , clusters ) : [EOL] [docstring] [EOL] while True : [EOL] [EOL] if queue . empty ( ) : [EOL] break [EOL] [EOL] tokens , offset = queue . get ( ) [EOL] data = [string] . join ( [string] . join ( x ) for x in tokens ) [EOL] [EOL] logger . debug ( [string] , data ) [EOL] response = requests . post ( self . _address , data = data . encode ( [string] ) , params = self . _params , headers = self . _headers ) [EOL] [EOL] logger . debug ( [string] , response . url ) [EOL] [EOL] try : [EOL] response_json = response . json ( ) [EOL] except JSONDecodeError : [EOL] logger . warning ( [string] , data ) [EOL] continue [EOL] [EOL] coref = response_json [ [string] ] [EOL] instance_clusters = [ ] [EOL] sent_starts = [ [number] , * list ( accumulate ( len ( x ) for x in tokens ) ) [ : - [number] ] ] [EOL] for cluster in coref . values ( ) : [EOL] spans = [ ] [EOL] for x in cluster : [EOL] start = x [ [string] ] + sent_starts [ x [ [string] ] - [number] ] - [number] [EOL] end = x [ [string] ] + sent_starts [ x [ [string] ] - [number] ] - [number] [EOL] spans . append ( [ start , end ] ) [EOL] instance_clusters . append ( spans ) [EOL] [EOL] instance_clusters = _add_offset ( instance_clusters , offset ) [EOL] logger . debug ( [string] , instance_clusters ) [EOL] clusters . append ( instance_clusters ) [EOL] [EOL] [EOL] def main ( _ ) : [EOL] logger . info ( [string] , FLAGS . n_threads ) [EOL] coref_predictor = CoreNLPCorefPredictor ( n_threads = FLAGS . n_threads ) [EOL] with open ( FLAGS . input , [string] ) as f : [EOL] for line in tqdm ( f ) : [EOL] data = json . loads ( line ) [EOL] try : [EOL] out = coref_predictor . predict_json ( data ) [EOL] except Exception as e : [EOL] logger . warning ( [string] , e , data ) [EOL] else : [EOL] print ( json . dumps ( out ) ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] , type = str ) [EOL] parser . add_argument ( [string] , type = int , default = [number] ) [EOL] parser . add_argument ( [string] , action = [string] ) [EOL] FLAGS , _ = parser . parse_known_args ( ) [EOL] [EOL] if FLAGS . debug : [EOL] level = logging . DEBUG [EOL] else : [EOL] level = logging . INFO [EOL] logging . basicConfig ( level = level ) [EOL] [EOL] main ( _ ) [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 $requests.models.Response$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $requests.models.Response$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 $requests.models.Response$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.List[builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 $typing.List[typing.Any]$ 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] from typing import Set , List , Deque , Pattern , Any , Dict , Tuple [EOL] from collections import deque [EOL] import builtins [EOL] import collections [EOL] import kglm_data [EOL] import logging [EOL] import sqlitedict [EOL] import multiprocessing [EOL] import argparse [EOL] import typing [EOL] import io [EOL] import spacy [EOL] [docstring] [EOL] from typing import Any , Deque , Dict , List , Set , Tuple [EOL] import argparse [EOL] from collections import defaultdict , deque [EOL] import json [EOL] import logging [EOL] from multiprocessing import JoinableQueue , Lock , Process [EOL] import pickle [EOL] import re [EOL] [EOL] import spacy [EOL] from spacy . lang . en . stop_words import STOP_WORDS [EOL] from spacy . tokens import Doc , Token [EOL] from sqlitedict import SqliteDict [EOL] [EOL] from kglm_data . prefix_tree import PrefixTree [EOL] from kglm_data . render import process_literal [EOL] from kglm_data . util import format_wikilink , flatten_tokens , LOG_FORMAT [EOL] [EOL] logger = logging . getLogger ( __name__ ) [comment] [EOL] [EOL] [EOL] [comment] [EOL] PRONOUNS = set ( [ [string] , [string] , [string] , [string] ] ) [EOL] NEL_SCORE_CUTOFF = [number] [EOL] RE_ENTITY = re . compile ( [string] ) [EOL] [EOL] [EOL] [comment] [EOL] Doc . set_extension ( [string] , default = [ ] ) [EOL] Token . set_extension ( [string] , default = None ) [EOL] Token . set_extension ( [string] , default = None ) [EOL] Token . set_extension ( [string] , default = None ) [EOL] Token . set_extension ( [string] , default = None ) [EOL] [EOL] [EOL] def _extract_annotation ( token ) : [EOL] [docstring] [EOL] if token . _ . id is not None : [EOL] annotation = { [string] : token . _ . source , [string] : token . _ . id , [string] : token . _ . relation , [string] : token . _ . parent_id } [EOL] return annotation [EOL] return None [EOL] [EOL] [EOL] def capitalize ( tokens ) : [EOL] if len ( tokens ) > [number] : [EOL] return ( tokens [ [number] ] . capitalize ( ) , * tokens [ [number] : ] ) [EOL] else : [EOL] return ( tokens [ [number] ] . capitalize ( ) , ) [EOL] [EOL] [EOL] def _bad_alias ( tokens ) : [EOL] if all ( x . tag_ in PRONOUNS for x in tokens ) : [EOL] return True [EOL] if all ( x . pos_ == [string] for x in tokens ) : [EOL] return True [EOL] if all ( x . text in STOP_WORDS for x in tokens ) : [EOL] return True [EOL] if all ( x . text . lower ( ) in STOP_WORDS for x in tokens ) : [EOL] return True [EOL] return False [EOL] [EOL] class Annotator : [EOL] [docstring] [EOL] [comment] [EOL] [comment] [EOL] def __init__ ( self , alias_db , relation_db , wiki_db , distance_cutoff = float ( [string] ) , match_aliases = False , unmatch = False , prune_clusters = False ) : [EOL] [EOL] [comment] [EOL] self . _alias_db = alias_db [EOL] self . _relation_db = relation_db [EOL] self . _wiki_db = wiki_db [EOL] [EOL] [comment] [EOL] self . _distance_cutoff = distance_cutoff [EOL] self . _match_aliases = match_aliases [EOL] self . _unmatch = unmatch [EOL] self . _prune_clusters = prune_clusters [EOL] [EOL] [comment] [EOL] self . _nlp = spacy . load ( [string] , disable = [ [string] , [string] ] ) [EOL] [EOL] [comment] [EOL] self . _reset ( ) [EOL] [EOL] def _reset ( self ) : [EOL] [docstring] [EOL] self . _last_seen = dict ( ) [comment] [EOL] self . _parents = defaultdict ( set ) [comment] [EOL] self . _alias_lookup = PrefixTree ( ) [comment] [EOL] [EOL] def _add_wikilinks ( self , doc , wikilinks ) : [EOL] [docstring] [EOL] wiki_ids = set ( ) [EOL] for id , start , end in wikilinks : [EOL] wiki_ids . add ( id ) [EOL] if self . _match_aliases : [EOL] self . _add_aliases ( id ) [EOL] for token in doc [ start : end ] : [EOL] token . _ . id = id [EOL] token . _ . source = [string] [EOL] return wiki_ids [EOL] [EOL] def _add_nel ( self , doc , nel , wiki_ids = None ) : [EOL] [docstring] [EOL] for candidate in nel : [EOL] logger . debug ( [string] , candidate ) [EOL] [EOL] if candidate [ [string] ] < NEL_SCORE_CUTOFF : [EOL] logger . debug ( [string] ) [EOL] continue [EOL] [EOL] start = candidate [ [string] ] [EOL] end = candidate [ [string] ] [EOL] [EOL] already_linked = False [EOL] for token in doc [ start : end ] : [EOL] if token . _ . id is not None : [EOL] already_linked = True [EOL] if already_linked : [EOL] logger . debug ( [string] ) [EOL] continue [EOL] [EOL] key = format_wikilink ( candidate [ [string] ] ) [EOL] logger . debug ( [string] , key ) [EOL] try : [EOL] id = self . _wiki_db [ key ] [EOL] except KeyError : [EOL] logger . debug ( [string] ) [EOL] continue [EOL] [EOL] matches = id in wiki_ids if self . _unmatch else True [EOL] if matches : [EOL] for token in doc [ start : end ] : [EOL] logger . debug ( [string] , token , id ) [EOL] token . _ . id = id [EOL] token . _ . source = [string] [EOL] [EOL] @ staticmethod def _detect_cluster_ids ( doc , cluster ) : [EOL] [docstring] [EOL] cluster_ids = set ( ) [EOL] for start , end in cluster : [EOL] mention_ids = [ token . _ . id for token in doc [ start : end + [number] ] if token . _ . id ] [EOL] cluster_ids . update ( mention_ids ) [EOL] return cluster_ids [EOL] [EOL] @ staticmethod def _prune_cluster ( doc , cluster , alias_token_set ) : [EOL] logger . debug ( [string] ) [EOL] [EOL] [comment] [EOL] new_cluster = [ ] [EOL] for start , end in cluster : [EOL] mention = doc [ start : end + [number] ] [EOL] [EOL] [comment] [EOL] if start == end : [EOL] if mention [ [number] ] . tag_ in PRONOUNS : [EOL] new_cluster . append ( [ start , end ] ) [EOL] logger . debug ( [string] , mention ) [EOL] continue [EOL] [EOL] [comment] [EOL] mention_tokens = tuple ( t . text for t in mention ) [EOL] mention_types = tuple ( x . tag_ for x in mention ) [EOL] keep = True [EOL] for token , type in zip ( mention_tokens , mention_types ) : [EOL] not_in_alias = token not in alias_token_set [EOL] not_det = type != [string] [EOL] if not_in_alias and not_det : [EOL] logger . debug ( [string] , token ) [EOL] keep = False [EOL] break [EOL] if keep : [EOL] new_cluster . append ( [ start , end ] ) [EOL] [EOL] return new_cluster [EOL] [EOL] def _propagate_ids ( self , doc , clusters , wiki_ids = None ) : [EOL] [docstring] [EOL] [EOL] for i , cluster in enumerate ( clusters ) : [EOL] [EOL] [comment] [EOL] [comment] [EOL] if self . _prune_clusters : [EOL] [EOL] [comment] [EOL] pre_pruned_cluster_ids = self . _detect_cluster_ids ( doc , cluster ) [EOL] logger . debug ( [string] , i , pre_pruned_cluster_ids ) [EOL] if len ( pre_pruned_cluster_ids ) != [number] : [EOL] logger . debug ( [string] ) [EOL] continue [EOL] pre_pruned_cluster_id = pre_pruned_cluster_ids . pop ( ) [EOL] [EOL] [comment] [EOL] alias_token_set = set ( ) [EOL] aliases = self . _alias_db [ pre_pruned_cluster_id ] [EOL] for alias in aliases : [EOL] if _bad_alias ( self . _nlp . tokenizer ( alias ) ) : [EOL] continue [EOL] alias_tokens = tuple ( x . text for x in self . _nlp . tokenizer ( alias ) ) [EOL] alias_token_set . update ( alias_tokens ) [EOL] alias_token_set . update ( capitalize ( alias_tokens ) ) [EOL] logger . debug ( [string] , alias_token_set ) [EOL] [EOL] logger . debug ( [string] , i ) [EOL] logger . debug ( [string] , cluster ) [EOL] cluster = self . _prune_cluster ( doc , cluster , alias_token_set ) [EOL] logger . debug ( [string] , cluster ) [EOL] [EOL] [comment] [EOL] cluster_ids = self . _detect_cluster_ids ( doc , cluster ) [EOL] logger . debug ( [string] , i , cluster_ids ) [EOL] if len ( cluster_ids ) != [number] : [EOL] logger . debug ( [string] ) [EOL] continue [EOL] id = cluster_ids . pop ( ) [EOL] [EOL] [comment] [EOL] logger . debug ( [string] , id , i ) [EOL] for start , end in cluster : [EOL] for token in doc [ start : end + [number] ] : [EOL] if token . _ . id != id : [EOL] if token . _ . id is not None : [EOL] raise RuntimeError ( [string] ) [EOL] token . _ . id = id [EOL] token . _ . source = [string] [EOL] [EOL] def _json_to_doc ( self , json_data , root_id ) : [EOL] [docstring] [EOL] [comment] [EOL] tokens = flatten_tokens ( json_data [ [string] ] ) [EOL] doc = Doc ( self . _nlp . vocab , words = tokens ) [EOL] [EOL] [comment] [EOL] for _ , pipe in self . _nlp . pipeline : [EOL] doc = pipe ( doc ) [EOL] [EOL] [comment] [EOL] wiki_ids = self . _add_wikilinks ( doc , json_data [ [string] ] ) [EOL] wiki_ids . add ( root_id ) [comment] [EOL] [EOL] [comment] [EOL] self . _add_nel ( doc , json_data [ [string] ] , wiki_ids ) [EOL] [EOL] [comment] [EOL] self . _propagate_ids ( doc , json_data [ [string] ] , wiki_ids ) [EOL] [EOL] return doc [EOL] [EOL] def _add_aliases ( self , id ) : [EOL] [docstring] [EOL] try : [EOL] aliases = self . _alias_db [ id ] [EOL] except KeyError : [comment] [EOL] logger . debug ( [string] , id ) [EOL] else : [EOL] for alias in aliases : [EOL] if _bad_alias ( self . _nlp . tokenizer ( alias ) ) : [EOL] continue [EOL] alias_tokens = [ x . text for x in self . _nlp . tokenizer ( alias ) ] [EOL] self . _alias_lookup . add ( alias_tokens , id ) [EOL] self . _alias_lookup . add ( capitalize ( alias_tokens ) , id ) [EOL] [EOL] def _add_relations ( self , id ) : [EOL] [docstring] [EOL] if id not in self . _relation_db : [EOL] logger . debug ( [string] ) [EOL] return [comment] [EOL] for prop , value in self . _relation_db [ id ] : [EOL] if value [ [string] ] == [string] : [EOL] child_id = value [ [string] ] [ [string] ] [EOL] try : [EOL] child_aliases = self . _alias_db [ child_id ] [EOL] except : [EOL] continue [EOL] else : [EOL] child_id , child_aliases = process_literal ( value ) [EOL] if child_id is None : [EOL] continue [EOL] [EOL] if prop == [string] : [EOL] logger . debug ( [string] ) [EOL] for child_alias in child_aliases : [EOL] if _bad_alias ( self . _nlp . tokenizer ( child_alias ) ) : [EOL] continue [EOL] child_alias_tokens = [ x . text for x in self . _nlp . tokenizer ( child_alias ) ] [EOL] if child_alias_tokens not in self . _alias_lookup : [EOL] self . _alias_lookup . add ( child_alias_tokens , id ) [EOL] self . _alias_lookup . add ( capitalize ( child_alias_tokens ) , id ) [EOL] return [EOL] [EOL] logger . debug ( [string] , child_id , id ) [EOL] self . _parents [ child_id ] . add ( ( prop , id ) ) [EOL] for child_alias in child_aliases : [EOL] child_alias_tokens = [ x . text for x in self . _nlp . tokenizer ( child_alias ) ] [EOL] logger . debug ( [string] , child_alias_tokens ) [EOL] if _bad_alias ( self . _nlp . tokenizer ( child_alias ) ) : [EOL] logger . debug ( [string] ) [EOL] continue [EOL] if child_alias_tokens not in self . _alias_lookup : [EOL] self . _alias_lookup . add ( child_alias_tokens , child_id ) [EOL] self . _alias_lookup . add ( capitalize ( child_alias_tokens ) , child_id ) [EOL] [EOL] def _expand ( self , id , loc ) : [EOL] [docstring] [EOL] logger . debug ( [string] , id , loc ) [EOL] if id not in self . _last_seen : [EOL] self . _add_relations ( id ) [EOL] else : [EOL] logger . debug ( [string] ) [EOL] self . _last_seen [ id ] = loc [EOL] [EOL] @ staticmethod def _existing_id ( active , token_stack ) : [EOL] [docstring] [EOL] id = active . _ . id [EOL] match_stack = deque ( ) [EOL] match_stack . append ( ( active , id ) ) [EOL] while True : [EOL] if token_stack : [EOL] tmp = token_stack . pop ( ) [EOL] else : [EOL] break [EOL] if tmp . _ . id != active . _ . id : [EOL] token_stack . append ( tmp ) [EOL] break [EOL] else : [EOL] match_stack . append ( ( tmp , id ) ) [EOL] return match_stack [EOL] [EOL] def _unknown_id ( self , active , token_stack ) : [EOL] [docstring] [EOL] match_stack = deque ( ) [EOL] while True : [EOL] [comment] [EOL] try : [EOL] id = self . _alias_lookup . step ( active . text ) [EOL] except IndexError : [EOL] match_stack . append ( ( active , None ) ) [EOL] return match_stack [EOL] else : [EOL] match_stack . append ( ( active , id ) ) [EOL] [comment] [EOL] if token_stack : [EOL] active = token_stack . pop ( ) [EOL] else : [EOL] return match_stack [EOL] [EOL] def _annotate_tokens ( self , doc ) : [EOL] [docstring] [EOL] token_stack = deque ( reversed ( doc ) ) [EOL] n = len ( token_stack ) [EOL] while token_stack : [EOL] active = token_stack . pop ( ) [EOL] id = active . _ . id [EOL] if id is None : [EOL] logger . debug ( [string] ) [EOL] match_stack = self . _unknown_id ( active , token_stack ) [EOL] else : [EOL] logger . debug ( [string] , id ) [EOL] match_stack = self . _existing_id ( active , token_stack ) [EOL] logger . debug ( [string] , match_stack ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] logger . debug ( [string] ) [EOL] while len ( match_stack ) > [number] : [EOL] _ , id = match_stack [ - [number] ] [EOL] if id is None : [EOL] tmp , _ = match_stack . pop ( ) [EOL] token_stack . append ( tmp ) [EOL] else : [EOL] break [EOL] logger . debug ( [string] , match_stack ) [EOL] _ , id = match_stack [ - [number] ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] if id is None : [EOL] continue [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] logger . debug ( [string] , id ) [EOL] loc = n - len ( token_stack ) + len ( match_stack ) [EOL] relation = [ ] [EOL] parent_id = [ ] [EOL] if id in self . _last_seen : [EOL] logger . debug ( [string] , self . _last_seen [ id ] ) [EOL] if ( loc - self . _last_seen [ id ] ) > self . _distance_cutoff : [EOL] logger . debug ( [string] ) [EOL] else : [EOL] relation . append ( [string] ) [EOL] parent_id . append ( id ) [EOL] if id in self . _parents : [EOL] parents = self . _parents [ id ] [EOL] logger . debug ( [string] , parents ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] parent_locs = [ ( loc - self . _last_seen [ parent_id ] ) for _ , parent_id in parents ] [EOL] logger . debug ( [string] , parent_locs ) [EOL] parents = [ ( x , y ) for x , y in zip ( parents , parent_locs ) if y < self . _distance_cutoff ] [EOL] parents . sort ( key = lambda x : x [ [number] ] ) [EOL] parents = [ x for x , y in parents ] [ : [number] ] [EOL] logger . debug ( [string] , parents ) [EOL] if parents : [EOL] _relation , _parent_id = zip ( * parents ) [EOL] relation . extend ( list ( _relation ) ) [EOL] parent_id . extend ( list ( _parent_id ) ) [EOL] if len ( relation ) == [number] : [EOL] logger . debug ( [string] ) [EOL] if RE_ENTITY . match ( id ) and any ( token . _ . source is not None for token , _ in match_stack ) : [EOL] relation = [ [string] ] [EOL] parent_id = [ id ] [EOL] else : [EOL] logger . debug ( [string] ) [EOL] for token , _ in match_stack : [EOL] token . _ . id = None [EOL] token . _ . relation = None [EOL] token . _ . parent_id = None [EOL] token . _ . source = None [EOL] continue [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] for token , _ in match_stack : [EOL] token . _ . id = id [EOL] token . _ . relation = relation [EOL] token . _ . parent_id = parent_id [EOL] if token . _ . source is None : [EOL] token . _ . source = [string] [EOL] [comment] [EOL] [comment] [EOL] if id in self . _alias_db : [EOL] self . _expand ( id , loc ) [EOL] [EOL] def _serialize_annotations ( self , doc ) : [EOL] [docstring] [EOL] annotations = [ ] [EOL] prev_annotation = None [EOL] start = None [EOL] for i , token in enumerate ( doc ) : [EOL] annotation = _extract_annotation ( token ) [EOL] logger . debug ( [string] , token . text , annotation ) [EOL] if annotation != prev_annotation : [EOL] if prev_annotation is not None : [EOL] prev_annotation [ [string] ] = [ start , i ] [EOL] annotations . append ( prev_annotation ) [EOL] start = i [EOL] prev_annotation = annotation [EOL] if prev_annotation is not None : [EOL] prev_annotation [ [string] ] = [ start , len ( doc ) ] [EOL] annotations . append ( prev_annotation ) [EOL] return annotations [EOL] [EOL] def annotate ( self , json_data ) : [EOL] [docstring] [EOL] self . _reset ( ) [EOL] key = format_wikilink ( json_data [ [string] ] ) [EOL] [EOL] try : [EOL] root_id = self . _wiki_db [ key ] [EOL] except KeyError : [EOL] logger . warning ( [string] , key ) [EOL] json_data [ [string] ] = [ ] [EOL] return json_data [EOL] else : [EOL] self . _add_aliases ( root_id ) [EOL] logger . debug ( [string] , self . _alias_lookup . _root ) [EOL] [EOL] doc = self . _json_to_doc ( json_data , root_id ) [EOL] [EOL] self . _annotate_tokens ( doc ) [EOL] [EOL] annotations = self . _serialize_annotations ( doc ) [EOL] json_data [ [string] ] = annotations [EOL] [EOL] return json_data [EOL] [EOL] [EOL] def worker ( q , i , output , print_lock , FLAGS ) : [EOL] [docstring] [EOL] if FLAGS . in_memory : [EOL] with open ( FLAGS . alias_db , [string] ) as f : [EOL] alias_db = pickle . load ( f ) [EOL] with open ( FLAGS . relation_db , [string] ) as f : [EOL] relation_db = pickle . load ( f ) [EOL] with open ( FLAGS . wiki_db , [string] ) as f : [EOL] wiki_db = pickle . load ( f ) [EOL] else : [EOL] alias_db = SqliteDict ( FLAGS . alias_db , flag = [string] ) [EOL] relation_db = SqliteDict ( FLAGS . relation_db , flag = [string] ) [EOL] wiki_db = SqliteDict ( FLAGS . wiki_db , flag = [string] ) [EOL] [EOL] annotator = Annotator ( alias_db , relation_db , wiki_db , distance_cutoff = FLAGS . cutoff , match_aliases = FLAGS . match_aliases , unmatch = FLAGS . unmatch , prune_clusters = FLAGS . prune_clusters ) [EOL] while True : [EOL] logger . debug ( [string] , i ) [EOL] json_data = q . get ( ) [EOL] if json_data is None : [EOL] break [EOL] annotation = annotator . annotate ( json_data ) [EOL] print_lock . acquire ( ) [EOL] output . write ( json . dumps ( annotation ) + [string] ) [EOL] print_lock . release ( ) [EOL] q . task_done ( ) [EOL] logger . debug ( [string] , i ) [EOL] [EOL] [EOL] def loader ( q , FLAGS ) : [EOL] i = [number] [EOL] with open ( FLAGS . input , [string] ) as f : [EOL] for i , line in enumerate ( f ) : [EOL] if line == [string] : [EOL] continue [EOL] q . put ( json . loads ( line . strip ( ) ) ) [EOL] logger . info ( [string] , i + [number] ) [EOL] [EOL] [EOL] def main ( _ ) : [comment] [EOL] if FLAGS . prune_clusters : [EOL] logger . warning ( [string] [string] [string] [string] ) [EOL] logger . info ( [string] ) [EOL] q = JoinableQueue ( maxsize = [number] ) [EOL] l = Process ( target = loader , args = ( q , FLAGS ) ) [EOL] l . start ( ) [EOL] [EOL] logger . info ( [string] ) [EOL] print_lock = Lock ( ) [EOL] output = open ( FLAGS . output , [string] ) [EOL] processes = [ Process ( target = worker , args = ( q , i , output , print_lock , FLAGS ) ) for i in range ( FLAGS . j ) ] [EOL] for p in processes : [EOL] p . start ( ) [EOL] [EOL] l . join ( ) [EOL] q . join ( ) [EOL] for _ in range ( FLAGS . j ) : [EOL] q . put ( None ) [EOL] for p in processes : [EOL] p . join ( ) [EOL] logger . info ( [string] ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( ) [comment] [EOL] parser . add_argument ( [string] , type = str ) [EOL] parser . add_argument ( [string] , type = str ) [EOL] parser . add_argument ( [string] , type = int , default = [number] , help = [string] ) [EOL] parser . add_argument ( [string] , type = str , default = [string] ) [EOL] parser . add_argument ( [string] , type = str , default = [string] ) [EOL] parser . add_argument ( [string] , type = str , default = [string] ) [EOL] parser . add_argument ( [string] , action = [string] ) [EOL] parser . add_argument ( [string] , [string] , type = float , default = float ( [string] ) , help = [string] ) [EOL] parser . add_argument ( [string] , [string] , action = [string] , help = [string] [string] ) [EOL] parser . add_argument ( [string] , [string] , action = [string] , help = [string] [string] ) [EOL] parser . add_argument ( [string] , [string] , action = [string] , help = [string] [string] ) [EOL] parser . add_argument ( [string] , action = [string] ) [EOL] FLAGS , _ = parser . parse_known_args ( ) [EOL] [EOL] if FLAGS . debug : [EOL] LEVEL = logging . DEBUG [EOL] else : [EOL] LEVEL = logging . INFO [EOL] logging . basicConfig ( format = LOG_FORMAT , level = LEVEL ) [EOL] [EOL] main ( _ ) [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $spacy.tokens.Doc$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.str]$ 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.str]$ 0 0 0 $typing.Tuple[builtins.str]$ 0 0 0 0 0 $typing.Tuple[builtins.str]$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.str]$ 0 0 $builtins.int$ 0 0 0 $typing.Tuple[builtins.str]$ 0 0 0 0 $typing.Tuple[builtins.str]$ 0 0 0 0 0 $typing.Tuple[builtins.str]$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.str]$ 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Set , Any [EOL] import typing [EOL] import io [EOL] import argparse [EOL] import logging [EOL] [docstring] [EOL] import argparse [EOL] import json [EOL] import logging [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def main ( _ ) : [EOL] [EOL] with open ( FLAGS . valid , [string] ) as f : [EOL] valid_set = set ( x . strip ( ) for x in f ) [EOL] logger . info ( [string] , len ( valid_set ) , FLAGS . valid ) [EOL] [EOL] with open ( FLAGS . test , [string] ) as f : [EOL] test_set = set ( x . strip ( ) for x in f ) [EOL] logger . info ( [string] , len ( test_set ) , FLAGS . test ) [EOL] [EOL] with open ( FLAGS . mini , [string] ) as f : [EOL] mini_set = set ( x . strip ( ) for x in f ) [EOL] logger . info ( [string] , len ( mini_set ) , FLAGS . mini ) [EOL] [EOL] logger . info ( [string] , FLAGS . input ) [EOL] train_file = open ( FLAGS . prefix + [string] , [string] ) [EOL] valid_file = open ( FLAGS . prefix + [string] , [string] ) [EOL] test_file = open ( FLAGS . prefix + [string] , [string] ) [EOL] mini_file = open ( FLAGS . prefix + [string] , [string] ) [EOL] with open ( FLAGS . input , [string] ) as f : [EOL] for line in f : [EOL] data = json . loads ( line ) [EOL] title = data [ [string] ] [EOL] if title in valid_set : [EOL] valid_file . write ( line ) [EOL] valid_set . remove ( title ) [EOL] elif title in test_set : [EOL] test_file . write ( line ) [EOL] test_set . remove ( title ) [EOL] else : [EOL] train_file . write ( line ) [EOL] if title in mini_set : [EOL] mini_file . write ( line ) [EOL] mini_set . remove ( title ) [EOL] [EOL] logger . info ( [string] ) [EOL] logger . info ( [string] , valid_set ) [EOL] logger . info ( [string] , test_set ) [EOL] logger . info ( [string] , mini_set ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] , type = str ) [EOL] parser . add_argument ( [string] , type = str ) [EOL] parser . add_argument ( [string] , [string] , type = str , required = True ) [EOL] parser . add_argument ( [string] , [string] , type = str , required = True ) [EOL] parser . add_argument ( [string] , [string] , type = str , required = True ) [EOL] FLAGS , _ = parser . parse_known_args ( ) [EOL] [EOL] logging . basicConfig ( level = logging . INFO ) [EOL] [EOL] main ( _ ) [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Union , List , Pattern , Any , Dict [EOL] import builtins [EOL] import bs4 [EOL] import logging [EOL] import sqlitedict [EOL] import typing [EOL] import argparse [EOL] import spacy [EOL] [docstring] [EOL] from typing import Any , Dict [EOL] [EOL] import argparse [EOL] import json [EOL] import logging [EOL] import pickle [EOL] import re [EOL] [EOL] from bs4 import BeautifulSoup , Comment [EOL] import spacy [EOL] from spacy . language import Language [EOL] from spacy . tokens import Doc [EOL] from sqlitedict import SqliteDict [EOL] [EOL] from kglm_data . util import format_wikilink [EOL] [EOL] logger = logging . getLogger ( __name__ ) [comment] [EOL] [EOL] [EOL] RE_WHITESPACE = re . compile ( [string] ) [EOL] RE_HEADER = re . compile ( [string] ) [EOL] [EOL] [EOL] def generate_instances ( input ) : [EOL] [docstring] [EOL] with open ( FLAGS . input , [string] ) as f : [EOL] for line in f : [EOL] data = json . loads ( line ) [EOL] yield data [EOL] [EOL] [EOL] def clean_soup ( root ) : [EOL] [docstring] [EOL] [comment] [EOL] unwanted_tags = [ [string] , [string] , [string] , [string] ] [EOL] for tag in unwanted_tags : [EOL] for branch in root ( tag , recusive = False ) : [EOL] branch . decompose ( ) [EOL] [comment] [EOL] for reference in root . select ( [string] ) : [EOL] reference . decompose ( ) [EOL] [comment] [EOL] for edit in root . select ( [string] ) : [EOL] edit . decompose ( ) [EOL] [comment] [EOL] for invisible in root . select ( [string] ) : [EOL] invisible . decompose ( ) [EOL] [comment] [EOL] for comment in root ( string = lambda text : isinstance ( text , Comment ) ) : [EOL] comment . extract ( ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] for equation in root . select ( [string] ) : [EOL] equation . replace_with ( [string] ) [EOL] [comment] [EOL] format_tags = [ [string] , [string] , [string] , [string] ] [EOL] for tag in format_tags : [EOL] for branch in root ( tag ) : [EOL] branch . replaceWithChildren ( ) [EOL] [EOL] [EOL] def process ( title , root , wiki_db , nlp ) : [EOL] [docstring] [EOL] ids = [ ] [EOL] text = [ ] [EOL] try : [EOL] title_id = wiki_db [ format_wikilink ( title ) ] [EOL] except KeyError : [EOL] logger . warning ( [string] , title ) [EOL] [EOL] [comment] [EOL] def _recursion ( node ) : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] if node . name == [string] : [EOL] try : [EOL] key = format_wikilink ( node [ [string] ] ) [EOL] except KeyError : [EOL] key = None [EOL] if key in wiki_db : [EOL] id = wiki_db [ key ] [EOL] else : [EOL] id = None [EOL] ids . append ( id ) [EOL] text . append ( node . text ) [EOL] [comment] [EOL] elif RE_HEADER . search ( str ( node . name ) ) : [EOL] pass [EOL] elif node . name == [string] and len ( text ) < [number] : [EOL] logger . debug ( [string] , node . text ) [EOL] ids . append ( title_id ) [EOL] text . append ( node . text ) [EOL] [comment] [EOL] else : [EOL] if hasattr ( node , [string] ) : [EOL] for child in node . children : [EOL] _recursion ( child ) [EOL] [comment] [EOL] else : [EOL] ids . append ( None ) [EOL] text . append ( str ( node ) ) [EOL] [EOL] _recursion ( root ) [EOL] [EOL] [comment] [EOL] words = [ ] [EOL] spaces = [ ] [EOL] entities = [ ] [EOL] for id , doc in zip ( ids , nlp . tokenizer . pipe ( text , FLAGS . batch_size , FLAGS . n_threads ) ) : [EOL] start = len ( words ) [EOL] tokens = [ token for token in doc if not RE_WHITESPACE . search ( token . text ) ] [EOL] words . extend ( [ token . text for token in tokens ] ) [EOL] spaces . extend ( [ token . whitespace_ != [string] for token in tokens ] ) [EOL] end = len ( words ) [EOL] if id is not None : [EOL] entities . append ( [ id , start , end ] ) [EOL] assert len ( words ) == len ( spaces ) , [string] [EOL] [EOL] doc = Doc ( nlp . vocab , words = words , spaces = spaces ) [EOL] for _ , proc in nlp . pipeline : [EOL] doc = proc ( doc ) [EOL] tokens = [ [ token . text for token in sentence ] for sentence in doc . sents ] [EOL] [EOL] out = { [string] : title , [string] : tokens , [string] : entities } [EOL] [EOL] return out [EOL] [EOL] [EOL] def main ( _ ) : [EOL] with open ( FLAGS . wiki_db , [string] ) as f : [EOL] wiki_db = pickle . load ( f ) [EOL] nlp = spacy . load ( [string] , disable = [ [string] ] ) [EOL] for instance in generate_instances ( FLAGS . input ) : [EOL] soup = BeautifulSoup ( instance [ [string] ] ) [EOL] root = soup . div [EOL] clean_soup ( root ) [EOL] try : [EOL] processed = process ( instance [ [string] ] , root , wiki_db , nlp ) [EOL] except NameError : [EOL] continue [EOL] print ( json . dumps ( processed ) ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] , type = str ) [EOL] parser . add_argument ( [string] , type = str , default = [string] ) [EOL] parser . add_argument ( [string] , type = int , default = [number] ) [EOL] parser . add_argument ( [string] , type = int , default = [number] ) [EOL] parser . add_argument ( [string] , type = int , default = [number] ) [EOL] parser . add_argument ( [string] , action = [string] ) [EOL] FLAGS , _ = parser . parse_known_args ( ) [EOL] [EOL] if FLAGS . debug : [EOL] LEVEL = logging . DEBUG [EOL] else : [EOL] LEVEL = logging . INFO [EOL] logging . basicConfig ( level = LEVEL ) [EOL] [EOL] main ( _ ) [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Iterable [EOL] import logging [EOL] import builtins [EOL] import typing [EOL] import kglm_data [EOL] [docstring] [EOL] import logging [EOL] from typing import Tuple , Iterable [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class TreeNode ( dict ) : [EOL] [docstring] [EOL] def __init__ ( self , id = None ) : [EOL] super ( TreeNode , self ) . __init__ ( ) [EOL] self . id = id [EOL] [EOL] @ property def is_terminal ( self ) : [EOL] return self . id is not None [EOL] [EOL] [EOL] class PrefixTree ( object ) : [EOL] [docstring] [EOL] def __init__ ( self , fixed = True ) : [EOL] self . _root = TreeNode ( ) [EOL] self . _active = self . _root [EOL] self . _fixed = fixed [EOL] [EOL] def __contains__ ( self , iter ) : [EOL] [docstring] [EOL] active = self . _root [EOL] for elt in iter : [EOL] try : [EOL] active = active [ elt ] [EOL] except KeyError : [EOL] return False [EOL] if active . is_terminal : [EOL] return True [EOL] else : [EOL] return False [EOL] [EOL] def step ( self , x ) : [EOL] [docstring] [EOL] try : [EOL] next = self . _active [ x ] [EOL] except KeyError : [EOL] self . _active = self . _root [EOL] raise IndexError ( [string] % x ) [EOL] else : [EOL] self . _active = next [EOL] return self . _active . id [EOL] [EOL] def add ( self , iter , id ) : [EOL] [docstring] [EOL] assert id is not None , [string] [EOL] active = self . _root [EOL] for elt in iter : [EOL] if elt not in active : [EOL] active [ elt ] = TreeNode ( ) [EOL] active = active [ elt ] [EOL] if active . id is None : [EOL] active . id = id [EOL] elif active . id != id : [EOL] if self . _fixed : [EOL] logger . warning ( [string] , active . id , id ) [EOL] else : [EOL] logger . warning ( [string] , active . id , id ) [EOL] active . id = id [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 $kglm_data.prefix_tree.TreeNode$ 0 0 0 0 0 0 0 0 0 0 0 $kglm_data.prefix_tree.TreeNode$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Iterable[builtins.str]$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Iterable[builtins.str]$ 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 $typing.Iterable[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Iterable[builtins.str]$ 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0
from typing import Any , Dict , DefaultDict [EOL] import typing [EOL] import argparse [EOL] [docstring] [EOL] import argparse [EOL] from collections import defaultdict [EOL] import json [EOL] import logging [EOL] [EOL] [EOL] def default_factory ( ) : [EOL] return [ None , None ] [EOL] [EOL] [EOL] def diff ( data1 , data2 ) : [EOL] token_ids = defaultdict ( default_factory ) [EOL] for annotation in data1 [ [string] ] : [EOL] for i in range ( * annotation [ [string] ] ) : [EOL] token_ids [ i ] [ [number] ] = annotation [EOL] for annotation in data2 [ [string] ] : [EOL] for i in range ( * annotation [ [string] ] ) : [EOL] token_ids [ i ] [ [number] ] = annotation [EOL] [EOL] joint_annotations = [ ] [EOL] for i , annotations in token_ids . items ( ) : [EOL] joint_annotation = { } [EOL] joint_annotation [ [string] ] = [ i , i + [number] ] [EOL] joint_annotation [ [string] ] = annotations [EOL] joint_annotations . append ( joint_annotation ) [EOL] [EOL] data = data1 . copy ( ) [EOL] data [ [string] ] = joint_annotations [EOL] [EOL] return data [EOL] [EOL] [EOL] def main ( _ ) : [EOL] with open ( FLAGS . file1 , [string] ) as f , open ( FLAGS . file2 , [string] ) as g : [EOL] for line1 , line2 in zip ( f , g ) : [EOL] data1 = json . loads ( line1 ) [EOL] data2 = json . loads ( line2 ) [EOL] assert data1 [ [string] ] == data2 [ [string] ] , [string] [EOL] data = diff ( data1 , data2 ) [EOL] data [ [string] ] = ( FLAGS . alias1 , FLAGS . alias2 ) [EOL] print ( json . dumps ( data ) ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] , type = str ) [EOL] parser . add_argument ( [string] , type = str ) [EOL] parser . add_argument ( [string] , type = str , default = None ) [EOL] parser . add_argument ( [string] , type = str , default = None ) [EOL] parser . add_argument ( [string] , action = [string] ) [EOL] FLAGS , _ = parser . parse_known_args ( ) [EOL] [EOL] if FLAGS . debug : [EOL] LEVEL = logging . DEBUG [EOL] else : [EOL] LEVEL = logging . INFO [EOL] logging . basicConfig ( level = LEVEL ) [EOL] [EOL] main ( _ ) [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0
from typing import Any , Iterator , Tuple , Optional [EOL] import builtins [EOL] import xml [EOL] import logging [EOL] import argparse [EOL] import typing [EOL] [docstring] [EOL] import argparse [EOL] import bz2 [EOL] import logging [EOL] import pickle [EOL] import sys [EOL] from xml . etree import ElementTree [EOL] from xml . sax . saxutils import unescape [EOL] [EOL] from sqlitedict import SqliteDict [EOL] [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] xmlns = [string] [EOL] [EOL] [EOL] def extract_redirect ( elem ) : [EOL] [docstring] [EOL] [comment] [EOL] title = elem . find ( f'{ xmlns } [string] ' ) [EOL] if title is None : [EOL] logger . debug ( [string] ) [EOL] return [EOL] _from = title . text . replace ( [string] , [string] ) . capitalize ( ) [EOL] [comment] [EOL] redirect = elem . find ( f'{ xmlns } [string] ' ) [EOL] if redirect is None : [EOL] logger . debug ( [string] ) [EOL] return [EOL] _to = redirect . attrib [ [string] ] . replace ( [string] , [string] ) . capitalize ( ) [EOL] logger . debug ( [string] , _from , _to ) [EOL] return _from , _to [EOL] [EOL] [EOL] def main ( _ ) : [EOL] logger . info ( [string] , FLAGS . wiki_db ) [EOL] [EOL] if FLAGS . in_memory : [EOL] with open ( FLAGS . wiki_db , [string] ) as f : [EOL] wiki_db = pickle . load ( f ) [EOL] else : [EOL] wiki_db = SqliteDict ( FLAGS . wiki_db , autocommit = True ) [EOL] [EOL] with bz2 . open ( FLAGS . input , [string] ) as f : [EOL] tree = ElementTree . iterparse ( f , events = ( [string] , [string] ) ) [EOL] root = None [EOL] for event , elem in tree : [EOL] if event == [string] : [EOL] if root is None : [EOL] root = elem [EOL] else : [EOL] continue [EOL] if elem . tag == f'{ xmlns } [string] ' : [EOL] redirect = extract_redirect ( elem ) [EOL] if redirect is None : [EOL] continue [EOL] _from , _to = redirect [EOL] logger . debug ( [string] , _to ) [EOL] try : [EOL] entity_id = wiki_db [ _to ] [EOL] logger . debug ( [string] , entity_id ) [EOL] except KeyError : [EOL] logger . debug ( [string] , _to ) [EOL] continue [EOL] if _from in wiki_db : [EOL] logger . warning ( [string] , _from ) [EOL] else : [EOL] wiki_db [ _from ] = entity_id [EOL] elem . clear ( ) [EOL] root . clear ( ) [EOL] [EOL] if FLAGS . in_memory : [EOL] logger . info ( [string] ) [EOL] with open ( FLAGS . wiki_db , [string] ) as f : [EOL] pickle . dump ( wiki_db , f ) [EOL] else : [EOL] wiki_db . commit ( ) [EOL] [EOL] logger . info ( [string] ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] , type = str ) [EOL] parser . add_argument ( [string] , type = str ) [EOL] parser . add_argument ( [string] , action = [string] ) [EOL] parser . add_argument ( [string] , action = [string] ) [EOL] FLAGS , _ = parser . parse_known_args ( ) [EOL] [EOL] if FLAGS . debug : [EOL] LEVEL = logging . DEBUG [EOL] else : [EOL] LEVEL = logging . INFO [EOL] logging . basicConfig ( level = logging . INFO ) [EOL] [EOL] main ( _ ) [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Set , List , Pattern , Any , Dict , DefaultDict , Counter [EOL] import typing [EOL] import argparse [EOL] import logging [EOL] import collections [EOL] import argparse [EOL] from collections import Counter , defaultdict [EOL] import json [EOL] import logging [EOL] import pickle [EOL] import re [EOL] from statistics import mean [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] MANUAL_DELETIONS = [ re . compile ( [string] ) , re . compile ( [string] ) ] [EOL] [EOL] def _callable ( ) : [EOL] return defaultdict ( set ) [EOL] [EOL] [EOL] def main ( _ ) : [EOL] [EOL] [comment] [EOL] logger . info ( [string] ) [EOL] with open ( FLAGS . relation_db , [string] ) as f : [EOL] relation_db = pickle . load ( f ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] logger . info ( [string] ) [EOL] rs = defaultdict ( _callable ) [EOL] sr = defaultdict ( _callable ) [EOL] for subject , relations in relation_db . items ( ) : [EOL] for relation , object in relations : [EOL] if object [ [string] ] != [string] : [EOL] continue [EOL] object = object [ [string] ] [ [string] ] [EOL] rs [ relation ] [ subject ] . add ( object ) [EOL] sr [ subject ] [ relation ] . add ( object ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] logger . info ( [string] ) [EOL] global_bad_relations = set ( ) [EOL] for relation , edges in rs . items ( ) : [EOL] avg = mean ( len ( x ) for x in edges . values ( ) ) [EOL] if avg >= FLAGS . max_avg_fan : [EOL] logger . info ( [string] , relation ) [EOL] global_bad_relations . add ( relation ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] logger . info ( [string] ) [EOL] relation_counts = Counter ( ) [EOL] with open ( FLAGS . input , [string] ) as f : [EOL] for line in f : [EOL] data = json . loads ( line ) [EOL] for annotation in data [ [string] ] : [EOL] for relation in annotation [ [string] ] : [EOL] relation_counts [ relation ] += [number] [EOL] logger . info ( [string] ) [EOL] low_freq_relations = set ( x for x , y in relation_counts . items ( ) if y <= FLAGS . min_count ) [EOL] for relation in low_freq_relations : [EOL] logger . info ( [string] , relation ) [EOL] [EOL] [comment] [EOL] logger . info ( [string] ) [EOL] pruned_relation_db = dict ( ) [EOL] for entity , children in relation_db . items ( ) : [EOL] pruned_children = [ ] [EOL] for relation , value in children : [EOL] if any ( regex . search ( relation ) for regex in MANUAL_DELETIONS ) : [EOL] logger . info ( [string] , relation , entity ) [EOL] elif relation in global_bad_relations : [EOL] logger . info ( [string] , relation , entity ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] elif relation in low_freq_relations : [EOL] logger . info ( [string] , relation , entity ) [EOL] else : [EOL] logger . info ( [string] , relation , entity ) [EOL] pruned_children . append ( ( relation , value ) ) [EOL] pruned_relation_db [ entity ] = pruned_children [EOL] with open ( FLAGS . output , [string] ) as f : [EOL] pickle . dump ( pruned_relation_db , f ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] , type = str ) [EOL] parser . add_argument ( [string] , type = str , default = [string] ) [EOL] parser . add_argument ( [string] , type = str , default = [string] ) [EOL] parser . add_argument ( [string] , type = int , default = [number] , help = [string] [string] ) [EOL] parser . add_argument ( [string] , type = int , default = [number] , help = [string] [string] ) [EOL] parser . add_argument ( [string] , type = int , default = [number] , help = [string] [string] ) [EOL] FLAGS , _ = parser . parse_known_args ( ) [EOL] [EOL] logging . basicConfig ( level = logging . INFO ) [EOL] [EOL] main ( _ ) [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Pattern[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Pattern[builtins.str]]$ 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import List , Any , Dict , Tuple , DefaultDict , Counter [EOL] import builtins [EOL] import collections [EOL] import logging [EOL] import argparse [EOL] import typing [EOL] [docstring] [EOL] from typing import Any , Dict [EOL] [EOL] import argparse [EOL] from collections import Counter , defaultdict [EOL] import json [EOL] import logging [EOL] import pickle [EOL] import random [EOL] [EOL] logger = logging . getLogger ( __name__ ) [comment] [EOL] [EOL] BORING_RELATIONS = [ [string] , [string] ] [EOL] [EOL] [EOL] def generate_instances ( fname ) : [EOL] [docstring] [EOL] with open ( fname , [string] ) as f : [EOL] for line in f : [EOL] yield json . loads ( line ) [EOL] [EOL] [EOL] def main ( _ ) : [EOL] logger . info ( [string] ) [EOL] examples = defaultdict ( list ) [EOL] relation_counts = Counter ( ) [EOL] generator_counts = Counter ( ) [EOL] length_counts = Counter ( ) [EOL] last_seen = dict ( ) [EOL] entity_string = [string] [EOL] [EOL] logger . info ( [string] ) [EOL] with open ( FLAGS . alias_db , [string] ) as f : [EOL] alias_db = pickle . load ( f ) [EOL] [EOL] logger . info ( [string] ) [EOL] for instance in generate_instances ( FLAGS . input ) : [EOL] tokens = [ x for sent in instance [ [string] ] for x in sent ] [comment] [EOL] for annotation in instance [ [string] ] : [EOL] relations = annotation [ [string] ] [EOL] parent_ids = annotation [ [string] ] [EOL] id = annotation [ [string] ] [EOL] span = annotation [ [string] ] [EOL] source = annotation [ [string] ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] for relation , parent_id in zip ( relations , parent_ids ) : [EOL] [EOL] if relation in BORING_RELATIONS : [EOL] generator_counts [ relation ] += [number] [EOL] continue [EOL] else : [EOL] generator_counts [ [string] ] += [number] [EOL] [EOL] relation_strings = [ ] [EOL] for s in relation . split ( [string] ) : [EOL] if s in alias_db : [EOL] try : [EOL] alias = alias_db [ s ] [ [number] ] [EOL] except IndexError : [EOL] alias = s [EOL] relation_strings . append ( alias ) [EOL] else : [EOL] relation_strings . append ( s ) [EOL] relation = [string] . join ( relation_strings ) [EOL] [EOL] try : [EOL] parent_name = alias_db [ parent_id ] [ [number] ] [EOL] except IndexError : [EOL] parent_name = parent_id [EOL] [EOL] try : [EOL] name = alias_db [ id ] [ [number] ] [EOL] except IndexError : [EOL] name = id [EOL] [EOL] relation_counts [ relation ] += [number] [EOL] [EOL] if parent_id in last_seen : [EOL] [comment] [EOL] parent_span = last_seen [ parent_id ] [ [string] ] [EOL] parent_source = last_seen [ parent_id ] [ [string] ] [EOL] [comment] [EOL] start = parent_span [ [number] ] [EOL] end = span [ [number] ] [EOL] length = end - start [EOL] [comment] [EOL] length_counts [ length ] += [number] [EOL] [EOL] if length < FLAGS . l : [EOL] [comment] [EOL] parent_tokens = [string] . join ( tokens [ parent_span [ [number] ] : parent_span [ [number] ] ] ) [EOL] parent_string = entity_string % ( parent_tokens , parent_name , parent_source ) [EOL] [comment] [EOL] child_tokens = [string] . join ( tokens [ span [ [number] ] : span [ [number] ] ] ) [EOL] child_string = entity_string % ( child_tokens , name , source ) [EOL] [comment] [EOL] excerpt = [string] . join ( tokens [ parent_span [ [number] ] : span [ [number] ] ] ) [EOL] excerpt = [string] . join ( [ parent_string , excerpt , child_string ] ) [EOL] examples [ relation ] . append ( excerpt ) [EOL] [EOL] [comment] [EOL] last_seen [ id ] = annotation [EOL] [EOL] [comment] [EOL] logger . info ( [string] ) [EOL] with open ( FLAGS . prefix + [string] , [string] ) as f : [EOL] [EOL] length_list = sorted ( length_counts . items ( ) , key = lambda x : x [ [number] ] ) [EOL] accumulated = [number] [EOL] total = sum ( x [ [number] ] for x in length_list ) [EOL] [EOL] f . write ( [string] ) [EOL] for length , count in length_list : [EOL] accumulated += count [EOL] f . write ( [string] % ( length , accumulated / total ) ) [EOL] [EOL] [comment] [EOL] logger . info ( [string] ) [EOL] with open ( FLAGS . prefix + [string] , [string] ) as f : [EOL] f . write ( [string] ) [EOL] for tuple in generator_counts . most_common ( ) : [EOL] f . write ( [string] % tuple ) [EOL] for tuple in relation_counts . most_common ( ) : [EOL] f . write ( [string] % tuple ) [EOL] [EOL] [comment] [EOL] logger . info ( [string] ) [EOL] with open ( FLAGS . prefix + [string] , [string] ) as f : [EOL] for relation_tuple , _ in relation_counts . most_common ( ) : [EOL] f . write ( [string] % ( relation_tuple , ) ) [EOL] for i , example in enumerate ( examples [ relation_tuple ] ) : [EOL] f . write ( [string] % ( i , example ) ) [EOL] if i == FLAGS . n : [EOL] break [EOL] [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] , type = str ) [EOL] parser . add_argument ( [string] , type = str ) [EOL] parser . add_argument ( [string] , type = int , default = None , help = [string] ) [EOL] parser . add_argument ( [string] , type = int , default = None , help = [string] ) [EOL] parser . add_argument ( [string] , type = str , default = [string] ) [EOL] parser . add_argument ( [string] , action = [string] ) [EOL] FLAGS , _ = parser . parse_known_args ( ) [EOL] [EOL] if FLAGS . debug : [EOL] LEVEL = logging . DEBUG [EOL] else : [EOL] LEVEL = logging . INFO [EOL] logging . basicConfig ( level = LEVEL ) [EOL] [EOL] main ( _ ) [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] import argparse [EOL] [docstring] [EOL] import argparse [EOL] import json [EOL] [EOL] [EOL] def main ( _ ) : [EOL] with open ( FLAGS . input , [string] ) as f : [EOL] for line in f : [EOL] data = json . loads ( line ) [EOL] if len ( data [ [string] ] ) > [number] : [EOL] print ( json . dumps ( data ) ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] , type = str ) [EOL] FLAGS , _ = parser . parse_known_args ( ) [EOL] [EOL] main ( _ ) [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Set , Union , List , Pattern , Any , Dict [EOL] import typing [EOL] import argparse [EOL] import logging [EOL] import _csv [EOL] [docstring] [EOL] import argparse [EOL] from collections import defaultdict [EOL] import csv [EOL] import json [EOL] import logging [EOL] import pickle [EOL] import re [EOL] import sys [EOL] [EOL] from sqlitedict import SqliteDict [EOL] [EOL] from kglm_data . util import generate_from_wikidump , load_allowed_entities [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] BAD_DATATYPES = [ [string] , [string] , [string] , [string] ] [EOL] RE_PROPERTY = re . compile ( [string] ) [EOL] [EOL] [EOL] def load_allowed_properties ( fname ) : [EOL] [docstring] [EOL] if fname is None : [EOL] logger . info ( [string] ) [EOL] return [EOL] else : [EOL] logger . info ( [string] , fname ) [EOL] allowed_properties = set ( ) [EOL] with open ( fname , [string] ) as f : [EOL] reader = csv . reader ( f ) [EOL] for row in reader : [EOL] logger . debug ( row ) [EOL] match = RE_PROPERTY . search ( row [ [number] ] ) [EOL] if match is not None : [EOL] logger . debug ( [string] , match . group ( [number] ) ) [EOL] allowed_properties . add ( match . group ( [number] ) ) [EOL] logger . info ( [string] , len ( allowed_properties ) ) [EOL] return allowed_properties [EOL] [EOL] [EOL] def main ( _ ) : [EOL] allowed_properties = load_allowed_properties ( FLAGS . properties ) [EOL] allowed_entities = load_allowed_entities ( FLAGS . entities ) [EOL] [EOL] if FLAGS . in_memory : [EOL] db = defaultdict ( list ) [EOL] else : [EOL] logger . info ( [string] , FLAGS . db ) [EOL] db = SqliteDict ( FLAGS . db , autocommit = True , journal_mode = [string] ) [EOL] [EOL] if FLAGS . reverse and not FLAGS . in_memory : [EOL] raise RuntimeError ( [string] [string] ) [EOL] [EOL] for data in generate_from_wikidump ( FLAGS . input ) : [EOL] id = data [ [string] ] [EOL] [EOL] [comment] [EOL] if allowed_entities is not None : [EOL] if id not in allowed_entities : [EOL] continue [EOL] [EOL] claims = data [ [string] ] [EOL] properties = [ ] [EOL] for property , snaks in claims . items ( ) : [EOL] [EOL] [comment] [EOL] if allowed_properties is not None : [EOL] if property not in allowed_properties : [EOL] continue [EOL] [EOL] for snak in snaks : [EOL] [EOL] [comment] [EOL] mainsnak = snak [ [string] ] [EOL] if mainsnak [ [string] ] in BAD_DATATYPES : [EOL] continue [EOL] try : [EOL] value = mainsnak [ [string] ] [EOL] except KeyError : [EOL] continue [EOL] [EOL] [comment] [EOL] if mainsnak [ [string] ] == [string] : [EOL] [comment] [EOL] if value [ [string] ] [ [string] ] != [string] : [EOL] continue [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] properties . append ( ( property , value ) ) [EOL] [EOL] [comment] [EOL] if [string] in snak : [EOL] [EOL] qualifiers = snak [ [string] ] [EOL] [EOL] for qual_prop , qual_snaks in qualifiers . items ( ) : [EOL] [EOL] qual_prop = property + [string] + qual_prop [EOL] for qual_snak in qual_snaks : [EOL] [EOL] [comment] [EOL] if qual_snak [ [string] ] in BAD_DATATYPES : [EOL] continue [EOL] try : [EOL] qual_value = qual_snak [ [string] ] [EOL] except KeyError : [EOL] continue [EOL] [EOL] [comment] [EOL] if qual_snak [ [string] ] == [string] : [EOL] [comment] [EOL] if qual_value [ [string] ] [ [string] ] != [string] : [EOL] continue [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] properties . append ( ( qual_prop , qual_value ) ) [EOL] [EOL] logger . debug ( [string] , id ) [EOL] logger . debug ( [string] , properties ) [EOL] [EOL] if FLAGS . in_memory : [EOL] db [ id ] . extend ( properties ) [EOL] else : [EOL] db [ id ] = properties [EOL] [EOL] [comment] [EOL] if FLAGS . reverse : [EOL] logger . debug ( [string] ) [EOL] for rel , tail in properties : [EOL] if tail [ [string] ] != [string] : [EOL] continue [EOL] tail_id = tail [ [string] ] [ [string] ] [EOL] bw_prop = [string] + rel [EOL] bw_value = { [string] : [string] , [string] : { [string] : id } } [EOL] db [ tail_id ] . append ( ( bw_prop , bw_value ) ) [EOL] [EOL] if FLAGS . in_memory : [EOL] logger . info ( [string] ) [EOL] with open ( FLAGS . db , [string] ) as f : [EOL] pickle . dump ( db , f ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] , type = str ) [EOL] parser . add_argument ( [string] , type = str , default = [string] ) [EOL] parser . add_argument ( [string] , [string] , type = str , default = None ) [EOL] parser . add_argument ( [string] , [string] , type = str , default = None ) [EOL] parser . add_argument ( [string] , action = [string] ) [EOL] parser . add_argument ( [string] , action = [string] ) [EOL] parser . add_argument ( [string] , action = [string] ) [EOL] FLAGS , _ = parser . parse_known_args ( ) [EOL] [EOL] if FLAGS . debug : [EOL] LEVEL = logging . DEBUG [EOL] else : [EOL] LEVEL = logging . INFO [EOL] logging . basicConfig ( level = LEVEL ) [EOL] [EOL] main ( _ ) [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Pattern[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 $typing.Pattern[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0
from typing import Any , Pattern , Dict [EOL] import argparse [EOL] import logging [EOL] import typing [EOL] [docstring] [EOL] import argparse [EOL] import bz2 [EOL] import json [EOL] import logging [EOL] import re [EOL] [EOL] from kglm_data . wikidump_to_jsonl import page_generator [EOL] [EOL] logger = logging . getLogger ( __name__ ) [comment] [EOL] RE_GF = re . compile ( [string] ) [EOL] [EOL] [EOL] def main ( _ ) : [EOL] for title , wikitext in page_generator ( FLAGS . input ) : [EOL] if RE_GF . search ( wikitext ) : [EOL] out = { [string] : title , [string] : wikitext } [EOL] print ( json . dumps ( out ) ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] , type = str ) [EOL] FLAGS , _ = parser . parse_known_args ( ) [EOL] [EOL] main ( _ ) [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 $typing.Pattern[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Pattern[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Tuple , List [EOL] import typing [EOL] import argparse [EOL] [docstring] [EOL] import argparse [EOL] from collections import defaultdict [EOL] import json [EOL] import pickle [EOL] [EOL] from sqlitedict import SqliteDict [EOL] [EOL] [EOL] def main ( _ ) : [EOL] if FLAGS . in_memory : [EOL] with open ( FLAGS . alias_db , [string] ) as f : [EOL] alias_db = pickle . load ( f ) [EOL] else : [EOL] alias_db = SqliteDict ( FLAGS . alias_db , flag = [string] ) [EOL] [EOL] def lookup ( id ) : [EOL] if id in alias_db : [EOL] return alias_db [ id ] [ [number] ] [EOL] else : [EOL] return [string] [EOL] [EOL] with open ( FLAGS . input , [string] ) as f : [EOL] for line in f : [EOL] data = json . loads ( line ) [EOL] annotations = data [ [string] ] [EOL] readable_annotations = [ ] [EOL] [EOL] for annotation in annotations : [EOL] [EOL] id = annotation [ [string] ] [EOL] new_id = ( id , lookup ( id ) ) [EOL] [EOL] parent_ids = annotation [ [string] ] [EOL] relations = annotation [ [string] ] [EOL] sorted_pairs = sorted ( list ( zip ( parent_ids , relations ) ) , key = lambda x : x [ [number] ] + x [ [number] ] ) [EOL] parent_ids , relations = zip ( * sorted_pairs ) [EOL] [EOL] parent_strings = [ ] [EOL] relation_strings = [ ] [EOL] [EOL] for parent_id , relation in sorted_pairs : [EOL] [EOL] [comment] [EOL] if relation is None : [EOL] continue [EOL] readable = [ ] [EOL] for piece in relation . split ( [string] ) : [EOL] if piece [ [number] ] == [string] : [EOL] readable . append ( [string] ) [EOL] else : [EOL] readable . append ( lookup ( piece ) ) [EOL] readable = [string] . join ( readable ) [EOL] [EOL] parent_strings . append ( lookup ( parent_id ) ) [EOL] relation_strings . append ( readable ) [EOL] [EOL] parent_ids = [string] . join ( parent_ids ) [EOL] parent_strings = [string] . join ( parent_strings ) [EOL] new_parent_id = ( parent_ids , parent_strings ) [EOL] [EOL] relations = [string] . join ( relations ) [EOL] relation_strings = [string] . join ( relation_strings ) [EOL] new_relation = ( relations , relation_strings ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] readable_annotation = annotation . copy ( ) [EOL] readable_annotation [ [string] ] = new_id [EOL] readable_annotation [ [string] ] = new_relation [EOL] readable_annotation [ [string] ] = new_parent_id [EOL] [EOL] readable_annotations . append ( readable_annotation ) [EOL] [EOL] data [ [string] ] = readable_annotations [EOL] print ( json . dumps ( data ) ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] , type = str ) [EOL] parser . add_argument ( [string] , action = [string] ) [EOL] parser . add_argument ( [string] , type = str , default = [string] ) [EOL] FLAGS , _ = parser . parse_known_args ( ) [EOL] [EOL] main ( _ ) [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Set , Any , List [EOL] import typing [EOL] import argparse [EOL] import logging [EOL] [docstring] [EOL] import argparse [EOL] from collections import defaultdict [EOL] import json [EOL] import logging [EOL] import pickle [EOL] import sys [EOL] [EOL] from sqlitedict import SqliteDict [EOL] [EOL] from kglm_data . util import generate_from_wikidump , load_allowed_entities , LOG_FORMAT [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def main ( _ ) : [EOL] allowed_entities = load_allowed_entities ( FLAGS . entities ) [EOL] logger . info ( [string] , FLAGS . db ) [EOL] [EOL] if FLAGS . in_memory : [EOL] db = defaultdict ( list ) [EOL] else : [EOL] db = SqliteDict ( FLAGS . db , autocommit = True , journal_mode = [string] ) [EOL] [EOL] for data in generate_from_wikidump ( FLAGS . input ) : [EOL] [EOL] id = data [ [string] ] [EOL] [EOL] [comment] [EOL] if allowed_entities is not None : [EOL] is_entity = id [ [number] ] == [string] [EOL] if id not in allowed_entities and is_entity : [EOL] continue [EOL] [EOL] [comment] [EOL] aliases = [ ] [EOL] try : [EOL] name = data [ [string] ] [ [string] ] [ [string] ] [EOL] aliases . append ( name ) [EOL] except : [EOL] logger . warning ( [string] , id ) [EOL] try : [EOL] aliases . extend ( x [ [string] ] for x in data [ [string] ] [ [string] ] ) [EOL] except : [EOL] [comment] [EOL] [comment] [EOL] logger . debug ( [string] , id ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] if len ( aliases ) == [number] : [EOL] continue [EOL] [EOL] logger . debug ( [string] , id , aliases ) [EOL] db [ id ] = aliases [EOL] [EOL] [EOL] if FLAGS . in_memory : [EOL] logger . info ( [string] ) [EOL] with open ( FLAGS . db , [string] ) as f : [EOL] pickle . dump ( db , f ) [EOL] else : [EOL] db . commit ( ) [EOL] [EOL] logger . info ( [string] ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] , type = str ) [EOL] parser . add_argument ( [string] , type = str , default = [string] ) [EOL] parser . add_argument ( [string] , [string] , type = str , default = None ) [EOL] parser . add_argument ( [string] , action = [string] ) [EOL] parser . add_argument ( [string] , action = [string] ) [EOL] FLAGS , _ = parser . parse_known_args ( ) [EOL] [EOL] if FLAGS . debug : [EOL] LEVEL = logging . DEBUG [EOL] else : [EOL] LEVEL = logging . INFO [EOL] logging . basicConfig ( format = LOG_FORMAT , level = LEVEL ) [EOL] [EOL] main ( _ ) [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0
from typing import Any , DefaultDict , List [EOL] import typing [EOL] import argparse [EOL] import logging [EOL] import _csv [EOL] [docstring] [EOL] import argparse [EOL] from collections import defaultdict [EOL] import csv [EOL] import json [EOL] import logging [EOL] import pickle [EOL] from statistics import mean , stdev , StatisticsError [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def fan_stats ( edges ) : [EOL] _avg = mean ( len ( x ) for x in edges . values ( ) ) [EOL] try : [EOL] _std = stdev ( len ( x ) for x in edges . values ( ) ) [EOL] except StatisticsError : [EOL] _std = [number] [EOL] _max = max ( len ( x ) for x in edges . values ( ) ) [EOL] _min = min ( len ( x ) for x in edges . values ( ) ) [EOL] return _avg , _std , _max , _min [EOL] [EOL] [EOL] def readable ( relation , alias_db ) : [EOL] relation_strings = [ ] [EOL] for s in relation . split ( [string] ) : [EOL] if s in alias_db : [EOL] try : [EOL] alias = alias_db [ s ] [ [number] ] [EOL] except IndexError : [EOL] alias = s [EOL] relation_strings . append ( alias ) [EOL] else : [EOL] relation_strings . append ( s ) [EOL] relation = [string] . join ( relation_strings ) [EOL] return relation [EOL] [EOL] [EOL] [EOL] [EOL] def main ( _ ) : [EOL] [EOL] logger . info ( [string] ) [EOL] with open ( FLAGS . alias_db , [string] ) as f : [EOL] alias_db = pickle . load ( f ) [EOL] [EOL] with open ( FLAGS . relation_db , [string] ) as f : [EOL] relation_db = pickle . load ( f ) [EOL] [EOL] [comment] [EOL] def _callable ( ) : [EOL] return defaultdict ( set ) [EOL] [EOL] logger . info ( [string] ) [EOL] wikidata = defaultdict ( _callable ) [EOL] for subject , relations in relation_db . items ( ) : [EOL] for relation , object in relations : [EOL] if object [ [string] ] != [string] : [EOL] continue [EOL] object = object [ [string] ] [ [string] ] [EOL] wikidata [ relation ] [ subject ] . add ( object ) [EOL] [EOL] logger . info ( [string] ) [EOL] annotated_data = defaultdict ( _callable ) [EOL] with open ( FLAGS . input , [string] ) as f : [EOL] for line in f : [EOL] data = json . loads ( line ) [EOL] for annotation in data [ [string] ] : [EOL] subject = annotation [ [string] ] [EOL] relations = annotation [ [string] ] [EOL] objects = annotation [ [string] ] [EOL] for relation , object in zip ( relations , objects ) : [EOL] annotated_data [ relation ] [ subject ] . add ( object ) [EOL] [EOL] logger . info ( [string] ) [EOL] with open ( FLAGS . prefix + [string] , [string] ) as f : [EOL] writer = csv . writer ( f ) [EOL] for relation , edges in wikidata . items ( ) : [EOL] writer . writerow ( [ readable ( relation , alias_db ) , * fan_stats ( edges ) ] ) [EOL] [EOL] with open ( FLAGS . prefix + [string] , [string] ) as f : [EOL] writer = csv . writer ( f ) [EOL] for relation , edges in annotated_data . items ( ) : [EOL] writer . writerow ( [ readable ( relation , alias_db ) , * fan_stats ( edges ) ] ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] , type = str ) [EOL] parser . add_argument ( [string] , type = str ) [EOL] parser . add_argument ( [string] , type = str , default = [string] ) [EOL] parser . add_argument ( [string] , type = str , default = [string] ) [EOL] FLAGS , _ = parser . parse_known_args ( ) [EOL] [EOL] logging . basicConfig ( level = logging . INFO ) [EOL] [EOL] main ( _ ) [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Dict [EOL] import typing [EOL] import argparse [EOL] import logging [EOL] import requests [EOL] [docstring] [EOL] import argparse [EOL] import json [EOL] import logging [EOL] import requests [EOL] [EOL] logger = logging . getLogger ( __name__ ) [comment] [EOL] [EOL] [EOL] def main ( _ ) : [EOL] endpoint = [string] [EOL] headers = { [string] : [string] , [string] : [string] } [EOL] base_params = { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] } [EOL] logger . info ( [string] , endpoint ) [EOL] logger . info ( [string] , headers ) [EOL] with open ( FLAGS . input , [string] ) as f : [EOL] for i , line in enumerate ( f ) : [EOL] if not i % [number] : [EOL] logger . info ( [string] , i ) [EOL] data = json . loads ( line ) [EOL] params = base_params . copy ( ) [EOL] params [ [string] ] = data [ [string] ] [EOL] logger . debug ( [string] , params ) [EOL] [EOL] response = requests . get ( endpoint , params = params , headers = headers ) [EOL] logger . debug ( [string] , response ) [EOL] [EOL] if response . status_code : [EOL] response_json = response . json ( ) [EOL] try : [EOL] html = response_json [ [string] ] [ [string] ] [ [string] ] [EOL] except KeyError : [EOL] html = None [EOL] logger . warning ( [string] , data [ [string] ] ) [EOL] out = { [string] : data [ [string] ] , [string] : html } [EOL] print ( json . dumps ( out ) ) [EOL] else : [EOL] logger . warning ( [string] , data [ [string] ] ) [EOL] del params [EOL] logger . info ( [string] , i + [number] ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] , type = str ) [EOL] parser . add_argument ( [string] , action = [string] ) [EOL] FLAGS , _ = parser . parse_known_args ( ) [EOL] [EOL] if FLAGS . debug : [EOL] LEVEL = logging . DEBUG [EOL] else : [EOL] LEVEL = logging . INFO [EOL] logging . basicConfig ( level = LEVEL ) [EOL] [EOL] main ( _ ) [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0
[comment] [EOL] from typing import Any [EOL] import argparse [EOL] import logging [EOL] import typing [EOL] [docstring] [EOL] import argparse [EOL] import json [EOL] import logging [EOL] import pickle [EOL] import sys [EOL] [EOL] from sqlitedict import SqliteDict [EOL] [EOL] from kglm_data . util import format_wikilink , generate_from_wikidump , load_allowed_entities , LOG_FORMAT [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def main ( _ ) : [EOL] if FLAGS . in_memory : [EOL] db = dict ( ) [EOL] else : [EOL] db = SqliteDict ( FLAGS . db , autocommit = True , journal_mode = [string] ) [EOL] [EOL] for data in generate_from_wikidump ( FLAGS . input ) : [EOL] [EOL] id = data [ [string] ] [EOL] [EOL] try : [EOL] wikilink = data [ [string] ] [ [string] ] [ [string] ] [EOL] except KeyError : [EOL] logger . debug ( [string] , id ) [EOL] continue [EOL] else : [EOL] wikilink = format_wikilink ( wikilink ) [EOL] [EOL] logger . debug ( [string] , id , wikilink ) [EOL] if wikilink in db : [EOL] logger . warning ( [string] , wikilink ) [EOL] [EOL] db [ wikilink ] = id [EOL] [EOL] if FLAGS . in_memory : [EOL] logger . info ( [string] ) [EOL] with open ( FLAGS . db , [string] ) as f : [EOL] pickle . dump ( db , f ) [EOL] else : [EOL] db . commit ( ) [EOL] [EOL] logger . info ( [string] ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] , type = str ) [EOL] parser . add_argument ( [string] , type = str , default = [string] ) [EOL] parser . add_argument ( [string] , action = [string] ) [EOL] parser . add_argument ( [string] , action = [string] ) [EOL] FLAGS , _ = parser . parse_known_args ( ) [EOL] [EOL] if FLAGS . debug : [EOL] LEVEL = logging . DEBUG [EOL] else : [EOL] LEVEL = logging . INFO [EOL] logging . basicConfig ( format = LOG_FORMAT , level = LEVEL ) [EOL] [EOL] main ( _ ) [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0
from typing import Set , Any [EOL] import typing [EOL] import argparse [EOL] import logging [EOL] import kglm_data [EOL] [docstring] [EOL] import argparse [EOL] from collections import Counter [EOL] import json [EOL] import logging [EOL] [EOL] from sqlitedict import SqliteDict [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] class Stats ( ) : [EOL] def __init__ ( self ) : [EOL] self . _prop_counts = Counter ( ) [EOL] self . _p_source_given_new = Counter ( ) [EOL] self . _n = [number] [EOL] self . _n_entities = [number] [EOL] self . _n_tokens = [number] [EOL] self . _n_entity_tokens = [number] [EOL] self . _total_annotations = [number] [EOL] self . _new_entities = [number] [EOL] self . _related_entities = [number] [EOL] self . _reflexive_entities = [number] [EOL] self . _n_wiki = [number] [EOL] self . _n_nel = [number] [EOL] self . _n_coref = [number] [EOL] self . _n_kg = [number] [EOL] self . _max_ent = [number] [EOL] self . _max_len = [number] [EOL] [EOL] def update ( self , data ) : [EOL] self . _n += [number] [EOL] self . _n_tokens += sum ( len ( x ) for x in data [ [string] ] ) [EOL] annotations = data [ [string] ] [EOL] seen = set ( ) [EOL] ml = [number] [EOL] for annotation in annotations : [EOL] self . _n_entities += [number] [EOL] self . _total_annotations += [number] [EOL] relation = annotation [ [string] ] [EOL] if relation == [ [string] ] : [EOL] self . _new_entities += [number] [EOL] self . _p_source_given_new [ annotation [ [string] ] ] += [number] [EOL] if [string] in relation : [EOL] self . _reflexive_entities += [number] [EOL] if any ( r not in [ [string] , [string] ] for r in relation ) : [EOL] self . _related_entities += [number] [EOL] [comment] [EOL] span = annotation [ [string] ] [EOL] span_length = span [ [number] ] - span [ [number] ] [EOL] [EOL] seen . add ( annotation [ [string] ] ) [EOL] ml = max ( ml , span_length ) [EOL] self . _n_entity_tokens += span_length [EOL] source = annotation [ [string] ] [EOL] if source == [string] : [EOL] self . _n_wiki += [number] [EOL] elif source == [string] : [EOL] self . _n_nel += [number] [EOL] elif source == [string] : [EOL] self . _n_coref += [number] [EOL] elif source == [string] : [EOL] self . _n_kg += [number] [EOL] self . _max_ent = max ( self . _max_ent , len ( seen ) ) [EOL] self . _max_len = max ( self . _max_len , ml ) [EOL] [EOL] [EOL] def log ( self ) : [EOL] print ( [string] % self . _n_tokens ) [EOL] print ( [string] % self . _total_annotations ) [EOL] print ( [string] % ( self . _total_annotations / self . _n ) ) [EOL] [comment] [EOL] [comment] [EOL] print ( [string] % ( self . _reflexive_entities / self . _total_annotations ) ) [EOL] [comment] [EOL] [comment] [EOL] print ( [string] % ( self . _n_wiki / self . _n_entities ) ) [EOL] print ( [string] % ( self . _n_nel / self . _n_entities ) ) [EOL] print ( [string] % ( self . _n_coref / self . _n_entities ) ) [EOL] print ( [string] % ( self . _n_kg / self . _n_entities ) ) [EOL] total = sum ( self . _p_source_given_new . values ( ) ) [EOL] for source , count in self . _p_source_given_new . items ( ) : [EOL] print ( [string] % ( source , count / total ) ) [EOL] print ( [string] % ( self . _new_entities / self . _n_entities ) ) [EOL] print ( [string] % ( self . _related_entities / self . _n_entities ) ) [EOL] print ( [string] % self . _max_ent ) [EOL] print ( [string] % self . _max_len ) [EOL] [EOL] [EOL] [EOL] [EOL] def main ( _ ) : [EOL] stats = Stats ( ) [EOL] with open ( FLAGS . input , [string] ) as f : [EOL] for line in f : [EOL] data = json . loads ( line ) [EOL] stats . update ( data ) [EOL] stats . log ( ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] , type = str ) [EOL] parser . add_argument ( [string] , type = str , default = [string] ) [EOL] parser . add_argument ( [string] , action = [string] ) [EOL] FLAGS , _ = parser . parse_known_args ( ) [EOL] [EOL] if FLAGS . debug : [EOL] LEVEL = logging . DEBUG [EOL] else : [EOL] LEVEL = logging . INFO [EOL] [EOL] logging . basicConfig ( level = LEVEL ) [EOL] [EOL] main ( _ ) [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0
from typing import Any , Pattern , Dict , List [EOL] import typing [EOL] import argparse [EOL] [docstring] [EOL] import argparse [EOL] import json [EOL] import re [EOL] [EOL] [EOL] BAD_SPANS = [ [ [string] ] , [ [string] ] ] [EOL] CUTOFF = [number] [EOL] POINT_IN_TIME = re . compile ( [string] ) [EOL] [EOL] [EOL] def main ( args ) : [EOL] with open ( args . dataset , [string] ) as f : [EOL] for line in f : [EOL] data = json . loads ( line ) [EOL] flat_tokens = [ t for s in data [ [string] ] for t in s ] [EOL] clean_annotations = [ ] [EOL] last_seen = dict ( ) [EOL] for annotation in data [ [string] ] : [EOL] start , end = annotation [ [string] ] [EOL] last_seen [ annotation [ [string] ] ] = end [EOL] if flat_tokens [ start : end ] in BAD_SPANS : [EOL] continue [EOL] new_relation = [ ] [EOL] new_parent_id = [ ] [EOL] for relation , parent_id in zip ( annotation [ [string] ] , annotation [ [string] ] ) : [EOL] if POINT_IN_TIME . match ( relation ) : [EOL] continue [EOL] if parent_id not in last_seen : [EOL] continue [EOL] if start - last_seen [ parent_id ] > CUTOFF : [EOL] continue [EOL] new_relation . append ( relation ) [EOL] new_parent_id . append ( parent_id ) [EOL] if len ( new_relation ) == [number] : [EOL] continue [EOL] clean_annotation = annotation . copy ( ) [EOL] clean_annotation [ [string] ] = new_relation [EOL] clean_annotation [ [string] ] = new_parent_id [EOL] clean_annotations . append ( clean_annotation ) [EOL] new_data = data . copy ( ) [EOL] new_data [ [string] ] = clean_annotations [EOL] print ( json . dumps ( new_data ) ) [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] , type = str ) [EOL] args , _ = parser . parse_known_args ( ) [EOL] [EOL] main ( args ) [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.List[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 $typing.Pattern[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.List[builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Pattern[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Set , Generator , List , Any , Dict [EOL] import typing [EOL] import builtins [EOL] import logging [EOL] [docstring] [EOL] from typing import Any , Dict , Generator , List , Set [EOL] import gzip [EOL] import json [EOL] import logging [EOL] [EOL] from tqdm import tqdm [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] LOG_FORMAT = [string] [EOL] [EOL] [EOL] def flatten_tokens ( tokens ) : [EOL] return [ word for sent in tokens for word in sent ] [EOL] [EOL] [EOL] def format_wikilink ( wikilink ) : [EOL] [docstring] [EOL] wikilink = wikilink . replace ( [string] , [string] ) [EOL] if len ( wikilink ) == [number] : [EOL] return wikilink . capitalize ( ) [EOL] else : [EOL] return wikilink [ [number] ] . capitalize ( ) + wikilink [ [number] : ] [EOL] return wikilink [EOL] [EOL] [EOL] def generate_from_wikidump ( fname ) : [EOL] [docstring] [EOL] with gzip . open ( fname ) as f : [EOL] for line in tqdm ( f ) : [EOL] if line [ [number] ] == [string] : [EOL] line = line [ [number] : ] [EOL] elif line [ - [number] ] == [string] : [EOL] line = line [ : - [number] ] [EOL] else : [EOL] line = line [ : - [number] ] [EOL] try : [EOL] data = json . loads ( line ) [EOL] except json . JSONDecodeError : [EOL] logger . warning ( [string] , line ) [EOL] continue [EOL] yield data [EOL] [EOL] [EOL] def load_allowed_entities ( fname ) : [EOL] [docstring] [EOL] if fname is None : [EOL] logger . info ( [string] ) [EOL] return [EOL] else : [EOL] logger . info ( [string] , fname ) [EOL] allowed_entities = set ( ) [EOL] with open ( fname , [string] ) as f : [EOL] for line in f : [EOL] allowed_entities . add ( line . strip ( ) ) [EOL] logger . info ( [string] , len ( allowed_entities ) ) [EOL] return allowed_entities [EOL] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Generator[typing.Dict[builtins.str,typing.Any],None,None]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Set[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0