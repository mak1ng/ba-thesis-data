from typing import List , Any , Dict [EOL] import builtins [EOL] import typing [EOL] import os [EOL] from setuptools import setup , find_packages [EOL] [EOL] [EOL] setup_requirements = [ [string] , [string] ] [EOL] on_rtd = os . environ . get ( [string] ) == [string] [EOL] [EOL] [EOL] def requirements ( fp ) : [EOL] with open ( os . path . join ( os . path . dirname ( __file__ ) , [string] , fp ) ) as f : [EOL] return [ r . strip ( ) for r in f . readlines ( ) if r . strip ( ) and not r . startswith ( [string] ) and not r . startswith ( [string] ) ] [EOL] [EOL] [EOL] extras_require = { [string] : requirements ( [string] ) , [string] : requirements ( [string] ) , [string] : requirements ( [string] ) , [string] : requirements ( [string] ) , } [EOL] extras_require [ [string] ] = extras_require [ [string] ] + extras_require [ [string] ] [EOL] [EOL] install_requires = requirements ( [string] ) [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] if on_rtd : [EOL] install_requires = [ req for req in install_requires if [string] not in req ] [EOL] [EOL] setup ( author = [string] , author_email = [string] , classifiers = [ [string] , [string] , [string] , [string] , [string] , ] , description = [string] , entry_points = { [string] : [ [string] ] } , install_requires = install_requires , license = [string] , name = [string] , packages = find_packages ( ) , setup_requires = setup_requirements , test_suite = [string] , tests_require = extras_require [ [string] ] , extras_require = extras_require , url = [string] , use_scm_version = { [string] : [string] , [string] : __file__ } , zip_safe = True , package_data = { [string] : [ [string] ] } , include_package_data = True , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] from typing import List , Any [EOL] import builtins [EOL] import typing [EOL] from typing import List [EOL] [EOL] import numpy as np [EOL] [EOL] from tests . conftest import gordo_ml_server_client , trained_model_directory , sensors [EOL] [EOL] [EOL] [docstring] [EOL] [EOL] [EOL] def single_post_to_ml_server ( client , path , X ) : [EOL] [docstring] [EOL] resp = client . post ( path , json = { [string] : X } ) [EOL] return resp [EOL] [EOL] [EOL] def test_bench_ml_server_anomaly_post ( benchmark , gordo_ml_server_client , sensors ) : [EOL] [docstring] [EOL] X = np . random . random ( ( [number] , len ( sensors ) ) ) . tolist ( ) [EOL] resp = benchmark . pedantic ( single_post_to_ml_server , args = ( gordo_ml_server_client , [string] , X ) , iterations = [number] , rounds = [number] , ) [EOL] assert resp . status_code == [number] [EOL] [EOL] [EOL] def test_bench_ml_server_base_post ( benchmark , gordo_ml_server_client , sensors ) : [EOL] [docstring] [EOL] X = np . random . random ( ( [number] , len ( sensors ) ) ) . tolist ( ) [EOL] resp = benchmark . pedantic ( single_post_to_ml_server , args = ( gordo_ml_server_client , [string] , X ) , iterations = [number] , rounds = [number] , ) [EOL] assert resp . status_code == [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import List , Any , Type , Dict [EOL] import requests [EOL] import jinja2 [EOL] import benchmarks [EOL] import typing [EOL] import os [EOL] import requests [EOL] import subprocess [EOL] import yaml [EOL] from collections import namedtuple [EOL] [EOL] import numpy as np [EOL] import jinja2 [EOL] import click [EOL] from locust import HttpLocust [EOL] [EOL] from gordo . client . utils import EndpointMetadata [EOL] [EOL] TEMPLATE_FILE = [string] [EOL] Task = namedtuple ( [string] , [string] ) [EOL] [EOL] [EOL] def fetch_metadata ( project_name , host , port , ambassador , watchman_port ) : [EOL] if ambassador : [EOL] data = requests . get ( f"{ host } [string] { port } [string] { project_name } [string] " , proxies = { [string] : None } ) [EOL] else : [EOL] data = requests . get ( f"{ host } [string] { watchman_port }" , proxies = { [string] : None } ) [EOL] [EOL] json_data = yaml . safe_load ( data . content ) [EOL] [EOL] endpoint_metadata = [ EndpointMetadata ( endpoint ) for endpoint in json_data [ [string] ] ] [EOL] tags = { metadata . name : { [string] : len ( metadata . tag_list ) , [string] : len ( metadata . target_tag_list ) , } for metadata in endpoint_metadata } [EOL] [EOL] return tags [EOL] [EOL] [EOL] def generate_random_data ( len_x , len_y , samples = [number] ) : [EOL] if len_y > [number] : [EOL] return { [string] : np . random . random ( ( samples , len_x ) ) . tolist ( ) , [string] : np . random . random ( ( samples , len_y ) ) . tolist ( ) , } [EOL] return { [string] : np . random . random ( ( samples , len_x ) ) . tolist ( ) } [EOL] [EOL] [EOL] def make_tasks ( tags , endpoint ) : [EOL] tasks = list ( ) [EOL] for name , dict_values in tags . items ( ) : [EOL] data = generate_random_data ( dict_values [ [string] ] , dict_values [ [string] ] ) [EOL] path = f" [string] { endpoint } [string] { name } [string] " [EOL] tasks . append ( Task ( name = f" [string] { name . replace ( [string] , [string] ) }" , path = path , json = data ) ) [EOL] [EOL] return tasks [EOL] [EOL] [EOL] @ click . command ( ) @ click . option ( [string] , type = str , help = [string] , required = True ) @ click . option ( [string] , type = str , default = [string] , help = [string] , ) @ click . option ( [string] , type = int , default = [number] , help = [string] ) @ click . option ( [string] , is_flag = True , help = [string] ) @ click . option ( [string] , type = int , default = [number] , help = [string] , ) def main ( project_name , host , port , ambassador , watchman_port ) : [EOL] template_loader = jinja2 . FileSystemLoader ( searchpath = os . path . dirname ( __file__ ) ) [EOL] template_env = jinja2 . Environment ( loader = template_loader ) [EOL] template = template_env . get_template ( TEMPLATE_FILE ) [EOL] [EOL] tags = fetch_metadata ( project_name , host , port , ambassador , watchman_port ) [EOL] tasks = make_tasks ( tags , project_name ) [EOL] path = os . path . join ( os . path . dirname ( __file__ ) , [string] ) [EOL] template . stream ( tasks = tasks ) . dump ( path ) [EOL] [EOL] subprocess . run ( [ [string] , [string] , f"{ __file__ }" , [string] , f"{ host } [string] { port }" ] ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL] [EOL] [EOL] class MyLocust ( HttpLocust ) : [EOL] from benchmarks . load_test . task_set import Tasks [EOL] [EOL] task_set = Tasks [EOL] min_wait = [number] [EOL] max_wait = [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.Type[benchmarks.load_test.load_test.Task]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[benchmarks.load_test.load_test.Task]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[benchmarks.load_test.load_test.MyLocust]$ 0 0 0 0 $typing.Type[benchmarks.load_test.load_test.MyLocust]$ 0 0 0 $builtins.int$ 0 0 0 $builtins.int$ 0 0 0
	0
[comment] [EOL] from typing import List [EOL] import typing [EOL] import os [EOL] import sys [EOL] [EOL] [EOL] def test_formatting_black ( ) : [EOL] project_path = os . path . join ( os . path . dirname ( __file__ ) , [string] ) [EOL] gordo_path = os . path . join ( project_path , [string] ) [EOL] tests_path = os . path . join ( project_path , [string] ) [EOL] cmd = [ sys . executable , [string] , [string] , [string] , [string] , gordo_path , tests_path , [string] , [string] , ] [EOL] exit_code = os . system ( [string] . join ( cmd ) ) [EOL] assert exit_code == [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
[comment] [EOL] [EOL] from typing import Tuple [EOL] import builtins [EOL] import typing [EOL] import pytest [EOL] from typing import Tuple [EOL] [EOL] from gordo import _parse_version , __version__ [EOL] [EOL] [EOL] def test_version ( ) : [EOL] assert isinstance ( __version__ , str ) [EOL] versions = _parse_version ( __version__ ) [EOL] for v in versions : [EOL] assert isinstance ( v , int ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [string] , ( [number] , [number] ) ) , ( [string] , ( [number] , [number] ) ) , ( [string] , ( [number] , [number] ) ) , ( [string] , ( [number] , [number] ) ) , ] , ) def test_version_parser ( version , expected ) : [EOL] assert _parse_version ( version ) == expected [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
[comment] [EOL] [EOL] import pytest [EOL] import numpy as np [EOL] [EOL] from sklearn . ensemble import RandomForestClassifier [EOL] from sklearn . pipeline import Pipeline [EOL] from sklearn . preprocessing import MinMaxScaler [EOL] from sklearn . decomposition import PCA [EOL] [EOL] from gordo . server import model_io [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ RandomForestClassifier ( n_estimators = [number] ) , Pipeline ( [ ( [string] , RandomForestClassifier ( n_estimators = [number] ) ) ] ) , Pipeline ( [ ( [string] , MinMaxScaler ( ) ) , ( [string] , RandomForestClassifier ( n_estimators = [number] ) ) ] ) , Pipeline ( [ ( [string] , PCA ( ) ) ] ) , ] , ) def test_model_mixin_get_model_output ( model ) : [EOL] [docstring] [EOL] X , y = np . random . random ( ( [number] , [number] ) ) , np . random . randint ( low = [number] , high = [number] , size = [number] ) [EOL] model . fit ( X , y ) [EOL] out = model_io . get_model_output ( model , X ) [EOL] assert isinstance ( out , np . ndarray ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Any [EOL] import flask [EOL] import builtins [EOL] import gordo [EOL] import typing [EOL] import prometheus_client [EOL] import pytest [EOL] from flask import Flask [EOL] from mock import patch [EOL] [EOL] from gordo . server . prometheus import GordoServerPrometheusMetrics [EOL] from prometheus_client import CollectorRegistry [EOL] [EOL] [EOL] @ pytest . fixture def registry ( ) : [EOL] return CollectorRegistry ( ) [EOL] [EOL] [EOL] @ pytest . fixture def prometheus_metrics ( registry ) : [EOL] return GordoServerPrometheusMetrics ( args_labels = ( ( [string] , [string] ) , ( [string] , [string] ) ) , info = { [string] : [string] } , ignore_paths = [ [string] ] , registry = registry , ) [EOL] [EOL] [EOL] @ pytest . fixture def gordo_server ( prometheus_metrics ) : [EOL] app = Flask ( [string] ) [EOL] [EOL] @ app . route ( [string] ) def healthcheck ( ) : [EOL] return [string] , [number] [EOL] [EOL] @ app . route ( [string] ) def success ( gordo_project , gordo_name ) : [EOL] return [string] , [number] [EOL] [EOL] @ app . route ( [string] ) def failed ( gordo_project ) : [EOL] return [string] , [number] [EOL] [EOL] with patch ( [string] , side_effect = [ [number] , [number] ] ) : [EOL] prometheus_metrics . prepare_app ( app ) [EOL] [EOL] yield app [EOL] [EOL] [EOL] def test_success ( gordo_server , registry ) : [EOL] client = gordo_server . test_client ( ) [EOL] client . get ( [string] ) [EOL] sample_value = registry . get_sample_value ( [string] , { [string] : [string] } ) [EOL] assert sample_value == [number] , [string] [EOL] sample_value = registry . get_sample_value ( [string] , { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , } , ) [EOL] assert ( sample_value == [number] ) , [string] [EOL] sample_value = registry . get_sample_value ( [string] , { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , } , ) [EOL] assert sample_value == [number] , [string] [EOL] [EOL] [EOL] def test_failed ( gordo_server , registry ) : [EOL] client = gordo_server . test_client ( ) [EOL] client . get ( [string] ) [EOL] sample_value = registry . get_sample_value ( [string] , { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , } , ) [EOL] assert ( sample_value == [number] ) , [string] [EOL] sample_value = registry . get_sample_value ( [string] , { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , } , ) [EOL] assert sample_value == [number] , [string] [EOL] [EOL] [EOL] def test_ignore ( gordo_server , registry ) : [EOL] client = gordo_server . test_client ( ) [EOL] client . get ( [string] ) [EOL] sample_value = registry . get_sample_value ( [string] , { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , [string] : [string] , } , ) [EOL] assert sample_value is None , [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] from typing import Optional , Union , List , Dict , Any [EOL] import logging [EOL] import builtins [EOL] import typing [EOL] import gordo [EOL] import ast [EOL] import json [EOL] import logging [EOL] from io import StringIO [EOL] from datetime import datetime , timezone [EOL] [EOL] import pytest [EOL] import yaml [EOL] [EOL] from gordo import __version__ [EOL] from gordo . machine . dataset . datasets import TimeSeriesDataset [EOL] from gordo . machine import Machine [EOL] from gordo . workflow . config_elements . normalized_config import NormalizedConfig [EOL] from gordo . workflow . workflow_generator . workflow_generator import get_dict_from_yaml [EOL] [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def test_dataset_from_dict ( ) : [EOL] [docstring] [EOL] element_str = [string] [EOL] dataset_config = get_dict_from_yaml ( StringIO ( element_str ) ) [ [string] ] [EOL] dataset = TimeSeriesDataset . from_dict ( dataset_config . copy ( ) ) [EOL] asdict = dataset . to_dict ( ) [EOL] assert asdict [ [string] ] == [ [string] , [string] , [string] , ] [EOL] assert asdict [ [string] ] == [string] [EOL] assert asdict [ [string] ] == [string] [EOL] assert asdict [ [string] ] == [string] [EOL] [EOL] [EOL] def test_dataset_from_config_checks_dates ( ) : [EOL] [docstring] [EOL] element_str = [string] [EOL] dataset_config = yaml . load ( element_str , Loader = yaml . FullLoader ) [ [string] ] [EOL] with pytest . raises ( ValueError ) : [EOL] TimeSeriesDataset . from_dict ( dataset_config ) [EOL] [EOL] [EOL] @ pytest . fixture def default_globals ( ) : [EOL] default_globals = dict ( NormalizedConfig . DEFAULT_CONFIG_GLOBALS ) [EOL] [comment] [EOL] [comment] [EOL] default_globals [ [string] ] = { [string] : { [string] : { [string] : { [string] : [number] , [string] : [number] } , [string] : { [string] : [number] , [string] : [number] } , } } } [EOL] default_globals [ [string] ] = { [string] : [string] } [EOL] return default_globals [EOL] [EOL] [EOL] def test_machine_from_config ( default_globals ) : [EOL] [docstring] [EOL] [EOL] element_str = [string] [EOL] element = get_dict_from_yaml ( StringIO ( element_str ) ) [EOL] machine = Machine . from_config ( element , project_name = [string] , config_globals = default_globals ) [EOL] logger . info ( f"{ machine }" ) [EOL] assert isinstance ( machine , Machine ) [EOL] assert len ( machine . dataset . tag_list ) == [number] [EOL] [EOL] [comment] [EOL] json . dumps ( machine . to_dict ( ) [ [string] ] ) [EOL] [EOL] [comment] [EOL] assert ( ast . literal_eval ( str ( machine . to_dict ( ) [ [string] ] ) ) == machine . to_dict ( ) [ [string] ] ) [EOL] [comment] [EOL] expected = { [string] : { [string] : [string] , [string] : [string] , [string] : { [string] : None , [string] : False , [string] : [string] , [string] : [string] , } , [string] : None , [string] : { [string] : [string] , [string] : [number] , [string] : [number] } , [string] : [number] , [string] : [string] , [string] : [string] , [string] : - [number] , [string] : [number] , [string] : [string] , [string] : [string] , [string] : [number] , [string] : [ [string] , [string] , [string] , ] , [string] : [ [string] ] , [string] : [string] , [string] : [string] , [string] : [string] , } , [string] : { [string] : [string] , [string] : [ [string] , [string] , [string] , [string] , ] , [string] : None , } , [string] : { [string] : { [string] : { [string] : { [string] : None , [string] : { } , [string] : { } , } , [string] : __version__ , [string] : None , [string] : { } , [string] : [number] , [string] : None , } , [string] : { [string] : None , [string] : { } } , } , [string] : { [string] : { } , [string] : { [string] : [string] } , } , } , [string] : { [string] : { [string] : [ [string] , { [string] : { [string] : [string] } } , ] } } , [string] : [string] , [string] : [string] , [string] : { [string] : [ ] , [string] : { [string] : { [string] : { [string] : [number] , [string] : [number] } , [string] : { [string] : [number] , [string] : [number] } , } } , } , } [EOL] assert machine . to_dict ( ) == expected [EOL] [EOL] [EOL] def test_invalid_model ( default_globals ) : [EOL] [docstring] [EOL] element_str = [string] [EOL] element = get_dict_from_yaml ( StringIO ( element_str ) ) [EOL] with pytest . raises ( ValueError ) : [EOL] Machine . from_config ( element , project_name = [string] , config_globals = default_globals ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] from typing import List , Any , Dict , Set [EOL] import logging [EOL] import builtins [EOL] import click [EOL] import gordo [EOL] import typing [EOL] import logging [EOL] import os [EOL] import re [EOL] [EOL] import docker [EOL] import pytest [EOL] import yaml [EOL] from unittest . mock import patch [EOL] from packaging import version [EOL] [EOL] from click . testing import CliRunner [EOL] [EOL] from gordo . workflow . workflow_generator import workflow_generator as wg [EOL] from gordo import cli [EOL] from gordo . workflow . config_elements . normalized_config import NormalizedConfig [EOL] from gordo . machine . dataset import sensor_tag [EOL] [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] @ pytest . fixture ( scope = [string] ) def path_to_config_files ( ) : [EOL] [docstring] [EOL] return os . path . join ( os . path . dirname ( __file__ ) , [string] ) [EOL] [EOL] [EOL] def _generate_test_workflow_yaml ( path_to_config_files , config_filename , project_name = [string] ) : [EOL] [docstring] [EOL] getvalue = _generate_test_workflow_str ( path_to_config_files , config_filename , project_name = project_name ) [EOL] expanded_template = yaml . load ( getvalue , Loader = yaml . FullLoader ) [EOL] [EOL] return expanded_template [EOL] [EOL] [EOL] def _generate_test_workflow_str ( path_to_config_files , config_filename , project_name = [string] ) : [EOL] [docstring] [EOL] config_file = os . path . join ( path_to_config_files , config_filename ) [EOL] args = [ [string] , [string] , [string] , config_file , [string] , project_name , ] [EOL] runner = CliRunner ( ) [EOL] [EOL] with patch . object ( sensor_tag , [string] , return_value = [string] ) : [EOL] result = runner . invoke ( cli . gordo , args ) [EOL] [EOL] if result . exception is not None : [EOL] raise result . exception [EOL] return result . output [EOL] [EOL] [EOL] def _get_env_for_machine_build_serve_task ( machine , expanded_template ) : [EOL] templates = expanded_template [ [string] ] [ [string] ] [EOL] do_all = [ task for task in templates if task [ [string] ] == [string] ] [ [number] ] [EOL] model_builder_machine = [ task for task in do_all [ [string] ] [ [string] ] if task [ [string] ] == f" [string] { machine }" ] [ [number] ] [EOL] model_builder_machine_env = { e [ [string] ] : e [ [string] ] for e in model_builder_machine [ [string] ] [ [string] ] } [EOL] return model_builder_machine_env [EOL] [EOL] [EOL] @ pytest . mark . dockertest def test_argo_lint ( repo_dir , tmpdir , argo_version ) : [EOL] [docstring] [EOL] if version . parse ( argo_version ) >= version . parse ( [string] ) : [EOL] [comment] [EOL] [comment] [EOL] pytest . skip ( [string] % argo_version ) [EOL] [EOL] docker_client = docker . from_env ( ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] config = _generate_test_workflow_yaml ( path_to_config_files = os . path . join ( repo_dir , [string] ) , config_filename = [string] , ) [EOL] assert isinstance ( config , dict ) [EOL] [EOL] workflow_output_path = os . path . join ( tmpdir , [string] ) [EOL] with open ( workflow_output_path , [string] ) as f : [EOL] yaml . dump ( config , f ) [EOL] [EOL] logger . info ( [string] ) [EOL] result = docker_client . containers . run ( f" [string] { argo_version }" , command = [string] , auto_remove = True , stderr = True , stdout = True , detach = False , volumes = { str ( tmpdir ) : { [string] : [string] , [string] : [string] } } , ) [EOL] assert result . decode ( ) . strip ( ) . split ( [string] ) [ - [number] ] == [string] [EOL] [EOL] [EOL] def test_basic_generation ( path_to_config_files ) : [EOL] [docstring] [EOL] [EOL] project_name = [string] [EOL] model_config = [string] [EOL] [EOL] config_filename = [string] [EOL] expanded_template = _generate_test_workflow_str ( path_to_config_files , config_filename , project_name = project_name ) [EOL] [EOL] assert ( project_name in expanded_template ) , f" [string] { project_name } [string] { expanded_template }" [EOL] [EOL] assert ( model_config in expanded_template ) , f" [string] { model_config } [string] { expanded_template }" [EOL] [EOL] yaml_content = wg . get_dict_from_yaml ( os . path . join ( path_to_config_files , config_filename ) ) [EOL] [EOL] with patch . object ( sensor_tag , [string] , return_value = [string] ) : [EOL] machines = NormalizedConfig ( yaml_content , project_name = project_name ) . machines [EOL] [EOL] assert len ( machines ) == [number] [EOL] [EOL] [EOL] def test_generation_to_file ( tmpdir , path_to_config_files ) : [EOL] [docstring] [EOL] project_name = [string] [EOL] config_filename = [string] [EOL] expanded_template = _generate_test_workflow_str ( path_to_config_files , config_filename , project_name = project_name ) [EOL] [EOL] [comment] [EOL] config_file = os . path . join ( path_to_config_files , config_filename ) [EOL] outfile = os . path . join ( tmpdir , [string] ) [EOL] args = [ [string] , [string] , [string] , config_file , [string] , project_name , [string] , outfile , ] [EOL] runner = CliRunner ( ) [EOL] with patch . object ( sensor_tag , [string] , return_value = [string] ) : [EOL] result = runner . invoke ( cli . gordo , args ) [EOL] assert result . exit_code == [number] [EOL] [EOL] [comment] [EOL] with open ( outfile , [string] ) as f : [EOL] outfile_contents = f . read ( ) [EOL] assert outfile_contents . rstrip ( ) == expanded_template . rstrip ( ) [EOL] [EOL] [EOL] def test_quotes_work ( path_to_config_files ) : [EOL] [docstring] [EOL] expanded_template = _generate_test_workflow_yaml ( path_to_config_files , [string] ) [EOL] model_builder_machine_1_env = _get_env_for_machine_build_serve_task ( [string] , expanded_template ) [EOL] [EOL] machine_1_metadata = yaml . safe_load ( model_builder_machine_1_env [ [string] ] ) [EOL] assert machine_1_metadata [ [string] ] [ [string] ] [ [string] ] == { [string] : [string] , [string] : [string] , [string] : [string] , } [EOL] [EOL] machine_1_dataset = yaml . safe_load ( model_builder_machine_1_env [ [string] ] ) [EOL] assert machine_1_dataset [ [string] ] [ [string] ] == [ [string] , [string] , [string] ] [EOL] [EOL] [EOL] def test_overrides_builder_datasource ( path_to_config_files ) : [EOL] expanded_template = _generate_test_workflow_yaml ( path_to_config_files , [string] ) [EOL] [EOL] model_builder_machine_1_env = _get_env_for_machine_build_serve_task ( [string] , expanded_template ) [EOL] model_builder_machine_2_env = _get_env_for_machine_build_serve_task ( [string] , expanded_template ) [EOL] model_builder_machine_3_env = _get_env_for_machine_build_serve_task ( [string] , expanded_template ) [EOL] [EOL] [comment] [EOL] assert { [string] : [string] , [string] : [number] } == yaml . safe_load ( model_builder_machine_1_env [ [string] ] ) [ [string] ] [ [string] ] [EOL] [EOL] [comment] [EOL] assert { [string] : [string] , [string] : [number] } == yaml . safe_load ( model_builder_machine_2_env [ [string] ] ) [ [string] ] [ [string] ] [EOL] [EOL] [comment] [EOL] assert { [string] : [string] , [string] : [number] } == yaml . safe_load ( model_builder_machine_3_env [ [string] ] ) [ [string] ] [ [string] ] [EOL] [EOL] [EOL] def test_runtime_overrides_builder ( path_to_config_files ) : [EOL] expanded_template = _generate_test_workflow_yaml ( path_to_config_files , [string] ) [EOL] templates = expanded_template [ [string] ] [ [string] ] [EOL] model_builder_task = [ task for task in templates if task [ [string] ] == [string] ] [ [number] ] [EOL] model_builder_resource = model_builder_task [ [string] ] [ [string] ] [EOL] [EOL] [comment] [EOL] assert model_builder_resource [ [string] ] [ [string] ] == [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] assert model_builder_resource [ [string] ] [ [string] ] == [string] [EOL] [comment] [EOL] assert model_builder_resource [ [string] ] [ [string] ] == [string] [EOL] [EOL] [EOL] def test_runtime_overrides_client_para ( path_to_config_files ) : [EOL] [docstring] [EOL] expanded_template = _generate_test_workflow_yaml ( path_to_config_files , [string] ) [EOL] templates = expanded_template [ [string] ] [ [string] ] [EOL] client_task = [ task for task in templates if task [ [string] ] == [string] ] [ [number] ] [EOL] [EOL] client_env = { e [ [string] ] : e [ [string] ] for e in client_task [ [string] ] [ [string] ] } [EOL] [EOL] assert client_env [ [string] ] == [string] [EOL] [EOL] [EOL] def test_runtime_overrides_client ( path_to_config_files ) : [EOL] expanded_template = _generate_test_workflow_yaml ( path_to_config_files , [string] ) [EOL] templates = expanded_template [ [string] ] [ [string] ] [EOL] model_client_task = [ task for task in templates if task [ [string] ] == [string] ] [ [number] ] [EOL] model_client_resource = model_client_task [ [string] ] [ [string] ] [EOL] [EOL] [comment] [EOL] assert model_client_resource [ [string] ] [ [string] ] == [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] assert model_client_resource [ [string] ] [ [string] ] == [string] [EOL] [comment] [EOL] assert model_client_resource [ [string] ] [ [string] ] == [string] [EOL] [EOL] [EOL] def test_runtime_overrides_influx ( path_to_config_files ) : [EOL] expanded_template = _generate_test_workflow_yaml ( path_to_config_files , [string] ) [EOL] templates = expanded_template [ [string] ] [ [string] ] [EOL] influx_task = [ task for task in templates if task [ [string] ] == [string] ] [ [number] ] [EOL] influx_statefulset_definition = yaml . load ( influx_task [ [string] ] [ [string] ] , Loader = yaml . FullLoader ) [EOL] influx_resource = influx_statefulset_definition [ [string] ] [ [string] ] [ [string] ] [ [string] ] [ [number] ] [ [string] ] [EOL] [comment] [EOL] assert influx_resource [ [string] ] [ [string] ] == [string] [EOL] [EOL] [comment] [EOL] [comment] [EOL] assert influx_resource [ [string] ] [ [string] ] == [string] [EOL] [comment] [EOL] assert influx_resource [ [string] ] [ [string] ] == [string] [EOL] assert influx_resource [ [string] ] [ [string] ] == [string] [EOL] [EOL] [EOL] def test_disable_influx ( path_to_config_files ) : [EOL] [docstring] [EOL] expanded_template = _generate_test_workflow_yaml ( path_to_config_files , [string] ) [EOL] templates = expanded_template [ [string] ] [ [string] ] [EOL] do_all = [ task for task in templates if task [ [string] ] == [string] ] [ [number] ] [EOL] influx_tasks = [ task [ [string] ] for task in do_all [ [string] ] [ [string] ] if [string] in task [ [string] ] ] [EOL] client_tasks = [ task [ [string] ] for task in do_all [ [string] ] [ [string] ] if [string] in task [ [string] ] ] [EOL] [EOL] [comment] [EOL] assert influx_tasks == [ [string] ] [EOL] assert client_tasks == [ ] [EOL] [EOL] [EOL] def test_selective_influx ( path_to_config_files ) : [EOL] [docstring] [EOL] expanded_template = _generate_test_workflow_yaml ( path_to_config_files , [string] ) [EOL] templates = expanded_template [ [string] ] [ [string] ] [EOL] do_all = [ task for task in templates if task [ [string] ] == [string] ] [ [number] ] [EOL] influx_tasks = [ task [ [string] ] for task in do_all [ [string] ] [ [string] ] if [string] in task [ [string] ] ] [EOL] client_tasks = [ task [ [string] ] for task in do_all [ [string] ] [ [string] ] if [string] in task [ [string] ] ] [EOL] [EOL] [comment] [EOL] assert influx_tasks == [ [string] , [string] ] [EOL] [EOL] [comment] [EOL] assert client_tasks == [ [string] ] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , ( True , False ) ) def test_main_tag_list ( output_to_file , path_to_config_files , tmpdir ) : [EOL] config_file = os . path . join ( path_to_config_files , [string] ) [EOL] args = [ [string] , [string] , [string] , config_file ] [EOL] [EOL] out_file = os . path . join ( tmpdir , [string] ) [EOL] [EOL] if output_to_file : [EOL] args . extend ( [ [string] , out_file ] ) [EOL] [EOL] runner = CliRunner ( ) [EOL] with patch . object ( sensor_tag , [string] , return_value = [string] ) : [EOL] result = runner . invoke ( cli . gordo , args ) [EOL] [EOL] assert result . exit_code == [number] [EOL] [EOL] if output_to_file : [EOL] assert os . path . isfile ( out_file ) [EOL] else : [EOL] output_tags = set ( result . output . split ( sep = [string] ) [ : - [number] ] ) [EOL] expected_output_tags = { [string] , [string] , [string] , [string] , [string] } [EOL] [EOL] assert ( output_tags == expected_output_tags ) , f" [string] { expected_output_tags } [string] { output_tags }" [EOL] [EOL] [EOL] def test_valid_dateformats ( path_to_config_files ) : [EOL] output_workflow = _generate_test_workflow_str ( path_to_config_files , [string] ) [EOL] [comment] [EOL] [comment] [EOL] assert output_workflow . count ( [string] ) == [number] [EOL] assert output_workflow . count ( [string] ) == [number] [EOL] [EOL] [EOL] def test_model_names_embedded ( path_to_config_files ) : [EOL] [docstring] [EOL] output_workflow = _generate_test_workflow_yaml ( path_to_config_files , [string] ) [EOL] parsed_machines = yaml . load ( output_workflow [ [string] ] [ [string] ] [ [string] ] , Loader = yaml . FullLoader , ) [EOL] assert parsed_machines == [ [string] , [string] , [string] ] [EOL] [EOL] [EOL] def test_missing_timezone ( path_to_config_files ) : [EOL] with pytest . raises ( ValueError ) : [EOL] _generate_test_workflow_yaml ( path_to_config_files , [string] ) [EOL] [EOL] with pytest . raises ( ValueError ) : [EOL] _generate_test_workflow_yaml ( path_to_config_files , [string] ) [EOL] [EOL] [EOL] def test_validates_resource_format ( path_to_config_files ) : [EOL] [docstring] [EOL] with pytest . raises ( ValueError ) : [EOL] _generate_test_workflow_str ( path_to_config_files , [string] ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , ( ( [string] , False ) , ( [string] , False ) , ( [string] , True , ) , ) , ) def test_valid_owner_ref ( owner_ref_str , valid ) : [EOL] if valid : [EOL] wg . _valid_owner_ref ( owner_ref_str ) [EOL] else : [EOL] with pytest . raises ( TypeError ) : [EOL] wg . _valid_owner_ref ( owner_ref_str ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , ( ( [string] , [string] ) , ( [string] , [string] ) , ) , ) def test_log_level_key ( test_file , log_level , path_to_config_files ) : [EOL] [docstring] [EOL] workflow_str = _generate_test_workflow_str ( path_to_config_files , test_file ) [EOL] [EOL] [comment] [EOL] gordo_log_levels = re . findall ( [string] , workflow_str ) [EOL] [EOL] [comment] [EOL] assert all ( [ log_level in value for value in gordo_log_levels ] ) [EOL] [EOL] [EOL] def test_expected_models_in_workflow ( repo_dir ) : [EOL] [docstring] [EOL] workflow_str = _generate_test_workflow_str ( path_to_config_files = os . path . join ( repo_dir , [string] ) , config_filename = [string] , ) [EOL] assert [string] in workflow_str [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] expected_models_str = ( workflow_str . split ( [string] ) [ [number] ] . split ( [string] ) [ [number] ] . split ( [string] ) [ [number] ] . split ( ) [ [number] ] ) [EOL] assert isinstance ( yaml . safe_load ( expected_models_str ) , list ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
	0
[comment] [EOL] [EOL] import pathlib [EOL] import pathlib [EOL] [EOL] from gordo . util import disk_registry [EOL] [EOL] [EOL] def test_simple_happy_path ( tmpdir ) : [EOL] [docstring] [EOL] disk_registry . write_key ( tmpdir , [string] , [string] ) [EOL] assert disk_registry . get_value ( tmpdir , [string] ) == [string] [EOL] [EOL] [EOL] def test_new_registry ( tmpdir ) : [EOL] [docstring] [EOL] registry = pathlib . Path ( tmpdir ) . joinpath ( [string] ) [EOL] disk_registry . write_key ( registry , [string] , [string] ) [EOL] assert disk_registry . get_value ( registry , [string] ) == [string] [EOL] [EOL] [EOL] def test_complicated_happy_path ( tmpdir ) : [EOL] [docstring] [EOL] value = [string] [EOL] disk_registry . write_key ( tmpdir , [string] , value ) [EOL] assert disk_registry . get_value ( tmpdir , [string] ) == value [EOL] [EOL] [EOL] def test_overwrites_existing ( tmpdir ) : [EOL] [docstring] [EOL] the_key = [string] [EOL] first_value = [string] [EOL] disk_registry . write_key ( tmpdir , the_key , first_value ) [EOL] assert disk_registry . get_value ( tmpdir , the_key ) == first_value [EOL] second_value = [string] [EOL] disk_registry . write_key ( tmpdir , the_key , second_value ) [EOL] assert disk_registry . get_value ( tmpdir , the_key ) == second_value [EOL] [EOL] [EOL] def test_delete ( tmpdir ) : [EOL] [docstring] [EOL] the_key = [string] [EOL] first_value = [string] [EOL] disk_registry . write_key ( tmpdir , the_key , first_value ) [EOL] assert disk_registry . get_value ( tmpdir , the_key ) == first_value [EOL] [EOL] existed_p = disk_registry . delete_value ( tmpdir , the_key ) [EOL] assert disk_registry . get_value ( tmpdir , the_key ) is None [EOL] [comment] [EOL] assert existed_p [EOL] [EOL] [EOL] def test_double_delete ( tmpdir ) : [EOL] [docstring] [EOL] the_key = [string] [EOL] existed_p = disk_registry . delete_value ( tmpdir , the_key ) [EOL] assert disk_registry . get_value ( tmpdir , the_key ) is None [EOL] assert not existed_p [EOL] [EOL] [EOL] def test_get_value_without_registry_dir ( ) : [EOL] [docstring] [EOL] assert disk_registry . get_value ( None , [string] ) is None [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[EOL] [EOL]	0 0
	0
	0
	0
import builtins [EOL] class DefinitionTestModel : [EOL] @ classmethod def from_definition ( cls , definition ) : [EOL] return cls ( int ( definition . get ( [string] , [number] ) ) ) [EOL] [EOL] def __init__ ( self , depth ) : [EOL] self . depth = depth [EOL] [EOL] def into_definition ( self ) : [EOL] return { [string] : self . depth } [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.dict$ 0 0 0 0 0 0 0 0 $builtins.dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
	0
	0
[comment] [EOL] [EOL] from typing import Any [EOL] import typing [EOL] import unittest [EOL] [EOL] import pytest [EOL] from tensorflow . keras import optimizers [EOL] [EOL] from gordo . machine . model . factories . lstm_autoencoder import ( lstm_model , lstm_symmetric , lstm_hourglass , ) [EOL] [EOL] [EOL] class LSTMAutoEncoderTestCase ( unittest . TestCase ) : [EOL] def test_lstm_defaults ( self ) : [EOL] [docstring] [EOL] [comment] [EOL] base = lstm_model ( [number] ) [EOL] symmetric = lstm_symmetric ( [number] ) [EOL] hourglass = lstm_hourglass ( [number] ) [EOL] [EOL] [comment] [EOL] for i in range ( len ( base . layers ) ) : [EOL] [comment] [EOL] config = base . layers [ i ] . get_config ( ) . update ( { [string] : [string] } ) [EOL] symmetric_config = symmetric . layers [ i ] . get_config ( ) . update ( { [string] : [string] } ) [EOL] hourglass_config = hourglass . layers [ i ] . get_config ( ) . update ( { [string] : [string] } ) [EOL] assert config == symmetric_config [EOL] assert config == hourglass_config [EOL] [EOL] def test_lstm_symmetric_checks_dims ( self ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] with self . assertRaises ( ValueError ) : [EOL] lstm_symmetric ( [number] , dims = ( ) , funcs = ( ) ) [EOL] [EOL] [comment] [EOL] with self . assertRaises ( ValueError ) : [EOL] lstm_symmetric ( [number] , funcs = ( [string] , [string] ) ) [EOL] [EOL] def test_lstm_hourglass_basic ( self ) : [EOL] [docstring] [EOL] [EOL] model = lstm_hourglass ( n_features = [number] , func = [string] , out_func = [string] , optimizer = [string] , optimizer_kwargs = { [string] : [number] , [string] : [number] } , compile_kwargs = { [string] : [string] } , ) [EOL] [EOL] [comment] [EOL] self . assertEqual ( model . layers [ [number] ] . input_shape [ [number] ] , [number] ) [EOL] [EOL] [comment] [EOL] self . assertEqual ( [ model . layers [ i ] . input_shape [ [number] ] for i in range ( [number] , [number] ) ] , [ [number] , [number] , [number] ] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] self . assertEqual ( [ model . layers [ i ] . input_shape [ [number] ] for i in range ( [number] , [number] ) ] , [ [number] , [number] ] ) [EOL] [EOL] [comment] [EOL] self . assertEqual ( model . layers [ [number] ] . input_shape [ [number] ] , [number] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] self . assertEqual ( [ model . layers [ i ] . activation . __name__ for i in range ( [number] , [number] ) ] , [ [string] , [string] , [string] ] , ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] self . assertEqual ( [ model . layers [ i ] . activation . __name__ for i in range ( [number] , [number] ) ] , [ [string] , [string] , [string] ] , ) [EOL] [EOL] [comment] [EOL] self . assertEqual ( model . layers [ [number] ] . activation . __name__ , [string] ) [EOL] [EOL] [comment] [EOL] self . assertEqual ( model . optimizer . __class__ , optimizers . SGD ) [EOL] [EOL] [comment] [EOL] self . assertEqual ( model . loss , [string] ) [EOL] [EOL] def test_lstm_hourglass_checks_enc_layers ( self ) : [EOL] [docstring] [EOL] with self . assertRaises ( ValueError ) : [EOL] lstm_hourglass ( [number] , encoding_layers = [number] ) [EOL] [EOL] def test_lstm_hourglass_checks_compression_factor ( self ) : [EOL] [docstring] [EOL] with self . assertRaises ( ValueError ) : [EOL] lstm_hourglass ( [number] , compression_factor = [number] ) [EOL] with self . assertRaises ( ValueError ) : [EOL] lstm_hourglass ( [number] , compression_factor = - [number] ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , ( [number] , ) ) @ pytest . mark . parametrize ( [string] , ( [number] , [number] , [number] , [number] ) ) def test_lstm_symmetric_basic ( n_features , n_features_out ) : [EOL] [docstring] [EOL] model = lstm_symmetric ( n_features = n_features , n_features_out = n_features_out , lookback_window = [number] , dims = ( [number] , [number] , [number] , [number] ) , funcs = ( [string] , [string] , [string] , [string] ) , out_func = [string] , optimizer = [string] , optimizer_kwargs = { [string] : [number] } , loss = [string] , ) [EOL] [EOL] [comment] [EOL] assert model . layers [ [number] ] . input_shape [ [number] ] == n_features [EOL] [EOL] [comment] [EOL] assert [ model . layers [ i ] . input_shape [ [number] ] for i in range ( [number] , [number] ) ] == [ [number] , [number] , [number] , [number] ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] assert [ model . layers [ i ] . input_shape [ [number] ] for i in range ( [number] , [number] ) ] == [ [number] , [number] , [number] ] [EOL] [EOL] [comment] [EOL] assert model . layers [ [number] ] . input_shape [ [number] ] == [number] [EOL] [EOL] [comment] [EOL] [comment] [EOL] assert [ model . layers [ i ] . activation . __name__ for i in range ( [number] , [number] ) ] == [ [string] , [string] , [string] , [string] , ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] assert [ model . layers [ i ] . activation . __name__ for i in range ( [number] , [number] ) ] == [ [string] , [string] , [string] , [string] , ] [EOL] [EOL] [comment] [EOL] assert model . layers [ [number] ] . activation . __name__ == [string] [EOL] [EOL] [comment] [EOL] assert model . optimizer . __class__ == optimizers . SGD [EOL] [EOL] [comment] [EOL] assert model . loss == [string] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] import builtins [EOL] import unittest [EOL] from unittest import mock [EOL] [EOL] from gordo . machine . model . factories . feedforward_autoencoder import ( feedforward_symmetric , feedforward_hourglass , ) [EOL] [EOL] [EOL] def feedforward_model_mocker ( n_features , n_features_out , encoding_dim , decoding_dim , encoding_func , decoding_func , optimizer , optimizer_kwargs , compile_kwargs , ) : [EOL] return ( n_features , n_features_out , encoding_dim , decoding_dim , encoding_func , decoding_func , optimizer , optimizer_kwargs , compile_kwargs , ) [EOL] [EOL] [EOL] class FeedForwardAutoEncoderTestCase ( unittest . TestCase ) : [EOL] @ mock . patch ( [string] , side_effect = feedforward_model_mocker , ) def test_feedforward_symmetric_basic ( self , _ ) : [EOL] [docstring] [EOL] ( n_features , n_features_out , encoding_dim , decoding_dim , encoding_func , decoding_func , optimizer , optimizer_kwargs , compile_kwargs , ) = feedforward_symmetric ( [number] , [number] , ( [number] , [number] , [number] , [number] ) , ( [string] , [string] , [string] , [string] ) , { } ) [EOL] self . assertEqual ( n_features , [number] ) [EOL] self . assertEqual ( compile_kwargs , { } ) [EOL] self . assertEqual ( encoding_dim , ( [number] , [number] , [number] , [number] ) ) [EOL] self . assertEqual ( decoding_dim , ( [number] , [number] , [number] , [number] ) ) [EOL] self . assertEqual ( encoding_func , ( [string] , [string] , [string] , [string] ) ) [EOL] self . assertEqual ( decoding_func , ( [string] , [string] , [string] , [string] ) ) [EOL] [EOL] def test_feedforward_symmetric_checks_dims ( self ) : [EOL] [docstring] [EOL] with self . assertRaises ( ValueError ) : [EOL] feedforward_symmetric ( [number] , ( ) , ( ) ) [EOL] [EOL] @ mock . patch ( [string] , side_effect = feedforward_model_mocker , ) def test_feedforward_hourglass_basic ( self , _ ) : [EOL] [docstring] [EOL] ( n_features , n_features_out , encoding_dim , decoding_dim , encoding_func , decoding_func , optimizer , optimizer_kwargs , compile_kwargs , ) = feedforward_hourglass ( [number] , [number] , func = [string] ) [EOL] self . assertEqual ( n_features , [number] ) [EOL] self . assertEqual ( n_features_out , [number] ) [EOL] self . assertEqual ( encoding_dim , ( [number] , [number] , [number] ) ) [EOL] self . assertEqual ( decoding_dim , ( [number] , [number] , [number] ) ) [EOL] self . assertEqual ( encoding_func , ( [string] , [string] , [string] ) ) [EOL] self . assertEqual ( decoding_func , ( [string] , [string] , [string] ) ) [EOL] [EOL] ( n_features , n_features_out , encoding_dim , decoding_dim , encoding_func , decoding_func , optimizer , optimizer_kwargs , compile_kwargs , ) = feedforward_hourglass ( [number] , [number] ) [EOL] self . assertEqual ( n_features , [number] ) [EOL] self . assertEqual ( n_features_out , [number] ) [EOL] self . assertEqual ( encoding_dim , ( [number] , [number] , [number] ) ) [EOL] self . assertEqual ( decoding_dim , ( [number] , [number] , [number] ) ) [EOL] self . assertEqual ( encoding_func , ( [string] , [string] , [string] ) ) [EOL] self . assertEqual ( decoding_func , ( [string] , [string] , [string] ) ) [EOL] [EOL] ( n_features , n_features_out , encoding_dim , decoding_dim , encoding_func , decoding_func , optimizer , optimizer_kwargs , compile_kwargs , ) = feedforward_hourglass ( [number] , [number] , compression_factor = [number] ) [EOL] self . assertEqual ( n_features , [number] ) [EOL] self . assertEqual ( n_features_out , [number] ) [EOL] self . assertEqual ( encoding_dim , ( [number] , [number] , [number] ) ) [EOL] self . assertEqual ( decoding_dim , ( [number] , [number] , [number] ) ) [EOL] self . assertEqual ( encoding_func , ( [string] , [string] , [string] ) ) [EOL] self . assertEqual ( decoding_func , ( [string] , [string] , [string] ) ) [EOL] [EOL] @ mock . patch ( [string] , side_effect = feedforward_model_mocker , ) def test_feedforward_hourglass_compression_factors ( self , _ ) : [EOL] [docstring] [EOL] [EOL] [comment] [EOL] ( n_features , n_features_out , encoding_dim , decoding_dim , encoding_func , decoding_func , optimizer , optimizer_kwargs , compile_kwargs , ) = feedforward_hourglass ( [number] , [number] , compression_factor = [number] ) [EOL] self . assertEqual ( n_features , [number] ) [EOL] self . assertEqual ( n_features_out , [number] ) [EOL] self . assertEqual ( encoding_dim , ( [number] , [number] , [number] ) ) [EOL] self . assertEqual ( decoding_dim , ( [number] , [number] , [number] ) ) [EOL] self . assertEqual ( encoding_func , ( [string] , [string] , [string] ) ) [EOL] self . assertEqual ( decoding_func , ( [string] , [string] , [string] ) ) [EOL] [EOL] [comment] [EOL] ( n_features , n_features_out , encoding_dim , decoding_dim , encoding_func , decoding_func , optimizer , optimizer_kwargs , compile_kwargs , ) = feedforward_hourglass ( [number] , [number] , compression_factor = [number] ) [EOL] self . assertEqual ( n_features , [number] ) [EOL] self . assertEqual ( n_features_out , [number] ) [EOL] self . assertEqual ( encoding_dim , ( [number] , [number] , [number] ) ) [EOL] self . assertEqual ( decoding_dim , ( [number] , [number] , [number] ) ) [EOL] self . assertEqual ( encoding_func , ( [string] , [string] , [string] ) ) [EOL] self . assertEqual ( decoding_func , ( [string] , [string] , [string] ) ) [EOL] [EOL] def test_feedforward_hourglass_checks_enc_layers ( self ) : [EOL] [docstring] [EOL] with self . assertRaises ( ValueError ) : [EOL] feedforward_hourglass ( [number] , encoding_layers = [number] ) [EOL] [EOL] def test_feedforward_hourglass_checks_compression_factor ( self ) : [EOL] [docstring] [EOL] with self . assertRaises ( ValueError ) : [EOL] feedforward_hourglass ( [number] , compression_factor = [number] ) [EOL] with self . assertRaises ( ValueError ) : [EOL] feedforward_hourglass ( [number] , compression_factor = - [number] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
[comment] [EOL] [EOL] from typing import Tuple [EOL] import typing [EOL] import pytest [EOL] [EOL] from gordo . machine . model . factories . utils import hourglass_calc_dims , check_dim_func_len [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( ( [number] , [number] , [number] ) , ( [number] , [number] , [number] , [number] ) ) , ( ( [number] , [number] , [number] ) , ( [number] , [number] , [number] ) ) , ( ( [number] , [number] , [number] ) , ( [number] , [number] , [number] ) ) , ( ( [number] , [number] , [number] ) , ( [number] , [number] , [number] ) ) , ( ( [number] , [number] , [number] ) , ( [number] , [number] , [number] ) ) , ( ( [number] , [number] , [number] ) , ( [number] , [number] , [number] ) ) , ] , ) def test_hourglass_calc_dims_check_dims ( test_input , test_expected ) : [EOL] [docstring] [EOL] dims = hourglass_calc_dims ( * test_input ) [EOL] assert dims == test_expected [EOL] [EOL] [EOL] def test_check_dim_func_len ( ) : [EOL] [docstring] [EOL] with pytest . raises ( ValueError ) : [EOL] check_dim_func_len ( [string] , dim = ( [number] , [number] ) , func = ( [string] , [string] , [string] ) ) [EOL] [EOL] with pytest . raises ( ValueError ) : [EOL] check_dim_func_len ( [string] , dim = ( [number] , [number] , [number] ) , func = ( [string] , [string] ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
	0
	0
from typing import Tuple [EOL] import builtins [EOL] import typing [EOL] import logging [EOL] import os [EOL] import traceback [EOL] from typing import Tuple [EOL] import warnings [EOL] [EOL] try : [EOL] from . _version import version as __version__ [EOL] except ImportError : [EOL] __version__ = [string] [EOL] [EOL] [EOL] def _parse_version ( version ) : [EOL] [docstring] [EOL] return tuple ( int ( i ) for i in version . split ( [string] ) [ : [number] ] ) [EOL] [EOL] [EOL] MAJOR_VERSION , MINOR_VERSION = _parse_version ( __version__ ) [EOL] [EOL] try : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] import absl . logging [EOL] [EOL] logging . root . removeHandler ( absl . logging . _absl_handler ) [EOL] absl . logging . _warn_preinit_stderr = False [EOL] [EOL] except Exception : [EOL] warnings . warn ( f" [string] { traceback . format_exc ( ) }" ) [EOL] pass [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 $typing.Tuple[builtins.int,...]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] from typing import Tuple [EOL] import builtins [EOL] import typing [EOL] import math [EOL] from typing import Tuple [EOL] [EOL] [EOL] def hourglass_calc_dims ( compression_factor , encoding_layers , n_features ) : [EOL] [docstring] [EOL] if not ( [number] >= compression_factor >= [number] ) : [EOL] raise ValueError ( [string] ) [EOL] if encoding_layers < [number] : [EOL] raise ValueError ( [string] ) [EOL] smallest_layer = max ( min ( math . ceil ( compression_factor * n_features ) , n_features ) , [number] ) [EOL] diff = n_features - smallest_layer [EOL] average_slope = diff / encoding_layers [EOL] dims = tuple ( round ( n_features - ( i * average_slope ) ) for i in range ( [number] , encoding_layers + [number] ) ) [EOL] return dims [EOL] [EOL] [EOL] def check_dim_func_len ( prefix , dim , func ) : [EOL] [docstring] [EOL] if len ( dim ) != len ( func ) : [EOL] raise ValueError ( f" [string] { prefix } [string] " f" [string] { len ( dim ) } [string] { prefix } [string] { len ( func ) } [string] " f"{ prefix } [string] { prefix } [string] " f" [string] { prefix } [string] " ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.int,...]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] from typing import Any , Tuple , Dict , Union [EOL] import tensorflow [EOL] import builtins [EOL] import typing [EOL] from typing import Tuple , Dict , Any , Union [EOL] [EOL] from tensorflow . keras . optimizers import Optimizer [EOL] from tensorflow . keras import regularizers [EOL] from tensorflow . keras . layers import Dense [EOL] from tensorflow import keras [EOL] [EOL] from tensorflow . keras . models import Sequential as KerasSequential [EOL] from gordo . machine . model . register import register_model_builder [EOL] from gordo . machine . model . factories . utils import hourglass_calc_dims , check_dim_func_len [EOL] [EOL] [EOL] @ register_model_builder ( type = [string] ) def feedforward_model ( n_features , n_features_out = None , encoding_dim = ( [number] , [number] , [number] ) , encoding_func = ( [string] , [string] , [string] ) , decoding_dim = ( [number] , [number] , [number] ) , decoding_func = ( [string] , [string] , [string] ) , out_func = [string] , optimizer = [string] , optimizer_kwargs = dict ( ) , compile_kwargs = dict ( ) , ** kwargs , ) : [EOL] [docstring] [EOL] [EOL] input_dim = n_features [EOL] n_features_out = n_features_out or n_features [EOL] [EOL] check_dim_func_len ( [string] , encoding_dim , encoding_func ) [EOL] check_dim_func_len ( [string] , decoding_dim , decoding_func ) [EOL] [EOL] model = KerasSequential ( ) [EOL] [EOL] [comment] [EOL] for i , ( units , activation ) in enumerate ( zip ( encoding_dim , encoding_func ) ) : [EOL] [EOL] args = { [string] : units , [string] : activation } [EOL] [EOL] if i == [number] : [EOL] args [ [string] ] = input_dim [EOL] else : [EOL] args [ [string] ] = regularizers . l1 ( [number] ) [EOL] [EOL] model . add ( Dense ( ** args ) ) [EOL] [EOL] [comment] [EOL] for i , ( units , activation ) in enumerate ( zip ( decoding_dim , decoding_func ) ) : [EOL] model . add ( Dense ( units = units , activation = activation ) ) [EOL] [EOL] [comment] [EOL] if isinstance ( optimizer , str ) : [EOL] Optim = getattr ( keras . optimizers , optimizer ) [EOL] optimizer = Optim ( ** optimizer_kwargs ) [EOL] [EOL] [comment] [EOL] model . add ( Dense ( n_features_out , activation = out_func ) ) [EOL] [EOL] [comment] [EOL] compile_kwargs . update ( { [string] : optimizer } ) [EOL] compile_kwargs . setdefault ( [string] , [string] ) [EOL] compile_kwargs . setdefault ( [string] , [ [string] ] ) [EOL] [EOL] model . compile ( ** compile_kwargs ) [EOL] return model [EOL] [EOL] [EOL] @ register_model_builder ( type = [string] ) def feedforward_symmetric ( n_features , n_features_out = None , dims = ( [number] , [number] , [number] ) , funcs = ( [string] , [string] , [string] ) , optimizer = [string] , optimizer_kwargs = dict ( ) , compile_kwargs = dict ( ) , ** kwargs , ) : [EOL] [docstring] [EOL] if len ( dims ) == [number] : [EOL] raise ValueError ( [string] ) [EOL] return feedforward_model ( n_features , n_features_out , encoding_dim = dims , decoding_dim = dims [ : : - [number] ] , encoding_func = funcs , decoding_func = funcs [ : : - [number] ] , optimizer = optimizer , optimizer_kwargs = optimizer_kwargs , compile_kwargs = compile_kwargs , ** kwargs , ) [EOL] [EOL] [EOL] @ register_model_builder ( type = [string] ) def feedforward_hourglass ( n_features , n_features_out = None , encoding_layers = [number] , compression_factor = [number] , func = [string] , optimizer = [string] , optimizer_kwargs = dict ( ) , compile_kwargs = dict ( ) , ** kwargs , ) : [EOL] [docstring] [EOL] dims = hourglass_calc_dims ( compression_factor , encoding_layers , n_features ) [EOL] [EOL] return feedforward_symmetric ( n_features , n_features_out , dims = dims , funcs = tuple ( [ func ] * len ( dims ) ) , optimizer = optimizer , optimizer_kwargs = optimizer_kwargs , compile_kwargs = compile_kwargs , ** kwargs , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $tensorflow.keras.models.Sequential$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $tensorflow.keras.models.Sequential$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $tensorflow.keras.models.Sequential$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Any , Union [EOL] import logging [EOL] import datetime [EOL] import io [EOL] import builtins [EOL] import jinja2 [EOL] import typing [EOL] import os [EOL] import yaml [EOL] import dateutil . parser [EOL] import logging [EOL] import jinja2 [EOL] import io [EOL] [EOL] from typing import Union [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def _docker_friendly_version ( version ) : [EOL] [docstring] [EOL] return version . replace ( [string] , [string] ) [EOL] [EOL] [EOL] def _valid_owner_ref ( owner_reference_str ) : [EOL] [docstring] [EOL] owner_ref = yaml . safe_load ( owner_reference_str ) [EOL] if not type ( owner_ref ) == list or len ( owner_ref ) < [number] : [EOL] raise TypeError ( [string] ) [EOL] for oref in owner_ref : [EOL] if ( [string] not in oref or [string] not in oref or [string] not in oref or [string] not in oref ) : [EOL] raise TypeError ( [string] [string] ) [EOL] return owner_ref [EOL] [EOL] [EOL] def _timestamp_constructor ( _loader , node ) : [EOL] parsed_date = dateutil . parser . isoparse ( node . value ) [EOL] if parsed_date . tzinfo is None : [EOL] raise ValueError ( [string] [string] . format ( node . value , node . value + [string] , node . value + [string] ) ) [EOL] return parsed_date [EOL] [EOL] [EOL] def get_dict_from_yaml ( config_file ) : [EOL] [docstring] [EOL] [comment] [EOL] [comment] [EOL] yaml . FullLoader . add_constructor ( tag = [string] , constructor = _timestamp_constructor ) [EOL] if hasattr ( config_file , [string] ) : [EOL] yaml_content = yaml . load ( config_file , Loader = yaml . FullLoader ) [EOL] else : [EOL] try : [EOL] path_to_config_file = os . path . abspath ( config_file ) [comment] [EOL] with open ( path_to_config_file , [string] ) as yamlfile : [comment] [EOL] yaml_content = yaml . load ( yamlfile , Loader = yaml . FullLoader ) [EOL] except FileNotFoundError : [EOL] raise FileNotFoundError ( f" [string] { path_to_config_file } [string] " ) [EOL] [comment] [EOL] if [string] in yaml_content : [EOL] yaml_content = yaml_content [ [string] ] [ [string] ] [EOL] [EOL] return yaml_content [EOL] [EOL] [EOL] def load_workflow_template ( workflow_template ) : [EOL] [docstring] [EOL] path_to_workflow_template = os . path . abspath ( workflow_template ) [EOL] template_dir = os . path . dirname ( path_to_workflow_template ) [EOL] [EOL] templateEnv = jinja2 . Environment ( loader = jinja2 . FileSystemLoader ( template_dir ) , undefined = jinja2 . StrictUndefined ) [EOL] return templateEnv . get_template ( os . path . basename ( workflow_template ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $jinja2.Template$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import List , Any , Tuple [EOL] import typing [EOL] import builtins [EOL] import dictdiffer [EOL] [EOL] [EOL] def patch_dict ( original_dict , patch_dictionary ) : [EOL] [docstring] [EOL] diff = dictdiffer . diff ( original_dict , patch_dictionary ) [EOL] adds_and_mods = [ ( f , d , s ) for ( f , d , s ) in diff if f != [string] ] [EOL] return dictdiffer . patch ( adds_and_mods , original_dict ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
	0
[comment] [EOL] [EOL] from flask import url_for [EOL] from flask_restplus import Api as BaseApi [EOL] [EOL] [EOL] class Api ( BaseApi ) : [EOL] [docstring] [EOL] [EOL] @ property def specs_url ( self ) : [EOL] return url_for ( self . endpoint ( [string] ) , _external = False ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] import logging [EOL] import numpy [EOL] import sklearn [EOL] import logging [EOL] [EOL] import numpy as np [EOL] [EOL] from sklearn . pipeline import Pipeline [EOL] [EOL] [docstring] [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def get_model_output ( model , X ) : [EOL] [docstring] [EOL] try : [EOL] return model . predict ( X ) [comment] [EOL] [EOL] [comment] [EOL] except AttributeError : [EOL] try : [EOL] return model . transform ( X ) [comment] [EOL] except Exception as exc : [EOL] logger . error ( f" [string] { exc }" ) [EOL] raise [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 $numpy.ndarray$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0
	0
from prometheus_client import multiprocess [EOL] [EOL] [EOL] def child_exit ( server , worker ) : [EOL] multiprocess . mark_process_dead ( worker . pid ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import List [EOL] import typing [EOL] from . metrics import GordoServerPrometheusMetrics , current_time [EOL] [EOL] __all__ = [ [string] , [string] ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0
from typing import Optional , Tuple , List , Dict , Iterable , Any [EOL] import flask [EOL] import builtins [EOL] import typing [EOL] import prometheus_client [EOL] import timeit [EOL] [EOL] from copy import copy [EOL] from flask import Flask , g , request , Request , Response [EOL] from typing import Optional , Tuple , List , Dict , Iterable [EOL] from prometheus_client . multiprocess import MultiProcessCollector [EOL] from prometheus_client . registry import CollectorRegistry [EOL] from prometheus_client import Counter , Histogram , Gauge [EOL] from http import HTTPStatus [EOL] [EOL] [EOL] def create_registry ( ) : [EOL] registry = CollectorRegistry ( ) [EOL] MultiProcessCollector ( registry ) [EOL] return registry [EOL] [EOL] [EOL] def to_status_code ( response_status ) : [EOL] if isinstance ( response_status , HTTPStatus ) : [EOL] return response_status . value [EOL] else : [EOL] return response_status [EOL] [EOL] [EOL] def url_rule_to_str ( url_rule ) : [EOL] return url_rule . rule [EOL] [EOL] [EOL] def current_time ( ) : [EOL] return timeit . default_timer ( ) [EOL] [EOL] [EOL] class GordoServerPrometheusMetrics : [EOL] [docstring] [EOL] [EOL] prefix = [string] [EOL] main_labels = ( [string] , [string] , [string] ) [EOL] [EOL] @ staticmethod def main_label_values ( req , resp ) : [EOL] return ( req . method , url_rule_to_str ( req . url_rule ) , to_status_code ( resp . status_code ) , ) [EOL] [EOL] def __init__ ( self , args_labels = None , info = None , ignore_paths = None , registry = None , ) : [EOL] self . args_labels = args_labels if args_labels is not None else [ ] [EOL] if ignore_paths is not None : [EOL] ignore_paths = set ( ignore_paths ) [EOL] self . ignore_paths = ignore_paths if ignore_paths is not None else { } [EOL] self . info = info [EOL] self . label_names = [ ] [EOL] self . label_values = [ ] [EOL] self . args_names = [ ] [EOL] [EOL] if registry is None : [EOL] registry = create_registry ( ) [EOL] self . registry = registry [EOL] self . init_labels ( ) [EOL] self . request_duration_seconds = Histogram ( [string] % self . prefix , [string] , self . label_names , registry = registry , ) [EOL] self . request_count = Counter ( [string] % self . prefix , [string] , self . label_names , registry = registry , ) [EOL] [EOL] def init_labels ( self ) : [EOL] label_names , label_values = [ ] , [ ] [EOL] if self . info is not None : [EOL] for name , value in self . info . items ( ) : [EOL] label_names . append ( name ) [EOL] label_values . append ( value ) [EOL] gauge_info = Gauge ( self . prefix + [string] , [string] , label_names , registry = self . registry , ) [EOL] gauge_info = gauge_info . labels ( * label_values ) [EOL] gauge_info . set ( [number] ) [EOL] args_names = [ ] [EOL] for arg_name , label_name in self . args_labels : [EOL] args_names . append ( arg_name ) [EOL] label_names . append ( label_name ) [EOL] self . args_names = args_names [EOL] label_names . extend ( self . main_labels ) [EOL] self . label_names = label_names [EOL] self . label_values = label_values [EOL] [EOL] def request_label_values ( self , req , resp ) : [EOL] label_values = copy ( self . label_values ) [EOL] view_args = req . view_args [EOL] for arg_name in self . args_names : [EOL] value = view_args . get ( arg_name , [string] ) if view_args is not None else [string] [EOL] label_values . append ( value ) [EOL] label_values . extend ( self . main_label_values ( req , resp ) ) [EOL] return label_values [EOL] [EOL] def prepare_app ( self , app ) : [EOL] @ app . before_request def _start_prometheus ( ) : [EOL] g . prometheus_metrics = self [EOL] g . prometheus_start_time = current_time ( ) [EOL] [EOL] @ app . after_request def _end_prometheus ( response ) : [EOL] url_rule = url_rule_to_str ( request . url_rule ) [EOL] if self . ignore_paths is not None and url_rule in self . ignore_paths : [EOL] return response [EOL] label_values = self . request_label_values ( request , response ) [EOL] self . request_duration_seconds . labels ( * label_values ) . observe ( current_time ( ) - g . prometheus_start_time ) [EOL] self . request_count . labels ( * label_values ) . inc ( [number] ) [EOL] del g . prometheus_metrics [EOL] return response [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.Tuple[builtins.str,builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $flask.Request$ 0 $flask.Response$ 0 0 0 0 0 $flask.Request$ 0 0 0 0 0 $flask.Request$ 0 0 0 0 0 0 $flask.Response$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.Dict[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.Dict[builtins.str,builtins.str]]$ 0 $typing.Optional[typing.Dict[builtins.str,builtins.str]]$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 $typing.List[builtins.str]$ 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 $typing.List[builtins.str]$ 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 $typing.List[builtins.str]$ 0 0 0 $typing.List[builtins.str]$ 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 $flask.Request$ 0 $flask.Response$ 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 $flask.Request$ 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Any]$ 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 $typing.Any$ 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 $flask.Request$ 0 $flask.Response$ 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 $flask.Flask$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $flask.Response$ 0 $flask.Response$ 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $flask.Response$ 0 $typing.Any$ 0 0 0 0 0 0 0 $flask.Response$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $flask.Response$ 0
from . disk_registry import get_value , write_key [EOL] from . utils import capture_args [EOL] from . text import replace_all_non_ascii_chars [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Pattern [EOL] import typing [EOL] import builtins [EOL] import re [EOL] [EOL] non_ascii_re = re . compile ( [string] ) [EOL] [EOL] [EOL] def replace_all_non_ascii_chars ( s , replace_with = [string] ) : [EOL] return non_ascii_re . sub ( replace_with , s ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Pattern[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $typing.Pattern[builtins.str]$ 0 0 0 0 0 0 0 0
from typing import Tuple , AbstractSet , Dict , Callable , Any [EOL] import inspect [EOL] import typing [EOL] import functools [EOL] import inspect [EOL] from typing import Callable [EOL] [EOL] [EOL] def capture_args ( method ) : [EOL] [docstring] [EOL] [EOL] @ functools . wraps ( method ) def wrapper ( self , * args , ** kwargs ) : [EOL] [EOL] sig_params = inspect . signature ( method ) . parameters . items ( ) [EOL] [EOL] [comment] [EOL] params = { param : value . default for param , value in sig_params if value . default is not inspect . Parameter . empty and param != [string] } [EOL] [EOL] [comment] [EOL] arg_map = dict ( ) [EOL] for arg_val , arg_key in zip ( args , ( arg for arg in inspect . getfullargspec ( method ) . args if arg != [string] ) ) : [EOL] arg_map [ arg_key ] = arg_val [EOL] [EOL] [comment] [EOL] params . update ( arg_map ) [EOL] params . update ( kwargs ) [EOL] [EOL] self . _params = params [EOL] return method ( self , * args , ** kwargs ) [EOL] [EOL] return wrapper [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Optional , AnyStr , Union [EOL] import os [EOL] import logging [EOL] import pathlib [EOL] import builtins [EOL] import typing [EOL] import os [EOL] from pathlib import Path [EOL] from typing import Union , AnyStr , Optional [EOL] [EOL] import logging [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [docstring] [EOL] [EOL] [EOL] def write_key ( registry_dir , key , val ) : [EOL] [docstring] [EOL] key_file_path = Path ( registry_dir ) . joinpath ( key ) [EOL] logger . info ( f" [string] { key } [string] { key_file_path }" ) [EOL] [comment] [EOL] if key_file_path . exists ( ) : [EOL] logger . warning ( f" [string] { key } [string] " f" [string] " ) [EOL] elif not Path ( registry_dir ) . exists ( ) : [EOL] logger . debug ( f" [string] { registry_dir } [string] " ) [EOL] [comment] [EOL] [comment] [EOL] os . makedirs ( registry_dir , exist_ok = True ) [EOL] with key_file_path . open ( mode = [string] ) as f : [EOL] f . write ( val ) [comment] [EOL] [EOL] [EOL] def get_value ( registry_dir , key ) : [EOL] [docstring] [EOL] output_val = None [EOL] [EOL] if registry_dir is None : [EOL] return output_val [EOL] [EOL] key_file_path = Path ( registry_dir ) . joinpath ( key ) [EOL] logger . info ( f" [string] { key } [string] " f"{ key_file_path }" ) [EOL] [comment] [EOL] if key_file_path . exists ( ) : [EOL] with key_file_path . open ( mode = [string] ) as f : [EOL] output_val = f . read ( ) [EOL] logger . debug ( f" [string] { output_val } [string] " ) [EOL] else : [EOL] logger . info ( f" [string] { key } [string] { key_file_path }" ) [EOL] return output_val [comment] [EOL] [EOL] [EOL] def delete_value ( registry_dir , key ) : [EOL] [docstring] [EOL] key_file_path = Path ( registry_dir ) . joinpath ( key ) [EOL] logger . info ( f" [string] { key } [string] " f"{ key_file_path }" ) [EOL] [comment] [EOL] if key_file_path . exists ( ) : [EOL] key_file_path . unlink ( ) [EOL] logger . debug ( f" [string] { key } [string] " ) [EOL] return True [EOL] else : [EOL] logger . info ( f" [string] { key } [string] { key_file_path }" ) [EOL] return False [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.AnyStr]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.bool$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
class ReporterException ( Exception ) : [EOL] pass [EOL]	0 0 0 0 0 0 0 0 0
	0