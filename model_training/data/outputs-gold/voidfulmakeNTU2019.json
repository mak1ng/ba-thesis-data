	0
from typing import Tuple , Dict , Optional , Any , List [EOL] import typing [EOL] import requests [EOL] import sys [EOL] from dotenv import load_dotenv [EOL] [EOL] load_dotenv ( ) [EOL] import string [EOL] from urllib . parse import quote [EOL] import os [EOL] from requests import get [EOL] from libextract . api import extract [EOL] from selenium import webdriver [EOL] from time import sleep [EOL] import requests [EOL] from gsearch . googlesearch import search [EOL] from elasticsearch import Elasticsearch [EOL] from nlp2 import * [EOL] from pyfasttext import FastText [EOL] [EOL] es = Elasticsearch ( os . getenv ( [string] ) ) [EOL] model = FastText ( os . getenv ( [string] ) ) [EOL] model_size = [number] [EOL] [EOL] sys . path . insert ( [number] , [string] ) [EOL] chrome_options = webdriver . ChromeOptions ( ) [EOL] chrome_options . add_argument ( [string] ) [EOL] chrome_options . add_argument ( [string] ) [EOL] chrome_options . add_argument ( [string] ) [EOL] wd = webdriver . Chrome ( [string] , options = chrome_options ) [EOL] [EOL] [EOL] def find_most_match_passage ( question , passages ) : [EOL] ques = doc2vec_aver ( model , model_size , spilt_sentence_to_array ( question , True ) ) [EOL] most_p = [string] [EOL] most_s = [number] [EOL] for i in passages : [EOL] for j in passage_into_chunk ( i , int ( os . getenv ( [string] ) ) ) : [EOL] passa = doc2vec_aver ( model , model_size , spilt_sentence_to_array ( j , True ) ) [EOL] score = cosine_similarity ( ques , passa ) [EOL] if score > most_s : [EOL] most_p = j [EOL] most_s = score [EOL] return most_p , most_s [EOL] [EOL] [EOL] def rank_question_passage ( question , passages ) : [EOL] ques = doc2vec_aver ( model , model_size , spilt_sentence_to_array ( question , True ) ) [EOL] result_dict = dict ( ) [EOL] for i in passages : [EOL] for j in passage_into_chunk ( i , int ( os . getenv ( [string] ) ) ) : [EOL] passa = doc2vec_aver ( model , model_size , spilt_sentence_to_array ( j , True ) ) [EOL] score = cosine_similarity ( ques , passa ) [EOL] result_dict [ j ] = score [EOL] return result_dict [EOL] [EOL] [EOL] def elastic_search_index ( search_term , index = [string] , max_doc = [number] ) : [EOL] result = [ ] [EOL] res = es . search ( index = index ) [EOL] res = es . search ( index = res [ [string] ] [ [string] ] [ [number] ] [ [string] ] [ [string] ] , body = { [string] : { [string] : { [string] : search_term } } } ) [EOL] for doc in res [ [string] ] [ [string] ] [ : max_doc ] : [EOL] rs = { [string] : doc [ [string] ] [ [string] ] , [string] : doc [ [string] ] } [EOL] result . append ( rs ) [EOL] return result [EOL] [EOL] [EOL] def elastic_search_all ( search_term , index = [string] , max_doc = [number] ) : [EOL] result = [ ] [EOL] res = es . search ( index = index , body = { [string] : { [string] : { [string] : [ { [string] : { [string] : search_term } } ] } } } ) [EOL] [EOL] print ( [string] % res [ [string] ] [ [string] ] ) [EOL] doc = res [ [string] ] [ [string] ] [ [number] ] [EOL] res = es . search ( index = doc [ [string] ] [ [string] ] , body = { [string] : { [string] : { [string] : search_term } } } ) [EOL] for doc in res [ [string] ] [ [string] ] [ : max_doc ] : [EOL] rs = { [string] : doc [ [string] ] [ [string] ] , [string] : doc [ [string] ] } [EOL] result . append ( rs ) [EOL] return result [EOL] [EOL] [EOL] def microsoft ( search_term , max_doc = [number] ) : [EOL] result = [ ] [EOL] subscription_key = os . getenv ( [string] ) [EOL] search_url = os . getenv ( [string] ) [EOL] [EOL] headers = { [string] : subscription_key } [EOL] params = { [string] : search_term , [string] : True , [string] : [string] } [EOL] response = requests . get ( search_url , headers = headers , params = params ) [EOL] response . raise_for_status ( ) [EOL] search_results = response . json ( ) [EOL] [EOL] for i in search_results [ [string] ] [ [string] ] [ : max_doc ] : [EOL] wd . get ( i [ [string] ] ) [EOL] sleep ( [number] ) [EOL] textnodes = list ( extract ( wd . page_source . encode ( [string] ) ) ) [EOL] result . append ( [string] . join ( [ elem . text_content ( ) for elem in textnodes ] ) ) [EOL] [EOL] rank = rank_question_passage ( search_term , result ) [EOL] sort = [ ( k , rank [ k ] ) for k in sorted ( rank , key = rank . get , reverse = True ) ] [EOL] return [ { [string] : p , [string] : s } for p , s in sort ] [EOL] [EOL] [EOL] def google ( search_term , max_doc = [number] ) : [EOL] result = [ ] [EOL] search_term += [string] [EOL] response = search ( search_term , num_results = max_doc ) [EOL] for i in response : [EOL] url = quote ( i [ [number] ] , safe = string . printable ) [EOL] wd . get ( url ) [EOL] sleep ( [number] ) [EOL] textnodes = list ( extract ( wd . page_source . encode ( [string] ) ) ) [EOL] result . append ( [string] . join ( [ elem . text_content ( ) for elem in textnodes ] ) ) [EOL] rank = rank_question_passage ( search_term , result ) [EOL] sort = [ ( k , rank [ k ] ) for k in sorted ( rank , key = rank . get , reverse = True ) ] [EOL] return [ { [string] : p , [string] : s } for p , s in sort ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0