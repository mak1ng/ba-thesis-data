[comment] [EOL] [EOL] import asyncio [EOL] import influxdb_sync [EOL] [docstring] [EOL] import sys [EOL] import click [EOL] import functools [EOL] import asyncio [EOL] [EOL] from aioinflux import InfluxDBClient [EOL] [EOL] from . import sync [EOL] [EOL] [EOL] def async_cli ( f ) : [EOL] def wrapper ( * args , ** kwargs ) : [EOL] loop = asyncio . get_event_loop ( ) [EOL] return loop . run_until_complete ( f ( * args , ** kwargs ) ) [EOL] return functools . update_wrapper ( wrapper , f ) [EOL] [EOL] [EOL] @ click . command ( ) @ click . option ( [string] , default = [string] ) @ click . option ( [string] , default = [string] ) @ click . option ( [string] , default = [number] ) @ click . option ( [string] , default = [number] ) @ click . option ( [string] , default = None ) @ click . option ( [string] , default = None ) @ click . option ( [string] , default = None ) @ click . option ( [string] , default = None ) @ click . option ( [string] ) @ async_cli async def main ( src , dst , src_port , dst_port , src_username , dst_username , src_password , dst_password , db , args = None ) : [EOL] print ( src , dst , src_port , dst_port ) [EOL] async with InfluxDBClient ( host = src , port = src_port , username = src_username , password = src_password , db = db ) as src_client : [EOL] async with InfluxDBClient ( host = dst , port = dst_port , username = dst_username , password = dst_password , db = db ) as dst_client : [EOL] await dst_client . create_database ( db = db ) [EOL] syncer = sync . Synchronizer ( src_client , dst_client , db , db ) [EOL] await syncer . run ( ) [EOL] [EOL] return [number] [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] sys . exit ( main ( ) ) [comment] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Set , Dict , List , Coroutine , Type , Union [EOL] import builtins [EOL] import aioinflux [EOL] import typing [EOL] import logging [EOL] import influxdb_sync [EOL] import time [EOL] import logging [EOL] import collections [EOL] import asyncio [EOL] [EOL] import aioinflux [EOL] [EOL] [EOL] LOG = logging . getLogger ( __name__ ) [EOL] [comment] [EOL] [EOL] [EOL] async def get_date ( client , measurement , order ) : [EOL] query = f' [string] { measurement . measurement_name } [string] { order } [string] ' [EOL] try : [EOL] results = await client . query ( query ) [EOL] return date_from_result ( results ) [EOL] except aioinflux . client . InfluxDBError : [EOL] return None [EOL] [EOL] [EOL] def date_from_result ( results ) : [EOL] results = results . get ( [string] , results ) [EOL] series = results [ [number] ] . get ( [string] ) [EOL] if series : [EOL] values = series [ [number] ] [ [string] ] [EOL] return values [ [number] ] [ [number] ] [EOL] return None [EOL] [EOL] [EOL] class Synchronizer : [EOL] def __init__ ( self , src_client , dst_client , src_db = None , dst_db = None , max_queue_size = [number] ) : [EOL] self . src_client = src_client [EOL] self . dst_client = dst_client [EOL] self . backlog = asyncio . Queue ( maxsize = max_queue_size ) [EOL] self . src_db = src_db [EOL] self . dst_db = dst_db [EOL] self . src_batch_size = [number] [EOL] self . dst_batch_combiner = [number] [EOL] self . stats_data_send = [number] [EOL] self . stats_time = time . time ( ) [EOL] self . consumer_count = [number] [EOL] self . producer_count = [number] [EOL] self . reset_stats ( ) [EOL] [EOL] def reset_stats ( self ) : [EOL] self . skipped_points = [number] [EOL] self . modified_points = [number] [EOL] [EOL] async def run ( self ) : [EOL] self . running = True [EOL] self . _stats_task = asyncio . create_task ( self . write_stats ( ) ) [EOL] self . _consume_task = asyncio . create_task ( self . consume ( ) ) [EOL] await asyncio . gather ( self . produce ( ) , self . _stats_task , self . _consume_task ) [EOL] [EOL] async def write_stats ( self ) : [EOL] while self . running : [EOL] try : [EOL] await asyncio . sleep ( [number] ) [EOL] except asyncio . CancelledError : [EOL] return [EOL] [EOL] now = time . time ( ) [EOL] points_per_second = self . stats_data_send / ( now - self . stats_time ) / [number] [EOL] skipped_points = self . skipped_points / [number] [EOL] modified_points = self . modified_points / [number] [EOL] print ( f' [string] { self . backlog . qsize ( ) } [string] ' f' [string] { skipped_points : [string] } [string] ' f' [string] { modified_points : [string] } [string] ' f' [string] { points_per_second : [string] } [string] ' ) [EOL] self . stats_data_send = [number] [EOL] self . stats_time = now [EOL] [EOL] async def produce ( self ) : [EOL] self . _producer_sem = asyncio . Semaphore ( self . producer_count ) [EOL] [EOL] if not hasattr ( self . src_client , [string] ) : [EOL] self . src_client . db_info = await DataBaseInfo . from_db ( self . src_client , self . dst_db ) [EOL] [EOL] for measurement in self . src_client . db_info . measurements . values ( ) : [EOL] await self . series_producer ( measurement ) [EOL] [EOL] LOG . debug ( [string] ) [EOL] for _ in range ( self . producer_count ) : [EOL] await self . _producer_sem . acquire ( ) [EOL] [EOL] self . running = False [EOL] [EOL] [EOL] async def series_producer ( self , measurement ) : [EOL] query = f' [string] { measurement . measurement_name } [string] ' [EOL] result = await self . src_client . query ( query ) [EOL] cardinality = result [ [string] ] [ [number] ] [ [string] ] [ [number] ] [ [string] ] [ [number] ] [ [number] ] [EOL] [EOL] print ( f' [string] { measurement . measurement_name } [string] { cardinality } [string] ' ) [EOL] [EOL] for soffset in range ( cardinality ) : [EOL] worker = self . produce_series ( measurement , soffset ) [EOL] await self . _producer_sem . acquire ( ) [EOL] [EOL] [comment] [EOL] asyncio . ensure_future ( worker ) [EOL] [comment] [EOL] [EOL] async def produce_series ( self , measurement , soffset ) : [EOL] try : [EOL] await self . _produce_worker ( measurement , soffset ) [EOL] finally : [EOL] self . _producer_sem . release ( ) [EOL] [EOL] async def _produce_worker ( self , measurement , soffset ) : [EOL] select_clause = f' [string] { measurement . measurement_name } [string] ' [EOL] slimit_clause = f' [string] { soffset }' [EOL] start_time = [number] [EOL] [EOL] max_offset_multiplier = [number] [EOL] check_offset = self . src_batch_size * max_offset_multiplier [EOL] tags_clause = [string] [EOL] [EOL] while True : [EOL] query_base = f'{ select_clause } [string] { start_time }' [EOL] group_by = [string] [EOL] compare_query = f'{ query_base } [string] { group_by } [string] { check_offset } [string] { slimit_clause }' [EOL] [EOL] src = await self . src_client . query ( compare_query ) [EOL] if [string] in src [ [string] ] [ [number] ] : [EOL] [comment] [EOL] tags = src [ [string] ] [ [number] ] [ [string] ] [ [number] ] [ [string] ] [EOL] tags = [ f'{ k } [string] { repr ( v ) }' for k , v in tags . items ( ) ] [EOL] tags_clause = [string] . join ( tags ) [EOL] if start_time == [number] : [EOL] print ( tags_clause ) [EOL] query = f'{ query_base } [string] { tags_clause } [string] { group_by } [string] { check_offset }' [EOL] dst = await self . dst_client . query ( query ) [EOL] [EOL] [comment] [EOL] src [ [string] ] [ [number] ] [ [string] ] = [ src [ [string] ] [ [number] ] [ [string] ] [ [number] ] ] [EOL] [EOL] if src == dst : [EOL] [comment] [EOL] start_time = date_from_result ( src ) [EOL] self . skipped_points += check_offset [EOL] self . stats_data_send += check_offset [EOL] if check_offset < self . src_batch_size * max_offset_multiplier : [EOL] check_offset *= [number] [EOL] continue [EOL] else : [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] pass [EOL] else : [EOL] if max_offset_multiplier != [number] : [EOL] check_offset = self . src_batch_size [EOL] max_offset_multiplier /= [number] [EOL] continue [EOL] [EOL] [EOL] check_offset = self . src_batch_size [EOL] [EOL] query = f'{ query_base } [string] { group_by } [string] { self . src_batch_size } [string] { slimit_clause }' [EOL] entries = await self . _produce_from_query ( measurement , query ) [EOL] [EOL] await self . backlog . put ( entries ) [EOL] if len ( entries ) < self . src_batch_size : [EOL] LOG . debug ( [string] , measurement . measurement_name , soffset ) [EOL] print ( tags_clause , [string] ) [EOL] return [EOL] [EOL] start_time = entries [ - [number] ] [ [string] ] [EOL] [EOL] [EOL] async def _produce_from_query ( self , measurement , query ) : [EOL] results = await self . src_client . query ( query ) [EOL] entries = [ ] [EOL] for result in results [ [string] ] : [EOL] for series in result . get ( [string] , [ ] ) : [EOL] columns = series [ [string] ] [EOL] tags = series . get ( [string] , { } ) [EOL] for row in series [ [string] ] : [EOL] entry = { [string] : measurement . measurement_name , [string] : tags , [string] : { } } [EOL] for i , key in enumerate ( columns ) : [EOL] value = row [ i ] [EOL] if key == [string] : [EOL] entry [ [string] ] = value [EOL] [comment] [EOL] [comment] [EOL] elif value is not None : [EOL] entry [ [string] ] [ key ] = measurement . values [ key ] ( value ) [EOL] else : [EOL] entry [ [string] ] [ key ] = None [EOL] [EOL] entries . append ( entry ) [EOL] [EOL] return entries [EOL] [EOL] async def consume ( self ) : [EOL] consumers = [ ] [EOL] for _ in range ( self . consumer_count ) : [EOL] consumers . append ( self . _consume ( ) ) [EOL] [EOL] try : [EOL] await asyncio . gather ( * consumers ) [EOL] except asyncio . CancelledError : [EOL] pass [EOL] [EOL] def _check_done ( self ) : [EOL] if self . backlog . empty ( ) : [EOL] self . _stats_task . cancel ( ) [EOL] self . _consume_task . cancel ( ) [EOL] [EOL] async def _consume ( self ) : [EOL] while self . running or not self . backlog . empty ( ) : [EOL] batch = await self . backlog . get ( ) [EOL] [EOL] for _ in range ( self . dst_batch_combiner - [number] ) : [EOL] try : [EOL] batch += self . backlog . get_nowait ( ) [EOL] except asyncio . queues . QueueEmpty : [EOL] break [EOL] [EOL] try : [EOL] await asyncio . shield ( self . dst_client . write ( batch ) ) [EOL] point_count = len ( batch ) [EOL] self . stats_data_send += point_count [EOL] self . modified_points += point_count [EOL] except asyncio . CancelledError : [EOL] return [EOL] except Exception as e : [EOL] print ( [string] , len ( batch ) ) [EOL] [comment] [EOL] asyncio . ensure_future ( self . requeue ( batch ) ) [EOL] await asyncio . sleep ( [number] ) [EOL] print ( e ) [EOL] self . backlog . task_done ( ) [EOL] self . _check_done ( ) [EOL] [EOL] async def requeue ( self , entries ) : [EOL] for i in range ( [number] , len ( entries ) , [number] ) : [EOL] await self . backlog . put ( entries [ i : i + [number] ] ) [EOL] [EOL] [EOL] class MeasurementInfo : [EOL] type_map = { [string] : float , [string] : str , [string] : int , [string] : bool } [EOL] [EOL] def __init__ ( self , db_name , measurement_name , tags , values ) : [EOL] self . db_name = db_name [EOL] self . measurement_name = measurement_name [EOL] self . tags = tags [EOL] self . values = values [EOL] [EOL] @ classmethod async def from_db ( self , client , db_name , measurement_name ) : [EOL] [comment] [EOL] query = f' [string] { db_name } [string] { measurement_name } [string] ' [EOL] keys_result = await client . query ( query ) [EOL] [EOL] query = f' [string] { db_name } [string] { measurement_name } [string] ' [EOL] values_result = await client . query ( query ) [EOL] [EOL] key_names = set ( ) [EOL] for result in keys_result [ [string] ] : [EOL] for series in result [ [string] ] : [EOL] assert series [ [string] ] == [ [string] ] [EOL] for value in series [ [string] ] : [EOL] key_names . add ( value [ [number] ] ) [EOL] [EOL] [EOL] value_types = { } [EOL] for result in values_result [ [string] ] : [EOL] for series in result [ [string] ] : [EOL] assert series [ [string] ] == [ [string] , [string] ] [EOL] for field_key , field_type in series [ [string] ] : [EOL] value_types [ field_key ] = self . type_map [ field_type ] [EOL] [EOL] return MeasurementInfo ( db_name , measurement_name , key_names , value_types ) [EOL] [EOL] [EOL] class DataBaseInfo : [EOL] def __init__ ( self ) : [EOL] self . measurements = { } [EOL] [EOL] @ classmethod async def from_db ( cls , client , db_name ) : [EOL] [comment] [EOL] query = f' [string] { db_name } [string] ' [EOL] measurements = await client . query ( query ) [EOL] [EOL] measurement_names = [ ] [EOL] for result in measurements [ [string] ] : [EOL] for series in result [ [string] ] : [EOL] assert series [ [string] ] == [ [string] ] [EOL] for value in series [ [string] ] : [EOL] measurement_names . append ( value [ [number] ] ) [EOL] [EOL] measurement_infos = [ ] [EOL] for measurement_name in measurement_names : [EOL] future = MeasurementInfo . from_db ( client , db_name , measurement_name ) [EOL] measurement_infos . append ( future ) [EOL] [EOL] instance = DataBaseInfo ( ) [EOL] measurements = await asyncio . gather ( * measurement_infos ) [EOL] instance . measurements = { m . measurement_name : m for m in measurements } [EOL] return instance [EOL] [EOL] [EOL] class ServerInfo : [EOL] pass [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,unknown]$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,unknown]$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,unknown]$ 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Dict[builtins.str,unknown]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Dict[builtins.str,unknown]$ 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,unknown]$ 0 0 0 $typing.Dict[builtins.str,unknown]$ 0 0 0 0 $typing.Dict[builtins.str,unknown]$ 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $builtins.int$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Type[typing.Union[builtins.float,builtins.str]]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $typing.Set[typing.Any]$ 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $typing.Set[typing.Any]$ 0 $typing.Set[typing.Any]$ 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Set[typing.Any]$ 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $aioinflux.InfluxDBClient$ 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $aioinflux.InfluxDBClient$ 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 $typing.Coroutine[typing.Any,typing.Any,typing.Any]$ 0 0 0 0 0 $aioinflux.InfluxDBClient$ 0 $builtins.str$ 0 0 0 0 $typing.List[typing.Any]$ 0 0 0 $typing.Coroutine[typing.Any,typing.Any,typing.Any]$ 0 0 0 $influxdb_sync.sync.DataBaseInfo$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Any]$ 0 0 $influxdb_sync.sync.DataBaseInfo$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $influxdb_sync.sync.DataBaseInfo$ 0 0 0 0 0 0 0 0 0
[comment] [EOL] [EOL] [docstring] [EOL] [EOL] __author__ = [string] [EOL] __email__ = [string] [EOL] __version__ = [string] [EOL]	0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0
from typing import Any [EOL] import typing [EOL] import dockerdb . influxdb_pytest [EOL] [EOL] [EOL] influx_src = dockerdb . influxdb_pytest . fixture ( scope = [string] , versions = [ [string] ] , exposed_port = [number] ) [EOL] influx_dst = dockerdb . influxdb_pytest . fixture ( scope = [string] , versions = [ [string] ] , exposed_port = [number] )	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[comment] [EOL] [comment] [EOL] [EOL] import builtins [EOL] from typing import Dict , List , Any , Union [EOL] import random [EOL] import influxdb_sync [EOL] import typing [EOL] [docstring] [EOL] [EOL] import asyncio [EOL] import random [EOL] [EOL] import pytest [EOL] from aioinflux import InfluxDBClient [EOL] import aioinflux [EOL] [EOL] import influxdb_sync . sync [EOL] [EOL] point = { [string] : [string] , [string] : [string] , [string] : { [string] : [string] , [string] : [string] } , [string] : { [string] : [number] , [string] : [string] , [string] : [number] } } [EOL] [EOL] [EOL] async def ensure_influx_setup ( client ) : [EOL] try : [EOL] resp = await client . query ( [string] ) [EOL] return [EOL] except aioinflux . client . InfluxDBError : [EOL] [comment] [EOL] pass [EOL] [EOL] await client . create_database ( db = [string] ) [EOL] await client . write ( point ) [EOL] [EOL] [EOL] async def gen_test_data ( client , amount , start_time = [number] , seed = [number] ) : [EOL] r = random . Random ( seed ) [EOL] t = start_time [EOL] for i in range ( amount ) : [EOL] batch = [ ] [EOL] for _ in range ( [number] ) : [EOL] t += r . randint ( [number] , [number] ) [EOL] entry = { [string] : t , [string] : [string] , [string] : { [string] : r . choice ( [ [string] , [string] , [string] ] ) , [string] : [string] } , [string] : { [string] : r . random ( ) } } [EOL] batch . append ( entry ) [EOL] await client . write ( batch ) [EOL] return t [EOL] [EOL] [EOL] async def compare ( src_client , dst_client , query ) : [EOL] src_results , dst_results = await asyncio . gather ( src_client . query ( query ) , dst_client . query ( query ) ) [EOL] [EOL] src_results = src_results [ [string] ] [EOL] dst_results = dst_results [ [string] ] [EOL] [EOL] assert len ( src_results ) == len ( dst_results ) == [number] [EOL] assert [string] in src_results [ [number] ] [EOL] assert [string] in dst_results [ [number] ] [EOL] src_series = src_results [ [number] ] [ [string] ] [EOL] dst_series = dst_results [ [number] ] [ [string] ] [EOL] assert len ( src_series ) == len ( dst_series ) == [number] [EOL] [EOL] src_series = src_series [ [number] ] [EOL] dst_series = dst_series [ [number] ] [EOL] [EOL] assert src_series [ [string] ] == dst_series [ [string] ] [EOL] [EOL] assert len ( src_series [ [string] ] ) == len ( dst_series [ [string] ] ) [EOL] for i , row in enumerate ( src_series [ [string] ] ) : [EOL] assert row == dst_series [ [string] ] [ i ] [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_sync ( influx_src , influx_dst ) : [EOL] async with InfluxDBClient ( port = influx_src . exposed_port , db = [string] ) as src_client : [EOL] await ensure_influx_setup ( src_client ) [EOL] [EOL] async with InfluxDBClient ( port = influx_dst . exposed_port , db = [string] ) as dst_client : [EOL] await dst_client . create_database ( db = [string] ) [EOL] [EOL] [EOL] [EOL] syncer = influxdb_sync . sync . Synchronizer ( src_client , dst_client , [string] , [string] ) [EOL] syncer . src_batch_size = [number] [EOL] [EOL] [comment] [EOL] [comment] [EOL] with pytest . raises ( AssertionError ) : [EOL] await compare ( src_client , dst_client , [string] ) [EOL] [EOL] await syncer . run ( ) [EOL] [EOL] await compare ( src_client , dst_client , [string] ) [EOL] [EOL] [comment] [EOL] t = await gen_test_data ( src_client , [number] ) [EOL] [EOL] [EOL] [EOL] [comment] [EOL] with pytest . raises ( AssertionError ) : [EOL] await compare ( src_client , dst_client , [string] ) [EOL] [EOL] await syncer . run ( ) [EOL] [EOL] await compare ( src_client , dst_client , [string] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] syncer . src_batch_size = [number] [EOL] measurement = syncer . src_client . db_info . measurements [ [string] ] [EOL] syncer . reset_stats ( ) [EOL] await syncer . produce ( ) [EOL] assert syncer . skipped_points > [number] [EOL] assert syncer . modified_points < syncer . src_batch_size [EOL] [EOL] [comment] [EOL] await gen_test_data ( src_client , [number] , start_time = t ) [EOL] [EOL] [comment] [EOL] with pytest . raises ( AssertionError ) : [EOL] await compare ( src_client , dst_client , [string] ) [EOL] [EOL] await syncer . run ( ) [EOL] [EOL] await compare ( src_client , dst_client , [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0