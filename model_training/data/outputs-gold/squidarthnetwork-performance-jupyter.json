[comment] [EOL] [EOL] from typing import Any [EOL] import argparse [EOL] import typing [EOL] import argparse [EOL] from src . receiver import Receiver [EOL] [EOL] [EOL] def main ( ) : [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] ) [EOL] parser . add_argument ( [string] , nargs = [string] ) [EOL] args = parser . parse_args ( ) [EOL] running_time = args . running_time [EOL] peers = args . ip_port_pairs [EOL] [EOL] receiver = Receiver ( int ( running_time ) , [ ( peers [ i ] , int ( peers [ i + [number] ] ) ) for i in range ( [number] , len ( peers ) , [number] ) ] ) [EOL] [EOL] try : [EOL] receiver . perform_handshakes ( ) [EOL] receiver . run ( ) [EOL] except KeyboardInterrupt : [EOL] pass [EOL] finally : [EOL] receiver . cleanup ( ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List , Union , Dict [EOL] import src [EOL] import argparse [EOL] import typing [EOL] import argparse [EOL] import torch [EOL] import torch . nn as nn [EOL] import torch . optim as optim [EOL] import torch . nn . functional as F [EOL] import matplotlib [EOL] [comment] [EOL] [comment] [EOL] matplotlib . use ( [string] ) [EOL] import matplotlib . pyplot as plt [EOL] from src . helpers import run_with_mahi_settings , get_open_udp_port [EOL] from src . senders import Sender [EOL] from src . ml_strategy import ReinforcementStrategy [EOL] from src . ml_helpers import LSTM_DQN [EOL] [EOL] from os import mkdir [EOL] from os . path import join , exists [EOL] import json [EOL] [EOL] [comment] [EOL] OUTPUT_DIRECTORY = [string] [EOL] EXPERIMENT_PREFIX = [string] [EOL] HYPERPARAMS_FILENAME = [string] [EOL] [EOL] mahimahi_settings = { [string] : [number] , [string] : [string] , [string] : [string] , [string] : { [string] : [number] } } [EOL] [EOL] def run_experiment ( hyperparameters_file_name , experiment_name ) : [EOL] experiment_dir = join ( OUTPUT_DIRECTORY , EXPERIMENT_PREFIX + experiment_name ) [EOL] device = torch . device ( [string] if torch . cuda . is_available ( ) else [string] ) [EOL] if not exists ( OUTPUT_DIRECTORY ) : [EOL] mkdir ( OUTPUT_DIRECTORY ) [EOL] [EOL] if not exists ( experiment_dir ) : [EOL] mkdir ( experiment_dir ) [EOL] [EOL] hyperparameters = None [EOL] with open ( hyperparameters_file_name ) as hyperparams_file : [EOL] hyperparameters = json . loads ( hyperparams_file . read ( ) ) [EOL] [EOL] NUM_EPISODES = hyperparameters [ [string] ] [ [string] ] [EOL] TARGET_UPDATE = hyperparameters [ [string] ] [ [string] ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] policy_net = LSTM_DQN ( hyperparameters [ [string] ] , device ) . to ( device = device ) [EOL] target_net = LSTM_DQN ( hyperparameters [ [string] ] , device ) . to ( device = device ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] target_net . load_state_dict ( policy_net . state_dict ( ) ) [EOL] optimizer = optim . RMSprop ( policy_net . parameters ( ) ) [EOL] transitions = [ ] [EOL] total_losses = [ ] [EOL] for i in range ( NUM_EPISODES ) : [EOL] port = get_open_udp_port ( ) [EOL] strategy = ReinforcementStrategy ( policy_net = policy_net , target_net = target_net , device = device , optimizer = optimizer , hyperparameters = hyperparameters [ [string] ] , episode_num = i , transitions = transitions ) [EOL] print ( [string] % i ) [EOL] run_with_mahi_settings ( mahimahi_settings , [number] , [ Sender ( port , strategy ) ] , True , i , write_to_disk = True , output_dir = OUTPUT_DIRECTORY , experiment_dir = experiment_dir ) [EOL] total_losses . append ( strategy . losses ) [EOL] if i % TARGET_UPDATE == [number] : [EOL] target_net . load_state_dict ( policy_net . state_dict ( ) ) [EOL] [comment] [EOL] policy_net_filename = join ( experiment_dir , [string] + str ( i ) + [string] ) [EOL] torch . save ( policy_net . state_dict ( ) , policy_net_filename ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [EOL] colors = [ [string] , [string] , [string] , [string] , [string] ] [EOL] start = [number] [EOL] for i , loss_array in enumerate ( total_losses ) : [EOL] x = list ( range ( start , start + len ( loss_array ) ) ) [EOL] plt . plot ( x , loss_array , c = colors [ i % [number] ] ) [EOL] start += len ( loss_array ) [EOL] plt . savefig ( join ( experiment_dir , [string] ) ) [EOL] plt . close ( ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( description = [string] ) [EOL] parser . add_argument ( [string] , required = True ) [EOL] parser . add_argument ( [string] , required = True ) [EOL] args = parser . parse_args ( ) [EOL] print ( [string] % ( args . hyperparameters_file , args . experiment_name ) ) [EOL] run_experiment ( args . hyperparameters_file , args . experiment_name ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0 0 $typing.Dict[builtins.str,typing.Union[typing.Dict[builtins.str,builtins.int],builtins.int,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,typing.Union[typing.Dict[builtins.str,builtins.int],builtins.int,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 $argparse.Namespace$ 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 $argparse.Namespace$ 0 0 0 $argparse.Namespace$ 0 0 0 0 0 0 0 $argparse.Namespace$ 0 0 0 $argparse.Namespace$ 0 0 0 0
from typing import Any [EOL] import builtins [EOL] import argparse [EOL] import typing [EOL] import argparse [EOL] import numpy as np [EOL] [EOL] def generate_trace_file ( trace_file_path , bandwidth ) : [EOL] num_packets = int ( float ( bandwidth ) * [number] ) [EOL] timestamp_list = np . linspace ( [number] , [number] , num = num_packets , endpoint = False ) [EOL] with open ( trace_file_path , [string] ) as trace : [EOL] for ts in timestamp_list : [EOL] trace . write ( [string] % ts ) [EOL] [EOL] if __name__ == [string] : [EOL] parser = argparse . ArgumentParser ( ) [EOL] parser . add_argument ( [string] , metavar = [string] , required = True , help = [string] ) [EOL] parser . add_argument ( [string] , metavar = [string] , required = True , help = [string] ) [EOL] [EOL] args = parser . parse_args ( ) [EOL] generate_trace_file ( args . trace_path , float ( args . bandwidth ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $argparse.Namespace$ 0 $argparse.ArgumentParser$ 0 0 0 0 0 0 0 $argparse.Namespace$ 0 0 0 0 0 $argparse.Namespace$ 0 0 0 0 0
	0
from typing import Any , List , Pattern , Dict [EOL] import src [EOL] import builtins [EOL] import threading [EOL] import socket [EOL] import typing [EOL] import matplotlib [EOL] import matplotlib . pyplot as plt [EOL] import re [EOL] import os [EOL] from subprocess import Popen [EOL] import socket [EOL] from threading import Thread [EOL] from typing import Dict , List [EOL] from src . senders import Sender [EOL] from os . path import join [EOL] [EOL] [EOL] RECEIVER_FILE = [string] [EOL] AVERAGE_SEGMENT_SIZE = [number] [EOL] QUEUE_LOG_FILE = [string] [EOL] QUEUE_LOG_TMP_FILE = [string] [EOL] [EOL] DROP_LOG = [string] [EOL] DROP_LOG_TMP_FILE = [string] [EOL] [EOL] def generate_mahimahi_command ( mahimahi_settings ) : [EOL] if mahimahi_settings . get ( [string] ) : [EOL] loss_directive = [string] % mahimahi_settings . get ( [string] ) [EOL] else : [EOL] loss_directive = [string] [EOL] [EOL] queue_type = mahimahi_settings . get ( [string] , [string] ) [EOL] [EOL] if mahimahi_settings . get ( [string] ) : [EOL] downlink_queue_options = [string] + [string] . join ( [ [string] % ( key , value ) for key , value in mahimahi_settings . get ( [string] ) . items ( ) ] ) [EOL] else : [EOL] downlink_queue_options = [string] [EOL] [EOL] if mahimahi_settings . get ( [string] ) : [EOL] uplink_queue_options = [string] . join ( [ [string] % ( key , value ) for key , value in mahimahi_settings . get ( [string] ) . items ( ) ] ) [EOL] else : [EOL] uplink_queue_options = [string] [EOL] [EOL] return [string] . format ( delay = mahimahi_settings [ [string] ] , downlink_queue_options = downlink_queue_options , uplink_queue_options = uplink_queue_options , loss_directive = loss_directive , trace_file = mahimahi_settings [ [string] ] , queue_type = queue_type , queue_log_file = QUEUE_LOG_FILE ) [EOL] [EOL] def get_open_udp_port ( ) : [EOL] s = socket . socket ( socket . AF_INET , socket . SOCK_DGRAM ) [EOL] s . setsockopt ( socket . SOL_SOCKET , socket . SO_REUSEADDR , [number] ) [EOL] [EOL] s . bind ( ( [string] , [number] ) ) [EOL] port = s . getsockname ( ) [ [number] ] [EOL] s . close ( ) [EOL] return port [EOL] [EOL] SENDER_COLORS = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] [EOL] def print_performance ( senders , num_seconds , episode_num , write_to_disk , output_dir , experiment_dir ) : [EOL] [EOL] if write_to_disk : [EOL] with open ( join ( experiment_dir , [string] + str ( episode_num ) + [string] ) , [string] ) as out_stats : [EOL] for sender in senders : [EOL] out_stats . write ( [string] % ( sender . port , sender . strategy . __class__ . __name__ ) + [string] ) [EOL] out_stats . write ( [string] % ( AVERAGE_SEGMENT_SIZE * ( sender . strategy . ack_count / num_seconds ) ) + [string] ) [EOL] out_stats . write ( [string] % ( ( float ( sum ( sender . strategy . rtts ) ) / len ( sender . strategy . rtts ) ) * [number] ) + [string] ) [EOL] out_stats . write ( [string] ) [EOL] else : [EOL] for sender in senders : [EOL] print ( [string] % ( sender . port , sender . strategy . __class__ . __name__ ) ) [EOL] print ( [string] % ( AVERAGE_SEGMENT_SIZE * ( sender . strategy . ack_count / num_seconds ) ) ) [EOL] print ( [string] % ( ( float ( sum ( sender . strategy . rtts ) ) / len ( sender . strategy . rtts ) ) * [number] ) ) [EOL] print ( [string] ) [EOL] [EOL] [EOL] [comment] [EOL] queue_log_lines = open ( QUEUE_LOG_TMP_FILE ) . read ( ) . split ( [string] ) [ [number] : ] [EOL] regex = re . compile ( [string] ) [EOL] [EOL] plt . plot ( [ int ( regex . match ( line ) . group ( [number] ) ) for line in queue_log_lines if regex . match ( line ) is not None ] ) [EOL] [EOL] plt . xlabel ( [string] ) [EOL] plt . ylabel ( [string] ) [EOL] [EOL] if write_to_disk : [EOL] plt . savefig ( join ( experiment_dir , [string] + str ( episode_num ) + [string] ) ) [EOL] plt . close ( ) [EOL] else : [EOL] plt . show ( ) [EOL] [EOL] handles = [ ] [EOL] for idx , sender in enumerate ( senders ) : [EOL] plt . plot ( * zip ( * sender . strategy . cwnds ) , c = SENDER_COLORS [ idx ] , label = sender . strategy . __class__ . __name__ ) [EOL] plt . legend ( ) [EOL] plt . xlabel ( [string] ) [EOL] plt . ylabel ( [string] ) [EOL] [EOL] if write_to_disk : [EOL] plt . savefig ( join ( experiment_dir , [string] + str ( episode_num ) + [string] ) ) [EOL] plt . close ( ) [EOL] else : [EOL] plt . show ( ) [EOL] print ( [string] ) [EOL] [EOL] for idx , sender in enumerate ( senders ) : [EOL] plt . plot ( * zip ( * sender . strategy . rtt_recordings ) , c = SENDER_COLORS [ idx ] , label = sender . strategy . __class__ . __name__ ) [EOL] plt . legend ( ) [EOL] plt . xlabel ( [string] ) [EOL] plt . ylabel ( [string] ) [EOL] if write_to_disk : [EOL] plt . savefig ( join ( experiment_dir , [string] + str ( episode_num ) + [string] ) ) [EOL] plt . close ( ) [EOL] else : [EOL] plt . show ( ) [EOL] [EOL] def run_with_mahi_settings ( mahimahi_settings , seconds_to_run , senders , should_print_performance , episode_num , write_to_disk , output_dir , experiment_dir ) : [EOL] mahimahi_cmd = generate_mahimahi_command ( mahimahi_settings ) [EOL] [EOL] sender_ports = [string] . join ( [ [string] % sender . port for sender in senders ] ) [EOL] [EOL] cmd = [string] % ( mahimahi_cmd , RECEIVER_FILE , seconds_to_run , sender_ports ) [EOL] Popen ( cmd , shell = True ) [EOL] for sender in senders : [EOL] sender . handshake ( ) [EOL] threads = [ Thread ( target = sender . run , args = [ seconds_to_run ] ) for sender in senders ] [EOL] for thread in threads : [EOL] thread . start ( ) [EOL] for thread in threads : [EOL] thread . join ( ) [EOL] [EOL] os . rename ( QUEUE_LOG_FILE , QUEUE_LOG_TMP_FILE ) [EOL] [comment] [EOL] [EOL] if should_print_performance : [EOL] print_performance ( senders , seconds_to_run , episode_num , write_to_disk , output_dir , experiment_dir ) [EOL] Popen ( [string] , shell = True ) . wait ( ) [EOL] Popen ( [string] , shell = True ) . wait ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Type , List , Any [EOL] import src [EOL] import typing [EOL] import random [EOL] import torch [EOL] import torch . nn as nn [EOL] import torch . nn . functional as F [EOL] [EOL] from collections import namedtuple [EOL] [EOL] Transition = namedtuple ( [string] , ( [string] , [string] , [string] , [string] ) ) [EOL] [EOL] def optimize_model ( policy_net , target_net , device , optimizer , transitions , batch_size , reward_decay ) : [EOL] if ( len ( transitions ) < batch_size ) : [EOL] return [EOL] [EOL] transitions = random . sample ( transitions , batch_size ) [EOL] batch = Transition ( * zip ( * transitions ) ) [EOL] state_batch = torch . cat ( batch . state ) [EOL] action_batch = torch . cat ( batch . action ) [EOL] reward_batch = torch . cat ( batch . reward ) [EOL] [EOL] predicted_actions = policy_net ( state_batch ) [EOL] [EOL] state_action_values = predicted_actions . gather ( [number] , action_batch . unsqueeze ( - [number] ) ) [EOL] [EOL] next_state_values = target_net ( state_batch ) . max ( [number] ) [ [number] ] . detach ( ) [EOL] expected_state_action_values = ( next_state_values * reward_decay ) + reward_batch [EOL] loss = F . smooth_l1_loss ( state_action_values , expected_state_action_values . unsqueeze ( [number] ) ) [EOL] [EOL] optimizer . zero_grad ( ) [EOL] loss . backward ( ) [EOL] [EOL] for param in policy_net . parameters ( ) : [EOL] param . grad . data . clamp_ ( - [number] , [number] ) [EOL] optimizer . step ( ) [EOL] [EOL] return loss . data . item ( ) [EOL] [EOL] [EOL] class LSTM_DQN ( nn . Module ) : [EOL] [docstring] [EOL] def __init__ ( self , config , device , use_cuda = False ) : [EOL] super ( LSTM_DQN , self ) . __init__ ( ) [EOL] [EOL] self . device = device [EOL] self . W = nn . LSTM ( config [ [string] ] , config [ [string] ] , batch_first = True , bidirectional = config [ [string] ] , num_layers = config [ [string] ] ) [EOL] if config [ [string] ] : [EOL] self . h0 , self . c0 = ( torch . zeros ( [number] * config [ [string] ] , [number] , config [ [string] ] , device = device ) , torch . zeros ( [number] * config [ [string] ] , [number] , config [ [string] ] , device = device ) ) [EOL] self . U = nn . Linear ( config [ [string] ] * [number] , config [ [string] ] ) [EOL] else : [EOL] self . h0 , self . c0 = ( torch . zeros ( config [ [string] ] , [number] , config [ [string] ] , device = device ) , torch . zeros ( config [ [string] ] , [number] , config [ [string] ] , device = device ) ) [EOL] self . U = nn . Linear ( config [ [string] ] , config [ [string] ] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] for param in self . W . parameters ( ) : [EOL] if len ( param . size ( ) ) > [number] : [EOL] nn . init . orthogonal_ ( param ) [EOL] [EOL] for param in self . U . parameters ( ) : [EOL] if len ( param . size ( ) ) > [number] : [EOL] nn . init . orthogonal_ ( param ) [EOL] [EOL] self . config = config [EOL] [EOL] def forward ( self , x ) : [EOL] [comment] [EOL] batch_len , _ , _ = x . size ( ) [EOL] [EOL] h0 = self . h0 . repeat ( [number] , batch_len , [number] ) . to ( device = self . device ) [EOL] c0 = self . c0 . repeat ( [number] , batch_len , [number] ) . to ( device = self . device ) [EOL] [EOL] out , _ = self . W ( x , ( h0 , c0 ) ) [EOL] [EOL] return self . U ( out [ : , - [number] , : ] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[src.ml_helpers.Transition]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Type[src.ml_helpers.Transition]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0