from typing import Dict , List , Tuple , Union , Any [EOL] import flask [EOL] import typing [EOL] import builtins [EOL] [docstring] [EOL] import json [EOL] import os [EOL] from typing import Tuple [EOL] [EOL] from cassandra . cluster import Cluster [comment] [EOL] from flask import render_template , Flask [comment] [EOL] from kafka import KafkaConsumer [comment] [EOL] import pymysql [comment] [EOL] import simplejson as sj [comment] [EOL] from sqlalchemy import create_engine [comment] [EOL] [EOL] import helper_methods [EOL] from config_secure import SERVERS , MYSQL_CONF , CASSANDRA_CLUSTER [EOL] [EOL] [EOL] app = Flask ( __name__ ) [comment] [EOL] session = Cluster ( CASSANDRA_CLUSTER ) . connect ( [string] ) [comment] [EOL] UPLOAD_FOLDER = os . path . join ( os . path . dirname ( os . path . abspath ( __file__ ) ) , [string] ) [EOL] app . config [ [string] ] = UPLOAD_FOLDER [EOL] engine = create_engine ( MYSQL_CONF ) [comment] [EOL] print ( [string] ) [EOL] consumer = KafkaConsumer ( [string] , group_id = [string] , bootstrap_servers = SERVERS , value_deserializer = lambda m : json . loads ( m . decode ( [string] ) ) ) [EOL] print ( [string] ) [EOL] [EOL] [EOL] @ app . route ( [string] ) def dashboard ( ) : [EOL] [docstring] [EOL] brand_result = helper_methods . get_top_brands ( engine ) [EOL] influencer_result = helper_methods . get_top_influencers ( engine ) [EOL] brand_metrics_result = helper_methods . get_brand_metrics ( engine ) [EOL] [EOL] return render_template ( [string] , tags = brand_result , people = influencer_result , reach = brand_metrics_result ) [EOL] [EOL] [EOL] @ app . route ( [string] ) def render_map ( ) : [EOL] [docstring] [EOL] return render_template ( [string] ) [EOL] [EOL] [EOL] @ app . route ( [string] ) def user_photos ( username ) : [EOL] [docstring] [EOL] timeline = list ( helper_methods . get_user_timeline ( username , session ) ) [EOL] template_data = { [string] : timeline , [string] : username } [EOL] [EOL] return render_template ( [string] , ** template_data ) [EOL] [EOL] [EOL] @ app . errorhandler ( [number] ) def page_not_found ( error ) : [comment] [EOL] [docstring] [EOL] return render_template ( [string] ) , [number] [EOL] [EOL] [EOL] @ app . route ( [string] , methods = [ [string] ] ) def brand_metrics ( ) : [EOL] [docstring] [EOL] column_names = [ [string] , [string] , [string] , [string] , [string] , [string] , [string] ] [EOL] result = [ dict ( zip ( column_names , row ) ) for row in helper_methods . get_brand_metrics ( engine ) ] [EOL] return sj . dumps ( result , use_decimal = True ) [EOL] [EOL] [EOL] @ app . route ( [string] , methods = [ [string] ] ) def consume_photos ( ) : [EOL] [docstring] [EOL] message = next ( consumer ) [EOL] consumer . commit ( ) [EOL] return json . dumps ( message . value ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $flask.app.Flask$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $flask.app.Flask$ 0 0 0 0 0 0 $builtins.str$ 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $flask.app.Flask$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $flask.app.Flask$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $flask.app.Flask$ 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $flask.app.Flask$ 0 0 0 0 0 0 $typing.Tuple[builtins.str,builtins.int]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $flask.app.Flask$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $flask.app.Flask$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[docstring] [EOL] from views import app [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] app . run ( host = [string] , port = [number] , debug = True ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import builtins [EOL] import sqlalchemy [EOL] import typing [EOL] import cassandra [EOL] [docstring] [EOL] from cassandra . cluster import Cluster [comment] [EOL] from sqlalchemy . engine . interfaces import Dialect [comment] [EOL] [EOL] [EOL] def get_user_timeline ( user , db_session ) : [EOL] [docstring] [EOL] sql_query = f""" [string] { user } [string] """ [EOL] timeline = db_session . execute ( sql_query ) [EOL] return timeline [EOL] [EOL] [EOL] def get_top_brands ( mysql_engine ) : [EOL] [docstring] [EOL] sql_string = [string] [EOL] brand_result = mysql_engine . execute ( sql_string ) . fetchall ( ) [EOL] return brand_result [EOL] [EOL] [EOL] def get_top_influencers ( mysql_engine ) : [EOL] [docstring] [EOL] influencer_string = [string] [EOL] influencer_result = mysql_engine . execute ( influencer_string ) . fetchall ( ) [EOL] return influencer_result [EOL] [EOL] def get_brand_metrics ( mysql_engine ) : [EOL] [docstring] [EOL] brand_metrics = [string] [EOL] brand_metrics_result = mysql_engine . execute ( brand_metrics ) . fetchall ( ) [EOL] return brand_metrics_result [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] from datetime import datetime [EOL] import json [EOL] [EOL] from pyspark import SparkContext , SparkConf [EOL] from pyspark . streaming import StreamingContext [EOL] from pyspark . streaming . kafka import KafkaUtils [EOL] from pyspark . sql import SQLContext , SparkSession [EOL] [EOL] from config_secure import ZkQuorum [EOL] [EOL] sc = SparkContext ( appName = [string] ) [EOL] ssc = StreamingContext ( sc , [number] ) [EOL] sql = SQLContext ( sc ) [EOL] [EOL] [EOL] def getSparkSessionInstance ( sparkConf ) : [EOL] if ( [string] not in globals ( ) ) : [EOL] globals ( ) [ [string] ] = SparkSession . builder . config ( conf = sparkConf ) . getOrCreate ( ) [EOL] return globals ( ) [ [string] ] [EOL] [EOL] [EOL] def create_stream ( spark_stream_context , zk_quorum , group_name , topic_dict ) : [EOL] zookeeper_ips = [string] . join ( zk_quorum ) [EOL] [EOL] return KafkaUtils . createStream ( spark_stream_context , zookeeper_ips , group_name , topic_dict ) [EOL] [EOL] [EOL] def process_follows ( rdd ) : [EOL] [docstring] [EOL] [comment] [EOL] [comment] [EOL] pass [EOL] [EOL] [EOL] def main ( ) : [EOL] follow_events_stream = create_stream ( ssc , ZkQuorum , [string] , { [string] : [number] } ) [EOL] follow_event = follow_events_stream . map ( lambda tup : tup [ [number] ] ) [EOL] follow_event . foreachRDD ( process_follows ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL] ssc . start ( ) [EOL] ssc . awaitTermination ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] from datetime import datetime [EOL] import json [EOL] [EOL] from cassandra import ConsistencyLevel [EOL] from pyspark import SparkContext , SparkConf [EOL] from pyspark . streaming import StreamingContext [EOL] from pyspark . streaming . kafka import KafkaUtils [EOL] from pyspark . sql import SQLContext , SparkSession [EOL] [EOL] from config_secure import ZkQuorum [EOL] [EOL] sc = SparkContext ( appName = [string] ) [EOL] ssc = StreamingContext ( sc , [number] ) [EOL] sql = SQLContext ( sc ) [EOL] [EOL] def getSparkSessionInstance ( sparkConf ) : [EOL] sparkConf . set ( [string] , [string] ) [EOL] if ( [string] not in globals ( ) ) : [EOL] globals ( ) [ [string] ] = SparkSession . builder . config ( conf = sparkConf ) . getOrCreate ( ) [EOL] return globals ( ) [ [string] ] [EOL] [EOL] [EOL] def create_stream ( spark_stream_context , zk_quorum , group_name , topic_dict ) : [EOL] return KafkaUtils . createStream ( spark_stream_context , [string] . join ( zk_quorum ) , group_name , topic_dict ) [EOL] [EOL] [EOL] def process_users ( rdd ) : [EOL] if rdd . isEmpty ( ) : [EOL] return [EOL] spark = getSparkSessionInstance ( rdd . context . getConf ( ) ) [EOL] df = spark . read . json ( rdd ) [EOL] df . show ( ) [EOL] df . write . format ( [string] ) . mode ( [string] ) . options ( table = [string] , keyspace = [string] ) . save ( ) [EOL] for row in df . collect ( ) : [EOL] user_df = sql . createDataFrame ( [ { [string] : row . username , [string] : row . username } ] ) [EOL] user_df . write . format ( [string] ) . mode ( [string] ) . options ( table = [string] , keyspace = [string] ) . save ( ) [EOL] user_df . write . format ( [string] ) . mode ( [string] ) . options ( table = [string] , keyspace = [string] ) . save ( ) [EOL] [EOL] [EOL] def main ( ) : [EOL] create_user_stream = create_stream ( ssc , ZkQuorum , [string] , { [string] : [number] } ) [EOL] new_users = create_user_stream . map ( lambda tup : tup [ [number] ] ) [EOL] new_users . foreachRDD ( process_users ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL] ssc . start ( ) [EOL] ssc . awaitTermination ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] from datetime import datetime [EOL] import json [EOL] [EOL] from cassandra import ConsistencyLevel [EOL] from pyspark import SparkContext , SparkConf [EOL] from pyspark . streaming import StreamingContext [EOL] from pyspark . streaming . kafka import KafkaUtils [EOL] from pyspark . sql import SQLContext , SparkSession [EOL] from pyspark . sql . functions import col , udf [EOL] from pyspark . sql . types import * [EOL] import pyspark_cassandra [EOL] [EOL] from config_secure import ZkQuorum , CASSANDRA_CLUSTER [EOL] [EOL] sConf = SparkConf ( ) . set ( [string] , [string] ) . set ( CASSANDRA_CLUSTER ) [EOL] sc = pyspark_cassandra . CassandraSparkContext ( conf = sConf ) [EOL] ssc = StreamingContext ( sc , [number] ) [EOL] sql = SQLContext ( sc ) [EOL] [EOL] [EOL] def getSparkSessionInstance ( sparkConf ) : [EOL] if ( [string] not in globals ( ) ) : [EOL] globals ( ) [ [string] ] = SparkSession . builder . config ( conf = sparkConf ) . getOrCreate ( ) [EOL] return globals ( ) [ [string] ] [EOL] [EOL] [EOL] def create_stream ( spark_stream_context , zk_quorum , group_name , topic_dict ) : [EOL] return KafkaUtils . createStream ( spark_stream_context , [string] . join ( zk_quorum ) , group_name , topic_dict ) [EOL] [EOL] [EOL] def process_comments ( rdd ) : [EOL] if rdd . isEmpty ( ) : [EOL] return [EOL] [EOL] spark = getSparkSessionInstance ( rdd . context . getConf ( ) ) [EOL] df = spark . read . json ( rdd ) [EOL] df . show ( ) [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] comments_schema = StructType ( [ StructField ( [string] , ArrayType ( MapType ( StringType ( ) , StringType ( ) ) ) ) ] ) [EOL] append_if = udf ( lambda orig_comments , new_commenter , new_comment : orig_comments . append ( { [string] : new_commenter , [string] : new_comment } ) [EOL] if orig_comments else [ { [string] : new_commenter , [string] : new_comment } ] , ArrayType ( MapType ( StringType ( ) , StringType ( ) ) ) ) [EOL] [EOL] for row in df . collect ( ) : [EOL] followers = sc . cassandraTable ( [string] , [string] ) . select ( [string] ) . where ( [string] , row . followed_username ) . toDF ( ) [EOL] comments_df = sql . createDataFrame ( sc . cassandraTable ( [string] , [string] ) . select ( [string] ) . where ( [string] , row . followed_username ) . where ( [string] , row . photo_id ) , comments_schema ) [EOL] comments_df . show ( ) [EOL] revised_comments = comments_df . withColumn ( [string] , append_if ( comments_df . comments , row . follower_username , row . text ) ) [EOL] followers . show ( ) [EOL] revise_coments . show ( ) [EOL] [comment] [EOL] [comment] [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [EOL] [EOL] def main ( ) : [EOL] comment_stream = create_stream ( ssc , ZkQuorum , [string] , { [string] : [number] } ) [EOL] comment = comment_stream . map ( lambda tup : tup [ [number] ] ) [EOL] comment . foreachRDD ( process_comments ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL] ssc . start ( ) [EOL] ssc . awaitTermination ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] from datetime import datetime [EOL] import json [EOL] [EOL] from cassandra import ConsistencyLevel [EOL] from pyspark import SparkContext , SparkConf [EOL] from pyspark . streaming import StreamingContext [EOL] from pyspark . streaming . kafka import KafkaUtils [EOL] from pyspark . sql import SQLContext , SparkSession [EOL] [EOL] from config_secure import ZkQuorum , CASSANDRA_CLUSTER [EOL] [EOL] sConf = SparkConf ( ) . set ( [string] , [string] ) . set ( [string] , CASSANDRA_CLUSTER ) [EOL] sc = SparkContext ( appName = [string] , conf = sConf ) [EOL] ssc = StreamingContext ( sc , [number] ) [EOL] [EOL] [EOL] def getSparkSessionInstance ( sparkConf ) : [EOL] if ( [string] not in globals ( ) ) : [EOL] globals ( ) [ [string] ] = SparkSession . builder . config ( conf = sparkConf ) . getOrCreate ( ) [EOL] return globals ( ) [ [string] ] [EOL] [EOL] [EOL] def create_stream ( spark_stream_context , zk_quorum , group_name , topic_dict ) : [EOL] zookeeper_ips = [string] . join ( zk_quorum ) [EOL] [EOL] return KafkaUtils . createStream ( spark_stream_context , zookeeper_ips , group_name , topic_dict ) [EOL] [EOL] [EOL] def process_follows ( rdd ) : [EOL] [docstring] [EOL] spark = getSparkSessionInstance ( rdd . context . getConf ( ) ) [EOL] df = spark . read . json ( rdd ) [EOL] df = df . drop ( [string] ) [EOL] df . show ( ) [EOL] df . write . format ( [string] ) . mode ( [string] ) . options ( table = [string] , keyspace = [string] ) . save ( ) [EOL] df . write . format ( [string] ) . mode ( [string] ) . options ( table = [string] , keyspace = [string] ) . save ( ) [EOL] [EOL] [EOL] def main ( ) : [EOL] follow_events_stream = create_stream ( ssc , ZkQuorum , [string] , { [string] : [number] } ) [EOL] follow_event = follow_events_stream . map ( lambda tup : tup [ [number] ] ) [EOL] follow_event . foreachRDD ( process_follows ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL] ssc . start ( ) [EOL] ssc . awaitTermination ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0
from typing import List , Tuple , Any , Deque [EOL] import multiprocessing [EOL] import builtins [EOL] import typing [EOL] import pymysql [EOL] [docstring] [EOL] from collections import deque [EOL] from multiprocessing import Process [EOL] import random [EOL] import time [EOL] from typing import Deque , List , Tuple [EOL] [EOL] from kafka . client import SimpleClient [EOL] from kafka . producer import KeyedProducer [EOL] import pymysql [EOL] [EOL] from config_secure import SERVERS , MYSQL_CONF [EOL] from pkg . comment import comment_producer [EOL] from pkg . create_user import create_user_producer [comment] [EOL] from pkg . follow import follow_producer [EOL] from pkg . like import like_producer [EOL] from pkg . photo_upload import create_photo_producer [EOL] from pkg . unfollow import unfollow_producer [EOL] [EOL] [EOL] def generate_random_events ( events ) : [EOL] [docstring] [EOL] return random . choice ( events ) [EOL] [EOL] [EOL] def query_for_users ( mysql_session ) : [EOL] [docstring] [EOL] sql_string = [string] [EOL] with mysql_session . cursor ( ) as cursor : [EOL] cursor . execute ( sql_string ) [EOL] users = cursor . fetchall ( ) [EOL] return users [EOL] [EOL] [EOL] def query_for_tags ( mysql_session ) : [EOL] [docstring] [EOL] sql_string = [string] [EOL] with mysql_session . cursor ( ) as cursor : [EOL] cursor . execute ( sql_string ) [EOL] tags = cursor . fetchall ( ) [EOL] return tags [EOL] [EOL] [EOL] def query_for_locations ( mysql_session ) : [EOL] [docstring] [EOL] sql_string = [string] [EOL] with mysql_session . cursor ( ) as cursor : [EOL] cursor . execute ( sql_string ) [EOL] locations = cursor . fetchall ( ) [EOL] return locations [EOL] [EOL] [EOL] def main ( servers ) : [EOL] [docstring] [EOL] mysql_session = pymysql . connect ( ** MYSQL_CONF ) [EOL] [EOL] users = query_for_users ( mysql_session ) [EOL] photos = deque ( [ ] , maxlen = [number] ) [EOL] tags = query_for_tags ( mysql_session ) [EOL] locations = query_for_locations ( mysql_session ) [EOL] [EOL] simple_client = SimpleClient ( servers ) [EOL] producer = KeyedProducer ( simple_client ) [EOL] [EOL] events = [ comment_producer , follow_producer , like_producer , create_photo_producer , unfollow_producer ] [EOL] [EOL] while True : [EOL] event = generate_random_events ( events ) [EOL] print ( event ( users , photos , tags , locations , producer ) ) [EOL] time . sleep ( [number] ) [EOL] [EOL] if __name__ == [string] : [EOL] p1 = Process ( target = main , args = ( SERVERS , ) ) [comment] [EOL] p1 . start ( ) [EOL] p2 = Process ( target = main , args = ( SERVERS , ) ) [comment] [EOL] p2 . start ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.List[typing.Tuple[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , List , Tuple , Deque , Optional , Any [EOL] import typing [EOL] import kafka [EOL] import builtins [EOL] [docstring] [EOL] import json [EOL] import random [EOL] from typing import Deque , Dict , List , Optional , Tuple [EOL] [EOL] from faker import Factory [EOL] from kafka . producer import KeyedProducer [EOL] [EOL] from pkg . helper_functions import get_datetime [EOL] [EOL] [EOL] def get_text ( ) : [EOL] [docstring] [EOL] fake = Factory . create ( ) [EOL] return fake . sentence ( ) [EOL] [EOL] [EOL] def comment_producer ( users , photos , tags , locations , producer ) : [EOL] [docstring] [EOL] if not photos : [EOL] return None [EOL] follower = random . choice ( users ) [ [number] ] [EOL] photo , followee = random . choice ( photos ) [EOL] text = get_text ( ) [EOL] created_time , partition_date = get_datetime ( ) [EOL] [EOL] if not all ( [ photo , follower , followee ] ) : [EOL] return None [EOL] record = { [string] : follower , [string] : followee , [string] : photo , [string] : text , [string] : created_time , [string] : partition_date , [string] : [string] } [EOL] producer . send_messages ( [string] , bytes ( followee , [string] ) , json . dumps ( record ) . encode ( [string] ) ) [EOL] return record [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Optional[typing.Dict[builtins.str,builtins.str]]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	0
from typing import Dict , List , Tuple , Deque , Any [EOL] import typing [EOL] import kafka [EOL] import builtins [EOL] [docstring] [EOL] import json [EOL] import random [EOL] from typing import Deque , Dict , List , Tuple [EOL] [EOL] from kafka . producer import KeyedProducer [EOL] [EOL] from pkg . helper_functions import get_datetime [EOL] [EOL] [EOL] def create_photo_producer ( users , photos , tags , locations , producer ) : [EOL] [docstring] [EOL] user = random . choice ( users ) [ [number] ] [EOL] tag , link = random . choice ( tags ) [EOL] latitude , longitude = random . choice ( locations ) [EOL] created_time , partition_date = get_datetime ( ) [EOL] record = { [string] : user , [string] : tag , [string] : link , [string] : created_time , [string] : partition_date , [string] : latitude , [string] : longitude , [string] : [string] } [EOL] producer . send_messages ( [string] , bytes ( user , [string] ) , json . dumps ( record ) . encode ( [string] ) ) [EOL] photos . append ( ( created_time , user ) ) [EOL] return record [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Tuple [EOL] import datetime [EOL] import typing [EOL] import builtins [EOL] [docstring] [EOL] from datetime import datetime [EOL] from typing import Tuple [EOL] [EOL] [EOL] def get_datetime ( ) : [EOL] [docstring] [EOL] datetime_obj = datetime . now ( ) [EOL] return datetime_obj . strftime ( [string] ) , datetime_obj . strftime ( [string] ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , List , Tuple , Deque , Pattern , Any [EOL] import typing [EOL] import kafka [EOL] import builtins [EOL] [docstring] [EOL] import json [EOL] import random [EOL] import re [EOL] from typing import Deque , Dict , List , Tuple [EOL] [EOL] from faker import Faker [EOL] from kafka . producer import KeyedProducer [EOL] [EOL] from pkg . helper_functions import get_datetime [EOL] [EOL] [EOL] def remove_non_alpha_chars ( string ) : [EOL] [docstring] [EOL] regex = re . compile ( [string] ) [EOL] return regex . sub ( [string] , string ) [EOL] [EOL] [EOL] def fake_user ( ) : [EOL] [docstring] [EOL] fake = Faker ( ) [EOL] full_name = fake . name ( ) [comment] [EOL] name = remove_non_alpha_chars ( full_name ) . lower ( ) [EOL] username = name + [string] . format ( random . randrange ( [number] , [number] ) ) [EOL] return username , full_name [EOL] [EOL] [EOL] def create_user_producer ( users , photos , tags , locations , producer ) : [EOL] [docstring] [EOL] username , full_name = fake_user ( ) [EOL] created_time , partition_date = get_datetime ( ) [EOL] [EOL] record = { [string] : username , [string] : full_name , [string] : created_time , [string] : partition_date , [string] : [string] } [EOL] producer . send_messages ( [string] , bytes ( username , [string] ) , json . dumps ( record ) . encode ( [string] ) ) [EOL] users . append ( ( username , ) ) [EOL] return record [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Dict , List , Tuple , Deque , Any [EOL] import typing [EOL] import kafka [EOL] import builtins [EOL] [docstring] [EOL] import json [EOL] import random [EOL] from typing import Deque , Dict , List , Optional , Tuple [EOL] [EOL] from kafka . producer import KeyedProducer [EOL] [EOL] from pkg . helper_functions import get_datetime [EOL] [EOL] [EOL] def unfollow_producer ( users , photos , tags , locations , producer ) : [EOL] [docstring] [EOL] followee , follower = random . choice ( users ) [ [number] ] , random . choice ( users ) [ [number] ] [EOL] created_time , partition_date = get_datetime ( ) [EOL] record = { [string] : follower , [string] : followee , [string] : created_time , [string] : partition_date , [string] : [string] } [EOL] producer . send_messages ( [string] , bytes ( followee , [string] ) , json . dumps ( record ) . encode ( [string] ) ) [EOL] return record [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0