from typing import Any [EOL] import typing [EOL] import argparse [EOL] [EOL] import pytest [EOL] [EOL] from mila import cli [EOL] [EOL] [EOL] def test_main_prepare_flickr ( mocker ) : [EOL] [docstring] [EOL] flickr_mock = mocker . patch ( [string] ) [EOL] [EOL] cli . main ( [ [string] , [string] , [string] , [string] , [string] , [string] ] ) [EOL] [EOL] flickr_mock . assert_called_once ( ) [EOL] flickr_mock . assert_called_with ( [string] , [string] , [number] ) [EOL] [EOL] [EOL] def test_main_prepare_flickr_limit ( mocker ) : [EOL] [docstring] [EOL] flickr_mock = mocker . patch ( [string] ) [EOL] cli . main ( [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] ] ) [EOL] [EOL] flickr_mock . assert_called_once ( ) [EOL] flickr_mock . assert_called_with ( [string] , [string] , [number] ) [EOL] [EOL] [EOL] def test_main_prepare_test_split ( mocker ) : [EOL] [docstring] [EOL] split_mock = mocker . patch ( [string] ) [EOL] cli . main ( [ [string] , [string] , [string] ] ) [EOL] split_mock . assert_called_with ( equal_splits = True ) [EOL] [EOL] [EOL] def test_main_train_simple_defaults ( mocker ) : [EOL] [docstring] [EOL] simple_mock = mocker . patch ( [string] ) [EOL] cli . main ( [ [string] , [string] ] ) [EOL] simple_mock . assert_called_with ( ( [number] , [number] ) , [number] , [number] , [string] , debug = False , use_class_weights = False , use_image_variations = False ) [EOL] [EOL] [EOL] def test_main_train_simple_with_params ( mocker ) : [EOL] [docstring] [EOL] simple_mock = mocker . patch ( [string] ) [EOL] cli . main ( [ [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] , [string] ] ) [EOL] simple_mock . assert_called_with ( ( [number] , [number] ) , [number] , [number] , [string] , debug = True , use_class_weights = True , use_image_variations = True ) [EOL] [EOL] [EOL] def test_main_train_mobilenet_defaults ( mocker ) : [EOL] [docstring] [EOL] simple_mock = mocker . patch ( [string] ) [EOL] cli . main ( [ [string] , [string] ] ) [EOL] simple_mock . assert_called_with ( [number] , [number] , [string] , use_class_weights = False , use_image_variations = False ) [EOL] [EOL] [EOL] def test_main_predict_defaults ( mocker ) : [EOL] [docstring] [EOL] simple_mock = mocker . patch ( [string] ) [EOL] cli . main ( [ [string] , [string] , [string] ] ) [EOL] simple_mock . assert_called_with ( [string] , [string] ) [EOL] [EOL] [EOL] def test_main_explore ( mocker ) : [EOL] [docstring] [EOL] mocker . patch ( [string] , return_value = ( [string] , { [string] : [ [string] , [string] ] } ) ) [EOL] mocker . patch ( [string] , return_value = [string] ) [EOL] quiver_mock = mocker . patch ( [string] ) [EOL] cli . main ( [ [string] , [string] , [string] ] ) [EOL] quiver_mock . assert_called_with ( [string] , classes = [ [string] , [string] ] , input_folder = [string] , temp_folder = [string] , std = [ [number] , [number] , [number] ] )	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] import os [EOL] import shutil [EOL] [EOL] import pytest [EOL] [EOL] from mila import util [EOL] [EOL] [EOL] @ pytest . fixture def imagedata ( mocker ) : [EOL] config_mock = mocker . patch ( [string] ) [EOL] config_mock . IMAGE_DIRECTORY = [string] [EOL] yield config_mock [EOL] shutil . rmtree ( config_mock . IMAGE_DIRECTORY ) [EOL] [EOL] [EOL] @ pytest . fixture def cats_and_dogs ( imagedata ) : [EOL] [comment] [EOL] base_dir = os . path . join ( imagedata . IMAGE_DIRECTORY , [string] , [string] ) [EOL] os . makedirs ( base_dir , exist_ok = True ) [EOL] for i in range ( [number] ) : [EOL] with open ( os . path . join ( base_dir , [string] . format ( i ) ) , [string] ) as f : [EOL] f . write ( [string] ) [EOL] [EOL] base_dir = os . path . join ( imagedata . IMAGE_DIRECTORY , [string] , [string] ) [EOL] os . makedirs ( base_dir , exist_ok = True ) [EOL] for i in range ( [number] ) : [EOL] with open ( os . path . join ( base_dir , [string] . format ( i ) ) , [string] ) as f : [EOL] f . write ( [string] ) [EOL] [EOL] [EOL] [EOL] def test_find_categories ( imagedata ) : [EOL] [docstring] [EOL] for category in [ [string] , [string] ] : [EOL] base_dir = os . path . join ( imagedata . IMAGE_DIRECTORY , [string] , category ) [EOL] os . makedirs ( base_dir , exist_ok = True ) [EOL] assert util . find_categories ( ) == [ [string] , [string] ] [EOL] [EOL] [EOL] def test_find_categories_different_dir ( imagedata ) : [EOL] [docstring] [EOL] for category in [ [string] , [string] ] : [EOL] base_dir = os . path . join ( imagedata . IMAGE_DIRECTORY , [string] , category ) [EOL] os . makedirs ( base_dir , exist_ok = True ) [EOL] assert util . find_categories ( [string] ) == [ [string] , [string] ] [EOL] [EOL] [EOL] def test_find_categories_binary ( imagedata ) : [EOL] [docstring] [EOL] for category in [ [string] , [string] ] : [EOL] base_dir = os . path . join ( imagedata . IMAGE_DIRECTORY , [string] , category ) [EOL] os . makedirs ( base_dir , exist_ok = True ) [EOL] assert util . find_categories ( ) == [ [string] , [string] ] [EOL] [EOL] [EOL] def test_num_samples ( cats_and_dogs ) : [EOL] [docstring] [EOL] [comment] [EOL] assert util . num_samples ( ) == [number] [EOL] [EOL] [EOL] def test_compute_class_weight ( cats_and_dogs ) : [EOL] [docstring] [EOL] assert util . compute_class_weight ( { [string] : [number] , [string] : [number] } ) == { [number] : [number] , [number] : [number] } [EOL] [EOL] [EOL] def test_compute_class_weight_reverse ( cats_and_dogs ) : [EOL] [docstring] [EOL] assert util . compute_class_weight ( { [string] : [number] , [string] : [number] } ) == { [number] : [number] , [number] : [number] }	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] [docstring] [EOL] import os [EOL] import shutil [EOL] import tempfile [EOL] [EOL] import pytest [EOL] [EOL] from mila . prepare import train_split [EOL] [EOL] [EOL] @ pytest . fixture def num_images ( ) : [EOL] return [number] [EOL] [EOL] [EOL] @ pytest . fixture def categories ( ) : [EOL] return [ [string] , [string] ] [EOL] [EOL] [EOL] @ pytest . fixture def imagedata ( mocker , num_images , categories ) : [EOL] tmp = tempfile . mkdtemp ( prefix = [string] ) [EOL] config_mock = mocker . patch ( [string] ) [EOL] config_mock . IMAGE_DIRECTORY = os . path . join ( tmp , [string] ) [EOL] for i , category in enumerate ( categories ) : [EOL] base_dir = os . path . join ( config_mock . IMAGE_DIRECTORY , [string] , category ) [EOL] os . makedirs ( base_dir , exist_ok = True ) [EOL] for j in range ( num_images + i ) : [EOL] with open ( os . path . join ( base_dir , [string] . format ( j ) ) , [string] ) as f : [EOL] f . write ( [string] ) [EOL] yield config_mock . IMAGE_DIRECTORY [EOL] shutil . rmtree ( tmp ) [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ [number] ] ) def test_split_categories_less_than_hundred ( imagedata , categories ) : [EOL] [docstring] [EOL] train_split . split_categories ( categories ) [EOL] assert len ( os . listdir ( os . path . join ( imagedata , [string] ) ) ) == [number] [EOL] assert len ( os . listdir ( os . path . join ( imagedata , [string] ) ) ) == [number] [EOL] assert len ( os . listdir ( os . path . join ( imagedata , [string] ) ) ) == [number] [EOL] assert len ( os . listdir ( os . path . join ( imagedata , [string] ) ) ) == [number] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ [number] ] ) def test_split_categories_more_than_hundred ( imagedata , categories ) : [EOL] [docstring] [EOL] train_split . split_categories ( categories ) [EOL] assert len ( os . listdir ( os . path . join ( imagedata , [string] ) ) ) == [number] [EOL] assert len ( os . listdir ( os . path . join ( imagedata , [string] ) ) ) == [number] [EOL] assert len ( os . listdir ( os . path . join ( imagedata , [string] ) ) ) == [number] [EOL] assert len ( os . listdir ( os . path . join ( imagedata , [string] ) ) ) == [number] [EOL] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ [number] ] ) def test_split_categories_non_equal_splits ( imagedata , categories ) : [EOL] [docstring] [EOL] train_split . split_categories ( categories , equal_splits = False ) [EOL] assert len ( os . listdir ( os . path . join ( imagedata , [string] ) ) ) == [number] [EOL] assert len ( os . listdir ( os . path . join ( imagedata , [string] ) ) ) == [number] [EOL] assert len ( os . listdir ( os . path . join ( imagedata , [string] ) ) ) == [number] [EOL] assert len ( os . listdir ( os . path . join ( imagedata , [string] ) ) ) == [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Dict [EOL] import typing [EOL] [docstring] [EOL] import os [EOL] import shutil [EOL] import tempfile [EOL] from unittest . mock import MagicMock [EOL] [EOL] import pytest [EOL] [EOL] from mila . prepare import flickr [EOL] [EOL] [EOL] class AsyncMock ( MagicMock ) : [EOL] async def __call__ ( self , * args , ** kwargs ) : [EOL] return super ( AsyncMock , self ) . __call__ ( * args , ** kwargs ) [EOL] [EOL] [EOL] @ pytest . fixture def configmock ( mocker ) : [EOL] tmp = tempfile . mkdtemp ( prefix = [string] ) [EOL] config_mock = mocker . patch ( [string] ) [EOL] config_mock . IMAGE_DIRECTORY = os . path . join ( tmp , [string] ) [EOL] config_mock . FLICKR_API_KEY = [string] [EOL] yield config_mock . IMAGE_DIRECTORY [EOL] shutil . rmtree ( tmp ) [EOL] [EOL] [EOL] def create_session_get_callable ( data ) : [EOL] class MockGet ( MagicMock ) : [EOL] async def __call__ ( self , * args , ** kwargs ) : [EOL] resp_mock = MagicMock ( ) [EOL] resp_mock . json . return_value = data [EOL] resp_mock . content = data [EOL] return resp_mock [EOL] return MockGet [EOL] [EOL] [EOL] def test_merge_params ( configmock ) : [EOL] [docstring] [EOL] params = { [string] : [string] , } [EOL] assert flickr . add_default_params ( params ) == { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [number] } [EOL] [EOL] params = { [string] : [string] } [EOL] assert flickr . add_default_params ( params ) == { [string] : [string] , [string] : [string] , [string] : [string] , [string] : [number] } [EOL] [EOL] [EOL] def test_create_flickr_url ( ) : [EOL] [docstring] [EOL] assert flickr . create_flickr_url ( { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] } , [string] ) == [string] [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_get_public_photos_empty ( mocker ) : [EOL] [docstring] [EOL] get = create_session_get_callable ( { } ) [EOL] mocker . patch . object ( flickr . session , [string] , new_callable = get ) [EOL] assert await flickr . get_public_photos ( [string] , [number] , [number] ) == [ ] [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_get_public_photos_non_empty ( mocker ) : [EOL] [docstring] [EOL] get = create_session_get_callable ( { [string] : { [string] : [ { [string] : [number] } ] } } ) [EOL] mocker . patch . object ( flickr . session , [string] , new_callable = get ) [EOL] assert await flickr . get_public_photos ( [string] , [number] , [number] ) == [ { [string] : [number] } ] [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_process_photo_matches_tag ( mocker , configmock ) : [EOL] [docstring] [EOL] mocker . patch . object ( flickr . session , [string] , new_callable = create_session_get_callable ( [string] ) ) [EOL] await flickr . process_photo ( { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [string] } , [ [string] ] ) [EOL] expected_filename = os . path . join ( configmock , [string] ) [EOL] assert os . path . exists ( expected_filename ) [EOL] with open ( expected_filename ) as f : [EOL] assert f . read ( ) == [string] [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_process_photo_no_match_one_category ( mocker , configmock ) : [EOL] [docstring] [EOL] mocker . patch . object ( flickr . session , [string] , new_callable = create_session_get_callable ( [string] ) ) [EOL] await flickr . process_photo ( { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [string] } , [ [string] ] ) [EOL] expected_filename = os . path . join ( configmock , [string] ) [EOL] assert os . path . exists ( expected_filename ) [EOL] with open ( expected_filename ) as f : [EOL] assert f . read ( ) == [string] [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_process_photo_no_match_multiple_categories ( mocker ) : [EOL] [docstring] [EOL] mocker . patch . object ( flickr . session , [string] , new_callable = create_session_get_callable ( [string] ) ) [EOL] l = mocker . patch ( [string] ) [EOL] await flickr . process_photo ( { [string] : [number] , [string] : [number] , [string] : [number] , [string] : [number] , [string] : [string] } , [ [string] , [string] ] ) [EOL] l . info . assert_any_call ( [string] ) [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_fetch_photos_stop_immediately ( mocker ) : [EOL] [docstring] [EOL] p = mocker . patch ( [string] , new_callable = AsyncMock ) [EOL] p . return_value = [ ] [EOL] mocker . patch ( [string] , new_callable = AsyncMock ) [EOL] [EOL] await flickr . fetch_photos ( [string] , [ [string] ] , [number] ) [EOL] [EOL] [comment] [EOL] p . assert_any_call ( [string] , [number] , [number] ) [EOL] with pytest . raises ( AssertionError ) : [EOL] p . assert_any_call ( [string] , [number] , [number] ) [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_fetch_photos_stop_after_paging ( mocker ) : [EOL] [docstring] [EOL] p = mocker . patch ( [string] , new_callable = AsyncMock ) [EOL] p . side_effect = [ [ { } ] , [ { } ] , [ ] ] [EOL] mocker . patch ( [string] , new_callable = AsyncMock ) [EOL] [EOL] await flickr . fetch_photos ( [string] , [ [string] ] , [number] ) [EOL] [EOL] [comment] [EOL] p . assert_any_call ( [string] , [number] , [number] ) [EOL] p . assert_any_call ( [string] , [number] , [number] ) [EOL] p . assert_any_call ( [string] , [number] , [number] ) [EOL] with pytest . raises ( AssertionError ) : [EOL] p . assert_any_call ( [string] , [number] , [number] ) [EOL] [EOL] [EOL] @ pytest . mark . asyncio async def test_fetch_photos_stop_at_limit ( mocker ) : [EOL] [docstring] [EOL] p = mocker . patch ( [string] , new_callable = AsyncMock ) [EOL] p . side_effect = [ [ { } ] , [ { } ] , [ ] ] [EOL] mocker . patch ( [string] , new_callable = AsyncMock ) [EOL] [EOL] [comment] [EOL] await flickr . fetch_photos ( [string] , [ [string] ] , [number] ) [EOL] [EOL] [comment] [EOL] p . assert_any_call ( [string] , [number] , [number] ) [EOL] with pytest . raises ( AssertionError ) : [EOL] p . assert_any_call ( [string] , [number] , [number] )	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] import io [EOL] [docstring] [EOL] import os [EOL] import shutil [EOL] import tempfile [EOL] [EOL] import pytest [EOL] [EOL] from mila import config [EOL] from mila . train import simple [EOL] from mila . serve . app import app [EOL] [EOL] tmp = tempfile . mkdtemp ( prefix = [string] ) [EOL] output_dir = os . path . join ( tmp , [string] ) [EOL] image_dir = os . path . join ( tmp , [string] ) [EOL] [EOL] [EOL] @ pytest . fixture ( scope = [string] ) def modeldata ( ) : [EOL] train_dir1 = os . path . join ( image_dir , [string] , [string] ) [EOL] train_dir2 = os . path . join ( image_dir , [string] , [string] ) [EOL] val_dir1 = os . path . join ( image_dir , [string] , [string] ) [EOL] val_dir2 = os . path . join ( image_dir , [string] , [string] ) [EOL] os . makedirs ( train_dir1 ) [EOL] os . makedirs ( train_dir2 ) [EOL] os . makedirs ( val_dir1 ) [EOL] os . makedirs ( val_dir2 ) [EOL] shutil . copyfile ( [string] , os . path . join ( train_dir1 , [string] ) ) [EOL] shutil . copyfile ( [string] , os . path . join ( val_dir1 , [string] ) ) [EOL] shutil . copyfile ( [string] , os . path . join ( train_dir2 , [string] ) ) [EOL] shutil . copyfile ( [string] , os . path . join ( val_dir2 , [string] ) ) [EOL] prev_image_dir = config . IMAGE_DIRECTORY [EOL] prev_output_dir = config . OUTPUT_DIRECTORY [EOL] config . IMAGE_DIRECTORY = image_dir [EOL] config . OUTPUT_DIRECTORY = output_dir [EOL] simple . train ( ( [number] , [number] ) , [number] , [number] , [string] . format ( output_dir ) , None , False ) [EOL] yield [EOL] [comment] [EOL] [comment] [EOL] config . IMAGE_DIRECTORY = prev_image_dir [EOL] config . OUTPUT_DIRECTORY = prev_output_dir [EOL] shutil . rmtree ( tmp ) [EOL] [EOL] [EOL] @ pytest . fixture def configmock ( mocker ) : [EOL] config_mock = mocker . patch ( [string] ) [EOL] config_mock . IMAGE_DIRECTORY = image_dir [EOL] config_mock . OUTPUT_DIRECTORY = output_dir [EOL] [EOL] [EOL] def test_index_get ( modeldata , configmock ) : [EOL] [docstring] [EOL] _ , res = app . test_client . get ( [string] ) [EOL] assert res . status == [number] [EOL] assert res . json . get ( [string] ) == [ [string] ] [EOL] [EOL] [EOL] def test_model_get_404 ( modeldata , configmock ) : [EOL] [docstring] [EOL] _ , res = app . test_client . get ( [string] ) [EOL] assert res . status == [number] [EOL] assert res . json . get ( [string] ) == [string] [EOL] [EOL] [EOL] def test_model_get_success ( modeldata , configmock ) : [EOL] [docstring] [EOL] _ , res = app . test_client . get ( [string] , headers = { [string] : [string] } ) [EOL] assert res . status == [number] [EOL] assert res . json . get ( [string] , { } ) == { [string] : None , [string] : { [string] : [number] , [string] : [number] , [string] : [number] } } [EOL] assert res . json . get ( [string] , { } ) . get ( [string] ) == [ [string] , [string] ] [EOL] assert res . json . get ( [string] , { } ) . get ( [string] , { } ) . get ( [string] ) >= [number] [EOL] assert res . json . get ( [string] , { } ) . get ( [string] , { } ) . get ( [string] ) >= [number] [EOL] assert res . json . get ( [string] , { } ) . get ( [string] , { } ) . get ( [string] ) >= [number] [EOL] assert res . json . get ( [string] , { } ) . get ( [string] , { } ) . get ( [string] ) >= [number] [EOL] [EOL] [EOL] def test_model_get_prediction ( modeldata , configmock ) : [EOL] [docstring] [EOL] f = open ( os . path . join ( image_dir , [string] , [string] , [string] ) , [string] ) [EOL] _ , res = app . test_client . post ( [string] , data = f ) [EOL] assert res . status == [number] [EOL] assert len ( res . json ) == [number] [EOL] assert [string] in res . json [ [number] ] [EOL] assert [string] in res . json [ [number] ] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any [EOL] import typing [EOL] import argparse [EOL] [docstring] [EOL] import argparse [EOL] import logging [EOL] import os [EOL] [EOL] import tensorflow as tf [EOL] [EOL] from . import config [EOL] [EOL] [comment] [EOL] tensorflow_config = tf . ConfigProto ( ) [EOL] tensorflow_config . gpu_options . allow_growth = True [EOL] sess = tf . Session ( config = tensorflow_config ) [EOL] tf . keras . backend . set_session ( sess ) [EOL] [EOL] [EOL] def flickr_run ( args ) : [EOL] [docstring] [EOL] from . prepare . flickr import run [EOL] [EOL] run ( args . user , args . tags , args . limit ) [EOL] [EOL] [EOL] def train_split_run ( args ) : [EOL] [comment] [EOL] [docstring] [EOL] from . prepare . train_split import run [EOL] [EOL] run ( equal_splits = args . equalsplits ) [EOL] [EOL] [EOL] def train_simple_run ( args ) : [EOL] [docstring] [EOL] from . train . simple import train [EOL] [EOL] train ( args . imagesize , args . epochs , args . batchsize , args . outputdir , use_class_weights = args . classweights , debug = args . debug , use_image_variations = args . imagevariations , ) [EOL] [EOL] [EOL] def train_mobilenet_run ( args ) : [EOL] [docstring] [EOL] from . train . mobilenet import train [EOL] [EOL] train ( args . epochs , args . batchsize , args . outputdir , use_class_weights = args . classweights , use_image_variations = args . imagevariations , ) [EOL] [EOL] [EOL] def predict_run ( args ) : [EOL] from . predict import predict [EOL] [EOL] predict ( args . imagefile , args . modeldir ) [EOL] [EOL] [EOL] def explore_run ( args ) : [EOL] import tempfile [EOL] from quiver_engine import server [EOL] from . import predict [EOL] [EOL] model , meta = predict . load ( args . modeldir ) [EOL] server . launch ( model , classes = meta [ [string] ] , input_folder = args . imagedir , temp_folder = tempfile . mkdtemp ( prefix = [string] ) , std = [ [number] , [number] , [number] ] , ) [comment] [EOL] [EOL] [EOL] def evaluate_run ( args ) : [EOL] from . evaluate import evaluate [EOL] [EOL] evaluate ( args . modeldir , args . imagedir ) [EOL] [EOL] [EOL] def create_parser ( ) : [EOL] [docstring] [EOL] [comment] [EOL] parser = argparse . ArgumentParser ( ) [EOL] subparsers = parser . add_subparsers ( ) [EOL] [EOL] [comment] [EOL] prepare = subparsers . add_parser ( [string] , help = [string] ) [EOL] train = subparsers . add_parser ( [string] , help = [string] ) [EOL] predict = subparsers . add_parser ( [string] , help = [string] ) [EOL] evaluate = subparsers . add_parser ( [string] , help = [string] ) [EOL] explore = subparsers . add_parser ( [string] , help = [string] ) [EOL] [EOL] [comment] [EOL] prepare_subparser = prepare . add_subparsers ( ) [EOL] flickr = prepare_subparser . add_parser ( [string] , help = [string] ) [EOL] flickr . add_argument ( [string] , help = [string] , required = True ) [EOL] flickr . add_argument ( [string] , help = [string] , required = True ) [EOL] flickr . add_argument ( [string] , help = [string] , type = int , default = [number] ) [EOL] flickr . set_defaults ( func = flickr_run ) [EOL] [EOL] train_data = prepare_subparser . add_parser ( [string] , help = [string] ) [EOL] train_data . add_argument ( [string] , action = [string] , help = [string] , ) [EOL] train_data . set_defaults ( func = train_split_run ) [EOL] [EOL] def image_size_tuple ( s ) : [EOL] [docstring] [EOL] return tuple ( int ( i ) for i in s . split ( [string] ) ) [EOL] [EOL] train_subparser = train . add_subparsers ( ) [EOL] simple = train_subparser . add_parser ( [string] , help = [string] , ) [EOL] simple . add_argument ( [string] , type = image_size_tuple , default = ( [number] , [number] ) , help = [string] , ) [EOL] simple . add_argument ( [string] , type = int , default = [number] , help = [string] ) [EOL] simple . add_argument ( [string] , type = int , default = [number] , help = [string] ) [EOL] simple . add_argument ( [string] , default = os . path . join ( config . OUTPUT_DIRECTORY , [string] ) , help = [string] , ) [EOL] simple . add_argument ( [string] , action = [string] , help = [string] ) [EOL] simple . add_argument ( [string] , action = [string] , help = [string] ) [EOL] simple . add_argument ( [string] , action = [string] , help = [string] , ) [EOL] simple . set_defaults ( func = train_simple_run ) [EOL] [EOL] mobilenet = train_subparser . add_parser ( [string] , help = [string] ) [EOL] mobilenet . add_argument ( [string] , type = int , default = [number] , help = [string] ) [EOL] mobilenet . add_argument ( [string] , type = int , default = [number] , help = [string] ) [EOL] mobilenet . add_argument ( [string] , default = os . path . join ( config . OUTPUT_DIRECTORY , [string] ) , help = [string] , ) [EOL] mobilenet . add_argument ( [string] , action = [string] , help = [string] ) [EOL] mobilenet . add_argument ( [string] , action = [string] , help = [string] , ) [EOL] simple . set_defaults ( func = train_simple_run ) [EOL] mobilenet . set_defaults ( func = train_mobilenet_run ) [EOL] [EOL] predict . add_argument ( [string] , help = [string] ) [EOL] predict . add_argument ( [string] , help = [string] , ) [EOL] predict . set_defaults ( func = predict_run ) [EOL] [EOL] explore . add_argument ( [string] , help = [string] ) [EOL] explore . add_argument ( [string] , help = [string] , ) [EOL] explore . set_defaults ( func = explore_run ) [EOL] [EOL] evaluate . add_argument ( [string] , help = [string] , ) [EOL] evaluate . add_argument ( [string] , default = [string] , help = [string] , choices = [ [string] , [string] , [string] ] , ) [EOL] evaluate . set_defaults ( func = evaluate_run ) [EOL] [EOL] return parser [EOL] [EOL] [EOL] def main ( args = None ) : [EOL] [docstring] [EOL] logging . basicConfig ( level = logging . INFO ) [EOL] parser = create_parser ( ) [EOL] args = parser . parse_args ( args ) [EOL] args . func ( args ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] main ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Dict [EOL] import typing [EOL] import logging [EOL] [docstring] [EOL] import io [EOL] import json [EOL] import os [EOL] import logging [EOL] [EOL] import numpy as np [EOL] import tensorflow as tf [EOL] [EOL] from . import util [EOL] [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def load ( model_output_dir ) : [EOL] logger . info ( [string] . format ( model_output_dir ) ) [EOL] model_filename = os . path . join ( model_output_dir , [string] ) [EOL] metadata_filename = os . path . join ( model_output_dir , [string] ) [EOL] if not os . path . exists ( model_filename ) : [EOL] return None , None [EOL] [EOL] model = tf . keras . models . load_model ( model_filename ) [EOL] [EOL] meta = None [EOL] with open ( metadata_filename ) as f : [EOL] meta = json . load ( f ) [EOL] [EOL] return model , meta [EOL] [EOL] [EOL] def model_info ( model_output_dir ) : [EOL] model , meta = load ( model_output_dir ) [EOL] if not model : [EOL] return None [EOL] [EOL] batch_size , rows , cols , channels = model . inputs [ [number] ] . get_shape ( ) . as_list ( ) [EOL] return { [string] : { [string] : batch_size , [string] : { [string] : rows , [string] : cols , [string] : channels } , } , [string] : meta , } [EOL] [EOL] [EOL] def prepare_image ( image_file , target_size ) : [EOL] if isinstance ( image_file , bytes ) : [EOL] logger . debug ( [string] ) [EOL] img = tf . keras . preprocessing . image . load_img ( io . BytesIO ( image_file ) , target_size = target_size ) [EOL] yield ( [string] , tf . keras . preprocessing . image . img_to_array ( img ) ) [EOL] elif os . path . isfile ( image_file ) : [EOL] logger . debug ( [string] ) [EOL] img = tf . keras . preprocessing . image . load_img ( image_file , target_size = target_size ) [EOL] yield ( image_file , tf . keras . preprocessing . image . img_to_array ( img ) ) [EOL] elif os . path . isdir ( image_file ) : [EOL] logger . debug ( [string] ) [EOL] for filename in sorted ( os . listdir ( image_file ) ) : [EOL] filename = os . path . join ( image_file , filename ) [EOL] img = tf . keras . preprocessing . image . load_img ( filename , target_size = target_size ) [EOL] yield ( filename , tf . keras . preprocessing . image . img_to_array ( img ) ) [EOL] [EOL] [EOL] model_cache = { } [EOL] [EOL] [EOL] def predict ( image_file , model_output_dir , cache_model = False ) : [EOL] [docstring] [EOL] if model_output_dir in model_cache : [EOL] logger . info ( [string] ) [EOL] model , meta = model_cache . get ( model_output_dir ) [EOL] else : [EOL] logger . info ( [string] ) [EOL] model , meta = load ( model_output_dir ) [EOL] [EOL] if cache_model : [EOL] logger . debug ( [string] ) [EOL] model_cache [ model_output_dir ] = ( model , meta ) [EOL] [EOL] classes = meta [ [string] ] [EOL] trainer = meta . get ( [string] , [string] ) [EOL] _ , rows , cols , channels = ( model . inputs [ [number] ] . get_shape ( ) . as_list ( ) ) [comment] [EOL] assert channels == [number] [EOL] assert len ( classes ) >= [number] [EOL] logger . info ( [string] . format ( trainer ) ) [EOL] logger . info ( [string] . format ( rows , cols ) ) [EOL] logger . info ( [string] . format ( classes ) ) [EOL] [EOL] image_preprocessing_fun = util . image_preprocessing_fun ( trainer ) [EOL] [EOL] image_iterator = prepare_image ( image_file , ( rows , cols ) ) [EOL] [EOL] logger . info ( [string] ) [EOL] predictions = [ ] [EOL] [EOL] for i , ( img_file , img ) in enumerate ( image_iterator ) : [EOL] img = image_preprocessing_fun ( img ) [EOL] prediction = model . predict_on_batch ( np . array ( [ img ] ) ) [EOL] prediction = prediction [ [number] ] . tolist ( ) [comment] [EOL] outcomes = None [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] if len ( prediction ) == [number] : [EOL] outcome_index = round ( prediction [ [number] ] ) [EOL] not_outcome_index = ( outcome_index + [number] ) % [number] [EOL] outcomes = { classes [ outcome_index ] : [number] , classes [ not_outcome_index ] : [number] } [EOL] else : [EOL] logger . info ( [string] . format ( img_file , classes [ np . argmax ( prediction ) ] ) ) [EOL] outcomes = { classes [ i ] : prediction [ i ] for i , v in enumerate ( prediction ) } [EOL] [EOL] logger . info ( [string] . format ( i , img_file , outcomes ) ) [EOL] predictions . append ( outcomes ) [EOL] [EOL] return predictions [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 $typing.Dict[typing.Any,typing.Any]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[docstring] [EOL] import os [EOL] [EOL] FLICKR_API_KEY = os . environ . get ( [string] , [string] ) [EOL] FLICKR_API_SECRET = os . environ . get ( [string] , [string] ) [EOL] IMAGE_DIRECTORY = os . environ . get ( [string] , [string] ) [EOL] OUTPUT_DIRECTORY = os . environ . get ( [string] , [string] ) [EOL] [EOL] [comment] [EOL] PORT = int ( os . environ . get ( [string] , [number] ) ) [EOL] [EOL] TRAINER_SIMPLE = [string] [EOL] TRAINER_MOBILENET = [string] [EOL]	0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.int$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $builtins.str$ 0 0 0
from typing import Union , Dict , Literal , Any , List [EOL] import typing [EOL] import logging [EOL] import typing_extensions [EOL] [docstring] [EOL] import logging [EOL] import os [EOL] import itertools [EOL] [EOL] import matplotlib . pyplot as plt [EOL] import numpy as np [EOL] from sklearn . metrics import classification_report , confusion_matrix [EOL] [EOL] from . predict import predict [EOL] from . import util , config [EOL] [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def plot_confusion_matrix ( cm , classes , normalize = False , title = [string] , cmap = plt . cm . Blues ) : [EOL] [docstring] [EOL] if normalize : [EOL] cm = cm . astype ( [string] ) / cm . sum ( axis = [number] ) [ : , np . newaxis ] [EOL] print ( [string] ) [EOL] else : [EOL] print ( [string] ) [EOL] [EOL] plt . figure ( ) [EOL] plt . imshow ( cm , interpolation = [string] , cmap = cmap ) [EOL] plt . title ( title ) [EOL] plt . colorbar ( ) [EOL] tick_marks = np . arange ( len ( classes ) ) [EOL] plt . xticks ( tick_marks , classes , rotation = [number] ) [EOL] plt . yticks ( tick_marks , classes ) [EOL] [EOL] fmt = [string] if normalize else [string] [EOL] thresh = cm . max ( ) / [number] [EOL] for i , j in itertools . product ( range ( cm . shape [ [number] ] ) , range ( cm . shape [ [number] ] ) ) : [EOL] plt . text ( j , i , format ( cm [ i , j ] , fmt ) , horizontalalignment = [string] , color = [string] if cm [ i , j ] > thresh else [string] , ) [EOL] [EOL] plt . ylabel ( [string] ) [EOL] plt . xlabel ( [string] ) [EOL] plt . tight_layout ( ) [EOL] [EOL] [EOL] def evaluate ( model_output_dir , image_dir = [string] ) : [EOL] [comment] [EOL] [comment] [EOL] categories = util . find_categories ( image_dir ) [EOL] y_true = [ ] [EOL] y_pred = [ ] [EOL] y_pred_softmax = [ ] [EOL] [EOL] category_mapping = { category : i for i , category in enumerate ( categories ) } [EOL] [EOL] [comment] [EOL] for idx , category in enumerate ( categories ) : [EOL] path = os . path . join ( config . IMAGE_DIRECTORY , image_dir , category ) [EOL] predictions = predict ( path , model_output_dir , cache_model = True ) [EOL] for prediction in predictions : [EOL] y_true . append ( idx ) [EOL] [EOL] [comment] [EOL] sorted_prediction_pairs = sorted ( prediction . items ( ) , key = lambda item : item [ [number] ] , reverse = True ) [EOL] max_prediction = sorted_prediction_pairs [ [number] ] [EOL] predicted_label = category_mapping [ max_prediction [ [number] ] ] [EOL] predicted_softmax = max_prediction [ [number] ] [EOL] y_pred . append ( predicted_label ) [EOL] y_pred_softmax . append ( predicted_softmax ) [EOL] [EOL] labels = list ( range ( len ( categories ) ) ) [EOL] rep = classification_report ( y_true , y_pred , labels = labels , target_names = categories ) [EOL] logger . info ( [string] ) [EOL] logger . info ( [string] ) [EOL] logger . info ( [string] . format ( rep ) ) [EOL] [EOL] cm = confusion_matrix ( y_true , y_pred , labels = labels ) [EOL] plot_confusion_matrix ( cm , categories , normalize = True ) [EOL] plot_confusion_matrix ( cm , categories ) [EOL] plt . show ( ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List [EOL] import typing [EOL] import builtins [EOL] import logging [EOL] [docstring] [EOL] import logging [EOL] import os [EOL] import typing [EOL] [EOL] import tensorflow as tf [EOL] from sklearn . utils import class_weight [EOL] [EOL] from . import config [EOL] [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def find_categories ( from_dir = [string] ) : [EOL] [docstring] [EOL] dirs = os . listdir ( os . path . join ( config . IMAGE_DIRECTORY , from_dir ) ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] dirs . sort ( key = lambda x : [string] if x . startswith ( [string] ) else x ) [EOL] [EOL] return dirs [EOL] [EOL] [EOL] def num_samples ( from_dir = [string] ) : [EOL] [docstring] [EOL] categories = find_categories ( from_dir = from_dir ) [EOL] return sum ( len ( os . listdir ( os . path . join ( config . IMAGE_DIRECTORY , from_dir , category ) ) ) for category in categories ) [EOL] [EOL] [EOL] def compute_class_weight ( category_mapping , from_dir = [string] ) : [EOL] [docstring] [EOL] categories = find_categories ( from_dir = from_dir ) [EOL] y = [ category_mapping [ category ] for category in categories for _ in range ( len ( os . listdir ( os . path . join ( config . IMAGE_DIRECTORY , from_dir , category ) ) ) ) ] [EOL] [EOL] class_weights = class_weight . compute_class_weight ( [string] , list ( set ( category_mapping . values ( ) ) ) , y ) [EOL] [EOL] return { i : v for i , v in enumerate ( class_weights ) } [EOL] [EOL] [EOL] def image_preprocessing_fun ( trainer ) : [EOL] if trainer == config . TRAINER_SIMPLE : [EOL] return lambda x : x / [number] [EOL] [EOL] if trainer == config . TRAINER_MOBILENET : [EOL] return tf . keras . applications . mobilenet_v2 . preprocess_input [EOL] [EOL] logger . warning ( [string] . format ( trainer ) ) [EOL] [EOL] [comment] [EOL] return lambda x : x / [number] [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[docstring] [EOL]	0 0
from typing import List [EOL] import typing [EOL] import logging [EOL] [docstring] [EOL] import logging [EOL] import math [EOL] import os [EOL] import random [EOL] import shutil [EOL] [EOL] from . . import config , util [EOL] [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def split_categories ( categories , equal_splits = True ) : [EOL] [docstring] [EOL] [comment] [EOL] shutil . rmtree ( os . path . join ( config . IMAGE_DIRECTORY , [string] ) , ignore_errors = True ) [EOL] shutil . rmtree ( os . path . join ( config . IMAGE_DIRECTORY , [string] ) , ignore_errors = True ) [EOL] [EOL] min_images = min ( len ( os . listdir ( os . path . join ( config . IMAGE_DIRECTORY , [string] , category ) ) ) for category in categories ) [EOL] [EOL] if min_images < [number] : [EOL] logger . info ( [string] ) [EOL] [EOL] if equal_splits : [EOL] logger . info ( [string] . format ( min_images ) ) [EOL] [EOL] for category in categories : [EOL] logger . info ( [string] . format ( category ) ) [EOL] [EOL] [comment] [EOL] images = os . listdir ( os . path . join ( config . IMAGE_DIRECTORY , [string] , category ) ) [EOL] random . shuffle ( images ) [EOL] [EOL] if equal_splits : [EOL] images = images [ : min_images ] [EOL] [EOL] train_images = images [EOL] validation_images = [ ] [EOL] [EOL] [comment] [EOL] [comment] [EOL] if min_images >= [number] : [EOL] [comment] [EOL] split_point = math . ceil ( len ( images ) * [number] ) [EOL] train_images = images [ : split_point ] [EOL] validation_images = images [ split_point : ] [EOL] [EOL] logger . info ( [string] . format ( len ( train_images ) , len ( validation_images ) ) ) [EOL] [EOL] [comment] [EOL] os . makedirs ( os . path . join ( config . IMAGE_DIRECTORY , [string] , category ) , exist_ok = True ) [EOL] os . makedirs ( os . path . join ( config . IMAGE_DIRECTORY , [string] , category ) , exist_ok = True ) [EOL] [EOL] [comment] [EOL] for train_image in train_images : [EOL] shutil . copy ( os . path . join ( config . IMAGE_DIRECTORY , [string] , category , train_image ) , os . path . join ( config . IMAGE_DIRECTORY , [string] , category , train_image ) , ) [EOL] for validation_image in validation_images : [EOL] shutil . copy ( os . path . join ( config . IMAGE_DIRECTORY , [string] , category , validation_image ) , os . path . join ( config . IMAGE_DIRECTORY , [string] , category , validation_image ) , ) [EOL] [EOL] [EOL] def run ( equal_splits = True ) : [EOL] [docstring] [EOL] categories = util . find_categories ( ) [EOL] split_categories ( categories , equal_splits = equal_splits ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
[docstring] [EOL]	0 0
from typing import Set , Any , List , Dict [EOL] import typing [EOL] import builtins [EOL] import logging [EOL] [docstring] [EOL] import logging [EOL] import os [EOL] [EOL] import requests_threads [EOL] [EOL] from . . import config [EOL] [EOL] FLICKR_REST = [string] [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] session = requests_threads . AsyncSession ( n = [number] ) [EOL] [EOL] [EOL] def add_default_params ( params ) : [EOL] [docstring] [EOL] params . update ( { [string] : config . FLICKR_API_KEY , [string] : [string] , [string] : [number] } ) [EOL] return params [EOL] [EOL] [EOL] def create_flickr_url ( photo , size ) : [EOL] [docstring] [EOL] [comment] [EOL] return [string] . format ( size = size , ** photo ) [EOL] [EOL] [EOL] async def get_public_photos ( user_id , page , per_page ) : [EOL] [docstring] [EOL] params = add_default_params ( { [string] : [string] , [string] : user_id , [string] : [number] , [string] : [string] , [string] : page , [string] : per_page , [string] : [string] , } ) [EOL] [EOL] resp = await session . get ( FLICKR_REST , params = params ) [EOL] [EOL] [comment] [EOL] return resp . json ( ) . get ( [string] , { } ) . get ( [string] , [ ] ) [EOL] [EOL] [EOL] async def process_photo ( photo , tags ) : [EOL] [docstring] [EOL] url = create_flickr_url ( photo , [string] ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] valid_tags = set ( tags ) . intersection ( photo . get ( [string] , [string] ) . split ( [string] ) ) [EOL] filename = [string] [EOL] if valid_tags : [EOL] filename += [string] . format ( config . IMAGE_DIRECTORY , valid_tags . pop ( ) , photo [ [string] ] ) [EOL] elif len ( tags ) == [number] : [EOL] filename += [string] . format ( config . IMAGE_DIRECTORY , tags [ [number] ] , photo [ [string] ] ) [EOL] [EOL] [comment] [EOL] if filename : [EOL] os . makedirs ( os . path . dirname ( filename ) , exist_ok = True ) [EOL] logger . debug ( [string] . format ( url ) ) [EOL] resp = await session . get ( url , stream = True ) [EOL] [EOL] with open ( filename , [string] ) as f : [EOL] f . write ( resp . content ) [EOL] else : [EOL] logger . info ( [string] . format ( url ) ) [EOL] [EOL] [EOL] async def fetch_photos ( user_id , tags , limit ) : [EOL] [docstring] [EOL] found_photos = [number] [EOL] page , per_page = [number] , [number] [EOL] [EOL] futures = [ ] [EOL] [EOL] while True : [EOL] logger . info ( [string] . format ( per_page , page ) ) [EOL] photos = await get_public_photos ( user_id , page , per_page ) [EOL] page += [number] [EOL] found_photos += len ( photos ) [EOL] [EOL] for photo in photos : [EOL] futures . append ( process_photo ( photo , tags ) ) [EOL] [EOL] for future in futures : [EOL] await future [EOL] [EOL] futures = [ ] [EOL] [EOL] if not photos or found_photos >= limit : [EOL] break [EOL] [EOL] logger . info ( [string] ) [EOL] [EOL] [EOL] def run ( user_id , tags , limit ) : [EOL] [docstring] [EOL] [EOL] async def _run ( ) : [EOL] await fetch_photos ( user_id , tags . split ( [string] ) , limit ) [EOL] [EOL] session . run ( _run ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.dict$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0
[docstring] [EOL]	0 0
from typing import Any , List [EOL] import typing [EOL] import jinja2 [EOL] [docstring] [EOL] import logging [EOL] import os [EOL] [EOL] from sanic import Sanic , response [EOL] from sanic_cors import CORS [EOL] from jinja2 import Environment , FileSystemLoader [EOL] [EOL] from . . import config , predict [EOL] [EOL] [EOL] env = Environment ( loader = FileSystemLoader ( os . path . join ( os . path . dirname ( os . path . abspath ( __file__ ) ) , [string] ) ) ) [EOL] app = Sanic ( ) [EOL] CORS ( app ) [EOL] [EOL] [EOL] def render ( template , ** kwargs ) : [EOL] return env . get_template ( template ) . render ( ** kwargs ) [EOL] [EOL] [EOL] @ app . route ( [string] ) async def model_root ( request ) : [EOL] models = os . listdir ( config . OUTPUT_DIRECTORY ) [EOL] return response . json ( { [string] : models } ) [EOL] [EOL] [EOL] @ app . route ( [string] ) async def model_info ( request , model_name ) : [EOL] model_info = predict . model_info ( os . path . join ( config . OUTPUT_DIRECTORY , model_name ) ) [EOL] if not model_info : [EOL] return response . json ( { [string] : [string] . format ( model_name ) } , status = [number] ) [EOL] [EOL] if request . headers . get ( [string] ) == [string] : [EOL] return response . json ( model_info ) [EOL] [EOL] [comment] [EOL] return response . html ( render ( [string] , ** model_info ) ) [EOL] [EOL] [EOL] @ app . route ( [string] , methods = [ [string] , [string] ] ) async def model_prediction ( request , model_name ) : [EOL] predictions = predict . predict ( request . body , os . path . join ( config . OUTPUT_DIRECTORY , model_name ) , cache_model = True , ) [EOL] return response . json ( predictions ) [EOL] [EOL] [EOL] if __name__ == [string] : [EOL] logging . basicConfig ( level = logging . DEBUG ) [EOL] app . run ( host = [string] , port = config . PORT ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $jinja2.environment.Environment$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $jinja2.environment.Environment$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Tuple , Dict , Literal , Any , List [EOL] import typing [EOL] import builtins [EOL] import logging [EOL] import typing_extensions [EOL] [docstring] [EOL] import logging [EOL] import math [EOL] import os [EOL] [EOL] import tensorflow as tf [EOL] [EOL] from . . import util , config [EOL] from . import create_image_iterators , prepare_callbacks [EOL] [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def setup_network ( image_size , num_classes ) : [EOL] [docstring] [EOL] [comment] [EOL] [comment] [EOL] base_model = tf . keras . applications . mobilenet_v2 . MobileNetV2 ( weights = [string] , include_top = False , input_shape = image_size + ( [number] , ) ) [EOL] x = base_model . output [EOL] x = tf . keras . layers . GlobalAveragePooling2D ( ) ( x ) [EOL] x = tf . keras . layers . Dense ( [number] , activation = [string] ) ( x ) [EOL] predictions = tf . keras . layers . Dense ( num_classes , activation = [string] ) ( x ) [EOL] [EOL] model = tf . keras . models . Model ( inputs = base_model . input , outputs = predictions ) [EOL] [EOL] [comment] [EOL] for layer in base_model . layers : [EOL] layer . trainable = False [EOL] [EOL] model . compile ( optimizer = [string] , loss = [string] if num_classes == [number] else [string] , metrics = [ [string] ] , ) [EOL] [EOL] return base_model , model [EOL] [EOL] [EOL] def train ( epochs , batch_size , output_dir , use_class_weights = False , use_image_variations = False ) : [EOL] [comment] [EOL] image_size = ( [number] , [number] ) [EOL] [EOL] os . makedirs ( output_dir , exist_ok = True ) [EOL] model_filename = os . path . join ( output_dir , [string] ) [EOL] model_meta_filename = os . path . join ( output_dir , [string] ) [EOL] [EOL] categories = util . find_categories ( [string] ) [EOL] [EOL] [comment] [EOL] base_model , model = setup_network ( image_size , len ( categories ) ) [EOL] train_images , validation_images = create_image_iterators ( image_size , batch_size , categories , preprocessing_function = util . image_preprocessing_fun ( config . TRAINER_MOBILENET ) , use_image_variations = use_image_variations , ) [EOL] [EOL] model_checkpoint_monitor = [string] [EOL] validation_samples = util . num_samples ( [string] ) [EOL] if validation_samples == [number] : [EOL] logger . info ( [string] ) [EOL] model_checkpoint_monitor = [string] [EOL] [EOL] callbacks = prepare_callbacks ( model_filename , model_meta_filename , categories , batch_size , config . TRAINER_MOBILENET , monitor = model_checkpoint_monitor , ) [EOL] [EOL] steps = util . num_samples ( [string] ) [EOL] validation_steps = validation_samples [EOL] steps_per_epoch = math . ceil ( steps / batch_size ) [EOL] validation_steps = math . ceil ( validation_steps / batch_size ) [EOL] if steps_per_epoch < [number] : [EOL] steps_per_epoch = [number] [EOL] [EOL] [comment] [EOL] if validation_samples == [number] : [EOL] validation_steps = None [EOL] validation_images = None [EOL] elif validation_steps < [number] : [EOL] validation_steps = [number] [EOL] [EOL] class_weights = None [EOL] if use_class_weights : [EOL] class_weights = util . compute_class_weight ( train_images . class_indices , [string] ) [EOL] reverse_mapping = { v : k for k , v in train_images . class_indices . items ( ) } [EOL] nice_class_weights = { reverse_mapping [ i ] : v for i , v in class_weights . items ( ) } [EOL] logger . info ( [string] . format ( nice_class_weights ) ) [EOL] [EOL] logger . info ( [string] . format ( epochs , steps_per_epoch , validation_steps ) ) [EOL] [EOL] [comment] [EOL] model . fit_generator ( train_images , steps_per_epoch = steps_per_epoch , epochs = [number] , validation_data = validation_images , validation_steps = validation_steps , callbacks = callbacks , class_weight = class_weights , ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] [comment] [EOL] for layer in base_model . layers [ - [number] : ] : [EOL] layer . trainable = True [EOL] [EOL] logger . info ( [string] ) [EOL] [EOL] [comment] [EOL] model . compile ( optimizer = tf . keras . optimizers . SGD ( lr = [number] , momentum = [number] ) , loss = [string] [EOL] if len ( categories ) == [number] [EOL] else [string] , metrics = [ [string] ] , ) [EOL] [EOL] [comment] [EOL] model . fit_generator ( train_images , steps_per_epoch = steps_per_epoch , epochs = epochs , validation_data = validation_images , validation_steps = validation_steps , callbacks = callbacks , class_weight = class_weights , ) [EOL] [EOL] logger . info ( [string] ) [EOL] res = model . evaluate_generator ( train_images , steps = steps_per_epoch , verbose = [number] ) [EOL] for metric in zip ( model . metrics_names , res ) : [EOL] logger . info ( [string] . format ( metric [ [number] ] , metric [ [number] ] ) ) [EOL] [EOL] if validation_samples > [number] : [EOL] res = model . evaluate_generator ( validation_images , steps = validation_steps ) [EOL] logger . info ( [string] ) [EOL] for metric in zip ( model . metrics_names , res ) : [EOL] logger . info ( [string] . format ( metric [ [number] ] , metric [ [number] ] ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import List , Any , Dict [EOL] import typing [EOL] import builtins [EOL] import logging [EOL] [docstring] [EOL] import logging [EOL] import math [EOL] import os [EOL] [EOL] from tensorflow . keras . models import Model [EOL] from tensorflow . keras . layers import Input , Dense , Conv2D , MaxPooling2D , Dropout , Flatten [EOL] [EOL] from . . import config , util [EOL] from . import create_image_iterators , prepare_callbacks [EOL] [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def setup_network ( image_shape , num_classes ) : [EOL] [docstring] [EOL] rows , cols = image_shape [EOL] inputs = Input ( shape = ( rows , cols , [number] ) ) [EOL] [EOL] [comment] [EOL] x = Conv2D ( [number] , ( [number] , [number] ) , activation = [string] ) ( inputs ) [EOL] x = MaxPooling2D ( pool_size = ( [number] , [number] ) ) ( x ) [EOL] x = Conv2D ( [number] , ( [number] , [number] ) , activation = [string] ) ( x ) [EOL] x = MaxPooling2D ( pool_size = ( [number] , [number] ) ) ( x ) [EOL] x = Conv2D ( [number] , ( [number] , [number] ) , activation = [string] ) ( x ) [EOL] x = MaxPooling2D ( pool_size = ( [number] , [number] ) ) ( x ) [EOL] [EOL] [comment] [EOL] x = Flatten ( ) ( x ) [EOL] x = Dense ( [number] , activation = [string] ) ( x ) [EOL] x = Dropout ( [number] ) ( x ) [EOL] predictions = Dense ( num_classes , activation = [string] ) ( x ) [EOL] [EOL] model = Model ( inputs = inputs , outputs = predictions ) [EOL] model . compile ( optimizer = [string] , loss = [string] if num_classes == [number] else [string] , metrics = [ [string] ] , ) [EOL] return model [EOL] [EOL] [EOL] def train ( image_size , epochs , batch_size , output_dir , tensorboard_logs = [string] , save_model_checkpoints = True , early_stopping = True , use_class_weights = False , debug = False , use_image_variations = False , ) : [EOL] os . makedirs ( output_dir , exist_ok = True ) [EOL] model_filename = os . path . join ( output_dir , [string] ) [EOL] model_meta_filename = os . path . join ( output_dir , [string] ) [EOL] [EOL] categories = util . find_categories ( [string] ) [EOL] [EOL] [comment] [EOL] model = setup_network ( image_size , len ( categories ) ) [EOL] train_images , validation_images = create_image_iterators ( image_size , batch_size , categories , save_output = debug , preprocessing_function = util . image_preprocessing_fun ( config . TRAINER_SIMPLE ) , use_image_variations = use_image_variations , ) [EOL] [EOL] [comment] [EOL] [comment] [EOL] model_checkpoint_monitor = [string] [EOL] validation_samples = util . num_samples ( [string] ) [EOL] if validation_samples == [number] : [EOL] logger . info ( [string] ) [EOL] model_checkpoint_monitor = [string] [EOL] [EOL] callbacks = prepare_callbacks ( model_filename , model_meta_filename , categories , batch_size , config . TRAINER_SIMPLE , tensorboard_logs = tensorboard_logs , save_model_checkpoints = save_model_checkpoints , early_stopping = early_stopping , monitor = model_checkpoint_monitor , ) [EOL] [EOL] steps = util . num_samples ( [string] ) [EOL] validation_steps = validation_samples [EOL] steps_per_epoch = math . ceil ( steps / batch_size ) [EOL] validation_steps = math . ceil ( validation_steps / batch_size ) [EOL] if steps_per_epoch < [number] : [EOL] steps_per_epoch = [number] [EOL] [EOL] [comment] [EOL] if validation_samples == [number] : [EOL] validation_steps = None [EOL] validation_images = None [EOL] elif validation_steps < [number] : [EOL] validation_steps = [number] [EOL] [EOL] class_weights = None [EOL] if use_class_weights : [EOL] class_weights = util . compute_class_weight ( train_images . class_indices , [string] ) [EOL] reverse_mapping = { v : k for k , v in train_images . class_indices . items ( ) } [EOL] nice_class_weights = { reverse_mapping [ i ] : v for i , v in class_weights . items ( ) } [EOL] logger . info ( [string] . format ( nice_class_weights ) ) [EOL] [EOL] logger . info ( [string] . format ( epochs , steps_per_epoch , validation_steps ) ) [EOL] [EOL] [comment] [EOL] model . fit_generator ( train_images , steps_per_epoch = steps_per_epoch , epochs = epochs , validation_data = validation_images , validation_steps = validation_steps , callbacks = callbacks , class_weight = class_weights , use_multiprocessing = False , workers = [number] , ) [EOL] [EOL] [comment] [EOL] os . makedirs ( output_dir , exist_ok = True ) [EOL] if not save_model_checkpoints : [EOL] model . save ( model_filename ) [EOL] [EOL] res = model . evaluate_generator ( train_images , steps = steps_per_epoch ) [EOL] logger . info ( [string] ) [EOL] for metric in zip ( model . metrics_names , res ) : [EOL] logger . info ( [string] . format ( metric [ [number] ] , metric [ [number] ] ) ) [EOL] [EOL] if validation_samples > [number] : [EOL] res = model . evaluate_generator ( validation_images , steps = validation_steps ) [EOL] logger . info ( [string] ) [EOL] for metric in zip ( model . metrics_names , res ) : [EOL] logger . info ( [string] . format ( metric [ [number] ] , metric [ [number] ] ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , List [EOL] import typing [EOL] import builtins [EOL] import logging [EOL] [docstring] [EOL] import logging [EOL] import os [EOL] [EOL] from tensorflow . keras . callbacks import ( TensorBoard , ModelCheckpoint , EarlyStopping , ReduceLROnPlateau , ) [EOL] from tensorflow . keras . preprocessing . image import ImageDataGenerator [EOL] [EOL] from . . import config , util [EOL] from . import callback [EOL] [EOL] logger = logging . getLogger ( __name__ ) [EOL] [EOL] [EOL] def create_image_iterators ( image_size , batch_size , categories , save_output = False , preprocessing_function = None , use_image_variations = False , ) : [EOL] [docstring] [EOL] logger . info ( [string] . format ( len ( categories ) ) ) [EOL] if save_output : [EOL] output_images = os . path . join ( config . IMAGE_DIRECTORY , [string] ) [EOL] os . makedirs ( output_images , exist_ok = True ) [EOL] train_generator = ImageDataGenerator ( preprocessing_function = preprocessing_function , shear_range = [number] if use_image_variations else [number] , zoom_range = [number] if use_image_variations else [number] , horizontal_flip = True if use_image_variations else False , ) [EOL] train_generator = train_generator . flow_from_directory ( os . path . join ( config . IMAGE_DIRECTORY , [string] ) , classes = categories , class_mode = [string] , target_size = image_size , batch_size = batch_size , save_to_dir = output_images if save_output else None , save_prefix = [string] , ) [EOL] [EOL] [comment] [EOL] validation_generator = ImageDataGenerator ( preprocessing_function = preprocessing_function ) [EOL] validation_generator = validation_generator . flow_from_directory ( os . path . join ( config . IMAGE_DIRECTORY , [string] ) , classes = categories , class_mode = [string] , target_size = image_size , batch_size = batch_size , save_to_dir = output_images if save_output else None , save_prefix = [string] , ) [EOL] [EOL] return train_generator , validation_generator [EOL] [EOL] [EOL] def prepare_callbacks ( model_filename , model_meta_filename , categories , batch_size , trainer , tensorboard_logs = True , save_model_checkpoints = True , early_stopping = True , reduce_learning_on_plateau = True , monitor = [string] , ) : [EOL] [docstring] [EOL] callbacks = [ ] [EOL] if tensorboard_logs : [EOL] callbacks . append ( TensorBoard ( log_dir = [string] , histogram_freq = [number] , batch_size = batch_size , write_graph = True , write_images = True , ) ) [EOL] if save_model_checkpoints : [EOL] callbacks . append ( ModelCheckpoint ( model_filename , monitor = monitor , save_best_only = True , verbose = [number] ) ) [EOL] [EOL] if early_stopping : [EOL] callbacks . append ( EarlyStopping ( monitor = monitor , patience = [number] , verbose = [number] ) ) [EOL] [EOL] if reduce_learning_on_plateau : [EOL] callbacks . append ( ReduceLROnPlateau ( monitor = monitor , verbose = [number] ) ) [EOL] [EOL] callbacks . append ( callback . ModelMetadata ( model_meta_filename , categories , trainer ) ) [EOL] [EOL] return callbacks [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.tuple$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $logging.Logger$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import Any , Dict [EOL] import typing [EOL] [docstring] [EOL] import json [EOL] import logging [EOL] [EOL] from tensorflow . keras . callbacks import Callback [EOL] [EOL] [EOL] class ModelMetadata ( Callback ) : [EOL] def __init__ ( self , filename , categories , trainer ) : [EOL] super ( ) . __init__ ( ) [EOL] [EOL] self . filename = filename [EOL] self . categories = categories [EOL] self . logger = logging . getLogger ( __name__ ) [EOL] self . trainer = trainer [EOL] [EOL] def on_epoch_end ( self , epoch , logs = None ) : [EOL] [comment] [EOL] [comment] [EOL] logs = logs or { } [EOL] logs = { k : float ( v ) for k , v in logs . items ( ) } [EOL] with open ( self . filename , [string] ) as f : [EOL] json . dump ( { [string] : self . categories , [string] : dict ( ** logs ) , [string] : self . trainer , } , f , ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,builtins.float]$ 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,builtins.float]$ 0 $typing.Dict[typing.Any,builtins.float]$ 0 0 0 0 $typing.Dict[typing.Any,builtins.float]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,builtins.float]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Dict[typing.Any,builtins.float]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0