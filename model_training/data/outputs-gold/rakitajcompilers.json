from typing import List , Tuple [EOL] import builtins [EOL] import typing [EOL] from typing import List , Tuple [EOL] import os [EOL] [EOL] class ExampleProgram ( object ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , name , source_location ) : [EOL] self . name = name [EOL] self . source_location = source_location [EOL] self . source = self . get_text ( self . source_location ) [EOL] [EOL] def get_text ( self , location ) : [EOL] with open ( location ) as file : [EOL] program = file . read ( ) [EOL] return program [EOL] [EOL] [EOL] class ExampleProgramWithTokens ( ExampleProgram ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , name , source_location , tokens_location ) : [EOL] ExampleProgram . __init__ ( self , name , source_location ) [EOL] self . tokens = self . get_text ( tokens_location ) . split ( ) [EOL] [EOL] def get_test_directory ( ) : [EOL] return os . getenv ( [string] ) [EOL] [EOL] def get_test_file_location ( filename ) : [EOL] return f"{ get_test_directory ( ) } [string] { filename }" [EOL] [EOL] def create_test_tuple ( name ) : [EOL] return ( name , get_test_file_location ( f"{ name } [string] " ) , get_test_file_location ( f"{ name } [string] " ) ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 $typing.List[builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Tuple[builtins.str,builtins.str,builtins.str]$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
from typing import List , Any , Tuple [EOL] import c [EOL] import builtins [EOL] import typing [EOL] import re [EOL] from typing import List , Tuple [EOL] from tokens import Token , OpenParen , CloseParen , OpenBrace , CloseBrace , Semicolon , ReturnKeyword , Identifier , IntegerLiteral , IntKeyword [EOL] [EOL] class Token ( object ) : [EOL] [EOL] def __init__ ( self , name , regex_pattern ) : [EOL] self . name = name [EOL] self . regex_pattern = regex_pattern [EOL] [EOL] def __repr__ ( self ) : [EOL] return f" [string] { self . name } [string] { self . regex_pattern }" [EOL] [EOL] VALID_TOKENS = { OpenBrace ( ) . name : OpenBrace , CloseBrace ( ) . name : CloseBrace , OpenParen ( ) . name : OpenParen , CloseParen ( ) . name : CloseParen , Semicolon ( ) . name : Semicolon , IntKeyword ( ) . name : IntKeyword , IntegerLiteral ( ) . name : IntegerLiteral , Identifier ( ) . name : Identifier , ReturnKeyword ( ) . name : ReturnKeyword } [EOL] [EOL] [EOL] def lex ( program ) : [EOL] [docstring] [EOL] tokens = list ( ) [EOL] while len ( program ) > [number] : [EOL] hit = first_matching_regex ( program ) [EOL] if hit is None : [EOL] break [EOL] else : [EOL] value = program [ hit [ [number] ] : hit [ [number] ] ] [EOL] token = VALID_TOKENS [ hit [ [number] ] . name ] ( value ) [EOL] tokens . append ( token ) [EOL] program = program [ hit [ [number] ] : ] [EOL] return tokens [EOL] [EOL] def is_token_valid ( potential_token ) : [EOL] for key , value in VALID_TOKENS . items ( ) : [EOL] if re . match ( value ( ) . regex_pattern , potential_token ) : [EOL] return True [EOL] return False [EOL] [EOL] def first_matching_regex ( string ) : [EOL] [docstring] [EOL] all_hits = list ( ) [EOL] for key , value in VALID_TOKENS . items ( ) : [EOL] hits = [ ( key , m . start ( [number] ) , m . end ( [number] ) ) for m in re . finditer ( value ( ) . regex_pattern , string ) ] [EOL] all_hits . extend ( hits ) [EOL] if len ( all_hits ) > [number] : [EOL] first_hit = sorted ( all_hits , key = lambda tup : ( tup [ [number] ] , tup [ [number] ] ) ) [ [number] ] [EOL] return ( Token ( first_hit [ [number] ] , VALID_TOKENS [ first_hit [ [number] ] ] ) , first_hit [ [number] ] , first_hit [ [number] ] ) [EOL] else : [EOL] [comment] [EOL] [comment] [EOL] return None [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $None$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
import builtins [EOL] class Token ( object ) : [EOL] [docstring] [EOL] [EOL] def __init__ ( self , name , regex_pattern , value = None ) : [EOL] self . name = name [EOL] self . regex_pattern = regex_pattern [EOL] self . value = value [EOL] [EOL] def __eq__ ( self , other ) : [EOL] return self . name == other . name and self . regex_pattern == other . regex_pattern and self . value == other . value [EOL] [EOL] def __hash__ ( self ) : [EOL] return hash ( ( self . name , self . regex_pattern , self . value ) ) [EOL] [EOL] def __repr__ ( self ) : [EOL] return f"{ self . name } [string] { self . regex_pattern } [string] { self . value }" [EOL] [EOL] class OpenBrace ( Token ) : [EOL] [EOL] def __init__ ( self , value = None ) : [EOL] Token . __init__ ( self , [string] , [string] , value ) [EOL] [EOL] class CloseBrace ( Token ) : [EOL] [EOL] def __init__ ( self , value = None ) : [EOL] Token . __init__ ( self , [string] , [string] , value ) [EOL] [EOL] class OpenParen ( Token ) : [EOL] [EOL] def __init__ ( self , value = None ) : [EOL] Token . __init__ ( self , [string] , [string] , value ) [EOL] [EOL] class CloseParen ( Token ) : [EOL] [EOL] def __init__ ( self , value = None ) : [EOL] Token . __init__ ( self , [string] , [string] , value ) [EOL] [EOL] class Semicolon ( Token ) : [EOL] [EOL] def __init__ ( self , value = None ) : [EOL] Token . __init__ ( self , [string] , [string] , value ) [EOL] [EOL] class IntKeyword ( Token ) : [EOL] [EOL] def __init__ ( self , value = None ) : [EOL] Token . __init__ ( self , [string] , [string] , value ) [EOL] [EOL] class ReturnKeyword ( Token ) : [EOL] [EOL] def __init__ ( self , value = None ) : [EOL] Token . __init__ ( self , [string] , [string] , value ) [EOL] [EOL] class Identifier ( Token ) : [EOL] [EOL] def __init__ ( self , value = None ) : [EOL] Token . __init__ ( self , [string] , [string] , value ) [EOL] [EOL] class IntegerLiteral ( Token ) : [EOL] [EOL] def __init__ ( self , value = None ) : [EOL] Token . __init__ ( self , [string] , [string] , value ) [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0
from typing import Any [EOL] import typing [EOL] from ccompiler import * [EOL] import pytest [EOL] from helpers import * [EOL] [EOL] class TestTokenValidity ( object ) : [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ ( [string] , True ) , ( [string] , True ) , ( [string] , True ) , ( [string] , True ) , ( [string] , True ) , ( [string] , True ) , ( [string] , True ) , ( [string] , False ) ] ) def test_token_validity ( self , token_input , expected ) : [EOL] actual = is_token_valid ( token_input ) [EOL] assert actual == expected [EOL] [EOL] def test_simple_token_validity ( self ) : [EOL] actual = is_token_valid ( [string] ) [EOL] assert actual is True [EOL] [EOL] class TestLexer ( object ) : [EOL] [EOL] def test_first_matching_regex ( self ) : [EOL] program = [string] [EOL] actual = first_matching_regex ( program ) [EOL] print ( actual ) [EOL] assert actual [ [number] ] . name == [string] [EOL] assert actual [ [number] ] == [number] and actual [ [number] ] == [number] [EOL] [EOL] def test_lexing_simple_program ( self ) : [EOL] simple_program = [string] [EOL] result = lex ( simple_program ) [EOL] [comment] [EOL] assert result == [ IntKeyword ( [string] ) , Identifier ( [string] ) , OpenParen ( [string] ) , CloseParen ( [string] ) , OpenBrace ( [string] ) , ReturnKeyword ( [string] ) , IntegerLiteral ( [string] ) , Semicolon ( [string] ) , CloseBrace ( [string] ) ] [EOL] [EOL] @ pytest . mark . parametrize ( [string] , [ create_test_tuple ( [string] ) , create_test_tuple ( [string] ) ] ) def test_lexing ( self , name , source_location , tokens_location ) : [EOL] program = ExampleProgramWithTokens ( name , source_location , tokens_location ) [EOL] actual_tokens = lex ( program . source ) [EOL] assert actual_tokens == program . tokens [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.Any$ 0 0 0 $builtins.str$ 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $builtins.str$ 0 0 0 $typing.Any$ 0 0 0 $builtins.str$ 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 $typing.Any$ 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0 0 0
from typing import Any [EOL] import typing [EOL] import pytest [EOL] from tokens import * [EOL] [EOL] class TestTokens ( object ) : [EOL] [EOL] def test_token_equality ( self ) : [EOL] token1 = Token ( [string] , [string] , [string] ) [EOL] token2 = Token ( [string] , [string] , [string] ) [EOL] assert token1 == token2 [EOL]	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 0 0 0 0 0 0 0 0 0 0 $typing.Any$ 0 $typing.Any$ 0